WEBVTT
Kind: captions
Language: en

00:00:15.260 --> 00:00:18.260
Many believe driving is an activity

00:00:18.260 --> 00:00:20.260
solely reserved for those who can see.

00:00:20.260 --> 00:00:23.260
A blind person driving a vehicle safely and independently

00:00:23.260 --> 00:00:26.260
was thought to be an impossible task, until now.

00:00:26.260 --> 00:00:28.260
Hello, my name is Dennis Hong,

00:00:28.260 --> 00:00:30.260
and we're bringing freedom and independence to the blind

00:00:30.260 --> 00:00:33.260
by building a vehicle for the visually impaired.

00:00:33.260 --> 00:00:36.260
So before I talk about this car for the blind,

00:00:36.260 --> 00:00:38.260
let me briefly tell you about another project that I worked on

00:00:38.260 --> 00:00:40.260
called the DARPA Urban Challenge.

00:00:40.260 --> 00:00:42.260
Now this was about building a robotic car

00:00:42.260 --> 00:00:44.260
that can drive itself.

00:00:44.260 --> 00:00:46.260
You press start, nobody touches anything,

00:00:46.260 --> 00:00:49.260
and it can reach its destination fully autonomously.

00:00:49.260 --> 00:00:52.260
So in 2007, our team won half a million dollars

00:00:52.260 --> 00:00:54.260
by placing third place in this competition.

00:00:54.260 --> 00:00:56.260
So about that time,

00:00:56.260 --> 00:00:58.260
the National Federation of the Blind, or NFB,

00:00:58.260 --> 00:01:00.260
challenged the research committee

00:01:00.260 --> 00:01:02.260
about who can develop a car

00:01:02.260 --> 00:01:04.260
that lets a blind person drive safely and independently.

00:01:04.260 --> 00:01:06.260
We decided to give it a try,

00:01:06.260 --> 00:01:08.260
because we thought, "Hey, how hard could it be?"

00:01:08.260 --> 00:01:10.260
We have already an autonomous vehicle.

00:01:10.260 --> 00:01:12.260
We just put a blind person in it and we're done, right?

00:01:12.260 --> 00:01:14.260
(Laughter)

00:01:14.260 --> 00:01:16.260
We couldn't have been more wrong.

00:01:16.260 --> 00:01:18.260
What NFB wanted

00:01:18.260 --> 00:01:21.260
was not a vehicle that can drive a blind person around,

00:01:21.260 --> 00:01:24.260
but a vehicle where a blind person can make active decisions and drive.

00:01:24.260 --> 00:01:26.260
So we had to throw everything out the window

00:01:26.260 --> 00:01:28.260
and start from scratch.

00:01:28.260 --> 00:01:30.260
So to test this crazy idea,

00:01:30.260 --> 00:01:32.260
we developed a small dune buggy prototype vehicle

00:01:32.260 --> 00:01:34.260
to test the feasibility.

00:01:34.260 --> 00:01:36.260
And in the summer of 2009,

00:01:36.260 --> 00:01:39.260
we invited dozens of blind youth from all over the country

00:01:39.260 --> 00:01:41.260
and gave them a chance to take it for a spin.

00:01:41.260 --> 00:01:43.260
It was an absolutely amazing experience.

00:01:43.260 --> 00:01:45.260
But the problem with this car was

00:01:45.260 --> 00:01:48.260
it was designed to only be driven in a very controlled environment,

00:01:48.260 --> 00:01:50.260
in a flat, closed-off parking lot --

00:01:50.260 --> 00:01:52.260
even the lanes defined by red traffic cones.

00:01:52.260 --> 00:01:54.260
So with this success,

00:01:54.260 --> 00:01:56.260
we decided to take the next big step,

00:01:56.260 --> 00:01:59.260
to develop a real car that can be driven on real roads.

00:01:59.260 --> 00:02:01.260
So how does it work?

00:02:01.260 --> 00:02:03.260
Well, it's a rather complex system,

00:02:03.260 --> 00:02:06.260
but let me try to explain it, maybe simplify it.

00:02:06.260 --> 00:02:08.260
So we have three steps.

00:02:08.260 --> 00:02:10.260
We have perception, computation

00:02:10.260 --> 00:02:12.260
and non-visual interfaces.

00:02:12.260 --> 00:02:14.260
Now obviously the driver cannot see,

00:02:14.260 --> 00:02:16.260
so the system needs to perceive the environment

00:02:16.260 --> 00:02:18.260
and gather information for the driver.

00:02:18.260 --> 00:02:21.260
For that, we use an initial measurement unit.

00:02:21.260 --> 00:02:23.260
So it measures acceleration, angular acceleration --

00:02:23.260 --> 00:02:25.260
like a human ear, inner ear.

00:02:25.260 --> 00:02:27.260
We fuse that information with a GPS unit

00:02:27.260 --> 00:02:30.260
to get an estimate of the location of the car.

00:02:30.260 --> 00:02:33.260
We also use two cameras to detect the lanes of the road.

00:02:33.260 --> 00:02:35.260
And we also use three laser range finders.

00:02:35.260 --> 00:02:38.260
The lasers scan the environment to detect obstacles --

00:02:38.260 --> 00:02:40.260
a car approaching from the front, the back

00:02:40.260 --> 00:02:43.260
and also any obstacles that run into the roads,

00:02:43.260 --> 00:02:45.260
any obstacles around the vehicle.

00:02:45.260 --> 00:02:48.260
So all this vast amount of information is then fed into the computer,

00:02:48.260 --> 00:02:50.260
and the computer can do two things.

00:02:50.260 --> 00:02:53.260
One is, first of all, process this information

00:02:53.260 --> 00:02:55.260
to have an understanding of the environment --

00:02:55.260 --> 00:02:58.260
these are the lanes of the road, there's the obstacles --

00:02:58.260 --> 00:03:00.260
and convey this information to the driver.

00:03:00.260 --> 00:03:02.260
The system is also smart enough

00:03:02.260 --> 00:03:04.260
to figure out the safest way to operate the car.

00:03:04.260 --> 00:03:06.260
So we can also generate instructions

00:03:06.260 --> 00:03:08.260
on how to operate the controls of the vehicle.

00:03:08.260 --> 00:03:10.260
But the problem is this: How do we convey

00:03:10.260 --> 00:03:12.260
this information and instructions

00:03:12.260 --> 00:03:14.260
to a person who cannot see

00:03:14.260 --> 00:03:17.260
fast enough and accurate enough so he can drive?

00:03:17.260 --> 00:03:19.260
So for this, we developed many different types

00:03:19.260 --> 00:03:22.260
of non-visual user interface technology.

00:03:22.260 --> 00:03:24.260
So starting from a three-dimensional ping sound system,

00:03:24.260 --> 00:03:26.260
a vibrating vest,

00:03:26.260 --> 00:03:29.260
a click wheel with voice commands, a leg strip,

00:03:29.260 --> 00:03:31.260
even a shoe that applies pressure to the foot.

00:03:31.260 --> 00:03:33.260
But today we're going to talk about

00:03:33.260 --> 00:03:35.260
three of these non-visual user interfaces.

00:03:35.260 --> 00:03:38.260
Now the first interface is called a DriveGrip.

00:03:38.260 --> 00:03:40.260
So these are a pair of gloves,

00:03:40.260 --> 00:03:42.260
and it has vibrating elements on the knuckle part

00:03:42.260 --> 00:03:45.260
so you can convey instructions about how to steer --

00:03:45.260 --> 00:03:47.260
the direction and the intensity.

00:03:47.260 --> 00:03:49.260
Another device is called SpeedStrip.

00:03:49.260 --> 00:03:52.260
So this is a chair -- as a matter of fact, it's actually a massage chair.

00:03:52.260 --> 00:03:56.260
We gut it out, and we rearrange the vibrating elements in different patterns,

00:03:56.260 --> 00:03:59.260
and we actuate them to convey information about the speed,

00:03:59.260 --> 00:04:02.260
and also instructions how to use the gas and the brake pedal.

00:04:02.260 --> 00:04:04.260
So over here, you can see

00:04:04.260 --> 00:04:06.260
how the computer understands the environment,

00:04:06.260 --> 00:04:08.260
and because you cannot see the vibration,

00:04:08.260 --> 00:04:11.260
we actually put red LED's on the driver so that you can see what's happening.

00:04:11.260 --> 00:04:13.260
This is the sensory data,

00:04:13.260 --> 00:04:16.260
and that data is transferred to the devices through the computer.

00:04:16.260 --> 00:04:18.260
So these two devices, DriveGrip and SpeedStrip,

00:04:18.260 --> 00:04:20.260
are very effective.

00:04:20.260 --> 00:04:22.260
But the problem is

00:04:22.260 --> 00:04:24.260
these are instructional cue devices.

00:04:24.260 --> 00:04:26.260
So this is not really freedom, right?

00:04:26.260 --> 00:04:28.260
The computer tells you how to drive --

00:04:28.260 --> 00:04:30.260
turn left, turn right, speed up, stop.

00:04:30.260 --> 00:04:32.260
We call this the "backseat-driver problem."

00:04:32.260 --> 00:04:35.260
So we're moving away from the instructional cue devices,

00:04:35.260 --> 00:04:37.260
and we're now focusing more

00:04:37.260 --> 00:04:39.260
on the informational devices.

00:04:39.260 --> 00:04:41.260
A good example for this informational non-visual user interface

00:04:41.260 --> 00:04:43.260
is called AirPix.

00:04:43.260 --> 00:04:45.260
So think of it as a monitor for the blind.

00:04:45.260 --> 00:04:47.260
So it's a small tablet, has many holes in it,

00:04:47.260 --> 00:04:49.260
and compressed air comes out,

00:04:49.260 --> 00:04:51.260
so it can actually draw images.

00:04:51.260 --> 00:04:53.260
So even though you are blind, you can put your hand over it,

00:04:53.260 --> 00:04:55.260
you can see the lanes of the road and obstacles.

00:04:55.260 --> 00:04:58.260
Actually, you can also change the frequency of the air coming out

00:04:58.260 --> 00:05:00.260
and possibly the temperature.

00:05:00.260 --> 00:05:03.260
So it's actually a multi-dimensional user interface.

00:05:03.260 --> 00:05:06.260
So here you can see the left camera, the right camera from the vehicle

00:05:06.260 --> 00:05:09.260
and how the computer interprets that and sends that information to the AirPix.

00:05:09.260 --> 00:05:11.260
For this, we're showing a simulator,

00:05:11.260 --> 00:05:14.260
a blind person driving using the AirPix.

00:05:14.260 --> 00:05:17.260
This simulator was also very useful for training the blind drivers

00:05:17.260 --> 00:05:19.260
and also quickly testing different types of ideas

00:05:19.260 --> 00:05:21.260
for different types of non-visual user interfaces.

00:05:21.260 --> 00:05:23.260
So basically that's how it works.

00:05:23.260 --> 00:05:25.260
So just a month ago,

00:05:25.260 --> 00:05:27.260
on January 29th,

00:05:27.260 --> 00:05:29.260
we unveiled this vehicle for the very first time to the public

00:05:29.260 --> 00:05:32.260
at the world-famous Daytona International Speedway

00:05:32.260 --> 00:05:34.260
during the Rolex 24 racing event.

00:05:34.260 --> 00:05:37.260
We also had some surprises. Let's take a look.

00:05:37.260 --> 00:05:47.260
(Music)

00:05:47.260 --> 00:05:51.260
(Video) Announcer: This is an historic day in January.

00:05:51.260 --> 00:05:55.260
He's coming up to the grandstand, fellow Federationists.

00:05:55.260 --> 00:06:01.260
(Cheering)

00:06:01.260 --> 00:06:04.260
(Honking)

00:06:04.260 --> 00:06:06.260
There's the grandstand now.

00:06:06.260 --> 00:06:10.260
And he's [unclear] following that van that's out in front of him.

00:06:10.260 --> 00:06:12.260
Well there comes the first box.

00:06:12.260 --> 00:06:15.260
Now let's see if Mark avoids it.

00:06:15.260 --> 00:06:18.260
He does. He passes it on the right.

00:06:20.260 --> 00:06:23.260
Third box is out. The fourth box is out.

00:06:23.260 --> 00:06:26.260
And he's perfectly making his way between the two.

00:06:26.260 --> 00:06:28.260
He's closing in on the van

00:06:28.260 --> 00:06:31.260
to make the moving pass.

00:06:32.260 --> 00:06:34.260
Well this is what it's all about,

00:06:34.260 --> 00:06:38.260
this kind of dynamic display of audacity and ingenuity.

00:06:39.260 --> 00:06:42.260
He's approaching the end of the run,

00:06:42.260 --> 00:06:47.260
makes his way between the barrels that are set up there.

00:06:47.260 --> 00:06:50.260
(Honking)

00:06:50.260 --> 00:06:53.260
(Applause)

00:06:56.260 --> 00:06:58.260
Dennis Hong: I'm so happy for you.

00:06:58.260 --> 00:07:00.260
Mark's going to give me a ride back to the hotel.

00:07:00.260 --> 00:07:02.260
Mark Riccobono: Yes.

00:07:05.260 --> 00:07:14.260
(Applause)

00:07:14.260 --> 00:07:16.260
DH: So since we started this project,

00:07:16.260 --> 00:07:19.260
we've been getting hundreds of letters, emails, phone calls

00:07:19.260 --> 00:07:21.260
from people from all around the world.

00:07:21.260 --> 00:07:24.260
Letters thanking us, but sometimes you also get funny letters like this one:

00:07:24.260 --> 00:07:28.260
"Now I understand why there is Braille on a drive-up ATM machine."

00:07:28.260 --> 00:07:30.260
(Laughter)

00:07:30.260 --> 00:07:32.260
But sometimes --

00:07:32.260 --> 00:07:34.260
(Laughter)

00:07:34.260 --> 00:07:36.260
But sometimes I also do get --

00:07:36.260 --> 00:07:38.260
I wouldn't call it hate mail --

00:07:38.260 --> 00:07:40.260
but letters of really strong concern:

00:07:40.260 --> 00:07:42.260
"Dr. Hong, are you insane,

00:07:42.260 --> 00:07:44.260
trying to put blind people on the road?

00:07:44.260 --> 00:07:46.260
You must be out of your mind."

00:07:46.260 --> 00:07:48.260
But this vehicle is a prototype vehicle,

00:07:48.260 --> 00:07:50.260
and it's not going to be on the road

00:07:50.260 --> 00:07:52.260
until it's proven as safe as, or safer than, today's vehicle.

00:07:52.260 --> 00:07:55.260
And I truly believe that this can happen.

00:07:55.260 --> 00:07:57.260
But still, will the society,

00:07:57.260 --> 00:07:59.260
would they accept such a radical idea?

00:07:59.260 --> 00:08:01.260
How are we going to handle insurance?

00:08:01.260 --> 00:08:03.260
How are we going to issue driver's licenses?

00:08:03.260 --> 00:08:06.260
There's many of these different kinds of hurdles besides technology challenges

00:08:06.260 --> 00:08:09.260
that we need to address before this becomes a reality.

00:08:09.260 --> 00:08:11.260
Of course, the main goal of this project

00:08:11.260 --> 00:08:13.260
is to develop a car for the blind.

00:08:13.260 --> 00:08:15.260
But potentially more important than this

00:08:15.260 --> 00:08:18.260
is the tremendous value of the spin-off technology

00:08:18.260 --> 00:08:20.260
that can come from this project.

00:08:20.260 --> 00:08:22.260
The sensors that are used can see through the dark,

00:08:22.260 --> 00:08:24.260
the fog and rain.

00:08:24.260 --> 00:08:26.260
And together with this new type of interfaces,

00:08:26.260 --> 00:08:28.260
we can use these technologies

00:08:28.260 --> 00:08:30.260
and apply them to safer cars for sighted people.

00:08:30.260 --> 00:08:33.260
Or for the blind, everyday home appliances --

00:08:33.260 --> 00:08:35.260
in the educational setting, in the office setting.

00:08:35.260 --> 00:08:38.260
Just imagine, in a classroom a teacher writes on the blackboard

00:08:38.260 --> 00:08:41.260
and a blind student can see what's written and read

00:08:41.260 --> 00:08:43.260
using these non-visual interfaces.

00:08:43.260 --> 00:08:46.260
This is priceless.

00:08:46.260 --> 00:08:49.260
So today, the things I've showed you today, is just the beginning.

00:08:49.260 --> 00:08:51.260
Thank you very much.

00:08:51.260 --> 00:09:02.260
(Applause)

