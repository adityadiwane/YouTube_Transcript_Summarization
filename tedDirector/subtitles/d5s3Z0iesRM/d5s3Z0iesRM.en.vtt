WEBVTT
Kind: captions
Language: en

00:00:13.160 --> 00:00:19.160
I'm here to enlist you

00:00:19.160 --> 00:00:27.160
in helping reshape the story about how humans and other critters get things done.

00:00:27.160 --> 00:00:32.160
Here is the old story -- we've already heard a little bit about it:

00:00:32.160 --> 00:00:39.160
biology is war in which only the fiercest survive;

00:00:39.160 --> 00:00:47.160
businesses and nations succeed only by defeating,

00:00:47.160 --> 00:00:53.160
destroying and dominating competition;

00:00:53.160 --> 00:01:00.160
politics is about your side winning at all costs.

00:01:00.160 --> 00:01:08.160
But I think we can see the very beginnings of a new story beginning to emerge.

00:01:08.160 --> 00:01:15.160
It's a narrative spread across a number of different disciplines,

00:01:15.160 --> 00:01:23.160
in which cooperation, collective action and complex interdependencies

00:01:23.160 --> 00:01:26.160
play a more important role.

00:01:26.160 --> 00:01:35.160
And the central, but not all-important, role of competition and survival of the fittest

00:01:35.160 --> 00:01:39.160
shrinks just a little bit to make room.

00:01:39.160 --> 00:01:46.160
I started thinking about the relationship between communication, media

00:01:46.160 --> 00:01:51.160
and collective action when I wrote "Smart Mobs,"

00:01:51.160 --> 00:01:56.160
and I found that when I finished the book, I kept thinking about it.

00:01:56.160 --> 00:02:02.160
In fact, if you look back, human communication media

00:02:02.160 --> 00:02:09.160
and the ways in which we organize socially have been co-evolving for quite a long time.

00:02:09.160 --> 00:02:13.160
Humans have lived for much, much longer

00:02:13.160 --> 00:02:20.160
than the approximately 10,000 years of settled agricultural civilization

00:02:20.160 --> 00:02:28.160
in small family groups. Nomadic hunters bring down rabbits, gathering food.

00:02:28.160 --> 00:02:33.160
The form of wealth in those days was enough food to stay alive.

00:02:33.160 --> 00:02:40.160
But at some point, they banded together to hunt bigger game.

00:02:40.160 --> 00:02:43.160
And we don't know exactly how they did this,

00:02:43.160 --> 00:02:48.160
although they must have solved some collective action problems;

00:02:48.160 --> 00:02:52.160
it only makes sense that you can't hunt mastodons

00:02:52.160 --> 00:02:55.160
while you're fighting with the other groups.

00:02:55.160 --> 00:02:57.160
And again, we have no way of knowing,

00:02:57.160 --> 00:03:02.160
but it's clear that a new form of wealth must have emerged.

00:03:02.160 --> 00:03:07.160
More protein than a hunter's family could eat before it rotted.

00:03:07.160 --> 00:03:09.160
So that raised a social question

00:03:09.160 --> 00:03:12.160
that I believe must have driven new social forms.

00:03:12.160 --> 00:03:17.160
Did the people who ate that mastodon meat owe something

00:03:17.160 --> 00:03:19.160
to the hunters and their families?

00:03:19.160 --> 00:03:23.160
And if so, how did they make arrangements?

00:03:23.160 --> 00:03:26.160
Again, we can't know, but we can be pretty sure that some form of

00:03:26.160 --> 00:03:31.160
symbolic communication must have been involved.

00:03:31.160 --> 00:03:36.160
Of course, with agriculture came the first big civilizations,

00:03:36.160 --> 00:03:41.160
the first cities built of mud and brick, the first empires.

00:03:41.160 --> 00:03:45.160
And it was the administers of these empires

00:03:45.160 --> 00:03:51.160
who began hiring people to keep track of the wheat and sheep and wine that was owed

00:03:51.160 --> 00:03:53.160
and the taxes that was owed on them

00:03:53.160 --> 00:03:57.160
by making marks; marks on clay in that time.

00:03:57.160 --> 00:04:02.160
Not too much longer after that, the alphabet was invented.

00:04:02.160 --> 00:04:08.160
And this powerful tool was really reserved, for thousands of years,

00:04:08.160 --> 00:04:18.160
for the elite administrators (Laughter) who kept track of accounts for the empires.

00:04:18.160 --> 00:04:23.160
And then another communication technology enabled new media:

00:04:23.160 --> 00:04:28.160
the printing press came along, and within decades,

00:04:28.160 --> 00:04:30.160
millions of people became literate.

00:04:30.160 --> 00:04:34.160
And from literate populations,

00:04:34.160 --> 00:04:38.160
new forms of collective action emerged in the spheres of knowledge,

00:04:38.160 --> 00:04:42.160
religion and politics.

00:04:42.160 --> 00:04:47.160
We saw scientific revolutions, the Protestant Reformation,

00:04:47.160 --> 00:04:53.160
constitutional democracies possible where they had not been possible before.

00:04:53.160 --> 00:04:55.160
Not created by the printing press,

00:04:55.160 --> 00:05:00.160
but enabled by the collective action that emerges from literacy.

00:05:00.160 --> 00:05:04.160
And again, new forms of wealth emerged.

00:05:04.160 --> 00:05:09.160
Now, commerce is ancient. Markets are as old as the crossroads.

00:05:09.160 --> 00:05:13.160
But capitalism, as we know it, is only a few hundred years old,

00:05:13.160 --> 00:05:18.160
enabled by cooperative arrangements and technologies,

00:05:18.160 --> 00:05:21.160
such as the joint-stock ownership company,

00:05:21.160 --> 00:05:26.160
shared liability insurance, double-entry bookkeeping.

00:05:26.160 --> 00:05:31.160
Now of course, the enabling technologies are based on the Internet,

00:05:31.160 --> 00:05:38.160
and in the many-to-many era, every desktop is now a printing press,

00:05:38.160 --> 00:05:44.160
a broadcasting station, a community or a marketplace.

00:05:44.160 --> 00:05:47.160
Evolution is speeding up.

00:05:47.160 --> 00:05:53.160
More recently, that power is untethering and leaping off the desktops,

00:05:53.160 --> 00:05:59.160
and very, very quickly, we're going to see a significant proportion, if not the majority of

00:05:59.160 --> 00:06:07.160
the human race, walking around holding, carrying or wearing supercomputers

00:06:07.160 --> 00:06:10.160
linked at speeds greater

00:06:10.160 --> 00:06:14.160
than what we consider to be broadband today.

00:06:14.160 --> 00:06:17.160
Now, when I started looking into collective action,

00:06:17.160 --> 00:06:23.160
the considerable literature on it is based on what sociologists call "social dilemmas."

00:06:23.160 --> 00:06:26.160
And there are a couple of mythic narratives of social dilemmas.

00:06:26.160 --> 00:06:29.160
I'm going to talk briefly about two of them:

00:06:29.160 --> 00:06:32.160
the prisoner's dilemma and the tragedy of the commons.

00:06:32.160 --> 00:06:34.160
Now, when I talked about this with Kevin Kelly,

00:06:34.160 --> 00:06:38.160
he assured me that everybody in this audience pretty much knows the details

00:06:38.160 --> 00:06:40.160
of the prisoner's dilemma,

00:06:40.160 --> 00:06:43.160
so I'm just going to go over that very, very quickly.

00:06:43.160 --> 00:06:50.160
If you have more questions about it, ask Kevin Kelly later. (Laughter)

00:06:50.160 --> 00:06:53.160
The prisoner's dilemma is actually a story that's overlaid

00:06:53.160 --> 00:06:57.160
on a mathematical matrix that came out of the game theory

00:06:57.160 --> 00:07:01.160
in the early years of thinking about nuclear war:

00:07:01.160 --> 00:07:03.160
two players who couldn't trust each other.

00:07:03.160 --> 00:07:06.160
Let me just say that every unsecured transaction

00:07:06.160 --> 00:07:09.160
is a good example of a prisoner's dilemma.

00:07:09.160 --> 00:07:12.160
Person with the goods, person with the money,

00:07:12.160 --> 00:07:16.160
because they can't trust each other, are not going to exchange.

00:07:16.160 --> 00:07:19.160
Neither one wants to be the first one

00:07:19.160 --> 00:07:21.160
or they're going to get the sucker's payoff,

00:07:21.160 --> 00:07:25.160
but both lose, of course, because they don't get what they want.

00:07:25.160 --> 00:07:29.160
If they could only agree, if they could only turn a prisoner's dilemma into

00:07:29.160 --> 00:07:35.160
a different payoff matrix called an assurance game, they could proceed.

00:07:35.160 --> 00:07:39.160
Twenty years ago, Robert Axelrod used the prisoner's dilemma

00:07:39.160 --> 00:07:44.160
as a probe of the biological question:

00:07:44.160 --> 00:07:49.160
if we are here because our ancestors were such fierce competitors,

00:07:49.160 --> 00:07:51.160
how does cooperation exist at all?

00:07:51.160 --> 00:07:53.160
He started a computer tournament for

00:07:53.160 --> 00:07:58.160
people to submit prisoner's dilemma strategies and discovered,

00:07:58.160 --> 00:08:02.160
much to his surprise, that a very, very simple strategy won --

00:08:02.160 --> 00:08:06.160
it won the first tournament, and even after everyone knew it won,

00:08:06.160 --> 00:08:13.160
it won the second tournament -- that's known as tit for tat.

00:08:13.160 --> 00:08:19.160
Another economic game that may not be as well known as the prisoner's dilemma

00:08:19.160 --> 00:08:21.160
is the ultimatum game,

00:08:21.160 --> 00:08:23.160
and it's also a very interesting probe of

00:08:23.160 --> 00:08:29.160
our assumptions about the way people make economic transactions.

00:08:29.160 --> 00:08:32.160
Here's how the game is played: there are two players;

00:08:32.160 --> 00:08:34.160
they've never played the game before,

00:08:34.160 --> 00:08:37.160
they will not play the game again, they don't know each other,

00:08:37.160 --> 00:08:40.160
and they are, in fact, in separate rooms.

00:08:40.160 --> 00:08:42.160
First player is offered a hundred dollars

00:08:42.160 --> 00:08:48.160
and is asked to propose a split: 50/50, 90/10,

00:08:48.160 --> 00:08:55.160
whatever that player wants to propose. The second player either accepts the split --

00:08:55.160 --> 00:08:58.160
both players are paid and the game is over --

00:08:58.160 --> 00:09:04.160
or rejects the split -- neither player is paid and the game is over.

00:09:04.160 --> 00:09:08.160
Now, the fundamental basis of neoclassical economics

00:09:08.160 --> 00:09:12.160
would tell you it's irrational to reject a dollar

00:09:12.160 --> 00:09:17.160
because someone you don't know in another room is going to get 99.

00:09:17.160 --> 00:09:23.160
Yet in thousands of trials with American and European and Japanese students,

00:09:23.160 --> 00:09:29.160
a significant percentage would reject any offer that's not close to 50/50.

00:09:29.160 --> 00:09:34.160
And although they were screened and didn't know about the game

00:09:34.160 --> 00:09:36.160
and had never played the game before,

00:09:36.160 --> 00:09:39.160
proposers seemed to innately know this

00:09:39.160 --> 00:09:45.160
because the average proposal was surprisingly close to 50/50.

00:09:45.160 --> 00:09:47.160
Now, the interesting part comes in more recently

00:09:47.160 --> 00:09:51.160
when anthropologists began taking this game to other cultures

00:09:51.160 --> 00:09:54.160
and discovered, to their surprise,

00:09:54.160 --> 00:09:58.160
that slash-and-burn agriculturalists in the Amazon

00:09:58.160 --> 00:10:03.160
or nomadic pastoralists in Central Asia or a dozen different cultures --

00:10:03.160 --> 00:10:08.160
each had radically different ideas of what is fair.

00:10:08.160 --> 00:10:14.160
Which suggests that instead of there being an innate sense of fairness,

00:10:14.160 --> 00:10:17.160
that somehow the basis of our economic

00:10:17.160 --> 00:10:23.160
transactions can be influenced by our social institutions,

00:10:23.160 --> 00:10:25.160
whether we know that or not.

00:10:25.160 --> 00:10:30.160
The other major narrative of social dilemmas is the tragedy of the commons.

00:10:30.160 --> 00:10:36.160
Garrett Hardin used it to talk about overpopulation in the late 1960s.

00:10:36.160 --> 00:10:42.160
He used the example of a common grazing area in which each person

00:10:42.160 --> 00:10:45.160
by simply maximizing their own flock

00:10:45.160 --> 00:10:48.160
led to overgrazing and the depletion of the resource.

00:10:48.160 --> 00:10:50.160
He had the rather gloomy conclusion that

00:10:50.160 --> 00:10:55.160
humans will inevitably despoil any common pool resource

00:10:55.160 --> 00:11:01.160
in which people cannot be restrained from using it.

00:11:01.160 --> 00:11:04.160
Now, Elinor Ostrom, a political scientist, in

00:11:04.160 --> 00:11:09.160
1990 asked the interesting question that any good scientist should ask,

00:11:09.160 --> 00:11:14.160
which is: is it really true that humans will always despoil commons?

00:11:14.160 --> 00:11:18.160
So she went out and looked at what data she could find.

00:11:18.160 --> 00:11:22.160
She looked at thousands of cases of humans sharing watersheds,

00:11:22.160 --> 00:11:29.160
forestry resources, fisheries, and discovered that yes, in case after case,

00:11:29.160 --> 00:11:33.160
humans destroyed the commons that they depended on.

00:11:33.160 --> 00:11:40.160
But she also found many instances in which people escaped the prisoner's dilemma;

00:11:40.160 --> 00:11:46.160
in fact, the tragedy of the commons is a multiplayer prisoner's dilemma.

00:11:46.160 --> 00:11:51.160
And she said that people are only prisoners if they consider themselves to be.

00:11:51.160 --> 00:11:55.160
They escape by creating institutions for collective action.

00:11:55.160 --> 00:11:59.160
And she discovered, I think most interestingly,

00:11:59.160 --> 00:12:02.160
that among those institutions that worked,

00:12:02.160 --> 00:12:04.160
there were a number of common design

00:12:04.160 --> 00:12:07.160
principles, and those principles seem to be

00:12:07.160 --> 00:12:11.160
missing from those institutions that don't work.

00:12:11.160 --> 00:12:13.160
I'm moving very quickly over a number of

00:12:13.160 --> 00:12:16.160
disciplines. In biology, the notions of symbiosis,

00:12:16.160 --> 00:12:22.160
group selection, evolutionary psychology are contested, to be sure.

00:12:22.160 --> 00:12:27.160
But there is really no longer any major debate over the fact that

00:12:27.160 --> 00:12:33.160
cooperative arrangements have moved from a peripheral role to a central role

00:12:33.160 --> 00:12:39.160
in biology, from the level of the cell to the level of the ecology.

00:12:39.160 --> 00:12:44.160
And again, our notions of individuals as economic beings

00:12:44.160 --> 00:12:46.160
have been overturned.

00:12:46.160 --> 00:12:51.160
Rational self-interest is not always the dominating factor.

00:12:51.160 --> 00:12:59.160
In fact, people will act to punish cheaters, even at a cost to themselves.

00:12:59.160 --> 00:13:01.160
And most recently, neurophysiological measures

00:13:01.160 --> 00:13:07.160
have shown that people who punish cheaters in economic games

00:13:07.160 --> 00:13:11.160
show activity in the reward centers of their brain.

00:13:11.160 --> 00:13:18.160
Which led one scientist to declare that altruistic punishment

00:13:18.160 --> 00:13:22.160
may be the glue that holds societies together.

00:13:22.160 --> 00:13:27.160
Now, I've been talking about how new forms of communication and new media

00:13:27.160 --> 00:13:31.160
in the past have helped create new economic forms.

00:13:31.160 --> 00:13:36.160
Commerce is ancient. Markets are very old. Capitalism is fairly recent;

00:13:36.160 --> 00:13:40.160
socialism emerged as a reaction to that.

00:13:40.160 --> 00:13:46.160
And yet we see very little talk about how the next form may be emerging.

00:13:46.160 --> 00:13:51.160
Jim Surowiecki briefly mentioned Yochai Benkler's paper about open source,

00:13:51.160 --> 00:13:55.160
pointing to a new form of production: peer-to-peer production.

00:13:55.160 --> 00:14:01.160
I simply want you to keep in mind that if in the past, new forms of cooperation

00:14:01.160 --> 00:14:05.160
enabled by new technologies create new forms of wealth,

00:14:05.160 --> 00:14:09.160
we may be moving into yet another economic form

00:14:09.160 --> 00:14:13.160
that is significantly different from previous ones.

00:14:13.160 --> 00:14:19.160
Very briefly, let's look at some businesses. IBM, as you know, HP, Sun --

00:14:19.160 --> 00:14:25.160
some of the most fierce competitors in the IT world are open sourcing

00:14:25.160 --> 00:14:32.160
their software, are providing portfolios of patents for the commons.

00:14:32.160 --> 00:14:37.160
Eli Lilly -- in, again, the fiercely competitive pharmaceutical world --

00:14:37.160 --> 00:14:43.160
has created a market for solutions for pharmaceutical problems.

00:14:43.160 --> 00:14:48.160
Toyota, instead of treating its suppliers as a marketplace,

00:14:48.160 --> 00:14:52.160
treats them as a network and trains them to produce better,

00:14:52.160 --> 00:14:57.160
even though they are also training them to produce better for their competitors.

00:14:57.160 --> 00:15:01.160
Now none of these companies are doing this out of altruism;

00:15:01.160 --> 00:15:03.160
they're doing it because they're learning that

00:15:03.160 --> 00:15:09.160
a certain kind of sharing is in their self-interest.

00:15:09.160 --> 00:15:16.160
Open source production has shown us that world-class software, like Linux and Mozilla,

00:15:16.160 --> 00:15:22.160
can be created with neither the bureaucratic structure of the firm

00:15:22.160 --> 00:15:28.160
nor the incentives of the marketplace as we've known them.

00:15:28.160 --> 00:15:34.160
Google enriches itself by enriching thousands of bloggers through AdSense.

00:15:34.160 --> 00:15:38.160
Amazon has opened its Application Programming Interface

00:15:38.160 --> 00:15:43.160
to 60,000 developers, countless Amazon shops.

00:15:43.160 --> 00:15:49.160
They're enriching others, not out of altruism but as a way of enriching themselves.

00:15:49.160 --> 00:15:54.160
eBay solved the prisoner's dilemma and created a market

00:15:54.160 --> 00:15:58.160
where none would have existed by creating a feedback mechanism

00:15:58.160 --> 00:16:03.160
that turns a prisoner's dilemma game into an assurance game.

00:16:03.160 --> 00:16:08.160
Instead of, "Neither of us can trust each other, so we have to make suboptimal moves,"

00:16:08.160 --> 00:16:14.160
it's, "You prove to me that you are trustworthy and I will cooperate."

00:16:14.160 --> 00:16:20.160
Wikipedia has used thousands of volunteers to create a free encyclopedia

00:16:20.160 --> 00:16:27.160
with a million and a half articles in 200 languages in just a couple of years.

00:16:27.160 --> 00:16:34.160
We've seen that ThinkCycle has enabled NGOs in developing countries

00:16:34.160 --> 00:16:40.160
to put up problems to be solved by design students around the world,

00:16:40.160 --> 00:16:43.160
including something that's being used for tsunami relief right now:

00:16:43.160 --> 00:16:45.160
it's a mechanism for rehydrating

00:16:45.160 --> 00:16:48.160
cholera victims that's so simple to use it,

00:16:48.160 --> 00:16:51.160
illiterates can be trained to use it.

00:16:51.160 --> 00:16:55.160
BitTorrent turns every downloader into an uploader,

00:16:55.160 --> 00:17:00.160
making the system more efficient the more it is used.

00:17:00.160 --> 00:17:03.160
Millions of people have contributed their desktop computers

00:17:03.160 --> 00:17:08.160
when they're not using them to link together through the Internet

00:17:08.160 --> 00:17:10.160
into supercomputing collectives

00:17:10.160 --> 00:17:14.160
that help solve the protein folding problem for medical researchers --

00:17:14.160 --> 00:17:17.160
that's Folding@home at Stanford --

00:17:17.160 --> 00:17:22.160
to crack codes, to search for life in outer space.

00:17:22.160 --> 00:17:24.160
I don't think we know enough yet.

00:17:24.160 --> 00:17:28.160
I don't think we've even begun to discover what the basic principles are,

00:17:28.160 --> 00:17:31.160
but I think we can begin to think about them.

00:17:31.160 --> 00:17:34.160
And I don't have enough time to talk about all of them,

00:17:34.160 --> 00:17:36.160
but think about self-interest.

00:17:36.160 --> 00:17:39.160
This is all about self-interest that adds up to more.

00:17:39.160 --> 00:17:44.160
In El Salvador, both sides that withdrew from their civil war

00:17:44.160 --> 00:17:48.160
took moves that had been proven to mirror a prisoner's dilemma strategy.

00:17:48.160 --> 00:17:54.160
In the U.S., in the Philippines, in Kenya, around the world,

00:17:54.160 --> 00:17:57.160
citizens have self-organized political protests and

00:17:57.160 --> 00:18:03.160
get out the vote campaigns using mobile devices and SMS.

00:18:03.160 --> 00:18:06.160
Is an Apollo Project of cooperation possible?

00:18:06.160 --> 00:18:10.160
A transdisciplinary study of cooperation?

00:18:10.160 --> 00:18:14.160
I believe that the payoff would be very big.

00:18:14.160 --> 00:18:18.160
I think we need to begin developing maps of this territory

00:18:18.160 --> 00:18:20.160
so that we can talk about it across disciplines.

00:18:20.160 --> 00:18:24.160
And I am not saying that understanding cooperation 

00:18:24.160 --> 00:18:28.160
is going to cause us to be better people --

00:18:28.160 --> 00:18:31.160
and sometimes people cooperate to do bad things --

00:18:31.160 --> 00:18:34.160
but I will remind you that a few hundred years ago,

00:18:34.160 --> 00:18:38.160
people saw their loved ones die from diseases they thought

00:18:38.160 --> 00:18:43.160
were caused by sin or foreigners or evil spirits.

00:18:43.160 --> 00:18:47.160
Descartes said we need an entire new way of thinking.

00:18:47.160 --> 00:18:50.160
When the scientific method provided that new way of thinking

00:18:50.160 --> 00:18:54.160
and biology showed that microorganisms caused disease,

00:18:54.160 --> 00:18:57.160
suffering was alleviated.

00:18:57.160 --> 00:19:00.160
What forms of suffering could be alleviated,

00:19:00.160 --> 00:19:02.160
what forms of wealth could be created

00:19:02.160 --> 00:19:05.160
if we knew a little bit more about cooperation?

00:19:05.160 --> 00:19:09.160
I don't think that this transdisciplinary discourse

00:19:09.160 --> 00:19:11.160
is automatically going to happen;

00:19:11.160 --> 00:19:14.160
it's going to require effort.

00:19:14.160 --> 00:19:20.160
So I enlist you to help me get the cooperation project started.

00:19:20.160 --> 00:19:22.160
Thank you.

00:19:22.160 --> 00:19:25.160
(Applause)

