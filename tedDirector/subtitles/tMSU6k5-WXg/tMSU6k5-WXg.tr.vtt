WEBVTT
Kind: captions
Language: tr

00:00:00.000 --> 00:00:07.000
Çeviri: Sinem Çevikkan
Gözden geçirme: Sevkan Uzel

00:00:12.485 --> 00:00:15.477
On yıl önce "Son Yüzyılımız?" adını verdiğim

00:00:15.477 --> 00:00:17.800
bir kitap yazdım.

00:00:17.800 --> 00:00:21.377
Yayımcılarım soru işaretini kestiler. (Kahkaha)

00:00:21.377 --> 00:00:23.799
Amerikan yayımcılar ise başlığımızı

00:00:23.799 --> 00:00:26.668
''Son Saatimiz'' olarak değiştirdiler.

00:00:27.168 --> 00:00:30.660
Amerikalılar anlık zevklerden ve ters yüz etmekten hoşlanırlar.

00:00:30.660 --> 00:00:32.368
(Kahkaha)

00:00:32.368 --> 00:00:34.118
Benim temam şuydu:

00:00:34.118 --> 00:00:38.074
Dünyamız 45 milyon yüzyıldır varlığını sürdürdü,

00:00:38.074 --> 00:00:40.297
Ama bu seferki farklı —

00:00:40.297 --> 00:00:43.313
Bu, dünyanın geleceğinin tek bir türün,

00:00:43.313 --> 00:00:46.115
bizim türümüzün elinde bulunduğu ilk zaman.

00:00:46.115 --> 00:00:48.105
Neredeyse tüm Dünya tarihi boyunca

00:00:48.105 --> 00:00:50.041
tehditler hep doğadan geldi —

00:00:50.041 --> 00:00:53.537
salgınlar, depremler, göktaşı ve daha fazlası —

00:00:53.537 --> 00:00:58.859
Ama bundan sonra, en kötü tehditler bizden geliyor.

00:00:59.209 --> 00:01:02.260
Sadece nükleer tehdit de değil;

00:01:02.260 --> 00:01:04.381
her şeyin birbirine bağlı olduğu dünyamızda,

00:01:04.381 --> 00:01:07.614
şebeke aksaklıkları küresel biçimde katlanarak artabilir;

00:01:07.614 --> 00:01:11.350
uçak yolculuğu birkaç günde salgınları dünyaya yayabilir

00:01:11.350 --> 00:01:14.677
ve sosyal medya tam olarak ışık hızında

00:01:14.677 --> 00:01:17.354
panik ve dedikodu yayabilir.

00:01:17.894 --> 00:01:21.119
Küçük tehlikeler için çok fazla endişeleniyoruz —

00:01:21.119 --> 00:01:25.150
Olasılıksız uçak kazaları, yiyeceklerdeki kansorejenler,

00:01:25.150 --> 00:01:27.376
düşük radyasyon miktarı ve daha fazlası —

00:01:27.376 --> 00:01:30.201
ama biz ve politik başkanlarımız

00:01:30.201 --> 00:01:34.404
yok edici senaryoları inkar ediyoruz.

00:01:34.404 --> 00:01:37.442
Şükür ki en kötüsü daha yaşanmadı.

00:01:37.442 --> 00:01:39.638
Aslında, belki de yaşanmayacak.

00:01:39.638 --> 00:01:42.823
Ama eğer bir olayın yıkıcı olma ihtimali varsa,

00:01:42.823 --> 00:01:45.691
gerçekleşme ihtimali olmasa bile, ondan korunmak için

00:01:45.691 --> 00:01:49.527
ona önemli bir öncelik vermeye değer demektir,

00:01:49.527 --> 00:01:52.930
tıpkı evimize yangın sigortası yaptırmamız gibi.

00:01:54.040 --> 00:01:59.037
Ve bilim daha büyük bir güç ve umut vaat ettiği için

00:01:59.037 --> 00:02:02.903
dezavantajları daha korkutucu hale geliyor.

00:02:02.903 --> 00:02:05.142
Gittikçe daha savunmasız hale geliyoruz.

00:02:05.142 --> 00:02:07.150
Gelecek on - onbeş yıl içinde,

00:02:07.150 --> 00:02:11.030
milyonlarca kişi tıpkı bugün siber teknolojiyi kötüye kullandıkları gibi

00:02:11.030 --> 00:02:13.191
biyoteknolojiyi de kötüye kullanma

00:02:13.191 --> 00:02:15.594
gücüne kavuşacaklar.

00:02:15.884 --> 00:02:19.083
Bir TED konuşmasında Freeman Dyson,

00:02:19.083 --> 00:02:22.679
tıpkı kendi jenerasyonunun kimya aletleriyle oynadığı gibi

00:02:22.679 --> 00:02:27.190
gelecekteki çocukların yeni organizmalar tasarlayıp yaratacaklarını öngörmüştü.

00:02:27.190 --> 00:02:29.718
Bu, uç noktada bir bilim kurgu olabilir;

00:02:29.718 --> 00:02:33.461
ama şayet senaryosunun bir parçası bile gerçekleşecek olursa,

00:02:33.461 --> 00:02:35.638
ekolojimiz ve hatta türümüz

00:02:35.638 --> 00:02:39.237
kesinlikle uzun süre sağ salim kalmayacaktır.

00:02:39.627 --> 00:02:43.490
Örneğin, insan sayısının çok daha az olmasının

00:02:43.490 --> 00:02:46.429
gezegen için, Gaia için daha iyi olacağını düşünen

00:02:46.429 --> 00:02:49.092
bazı aşırı çevreciler var.

00:02:49.402 --> 00:02:52.299
Böyle düşünen insanlar, 2050 yılına kadar dünya çapında

00:02:52.299 --> 00:02:54.696
yayılmış olacak sentetik biyoloji

00:02:54.696 --> 00:02:57.108
alanında uzmanlaşırsa ne olur?

00:02:57.108 --> 00:03:00.150
İşte o zaman başka bilim kurgu kabusları

00:03:00.150 --> 00:03:01.860
gerçeğe dönüşebilir:

00:03:01.860 --> 00:03:03.930
serserileşen kalın kafalı robotlar

00:03:03.930 --> 00:03:06.347
veya kendi beynini yaratan ağlar

00:03:06.347 --> 00:03:08.606
hepimizi tehdit eder.

00:03:08.936 --> 00:03:12.206
Evet, peki biz bir düzenlemeyle bu risklerden korunabilir miyiz?

00:03:12.206 --> 00:03:14.613
Kesinlikle denemeliyiz ama bu girişimler

00:03:14.613 --> 00:03:17.242
öyle zorlu, öyle küresel

00:03:17.242 --> 00:03:20.122
ve ticari baskı tarafından öyle yönlendirilmiş ki;

00:03:20.122 --> 00:03:23.407
yapılabilecek herhangi bir şey, bir yerlerde mutlaka yapılacaktır;

00:03:23.407 --> 00:03:25.443
düzenlemeler ne derse desin.

00:03:25.443 --> 00:03:28.930
Bu tıpkı uyuşturucu yasaları gibi — düzenlemeye çalışırız ama yapamayız.

00:03:28.930 --> 00:03:31.974
Küresel köyün ahmak köylüleri de olacaktır

00:03:31.974 --> 00:03:35.470
ve onların küresel çeşitlilikleri olacaktır.

00:03:35.470 --> 00:03:37.761
Yani kitabımda söylediğim gibi,

00:03:37.761 --> 00:03:40.650
bu yüzyılda sıkıntılarla karşılaşacağız.

00:03:40.650 --> 00:03:44.140
Toplumumuzda aksaklıklar olabilir —

00:03:44.140 --> 00:03:48.255
aslında, büyük bir aksaklığın olma ihtimali yüzde 50.

00:03:48.255 --> 00:03:50.996
Ama daha kötüye gidebilecek

00:03:51.027 --> 00:03:53.330
akla gelen olaylar var mıdır,

00:03:53.330 --> 00:03:56.760
tüm yaşamı yok edecek olaylar?

00:03:56.760 --> 00:03:59.686
Yeni bir parçacık hızlandırıcısı devreye girdiğinde,

00:03:59.686 --> 00:04:01.475
bazı insanlar endişeyle sordular:

00:04:01.475 --> 00:04:03.725
bu Dünyayı yok edebilir miydi, ya da daha kötüsü

00:04:03.725 --> 00:04:06.384
uzayın yapısını parçalara ayırabilir miydi?

00:04:06.384 --> 00:04:09.927
Neyse ki, iç rahatlatan şeyler sunulabildi.

00:04:09.927 --> 00:04:11.741
Ben ve bir kaç başka kişi

00:04:11.741 --> 00:04:14.104
doğanın, kozmik ışın çarpışmaları yoluyla

00:04:14.104 --> 00:04:15.740
aynı deneyleri zaten

00:04:15.740 --> 00:04:17.855
milyarlarca defa yaptığını belirttik.

00:04:17.855 --> 00:04:20.909
Ama bilim adamları tabi ki doğal dünyada

00:04:20.909 --> 00:04:23.489
benzeri görülmemiş koşullar yaratan

00:04:23.489 --> 00:04:25.972
deneyler söz konusuysa, tedbirli olmalıdır.

00:04:25.972 --> 00:04:29.395
Biyologlar, genetiğiyle oynanmış, hasar verme potansiyeli olan

00:04:29.395 --> 00:04:32.110
patojenleri açığa çıkarmaktan kaçınmalıdır.

00:04:32.110 --> 00:04:35.627
Bu arada, bizim gerçek varoluşsal felaket risklerine

00:04:35.627 --> 00:04:39.088
karşı olan çekincemiz, özellikle

00:04:39.088 --> 00:04:42.363
felsefik ve etik bir soruya dayanır.

00:04:42.363 --> 00:04:44.033
Soru şudur:

00:04:44.033 --> 00:04:46.341
İki senaryo düşünün.

00:04:46.341 --> 00:04:50.917
A senaryosu insanlığın yüzde 90'ını yok ediyor.

00:04:50.917 --> 00:04:55.473
B senaryosu yüzde 100'ünü yok ediyor.

00:04:55.473 --> 00:04:58.391
B, A'dan ne kadar daha kötü?

00:04:58.391 --> 00:05:01.414
Bazıları yüzde 10 daha kötü olduğunu söyleyecektir.

00:05:01.414 --> 00:05:04.564
Kişi sayısı yüzde 10 daha fazla.

00:05:04.564 --> 00:05:07.470
Ama benim düşüncem, B kıyaslanamaz derecede daha kötü.

00:05:07.470 --> 00:05:10.099
Bir gökbilimci olarak, ben insanların hikayenin

00:05:10.099 --> 00:05:12.566
sonu olduğuna inanamam.

00:05:12.566 --> 00:05:15.889
Güneşin sönmesine daha 5 milyar yıl var

00:05:15.889 --> 00:05:18.600
ve evren sonsuza kadar var olabilir.

00:05:18.600 --> 00:05:20.892
Yani insandan sonra Dünya'da

00:05:20.892 --> 00:05:23.082
ve ötesinde gerçekleşecek evrim,

00:05:23.082 --> 00:05:25.796
bizi ortaya çıkaran Darwinsel süreç kadar uzun

00:05:25.796 --> 00:05:29.077
ve belki daha harika olabilir.

00:05:29.077 --> 00:05:31.741
Ve aslında, gelecek evrim daha hızlı gerçekleşecek,

00:05:31.741 --> 00:05:33.940
teknolojik zaman periyodunda,

00:05:33.940 --> 00:05:36.239
doğal seçilim periyodunda değil.

00:05:36.239 --> 00:05:40.434
Yani, biz tabi ki bu büyük tehlikelerden ötürü,

00:05:40.434 --> 00:05:43.820
insanlığın yok olmasının

00:05:43.820 --> 00:05:46.049
bu büyük potansiyeli önlemesinin

00:05:46.049 --> 00:05:48.359
milyarda bir riski bile kabul etmemeliyiz.

00:05:48.359 --> 00:05:50.131
Öngörülen bazı senaryolar

00:05:50.131 --> 00:05:51.950
daha çok bilim kurgu olabilir

00:05:51.950 --> 00:05:55.336
ama diğerleri rahatsız edecek derecede gerçek olabilir.

00:05:55.336 --> 00:05:58.210
Şu atasözünün söylediği önemlidir:

00:05:58.210 --> 00:06:00.907
Alışılmadık demek, olasılıksız demek değildir.

00:06:00.907 --> 00:06:03.305
Aslında bu yüzden biz Cambridge Üniversitesi'nde

00:06:03.305 --> 00:06:06.680
bu varoluşsal riskleri azaltmaya çalışmak için

00:06:06.680 --> 00:06:08.712
bir merkez kuruyoruz.

00:06:08.712 --> 00:06:12.095
Öyle görünüyor ki bu olası felaketler sadece birkaç

00:06:12.095 --> 00:06:14.091
kişi işin önemli.

00:06:14.091 --> 00:06:17.104
Ve başkalarından gelebilecek bütün yardımlara ihtiyacımız var,

00:06:17.104 --> 00:06:19.583
çünkü biz sonsuz evrende bulunan,

00:06:19.583 --> 00:06:23.066
değerli bir soluk mavi noktanın koruyucularıyız,

00:06:23.066 --> 00:06:26.444
önünde 50 milyon yüzyılı daha olan bir gezegenin.

00:06:26.444 --> 00:06:29.000
Öyleyse bu geleceği tehlikeye atmayalım.

00:06:29.000 --> 00:06:30.795
Konuşmamı Peter Madawar adındaki büyük bir

00:06:30.795 --> 00:06:34.296
bilimciden alıntı yaparak sonlandırmak istiyorum.

00:06:34.296 --> 00:06:37.569
''İnsanlık için çalan çanlar,

00:06:37.569 --> 00:06:40.213
Alp dağlarının sığırlarının çanlarına benzer.

00:06:40.213 --> 00:06:42.499
Onlar bizim boyunlarımıza bağlılar ve eğer

00:06:42.499 --> 00:06:45.174
uyumlu ve melodili sesler çıkarmıyorlarsa,

00:06:45.174 --> 00:06:47.305
bu bizim hatamızdır.''

00:06:47.305 --> 00:06:49.572
Çok teşekkür ederim.

00:06:49.572 --> 00:06:51.685
(Alkış)

