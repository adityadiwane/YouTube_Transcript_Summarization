WEBVTT
Kind: captions
Language: en

00:00:12.843 --> 00:00:15.434
In 2007, I became the attorney general

00:00:15.434 --> 00:00:17.159
of the state of New Jersey.

00:00:17.159 --> 00:00:19.439
Before that, I'd been a criminal prosecutor,

00:00:19.439 --> 00:00:22.120
first in the Manhattan district attorney's office,

00:00:22.120 --> 00:00:24.770
and then at the United States Department of Justice.

00:00:24.770 --> 00:00:26.971
But when I became the attorney general,

00:00:26.971 --> 00:00:30.866
two things happened that changed 
the way I see criminal justice.

00:00:30.866 --> 00:00:32.896
The first is that I asked what I thought

00:00:32.896 --> 00:00:35.082
were really basic questions.

00:00:35.082 --> 00:00:37.938
I wanted to understand who we were arresting,

00:00:37.938 --> 00:00:39.602
who we were charging,

00:00:39.602 --> 00:00:41.730
and who we were putting in our nation's jails

00:00:41.730 --> 00:00:43.146
and prisons.

00:00:43.146 --> 00:00:44.794
I also wanted to understand

00:00:44.794 --> 00:00:46.123
if we were making decisions

00:00:46.123 --> 00:00:48.641
in a way that made us safer.

00:00:48.641 --> 00:00:51.893
And I couldn't get this information out.

00:00:51.893 --> 00:00:55.250
It turned out that most big criminal justice agencies

00:00:55.250 --> 00:00:56.552
like my own

00:00:56.552 --> 00:00:58.934
didn't track the things that matter.

00:00:58.934 --> 00:01:02.252
So after about a month of being incredibly frustrated,

00:01:02.252 --> 00:01:04.223
I walked down into a conference room

00:01:04.223 --> 00:01:06.113
that was filled with detectives

00:01:06.113 --> 00:01:08.895
and stacks and stacks of case files,

00:01:08.895 --> 00:01:10.071
and the detectives were sitting there

00:01:10.071 --> 00:01:12.305
with yellow legal pads taking notes.

00:01:12.305 --> 00:01:13.891
They were trying to get the information

00:01:13.891 --> 00:01:15.109
I was looking for

00:01:15.109 --> 00:01:17.154
by going through case by case

00:01:17.154 --> 00:01:19.052
for the past five years.

00:01:19.052 --> 00:01:20.705
And as you can imagine,

00:01:20.705 --> 00:01:23.348
when we finally got the results, they weren't good.

00:01:23.348 --> 00:01:25.003
It turned out that we were doing

00:01:25.003 --> 00:01:27.023
a lot of low-level drug cases

00:01:27.023 --> 00:01:28.498
on the streets just around the corner

00:01:28.498 --> 00:01:30.766
from our office in Trenton.

00:01:30.766 --> 00:01:32.233
The second thing that happened

00:01:32.233 --> 00:01:35.907
is that I spent the day in the Camden,
New Jersey police department.

00:01:35.907 --> 00:01:37.794
Now, at that time, Camden, New Jersey,

00:01:37.794 --> 00:01:40.446
was the most dangerous city in America.

00:01:40.446 --> 00:01:44.273
I ran the Camden Police
Department because of that.

00:01:44.273 --> 00:01:46.385
I spent the day in the police department,

00:01:46.385 --> 00:01:49.111
and I was taken into a room
with senior police officials,

00:01:49.111 --> 00:01:50.786
all of whom were working hard

00:01:50.786 --> 00:01:54.043
and trying very hard to reduce crime in Camden.

00:01:54.043 --> 00:01:55.869
And what I saw in that room,

00:01:55.869 --> 00:01:58.114
as we talked about how to reduce crime,

00:01:58.114 --> 00:02:01.973
were a series of officers with a
lot of little yellow sticky notes.

00:02:01.973 --> 00:02:04.819
And they would take a yellow sticky
and they would write something on it

00:02:04.823 --> 00:02:06.622
and they would put it up on a board.

00:02:06.622 --> 00:02:08.793
And one of them said, 
"We had a robbery two weeks ago.

00:02:08.793 --> 00:02:10.504
We have no suspects."

00:02:10.504 --> 00:02:15.531
And another said, "We had a shooting in this neighborhood last week. We have no suspects."

00:02:15.531 --> 00:02:18.114
We weren't using data-driven policing.

00:02:18.114 --> 00:02:20.156
We were essentially trying to fight crime

00:02:20.156 --> 00:02:22.683
with yellow Post-it notes.

00:02:22.683 --> 00:02:24.818
Now, both of these things made me realize

00:02:24.818 --> 00:02:28.069
fundamentally that we were failing.

00:02:28.069 --> 00:02:31.192
We didn't even know who was
in our criminal justice system,

00:02:31.192 --> 00:02:34.427
we didn't have any data about
the things that mattered,

00:02:34.427 --> 00:02:36.995
and we didn't share data or use analytics

00:02:36.995 --> 00:02:39.146
or tools to help us make better decisions

00:02:39.146 --> 00:02:41.149
and to reduce crime.

00:02:41.149 --> 00:02:43.373
And for the first time, I started to think

00:02:43.373 --> 00:02:45.283
about how we made decisions.

00:02:45.283 --> 00:02:46.680
When I was an assistant D.A.,

00:02:46.680 --> 00:02:48.550
and when I was a federal prosecutor,

00:02:48.550 --> 00:02:50.296
I looked at the cases in front of me,

00:02:50.296 --> 00:02:52.922
and I generally made decisions based on my instinct

00:02:52.922 --> 00:02:54.614
and my experience.

00:02:54.614 --> 00:02:56.273
When I became attorney general,

00:02:56.273 --> 00:02:57.912
I could look at the system as a whole,

00:02:57.912 --> 00:02:59.730
and what surprised me is that I found

00:02:59.730 --> 00:03:01.635
that that was exactly how we were doing it

00:03:01.635 --> 00:03:03.938
across the entire system --

00:03:03.938 --> 00:03:06.339
in police departments, in prosecutors's offices,

00:03:06.339 --> 00:03:09.139
in courts and in jails.

00:03:09.139 --> 00:03:11.336
And what I learned very quickly

00:03:11.336 --> 00:03:14.969
is that we weren't doing a good job.

00:03:14.969 --> 00:03:16.985
So I wanted to do things differently.

00:03:16.985 --> 00:03:19.182
I wanted to introduce data and analytics

00:03:19.182 --> 00:03:21.231
and rigorous statistical analysis

00:03:21.231 --> 00:03:22.631
into our work.

00:03:22.631 --> 00:03:25.601
In short, I wanted to moneyball criminal justice.

00:03:25.601 --> 00:03:27.628
Now, moneyball, as many of you know,

00:03:27.628 --> 00:03:29.197
is what the Oakland A's did,

00:03:29.197 --> 00:03:31.170
where they used smart data and statistics

00:03:31.170 --> 00:03:32.792
to figure out how to pick players

00:03:32.792 --> 00:03:34.313
that would help them win games,

00:03:34.313 --> 00:03:37.293
and they went from a system that 
was based on baseball scouts

00:03:37.293 --> 00:03:39.153
who used to go out and watch players

00:03:39.153 --> 00:03:40.790
and use their instinct and experience,

00:03:40.790 --> 00:03:42.533
the scouts' instincts and experience,

00:03:42.533 --> 00:03:44.246
to pick players, from one to use

00:03:44.246 --> 00:03:47.068
smart data and rigorous statistical analysis

00:03:47.068 --> 00:03:50.439
to figure out how to pick players
that would help them win games.

00:03:50.439 --> 00:03:52.237
It worked for the Oakland A's,

00:03:52.237 --> 00:03:54.456
and it worked in the state of New Jersey.

00:03:54.456 --> 00:03:56.529
We took Camden off the top of the list

00:03:56.529 --> 00:03:58.700
as the most dangerous city in America.

00:03:58.700 --> 00:04:01.855
We reduced murders there by 41 percent,

00:04:01.855 --> 00:04:04.837
which actually means 37 lives were saved.

00:04:04.837 --> 00:04:08.577
And we reduced all crime in the city by 26 percent.

00:04:08.577 --> 00:04:11.816
We also changed the way
we did criminal prosecutions.

00:04:11.816 --> 00:04:13.821
So we went from doing low-level drug crimes

00:04:13.821 --> 00:04:15.463
that were outside our building

00:04:15.463 --> 00:04:17.805
to doing cases of statewide importance,

00:04:17.805 --> 00:04:20.963
on things like reducing violence
with the most violent offenders,

00:04:20.963 --> 00:04:22.821
prosecuting street gangs,

00:04:22.821 --> 00:04:26.229
gun and drug trafficking, and political corruption.

00:04:26.229 --> 00:04:28.731
And all of this matters greatly,

00:04:28.731 --> 00:04:30.676
because public safety to me

00:04:30.676 --> 00:04:33.212
is the most important function of government.

00:04:33.212 --> 00:04:35.510
If we're not safe, we can't be educated,

00:04:35.510 --> 00:04:36.858
we can't be healthy,

00:04:36.858 --> 00:04:39.803
we can't do any of the other things
we want to do in our lives.

00:04:39.803 --> 00:04:41.504
And we live in a country today

00:04:41.504 --> 00:04:44.638
where we face serious criminal justice problems.

00:04:44.638 --> 00:04:48.299
We have 12 million arrests every single year.

00:04:48.299 --> 00:04:50.342
The vast majority of those arrests

00:04:50.342 --> 00:04:53.354
are for low-level crimes, like misdemeanors,

00:04:53.354 --> 00:04:55.088
70 to 80 percent.

00:04:55.088 --> 00:04:57.079
Less than five percent of all arrests

00:04:57.079 --> 00:04:58.974
are for violent crime.

00:04:58.974 --> 00:05:01.029
Yet we spend 75 billion,

00:05:01.029 --> 00:05:02.447
that's b for billion,

00:05:02.447 --> 00:05:06.574
dollars a year on state and local corrections costs.

00:05:06.574 --> 00:05:09.415
Right now, today, we have 2.3 million people

00:05:09.415 --> 00:05:11.315
in our jails and prisons.

00:05:11.315 --> 00:05:14.111
And we face unbelievable public safety challenges

00:05:14.111 --> 00:05:16.050
because we have a situation

00:05:16.050 --> 00:05:18.948
in which two thirds of the people in our jails

00:05:18.948 --> 00:05:20.702
are there waiting for trial.

00:05:20.702 --> 00:05:22.837
They haven't yet been convicted of a crime.

00:05:22.837 --> 00:05:24.956
They're just waiting for their day in court.

00:05:24.956 --> 00:05:28.504
And 67 percent of people come back.

00:05:28.504 --> 00:05:31.532
Our recidivism rate is amongst 
the highest in the world.

00:05:31.532 --> 00:05:33.635
Almost seven in 10 people who are released

00:05:33.635 --> 00:05:35.286
from prison will be rearrested

00:05:35.286 --> 00:05:39.241
in a constant cycle of crime and incarceration.

00:05:39.241 --> 00:05:41.823
So when I started my job at the Arnold Foundation,

00:05:41.823 --> 00:05:44.559
I came back to looking at a lot of these questions,

00:05:44.559 --> 00:05:46.213
and I came back to thinking about how

00:05:46.213 --> 00:05:48.596
we had used data and analytics to transform

00:05:48.596 --> 00:05:51.180
the way we did criminal justice in New Jersey.

00:05:51.180 --> 00:05:53.324
And when I look at the criminal justice system

00:05:53.324 --> 00:05:54.980
in the United States today,

00:05:54.980 --> 00:05:56.619
I feel the exact same way that I did

00:05:56.619 --> 00:05:59.085
about the state of New Jersey when I started there,

00:05:59.085 --> 00:06:02.313
which is that we absolutely have to do better,

00:06:02.313 --> 00:06:04.236
and I know that we can do better.

00:06:04.236 --> 00:06:05.941
So I decided to focus

00:06:05.941 --> 00:06:08.158
on using data and analytics

00:06:08.158 --> 00:06:10.519
to help make the most critical decision

00:06:10.519 --> 00:06:12.125
in public safety,

00:06:12.125 --> 00:06:14.146
and that decision is the determination

00:06:14.146 --> 00:06:16.681
of whether, when someone has been arrested,

00:06:16.681 --> 00:06:18.596
whether they pose a risk to public safety

00:06:18.596 --> 00:06:20.122
and should be detained,

00:06:20.122 --> 00:06:22.478
or whether they don't pose a risk to public safety

00:06:22.478 --> 00:06:24.115
and should be released.

00:06:24.115 --> 00:06:26.034
Everything that happens in criminal cases

00:06:26.034 --> 00:06:27.806
comes out of this one decision.

00:06:27.806 --> 00:06:29.302
It impacts everything.

00:06:29.302 --> 00:06:30.652
It impacts sentencing.

00:06:30.652 --> 00:06:32.553
It impacts whether someone gets drug treatment.

00:06:32.553 --> 00:06:34.876
It impacts crime and violence.

00:06:34.876 --> 00:06:36.813
And when I talk to judges around the United States,

00:06:36.813 --> 00:06:38.741
which I do all the time now,

00:06:38.741 --> 00:06:40.578
they all say the same thing,

00:06:40.578 --> 00:06:43.685
which is that we put dangerous people in jail,

00:06:43.685 --> 00:06:47.210
and we let non-dangerous, nonviolent people out.

00:06:47.210 --> 00:06:49.443
They mean it and they believe it.

00:06:49.443 --> 00:06:51.176
But when you start to look at the data,

00:06:51.176 --> 00:06:53.640
which, by the way, the judges don't have,

00:06:53.640 --> 00:06:55.252
when we start to look at the data,

00:06:55.252 --> 00:06:57.670
what we find time and time again,

00:06:57.670 --> 00:06:59.652
is that this isn't the case.

00:06:59.652 --> 00:07:01.333
We find low-risk offenders,

00:07:01.333 --> 00:07:05.047
which makes up 50 percent of our
entire criminal justice population,

00:07:05.047 --> 00:07:07.446
we find that they're in jail.

00:07:07.446 --> 00:07:09.932
Take Leslie Chew, who was a Texas man

00:07:09.932 --> 00:07:12.816
who stole four blankets on a cold winter night.

00:07:12.816 --> 00:07:15.411
He was arrested, and he was kept in jail

00:07:15.411 --> 00:07:17.464
on 3,500 dollars bail,

00:07:17.464 --> 00:07:20.240
an amount that he could not afford to pay.

00:07:20.240 --> 00:07:22.828
And he stayed in jail for eight months

00:07:22.828 --> 00:07:24.893
until his case came up for trial,

00:07:24.893 --> 00:07:28.798
at a cost to taxpayers of more than 9,000 dollars.

00:07:28.798 --> 00:07:30.795
And at the other end of the spectrum,

00:07:30.795 --> 00:07:33.077
we're doing an equally terrible job.

00:07:33.077 --> 00:07:34.649
The people who we find

00:07:34.649 --> 00:07:36.668
are the highest-risk offenders,

00:07:36.668 --> 00:07:39.165
the people who we think have the highest likelihood

00:07:39.165 --> 00:07:41.117
of committing a new crime if they're released,

00:07:41.117 --> 00:07:44.067
we see nationally that 50 percent of those people

00:07:44.067 --> 00:07:46.041
are being released.

00:07:46.041 --> 00:07:49.215
The reason for this is the way we make decisions.

00:07:49.215 --> 00:07:50.924
Judges have the best intentions

00:07:50.924 --> 00:07:52.876
when they make these decisions about risk,

00:07:52.876 --> 00:07:55.360
but they're making them subjectively.

00:07:55.360 --> 00:07:57.506
They're like the baseball scouts 20 years ago

00:07:57.506 --> 00:07:59.637
who were using their instinct and their experience

00:07:59.637 --> 00:08:02.316
to try to decide what risk someone poses.

00:08:02.316 --> 00:08:03.846
They're being subjective,

00:08:03.846 --> 00:08:06.906
and we know what happens
with subjective decision making,

00:08:06.906 --> 00:08:09.649
which is that we are often wrong.

00:08:09.649 --> 00:08:11.032
What we need in this space

00:08:11.032 --> 00:08:13.584
are strong data and analytics.

00:08:13.584 --> 00:08:15.331
What I decided to look for

00:08:15.331 --> 00:08:18.167
was a strong data and analytic risk assessment tool,

00:08:18.167 --> 00:08:20.931
something that would let judges actually understand

00:08:20.931 --> 00:08:23.190
with a scientific and objective way

00:08:23.190 --> 00:08:24.837
what the risk was that was posed

00:08:24.837 --> 00:08:26.447
by someone in front of them.

00:08:26.447 --> 00:08:28.096
I looked all over the country,

00:08:28.096 --> 00:08:30.038
and I found that between five and 10 percent

00:08:30.038 --> 00:08:31.367
of all U.S. jurisdictions

00:08:31.367 --> 00:08:34.345
actually use any type of risk assessment tool,

00:08:34.345 --> 00:08:35.970
and when I looked at these tools,

00:08:35.970 --> 00:08:37.830
I quickly realized why.

00:08:37.830 --> 00:08:40.520
They were unbelievably expensive to administer,

00:08:40.520 --> 00:08:42.048
they were time-consuming,

00:08:42.048 --> 00:08:44.155
they were limited to the local jurisdiction

00:08:44.155 --> 00:08:45.585
in which they'd been created.

00:08:45.585 --> 00:08:47.378
So basically, they couldn't be scaled

00:08:47.378 --> 00:08:49.587
or transferred to other places.

00:08:49.587 --> 00:08:51.824
So I went out and built a phenomenal team

00:08:51.824 --> 00:08:53.868
of data scientists and researchers

00:08:53.868 --> 00:08:55.494
and statisticians

00:08:55.494 --> 00:08:58.339
to build a universal risk assessment tool,

00:08:58.339 --> 00:09:00.732
so that every single judge in
the United States of America

00:09:00.732 --> 00:09:05.056
can have an objective, scientific measure of risk.

00:09:05.056 --> 00:09:06.714
In the tool that we've built,

00:09:06.714 --> 00:09:09.582
what we did was we collected 1.5 million cases

00:09:09.582 --> 00:09:11.280
from all around the United States,

00:09:11.280 --> 00:09:12.924
from cities, from counties,

00:09:12.924 --> 00:09:14.435
from every single state in the country,

00:09:14.435 --> 00:09:16.181
the federal districts.

00:09:16.181 --> 00:09:18.370
And with those 1.5 million cases,

00:09:18.370 --> 00:09:20.310
which is the largest data set on pretrial

00:09:20.310 --> 00:09:22.115
in the United States today,

00:09:22.115 --> 00:09:23.980
we were able to basically find that there were

00:09:23.980 --> 00:09:27.302
900-plus risk factors that we could look at

00:09:27.302 --> 00:09:30.168
to try to figure out what mattered most.

00:09:30.168 --> 00:09:32.249
And we found that there were nine specific things

00:09:32.249 --> 00:09:34.484
that mattered all across the country

00:09:34.484 --> 00:09:37.461
and that were the most highly predictive of risk.

00:09:37.461 --> 00:09:41.166
And so we built a universal risk assessment tool.

00:09:41.166 --> 00:09:42.611
And it looks like this.

00:09:42.611 --> 00:09:45.223
As you'll see, we put some information in,

00:09:45.223 --> 00:09:47.236
but most of it is incredibly simple,

00:09:47.236 --> 00:09:48.668
it's easy to use,

00:09:48.668 --> 00:09:51.637
it focuses on things like the
defendant's prior convictions,

00:09:51.637 --> 00:09:53.616
whether they've been sentenced to incarceration,

00:09:53.616 --> 00:09:55.880
whether they've engaged in violence before,

00:09:55.880 --> 00:09:58.273
whether they've even failed to come back to court.

00:09:58.273 --> 00:10:00.773
And with this tool, we can predict three things.

00:10:00.773 --> 00:10:02.626
First, whether or not someone will commit

00:10:02.626 --> 00:10:04.191
a new crime if they're released.

00:10:04.191 --> 00:10:05.855
Second, for the first time,

00:10:05.855 --> 00:10:07.716
and I think this is incredibly important,

00:10:07.716 --> 00:10:09.639
we can predict whether someone will commit

00:10:09.639 --> 00:10:11.473
an act of violence if they're released.

00:10:11.473 --> 00:10:13.360
And that's the single most important thing

00:10:13.360 --> 00:10:15.167
that judges say when you talk to them.

00:10:15.167 --> 00:10:16.995
And third, we can predict whether someone

00:10:16.995 --> 00:10:18.985
will come back to court.

00:10:18.985 --> 00:10:22.018
And every single judge in the
United States of America can use it,

00:10:22.018 --> 00:10:25.830
because it's been created on a universal data set.

00:10:25.830 --> 00:10:28.439
What judges see if they run the risk assessment tool

00:10:28.439 --> 00:10:30.559
is this -- it's a dashboard.

00:10:30.559 --> 00:10:33.407
At the top, you see the New Criminal Activity Score,

00:10:33.407 --> 00:10:35.336
six of course being the highest,

00:10:35.336 --> 00:10:37.739
and then in the middle you
see, "Elevated risk of violence."

00:10:37.739 --> 00:10:39.485
What that says is that this person

00:10:39.485 --> 00:10:41.545
is someone who has an elevated risk of violence

00:10:41.545 --> 00:10:43.430
that the judge should look twice at.

00:10:43.430 --> 00:10:44.766
And then, towards the bottom,

00:10:44.766 --> 00:10:46.734
you see the Failure to Appear Score,

00:10:46.734 --> 00:10:48.126
which again is the likelihood

00:10:48.126 --> 00:10:51.139
that someone will come back to court.

00:10:51.139 --> 00:10:53.352
Now I want to say something really important.

00:10:53.352 --> 00:10:56.079
It's not that I think we should be eliminating

00:10:56.079 --> 00:10:58.323
the judge's instinct and experience

00:10:58.323 --> 00:10:59.927
from this process.

00:10:59.927 --> 00:11:00.985
I don't.

00:11:00.985 --> 00:11:02.992
I actually believe the problem that we see

00:11:02.992 --> 00:11:05.846
and the reason that we have
these incredible system errors,

00:11:05.846 --> 00:11:08.933
where we're incarcerating
low-level, nonviolent people

00:11:08.933 --> 00:11:12.105
and we're releasing high-risk, dangerous people,

00:11:12.105 --> 00:11:14.828
is that we don't have an objective measure of risk.

00:11:14.828 --> 00:11:16.128
But what I believe should happen

00:11:16.128 --> 00:11:18.928
is that we should take that
data-driven risk assessment

00:11:18.928 --> 00:11:21.969
and combine that with the
judge's instinct and experience

00:11:21.969 --> 00:11:24.927
to lead us to better decision making.

00:11:24.927 --> 00:11:28.230
The tool went statewide in Kentucky on July 1,

00:11:28.230 --> 00:11:31.581
and we're about to go up in a
number of other U.S. jurisdictions.

00:11:31.581 --> 00:11:34.172
Our goal, quite simply, is that every single judge

00:11:34.172 --> 00:11:36.364
in the United States will use a data-driven risk tool

00:11:36.364 --> 00:11:38.455
within the next five years.

00:11:38.455 --> 00:11:39.807
We're now working on risk tools

00:11:39.807 --> 00:11:43.091
for prosecutors and for police officers as well,

00:11:43.091 --> 00:11:45.791
to try to take a system that runs today

00:11:45.791 --> 00:11:48.587
in America the same way it did 50 years ago,

00:11:48.587 --> 00:11:50.684
based on instinct and experience,

00:11:50.684 --> 00:11:52.539
and make it into one that runs

00:11:52.539 --> 00:11:55.008
on data and analytics.

00:11:55.008 --> 00:11:56.929
Now, the great news about all this,

00:11:56.929 --> 00:11:58.546
and we have a ton of work left to do,

00:11:58.546 --> 00:12:00.403
and we have a lot of culture to change,

00:12:00.403 --> 00:12:02.149
but the great news about all of it

00:12:02.149 --> 00:12:04.017
is that we know it works.

00:12:04.017 --> 00:12:06.170
It's why Google is Google,

00:12:06.170 --> 00:12:08.632
and it's why all these baseball teams use moneyball

00:12:08.632 --> 00:12:10.413
to win games.

00:12:10.413 --> 00:12:12.150
The great news for us as well

00:12:12.150 --> 00:12:14.046
is that it's the way that we can transform

00:12:14.046 --> 00:12:16.367
the American criminal justice system.

00:12:16.367 --> 00:12:18.724
It's how we can make our streets safer,

00:12:18.724 --> 00:12:21.023
we can reduce our prison costs,

00:12:21.023 --> 00:12:23.090
and we can make our system much fairer

00:12:23.090 --> 00:12:24.815
and more just.

00:12:24.815 --> 00:12:26.977
Some people call it data science.

00:12:26.977 --> 00:12:29.278
I call it moneyballing criminal justice.

00:12:29.278 --> 00:12:31.082
Thank you.

00:12:31.082 --> 00:12:35.175
(Applause)

