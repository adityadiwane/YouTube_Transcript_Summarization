WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.000
Translator: Joseph Geni
Reviewer: Morton Bast

00:00:12.328 --> 00:00:15.277
The writer George Eliot cautioned us that,

00:00:15.277 --> 00:00:17.344
among all forms of mistake,

00:00:17.344 --> 00:00:19.707
prophesy is the most gratuitous.

00:00:19.707 --> 00:00:21.555
The person that we would all acknowledge

00:00:21.555 --> 00:00:25.857
as her 20th-century counterpart, Yogi Berra, agreed.

00:00:25.857 --> 00:00:27.722
He said, "It's tough to make predictions,

00:00:27.722 --> 00:00:30.458
especially about the future."

00:00:30.458 --> 00:00:32.269
I'm going to ignore their cautions

00:00:32.269 --> 00:00:34.242
and make one very specific forecast.

00:00:34.242 --> 00:00:36.882
In the world that we are creating very quickly,

00:00:36.882 --> 00:00:38.595
we're going to see more and more things

00:00:38.595 --> 00:00:40.320
that look like science fiction,

00:00:40.320 --> 00:00:43.436
and fewer and fewer things that look like jobs.

00:00:43.436 --> 00:00:46.188
Our cars are very quickly going to start driving themselves,

00:00:46.188 --> 00:00:48.884
which means we're going to need fewer truck drivers.

00:00:48.884 --> 00:00:51.005
We're going to hook Siri up to Watson

00:00:51.005 --> 00:00:53.602
and use that to automate a lot of the work

00:00:53.602 --> 00:00:55.828
that's currently done by customer service reps

00:00:55.828 --> 00:00:58.732
and troubleshooters and diagnosers,

00:00:58.732 --> 00:01:00.988
and we're already taking R2D2,

00:01:00.988 --> 00:01:04.228
painting him orange, and putting him to work

00:01:04.228 --> 00:01:06.777
carrying shelves around warehouses,

00:01:06.777 --> 00:01:08.852
which means we need a lot fewer people

00:01:08.852 --> 00:01:10.818
to be walking up and down those aisles.

00:01:10.818 --> 00:01:14.620
Now, for about 200 years,

00:01:14.620 --> 00:01:16.803
people have been saying exactly what I'm telling you --

00:01:16.803 --> 00:01:19.620
the age of technological unemployment is at hand —

00:01:19.620 --> 00:01:22.035
starting with the Luddites smashing looms in Britain

00:01:22.035 --> 00:01:23.931
just about two centuries ago,

00:01:23.931 --> 00:01:25.963
and they have been wrong.

00:01:25.963 --> 00:01:28.780
Our economies in the developed world have coasted along

00:01:28.780 --> 00:01:30.714
on something pretty close to full employment.

00:01:30.714 --> 00:01:32.813
Which brings up a critical question:

00:01:32.813 --> 00:01:35.739
Why is this time different, if it really is?

00:01:35.739 --> 00:01:38.735
The reason it's different is that, just in the past few years,

00:01:38.735 --> 00:01:40.630
our machines have started demonstrating skills

00:01:40.630 --> 00:01:43.255
they have never, ever had before:

00:01:43.255 --> 00:01:46.515
understanding, speaking, hearing, seeing,

00:01:46.515 --> 00:01:50.728
answering, writing, and they're still acquiring new skills.

00:01:50.728 --> 00:01:53.298
For example, mobile humanoid robots

00:01:53.298 --> 00:01:55.245
are still incredibly primitive,

00:01:55.245 --> 00:01:57.083
but the research arm of the Defense Department

00:01:57.083 --> 00:01:58.598
just launched a competition

00:01:58.598 --> 00:02:00.912
to have them do things like this,

00:02:00.912 --> 00:02:02.645
and if the track record is any guide,

00:02:02.645 --> 00:02:05.044
this competition is going to be successful.

00:02:05.044 --> 00:02:08.680
So when I look around, I think the day is not too far off at all

00:02:08.680 --> 00:02:10.856
when we're going to have androids

00:02:10.856 --> 00:02:13.737
doing a lot of the work that we are doing right now.

00:02:13.737 --> 00:02:17.495
And we're creating a world where there is going to be

00:02:17.495 --> 00:02:21.180
more and more technology and fewer and fewer jobs.

00:02:21.180 --> 00:02:23.429
It's a world that Erik Brynjolfsson and I are calling

00:02:23.429 --> 00:02:24.920
"the new machine age."

00:02:24.920 --> 00:02:27.053
The thing to keep in mind is that

00:02:27.053 --> 00:02:29.602
this is absolutely great news.

00:02:29.602 --> 00:02:32.919
This is the best economic news on the planet these days.

00:02:32.919 --> 00:02:36.448
Not that there's a lot of competition, right?

00:02:36.448 --> 00:02:38.347
This is the best economic news we have these days

00:02:38.347 --> 00:02:39.963
for two main reasons.

00:02:39.963 --> 00:02:42.948
The first is, technological progress is what allows us

00:02:42.948 --> 00:02:46.685
to continue this amazing recent run that we're on

00:02:46.685 --> 00:02:49.206
where output goes up over time,

00:02:49.206 --> 00:02:52.532
while at the same time, prices go down,

00:02:52.532 --> 00:02:56.736
and volume and quality just continue to explode.

00:02:56.736 --> 00:02:58.737
Now, some people look at this and talk about

00:02:58.737 --> 00:03:00.143
shallow materialism,

00:03:00.143 --> 00:03:02.561
but that's absolutely the wrong way to look at it.

00:03:02.561 --> 00:03:05.056
This is abundance, which is exactly

00:03:05.056 --> 00:03:08.478
what we want our economic system to provide.

00:03:08.478 --> 00:03:11.694
The second reason that the new machine age

00:03:11.694 --> 00:03:14.000
is such great news is that, once the androids

00:03:14.000 --> 00:03:17.252
start doing jobs, we don't have to do them anymore,

00:03:17.252 --> 00:03:21.008
and we get freed up from drudgery and toil.

00:03:21.008 --> 00:03:23.032
Now, when I talk about this with my friends

00:03:23.032 --> 00:03:25.584
in Cambridge and Silicon Valley, they say,

00:03:25.584 --> 00:03:27.857
"Fantastic. No more drudgery, no more toil.

00:03:27.857 --> 00:03:29.908
This gives us the chance to imagine

00:03:29.908 --> 00:03:32.201
an entirely different kind of society,

00:03:32.201 --> 00:03:35.113
a society where the creators and the discoverers

00:03:35.113 --> 00:03:36.942
and the performers and the innovators

00:03:36.942 --> 00:03:40.451
come together with their patrons and their financiers

00:03:40.451 --> 00:03:43.130
to talk about issues, entertain, enlighten,

00:03:43.130 --> 00:03:45.208
provoke each other."

00:03:45.208 --> 00:03:49.783
It's a society really, that looks a lot like the TED Conference.

00:03:49.783 --> 00:03:52.266
And there's actually a huge amount of truth here.

00:03:52.266 --> 00:03:55.289
We are seeing an amazing flourishing taking place.

00:03:55.289 --> 00:03:57.291
In a world where it is just about as easy

00:03:57.291 --> 00:04:00.698
to generate an object as it is to print a document,

00:04:00.698 --> 00:04:02.787
we have amazing new possibilities.

00:04:02.787 --> 00:04:06.464
The people who used to be craftsmen and hobbyists

00:04:06.464 --> 00:04:08.331
are now makers, and they're responsible

00:04:08.331 --> 00:04:10.721
for massive amounts of innovation.

00:04:10.721 --> 00:04:13.003
And artists who were formerly constrained

00:04:13.003 --> 00:04:16.171
can now do things that were never, ever possible

00:04:16.171 --> 00:04:18.067
for them before.

00:04:18.067 --> 00:04:20.184
So this is a time of great flourishing,

00:04:20.184 --> 00:04:23.116
and the more I look around, the more convinced I become

00:04:23.116 --> 00:04:26.190
that this quote, from the physicist Freeman Dyson,

00:04:26.190 --> 00:04:28.223
is not hyperbole at all.

00:04:28.223 --> 00:04:31.013
This is just a plain statement of the facts.

00:04:31.013 --> 00:04:32.858
We are in the middle of an astonishing period.

00:04:32.858 --> 00:04:33.742
["Technology is a gift of God. After the gift of life it is perhaps the greatest of God's gifts. It is the mother of civilizations, of arts and of sciences." — Freeman Dyson]

00:04:33.742 --> 00:04:36.533
Which brings up another great question:

00:04:36.533 --> 00:04:39.509
What could possibly go wrong in this new machine age?

00:04:39.509 --> 00:04:42.871
Right? Great, hang up, flourish, go home.

00:04:42.871 --> 00:04:45.537
We're going to face two really thorny sets of challenges

00:04:45.537 --> 00:04:48.330
as we head deeper into the future that we're creating.

00:04:48.330 --> 00:04:51.580
The first are economic, and they're really nicely summarized

00:04:51.580 --> 00:04:54.670
in an apocryphal story about a back-and-forth

00:04:54.670 --> 00:04:57.712
between Henry Ford II and Walter Reuther,

00:04:57.712 --> 00:05:00.457
who was the head of the auto workers union.

00:05:00.457 --> 00:05:02.640
They were touring one of the new modern factories,

00:05:02.640 --> 00:05:05.390
and Ford playfully turns to Reuther and says,

00:05:05.390 --> 00:05:07.552
"Hey Walter, how are you going to get these robots

00:05:07.552 --> 00:05:09.366
to pay union dues?"

00:05:09.366 --> 00:05:11.311
And Reuther shoots back, "Hey Henry,

00:05:11.311 --> 00:05:15.853
how are you going to get them to buy cars?"

00:05:15.853 --> 00:05:18.864
Reuther's problem in that anecdote

00:05:18.864 --> 00:05:22.973
is that it is tough to offer your labor to an economy

00:05:22.973 --> 00:05:24.608
that's full of machines,

00:05:24.608 --> 00:05:26.832
and we see this very clearly in the statistics.

00:05:26.832 --> 00:05:29.224
If you look over the past couple decades

00:05:29.224 --> 00:05:32.888
at the returns to capital -- in other words, corporate profits --

00:05:32.888 --> 00:05:34.572
we see them going up,

00:05:34.572 --> 00:05:36.659
and we see that they're now at an all-time high.

00:05:36.659 --> 00:05:39.360
If we look at the returns to labor, in other words

00:05:39.360 --> 00:05:41.244
total wages paid out in the economy,

00:05:41.244 --> 00:05:43.791
we see them at an all-time low

00:05:43.791 --> 00:05:46.856
and heading very quickly in the opposite direction.

00:05:46.856 --> 00:05:48.626
So this is clearly bad news for Reuther.

00:05:48.626 --> 00:05:52.024
It looks like it might be great news for Ford,

00:05:52.024 --> 00:05:54.328
but it's actually not. If you want to sell

00:05:54.328 --> 00:05:57.672
huge volumes of somewhat expensive goods to people,

00:05:57.672 --> 00:06:01.460
you really want a large, stable, prosperous middle class.

00:06:01.460 --> 00:06:03.684
We have had one of those in America

00:06:03.684 --> 00:06:06.317
for just about the entire postwar period.

00:06:06.317 --> 00:06:10.669
But the middle class is clearly under huge threat right now.

00:06:10.669 --> 00:06:12.080
We all know a lot of the statistics,

00:06:12.080 --> 00:06:14.439
but just to repeat one of them,

00:06:14.439 --> 00:06:17.206
median income in America has actually gone down

00:06:17.206 --> 00:06:18.897
over the past 15 years,

00:06:18.897 --> 00:06:20.612
and we're in danger of getting trapped

00:06:20.612 --> 00:06:24.537
in some vicious cycle where inequality and polarization

00:06:24.537 --> 00:06:27.717
continue to go up over time.

00:06:27.717 --> 00:06:30.116
The societal challenges that come along

00:06:30.116 --> 00:06:32.692
with that kind of inequality deserve some attention.

00:06:32.692 --> 00:06:34.360
There are a set of societal challenges

00:06:34.360 --> 00:06:36.304
that I'm actually not that worried about,

00:06:36.304 --> 00:06:38.655
and they're captured by images like this.

00:06:38.655 --> 00:06:40.477
This is not the kind of societal problem

00:06:40.477 --> 00:06:42.941
that I am concerned about.

00:06:42.941 --> 00:06:45.084
There is no shortage of dystopian visions

00:06:45.084 --> 00:06:48.567
about what happens when our machines become self-aware,

00:06:48.567 --> 00:06:51.743
and they decide to rise up and coordinate attacks against us.

00:06:51.743 --> 00:06:53.490
I'm going to start worrying about those

00:06:53.490 --> 00:06:56.719
the day my computer becomes aware of my printer.

00:06:56.719 --> 00:07:00.348
(Laughter) (Applause)

00:07:00.348 --> 00:07:03.320
So this is not the set of challenges we really need to worry about.

00:07:03.320 --> 00:07:06.108
To tell you the kinds of societal challenges

00:07:06.108 --> 00:07:08.320
that are going to come up in the new machine age,

00:07:08.320 --> 00:07:12.031
I want to tell a story about two stereotypical American workers.

00:07:12.031 --> 00:07:13.799
And to make them really stereotypical,

00:07:13.799 --> 00:07:15.946
let's make them both white guys.

00:07:15.946 --> 00:07:19.708
And the first one is a college-educated

00:07:19.708 --> 00:07:22.854
professional, creative type, manager,

00:07:22.854 --> 00:07:25.605
engineer, doctor, lawyer, that kind of worker.

00:07:25.605 --> 00:07:28.024
We're going to call him "Ted."

00:07:28.024 --> 00:07:30.297
He's at the top of the American middle class.

00:07:30.297 --> 00:07:33.179
His counterpart is not college-educated

00:07:33.179 --> 00:07:36.243
and works as a laborer, works as a clerk,

00:07:36.243 --> 00:07:39.555
does low-level white collar or blue collar work in the economy.

00:07:39.555 --> 00:07:41.960
We're going to call that guy "Bill."

00:07:41.960 --> 00:07:44.039
And if you go back about 50 years,

00:07:44.039 --> 00:07:47.856
Bill and Ted were leading remarkably similar lives.

00:07:47.856 --> 00:07:50.359
For example, in 1960 they were both very likely

00:07:50.359 --> 00:07:53.729
to have full-time jobs, working at least 40 hours a week.

00:07:53.729 --> 00:07:57.025
But as the social researcher Charles Murray has documented,

00:07:57.025 --> 00:07:59.993
as we started to automate the economy,

00:07:59.993 --> 00:08:04.140
and 1960 is just about when computers started to be used by businesses,

00:08:04.140 --> 00:08:07.011
as we started to progressively inject technology

00:08:07.011 --> 00:08:09.747
and automation and digital stuff into the economy,

00:08:09.747 --> 00:08:12.772
the fortunes of Bill and Ted diverged a lot.

00:08:12.772 --> 00:08:14.891
Over this time frame, Ted has continued

00:08:14.891 --> 00:08:17.643
to hold a full-time job. Bill hasn't.

00:08:17.643 --> 00:08:21.914
In many cases, Bill has left the economy entirely,

00:08:21.914 --> 00:08:24.178
and Ted very rarely has.

00:08:24.178 --> 00:08:27.443
Over time, Ted's marriage has stayed quite happy.

00:08:27.443 --> 00:08:29.084
Bill's hasn't.

00:08:29.084 --> 00:08:32.406
And Ted's kids have grown up in a two-parent home,

00:08:32.406 --> 00:08:35.626
while Bill's absolutely have not over time.

00:08:35.626 --> 00:08:38.030
Other ways that Bill is dropping out of society?

00:08:38.030 --> 00:08:41.719
He's decreased his voting in presidential elections,

00:08:41.719 --> 00:08:45.712
and he's started to go to prison a lot more often.

00:08:45.712 --> 00:08:49.696
So I cannot tell a happy story about these social trends,

00:08:49.696 --> 00:08:52.443
and they don't show any signs of reversing themselves.

00:08:52.443 --> 00:08:55.416
They're also true no matter which ethnic group

00:08:55.416 --> 00:08:57.137
or demographic group we look at,

00:08:57.137 --> 00:08:59.213
and they're actually getting so severe

00:08:59.213 --> 00:09:00.984
that they're in danger of overwhelming

00:09:00.984 --> 00:09:04.632
even the amazing progress we made with the Civil Rights Movement.

00:09:04.632 --> 00:09:07.144
And what my friends in Silicon Valley

00:09:07.144 --> 00:09:12.395
and Cambridge are overlooking is that they're Ted.

00:09:12.395 --> 00:09:15.832
They're living these amazingly busy, productive lives,

00:09:15.832 --> 00:09:18.222
and they've got all the benefits to show from that,

00:09:18.222 --> 00:09:20.657
while Bill is leading a very different life.

00:09:20.657 --> 00:09:22.797
They're actually both proof of how right Voltaire was

00:09:22.797 --> 00:09:25.049
when he talked about the benefits of work,

00:09:25.049 --> 00:09:28.630
and the fact that it saves us from not one but three great evils.

00:09:28.630 --> 00:09:29.627
["Work saves a man from three great evils: boredom, vice and need." — Voltaire]

00:09:29.627 --> 00:09:32.963
So with these challenges, what do we do about them?

00:09:32.963 --> 00:09:35.546
The economic playbook is surprisingly clear,

00:09:35.546 --> 00:09:38.686
surprisingly straightforward, in the short term especially.

00:09:38.686 --> 00:09:41.578
The robots are not going to take all of our jobs in the next year or two,

00:09:41.578 --> 00:09:46.046
so the classic Econ 101 playbook is going to work just fine:

00:09:46.046 --> 00:09:48.198
Encourage entrepreneurship,

00:09:48.198 --> 00:09:50.394
double down on infrastructure,

00:09:50.394 --> 00:09:52.093
and make sure we're turning out people

00:09:52.093 --> 00:09:55.690
from our educational system with the appropriate skills.

00:09:55.690 --> 00:09:58.967
But over the longer term, if we are moving into an economy

00:09:58.967 --> 00:10:01.619
that's heavy on technology and light on labor,

00:10:01.619 --> 00:10:04.047
and we are, then we have to consider

00:10:04.047 --> 00:10:05.831
some more radical interventions,

00:10:05.831 --> 00:10:09.030
for example, something like a guaranteed minimum income.

00:10:09.030 --> 00:10:12.742
Now, that's probably making some folk in this room uncomfortable,

00:10:12.742 --> 00:10:16.599
because that idea is associated with the extreme left wing

00:10:16.599 --> 00:10:19.818
and with fairly radical schemes for redistributing wealth.

00:10:19.818 --> 00:10:21.771
I did a little bit of research on this notion,

00:10:21.771 --> 00:10:24.226
and it might calm some folk down to know that

00:10:24.226 --> 00:10:26.858
the idea of a net guaranteed minimum income

00:10:26.858 --> 00:10:30.020
has been championed by those frothing-at-the-mouth socialists

00:10:30.035 --> 00:10:35.508
Friedrich Hayek, Richard Nixon and Milton Friedman.

00:10:35.508 --> 00:10:37.387
And if you find yourself worried

00:10:37.387 --> 00:10:40.696
that something like a guaranteed income

00:10:40.696 --> 00:10:42.971
is going to stifle our drive to succeed

00:10:42.971 --> 00:10:44.735
and make us kind of complacent,

00:10:44.735 --> 00:10:47.525
you might be interested to know that social mobility,

00:10:47.525 --> 00:10:50.200
one of the things we really pride ourselves on in the United States,

00:10:50.200 --> 00:10:53.540
is now lower than it is in the northern European countries

00:10:53.540 --> 00:10:56.739
that have these very generous social safety nets.

00:10:56.739 --> 00:10:59.531
So the economic playbook is actually pretty straightforward.

00:10:59.531 --> 00:11:02.587
The societal one is a lot more challenging.

00:11:02.587 --> 00:11:04.735
I don't know what the playbook is

00:11:04.735 --> 00:11:08.563
for getting Bill to engage and stay engaged throughout life.

00:11:08.563 --> 00:11:11.067
I do know that education is a huge part of it.

00:11:11.067 --> 00:11:12.847
I witnessed this firsthand.

00:11:12.847 --> 00:11:16.603
I was a Montessori kid for the first few years of my education,

00:11:16.603 --> 00:11:18.132
and what that education taught me

00:11:18.132 --> 00:11:20.223
is that the world is an interesting place

00:11:20.223 --> 00:11:22.864
and my job is to go explore it.

00:11:22.864 --> 00:11:24.565
The school stopped in third grade,

00:11:24.565 --> 00:11:26.633
so then I entered the public school system,

00:11:26.633 --> 00:11:30.999
and it felt like I had been sent to the Gulag.

00:11:30.999 --> 00:11:33.900
With the benefit of hindsight, I now know the job

00:11:33.900 --> 00:11:36.414
was to prepare me for life as a clerk or a laborer,

00:11:36.414 --> 00:11:38.744
but at the time it felt like the job was to kind of

00:11:38.744 --> 00:11:42.568
bore me into some submission with what was going on around me.

00:11:42.568 --> 00:11:43.916
We have to do better than this.

00:11:43.916 --> 00:11:47.592
We cannot keep turning out Bills.

00:11:47.592 --> 00:11:49.936
So we see some green shoots that things are getting better.

00:11:49.936 --> 00:11:52.760
We see technology deeply impacting education

00:11:52.760 --> 00:11:55.288
and engaging people, from our youngest learners

00:11:55.288 --> 00:11:57.052
up to our oldest ones.

00:11:57.052 --> 00:11:59.672
We see very prominent business voices telling us

00:11:59.672 --> 00:12:02.888
we need to rethink some of the things that we've been holding dear for a while.

00:12:02.888 --> 00:12:05.148
And we see very serious and sustained

00:12:05.148 --> 00:12:07.952
and data-driven efforts to understand

00:12:07.952 --> 00:12:11.495
how to intervene in some of the most troubled communities that we have.

00:12:11.495 --> 00:12:13.704
So the green shoots are out there.

00:12:13.704 --> 00:12:15.138
I don't want to pretend for a minute

00:12:15.138 --> 00:12:17.080
that what we have is going to be enough.

00:12:17.080 --> 00:12:19.222
We're facing very tough challenges.

00:12:19.222 --> 00:12:22.328
To give just one example, there are about five million Americans

00:12:22.328 --> 00:12:25.142
who have been unemployed for at least six months.

00:12:25.142 --> 00:12:26.484
We're not going to fix things for them

00:12:26.484 --> 00:12:28.927
by sending them back to Montessori.

00:12:28.927 --> 00:12:31.282
And my biggest worry is that we're creating a world

00:12:31.282 --> 00:12:33.831
where we're going to have glittering technologies

00:12:33.831 --> 00:12:36.136
embedded in kind of a shabby society

00:12:36.136 --> 00:12:39.103
and supported by an economy that generates inequality

00:12:39.103 --> 00:12:40.584
instead of opportunity.

00:12:40.584 --> 00:12:43.336
But I actually don't think that's what we're going to do.

00:12:43.336 --> 00:12:44.965
I think we're going to do something a lot better

00:12:44.965 --> 00:12:47.075
for one very straightforward reason:

00:12:47.075 --> 00:12:49.043
The facts are getting out there.

00:12:49.043 --> 00:12:51.085
The realities of this new machine age

00:12:51.085 --> 00:12:54.400
and the change in the economy are becoming more widely known.

00:12:54.400 --> 00:12:57.251
If we wanted to accelerate that process, we could do things

00:12:57.251 --> 00:13:00.017
like have our best economists and policymakers

00:13:00.017 --> 00:13:02.436
play "Jeopardy!" against Watson.

00:13:02.436 --> 00:13:05.986
We could send Congress on an autonomous car road trip.

00:13:05.986 --> 00:13:07.639
And if we do enough of these kinds of things,

00:13:07.639 --> 00:13:11.043
the awareness is going to sink in that things are going to be different.

00:13:11.043 --> 00:13:12.814
And then we're off to the races,

00:13:12.814 --> 00:13:15.244
because I don't believe for a second

00:13:15.244 --> 00:13:18.212
that we have forgotten how to solve tough challenges

00:13:18.212 --> 00:13:22.562
or that we have become too apathetic or hard-hearted to even try.

00:13:22.562 --> 00:13:24.956
I started my talk with quotes from wordsmiths

00:13:24.956 --> 00:13:27.772
who were separated by an ocean and a century.

00:13:27.772 --> 00:13:29.924
Let me end it with words from politicians

00:13:29.924 --> 00:13:31.655
who were similarly distant.

00:13:31.655 --> 00:13:34.988
Winston Churchill came to my home of MIT in 1949,

00:13:34.988 --> 00:13:37.136
and he said, "If we are to bring the broad masses

00:13:37.136 --> 00:13:40.846
of the people in every land to the table of abundance,

00:13:40.846 --> 00:13:43.876
it can only be by the tireless improvement

00:13:43.876 --> 00:13:46.849
of all of our means of technical production."

00:13:46.849 --> 00:13:49.468
Abraham Lincoln realized there was one other ingredient.

00:13:49.468 --> 00:13:52.366
He said, "I am a firm believer in the people.

00:13:52.366 --> 00:13:54.699
If given the truth, they can be depended upon

00:13:54.699 --> 00:13:57.068
to meet any national crisis.

00:13:57.068 --> 00:13:59.852
The great point is to give them the plain facts."

00:13:59.852 --> 00:14:02.962
So the optimistic note, great point that I want to leave you with

00:14:02.962 --> 00:14:06.107
is that the plain facts of the machine age are becoming clear,

00:14:06.107 --> 00:14:08.564
and I have every confidence that we're going to use them

00:14:08.564 --> 00:14:11.479
to chart a good course into the challenging,

00:14:11.479 --> 00:14:14.012
abundant economy that we're creating.

00:14:14.012 --> 00:14:15.703
Thank you very much.

00:14:15.703 --> 00:14:20.085
(Applause)

