WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.000
Translator: Leslie Gauthier
Reviewer: Camille MartÃ­nez

00:00:14.966 --> 00:00:18.783
I'm going to talk a little bit
about where technology's going.

00:00:19.509 --> 00:00:22.180
And often technology comes to us,

00:00:22.566 --> 00:00:24.431
we're surprised by what it brings.

00:00:24.455 --> 00:00:28.138
But there's actually
a large aspect of technology

00:00:28.162 --> 00:00:29.964
that's much more predictable,

00:00:29.988 --> 00:00:34.076
and that's because technological systems
of all sorts have leanings,

00:00:34.100 --> 00:00:35.275
they have urgencies,

00:00:35.299 --> 00:00:36.860
they have tendencies.

00:00:36.884 --> 00:00:41.816
And those tendencies are derived
from the very nature of the physics,

00:00:41.840 --> 00:00:44.990
chemistry of wires
and switches and electrons,

00:00:45.659 --> 00:00:49.261
and they will make reoccurring
patterns again and again.

00:00:49.745 --> 00:00:54.619
And so those patterns produce
these tendencies, these leanings.

00:00:54.643 --> 00:00:57.474
You can almost think of it
as sort of like gravity.

00:00:57.498 --> 00:00:59.817
Imagine raindrops falling into a valley.

00:00:59.841 --> 00:01:02.929
The actual path of a raindrop
as it goes down the valley

00:01:02.953 --> 00:01:04.122
is unpredictable.

00:01:04.651 --> 00:01:06.169
We cannot see where it's going,

00:01:06.193 --> 00:01:08.470
but the general direction
is very inevitable:

00:01:08.494 --> 00:01:09.728
it's downward.

00:01:10.377 --> 00:01:14.949
And so these baked-in
tendencies and urgencies

00:01:14.973 --> 00:01:16.449
in technological systems

00:01:17.051 --> 00:01:20.660
give us a sense of where things
are going at the large form.

00:01:21.149 --> 00:01:22.550
So in a large sense,

00:01:22.574 --> 00:01:25.935
I would say that telephones
were inevitable,

00:01:27.005 --> 00:01:28.347
but the iPhone was not.

00:01:29.094 --> 00:01:30.572
The Internet was inevitable,

00:01:31.274 --> 00:01:32.560
but Twitter was not.

00:01:33.036 --> 00:01:36.964
So we have many ongoing
tendencies right now,

00:01:36.988 --> 00:01:39.708
and I think one of the chief among them

00:01:39.732 --> 00:01:43.454
is this tendency to make things
smarter and smarter.

00:01:44.041 --> 00:01:46.253
I call it cognifying -- cognification --

00:01:46.783 --> 00:01:49.565
also known as artificial
intelligence, or AI.

00:01:50.025 --> 00:01:53.771
And I think that's going to be one
of the most influential developments

00:01:53.795 --> 00:01:59.370
and trends and directions and drives
in our society in the next 20 years.

00:02:00.021 --> 00:02:02.006
So, of course, it's already here.

00:02:02.030 --> 00:02:04.234
We already have AI,

00:02:04.258 --> 00:02:06.656
and often it works in the background,

00:02:06.680 --> 00:02:08.266
in the back offices of hospitals,

00:02:08.290 --> 00:02:12.976
where it's used to diagnose X-rays
better than a human doctor.

00:02:13.000 --> 00:02:14.726
It's in legal offices,

00:02:14.750 --> 00:02:17.118
where it's used to go
through legal evidence

00:02:17.142 --> 00:02:18.997
better than a human paralawyer.

00:02:19.506 --> 00:02:23.162
It's used to fly the plane
that you came here with.

00:02:24.165 --> 00:02:26.546
Human pilots only flew it
seven to eight minutes,

00:02:26.570 --> 00:02:28.523
the rest of the time the AI was driving.

00:02:28.547 --> 00:02:30.720
And of course, in Netflix and Amazon,

00:02:30.744 --> 00:02:33.274
it's in the background,
making those recommendations.

00:02:33.298 --> 00:02:34.559
That's what we have today.

00:02:34.583 --> 00:02:39.384
And we have an example, of course,
in a more front-facing aspect of it,

00:02:39.408 --> 00:02:46.037
with the win of the AlphaGo, who beat
the world's greatest Go champion.

00:02:46.478 --> 00:02:50.531
But it's more than that.

00:02:50.555 --> 00:02:53.197
If you play a video game,
you're playing against an AI.

00:02:53.221 --> 00:02:57.759
But recently, Google taught their AI

00:02:57.783 --> 00:03:00.195
to actually learn how to play video games.

00:03:00.686 --> 00:03:03.395
Again, teaching video games
was already done,

00:03:03.419 --> 00:03:07.316
but learning how to play
a video game is another step.

00:03:07.340 --> 00:03:09.018
That's artificial smartness.

00:03:10.571 --> 00:03:15.093
What we're doing is taking
this artificial smartness

00:03:15.117 --> 00:03:17.540
and we're making it smarter and smarter.

00:03:18.710 --> 00:03:22.605
There are three aspects
to this general trend

00:03:22.629 --> 00:03:24.318
that I think are underappreciated;

00:03:24.342 --> 00:03:26.619
I think we would understand
AI a lot better

00:03:26.643 --> 00:03:28.944
if we understood these three things.

00:03:28.968 --> 00:03:32.251
I think these things also would
help us embrace AI,

00:03:32.275 --> 00:03:35.283
because it's only by embracing it
that we actually can steer it.

00:03:35.887 --> 00:03:39.044
We can actually steer the specifics
by embracing the larger trend.

00:03:39.467 --> 00:03:42.446
So let me talk about
those three different aspects.

00:03:42.470 --> 00:03:46.143
The first one is: our own intelligence
has a very poor understanding

00:03:46.167 --> 00:03:47.657
of what intelligence is.

00:03:48.110 --> 00:03:51.763
We tend to think of intelligence
as a single dimension,

00:03:51.787 --> 00:03:54.537
that it's kind of like a note
that gets louder and louder.

00:03:54.561 --> 00:03:57.168
It starts like with IQ measurement.

00:03:57.192 --> 00:04:01.284
It starts with maybe a simple
low IQ in a rat or mouse,

00:04:01.308 --> 00:04:03.442
and maybe there's more in a chimpanzee,

00:04:03.887 --> 00:04:06.078
and then maybe there's more
in a stupid person,

00:04:06.102 --> 00:04:08.198
and then maybe an average
person like myself,

00:04:08.222 --> 00:04:09.512
and then maybe a genius.

00:04:09.536 --> 00:04:13.969
And this single IQ intelligence
is getting greater and greater.

00:04:14.516 --> 00:04:15.667
That's completely wrong.

00:04:15.691 --> 00:04:19.299
That's not what intelligence is --
not what human intelligence is, anyway.

00:04:19.673 --> 00:04:24.179
It's much more like a symphony
of different notes,

00:04:24.203 --> 00:04:27.812
and each of these notes is played
on a different instrument of cognition.

00:04:27.836 --> 00:04:31.537
There are many types
of intelligences in our own minds.

00:04:31.561 --> 00:04:34.609
We have deductive reasoning,

00:04:34.633 --> 00:04:36.854
we have emotional intelligence,

00:04:36.878 --> 00:04:38.271
we have spatial intelligence;

00:04:38.295 --> 00:04:42.316
we have maybe 100 different types
that are all grouped together,

00:04:42.340 --> 00:04:46.245
and they vary in different strengths
with different people.

00:04:46.269 --> 00:04:50.795
And of course, if we go to animals,
they also have another basket --

00:04:50.819 --> 00:04:53.360
another symphony of different
kinds of intelligences,

00:04:53.384 --> 00:04:56.950
and sometimes those same instruments
are the same that we have.

00:04:56.974 --> 00:05:00.535
They can think in the same way,
but they may have a different arrangement,

00:05:00.559 --> 00:05:03.026
and maybe they're higher
in some cases than humans,

00:05:03.050 --> 00:05:05.887
like long-term memory in a squirrel
is actually phenomenal,

00:05:05.911 --> 00:05:08.198
so it can remember
where it buried its nuts.

00:05:08.222 --> 00:05:10.209
But in other cases they may be lower.

00:05:10.233 --> 00:05:12.963
When we go to make machines,

00:05:12.987 --> 00:05:15.183
we're going to engineer
them in the same way,

00:05:15.207 --> 00:05:20.217
where we'll make some of those types
of smartness much greater than ours,

00:05:20.241 --> 00:05:22.812
and many of them won't be
anywhere near ours,

00:05:22.836 --> 00:05:24.380
because they're not needed.

00:05:24.404 --> 00:05:26.607
So we're going to take these things,

00:05:26.631 --> 00:05:28.712
these artificial clusters,

00:05:28.736 --> 00:05:34.098
and we'll be adding more varieties
of artificial cognition to our AIs.

00:05:34.507 --> 00:05:38.578
We're going to make them
very, very specific.

00:05:38.602 --> 00:05:45.144
So your calculator is smarter
than you are in arithmetic already;

00:05:45.168 --> 00:05:48.865
your GPS is smarter
than you are in spatial navigation;

00:05:49.337 --> 00:05:53.595
Google, Bing, are smarter
than you are in long-term memory.

00:05:54.339 --> 00:05:58.869
And we're going to take, again,
these kinds of different types of thinking

00:05:58.893 --> 00:06:00.826
and we'll put them into, like, a car.

00:06:00.850 --> 00:06:03.907
The reason why we want to put them
in a car so the car drives,

00:06:03.931 --> 00:06:06.233
is because it's not driving like a human.

00:06:06.257 --> 00:06:07.653
It's not thinking like us.

00:06:07.677 --> 00:06:09.597
That's the whole feature of it.

00:06:09.621 --> 00:06:11.156
It's not being distracted,

00:06:11.180 --> 00:06:13.934
it's not worrying about whether
it left the stove on,

00:06:13.958 --> 00:06:16.096
or whether it should have
majored in finance.

00:06:16.120 --> 00:06:17.273
It's just driving.

00:06:17.297 --> 00:06:18.439
(Laughter)

00:06:18.463 --> 00:06:20.304
Just driving, OK?

00:06:20.328 --> 00:06:23.265
And we actually might even
come to advertise these

00:06:23.289 --> 00:06:24.834
as "consciousness-free."

00:06:24.858 --> 00:06:26.632
They're without consciousness,

00:06:26.656 --> 00:06:28.760
they're not concerned about those things,

00:06:28.784 --> 00:06:29.940
they're not distracted.

00:06:29.964 --> 00:06:32.930
So in general, what we're trying to do

00:06:32.954 --> 00:06:37.454
is make as many different
types of thinking as we can.

00:06:37.804 --> 00:06:39.887
We're going to populate the space

00:06:39.911 --> 00:06:44.070
of all the different possible types,
or species, of thinking.

00:06:44.094 --> 00:06:46.162
And there actually may be some problems

00:06:46.186 --> 00:06:48.986
that are so difficult
in business and science

00:06:49.010 --> 00:06:53.052
that our own type of human thinking
may not be able to solve them alone.

00:06:53.076 --> 00:06:55.068
We may need a two-step program,

00:06:55.092 --> 00:06:59.295
which is to invent new kinds of thinking

00:06:59.692 --> 00:07:03.426
that we can work alongside of to solve
these really large problems,

00:07:03.450 --> 00:07:06.368
say, like dark energy or quantum gravity.

00:07:08.496 --> 00:07:11.142
What we're doing
is making alien intelligences.

00:07:11.166 --> 00:07:15.235
You might even think of this
as, sort of, artificial aliens

00:07:15.259 --> 00:07:16.466
in some senses.

00:07:16.490 --> 00:07:18.790
And they're going to help
us think different,

00:07:18.814 --> 00:07:22.446
because thinking different
is the engine of creation

00:07:22.470 --> 00:07:24.337
and wealth and new economy.

00:07:25.835 --> 00:07:30.758
The second aspect of this
is that we are going to use AI

00:07:30.782 --> 00:07:33.732
to basically make a second
Industrial Revolution.

00:07:34.135 --> 00:07:36.908
The first Industrial Revolution
was based on the fact

00:07:36.932 --> 00:07:40.394
that we invented something
I would call artificial power.

00:07:40.879 --> 00:07:42.029
Previous to that,

00:07:42.053 --> 00:07:44.087
during the Agricultural Revolution,

00:07:44.111 --> 00:07:47.813
everything that was made
had to be made with human muscle

00:07:47.837 --> 00:07:49.144
or animal power.

00:07:49.565 --> 00:07:51.628
That was the only way
to get anything done.

00:07:51.652 --> 00:07:54.597
The great innovation during
the Industrial Revolution was,

00:07:54.621 --> 00:07:57.730
we harnessed steam power, fossil fuels,

00:07:57.754 --> 00:08:01.610
to make this artificial power
that we could use

00:08:01.634 --> 00:08:03.303
to do anything we wanted to do.

00:08:03.327 --> 00:08:06.099
So today when you drive down the highway,

00:08:06.571 --> 00:08:11.096
you are, with a flick of the switch,
commanding 250 horses --

00:08:11.120 --> 00:08:12.692
250 horsepower --

00:08:12.716 --> 00:08:17.408
which we can use to build skyscrapers,
to build cities, to build roads,

00:08:17.432 --> 00:08:23.221
to make factories that would churn out
lines of chairs or refrigerators

00:08:23.245 --> 00:08:24.899
way beyond our own power.

00:08:24.923 --> 00:08:31.034
And that artificial power can also
be distributed on wires on a grid

00:08:31.058 --> 00:08:34.257
to every home, factory, farmstead,

00:08:34.281 --> 00:08:38.472
and anybody could buy
that artificial power,

00:08:38.496 --> 00:08:39.968
just by plugging something in.

00:08:39.992 --> 00:08:42.431
So this was a source
of innovation as well,

00:08:42.455 --> 00:08:45.873
because a farmer could take
a manual hand pump,

00:08:45.897 --> 00:08:48.813
and they could add this artificial
power, this electricity,

00:08:48.837 --> 00:08:50.334
and he'd have an electric pump.

00:08:50.358 --> 00:08:53.676
And you multiply that by thousands
or tens of thousands of times,

00:08:53.700 --> 00:08:56.859
and that formula was what brought us
the Industrial Revolution.

00:08:56.883 --> 00:09:00.468
All the things that we see,
all this progress that we now enjoy,

00:09:00.492 --> 00:09:02.555
has come from the fact
that we've done that.

00:09:02.579 --> 00:09:04.927
We're going to do
the same thing now with AI.

00:09:04.951 --> 00:09:07.026
We're going to distribute that on a grid,

00:09:07.050 --> 00:09:09.424
and now you can take that electric pump.

00:09:09.448 --> 00:09:12.416
You can add some artificial intelligence,

00:09:12.440 --> 00:09:13.921
and now you have a smart pump.

00:09:13.945 --> 00:09:15.873
And that, multiplied by a million times,

00:09:15.897 --> 00:09:18.260
is going to be this second
Industrial Revolution.

00:09:18.284 --> 00:09:20.666
So now the car is going down the highway,

00:09:20.690 --> 00:09:24.984
it's 250 horsepower,
but in addition, it's 250 minds.

00:09:25.008 --> 00:09:26.777
That's the auto-driven car.

00:09:26.801 --> 00:09:28.190
It's like a new commodity;

00:09:28.214 --> 00:09:29.517
it's a new utility.

00:09:29.541 --> 00:09:32.582
The AI is going to flow
across the grid -- the cloud --

00:09:32.606 --> 00:09:34.173
in the same way electricity did.

00:09:34.197 --> 00:09:36.577
So everything that we had electrified,

00:09:36.601 --> 00:09:38.324
we're now going to cognify.

00:09:38.693 --> 00:09:40.078
And I would suggest, then,

00:09:40.102 --> 00:09:43.834
that the formula
for the next 10,000 start-ups

00:09:43.858 --> 00:09:45.020
is very, very simple,

00:09:45.044 --> 00:09:48.211
which is to take x and add AI.

00:09:49.100 --> 00:09:51.912
That is the formula,
that's what we're going to be doing.

00:09:51.936 --> 00:09:55.242
And that is the way
in which we're going to make

00:09:55.266 --> 00:09:57.124
this second Industrial Revolution.

00:09:57.148 --> 00:09:59.302
And by the way -- right now, this minute,

00:09:59.326 --> 00:10:00.495
you can log on to Google

00:10:00.519 --> 00:10:04.401
and you can purchase
AI for six cents, 100 hits.

00:10:04.758 --> 00:10:06.362
That's available right now.

00:10:06.386 --> 00:10:08.672
So the third aspect of this

00:10:09.315 --> 00:10:11.993
is that when we take this AI
and embody it,

00:10:12.017 --> 00:10:13.190
we get robots.

00:10:13.214 --> 00:10:14.917
And robots are going to be bots,

00:10:14.941 --> 00:10:18.269
they're going to be doing many
of the tasks that we have already done.

00:10:20.357 --> 00:10:21.885
A job is just a bunch of tasks,

00:10:21.909 --> 00:10:23.671
so they're going to redefine our jobs

00:10:23.695 --> 00:10:25.954
because they're going to do
some of those tasks.

00:10:25.978 --> 00:10:29.175
But they're also going to create
whole new categories,

00:10:29.199 --> 00:10:31.446
a whole new slew of tasks

00:10:31.470 --> 00:10:33.927
that we didn't know
we wanted to do before.

00:10:33.951 --> 00:10:37.588
They're going to actually
engender new kinds of jobs,

00:10:37.612 --> 00:10:39.883
new kinds of tasks that we want done,

00:10:39.907 --> 00:10:43.312
just as automation made up
a whole bunch of new things

00:10:43.336 --> 00:10:45.170
that we didn't know we needed before,

00:10:45.194 --> 00:10:47.150
and now we can't live without them.

00:10:47.174 --> 00:10:51.130
So they're going to produce
even more jobs than they take away,

00:10:51.154 --> 00:10:54.588
but it's important that a lot of the tasks
that we're going to give them

00:10:54.612 --> 00:10:59.184
are tasks that can be defined
in terms of efficiency or productivity.

00:10:59.676 --> 00:11:01.504
If you can specify a task,

00:11:01.528 --> 00:11:03.763
either manual or conceptual,

00:11:03.787 --> 00:11:08.567
that can be specified in terms
of efficiency or productivity,

00:11:08.591 --> 00:11:10.368
that goes to the bots.

00:11:10.758 --> 00:11:12.936
Productivity is for robots.

00:11:12.960 --> 00:11:16.030
What we're really good at
is basically wasting time.

00:11:16.054 --> 00:11:17.082
(Laughter)

00:11:17.106 --> 00:11:19.422
We're really good at things
that are inefficient.

00:11:19.446 --> 00:11:22.471
Science is inherently inefficient.

00:11:22.816 --> 00:11:25.722
It runs on that fact that you have
one failure after another.

00:11:25.746 --> 00:11:29.170
It runs on the fact that you make tests
and experiments that don't work,

00:11:29.194 --> 00:11:30.636
otherwise you're not learning.

00:11:30.660 --> 00:11:31.822
It runs on the fact

00:11:31.846 --> 00:11:33.929
that there is not
a lot of efficiency in it.

00:11:33.953 --> 00:11:36.732
Innovation by definition is inefficient,

00:11:36.756 --> 00:11:38.147
because you make prototypes,

00:11:38.171 --> 00:11:40.878
because you try stuff that fails,
that doesn't work.

00:11:40.902 --> 00:11:44.014
Exploration is inherently inefficiency.

00:11:44.038 --> 00:11:45.569
Art is not efficient.

00:11:45.593 --> 00:11:47.720
Human relationships are not efficient.

00:11:47.744 --> 00:11:50.684
These are all the kinds of things
we're going to gravitate to,

00:11:50.708 --> 00:11:52.183
because they're not efficient.

00:11:52.207 --> 00:11:54.522
Efficiency is for robots.

00:11:55.338 --> 00:11:59.461
We're also going to learn
that we're going to work with these AIs

00:11:59.485 --> 00:12:01.482
because they think differently than us.

00:12:02.005 --> 00:12:06.319
When Deep Blue beat
the world's best chess champion,

00:12:06.343 --> 00:12:08.272
people thought it was the end of chess.

00:12:08.296 --> 00:12:12.698
But actually, it turns out that today,
the best chess champion in the world

00:12:12.722 --> 00:12:14.279
is not an AI.

00:12:14.906 --> 00:12:16.087
And it's not a human.

00:12:16.111 --> 00:12:18.826
It's the team of a human and an AI.

00:12:18.850 --> 00:12:22.850
The best medical diagnostician
is not a doctor, it's not an AI,

00:12:22.874 --> 00:12:24.050
it's the team.

00:12:24.074 --> 00:12:26.223
We're going to be working with these AIs,

00:12:26.247 --> 00:12:28.242
and I think you'll be paid in the future

00:12:28.266 --> 00:12:30.657
by how well you work with these bots.

00:12:31.026 --> 00:12:35.283
So that's the third thing,
is that they're different,

00:12:35.307 --> 00:12:36.472
they're utility

00:12:36.496 --> 00:12:40.312
and they are going to be something
we work with rather than against.

00:12:40.336 --> 00:12:42.975
We're working with these
rather than against them.

00:12:42.999 --> 00:12:44.476
So, the future:

00:12:44.500 --> 00:12:45.920
Where does that take us?

00:12:45.944 --> 00:12:49.511
I think that 25 years from now,
they'll look back

00:12:49.535 --> 00:12:52.660
and look at our understanding
of AI and say,

00:12:52.684 --> 00:12:55.984
"You didn't have AI. In fact,
you didn't even have the Internet yet,

00:12:56.008 --> 00:12:58.749
compared to what we're going
to have 25 years from now."

00:12:59.849 --> 00:13:02.896
There are no AI experts right now.

00:13:02.920 --> 00:13:04.619
There's a lot of money going to it,

00:13:04.643 --> 00:13:06.911
there are billions of dollars
being spent on it;

00:13:06.935 --> 00:13:09.099
it's a huge business,

00:13:09.123 --> 00:13:13.395
but there are no experts, compared
to what we'll know 20 years from now.

00:13:14.064 --> 00:13:16.949
So we are just at the beginning
of the beginning,

00:13:16.973 --> 00:13:19.136
we're in the first hour of all this.

00:13:19.160 --> 00:13:21.095
We're in the first hour of the Internet.

00:13:21.119 --> 00:13:23.159
We're in the first hour of what's coming.

00:13:23.183 --> 00:13:27.336
The most popular AI product
in 20 years from now,

00:13:27.360 --> 00:13:28.804
that everybody uses,

00:13:29.499 --> 00:13:31.043
has not been invented yet.

00:13:32.464 --> 00:13:34.931
That means that you're not late.

00:13:35.684 --> 00:13:36.835
Thank you.

00:13:36.859 --> 00:13:37.885
(Laughter)

00:13:37.909 --> 00:13:40.666
(Applause)

