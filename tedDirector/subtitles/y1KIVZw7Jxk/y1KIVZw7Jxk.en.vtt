WEBVTT
Kind: captions
Language: en

00:00:12.835 --> 00:00:14.990
Mark Twain summed up
what I take to be

00:00:14.990 --> 00:00:18.110
one of the fundamental problems
of cognitive science

00:00:18.110 --> 00:00:19.820
with a single witticism.

00:00:20.410 --> 00:00:23.492
He said, "There's something
fascinating about science.

00:00:23.492 --> 00:00:26.720
One gets such wholesale
returns of conjecture

00:00:26.720 --> 00:00:29.924
out of such a trifling
investment in fact."

00:00:29.924 --> 00:00:31.509
(Laughter)

00:00:32.199 --> 00:00:34.803
Twain meant it as a joke,
of course, but he's right:

00:00:34.803 --> 00:00:37.679
There's something
fascinating about science.

00:00:37.679 --> 00:00:41.940
From a few bones, we infer
the existence of dinosuars.

00:00:42.910 --> 00:00:46.781
From spectral lines,
the composition of nebulae.

00:00:47.471 --> 00:00:50.409
From fruit flies,

00:00:50.409 --> 00:00:53.352
the mechanisms of heredity,

00:00:53.352 --> 00:00:57.601
and from reconstructed images
of blood flowing through the brain,

00:00:57.601 --> 00:01:02.309
or in my case, from the behavior
of very young children,

00:01:02.309 --> 00:01:05.138
we try to say something about
the fundamental mechanisms

00:01:05.138 --> 00:01:06.756
of human cognition.

00:01:07.716 --> 00:01:12.475
In particular, in my lab in the Department
of Brain and Cognitive Sciences at MIT,

00:01:12.475 --> 00:01:16.129
I have spent the past decade
trying to understand the mystery

00:01:16.129 --> 00:01:20.106
of how children learn so much
from so little so quickly.

00:01:20.666 --> 00:01:23.644
Because, it turns out that
the fascinating thing about science

00:01:23.644 --> 00:01:27.173
is also a fascinating
thing about children,

00:01:27.173 --> 00:01:29.754
which, to put a gentler
spin on Mark Twain,

00:01:29.754 --> 00:01:34.404
is precisely their ability
to draw rich, abstract inferences

00:01:34.404 --> 00:01:39.065
rapidly and accurately
from sparse, noisy data.

00:01:40.355 --> 00:01:42.753
I'm going to give you
just two examples today.

00:01:42.753 --> 00:01:45.040
One is about a problem of generalization,

00:01:45.040 --> 00:01:47.890
and the other is about a problem
of causal reasoning.

00:01:47.890 --> 00:01:50.415
And although I'm going to talk
about work in my lab,

00:01:50.415 --> 00:01:53.875
this work is inspired by
and indebted to a field.

00:01:53.875 --> 00:01:58.158
I'm grateful to mentors, colleagues,
and collaborators around the world.

00:01:59.308 --> 00:02:02.282
Let me start with the problem
of generalization.

00:02:02.652 --> 00:02:06.785
Generalizing from small samples of data
is the bread and butter of science.

00:02:06.785 --> 00:02:09.339
We poll a tiny fraction of the electorate

00:02:09.339 --> 00:02:11.660
and we predict the outcome
of national elections.

00:02:12.240 --> 00:02:16.165
We see how a handful of patients
responds to treatment in a clinical trial,

00:02:16.165 --> 00:02:19.230
and we bring drugs to a national market.

00:02:19.230 --> 00:02:23.595
But this only works if our sample
is randomly drawn from the population.

00:02:23.595 --> 00:02:26.330
If our sample is cherry-picked
in some way --

00:02:26.330 --> 00:02:28.402
say, we poll only urban voters,

00:02:28.402 --> 00:02:32.790
or say, in our clinical trials
for treatments for heart disease,

00:02:32.790 --> 00:02:34.671
we include only men --

00:02:34.671 --> 00:02:37.829
the results may not generalize
to the broader population.

00:02:38.479 --> 00:02:42.060
So scientists care whether evidence
is randomly sampled or not,

00:02:42.060 --> 00:02:44.075
but what does that have to do with babies?

00:02:44.585 --> 00:02:49.206
Well, babies have to generalize
from small samples of data all the time.

00:02:49.206 --> 00:02:52.364
They see a few rubber ducks
and learn that they float,

00:02:52.364 --> 00:02:55.939
or a few balls and learn that they bounce.

00:02:55.939 --> 00:02:58.890
And they develop expectations
about ducks and balls

00:02:58.890 --> 00:03:01.606
that they're going to extend
to rubber ducks and balls

00:03:01.606 --> 00:03:03.485
for the rest of their lives.

00:03:03.485 --> 00:03:07.224
And the kinds of generalizations
babies have to make about ducks and balls

00:03:07.224 --> 00:03:09.313
they have to make about almost everything:

00:03:09.313 --> 00:03:13.230
shoes and ships and sealing wax
and cabbages and kings.

00:03:14.200 --> 00:03:17.161
So do babies care whether
the tiny bit of evidence they see

00:03:17.161 --> 00:03:20.853
is plausibly representative
of a larger population?

00:03:21.763 --> 00:03:23.663
Let's find out.

00:03:23.663 --> 00:03:25.386
I'm going to show you two movies,

00:03:25.386 --> 00:03:27.848
one from each of two conditions
of an experiment,

00:03:27.848 --> 00:03:30.286
and because you're going to see
just two movies,

00:03:30.286 --> 00:03:32.422
you're going to see just two babies,

00:03:32.422 --> 00:03:36.369
and any two babies differ from each other
in innumerable ways.

00:03:36.369 --> 00:03:39.420
But these babies, of course,
here stand in for groups of babies,

00:03:39.420 --> 00:03:41.315
and the differences you're going to see

00:03:41.315 --> 00:03:46.510
represent average group differences
in babies' behavior across conditions.

00:03:47.160 --> 00:03:49.743
In each movie, you're going to see
a baby doing maybe

00:03:49.743 --> 00:03:53.203
just exactly what you might
expect a baby to do,

00:03:53.203 --> 00:03:57.220
and we can hardly make babies
more magical than they already are.

00:03:58.090 --> 00:04:00.100
But to my mind the magical thing,

00:04:00.100 --> 00:04:02.189
and what I want you to pay attention to,

00:04:02.189 --> 00:04:05.300
is the contrast between
these two conditions,

00:04:05.300 --> 00:04:08.829
because the only thing
that differs between these two movies

00:04:08.829 --> 00:04:12.295
is the statistical evidence
the babies are going to observe.

00:04:13.425 --> 00:04:16.608
We're going to show babies
a box of blue and yellow balls,

00:04:16.608 --> 00:04:21.228
and my then-graduate student,
now colleague at Stanford, Hyowon Gweon,

00:04:21.228 --> 00:04:24.305
is going to pull three blue balls
in a row out of this box,

00:04:24.305 --> 00:04:27.428
and when she pulls those balls out,
she's going to squeeze them,

00:04:27.428 --> 00:04:29.541
and the balls are going to squeak.

00:04:29.541 --> 00:04:32.304
And if you're a baby,
that's like a TED Talk.

00:04:32.304 --> 00:04:34.208
It doesn't get better than that.

00:04:34.208 --> 00:04:36.769
(Laughter)

00:04:38.968 --> 00:04:42.627
But the important point is it's really
easy to pull three blue balls in a row

00:04:42.627 --> 00:04:44.932
out of a box of mostly blue balls.

00:04:44.932 --> 00:04:46.992
You could do that with your eyes closed.

00:04:46.992 --> 00:04:49.988
It's plausibly a random sample
from this population.

00:04:49.988 --> 00:04:53.720
And if you can reach into a box at random
and pull out things that squeak,

00:04:53.720 --> 00:04:56.559
then maybe everything in the box squeaks.

00:04:56.559 --> 00:05:00.209
So maybe babies should expect
those yellow balls to squeak as well.

00:05:00.209 --> 00:05:02.728
Now, those yellow balls
have funny sticks on the end,

00:05:02.728 --> 00:05:05.585
so babies could do other things
with them if they wanted to.

00:05:05.585 --> 00:05:07.416
They could pound them or whack them.

00:05:07.416 --> 00:05:10.002
But let's see what the baby does.

00:05:12.548 --> 00:05:15.891
(Video) Hyowon Gweon: See this?
(Ball squeaks)

00:05:16.531 --> 00:05:19.576
Did you see that?
(Ball squeaks)

00:05:20.036 --> 00:05:23.102
Cool.

00:05:24.706 --> 00:05:26.656
See this one?

00:05:26.656 --> 00:05:28.537
(Ball squeaks)

00:05:28.537 --> 00:05:31.190
Wow.

00:05:33.854 --> 00:05:35.967
Laura Schulz: Told you. (Laughs)

00:05:35.967 --> 00:05:39.998
(Video) HG: See this one?
(Ball squeaks)

00:05:39.998 --> 00:05:44.617
Hey Clara, this one's for you.
You can go ahead and play.

00:05:51.854 --> 00:05:56.219
(Laughter)

00:05:56.219 --> 00:05:59.214
LS: I don't even have to talk, right?

00:05:59.214 --> 00:06:02.113
All right, it's nice that babies
will generalize properties

00:06:02.113 --> 00:06:03.641
of blue balls to yellow balls,

00:06:03.641 --> 00:06:06.737
and it's impressive that babies
can learn from imitating us,

00:06:06.737 --> 00:06:10.406
but we've known those things about babies
for a very long time.

00:06:10.406 --> 00:06:12.217
The really interesting question

00:06:12.217 --> 00:06:15.069
is what happens when we show babies
exactly the same thing,

00:06:15.069 --> 00:06:18.680
and we can ensure it's exactly the same
because we have a secret compartment

00:06:18.680 --> 00:06:20.790
and we actually pull the balls from there,

00:06:20.790 --> 00:06:24.268
but this time, all we change
is the apparent population

00:06:24.268 --> 00:06:27.170
from which that evidence was drawn.

00:06:27.170 --> 00:06:30.723
This time, we're going to show babies
three blue balls

00:06:30.723 --> 00:06:34.107
pulled out of a box
of mostly yellow balls,

00:06:34.107 --> 00:06:35.429
and guess what?

00:06:35.429 --> 00:06:38.269
You [probably won't] randomly draw
three blue balls in a row

00:06:38.269 --> 00:06:40.753
out of a box of mostly yellow balls.

00:06:40.753 --> 00:06:44.500
That is not plausibly
randomly sampled evidence.

00:06:44.500 --> 00:06:49.623
That evidence suggests that maybe Hyowon
was deliberately sampling the blue balls.

00:06:49.623 --> 00:06:52.206
Maybe there's something special
about the blue balls.

00:06:52.846 --> 00:06:55.822
Maybe only the blue balls squeak.

00:06:55.822 --> 00:06:57.717
Let's see what the baby does.

00:06:57.717 --> 00:07:00.621
(Video) HG: See this?
(Ball squeaks)

00:07:02.851 --> 00:07:05.496
See this toy?
(Ball squeaks)

00:07:05.496 --> 00:07:10.976
Oh, that was cool. See?
(Ball squeaks)

00:07:10.976 --> 00:07:15.370
Now this one's for you to play.
You can go ahead and play.

00:07:18.074 --> 00:07:24.421
(Fussing)
(Laughter)

00:07:26.901 --> 00:07:29.649
LS: So you just saw
two 15-month-old babies

00:07:29.649 --> 00:07:31.591
do entirely different things

00:07:31.591 --> 00:07:35.190
based only on the probability
of the sample they observed.

00:07:35.190 --> 00:07:37.511
Let me show you the experimental results.

00:07:37.511 --> 00:07:40.275
On the vertical axis, you'll see
the percentage of babies

00:07:40.275 --> 00:07:42.805
who squeezed the ball in each condition,

00:07:42.805 --> 00:07:46.520
and as you'll see, babies are much
more likely to generalize the evidence

00:07:46.520 --> 00:07:49.655
when it's plausibly representative
of the population

00:07:49.655 --> 00:07:53.393
than when the evidence
is clearly cherry-picked.

00:07:53.393 --> 00:07:55.808
And this leads to a fun prediction:

00:07:55.808 --> 00:08:00.676
Suppose you pulled just one blue ball
out of the mostly yellow box.

00:08:00.896 --> 00:08:04.765
You [probably won't] pull three blue balls
in a row at random out of a yellow box,

00:08:04.765 --> 00:08:07.220
but you could randomly sample
just one blue ball.

00:08:07.220 --> 00:08:09.190
That's not an improbable sample.

00:08:09.190 --> 00:08:11.414
And if you could reach into
a box at random

00:08:11.414 --> 00:08:15.401
and pull out something that squeaks,
maybe everything in the box squeaks.

00:08:15.875 --> 00:08:20.320
So even though babies are going to see
much less evidence for squeaking,

00:08:20.320 --> 00:08:22.562
and have many fewer actions to imitate

00:08:22.562 --> 00:08:25.905
in this one ball condition than in
the condition you just saw,

00:08:25.905 --> 00:08:29.797
we predicted that babies themselves
would squeeze more,

00:08:29.797 --> 00:08:32.691
and that's exactly what we found.

00:08:32.691 --> 00:08:37.102
So 15-month-old babies,
in this respect, like scientists,

00:08:37.102 --> 00:08:40.190
care whether evidence
is randomly sampled or not,

00:08:40.190 --> 00:08:43.697
and they use this to develop
expectations about the world:

00:08:43.697 --> 00:08:45.879
what squeaks and what doesn't,

00:08:45.879 --> 00:08:49.024
what to explore and what to ignore.

00:08:50.384 --> 00:08:52.450
Let me show you another example now,

00:08:52.450 --> 00:08:55.180
this time about a problem
of causal reasoning.

00:08:55.180 --> 00:08:57.619
And it starts with a problem
of confounded evidence

00:08:57.619 --> 00:08:59.291
that all of us have,

00:08:59.291 --> 00:09:01.311
which is that we are part of the world.

00:09:01.311 --> 00:09:04.747
And this might not seem like a problem
to you, but like most problems,

00:09:04.747 --> 00:09:07.084
it's only a problem when things go wrong.

00:09:07.464 --> 00:09:09.275
Take this baby, for instance.

00:09:09.275 --> 00:09:10.980
Things are going wrong for him.

00:09:10.980 --> 00:09:13.251
He would like to make
this toy go, and he can't.

00:09:13.251 --> 00:09:15.780
I'll show you a few-second clip.

00:09:21.340 --> 00:09:23.260
And there's two possibilities, broadly:

00:09:23.260 --> 00:09:25.894
Maybe he's doing something wrong,

00:09:25.894 --> 00:09:30.110
or maybe there's something
wrong with the toy.

00:09:30.110 --> 00:09:32.221
So in this next experiment,

00:09:32.221 --> 00:09:35.518
we're going to give babies
just a tiny bit of statistical data

00:09:35.518 --> 00:09:38.100
supporting one hypothesis over the other,

00:09:38.100 --> 00:09:41.555
and we're going to see if babies
can use that to make different decisions

00:09:41.555 --> 00:09:43.389
about what to do.

00:09:43.389 --> 00:09:45.411
Here's the setup.

00:09:46.071 --> 00:09:49.101
Hyowon is going to try to make
the toy go and succeed.

00:09:49.101 --> 00:09:52.421
I am then going to try twice
and fail both times,

00:09:52.421 --> 00:09:55.533
and then Hyowon is going
to try again and succeed,

00:09:55.533 --> 00:09:58.705
and this roughly sums up my relationship
to my graduate students

00:09:58.705 --> 00:10:01.540
in technology across the board.

00:10:02.030 --> 00:10:05.322
But the important point here is
it provides a little bit of evidence

00:10:05.322 --> 00:10:08.990
that the problem isn't with the toy,
it's with the person.

00:10:08.990 --> 00:10:11.340
Some people can make this toy go,

00:10:11.340 --> 00:10:12.299
and some can't.

00:10:12.799 --> 00:10:16.212
Now, when the baby gets the toy,
he's going to have a choice.

00:10:16.212 --> 00:10:18.400
His mom is right there,

00:10:18.400 --> 00:10:21.715
so he can go ahead and hand off the toy
and change the person,

00:10:21.715 --> 00:10:24.873
but there's also going to be
another toy at the end of that cloth,

00:10:24.873 --> 00:10:28.425
and he can pull the cloth towards him
and change the toy.

00:10:28.425 --> 00:10:30.515
So let's see what the baby does.

00:10:30.515 --> 00:10:34.698
(Video) HG: Two, three. Go!
(Music)

00:10:34.698 --> 00:10:37.829
LS: One, two, three, go!

00:10:37.829 --> 00:10:45.211
Arthur, I'm going to try again.
One, two, three, go!

00:10:45.677 --> 00:10:48.277
YG: Arthur, let me try again, okay?

00:10:48.277 --> 00:10:52.827
One, two, three, go!
(Music)

00:10:53.583 --> 00:10:55.466
Look at that. Remember these toys?

00:10:55.466 --> 00:10:58.730
See these toys? Yeah, I'm going
to put this one over here,

00:10:58.730 --> 00:11:00.792
and I'm going to give this one to you.

00:11:00.792 --> 00:11:03.127
You can go ahead and play.

00:11:23.213 --> 00:11:27.950
LS: Okay, Laura, but of course,
babies love their mommies.

00:11:27.950 --> 00:11:30.132
Of course babies give toys
to their mommies

00:11:30.132 --> 00:11:32.162
when they can't make them work.

00:11:32.162 --> 00:11:35.755
So again, the really important question
is what happens when we change

00:11:35.755 --> 00:11:38.909
the statistical data ever so slightly.

00:11:38.909 --> 00:11:42.996
This time, babies are going to see the toy
work and fail in exactly the same order,

00:11:42.996 --> 00:11:45.411
but we're changing
the distribution of evidence.

00:11:45.411 --> 00:11:49.822
This time, Hyowon is going to succeed
once and fail once, and so am I.

00:11:49.822 --> 00:11:55.459
And this suggests it doesn't matter
who tries this toy, the toy is broken.

00:11:55.459 --> 00:11:57.345
It doesn't work all the time.

00:11:57.345 --> 00:11:59.310
Again, the baby's going to have a choice.

00:11:59.310 --> 00:12:02.706
Her mom is right next to her,
so she can change the person,

00:12:02.706 --> 00:12:05.910
and there's going to be another toy
at the end of the cloth.

00:12:05.910 --> 00:12:07.288
Let's watch what she does.

00:12:07.288 --> 00:12:11.636
(Video) HG: Two, three, go!
(Music)

00:12:11.636 --> 00:12:16.620
Let me try one more time.
One, two, three, go!

00:12:17.460 --> 00:12:19.157
Hmm.

00:12:19.950 --> 00:12:22.642
LS: Let me try, Clara.

00:12:22.642 --> 00:12:26.587
One, two, three, go!

00:12:27.265 --> 00:12:29.200
Hmm, let me try again.

00:12:29.200 --> 00:12:34.870
One, two, three, go!
(Music)

00:12:35.009 --> 00:12:37.242
HG: I'm going
to put this one over here,

00:12:37.242 --> 00:12:39.243
and I'm going to give this one to you.

00:12:39.243 --> 00:12:42.840
You can go ahead and play.

00:12:58.376 --> 00:13:03.273
(Applause)

00:13:04.993 --> 00:13:07.385
LS: Let me show you
the experimental results.

00:13:07.385 --> 00:13:09.860
On the vertical axis,
you'll see the distribution

00:13:09.860 --> 00:13:12.437
of children's choices in each condition,

00:13:12.437 --> 00:13:16.988
and you'll see that the distribution
of the choices children make

00:13:16.988 --> 00:13:19.775
depends on the evidence they observe.

00:13:19.775 --> 00:13:21.632
So in the second year of life,

00:13:21.632 --> 00:13:24.209
babies can use a tiny bit
of statistical data

00:13:24.209 --> 00:13:27.576
to decide between two
fundamentally different strategies

00:13:27.576 --> 00:13:29.457
for acting in the world:

00:13:29.457 --> 00:13:32.200
asking for help and exploring.

00:13:33.700 --> 00:13:37.134
I've just shown you
two laboratory experiments

00:13:37.134 --> 00:13:40.825
out of literally hundreds in the field
that make similar points,

00:13:40.825 --> 00:13:43.217
because the really critical point

00:13:43.217 --> 00:13:48.325
is that children's ability
to make rich inferences from sparse data

00:13:48.325 --> 00:13:53.666
underlies all the species-specific
cultural learning that we do.

00:13:53.666 --> 00:13:58.263
Children learn about new tools
from just a few examples.

00:13:58.263 --> 00:14:02.980
They learn new causal relationships
from just a few examples.

00:14:03.928 --> 00:14:08.799
They even learn new words,
in this case in American Sign Language.

00:14:08.799 --> 00:14:11.110
I want to close with just two points.

00:14:12.050 --> 00:14:15.738
If you've been following my world,
the field of brain and cognitive sciences,

00:14:15.738 --> 00:14:17.665
for the past few years,

00:14:17.665 --> 00:14:20.080
three big ideas will have come
to your attention.

00:14:20.080 --> 00:14:23.516
The first is that this is
the era of the brain.

00:14:23.516 --> 00:14:27.185
And indeed, there have been
staggering discoveries in neuroscience:

00:14:27.185 --> 00:14:30.621
localizing functionally specialized
regions of cortex,

00:14:30.621 --> 00:14:33.222
turning mouse brains transparent,

00:14:33.222 --> 00:14:36.998
activating neurons with light.

00:14:36.998 --> 00:14:38.994
A second big idea

00:14:38.994 --> 00:14:43.098
is that this is the era of big data
and machine learning,

00:14:43.098 --> 00:14:46.239
and machine learning promises
to revolutionize our understanding

00:14:46.239 --> 00:14:50.906
of everything from social networks
to epidemiology.

00:14:50.906 --> 00:14:53.599
And maybe, as it tackles problems
of scene understanding

00:14:53.599 --> 00:14:55.592
and natural language processing,

00:14:55.592 --> 00:14:58.916
to tell us something
about human cognition.

00:14:59.756 --> 00:15:01.693
And the final big idea you'll have heard

00:15:01.693 --> 00:15:05.080
is that maybe it's a good idea we're going
to know so much about brains

00:15:05.080 --> 00:15:06.997
and have so much access to big data,

00:15:06.997 --> 00:15:09.504
because left to our own devices,

00:15:09.504 --> 00:15:13.335
humans are fallible, we take shortcuts,

00:15:13.335 --> 00:15:16.772
we err, we make mistakes,

00:15:16.772 --> 00:15:20.456
we're biased, and in innumerable ways,

00:15:20.456 --> 00:15:23.425
we get the world wrong.

00:15:24.843 --> 00:15:27.792
I think these are all important stories,

00:15:27.792 --> 00:15:31.577
and they have a lot to tell us
about what it means to be human,

00:15:31.577 --> 00:15:35.106
but I want you to note that today
I told you a very different story.

00:15:35.966 --> 00:15:39.773
It's a story about minds and not brains,

00:15:39.773 --> 00:15:42.779
and in particular, it's a story
about the kinds of computations

00:15:42.779 --> 00:15:45.369
that uniquely human minds can perform,

00:15:45.369 --> 00:15:49.313
which involve rich, structured knowledge
and the ability to learn

00:15:49.313 --> 00:15:54.581
from small amounts of data,
the evidence of just a few examples.

00:15:56.301 --> 00:16:00.600
And fundamentally, it's a story
about how starting as very small children

00:16:00.600 --> 00:16:04.780
and continuing out all the way
to the greatest accomplishments

00:16:04.780 --> 00:16:08.623
of our culture,

00:16:08.623 --> 00:16:10.620
we get the world right.

00:16:12.433 --> 00:16:17.700
Folks, human minds do not only learn
from small amounts of data.

00:16:18.285 --> 00:16:20.386
Human minds think
of altogether new ideas.

00:16:20.746 --> 00:16:23.787
Human minds generate
research and discovery,

00:16:23.787 --> 00:16:29.060
and human minds generate
art and literature and poetry and theater,

00:16:29.070 --> 00:16:32.830
and human minds take care of other humans:

00:16:32.830 --> 00:16:36.257
our old, our young, our sick.

00:16:36.517 --> 00:16:38.884
We even heal them.

00:16:39.564 --> 00:16:42.667
In the years to come, we're going
to see technological innovations

00:16:42.667 --> 00:16:46.464
beyond anything I can even envision,

00:16:46.464 --> 00:16:48.614
but we are very unlikely

00:16:48.614 --> 00:16:54.323
to see anything even approximating
the computational power of a human child

00:16:54.323 --> 00:16:58.621
in my lifetime or in yours.

00:16:58.621 --> 00:17:03.668
If we invest in these most powerful
learners and their development,

00:17:03.668 --> 00:17:06.585
in babies and children

00:17:06.585 --> 00:17:08.411
and mothers and fathers

00:17:08.411 --> 00:17:11.110
and caregivers and teachers

00:17:11.110 --> 00:17:15.280
the ways we invest in our other
most powerful and elegant forms

00:17:15.280 --> 00:17:18.498
of technology, engineering and design,

00:17:18.498 --> 00:17:21.437
we will not just be dreaming
of a better future,

00:17:21.437 --> 00:17:23.564
we will be planning for one.

00:17:23.564 --> 00:17:25.909
Thank you very much.

00:17:25.909 --> 00:17:29.330
(Applause)

00:17:29.810 --> 00:17:34.236
Chris Anderson: Laura, thank you.
I do actually have a question for you.

00:17:34.236 --> 00:17:36.595
First of all, the research is insane.

00:17:36.595 --> 00:17:40.320
I mean, who would design
an experiment like that? (Laughter)

00:17:41.150 --> 00:17:42.940
I've seen that a couple of times,

00:17:42.940 --> 00:17:46.162
and I still don't honestly believe
that that can truly be happening,

00:17:46.162 --> 00:17:49.320
but other people have done
similar experiments; it checks out.

00:17:49.320 --> 00:17:50.953
The babies really are that genius.

00:17:50.953 --> 00:17:53.960
LS: You know, they look really impressive
in our experiments,

00:17:53.960 --> 00:17:56.612
but think about what they
look like in real life, right?

00:17:56.612 --> 00:17:57.762
It starts out as a baby.

00:17:57.762 --> 00:17:59.769
Eighteen months later,
it's talking to you,

00:17:59.769 --> 00:18:02.810
and babies' first words aren't just
things like balls and ducks,

00:18:02.810 --> 00:18:05.691
they're things like "all gone,"
which refer to disappearance,

00:18:05.691 --> 00:18:07.974
or "uh-oh," which refer
to unintentional actions.

00:18:07.974 --> 00:18:09.536
It has to be that powerful.

00:18:09.536 --> 00:18:12.311
It has to be much more powerful
than anything I showed you.

00:18:12.311 --> 00:18:14.285
They're figuring out the entire world.

00:18:14.285 --> 00:18:17.429
A four-year-old can talk to you
about almost anything.

00:18:17.429 --> 00:18:19.030
(Applause)

00:18:19.030 --> 00:18:22.444
CA: And if I understand you right,
the other key point you're making is,

00:18:22.444 --> 00:18:25.198
we've been through these years
where there's all this talk

00:18:25.198 --> 00:18:27.130
of how quirky and buggy our minds are,

00:18:27.130 --> 00:18:29.997
that behavioral economics
and the whole theories behind that

00:18:29.997 --> 00:18:31.600
that we're not rational agents.

00:18:31.600 --> 00:18:35.816
You're really saying that the bigger
story is how extraordinary,

00:18:35.816 --> 00:18:40.760
and there really is genius there
that is underappreciated.

00:18:40.760 --> 00:18:42.830
LS: One of my favorite
quotes in psychology

00:18:42.830 --> 00:18:45.120
comes from the social
psychologist Solomon Asch,

00:18:45.120 --> 00:18:47.927
and he said the fundamental task
of psychology is to remove

00:18:47.927 --> 00:18:50.553
the veil of self-evidence from things.

00:18:50.553 --> 00:18:55.104
There are orders of magnitude
more decisions you make every day

00:18:55.104 --> 00:18:56.451
that get the world right.

00:18:56.451 --> 00:18:58.583
You know about objects
and their properties.

00:18:58.583 --> 00:19:01.612
You know them when they're occluded.
You know them in the dark.

00:19:01.612 --> 00:19:02.920
You can walk through rooms.

00:19:02.920 --> 00:19:06.452
You can figure out what other people
are thinking. You can talk to them.

00:19:06.452 --> 00:19:08.682
You can navigate space.
You know about numbers.

00:19:08.682 --> 00:19:11.704
You know causal relationships.
You know about moral reasoning.

00:19:11.704 --> 00:19:14.060
You do this effortlessly,
so we don't see it,

00:19:14.060 --> 00:19:16.972
but that is how we get the world right,
and it's a remarkable

00:19:16.972 --> 00:19:19.290
and very difficult-to-understand
accomplishment.

00:19:19.290 --> 00:19:21.918
CA: I suspect there are people
in the audience who have

00:19:21.918 --> 00:19:24.156
this view of accelerating
technological power

00:19:24.156 --> 00:19:27.114
who might dispute your statement
that never in our lifetimes

00:19:27.114 --> 00:19:29.732
will a computer do what
a three-year-old child can do,

00:19:29.732 --> 00:19:32.980
but what's clear is that in any scenario,

00:19:32.980 --> 00:19:36.750
our machines have so much to learn
from our toddlers.

00:19:38.230 --> 00:19:41.446
LS: I think so. You'll have some
machine learning folks up here.

00:19:41.446 --> 00:19:45.649
I mean, you should never bet
against babies or chimpanzees

00:19:45.649 --> 00:19:49.294
or technology as a matter of practice,

00:19:49.294 --> 00:19:53.822
but it's not just
a difference in quantity,

00:19:53.822 --> 00:19:55.586
it's a difference in kind.

00:19:55.586 --> 00:19:57.746
We have incredibly powerful computers,

00:19:57.746 --> 00:20:00.137
and they do do amazingly
sophisticated things,

00:20:00.137 --> 00:20:03.341
often with very big amounts of data.

00:20:03.341 --> 00:20:05.948
Human minds do, I think,
something quite different,

00:20:05.948 --> 00:20:09.843
and I think it's the structured,
hierarchical nature of human knowledge

00:20:09.843 --> 00:20:11.875
that remains a real challenge.

00:20:11.875 --> 00:20:14.936
CA: Laura Schulz, wonderful
food for thought. Thank you so much.

00:20:14.936 --> 00:20:17.858
LS: Thank you.
(Applause)

