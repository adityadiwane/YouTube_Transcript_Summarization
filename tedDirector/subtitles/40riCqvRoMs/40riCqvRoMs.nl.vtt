WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Dick Stada
Nagekeken door: Rik Delaet

00:00:14.366 --> 00:00:17.864
Ik laat je wat zien.

00:00:17.864 --> 00:00:22.000
(Video) Meisje: Oké, dat is een poes
die in bed zit.

00:00:22.000 --> 00:00:26.300
De jongen verzorgt de olifant.

00:00:26.300 --> 00:00:30.414
Dat zijn mensen
die met het vliegtuig gaan.

00:00:30.414 --> 00:00:33.234
Dat is een groot vliegtuig.

00:00:33.234 --> 00:00:35.510
Fei-Fei Li: Dit is een kind van drie

00:00:35.510 --> 00:00:39.349
dat beschrijft wat het ziet
op een serie foto's.

00:00:39.349 --> 00:00:42.194
Het moet nog veel leren over de wereld,

00:00:42.194 --> 00:00:46.743
maar het is nu al een expert
in iets heel belangrijks:

00:00:46.743 --> 00:00:49.919
iets zinnigs maken van wat het ziet.

00:00:49.919 --> 00:00:54.185
Onze maatschappij is technologisch
verder dan ooit.

00:00:54.185 --> 00:00:57.924
We sturen mensen naar de maan,
maken telefoons die tegen ons praten,

00:00:57.924 --> 00:01:03.030
of stellen radiozenders samen, die alleen
muziek uitzenden die we mooi vinden.

00:01:03.030 --> 00:01:09.685
Toch worstelen onze geavanceerde machines
en computers met deze taak.

00:01:09.688 --> 00:01:13.327
Ik ben hier vandaag om je
de voortgang te laten zien

00:01:13.327 --> 00:01:17.384
van de recentste ontwikkelingen
in ons onderzoek naar computervisie,

00:01:17.384 --> 00:01:22.375
een van de meest grensverleggende
en mogelijk revolutionaire technologieën

00:01:22.375 --> 00:01:24.741
in de computerwetenschap.

00:01:24.741 --> 00:01:29.322
Ja, we hebben prototypes van auto's
die zelf kunnen rijden,

00:01:29.322 --> 00:01:33.265
maar zonder slim zicht,
zien ze het verschil niet

00:01:33.265 --> 00:01:37.235
tussen een verfrommelde papieren zak
op de weg, waar je overheen kan rijden,

00:01:37.235 --> 00:01:41.255
en een evengrote kei,
waar je omheen moet rijden.

00:01:41.255 --> 00:01:44.805
We hebben geweldige
megapixelcamera's gemaakt,

00:01:44.805 --> 00:01:48.280
maar we kunnen blinden
nog niet laten zien.

00:01:48.280 --> 00:01:51.525
Drones kunnen grote afstanden vliegen,

00:01:51.525 --> 00:01:53.859
maar hun visie-technologie schiet tekort

00:01:53.859 --> 00:01:57.320
om veranderingen te helpen opsporen
in het regenwoud.

00:01:57.320 --> 00:02:00.270
Er zijn overal veiligheidscamera's,

00:02:00.270 --> 00:02:06.057
maar die waarschuwen ons niet
als een kind verdrinkt in een zwembad.

00:02:06.057 --> 00:02:11.502
Foto's en filmpjes zijn deel
van ons leven geworden.

00:02:11.502 --> 00:02:15.849
Ze verschijnen sneller dan welk mens,

00:02:15.849 --> 00:02:18.632
of welk team mensen ooit kan bekijken,

00:02:18.632 --> 00:02:22.553
en jullie en ik dragen daaraan bij
op deze TED.

00:02:22.553 --> 00:02:27.785
Onze meest geavanceerde software 
heeft nog steeds moeite met het begrijpen

00:02:27.785 --> 00:02:31.661
van deze enorme hoeveelheid gegevens.

00:02:31.661 --> 00:02:38.239
Met andere woorden,
we zijn met z'n allen heel erg blind,

00:02:38.239 --> 00:02:43.306
omdat onze slimste machines
ook nog blind zijn.

00:02:43.306 --> 00:02:46.192
Je zal je afvragen
waarom het zo moeilijk is.

00:02:46.192 --> 00:02:48.825
Camera's kunnen dit soort foto's nemen

00:02:48.825 --> 00:02:52.749
door licht om te zetten
naar een 2-dimensionale serie getallen,

00:02:52.749 --> 00:02:54.789
bekend als pixels.

00:02:54.789 --> 00:02:57.040
Maar dit zijn slechts levenloze getallen.

00:02:57.040 --> 00:03:00.151
Ze hebben zelf geen betekenis.

00:03:00.151 --> 00:03:04.174
Horen is niet hetzelfde als luisteren.

00:03:04.174 --> 00:03:08.284
Foto's nemen is niet hetzelfde als zien.

00:03:08.284 --> 00:03:12.973
En met zien
bedoelen we echt begrijpen.

00:03:12.973 --> 00:03:19.470
Het kostte Moeder Natuur
540 miljoen jaar hard werken

00:03:19.470 --> 00:03:21.443
om dit te doen.

00:03:21.443 --> 00:03:23.204
Veel van die inspanning

00:03:23.204 --> 00:03:28.245
ging zitten in het ontwikkelen
van het verwerkingsgedeelte in ons brein.

00:03:28.245 --> 00:03:31.032
Niet de ogen zelf.

00:03:31.032 --> 00:03:33.809
Gezichtsvermogen begint bij de ogen,

00:03:33.809 --> 00:03:37.507
maar het gebeurt in feite
in de hersenen.

00:03:38.287 --> 00:03:42.557
Al 15 jaar, vanaf mijn
promoveren aan Caltech,

00:03:42.557 --> 00:03:46.173
en later, toen ik de leiding had
van het Stanford Vision Lab,

00:03:46.173 --> 00:03:50.669
werk ik samen met mijn mentoren,
medewerkers en studenten

00:03:50.669 --> 00:03:53.558
om computers te leren zien.

00:03:54.098 --> 00:03:57.952
Ons onderzoeksgebied heet
computervisie en machine-leren.

00:03:57.952 --> 00:04:02.840
Het is onderdeel van het algemene
gebied van kunstmatige intelligentie.

00:04:02.840 --> 00:04:08.283
Uiteindelijk willen we de machines
aanleren wat wijzelf ook doen:

00:04:08.283 --> 00:04:13.880
voorwerpen benoemen, mensen herkennen,
ruimtelijke vormen afleiden,

00:04:13.880 --> 00:04:19.568
het begrijpen van verhoudingen,
emoties, acties en bedoelingen.

00:04:19.568 --> 00:04:25.711
Jullie en ik maken complete verhalen
van mensen, plaatsen en dingen,

00:04:25.711 --> 00:04:28.935
op het moment dat we ernaar kijken.

00:04:28.935 --> 00:04:34.538
Eerst moeten we de computer leren
voorwerpen te zien,

00:04:34.538 --> 00:04:37.746
de bouwsteen van de visuele wereld.

00:04:37.746 --> 00:04:42.340
Heel simpel gezegd:
stel je dit leerproces voor

00:04:42.340 --> 00:04:45.335
als het aan de computer laten zien
van oefenplaatjes

00:04:45.335 --> 00:04:48.656
van bepaalde voorwerpen,
bijvoorbeeld katten,

00:04:48.656 --> 00:04:53.213
en ontwerp een model dat leert
van deze oefenplaatjes.

00:04:53.213 --> 00:04:55.277
Hoe moeilijk is dat?

00:04:55.277 --> 00:04:59.489
Een kat is tenslotte alleen maar
een verzameling vormen en kleuren.

00:04:59.489 --> 00:05:03.235
En dit deden we in het begintijd
van het modelleren van voorwerpen.

00:05:03.235 --> 00:05:07.197
We moesten de computer
algoritmes leren in een wiskundige taal,

00:05:07.197 --> 00:05:10.380
dat een kat een ronde kop heeft,
een mollig lijf,

00:05:10.380 --> 00:05:12.589
twee puntoren en een lange staart.

00:05:12.589 --> 00:05:14.679
En dat leek goed te gaan.

00:05:14.699 --> 00:05:16.672
Maar deze kat dan?

00:05:16.672 --> 00:05:17.753
(Gelach)

00:05:17.753 --> 00:05:19.439
Die ligt helemaal opgekruld.

00:05:19.439 --> 00:05:24.408
Nu moet je nog een vorm en gezichtspunt
toevoegen aan je model.

00:05:24.408 --> 00:05:27.033
Maar als katten zijn verstopt?

00:05:27.033 --> 00:05:29.838
Deze grappige katten bijvoorbeeld.

00:05:29.838 --> 00:05:31.363
(Gelach)

00:05:31.363 --> 00:05:33.529
Nu ga je het snappen.

00:05:33.529 --> 00:05:36.896
Zelf iets simpels als een huisdier

00:05:36.896 --> 00:05:41.000
kan zorgen voor ontelbaar veel
variaties van het model.

00:05:41.000 --> 00:05:44.333
Dat is nog maar één voorwerp.

00:05:44.573 --> 00:05:47.065
Acht jaar geleden

00:05:47.065 --> 00:05:53.185
veranderde een simpele
en grondige observatie mijn denken.

00:05:53.185 --> 00:05:55.900
Niemand vertelt aan een kind
hoe het moet kijken.

00:05:55.900 --> 00:05:58.131
Zeker niet in de eerste jaren.

00:05:58.131 --> 00:06:03.371
Ze leren het via ervaringen en voorbeelden
uit het echte leven.

00:06:03.371 --> 00:06:05.711
Bekijk de ogen van kinderen eens

00:06:05.711 --> 00:06:08.445
als een paar biologische camera's.

00:06:08.445 --> 00:06:12.555
Ze nemen elke 200 milliseconden een foto,

00:06:12.555 --> 00:06:15.679
de gemiddelde tijd van een oogbeweging.

00:06:15.679 --> 00:06:21.529
Als het drie is, heeft een kind
honderden miljoenen beelden gezien

00:06:21.529 --> 00:06:23.043
van de echte wereld.

00:06:23.043 --> 00:06:26.193
Dat zijn heel wat oefenvoorbeelden.

00:06:26.193 --> 00:06:32.082
In plaats van je alleen te richten op
steeds betere algoritmes,

00:06:32.082 --> 00:06:37.644
zag ik in dat je de algoritmes
de oefengegevens moest geven

00:06:37.644 --> 00:06:40.673
dat een kind ook krijgt door ervaring.

00:06:40.673 --> 00:06:44.841
Zowel qua kwantiteit als kwaliteit.

00:06:44.841 --> 00:06:46.439
Toen we dat wisten,

00:06:46.439 --> 00:06:49.670
wisten we dat we een verzameling 
gegevens moesten maken

00:06:49.670 --> 00:06:53.619
die veel meer plaatjes bevat
dan wij ooit hebben gehad.

00:06:53.619 --> 00:06:56.706
Misschien wel duizenden keren meer.

00:06:56.706 --> 00:07:00.817
Samen met professor Kai Li
aan de Princeton Universiteit,

00:07:00.817 --> 00:07:05.569
lanceerden we in 2007
het ImageNet-project.

00:07:05.569 --> 00:07:09.267
Gelukkig hoefden we geen camera
op ons hoofd te zetten

00:07:09.267 --> 00:07:10.991
en jaren te wachten.

00:07:10.991 --> 00:07:12.634
We gingen het internet op,

00:07:12.634 --> 00:07:17.070
de grootste schat aan plaatjes
die de mens ooit heeft gemaakt.

00:07:17.070 --> 00:07:20.111
We downloadden
meer dan een miljard plaatjes

00:07:20.111 --> 00:07:25.761
en gebruikten crowdsourcing,
zoals met de Amazon Mechanische Turk

00:07:25.761 --> 00:07:28.330
om ons de plaatjes te helpen kenmerken.

00:07:28.330 --> 00:07:33.230
Op zijn hoogtepunt was ImageNet
een van de grootste werkgevers

00:07:33.230 --> 00:07:36.226
voor de Amazon 
Mechanische Turk-werknemers:

00:07:36.226 --> 00:07:40.080
In totaal bijna 50.000 mensen

00:07:40.080 --> 00:07:44.020
uit 167 landen van de wereld

00:07:44.020 --> 00:07:48.067
hielpen ons met het opschonen,
sorteren en markeren

00:07:48.067 --> 00:07:52.232
van bijna een miljard
mogelijk bruikbare plaatjes.

00:07:52.232 --> 00:07:55.265
Zoveel moeite kostte het

00:07:55.265 --> 00:07:58.815
om slechts een fractie
van de beelden te verwerken

00:07:58.815 --> 00:08:03.778
dat een kind opneemt
in zijn eerste jaren.

00:08:03.778 --> 00:08:08.050
Achteraf gezien lijkt dit idee
om big data te gebruiken

00:08:08.050 --> 00:08:12.330
om computeralgoritmes te trainen,
nogal logisch,

00:08:12.330 --> 00:08:16.540
maar in 2007 was dat niet zo.

00:08:16.540 --> 00:08:20.308
We stonden best lang alleen
op deze weg.

00:08:20.308 --> 00:08:25.591
Een paar vriendelijke collega's
raadden me aan wat nuttigers te gaan doen,

00:08:25.591 --> 00:08:29.703
en we hadden veel moeite
om onderzoeksgeld bij elkaar te krijgen.

00:08:29.703 --> 00:08:32.418
Ik grapte een keer naar mijn studenten

00:08:32.418 --> 00:08:36.301
dat ik mijn stomerij zou heropenen
om ImageNet te sponsoren.

00:08:36.301 --> 00:08:40.962
Zo bekostigde ik immers ook mijn studie.

00:08:40.962 --> 00:08:42.898
We gingen dus door.

00:08:42.898 --> 00:08:47.702
In 2009 leverde het ImageNet-project
een database op

00:08:47.702 --> 00:08:50.556
met 15 miljoen plaatjes

00:08:50.556 --> 00:08:55.660
in 22.000 categorieën
van voorwerpen en dingen

00:08:55.660 --> 00:08:58.690
ingedeeld met alledaagse Engelse woorden.

00:08:58.690 --> 00:09:01.786
Zowel qua kwantiteit als kwaliteit,

00:09:01.786 --> 00:09:04.878
was dit een ongekende schaal.

00:09:04.878 --> 00:09:08.339
We hebben bijvoorbeeld
in het geval van de katten,

00:09:08.339 --> 00:09:11.148
meer dan 62.000 katten

00:09:11.148 --> 00:09:15.088
in allerlei posities en houdingen

00:09:15.088 --> 00:09:20.331
en allerlei soorten wilde en huiskatten.

00:09:20.331 --> 00:09:23.825
We waren enthousiast
toen we ImageNet in elkaar hadden gezet

00:09:23.825 --> 00:09:27.303
en we wilden dat de hele onderzoekswereld
er plezier van had.

00:09:27.303 --> 00:09:31.444
Dus volgens de TED-methode stelden we
gratis de hele verzameling beschikbaar

00:09:31.444 --> 00:09:36.276
aan de wereldwijde onderzoeksgemeenschap.

00:09:36.276 --> 00:09:40.636
(Applaus)

00:09:41.106 --> 00:09:45.774
Nu we de gegevens hebben
om het computerbrein te voeden,

00:09:45.774 --> 00:09:49.491
kunnen we terugkomen
op de algoritmes zelf.

00:09:49.491 --> 00:09:54.549
Het bleek dat de overdadige informatie
die ImageNet gaf,

00:09:54.549 --> 00:09:59.675
precies paste bij een speciaal soort
algoritme voor machineleren.

00:09:59.675 --> 00:10:02.090
die convolutioneel neuraal netwerk heet,

00:10:02.090 --> 00:10:07.338
het eerst aangepakt door Kunihiko
Fukushima, Geoff Hinton en Yann LeCun,

00:10:07.338 --> 00:10:10.853
in de jaren zeventig en tachtig.

00:10:10.853 --> 00:10:12.384
Net als in de hersenen,

00:10:12.384 --> 00:10:16.235
die bestaan uit miljarden 
goedverbonden neuronen,

00:10:16.235 --> 00:10:20.065
is de basiseenheid 
van een neuraal netwerk

00:10:20.065 --> 00:10:22.495
een neuronenachtig knooppunt.

00:10:22.495 --> 00:10:25.115
Het ontvangt input
van andere knooppunten

00:10:25.115 --> 00:10:27.993
en stuurt output naar andere.

00:10:27.993 --> 00:10:32.856
Deze honderdduizenden, 
of zelfs miljoenen knooppunten

00:10:32.856 --> 00:10:35.923
zijn bovendien
in hiërarchische lagen georganiseerd.

00:10:35.923 --> 00:10:38.357
Ook weer net als in de hersenen.

00:10:38.357 --> 00:10:43.420
In een neuraal netwerk dat we gebruiken
om voorwerpherkenning te trainen,

00:10:43.420 --> 00:10:46.601
zitten 24 miljoen knooppunten,

00:10:46.601 --> 00:10:49.228
140 miljoen parameters,

00:10:49.228 --> 00:10:52.371
en 15 miljard verbindingen.

00:10:52.371 --> 00:10:55.076
Dat is een gigantisch model.

00:10:55.076 --> 00:10:58.977
Mogelijk gemaakt door de enorme
hoeveelheid gegevens van IMageNet

00:10:58.977 --> 00:11:03.860
en moderne processoren
om zo'n gigantisch model te trainen,

00:11:03.860 --> 00:11:06.849
kwam het convolutioneel
neuraal netwerk tot bloei,

00:11:06.849 --> 00:11:10.035
op een manier die niemand had verwacht.

00:11:10.035 --> 00:11:11.883
Het werd de architectuur

00:11:11.883 --> 00:11:16.093
die de meeste opwindende 
nieuwe resultaten leverde

00:11:16.093 --> 00:11:17.993
op het gebied van voorwerpherkenning.

00:11:17.993 --> 00:11:20.793
Dit is een computer die ons vertelt

00:11:20.793 --> 00:11:23.173
dat op deze foto een kat staat

00:11:23.173 --> 00:11:24.776
en waar de kat is.

00:11:24.776 --> 00:11:27.188
Er zijn natuurlijk meer dingen dan katten.

00:11:27.188 --> 00:11:29.626
Hier is een computeralgoritme dat zegt

00:11:29.626 --> 00:11:32.900
dat op deze foto
een jongen met teddybeer staat,

00:11:32.900 --> 00:11:37.266
een hond, een persoon
en een vliegertje op de achtergrond,

00:11:37.266 --> 00:11:40.401
of een foto met veel dingen,

00:11:40.401 --> 00:11:45.045
zoals een man, een skateboard,
een hek, een lantaarnpaal, enzovoort.

00:11:45.045 --> 00:11:51.298
Soms, als de computer het
niet helemaal zeker weet,

00:11:51.298 --> 00:11:53.774
hebben we hem geleerd
slim genoeg te zijn

00:11:53.774 --> 00:11:57.462
om een veilig antwoord te geven
in plaats van te veel prijs te geven,

00:11:57.462 --> 00:12:00.133
wat wij ook zouden doen.

00:12:00.133 --> 00:12:05.129
Op andere momenten is het opmerkelijk
wat het computeralgoritme ons vertelt

00:12:05.129 --> 00:12:07.242
welke voorwerpen het precies zijn,

00:12:07.242 --> 00:12:10.818
zoals merk, model
en bouwjaar van de auto.

00:12:10.818 --> 00:12:16.084
We pasten dit algoritme toe op miljoenen
Google Street View-beelden

00:12:16.084 --> 00:12:19.059
dwars door honderden Amerikaanse steden,

00:12:19.059 --> 00:12:22.265
en we bemerkten iets interessants:

00:12:22.265 --> 00:12:25.765
ten eerste bevestigde het ons vermoeden

00:12:25.765 --> 00:12:28.875
dat autoprijzen gelijk op gaan

00:12:28.875 --> 00:12:31.030
met gezinsinkomens.

00:12:31.030 --> 00:12:35.747
Verrassend is echter, 
dat autoprijzen ook gelijk op gaan

00:12:35.747 --> 00:12:38.577
met de misdaadcijfers in de steden,

00:12:38.577 --> 00:12:42.970
of het stemgedrag met de postcode.

00:12:43.640 --> 00:12:46.266
Wacht even, is dat het?

00:12:46.266 --> 00:12:51.419
Is de computer al net zo goed als de mens
of zelfs al beter?

00:12:51.419 --> 00:12:53.557
Niet zo snel.

00:12:53.557 --> 00:12:58.340
Tot nu toe hebben we de computer
alleen geleerd voorwerpen te bekijken.

00:12:58.340 --> 00:13:02.954
Net als een kind leren een paar
zelfstandige naamwoorden te zeggen.

00:13:02.954 --> 00:13:05.554
Een ongelooflijke prestatie,

00:13:05.554 --> 00:13:08.254
maar pas de eerste stap.

00:13:08.254 --> 00:13:11.936
Er zal vlot een volgende mijlpaal
gehaald worden:

00:13:11.936 --> 00:13:15.477
het kind zal beginnen
te communiceren in zinnen.

00:13:15.477 --> 00:13:19.701
In plaats van te zeggen dat het een kat is
op het plaatje,

00:13:19.701 --> 00:13:24.903
heb je het meisje al horen zeggen
dat de kat op een bed ligt.

00:13:24.903 --> 00:13:30.498
Om een computer dus te leren
om een plaatje te zien en zinnen te maken,

00:13:30.498 --> 00:13:34.166
moet het huwelijk tussen big data
en machineleren

00:13:34.166 --> 00:13:36.721
de volgende stap nemen.

00:13:36.721 --> 00:13:40.877
De computer moet zowel leren
van plaatjes

00:13:40.877 --> 00:13:43.733
als van zinnen in natuurlijke taal,

00:13:43.733 --> 00:13:47.055
voortgebracht door mensen.

00:13:47.055 --> 00:13:50.908
Net zoals de hersenen
die beeld en taal integreren,

00:13:50.908 --> 00:13:56.109
hebben we een model ontwikkeld
dat delen van zichtbare dingen,

00:13:56.109 --> 00:13:58.013
visuele fragmenten,

00:13:58.013 --> 00:14:02.216
verbindt met woorden en zinsdelen.

00:14:02.216 --> 00:14:04.799
Ongeveer vier maanden geleden

00:14:04.799 --> 00:14:07.456
voegden we dit allemaal samen

00:14:07.456 --> 00:14:11.250
en maakten een van de eerste 
computervisie-modellen

00:14:11.250 --> 00:14:15.404
dat in staat is mensentaalachtige
zinnen te maken

00:14:15.404 --> 00:14:18.910
als het voor de eerste keer
een plaatje ziet.

00:14:18.910 --> 00:14:23.554
Ik ben zover dat ik wil laten zien
wat de computer zegt

00:14:23.554 --> 00:14:25.529
als die het plaatje ziet

00:14:25.529 --> 00:14:31.019
van het meisje dat je aan het begin 
van de talk hebt gezien.

00:14:31.019 --> 00:14:34.863
(Video) Computer: Een man staat
naast de olifant.

00:14:36.083 --> 00:14:40.027
Een groot vliegtuig staat
op een startbaan.

00:14:41.057 --> 00:14:45.269
FFL: Natuurlijk werken we hard
aan het verbeteren van de algoritmes

00:14:45.269 --> 00:14:47.865
en er moet nog veel geleerd worden.

00:14:47.865 --> 00:14:51.186
(Applaus)

00:14:51.196 --> 00:14:54.877
De computer maakt nog steeds fouten.

00:14:54.877 --> 00:14:58.008
(Video) Computer: Een kat 
ligt op een bed in een laken.

00:14:58.008 --> 00:15:00.571
FFL: Als hij te veel katten ziet,

00:15:00.571 --> 00:15:03.747
kan hij gaan denken dat alles een kat is.

00:15:05.317 --> 00:15:08.181
(Video) Computer: Een jongetje
heeft een honkbalknuppel vast.

00:15:08.181 --> 00:15:09.566
(Gelach)

00:15:09.566 --> 00:15:14.529
FFL: Als hij nog nooit een tandenborstel
heeft gezien, raakt hij in de war.

00:15:15.019 --> 00:15:18.483
(Video) Computer: Een man rijdt paard
door een straat langs een gebouw.

00:15:18.483 --> 00:15:20.546
(Gelach)

00:15:20.546 --> 00:15:25.448
FFL: We hebben Art 101 nog niet
aan de computer geleerd.

00:15:25.448 --> 00:15:28.252
(Video) Computer: Een zebra
staat in een grasveld.

00:15:28.252 --> 00:15:32.019
FFL: Het heeft nog niet geleerd 
de prachtige natuur te waarderen,

00:15:32.019 --> 00:15:34.267
zoals jullie en ik doen.

00:15:34.267 --> 00:15:37.109
De weg is dus lang.

00:15:37.109 --> 00:15:41.315
Het viel niet mee
om van nul naar drie jaar te komen

00:15:41.315 --> 00:15:47.111
Van drie tot 13 jaar of verder,
is helemaal een grote uitdaging.

00:15:47.111 --> 00:15:51.286
Denk nog even aan dit plaatje
van de jongen en de taart.

00:15:51.286 --> 00:15:55.540
Tot nu toe hebben we de computer geleerd
om voorwerpen te zien

00:15:55.540 --> 00:15:59.768
of zelfs een simpel verhaaltje
te vertellen bij het zien van een plaatje.

00:15:59.768 --> 00:16:03.574
(Video) Computer: Een persoon
zit aan tafel met een taart.

00:16:03.574 --> 00:16:05.744
FFL: Maar er zit meer aan vast

00:16:05.744 --> 00:16:08.094
dan alleen een persoon en een taart.

00:16:08.094 --> 00:16:12.941
De computer ziet niet dat dit
een speciale Italiaanse taart is

00:16:12.941 --> 00:16:15.928
die alleen met Pasen wordt gegeten.

00:16:15.928 --> 00:16:19.223
De jongen draagt zijn lievelingsshirt

00:16:19.223 --> 00:16:23.333
die hij heeft gekregen van zijn vader
na een reis naar Sydney,

00:16:23.333 --> 00:16:27.141
en iedereen ziet hoe blij hij is

00:16:27.141 --> 00:16:30.844
en waar hij precies aan denkt
op dat moment.

00:16:30.844 --> 00:16:34.079
Dit is mijn zoon Leo.

00:16:34.079 --> 00:16:36.783
Bij mijn zoektocht
naar visuele intelligentie

00:16:36.783 --> 00:16:39.204
denk ik steeds aan Leo

00:16:39.204 --> 00:16:42.107
en aan zijn toekomstige wereld.

00:16:42.107 --> 00:16:44.278
Als machines kunnen zien,

00:16:44.278 --> 00:16:48.990
zullen doktoren en verpleegsters
een extra paar onvermoeibare ogen hebben

00:16:48.990 --> 00:16:53.082
om te helpen bij de diagnose
en om voor de patiënten te zorgen.

00:16:53.082 --> 00:16:57.465
Auto's zullen slimmer 
en veiliger over de weg rijden..

00:16:57.465 --> 00:16:59.949
Robots, niet alleen mensen,

00:16:59.949 --> 00:17:05.288
zullen ons helpen rampplekken te betreden
om ingeslotenen en gewonden te redden.

00:17:05.288 --> 00:17:09.594
We zullen nieuwe soorten ontdekken
en betere materialen,

00:17:09.594 --> 00:17:14.713
en ongeziene gebieden verkennen
met behulp van machines.

00:17:14.713 --> 00:17:19.280
Beetje bij beetje geven we machines
gezichtsvermogen.

00:17:19.280 --> 00:17:21.798
Eerst leren we ze te kijken.

00:17:21.798 --> 00:17:24.841
Daarna helpen ze ons bij het kijken.

00:17:24.841 --> 00:17:29.006
Voor het eerst zijn menselijke ogen
niet de enige

00:17:29.006 --> 00:17:31.530
die over de wereld nadenken
en haar verkennen.

00:17:31.530 --> 00:17:35.400
We gaan de machines niet alleen
vanwege hun intelligentie gebruiken,

00:17:35.400 --> 00:17:37.580
en gaan met ze samenwerken

00:17:37.580 --> 00:17:40.960
op manieren die we ons 
niet kunnen voorstellen.

00:17:40.960 --> 00:17:43.740
Dit is mijn zoektocht:

00:17:43.740 --> 00:17:46.452
computers visuele intelligentie geven

00:17:46.452 --> 00:17:51.353
en een betere toekomst geven
aan Leo en aan de wereld.

00:17:51.353 --> 00:17:53.074
Dank je wel.

00:17:53.074 --> 00:17:55.389
(Applaus)

