WEBVTT
Kind: captions
Language: pl

00:00:00.000 --> 00:00:07.000
Tłumaczenie: Beata Wasylkiewicz-Jagoda
Korekta: Rysia Wand

00:00:14.366 --> 00:00:17.284
Pokażę wam coś.

00:00:17.284 --> 00:00:21.770
(Wideo) Dziewczynka: To jest kot 
siedzący na łóżku.

00:00:21.770 --> 00:00:26.300
Chłopiec głaszcze słonia.

00:00:26.300 --> 00:00:30.654
To są ludzie idący do samolotu.

00:00:30.654 --> 00:00:33.464
Samolot jest duży.

00:00:33.464 --> 00:00:35.670
Fei-Fei Li: Tak trzyletnie dziecko

00:00:35.670 --> 00:00:39.349
opisuje, co widzi na zdjęciach.

00:00:39.349 --> 00:00:42.194
Wielu rzeczy musi się jeszcze nauczyć,

00:00:42.194 --> 00:00:46.743
ale w jednej dziedzinie 
jest już ekspertem:

00:00:46.743 --> 00:00:49.589
rozumie, co widzi.

00:00:50.009 --> 00:00:54.455
Technicznie nasze społeczeństwo jest 
zaawansowane bardziej niż kiedykolwiek.

00:00:54.455 --> 00:00:58.084
Wysyłamy ludzi na Księżyc, 
tworzymy telefony, które rozmawiają z nami

00:00:58.084 --> 00:01:03.030
i potrafimy sprawić, żeby stacja radiowa, 
grała tylko naszą ulubioną muzykę.

00:01:03.030 --> 00:01:07.085
A jednak nawet najbardziej 
zaawansowane komputery

00:01:07.085 --> 00:01:09.988
ciągle nie mogą sobie poradzić 
z tym zadaniem.

00:01:09.988 --> 00:01:13.447
Dzisiaj chciałabym opowiedzieć

00:01:13.447 --> 00:01:17.494
o ostatnich osiągnięciach w dziedzinie 
widzenia komputerowego,

00:01:17.494 --> 00:01:21.655
jednej z najbardziej pionierskich 
i potencjalnie rewolucyjnych

00:01:21.655 --> 00:01:24.235
technologii w informatyce.

00:01:24.255 --> 00:01:29.412
Istnieje już prototyp samochodu,
który jeździ sam,

00:01:29.412 --> 00:01:32.019
ale bez umiejętności rozpoznawania obrazu

00:01:32.019 --> 00:01:34.326
nie umie odróżnić

00:01:34.326 --> 00:01:37.235
zmiętej papierowej torby,
po której można przejechać,

00:01:37.235 --> 00:01:40.575
od podobnej wielkości kamienia,
który trzeba ominąć.

00:01:41.415 --> 00:01:44.805
Istnieją aparaty fotograficzne 
o bardzo dużej rozdzielczości,

00:01:44.805 --> 00:01:47.940
ale nadal nie wiadomo, 
jak przywrócić wzrok niewidomym.

00:01:48.420 --> 00:01:51.725
Drony mogą latać na dużych przestrzeniach,

00:01:51.725 --> 00:01:53.859
ale nadal nie istnieje technologia,

00:01:53.859 --> 00:01:57.320
która pomogłaby śledzić zmiany 
w lasach deszczowych.

00:01:57.320 --> 00:02:00.270
Kamery przemysłowe są wszędzie,

00:02:00.270 --> 00:02:05.337
ale nie potrafią nas ostrzec, 
jeśli dziecko topi się w basenie.

00:02:06.167 --> 00:02:11.762
Zdjęcia i filmy video stały się 
integralną częścią naszego życia.

00:02:11.762 --> 00:02:15.849
Ilość materiału, który powstaje, 
przekracza możliwości odbiorcze

00:02:15.849 --> 00:02:18.632
pojedynczego człowieka, 
a nawet grupy ludzi.

00:02:18.632 --> 00:02:22.553
Podczas TED dokładamy 
do tego swoją cegiełkę.

00:02:22.553 --> 00:02:27.785
Najbardziej zaawansowane oprogramowanie 
nadal nie umie sobie poradzić

00:02:27.785 --> 00:02:31.661
ze zrozumieniem i zarządzaniem
tak ogromną ilością danych.

00:02:31.661 --> 00:02:36.933
Innymi słowy jako społeczeństwo

00:02:36.933 --> 00:02:38.679
jesteśmy niewidomi,

00:02:38.679 --> 00:02:42.066
bo nasze najmądrzejsze maszyny
wciąż nie widzą.

00:02:43.526 --> 00:02:46.452
"Co w tym trudnego?" moglibyście zapytać.

00:02:46.452 --> 00:02:49.145
Aparaty potrafią zrobić zdjęcie,

00:02:49.145 --> 00:02:53.139
przekształcając światło 
w dwuwymiarowy szereg liczb,

00:02:53.139 --> 00:02:54.789
czyli w piksele.

00:02:54.789 --> 00:02:57.040
Ale są to tylko liczby.

00:02:57.040 --> 00:03:00.151
Nie niosą ze sobą znaczenia.

00:03:00.151 --> 00:03:04.494
Słyszeć, to nie to samo co słuchać,

00:03:04.494 --> 00:03:08.534
a robić zdjęcia, 
to nie to samo co widzieć.

00:03:08.534 --> 00:03:12.363
Mówiąc o widzeniu, 
mam na myśli rozumienie.

00:03:13.292 --> 00:03:17.619
Zrealizowanie tego zadania 
zajęło Matce Naturze

00:03:17.619 --> 00:03:21.416
540 milionów lat ciężkiej pracy,

00:03:21.436 --> 00:03:23.324
a większość tego wysiłku włożyła

00:03:23.324 --> 00:03:28.595
w rozwój części mózgu odpowiedzialnej 
za przetwarzanie wizualne,

00:03:28.595 --> 00:03:31.242
a nie w rozwój oczu.

00:03:31.242 --> 00:03:33.989
Widzenie rozpoczyna się w oczach,

00:03:33.989 --> 00:03:37.507
ale tak naprawdę odbywa się w mózgu.

00:03:38.287 --> 00:03:43.347
Od 15 lat, zaczynając 
od doktoratu w Caltech,

00:03:43.347 --> 00:03:46.273
przez prowadzenie Stanford Vision Lab,

00:03:46.273 --> 00:03:50.669
pracowałam z moimi mentorami, 
współpracownikami i studentami

00:03:50.669 --> 00:03:53.558
nad nauczeniem komputerów widzenia.

00:03:54.658 --> 00:03:57.952
Pole naszych badań to widzenie 
komputerowe i systemy uczące się.

00:03:57.952 --> 00:04:01.830
Jest to część sztucznej inteligencji.

00:04:03.000 --> 00:04:08.493
Chcemy, żeby maszyny widziały tak, jak my,

00:04:08.493 --> 00:04:13.880
potrafiły nazwać rzeczy, rozpoznać ludzi,
wskazać ich położenie w przestrzeni,

00:04:13.880 --> 00:04:19.568
żeby rozumiały relacje, emocje, 
działania i intencje.

00:04:19.568 --> 00:04:25.721
Potrafimy opowiedzieć historię 
o ludziach, miejscach czy rzeczach

00:04:25.721 --> 00:04:27.885
w momencie, kiedy na nie spojrzymy.

00:04:28.955 --> 00:04:34.538
Żeby osiągnąć ten cel, trzeba nauczyć 
komputer widzenia rzeczy,

00:04:34.538 --> 00:04:37.906
klocków, z których składa się świat.

00:04:37.906 --> 00:04:42.340
Wyobraźcie sobie ten proces uczenia

00:04:42.340 --> 00:04:45.335
jako pokazywanie komputerom

00:04:45.335 --> 00:04:48.656
zdjęć konkretnych obiektów, 
na przykład kotów,

00:04:48.656 --> 00:04:53.393
i tworzenie modelu 
na podstawie tych obrazów.

00:04:53.393 --> 00:04:55.437
Czy to takie trudne?

00:04:55.437 --> 00:04:59.489
W końcu kot to tylko zbiór 
kształtów i kolorów.

00:04:59.489 --> 00:05:03.575
Tak właśnie traktowaliśmy obrazy 
na początku modelowania obiektowego.

00:05:03.575 --> 00:05:07.197
Używając języka matematyki, 
mówiliśmy algorytmowi komputerowemu,

00:05:07.197 --> 00:05:10.540
że kot ma okrągłą głowę, puchate ciało,

00:05:10.540 --> 00:05:12.839
szpiczaste uszy i długi ogon,

00:05:12.839 --> 00:05:14.249
i to brzmiało całkiem dobrze.

00:05:14.859 --> 00:05:16.972
Ale co zrobić z takim kotem?

00:05:16.972 --> 00:05:18.063
(Śmiech)

00:05:18.063 --> 00:05:19.689
On jest cały poskręcany.

00:05:19.689 --> 00:05:24.408
Teraz trzeba by dodać nowy kształt 
i punkt widzenia do modelu obiektu.

00:05:24.408 --> 00:05:26.123
A jeśli koty będą schowane?

00:05:27.143 --> 00:05:29.362
Co zrobić z takimi kotami?

00:05:31.112 --> 00:05:33.529
Teraz rozumiecie.

00:05:33.529 --> 00:05:36.896
Nawet coś tak banalnego, 
jak zwierzę domowe

00:05:36.896 --> 00:05:41.400
może dostarczyć nieskończenie wielu 
wersji modelowi obiektu,

00:05:41.400 --> 00:05:43.633
a to nadal tylko jeden obiekt.

00:05:44.573 --> 00:05:47.065
Osiem lat temu

00:05:47.065 --> 00:05:52.095
proste spostrzeżenie zmieniło 
mój sposób myślenia.

00:05:53.425 --> 00:05:56.110
Nikt nie mówi dziecku, jak ma widzieć,

00:05:56.110 --> 00:05:58.371
szczególnie we wczesnym dzieciństwie.

00:05:58.371 --> 00:06:03.371
Dzieci uczą się tego przez 
doświadczanie świata.

00:06:03.371 --> 00:06:06.111
Jeśli potraktować dziecięce oczy

00:06:06.111 --> 00:06:08.665
jako parę biologicznych aparatów,

00:06:08.665 --> 00:06:12.845
to robią one zdjęcie co 200 milisekund,

00:06:12.845 --> 00:06:15.979
co jest średnim czasem ruchu oka.

00:06:15.979 --> 00:06:19.719
Zanim skończy 3 lata, 
dziecko może zobaczyć

00:06:19.719 --> 00:06:23.363
setki milionów obrazów realnego świata.

00:06:23.363 --> 00:06:25.643
To bardzo dużo przykładów.

00:06:26.383 --> 00:06:32.372
Zamiast skupiać się wyłącznie
na ulepszaniu algorytmów,

00:06:32.372 --> 00:06:37.644
wolałam podać im dane treningowe 
podobne do tych,

00:06:37.644 --> 00:06:40.963
które otrzymuje małe dziecko 
poznające świat,

00:06:40.963 --> 00:06:44.841
zarówno pod względem ilościowym, 
jak i jakościowym.

00:06:44.841 --> 00:06:46.699
Kiedy się na to zdecydowaliśmy,

00:06:46.699 --> 00:06:49.670
wiedzieliśmy, że musimy zebrać

00:06:49.670 --> 00:06:54.129
dużo więcej zdjęć, niż mieliśmy dotąd,

00:06:54.129 --> 00:06:56.706
może nawet tysiące razy więcej.

00:06:56.706 --> 00:07:00.817
W związku z tym razem z profesorem Kai Li 
z uniwersytetu Princeton

00:07:00.817 --> 00:07:05.569
w 2007 r. uruchomiliśmy projekt ImageNet.

00:07:05.569 --> 00:07:09.407
Na szczęście nie musieliśmy 
montować aparatu na głowie

00:07:09.407 --> 00:07:11.171
i czekać wiele lat.

00:07:11.171 --> 00:07:12.634
Skorzystaliśmy z Internetu,

00:07:12.634 --> 00:07:17.070
największej skarbnicy zdjęć, 
jaką człowiek kiedykolwiek stworzył.

00:07:17.070 --> 00:07:20.111
Pobraliśmy blisko miliard zdjęć

00:07:20.111 --> 00:07:25.991
i użyliśmy crowdsourcingowej platformy 
Amazon Mechanical Turk,

00:07:25.991 --> 00:07:28.330
żeby je opisać.

00:07:28.330 --> 00:07:33.230
W szczytowym okresie ImageNet zatrudniał
najwięcej pracowników

00:07:33.230 --> 00:07:36.226
na Amazon Mechanical Turk:

00:07:36.226 --> 00:07:40.080
razem prawie 50 000 osób

00:07:40.080 --> 00:07:44.120
ze 167 krajów

00:07:44.120 --> 00:07:48.067
pomagało nam posegregować i opisać

00:07:48.067 --> 00:07:51.642
prawie miliard zdjęć.

00:07:52.612 --> 00:07:55.265
Tak wiele wysiłku kosztowało

00:07:55.265 --> 00:07:59.165
uchwycenie zaledwie ułamka zbioru obrazów,

00:07:59.165 --> 00:08:03.336
które dziecięcy mózg przyswaja
we wczesnych latach rozwoju.

00:08:04.148 --> 00:08:08.050
Pomysł użycia dużej ilości danych

00:08:08.050 --> 00:08:12.600
do uczenia algorytmu komputerowego,
może wydawać się teraz oczywisty,

00:08:12.600 --> 00:08:16.710
ale w 2007 roku taki nie był.

00:08:16.710 --> 00:08:20.588
Przez dłuższy czas 
byliśmy w tej podróży sami.

00:08:20.588 --> 00:08:25.591
Kilku kolegów radziło mi nawet, 
żebym zrobiła coś bardziej użytecznego

00:08:25.591 --> 00:08:29.933
i ciągle zmagaliśmy się 
z brakiem funduszy.

00:08:29.933 --> 00:08:32.418
Zdarzyło mi się nawet żartować 
z moimi studentami,

00:08:32.418 --> 00:08:36.481
że otworzę znowu pralnię, 
żeby sfinansować ImageNet.

00:08:36.481 --> 00:08:41.242
Jakby nie było, tak właśnie 
sfinansowałam swoje studia.

00:08:41.242 --> 00:08:43.098
Kontynuowaliśmy.

00:08:43.098 --> 00:08:46.813
W 2009 roku ImageNet miał już bazę

00:08:46.813 --> 00:08:50.855
15 milionów zdjęć

00:08:50.855 --> 00:08:55.660
skategoryzowanych w 22 000 klas 
obiektów i rzeczy

00:08:55.660 --> 00:08:58.980
oznaczonych angielskimi słowami.

00:08:58.980 --> 00:09:01.906
Zarówno pod względem ilości, jak i jakości

00:09:01.906 --> 00:09:04.878
ta baza była unikalna.

00:09:04.878 --> 00:09:08.339
Na przykład

00:09:08.339 --> 00:09:11.148
mieliśmy ponad 62 000 zdjęć kotów

00:09:11.148 --> 00:09:15.258
wszystkich rodzajów, w różnych pozach

00:09:15.258 --> 00:09:20.481
kotów domowych i dzikich, 
z najróżniejszych gatunków.

00:09:20.481 --> 00:09:23.825
Byliśmy tak podekscytowani 
stworzeniem ImageNet,

00:09:23.825 --> 00:09:27.563
że chcieliśmy, aby cały naukowy świat 
mógł z tego projektu korzystać,

00:09:27.563 --> 00:09:31.604
więc, podobnie jak TED, 
udostępniliśmy wszystkie dane

00:09:31.604 --> 00:09:35.196
za darmo.

00:09:36.636 --> 00:09:40.636
(Brawa)

00:09:41.416 --> 00:09:45.954
Mając dane do zasilenia 
komputerowego mózgu,

00:09:45.954 --> 00:09:49.691
byliśmy gotowi wrócić do algorytmów.

00:09:49.691 --> 00:09:54.869
Jak się okazało, bogactwo informacji
dostarczonych przez ImageNet

00:09:54.869 --> 00:09:59.675
doskonale odpowiadało konkretnej klasie 
algorytmów systemów uczących się,

00:09:59.675 --> 00:10:02.090
a konkretnie sieciom neuronowym

00:10:02.090 --> 00:10:07.338
zapoczątkowanym przez Kunihiko Fukushimę, 
Geoffa Hintona oraz Yanna LeCuna

00:10:07.338 --> 00:10:10.983
w latach 70. i 80.

00:10:10.983 --> 00:10:16.602
Podobnie jak mózg składa się z miliardów 
połączonych ze sobą komórek nerwowych,

00:10:16.602 --> 00:10:20.456
podstawową jednostką operacyjną
w sieci neuronowej

00:10:20.456 --> 00:10:22.871
jest węzeł przypominający taki neuron.

00:10:22.871 --> 00:10:25.425
Pobiera on dane wejściowe z innych węzłów

00:10:25.425 --> 00:10:28.143
i przekazuje innym dane wyjściowe.

00:10:28.143 --> 00:10:32.856
Co więcej te miliony węzłów

00:10:32.856 --> 00:10:36.083
są zorganizowane w hierarchiczne warstwy,

00:10:36.083 --> 00:10:38.637
podobnie jak mózg.

00:10:38.637 --> 00:10:43.420
W sieci neuronowej, której użyliśmy

00:10:43.420 --> 00:10:46.601
były 24 miliony węzłów,

00:10:46.601 --> 00:10:49.898
140 milionów parametrów,

00:10:49.898 --> 00:10:52.661
i 15 miliardów połączeń.

00:10:52.661 --> 00:10:55.076
To jest olbrzymi model.

00:10:55.076 --> 00:10:58.977
Zasilona wielką ilością danych z ImageNet,

00:10:58.977 --> 00:11:04.410
działająca dzięki nowoczesnym 
procesorom CPU i GPU

00:11:04.410 --> 00:11:07.369
sieć neuronowa rozwinęła się w sposób,

00:11:07.369 --> 00:11:10.215
którego nikt się nie spodziewał.

00:11:10.215 --> 00:11:12.723
Stała się najlepszą architekturą

00:11:12.723 --> 00:11:18.063
do osiągnięcia fascynujących rezultatów
w dziedzinie rozpoznawania obrazów.

00:11:18.063 --> 00:11:20.873
Ten komputer mówi,

00:11:20.873 --> 00:11:23.173
że na obrazku jest kot,

00:11:23.173 --> 00:11:25.076
i gdzie ten kot się znajduje.

00:11:25.076 --> 00:11:27.188
Oczywiście koty to nie wszystko,

00:11:27.188 --> 00:11:29.626
więc tutaj komputer mówi,

00:11:29.626 --> 00:11:32.900
że zdjęcie pokazuje chłopca 
i pluszowego misia;

00:11:32.900 --> 00:11:37.266
psa, osobę i mały latawiec w tle;

00:11:37.266 --> 00:11:40.401
albo zdjęcie pełne obiektów

00:11:40.401 --> 00:11:45.045
takich jak mężczyzna, 
deskorolka, poręcz, latarnia.

00:11:45.045 --> 00:11:50.338
Czasami, jeśli komputer 
nie jest pewien tego, co widzi,

00:11:51.498 --> 00:11:53.774
nauczyliśmy go udzielać

00:11:53.774 --> 00:11:57.652
wymijających odpowiedzi,

00:11:57.652 --> 00:12:00.463
takich, jakich udzieliłby człowiek.

00:12:00.463 --> 00:12:05.129
Ale są też przypadki, kiedy algorytm 
potrafi nad wyraz precyzyjnie określić,

00:12:05.129 --> 00:12:07.382
jakie obiekty znajdują się na zdjęciu,

00:12:07.382 --> 00:12:10.818
podając markę, model 
i rok produkcji samochodu.

00:12:10.818 --> 00:12:16.204
Zastosowaliśmy ten algorytm 
do milionów zdjęć z Google Street View

00:12:16.204 --> 00:12:19.339
powstałych w setkach amerykańskich miast

00:12:19.339 --> 00:12:22.265
i odkryliśmy coś interesującego.

00:12:22.265 --> 00:12:25.585
Po pierwsze potwierdził się 
popularny pogląd

00:12:25.585 --> 00:12:28.875
dotyczący relacji cen samochodów

00:12:28.875 --> 00:12:31.220
i dochodu gospodarstw domowych.

00:12:31.220 --> 00:12:35.747
Co zaskakujące, okazało się, 
że ceny samochodów wiążą się też

00:12:35.747 --> 00:12:38.047
ze skalą przestępczości w miastach,

00:12:39.007 --> 00:12:42.970
czy schematami głosowania.

00:12:44.060 --> 00:12:46.266
Ale zaraz, czy to już wszystko?

00:12:46.266 --> 00:12:49.336
Czy komputer dorównał właśnie 
ludzkim możliwościom,

00:12:49.336 --> 00:12:51.126
a może nawet je przekroczył?

00:12:51.126 --> 00:12:53.557
Nie tak szybko.

00:12:53.557 --> 00:12:58.480
Na razie komputer nauczył się
widzieć przedmioty.

00:12:58.480 --> 00:13:03.124
Można go porównać do małego dziecka, 
które nauczyło się pierwszych słów.

00:13:03.124 --> 00:13:05.794
To niesamowite osiągnięcie,

00:13:05.794 --> 00:13:08.254
ale to tylko pierwszy krok.

00:13:08.254 --> 00:13:12.016
Wkrótce kolejny milowy krok

00:13:12.016 --> 00:13:15.477
i dziecko nauczy się tworzyć zdania.

00:13:15.477 --> 00:13:19.701
Dziewczyna z początku prelekcji 
nie mówi, że na zdjęciu jest kot,

00:13:19.701 --> 00:13:24.903
tylko że kot leży na łóżku.

00:13:24.903 --> 00:13:30.498
Żeby nauczyć komputer 
patrzenia na zdjęcia i tworzenia zdań,

00:13:30.498 --> 00:13:34.446
połączenie danych 
i algorytmu systemów uczących się

00:13:34.446 --> 00:13:36.721
musi posunąć się dalej.

00:13:36.721 --> 00:13:40.877
Teraz komputer musi uczyć się 
zarówno ze zdjęć,

00:13:40.877 --> 00:13:43.733
jak i ze zdań

00:13:43.733 --> 00:13:47.055
tworzonych przez ludzi.

00:13:47.055 --> 00:13:50.908
Tak, jak mózg łączy wizję i język,

00:13:50.908 --> 00:13:56.109
rozwinęliśmy model, 
który łączy fragmenty rzeczy,

00:13:56.109 --> 00:13:58.013
jak elementy wizualne,

00:13:58.013 --> 00:14:02.216
z wyrazami i określeniami w zdaniach.

00:14:02.216 --> 00:14:04.979
Cztery miesiące temu

00:14:04.979 --> 00:14:07.626
w końcu połączyliśmy to wszystko razem

00:14:07.626 --> 00:14:11.410
i stworzyliśmy jeden z pierwszych modeli 
widzenia komputerowego,

00:14:11.410 --> 00:14:15.404
który umie tworzyć zdania

00:14:15.404 --> 00:14:18.910
na temat pierwszy raz widzianego zdjęcia.

00:14:18.910 --> 00:14:23.554
Pokażę wam, co komputer powiedział,

00:14:23.554 --> 00:14:25.529
kiedy zobaczył zdjęcia,

00:14:25.529 --> 00:14:29.359
które widziała dziewczynka 
z początku tej prelekcji.

00:14:31.519 --> 00:14:34.863
(Wideo) Komputer: 
Człowiek stoi obok słonia.

00:14:36.393 --> 00:14:40.027
Duży samolot na pasie startowym.

00:14:41.057 --> 00:14:45.269
FFL: Oczywiście ciągle pracujemy 
nad poprawieniem naszych algorytmów

00:14:45.269 --> 00:14:47.865
i one muszą się jeszcze sporo nauczyć.

00:14:47.865 --> 00:14:50.156
(Brawa)

00:14:51.556 --> 00:14:54.867
Komputer nadal popełnia błędy.

00:14:54.867 --> 00:14:58.268
(Wideo) Komputer: 
Kot na łóżku zawinięty w koc.

00:14:58.268 --> 00:15:00.821
FFL: Jeśli widział zbyt wiele kotów,

00:15:00.821 --> 00:15:03.747
wszystko zaczyna mu przypominać kota.

00:15:05.317 --> 00:15:08.181
(Wideo) Komputer: 
Chłopczyk trzyma kij baseballowy.

00:15:08.181 --> 00:15:09.946
(Śmiech)

00:15:09.946 --> 00:15:13.508
FFL: Jeśli nie widział 
szczoteczki do zębów,

00:15:13.508 --> 00:15:15.440
myli ją z kijem baseballowym.

00:15:15.440 --> 00:15:18.743
(Wideo) Komputer: Mężczyzna jadący 
konno po ulicy obok budynku.

00:15:18.743 --> 00:15:20.766
(Śmiech)

00:15:20.766 --> 00:15:24.318
FFL: Nie nauczyliśmy jeszcze 
komputera podstaw sztuki.

00:15:25.768 --> 00:15:28.652
(Wideo) Komputer: Zebra na pastwisku.

00:15:28.652 --> 00:15:32.019
FFL: Nie umie też doceniać piękna natury,

00:15:32.019 --> 00:15:34.457
jak my.

00:15:34.457 --> 00:15:37.289
To była długa droga.

00:15:37.289 --> 00:15:41.515
Przejście od wieku zero
do 3 lat było trudne.

00:15:41.515 --> 00:15:47.111
Ale prawdziwym wyzwaniem jest 
przejście od 3 lat do 13 i dalej.

00:15:47.111 --> 00:15:51.466
Pozwólcie, że przypomnę wam 
zdjęcie chłopca z tortem.

00:15:51.466 --> 00:15:55.540
Dotąd uczyliśmy komputer
dostrzegać przedmioty,

00:15:55.540 --> 00:15:59.998
a nawet opowiedzieć krótką historię
na podstawie zdjęcia.

00:15:59.998 --> 00:16:03.574
(Wideo) Komputer: 
Osoba przy stole z tortem

00:16:03.574 --> 00:16:06.204
FFL: Ale na tym zdjęciu widać dużo więcej,

00:16:06.204 --> 00:16:08.474
niż tylko osobę i tort.

00:16:08.474 --> 00:16:12.941
Komputer nie widzi, 
że ten tort to włoski przysmak,

00:16:12.941 --> 00:16:16.158
serwowany tylko na Wielkanoc.

00:16:16.158 --> 00:16:19.363
Chłopiec ma na sobie ulubioną koszulkę,

00:16:19.363 --> 00:16:23.333
którą dziadek przywiózł mu z Sydney.

00:16:23.333 --> 00:16:27.141
Widać, jak bardzo jest 
w tym momencie szczęśliwy

00:16:27.141 --> 00:16:30.344
i co mu właśnie chodzi po głowie.

00:16:31.214 --> 00:16:34.339
To mój syn, Leo.

00:16:34.339 --> 00:16:36.963
Podczas zmagań z wizualną inteligencją

00:16:36.963 --> 00:16:39.354
myślę bez przerwy o Leo

00:16:39.354 --> 00:16:42.257
i o przyszłym świecie, 
w którym będzie żył.

00:16:42.257 --> 00:16:44.278
W którym maszyny będą umiały widzieć,

00:16:44.278 --> 00:16:48.990
lekarze i pielęgniarki będą mieli 
dodatkową parę niezmęczonych oczu,

00:16:48.990 --> 00:16:53.082
które będą pomagać w leczeniu pacjentów.

00:16:53.082 --> 00:16:57.465
Samochody będą bezpieczniejsze.

00:16:57.465 --> 00:17:00.159
Roboty, nie tylko ludzie,

00:17:00.159 --> 00:17:05.008
będą pomagać w poszukiwaniu rannych 
na obszarach dotkniętych przez katastrofy.

00:17:05.798 --> 00:17:09.594
Odkryjemy nowe gatunki, lepsze materiały

00:17:09.594 --> 00:17:14.103
i przekroczymy nieznane dotąd granice
dzięki pomocy maszyn.

00:17:15.113 --> 00:17:19.280
Powoli dajemy wzrok maszynom.

00:17:19.280 --> 00:17:22.078
Najpierw uczymy je widzieć.

00:17:22.078 --> 00:17:24.841
Potem one pomogą nam lepiej widzieć.

00:17:24.841 --> 00:17:29.006
Po raz pierwszy ludzkie oczy 
nie będą jedynymi,

00:17:29.006 --> 00:17:31.940
które odkrywają świat.

00:17:31.940 --> 00:17:35.400
Będziemy używać maszyn 
nie tylko dla ich inteligencji.

00:17:35.400 --> 00:17:41.579
Naszą współpracę z nimi 
trudno sobie teraz wyobrazić.

00:17:41.579 --> 00:17:43.740
To moje zadanie:

00:17:43.740 --> 00:17:46.452
dać komputerom wizualną inteligencję

00:17:46.452 --> 00:17:51.583
i stworzyć lepszą przyszłość 
dla Leo i dla świata.

00:17:51.583 --> 00:17:53.394
Dziękuję.

00:17:53.394 --> 00:17:57.179
(Brawa)

