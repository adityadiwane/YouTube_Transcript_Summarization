WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:07.000
翻译人员: Twisted Meadows
校对人员: Min WANG

00:00:15.546 --> 00:00:17.614
我先来给你们看点东西。

00:00:17.614 --> 00:00:21.960
（视频）女孩：
好吧，这是只猫，坐在床上。

00:00:21.960 --> 00:00:26.200
一个男孩摸着一头大象。

00:00:26.200 --> 00:00:30.654
那些人正准备登机。

00:00:30.654 --> 00:00:33.184
那是架大飞机。

00:00:33.184 --> 00:00:35.530
李飞飞：
这是一个三岁的小孩

00:00:35.530 --> 00:00:39.349
在讲述她从一系列照片里看到的东西。

00:00:39.349 --> 00:00:42.194
对这个世界，
她也许还有很多要学的东西，

00:00:42.194 --> 00:00:46.743
但在一个重要的任务上，
她已经是专家了：

00:00:46.743 --> 00:00:49.589
去理解她所看到的东西。

00:00:50.119 --> 00:00:54.455
我们的社会已经在科技上
取得了前所未有的进步。

00:00:54.455 --> 00:00:58.084
我们把人送上月球，
我们制造出可以与我们对话的手机，

00:00:58.084 --> 00:01:03.030
或者订制一个音乐电台，
播放的全是我们喜欢的音乐。

00:01:03.030 --> 00:01:07.085
然而，哪怕是我们最先进的机器和电脑

00:01:07.085 --> 00:01:09.988
也会在这个问题上犯难。

00:01:09.988 --> 00:01:13.523
所以今天我在这里，
向大家做个进度汇报：

00:01:13.523 --> 00:01:17.778
关于我们在计算机
视觉方面最新的研究进展。

00:01:17.778 --> 00:01:21.656
这是计算机科学领域最前沿的、

00:01:21.656 --> 00:01:25.014
具有革命性潜力的科技。

00:01:25.014 --> 00:01:29.412
是的，我们现在已经有了
具备自动驾驶功能的原型车，

00:01:29.412 --> 00:01:33.265
但是如果没有敏锐的视觉，
它们就不能真正区分出

00:01:33.265 --> 00:01:37.235
地上摆着的是一个压扁的纸袋，
可以被轻易压过，

00:01:37.235 --> 00:01:40.575
还是一块相同体积的石头，
应该避开。

00:01:41.415 --> 00:01:44.805
我们已经造出了超高清的相机，

00:01:44.805 --> 00:01:47.940
但我们仍然无法把
这些画面传递给盲人。

00:01:48.420 --> 00:01:51.725
我们的无人机可以飞跃广阔的土地，

00:01:51.725 --> 00:01:53.589
却没有足够的视觉技术

00:01:53.589 --> 00:01:57.320
去帮我们追踪热带雨林的变化。

00:01:57.320 --> 00:02:00.270
安全摄像头到处都是，

00:02:00.270 --> 00:02:05.337
但当有孩子在泳池里溺水时
它们无法向我们报警。

00:02:06.167 --> 00:02:11.762
照片和视频，已经成为
全人类生活里不可缺少的部分。

00:02:11.762 --> 00:02:16.119
它们以极快的速度被创造出来，
以至于没有任何人，或者团体，

00:02:16.119 --> 00:02:18.632
能够完全浏览这些内容，

00:02:18.632 --> 00:02:22.553
而你我正参与其中的这场TED，
也为之添砖加瓦。

00:02:22.553 --> 00:02:27.785
直到现在，我们最先进的
软件也依然为之犯难：

00:02:27.785 --> 00:02:31.661
该怎么理解和处理
这些数量庞大的内容？

00:02:31.661 --> 00:02:36.123
所以换句话说，
在作为集体的这个社会里，

00:02:36.123 --> 00:02:42.159
我们依然非常茫然，因为我们最智能的机器
依然有视觉上的缺陷。

00:02:43.526 --> 00:02:46.192
”为什么这么困难？“你也许会问。

00:02:46.192 --> 00:02:49.015
照相机可以像这样获得照片：

00:02:49.015 --> 00:02:52.880
它把采集到的光线转换成
二维数字矩阵来存储

00:02:52.880 --> 00:02:54.365
——也就是“像素”，

00:02:54.365 --> 00:02:57.040
但这些仍然是死板的数字。

00:02:57.040 --> 00:03:00.151
它们自身并不携带任何意义。

00:03:00.151 --> 00:03:04.494
就像”听到“和”听“完全不同，

00:03:04.494 --> 00:03:08.534
”拍照“和”看“也完全不同。

00:03:08.534 --> 00:03:12.363
通过“看”，
我们实际上是“理解”了这个画面。

00:03:13.293 --> 00:03:19.470
事实上，大自然经过了5亿4千万年的努力

00:03:19.470 --> 00:03:21.443
才完成了这个工作，

00:03:21.443 --> 00:03:23.324
而这努力中更多的部分

00:03:23.324 --> 00:03:28.595
是用在进化我们的大脑内
用于视觉处理的器官，

00:03:28.595 --> 00:03:31.242
而不是眼睛本身。

00:03:31.242 --> 00:03:33.989
所以"视觉”从眼睛采集信息开始，

00:03:33.989 --> 00:03:37.507
但大脑才是它真正呈现意义的地方。

00:03:38.287 --> 00:03:43.347
所以15年来，
从我进入加州理工学院攻读Ph.D.

00:03:43.347 --> 00:03:46.273
到后来领导
斯坦福大学的视觉实验室，

00:03:46.273 --> 00:03:50.669
我一直在和我的导师、
合作者和学生们一起

00:03:50.669 --> 00:03:53.558
教计算机如何去“看”。

00:03:54.338 --> 00:03:57.952
我们的研究领域叫做
"计算机视觉与机器学习"。

00:03:57.952 --> 00:04:01.830
这是AI（人工智能）领域的一个分支。

00:04:03.000 --> 00:04:08.493
最终，我们希望能教会机器
像我们一样看见事物：

00:04:08.493 --> 00:04:13.880
识别物品、辨别不同的人、
推断物体的立体形状、

00:04:13.880 --> 00:04:19.568
理解事物的关联、
人的情绪、动作和意图。

00:04:19.568 --> 00:04:27.961
像你我一样，只凝视一个画面一眼
就能理清整个故事中的人物、地点、事件。

00:04:28.955 --> 00:04:34.538
实现这一目标的第一步是
教计算机看到“对象”（物品），

00:04:34.538 --> 00:04:37.906
这是建造视觉世界的基石。

00:04:37.906 --> 00:04:42.340
在这个最简单的任务里，
想象一下这个教学过程：

00:04:42.340 --> 00:04:48.575
给计算机看一些特定物品的训练图片，
比如说猫，

00:04:48.656 --> 00:04:53.393
并让它从这些训练图片中，
学习建立出一个模型来。

00:04:53.393 --> 00:04:55.237
这有多难呢？

00:04:55.237 --> 00:04:59.489
不管怎么说，一只猫只是一些
形状和颜色拼凑起来的图案罢了，

00:04:59.489 --> 00:05:03.575
比如这个就是我们
最初设计的抽象模型。

00:05:03.575 --> 00:05:07.197
我们用数学的语言，
告诉计算机这种算法：

00:05:07.197 --> 00:05:10.540
“猫”有着圆脸、胖身子、

00:05:10.540 --> 00:05:12.839
两个尖尖的耳朵，还有一条长尾巴，

00:05:12.839 --> 00:05:14.249
这（算法）看上去挺好的。

00:05:14.719 --> 00:05:16.592
但如果遇到这样的猫呢？

00:05:16.592 --> 00:05:17.663
（笑）

00:05:17.663 --> 00:05:19.409
它整个蜷缩起来了。

00:05:19.409 --> 00:05:24.408
现在你不得不加入一些别的形状和视角
来描述这个物品模型。

00:05:24.408 --> 00:05:26.443
但如果猫是藏起来的呢？

00:05:27.143 --> 00:05:29.732
再看看这些傻猫呢？

00:05:31.112 --> 00:05:33.529
你现在知道了吧。

00:05:33.529 --> 00:05:36.896
即使那些事物简单到
只是一只家养的宠物，

00:05:36.896 --> 00:05:41.260
都可以出呈现出无限种变化的外观模型，

00:05:41.260 --> 00:05:43.633
而这还只是“一个”对象的模型。

00:05:44.573 --> 00:05:47.065
所以大概在8年前，

00:05:47.065 --> 00:05:52.095
一个非常简单、有冲击力的
观察改变了我的想法。

00:05:53.425 --> 00:05:56.110
没有人教过婴儿怎么“看”，

00:05:56.110 --> 00:05:58.371
尤其是在他们还很小的时候。

00:05:58.371 --> 00:06:03.371
他们是从真实世界的经验
和例子中学到这个的。

00:06:03.371 --> 00:06:05.931
如果你把孩子的眼睛

00:06:05.931 --> 00:06:08.665
都看作是生物照相机，

00:06:08.665 --> 00:06:12.845
那他们每200毫秒就拍一张照。

00:06:12.845 --> 00:06:15.809
——这是眼球转动一次的平均时间。

00:06:15.809 --> 00:06:22.799
所以到3岁大的时候，一个孩子已经看过了
上亿张的真实世界照片。

00:06:23.093 --> 00:06:25.753
这种“训练照片”的数量是非常大的。

00:06:26.183 --> 00:06:32.172
所以，与其孤立地关注于
算法的优化、再优化，

00:06:32.172 --> 00:06:37.644
我的关注点放在了给算法
提供像那样的训练数据

00:06:37.644 --> 00:06:43.993
——那些，婴儿们从经验中获得的
质量和数量都极其惊人的训练照片。

00:06:44.841 --> 00:06:46.699
一旦我们知道了这个，

00:06:46.699 --> 00:06:49.670
我们就明白自己需要收集的数据集，

00:06:49.670 --> 00:06:54.129
必须比我们曾有过的任何数据库都丰富

00:06:54.129 --> 00:06:56.706
——可能要丰富数千倍。

00:06:56.706 --> 00:07:00.817
因此，通过与普林斯顿大学的
Kai Li教授合作，

00:07:00.817 --> 00:07:05.569
我们在2007年发起了
ImageNet（图片网络）计划。

00:07:05.569 --> 00:07:10.861
幸运的是，我们不必在自己脑子里
装上一台照相机，然后等它拍很多年。

00:07:10.861 --> 00:07:12.634
我们运用了互联网，

00:07:12.634 --> 00:07:17.070
这个由人类创造的
最大的图片宝库。

00:07:17.070 --> 00:07:20.111
我们下载了接近10亿张图片

00:07:20.111 --> 00:07:25.991
并利用众包技术（利用互联网分配工作、发现创意或
解决技术问题），像“亚马逊土耳其机器人”这样的平台

00:07:25.991 --> 00:07:28.330
来帮我们标记这些图片。

00:07:28.330 --> 00:07:36.040
在高峰期时，ImageNet是「亚马逊土耳其机器人」
这个平台上最大的雇主之一：

00:07:36.076 --> 00:07:43.880
来自世界上167个国家的
接近5万个工作者，在一起工作

00:07:43.880 --> 00:07:52.007
帮我们筛选、排序、标记了
接近10亿张备选照片。

00:07:52.212 --> 00:07:55.265
这就是我们为这个计划投入的精力，

00:07:55.265 --> 00:08:03.275
去捕捉，一个婴儿可能在他早期发育阶段
获取的”一小部分“图像。

00:08:03.718 --> 00:08:12.250
事后我们再来看，这个利用大数据来训练
计算机算法的思路，也许现在看起来很普通，

00:08:12.250 --> 00:08:16.450
但回到2007年时，它就不那么寻常了。

00:08:16.450 --> 00:08:20.248
我们在这段旅程上孤独地前行了很久。

00:08:20.248 --> 00:08:25.591
一些很友善的同事建议我
做一些更有用的事来获得终身教职，

00:08:25.591 --> 00:08:29.933
而且我们也不断地为项目的研究经费发愁。

00:08:29.933 --> 00:08:32.418
有一次，我甚至对
我的研究生学生开玩笑说：

00:08:32.418 --> 00:08:36.481
我要重新回去开我的干洗店
来赚钱资助ImageNet了。

00:08:36.481 --> 00:08:40.842
——毕竟，我的大学时光
就是靠这个资助的。

00:08:40.842 --> 00:08:42.768
所以我们仍然在继续着。

00:08:42.768 --> 00:08:46.813
在2009年，ImageNet项目诞生了——

00:08:46.813 --> 00:08:55.555
一个含有1500万张照片的数据库，
涵盖了22000种物品。

00:08:55.565 --> 00:08:58.860
这些物品是根据日常英语单词
进行分类组织的。

00:08:58.860 --> 00:09:01.756
无论是在质量上还是数量上，

00:09:01.756 --> 00:09:05.458
这都是一个规模空前的数据库。

00:09:05.458 --> 00:09:08.339
举个例子，在"猫"这个对象中，

00:09:08.339 --> 00:09:11.148
我们有超过62000只猫

00:09:11.148 --> 00:09:15.258
长相各异，姿势五花八门，

00:09:15.258 --> 00:09:20.301
而且涵盖了各种品种的家猫和野猫。

00:09:20.301 --> 00:09:23.825
我们对ImageNet收集到的图片
感到异常兴奋，

00:09:23.825 --> 00:09:27.303
而且我们希望整个研究界能从中受益，

00:09:27.303 --> 00:09:28.984
所以以一种和TED一样的方式，

00:09:28.984 --> 00:09:35.196
我们公开了整个数据库，
免费提供给全世界的研究团体。

00:09:35.336 --> 00:09:40.146
（掌声）

00:09:41.226 --> 00:09:45.584
那么现在，我们有了用来
培育计算机大脑的数据库，

00:09:45.584 --> 00:09:49.321
我们可以回到”算法“本身上来了。

00:09:49.321 --> 00:09:59.469
因为ImageNet的横空出世，它提供的信息财富
完美地适用于一些特定类别的机器学习算法，

00:09:59.535 --> 00:10:02.090
称作“卷积神经网络”，

00:10:02.090 --> 00:10:10.608
最早由Kunihiko Fukushima，Geoff Hinton，
和Yann LeCun在上世纪七八十年代开创。

00:10:10.608 --> 00:10:16.602
就像大脑是由上十亿的
紧密联结的神经元组成，

00:10:16.602 --> 00:10:22.856
神经网络里最基础的运算单元
也是一个“神经元式”的节点。

00:10:22.876 --> 00:10:27.905
每个节点从其它节点处获取输入信息，
然后把自己的输出信息再交给另外的节点。

00:10:27.905 --> 00:10:32.856
此外，这些成千上万、甚至上百万的节点

00:10:32.856 --> 00:10:35.923
都被按等级分布于不同层次，

00:10:35.923 --> 00:10:38.367
就像大脑一样。

00:10:38.367 --> 00:10:43.420
在一个我们用来训练“对象识别模型”的
典型神经网络里，

00:10:43.420 --> 00:10:52.301
有着2400万个节点，1亿4千万个参数，
和150亿个联结。

00:10:52.301 --> 00:10:55.076
这是一个庞大的模型。

00:10:55.076 --> 00:10:58.767
借助ImageNet提供的巨大规模数据支持，

00:10:58.767 --> 00:11:04.350
通过大量最先进的CPU和GPU，
来训练这些堆积如山的模型，

00:11:04.350 --> 00:11:09.949
“卷积神经网络”
以难以想象的方式蓬勃发展起来。

00:11:09.949 --> 00:11:12.723
它成为了一个成功体系，

00:11:12.723 --> 00:11:18.063
在对象识别领域，
产生了激动人心的新成果。

00:11:18.063 --> 00:11:20.873
这张图，是计算机在告诉我们：

00:11:20.873 --> 00:11:23.173
照片里有一只猫、

00:11:23.173 --> 00:11:24.816
还有猫所在的位置。

00:11:24.816 --> 00:11:27.008
当然不止有猫了，

00:11:27.008 --> 00:11:29.446
所以这是计算机算法在告诉我们

00:11:29.446 --> 00:11:32.660
照片里有一个男孩，和一个泰迪熊；

00:11:32.660 --> 00:11:36.966
一只狗，一个人，和背景里的小风筝；

00:11:36.966 --> 00:11:44.815
或者是一张拍摄于闹市的照片
比如人、滑板、栏杆、灯柱…等等。

00:11:44.815 --> 00:11:50.338
有时候，如果计算机
不是很确定它看到的是什么，

00:11:51.498 --> 00:11:57.454
我们还教它用足够聪明的方式
给出一个“安全”的答案，而不是“言多必失”

00:11:57.454 --> 00:12:00.456
——就像人类面对这类问题时一样。

00:12:00.456 --> 00:12:05.138
但在其他时候，我们的计算机
算法厉害到可以告诉我们

00:12:05.138 --> 00:12:10.830
关于对象的更确切的信息，
比如汽车的品牌、型号、年份。

00:12:10.830 --> 00:12:16.204
我们在上百万张谷歌街景照片中
应用了这一算法，

00:12:16.204 --> 00:12:19.019
那些照片涵盖了上百个美国城市。

00:12:19.019 --> 00:12:22.135
我们从中发现一些有趣的事：

00:12:22.135 --> 00:12:25.585
首先，它证实了我们的一些常识：

00:12:25.585 --> 00:12:31.040
汽车的价格，与家庭收入
呈现出明显的正相关。

00:12:31.040 --> 00:12:37.907
但令人惊奇的是，汽车价格与犯罪率
也呈现出明显的正相关性，

00:12:37.927 --> 00:12:43.640
以上结论是基于城市、或投票的
邮编区域进行分析的结果。

00:12:43.640 --> 00:12:45.946
那么等一下，这就是全部成果了吗？

00:12:45.946 --> 00:12:51.419
计算机是不是已经达到，
或者甚至超过了人类的能力？

00:12:51.419 --> 00:12:53.337
——还没有那么快。

00:12:53.337 --> 00:12:58.480
目前为止，我们还只是
教会了计算机去看对象。

00:12:58.480 --> 00:13:02.874
这就像是一个小宝宝学会说出几个名词。

00:13:02.874 --> 00:13:05.624
这是一项难以置信的成就，

00:13:05.624 --> 00:13:08.084
但这还只是第一步。

00:13:08.084 --> 00:13:11.876
很快，我们就会到达
发展历程的另一个里程碑：

00:13:11.876 --> 00:13:15.477
这个小孩会开始用“句子”进行交流。

00:13:15.477 --> 00:13:19.701
所以不止是说这张图里有只“猫”，

00:13:19.701 --> 00:13:24.903
你在开头已经听到小妹妹
告诉我们“这只猫是坐在床上的”。

00:13:24.903 --> 00:13:30.498
为了教计算机看懂图片并生成句子，

00:13:30.498 --> 00:13:36.176
“大数据”和“机器学习算法”的结合
需要更进一步。

00:13:36.361 --> 00:13:46.285
现在，计算机需要从图片和人类创造的
自然语言句子中同时进行学习。

00:13:46.685 --> 00:13:50.908
就像我们的大脑，
把视觉现象和语言融合在一起，

00:13:50.908 --> 00:13:52.779
我们开发了一个模型，

00:13:52.779 --> 00:14:02.893
可以把一部分视觉信息，像视觉片段，
与语句中的文字、短语联系起来。

00:14:02.893 --> 00:14:07.376
大约4个月前，
我们最终把所有技术结合在了一起，

00:14:07.376 --> 00:14:11.410
创造了第一个“计算机视觉模型”，

00:14:11.410 --> 00:14:18.844
它在看到图片的第一时间，就有能力生成
类似人类语言的句子。

00:14:18.844 --> 00:14:25.149
现在，我准备给你们看看
计算机看到图片时会说些什么

00:14:25.149 --> 00:14:28.919
——还是那些在演讲开头给小女孩看的图片。

00:14:30.789 --> 00:14:34.383
（视频）计算机：
“一个男人站在一头大象旁边。”

00:14:36.243 --> 00:14:40.027
“一架大飞机停在机场跑道一端。”

00:14:41.057 --> 00:14:45.269
李飞飞：
当然，我们还在努力改善我们的算法，

00:14:45.269 --> 00:14:47.415
它还有很多要学的东西。

00:14:47.415 --> 00:14:50.886
（掌声）

00:14:51.266 --> 00:14:54.497
计算机还是会犯很多错误的。

00:14:54.497 --> 00:14:57.968
（视频）计算机：
“一只猫躺在床上的毯子上。”

00:14:57.968 --> 00:15:03.981
李飞飞：所以…当然——如果它看过太多种的猫，
它就会觉得什么东西都长得像猫……

00:15:04.997 --> 00:15:08.181
（视频）计算机：
“一个小男孩拿着一根棒球棍。”

00:15:08.181 --> 00:15:09.566
（笑声）

00:15:09.566 --> 00:15:14.669
李飞飞：或者…如果它从没见过牙刷，
它就分不清牙刷和棒球棍的区别。

00:15:15.049 --> 00:15:18.743
（视频）计算机：
“建筑旁的街道上有一个男人骑马经过。”

00:15:18.743 --> 00:15:20.336
（笑声）

00:15:20.336 --> 00:15:24.448
李飞飞：我们还没教它Art 101
（美国大学艺术基础课）。

00:15:25.138 --> 00:15:28.442
（视频）计算机：
“一只斑马站在一片草原上。”

00:15:28.442 --> 00:15:33.629
李飞飞：它还没学会像你我一样
欣赏大自然里的绝美景色。

00:15:34.137 --> 00:15:37.079
所以，这是一条漫长的道路。

00:15:37.079 --> 00:15:41.205
将一个孩子从出生培养到3岁是很辛苦的。

00:15:41.205 --> 00:15:46.891
而真正的挑战是从3岁到13岁的过程中，
而且远远不止于此。

00:15:46.891 --> 00:15:51.046
让我再给你们看看这张
关于小男孩和蛋糕的图。

00:15:51.046 --> 00:15:55.540
目前为止，
我们已经教会计算机“看”对象，

00:15:55.540 --> 00:15:59.858
或者甚至基于图片，
告诉我们一个简单的故事。

00:15:59.858 --> 00:16:03.324
（视频）计算机：
”一个人坐在放蛋糕的桌子旁。“

00:16:03.324 --> 00:16:08.334
李飞飞：但图片里还有更多信息
——远不止一个人和一个蛋糕。

00:16:08.334 --> 00:16:12.751
计算机无法理解的是：
这是一个特殊的意大利蛋糕，

00:16:12.751 --> 00:16:15.988
它只在复活节限时供应。

00:16:15.988 --> 00:16:19.033
而这个男孩穿着的
是他最喜欢的T恤衫，

00:16:19.033 --> 00:16:23.163
那是他父亲去悉尼旅行时
带给他的礼物。

00:16:23.163 --> 00:16:30.061
另外，你和我都能清楚地看出，
这个小孩有多高兴，以及这一刻在想什么。

00:16:30.864 --> 00:16:33.809
这是我的儿子Leo。

00:16:33.809 --> 00:16:36.643
在我探索视觉智能的道路上，

00:16:36.643 --> 00:16:41.777
我不断地想到Leo
和他未来将要生活的那个世界。

00:16:41.777 --> 00:16:44.068
当机器可以“看到”的时候，

00:16:44.068 --> 00:16:48.670
医生和护士会获得一双额外的、
不知疲倦的眼睛，

00:16:48.670 --> 00:16:53.082
帮他们诊断病情、照顾病人。

00:16:53.082 --> 00:16:57.235
汽车可以在道路上行驶得
更智能、更安全。

00:16:57.235 --> 00:16:59.989
机器人，而不只是人类，

00:16:59.989 --> 00:17:05.008
会帮我们救助灾区被困和受伤的人员。

00:17:05.408 --> 00:17:09.314
我们会发现新的物种、更好的材料，

00:17:09.314 --> 00:17:14.223
还可以在机器的帮助下
探索从未见到过的前沿地带。

00:17:14.903 --> 00:17:19.150
一点一点地，
我们正在赋予机器以视力。

00:17:19.150 --> 00:17:21.728
首先，我们教它们去“看”。

00:17:21.728 --> 00:17:24.841
然后，它们反过来也帮助我们，
让我们看得更清楚。

00:17:24.841 --> 00:17:31.806
这是第一次，人类的眼睛不再
独自地思考和探索我们的世界。

00:17:31.820 --> 00:17:35.190
我们将不止是“使用”机器的智力，

00:17:35.190 --> 00:17:41.239
我们还要以一种从未想象过的方式，
与它们“合作”。

00:17:41.239 --> 00:17:43.510
我所追求的是：

00:17:43.510 --> 00:17:46.252
赋予计算机视觉智能，

00:17:46.252 --> 00:17:51.033
并为Leo和这个世界，
创造出更美好的未来。

00:17:51.293 --> 00:17:52.724
谢谢。

00:17:52.724 --> 00:17:57.179
（掌声）

