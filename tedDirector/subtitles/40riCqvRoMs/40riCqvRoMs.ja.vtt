WEBVTT
Kind: captions
Language: ja

00:00:00.000 --> 00:00:07.000
翻訳: Yasushi Aoki
校正: Tadashi Koyama

00:00:14.366 --> 00:00:18.104
まずこのビデオを
ご覧ください

00:00:18.104 --> 00:00:22.260
(女の子の声) ネコがベッドに座ってる

00:00:22.260 --> 00:00:26.300
男の子が象をなでてる

00:00:26.300 --> 00:00:30.234
飛行機へ行く人たち

00:00:30.234 --> 00:00:33.284
大きな飛行機よ

00:00:33.284 --> 00:00:35.670
(講演者) これは３歳児が

00:00:35.670 --> 00:00:39.349
見た写真を
説明しているところです

00:00:39.349 --> 00:00:42.644
彼女にはこの世界で学ぶことが 
まだまだあるかもしれませんが

00:00:42.644 --> 00:00:46.743
ひとつの重要な作業については
すでにエキスパートです

00:00:46.743 --> 00:00:49.589
見たものを理解する
ということです

00:00:50.229 --> 00:00:54.455
私たちの社会は技術的に
かつてなく進歩しています

00:00:54.455 --> 00:00:58.084
月へと人を送り込み 
人に話しかける電話を作り

00:00:58.084 --> 00:01:03.030
自分の好きな曲だけがかかるように
ラジオをカスタマイズしています

00:01:03.030 --> 00:01:07.085
しかしながら最先端の
コンピュータでも

00:01:07.085 --> 00:01:09.988
まだこの作業には
手こずっているんです

00:01:09.988 --> 00:01:13.447
私は今日コンピュータビジョンの

00:01:13.447 --> 00:01:17.494
最新動向について
お伝えするために来ました

00:01:17.494 --> 00:01:21.655
これはコンピュータサイエンスの中でも
先端にあって

00:01:21.655 --> 00:01:24.861
画期的なものになる
可能性のある技術です

00:01:24.861 --> 00:01:29.412
自分で運転する車の
プロトタイプが作られていますが

00:01:29.412 --> 00:01:33.265
知的な視覚処理能力がなかったら

00:01:33.265 --> 00:01:37.235
踏みつぶしても問題のない
道路上の丸めた紙袋と

00:01:37.235 --> 00:01:40.855
避けて通るべき同じ大きさの石とを
見分けることもできません

00:01:41.415 --> 00:01:44.805
すごいメガピクセルの
カメラが作られていますが

00:01:44.805 --> 00:01:48.300
盲目の人に視力を与えることは
できていません

00:01:48.420 --> 00:01:51.725
無人機を広大な土地の上に
飛ばすことはできても

00:01:51.725 --> 00:01:54.789
熱帯雨林の変化を
追跡できるだけの

00:01:54.789 --> 00:01:57.320
画像技術はまだありません

00:01:57.320 --> 00:02:00.270
監視カメラが至る所に
設置されていますが

00:02:00.270 --> 00:02:05.337
プールで溺れている子がいても
警告してはくれません

00:02:06.167 --> 00:02:11.552
写真やビデオは世界において
生活に不可欠な一部をなしています

00:02:11.552 --> 00:02:15.849
どんな個人であれ チームであれ
見切れないほどのペースで

00:02:15.849 --> 00:02:18.632
映像が量産されています

00:02:18.632 --> 00:02:22.553
そして私たちも ここTEDで
それに貢献しています

00:02:22.553 --> 00:02:25.725
しかし最も進んだ
ソフトウェアでさえ

00:02:25.725 --> 00:02:31.661
この膨大な映像を理解し管理するのに
手こずっています

00:02:31.661 --> 00:02:33.553
言ってみれば

00:02:33.553 --> 00:02:36.959
私たちの社会は
集合的に盲目であり

00:02:36.959 --> 00:02:42.066
それは最も知的な機械が
いまだ盲目だからです

00:02:43.336 --> 00:02:46.452
なぜそんなに難しいのかと
思うかもしれません

00:02:46.452 --> 00:02:49.005
カメラはこのような写真を撮って

00:02:49.005 --> 00:02:51.219
光をピクセルと呼ばれる

00:02:51.219 --> 00:02:54.789
数字の２次元配列へと
変換しますが

00:02:54.789 --> 00:02:57.040
これは死んだ数字の列に
過ぎません

00:02:57.040 --> 00:02:59.981
数字自体に意味はありません

00:02:59.981 --> 00:03:04.494
単に音が耳に入ってくるのと
「聴く」のとは違うように

00:03:04.494 --> 00:03:08.534
「写真を撮る」のと「見る」のとは
同じではありません

00:03:08.534 --> 00:03:12.363
「見る」ということには
理解することが含まれているのです

00:03:13.293 --> 00:03:16.150
実際この仕事を
成し遂げられるようにするために

00:03:16.150 --> 00:03:21.443
母なる自然は 5億4千万年という
長い歳月を必要としたのです

00:03:21.443 --> 00:03:23.324
そしてその努力の多くは

00:03:23.324 --> 00:03:26.255
目そのものではなく

00:03:26.255 --> 00:03:31.242
脳の視覚処理能力を発達させるために
費やされました

00:03:31.242 --> 00:03:33.989
視覚というのは
目から始まりますが

00:03:33.989 --> 00:03:37.507
それが本当に起きているのは
脳の中なのです

00:03:38.287 --> 00:03:42.527
これまで15年間 
カリフォルニア工科大学の博士課程の頃から

00:03:42.527 --> 00:03:46.463
スタンフォード大でコンピュータビジョン研究室を
率いている今に到るまで

00:03:46.463 --> 00:03:50.669
私は指導教官や共同研究者や
学生達とともに

00:03:50.669 --> 00:03:53.758
コンピュータに見ることを
教えようとしてきました

00:03:54.658 --> 00:03:57.952
私たちの研究領域は
コンピュータビジョンと機械学習で

00:03:57.952 --> 00:04:01.830
これは人工知能の分野の一部です

00:04:03.000 --> 00:04:08.493
最終的に私たちがしたいのは 
機械も人間のようにものを見られるようにすることです

00:04:08.493 --> 00:04:13.880
物が何か言い当て 人を識別し 
３次元的な配置を推量し

00:04:13.880 --> 00:04:19.568
関係や感情や行動や意図を
理解するということです

00:04:19.568 --> 00:04:22.571
私たち人間は一目見ただけで

00:04:22.571 --> 00:04:27.885
人 場所 物の織りなす物語全体を
捉えることができます

00:04:28.954 --> 00:04:31.738
この目標に向けた第一歩は

00:04:31.738 --> 00:04:37.906
コンピュータに視覚世界の構成要素である物を
見られるようにすることです

00:04:37.906 --> 00:04:39.860
簡単に言うと

00:04:39.860 --> 00:04:42.705
ネコのような特定の物の

00:04:42.705 --> 00:04:48.756
訓練用画像を
コンピュータに与えて

00:04:48.756 --> 00:04:53.393
それらの画像から学習する
モデルを設計するんです

00:04:53.393 --> 00:04:55.437
簡単そうに聞こえますよね？

00:04:55.437 --> 00:04:59.489
ネコの画像は色と形の
集まりに過ぎません

00:04:59.489 --> 00:05:03.575
これは初期のオブジェクト・モデリングで
私たちがやっていたことでした

00:05:03.575 --> 00:05:07.197
数学的な言語を使って
コンピュータアルゴリズムに

00:05:07.197 --> 00:05:10.540
ネコには 丸い顔と
ぽっちゃりした体と

00:05:10.540 --> 00:05:12.839
２つのとがった耳と
長いしっぽがあると教え

00:05:12.839 --> 00:05:14.429
それでうまくいきそうでした

00:05:14.859 --> 00:05:16.972
でもこのネコはどうでしょう？

00:05:16.972 --> 00:05:18.063
(笑)

00:05:18.063 --> 00:05:19.689
体がすっかり反り返っています

00:05:19.689 --> 00:05:24.408
オブジェクトモデルに新しい形と視点を
追加する必要があります

00:05:24.408 --> 00:05:26.383
でもネコが一部隠れていたら
どうでしょう？

00:05:27.143 --> 00:05:29.362
このおかしなネコたちはどうでしょう？

00:05:31.112 --> 00:05:33.529
言いたいこと分かりますよね？

00:05:33.529 --> 00:05:36.896
身近なペットのネコという
シンプルなものでさえ

00:05:36.896 --> 00:05:41.060
オブジェクトモデルに
無数のバリエーションを定義する必要があり

00:05:41.060 --> 00:05:43.863
しかもこれは沢山あるものの
１つに過ぎないんです

00:05:44.573 --> 00:05:47.065
８年ほど前

00:05:47.065 --> 00:05:52.095
とてもシンプルながら本質的なある観察が
私の考え方を変えました

00:05:53.425 --> 00:05:55.820
子供は教えられなくても

00:05:55.820 --> 00:05:58.711
成長の初期に
ものの見方を身に付けるということです

00:05:58.711 --> 00:06:03.371
子供は現実の世界における
経験と例を通して学ぶのです

00:06:03.371 --> 00:06:05.831
子供の目が
生きたカメラで

00:06:05.831 --> 00:06:08.665
200ミリ秒ごとに１枚

00:06:08.665 --> 00:06:12.845
写真を撮っていると
考えてみましょう

00:06:12.845 --> 00:06:15.979
これは目が動く
平均時間です

00:06:15.979 --> 00:06:19.509
すると子供は３歳になるまでに 
何億枚という

00:06:19.509 --> 00:06:23.143
現実世界の写真を
見ていることになります

00:06:23.143 --> 00:06:25.643
膨大な量の訓練例です

00:06:26.383 --> 00:06:32.372
それで気が付いたのは 
アルゴリズムの改良ばかりに集中するのではなく

00:06:32.372 --> 00:06:37.644
子供が経験を通じて
受け取るような

00:06:37.644 --> 00:06:40.963
量と質の訓練データを

00:06:40.963 --> 00:06:44.841
アルゴリズムに与えてはどうか
ということでした

00:06:44.841 --> 00:06:46.699
このことに気付いた時

00:06:46.699 --> 00:06:49.670
私たちが持っているよりも
遙かに多くの画像データを

00:06:49.670 --> 00:06:54.129
集めなければならないことが
明らかでした

00:06:54.129 --> 00:06:56.706
何千倍も必要です

00:06:56.706 --> 00:07:00.817
それで私はプリンストン大学の
カイ・リー教授と一緒に

00:07:00.817 --> 00:07:05.569
2007年にImageNetプロジェクトを
立ち上げました

00:07:05.569 --> 00:07:09.067
幸い私たちは
頭にカメラを付けて

00:07:09.067 --> 00:07:11.171
何年も歩き回る必要は
ありませんでした

00:07:11.171 --> 00:07:14.334
人類がかつて作った
最大の画像の宝庫

00:07:14.334 --> 00:07:17.070
インターネットに
向かったのです

00:07:17.070 --> 00:07:20.111
私たちは10億枚近い画像を
ダウンロードし

00:07:20.111 --> 00:07:25.991
アマゾン・メカニカル・タークのような
クラウドソーシング技術を使って

00:07:25.991 --> 00:07:28.330
それらの画像に
ラベル付けをしました

00:07:28.330 --> 00:07:33.230
最盛期にはImageNetは
アマゾン・メカニカル・ターク作業者の

00:07:33.230 --> 00:07:36.226
最大の雇用者の１つに
なっていました

00:07:36.226 --> 00:07:40.080
167カ国の

00:07:40.080 --> 00:07:44.120
５万人近い作業者が

00:07:44.120 --> 00:07:48.067
10億枚近い画像を
整理しラベル付けする作業に

00:07:48.067 --> 00:07:51.642
携わりました

00:07:52.612 --> 00:07:55.265
子供がその成長の初期に
受け取るのに

00:07:55.265 --> 00:07:59.165
匹敵する量の画像を
用意するためには

00:07:59.165 --> 00:08:03.336
それほどの労力が
必要だったのです

00:08:04.148 --> 00:08:08.050
コンピュータアルゴリズムの訓練に
ビッグデータを使うというアイデアは

00:08:08.050 --> 00:08:12.600
今からすると
自明なものに見えるでしょうが

00:08:12.600 --> 00:08:16.710
2007年当時は
そうではありませんでした

00:08:16.710 --> 00:08:20.588
かなり長い間 こんなことをやっている人は
私たち以外にいませんでした

00:08:20.588 --> 00:08:25.871
親切な同僚が将来の職のためにもう少し有用なことを
した方がいいとアドバイスしてくれたくらいです

00:08:25.871 --> 00:08:29.793
研究資金には
いつも困っていました

00:08:29.793 --> 00:08:33.818
ImageNetの資金調達のために
クリーニング屋をまた開こうかしらと

00:08:33.818 --> 00:08:36.481
学生に冗談で言ったくらいです

00:08:36.481 --> 00:08:41.032
私が学生の頃 学費のために
やっていたことです

00:08:41.032 --> 00:08:43.098
私たちは進み続け

00:08:43.098 --> 00:08:46.813
2009年に
ImageNetプロジェクトは

00:08:46.813 --> 00:08:50.855
日常的な英語を使って
2万2千のカテゴリに分類した

00:08:50.855 --> 00:08:55.659
1500万枚の画像の
データベースを

00:08:55.659 --> 00:08:58.980
完成させました

00:08:58.980 --> 00:09:01.906
これは量という点でも
質という点でも

00:09:01.906 --> 00:09:04.878
かつてないスケールのものでした

00:09:04.878 --> 00:09:07.109
一例を挙げると

00:09:07.109 --> 00:09:11.148
ネコの画像は
6万2千点以上あって

00:09:11.148 --> 00:09:15.258
様々な見かけや
ポーズのネコがいて

00:09:15.258 --> 00:09:20.481
飼い猫から山猫まで
あらゆる種類を網羅しています

00:09:20.481 --> 00:09:23.825
私たちはImageNetが
できあがったことを喜び

00:09:23.825 --> 00:09:27.563
世界の研究者にも
その恩恵を受けて欲しいと思い

00:09:27.563 --> 00:09:31.604
TEDの流儀で
データセットをまるごと

00:09:31.604 --> 00:09:35.316
無償で世界の研究者コミュニティに
公開しました

00:09:35.316 --> 00:09:40.116
(拍手)

00:09:41.416 --> 00:09:45.954
こうしてコンピュータの脳を
育てるためのデータができ

00:09:45.954 --> 00:09:49.691
アルゴリズムに取り組む
用意が整いました

00:09:49.691 --> 00:09:54.869
それで分かったのは 
ImageNetが提供する豊かな情報に適した

00:09:54.869 --> 00:09:59.675
機械学習アルゴリズムがあることです

00:09:59.675 --> 00:10:02.090
畳み込みニューラルネットワークと言って

00:10:02.090 --> 00:10:07.338
福島邦彦 ジェフリー・ヒントン 
ヤン・ルカンといった人たちが

00:10:07.338 --> 00:10:10.983
1970年代から1980年代にかけて
開拓した領域です

00:10:10.983 --> 00:10:16.602
脳が何十億という高度に結合し合った
ニューロンからできているように

00:10:16.602 --> 00:10:20.456
ニューラルネットワークの
基本要素となっているのは

00:10:20.456 --> 00:10:22.871
ニューロンのようなノードです

00:10:22.871 --> 00:10:25.425
他のノードからの入力を受けて

00:10:25.425 --> 00:10:28.143
他のノードへ出力を渡します

00:10:28.143 --> 00:10:32.856
何十万 何百万という
このようなノードが

00:10:32.856 --> 00:10:35.753
これも脳と同様に

00:10:35.753 --> 00:10:38.637
階層的に組織化されています

00:10:38.637 --> 00:10:43.900
物を認識するモデルを訓練するために
私たちが通常使うニューラルネットワークには

00:10:43.900 --> 00:10:46.601
2千4百万のノード

00:10:46.601 --> 00:10:49.488
1億4千万のパラメータ

00:10:49.488 --> 00:10:52.461
150億の結合があります

00:10:52.461 --> 00:10:55.076
ものすごく大きなモデルです

00:10:55.076 --> 00:10:58.977
ImageNetの膨大なデータと

00:10:58.977 --> 00:11:04.410
現代のCPUやGPUの性能を使って
このような巨大なモデルを訓練することで

00:11:04.410 --> 00:11:06.779
畳み込みニューラルネットワークは

00:11:06.779 --> 00:11:10.215
誰も予想しなかったくらいに
大きく花開きました

00:11:10.215 --> 00:11:13.503
これは物の認識において
目覚ましい結果を出す

00:11:13.503 --> 00:11:18.063
大当たりのアーキテクチャとなっています

00:11:18.063 --> 00:11:20.873
ここではコンピュータが

00:11:20.873 --> 00:11:23.173
写真の中にネコがいることと

00:11:23.173 --> 00:11:25.076
その場所を示しています

00:11:25.076 --> 00:11:27.188
もちろんネコ以外のものも
認識できます

00:11:27.188 --> 00:11:29.626
こちらではコンピュータアルゴリズムが

00:11:29.626 --> 00:11:32.900
写真の中に男の子とテディベアが
写っていることを教えています

00:11:32.900 --> 00:11:37.266
犬と 人物と 後方に小さな凧が
あることを示しています

00:11:37.266 --> 00:11:40.401
とても沢山のものが
写った写真から

00:11:40.401 --> 00:11:45.045
男性 スケートボード 手すり 
街灯などを見分けています

00:11:45.045 --> 00:11:50.338
写っているものが何なのか コンピュータが
そんなに自信を持てない場合もあります [動物]

00:11:51.498 --> 00:11:53.774
コンピュータには
当て推量をするよりは

00:11:53.774 --> 00:11:57.652
確かなところを答えるよう
教えています

00:11:57.652 --> 00:12:00.463
ちょうど私たち自身がするように

00:12:00.463 --> 00:12:05.129
一方で何が写っているかについて
コンピュータアルゴリズムが

00:12:05.129 --> 00:12:07.382
驚くほど正確に
言い当てることもあります

00:12:07.382 --> 00:12:10.818
たとえば自動車の車種や
モデルや年式のような

00:12:10.818 --> 00:12:16.204
このアルゴリズムを
アメリカの数百都市の

00:12:16.204 --> 00:12:19.339
何百万という
Googleストリートビュー画像に適用した結果

00:12:19.339 --> 00:12:22.265
面白い発見がありました

00:12:22.265 --> 00:12:25.345
まず 車の値段は

00:12:25.345 --> 00:12:28.875
家計収入とよく相関しているという

00:12:28.875 --> 00:12:31.220
予想が裏付けられました

00:12:31.220 --> 00:12:34.737
でも驚いたことに 
車の値段は

00:12:34.737 --> 00:12:38.047
街の犯罪率とも
よく相関していたんです

00:12:38.827 --> 00:12:42.970
それはまた郵便番号区域ごとの
投票傾向とも相関しています

00:12:44.060 --> 00:12:46.266
それでは コンピュータは

00:12:46.266 --> 00:12:51.419
既に人間の能力に追いつき 
追い越しているのでしょうか？

00:12:51.419 --> 00:12:53.557
結論を急がないで

00:12:53.557 --> 00:12:58.480
これまでのところ 私たちは
コンピュータに物の見方を教えただけです

00:12:58.480 --> 00:13:03.124
小さな子供が名詞をいくつか
言えるようになったようなものです

00:13:03.124 --> 00:13:05.794
ものすごい成果ですが

00:13:05.794 --> 00:13:08.254
まだ第一歩にすぎず

00:13:08.254 --> 00:13:12.016
次の開発目標があります

00:13:12.016 --> 00:13:15.477
子供は文章でコミュニケーションを
するようになります

00:13:15.477 --> 00:13:19.701
だから写真を見て小さな女の子が
単にネコと言わずに

00:13:19.701 --> 00:13:24.903
ネコがベッドに座っていると
言うのを聞いたわけです

00:13:24.903 --> 00:13:30.498
コンピュータが写真を見て
文章を作れるよう教えるために

00:13:30.498 --> 00:13:34.446
このビッグデータと
機械学習の結びつきが

00:13:34.446 --> 00:13:36.721
新たなステップを
踏む必要があります

00:13:36.721 --> 00:13:40.877
コンピュータは
写真だけでなく

00:13:40.877 --> 00:13:43.733
人が発する自然言語の文章も

00:13:43.733 --> 00:13:47.055
学ぶ必要があります

00:13:47.055 --> 00:13:50.908
脳が視覚と言語を
結びつけるように

00:13:50.908 --> 00:13:56.109
画像の断片のような
視覚的なものの一部と

00:13:56.109 --> 00:14:00.073
文章の中の単語やフレーズを
繋ぎ合わせるモデルを

00:14:00.073 --> 00:14:02.216
私たちは開発しました

00:14:02.216 --> 00:14:04.979
４ヶ月ほど前

00:14:04.979 --> 00:14:07.626
ついに私たちは
すべてをまとめ

00:14:07.626 --> 00:14:10.940
初めて見た写真について

00:14:10.940 --> 00:14:15.404
人が書いたような
記述文を生成できる

00:14:15.404 --> 00:14:18.910
最初のコンピュータ・ビジョン・
モデルを作り上げました

00:14:18.910 --> 00:14:23.554
冒頭で小さな女の子が説明したのと
同じ写真を見て

00:14:23.554 --> 00:14:25.529
そのコンピュータが何と言ったか

00:14:25.529 --> 00:14:29.359
お見せしましょう

00:14:31.049 --> 00:14:34.863
「ゾウの横に立っている男」

00:14:36.393 --> 00:14:40.027
「空港の滑走路にいる大きな飛行機」

00:14:41.057 --> 00:14:45.269
私たちは今もアルゴリズムを改良しようと
熱心に取り組んでいて

00:14:45.269 --> 00:14:47.865
学ぶべきことは
まだまだあります

00:14:47.865 --> 00:14:50.156
(拍手)

00:14:51.556 --> 00:14:54.877
コンピュータは
まだ間違いを犯します

00:14:54.877 --> 00:14:58.268
「ベッドの上の毛布の中のネコ」

00:14:58.268 --> 00:15:00.821
ネコを沢山見過ぎたせいで

00:15:00.821 --> 00:15:03.747
何でもネコみたいに
見えるのかもしれません

00:15:05.317 --> 00:15:08.181
「野球バットを持つ小さな男の子」

00:15:08.181 --> 00:15:09.946
(笑)

00:15:09.946 --> 00:15:14.529
歯ブラシを見たことがないと 
野球バットと混同してしまいます

00:15:15.309 --> 00:15:18.743
「建物脇の道を馬に乗って行く男」

00:15:18.743 --> 00:15:20.766
(笑)

00:15:20.766 --> 00:15:24.318
美術はまだコンピュータに
教えていませんでした

00:15:25.768 --> 00:15:28.652
「草原に立つシマウマ」

00:15:28.652 --> 00:15:32.019
私たちのように
自然の美を慈しむことは

00:15:32.019 --> 00:15:34.457
まだ学んでいません

00:15:34.457 --> 00:15:37.289
長い道のりでした

00:15:37.289 --> 00:15:41.515
０歳から３歳まで行くのは
大変でした

00:15:41.515 --> 00:15:47.111
でも本当の挑戦は３歳から13歳 
さらにその先へと行くことです

00:15:47.111 --> 00:15:51.476
あの男の子とケーキの写真を
もう一度見てみましょう

00:15:51.476 --> 00:15:55.540
私たちはコンピュータに
物を識別することを教え

00:15:55.540 --> 00:15:59.998
写真を簡単に説明することさえ
教えました

00:15:59.998 --> 00:16:03.574
「ケーキのあるテーブルにつく人」

00:16:03.574 --> 00:16:06.204
しかしこの写真には
単に人とケーキというよりも

00:16:06.204 --> 00:16:08.474
遙かに多くのものがあります

00:16:08.474 --> 00:16:12.941
コンピュータが見なかったのは 
このケーキが特別なイタリアのケーキで

00:16:12.941 --> 00:16:16.158
イースターの時に
食べるものだということです

00:16:16.158 --> 00:16:19.363
男の子が着ているのは
お気に入りのTシャツで

00:16:19.363 --> 00:16:23.333
お父さんがシドニー旅行の
おみやげにくれたものだということ

00:16:23.333 --> 00:16:27.141
私たちはみんな 
この男の子がどんなに喜んでいるか

00:16:27.141 --> 00:16:30.344
何を思っているかが分かります

00:16:31.214 --> 00:16:34.339
これは息子のレオです

00:16:34.339 --> 00:16:36.963
視覚的な知性を
追い求める探求の中で

00:16:36.963 --> 00:16:39.354
私はいつもレオのことや

00:16:39.354 --> 00:16:42.257
レオが住むであろう
未来の世界のことを考えています

00:16:42.257 --> 00:16:44.278
機械に見ることが
できるようになれば

00:16:44.278 --> 00:16:48.990
医師や看護師は疲れを知らない
別の目を手に入れて

00:16:48.990 --> 00:16:53.082
患者の診断や世話に
役立てられるでしょう

00:16:53.082 --> 00:16:57.465
自動車は道路をより賢明に
安全に走行するようになるでしょう

00:16:57.465 --> 00:17:00.159
人間だけでなくロボットも

00:17:00.159 --> 00:17:05.008
災害地域に取り残され負傷した人々を救出する
手助けができるようになるでしょう

00:17:05.798 --> 00:17:10.164
私たちは機械の助けを借りて 
新種の生物やより優れた素材を発見し

00:17:10.164 --> 00:17:14.103
未だ見ぬフロンティアを
探検するようになるでしょう

00:17:15.113 --> 00:17:19.280
私たちは少しずつ機械に
視覚を与えています

00:17:19.280 --> 00:17:21.617
最初に私たちが
機械に見ることを教え

00:17:21.617 --> 00:17:25.358
それから機械が より良く見られるよう
私たちを助けてくれることでしょう

00:17:25.358 --> 00:17:29.006
歴史上初めて
人間以外の目が

00:17:29.006 --> 00:17:31.940
世界について考察し
探求するようになるのです

00:17:31.940 --> 00:17:35.400
私たちは機械の知性を
利用するだけでなく

00:17:35.400 --> 00:17:41.579
想像もできないような方法で
機械と人間が協力し合うようになるでしょう

00:17:41.579 --> 00:17:43.740
私が追い求めているのは

00:17:43.740 --> 00:17:46.452
コンピュータに視覚的な知性を与え

00:17:46.452 --> 00:17:51.583
レオや世界のために
より良い未来を作り出すということです

00:17:51.583 --> 00:17:53.394
ありがとうございました

00:17:53.394 --> 00:17:57.179
(拍手)

