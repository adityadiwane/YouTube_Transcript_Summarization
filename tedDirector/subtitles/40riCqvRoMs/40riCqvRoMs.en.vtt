WEBVTT
Kind: captions
Language: en

00:00:14.366 --> 00:00:18.104
Let me show you something.

00:00:18.104 --> 00:00:22.260
(Video) Girl: Okay, that's a cat
sitting in a bed.

00:00:22.260 --> 00:00:26.300
The boy is petting the elephant.

00:00:26.300 --> 00:00:30.654
Those are people
that are going on an airplane.

00:00:30.654 --> 00:00:33.464
That's a big airplane.

00:00:33.464 --> 00:00:35.670
Fei-Fei Li: This is
a three-year-old child

00:00:35.670 --> 00:00:39.349
describing what she sees
in a series of photos.

00:00:39.349 --> 00:00:42.194
She might still have a lot
to learn about this world,

00:00:42.194 --> 00:00:46.743
but she's already an expert
at one very important task:

00:00:46.743 --> 00:00:49.589
to make sense of what she sees.

00:00:50.229 --> 00:00:54.455
Our society is more
technologically advanced than ever.

00:00:54.455 --> 00:00:58.084
We send people to the moon,
we make phones that talk to us

00:00:58.084 --> 00:01:03.030
or customize radio stations
that can play only music we like.

00:01:03.030 --> 00:01:07.085
Yet, our most advanced
machines and computers

00:01:07.085 --> 00:01:09.988
still struggle at this task.

00:01:09.988 --> 00:01:13.447
So I'm here today
to give you a progress report

00:01:13.447 --> 00:01:17.494
on the latest advances
in our research in computer vision,

00:01:17.494 --> 00:01:21.655
one of the most frontier
and potentially revolutionary

00:01:21.655 --> 00:01:24.861
technologies in computer science.

00:01:24.861 --> 00:01:29.412
Yes, we have prototyped cars
that can drive by themselves,

00:01:29.412 --> 00:01:33.265
but without smart vision,
they cannot really tell the difference

00:01:33.265 --> 00:01:37.235
between a crumpled paper bag
on the road, which can be run over,

00:01:37.235 --> 00:01:40.575
and a rock that size,
which should be avoided.

00:01:41.415 --> 00:01:44.805
We have made fabulous megapixel cameras,

00:01:44.805 --> 00:01:47.940
but we have not delivered
sight to the blind.

00:01:48.420 --> 00:01:51.725
Drones can fly over massive land,

00:01:51.725 --> 00:01:53.859
but don't have enough vision technology

00:01:53.859 --> 00:01:57.320
to help us to track
the changes of the rainforests.

00:01:57.320 --> 00:02:00.270
Security cameras are everywhere,

00:02:00.270 --> 00:02:05.337
but they do not alert us when a child
is drowning in a swimming pool.

00:02:06.167 --> 00:02:11.762
Photos and videos are becoming
an integral part of global life.

00:02:11.762 --> 00:02:15.849
They're being generated at a pace
that's far beyond what any human,

00:02:15.849 --> 00:02:18.632
or teams of humans, could hope to view,

00:02:18.632 --> 00:02:22.553
and you and I are contributing
to that at this TED.

00:02:22.553 --> 00:02:27.785
Yet our most advanced software
is still struggling at understanding

00:02:27.785 --> 00:02:31.661
and managing this enormous content.

00:02:31.661 --> 00:02:36.933
So in other words,
collectively as a society,

00:02:36.933 --> 00:02:38.679
we're very much blind,

00:02:38.679 --> 00:02:42.066
because our smartest 
machines are still blind.

00:02:43.526 --> 00:02:46.452
"Why is this so hard?" you may ask.

00:02:46.452 --> 00:02:49.145
Cameras can take pictures like this one

00:02:49.145 --> 00:02:53.139
by converting lights into
a two-dimensional array of numbers

00:02:53.139 --> 00:02:54.789
known as pixels,

00:02:54.789 --> 00:02:57.040
but these are just lifeless numbers.

00:02:57.040 --> 00:03:00.151
They do not carry meaning in themselves.

00:03:00.151 --> 00:03:04.494
Just like to hear is not
the same as to listen,

00:03:04.494 --> 00:03:08.534
to take pictures is not
the same as to see,

00:03:08.534 --> 00:03:12.363
and by seeing,
we really mean understanding.

00:03:13.293 --> 00:03:19.470
In fact, it took Mother Nature
540 million years of hard work

00:03:19.470 --> 00:03:21.443
to do this task,

00:03:21.443 --> 00:03:23.324
and much of that effort

00:03:23.324 --> 00:03:28.595
went into developing the visual
processing apparatus of our brains,

00:03:28.595 --> 00:03:31.242
not the eyes themselves.

00:03:31.242 --> 00:03:33.989
So vision begins with the eyes,

00:03:33.989 --> 00:03:37.507
but it truly takes place in the brain.

00:03:38.287 --> 00:03:43.347
So for 15 years now, starting
from my Ph.D. at Caltech

00:03:43.347 --> 00:03:46.273
and then leading Stanford's Vision Lab,

00:03:46.273 --> 00:03:50.669
I've been working with my mentors,
collaborators and students

00:03:50.669 --> 00:03:53.558
to teach computers to see.

00:03:54.658 --> 00:03:57.952
Our research field is called
computer vision and machine learning.

00:03:57.952 --> 00:04:01.830
It's part of the general field
of artificial intelligence.

00:04:03.000 --> 00:04:08.493
So ultimately, we want to teach
the machines to see just like we do:

00:04:08.493 --> 00:04:13.880
naming objects, identifying people,
inferring 3D geometry of things,

00:04:13.880 --> 00:04:19.568
understanding relations, emotions,
actions and intentions.

00:04:19.568 --> 00:04:25.721
You and I weave together entire stories
of people, places and things

00:04:25.721 --> 00:04:27.885
the moment we lay our gaze on them.

00:04:28.955 --> 00:04:34.538
The first step towards this goal
is to teach a computer to see objects,

00:04:34.538 --> 00:04:37.906
the building block of the visual world.

00:04:37.906 --> 00:04:42.340
In its simplest terms,
imagine this teaching process

00:04:42.340 --> 00:04:45.335
as showing the computers
some training images

00:04:45.335 --> 00:04:48.656
of a particular object, let's say cats,

00:04:48.656 --> 00:04:53.393
and designing a model that learns
from these training images.

00:04:53.393 --> 00:04:55.437
How hard can this be?

00:04:55.437 --> 00:04:59.489
After all, a cat is just
a collection of shapes and colors,

00:04:59.489 --> 00:05:03.575
and this is what we did
in the early days of object modeling.

00:05:03.575 --> 00:05:07.197
We'd tell the computer algorithm
in a mathematical language

00:05:07.197 --> 00:05:10.540
that a cat has a round face,
a chubby body,

00:05:10.540 --> 00:05:12.839
two pointy ears, and a long tail,

00:05:12.839 --> 00:05:14.249
and that looked all fine.

00:05:14.859 --> 00:05:16.972
But what about this cat?

00:05:16.972 --> 00:05:18.063
(Laughter)

00:05:18.063 --> 00:05:19.689
It's all curled up.

00:05:19.689 --> 00:05:24.408
Now you have to add another shape
and viewpoint to the object model.

00:05:24.408 --> 00:05:26.123
But what if cats are hidden?

00:05:27.143 --> 00:05:29.362
What about these silly cats?

00:05:31.112 --> 00:05:33.529
Now you get my point.

00:05:33.529 --> 00:05:36.896
Even something as simple
as a household pet

00:05:36.896 --> 00:05:41.400
can present an infinite number
of variations to the object model,

00:05:41.400 --> 00:05:43.633
and that's just one object.

00:05:44.573 --> 00:05:47.065
So about eight years ago,

00:05:47.065 --> 00:05:52.095
a very simple and profound observation
changed my thinking.

00:05:53.425 --> 00:05:56.110
No one tells a child how to see,

00:05:56.110 --> 00:05:58.371
especially in the early years.

00:05:58.371 --> 00:06:03.371
They learn this through
real-world experiences and examples.

00:06:03.371 --> 00:06:06.111
If you consider a child's eyes

00:06:06.111 --> 00:06:08.665
as a pair of biological cameras,

00:06:08.665 --> 00:06:12.845
they take one picture
about every 200 milliseconds,

00:06:12.845 --> 00:06:15.979
the average time an eye movement is made.

00:06:15.979 --> 00:06:21.529
So by age three, a child would have seen
hundreds of millions of pictures

00:06:21.529 --> 00:06:23.363
of the real world.

00:06:23.363 --> 00:06:25.643
That's a lot of training examples.

00:06:26.383 --> 00:06:32.372
So instead of focusing solely
on better and better algorithms,

00:06:32.372 --> 00:06:37.644
my insight was to give the algorithms
the kind of training data

00:06:37.644 --> 00:06:40.963
that a child was given through experiences

00:06:40.963 --> 00:06:44.841
in both quantity and quality.

00:06:44.841 --> 00:06:46.699
Once we know this,

00:06:46.699 --> 00:06:49.670
we knew we needed to collect a data set

00:06:49.670 --> 00:06:54.129
that has far more images
than we have ever had before,

00:06:54.129 --> 00:06:56.706
perhaps thousands of times more,

00:06:56.706 --> 00:07:00.817
and together with Professor
Kai Li at Princeton University,

00:07:00.817 --> 00:07:05.569
we launched the ImageNet project in 2007.

00:07:05.569 --> 00:07:09.407
Luckily, we didn't have to mount
a camera on our head

00:07:09.407 --> 00:07:11.171
and wait for many years.

00:07:11.171 --> 00:07:12.634
We went to the Internet,

00:07:12.634 --> 00:07:17.070
the biggest treasure trove of pictures
that humans have ever created.

00:07:17.070 --> 00:07:20.111
We downloaded nearly a billion images

00:07:20.111 --> 00:07:25.991
and used crowdsourcing technology
like the Amazon Mechanical Turk platform

00:07:25.991 --> 00:07:28.330
to help us to label these images.

00:07:28.330 --> 00:07:33.230
At its peak, ImageNet was one of
the biggest employers

00:07:33.230 --> 00:07:36.226
of the Amazon Mechanical Turk workers:

00:07:36.226 --> 00:07:40.080
together, almost 50,000 workers

00:07:40.080 --> 00:07:44.120
from 167 countries around the world

00:07:44.120 --> 00:07:48.067
helped us to clean, sort and label

00:07:48.067 --> 00:07:51.642
nearly a billion candidate images.

00:07:52.612 --> 00:07:55.265
That was how much effort it took

00:07:55.265 --> 00:07:59.165
to capture even a fraction
of the imagery

00:07:59.165 --> 00:08:03.336
a child's mind takes in
in the early developmental years.

00:08:04.148 --> 00:08:08.050
In hindsight, this idea of using big data

00:08:08.050 --> 00:08:12.600
to train computer algorithms
may seem obvious now,

00:08:12.600 --> 00:08:16.710
but back in 2007, it was not so obvious.

00:08:16.710 --> 00:08:20.588
We were fairly alone on this journey
for quite a while.

00:08:20.588 --> 00:08:25.591
Some very friendly colleagues advised me
to do something more useful for my tenure,

00:08:25.591 --> 00:08:29.933
and we were constantly struggling
for research funding.

00:08:29.933 --> 00:08:32.418
Once, I even joked to my graduate students

00:08:32.418 --> 00:08:36.481
that I would just reopen
my dry cleaner's shop to fund ImageNet.

00:08:36.481 --> 00:08:41.242
After all, that's how I funded
my college years.

00:08:41.242 --> 00:08:43.098
So we carried on.

00:08:43.098 --> 00:08:46.813
In 2009, the ImageNet project delivered

00:08:46.813 --> 00:08:50.855
a database of 15 million images

00:08:50.855 --> 00:08:55.660
across 22,000 classes
of objects and things

00:08:55.660 --> 00:08:58.980
organized by everyday English words.

00:08:58.980 --> 00:09:01.906
In both quantity and quality,

00:09:01.906 --> 00:09:04.878
this was an unprecedented scale.

00:09:04.878 --> 00:09:08.339
As an example, in the case of cats,

00:09:08.339 --> 00:09:11.148
we have more than 62,000 cats

00:09:11.148 --> 00:09:15.258
of all kinds of looks and poses

00:09:15.258 --> 00:09:20.481
and across all species
of domestic and wild cats.

00:09:20.481 --> 00:09:23.825
We were thrilled
to have put together ImageNet,

00:09:23.825 --> 00:09:27.563
and we wanted the whole research world
to benefit from it,

00:09:27.563 --> 00:09:31.604
so in the TED fashion,
we opened up the entire data set

00:09:31.604 --> 00:09:35.196
to the worldwide
research community for free.

00:09:36.636 --> 00:09:40.636
(Applause)

00:09:41.416 --> 00:09:45.954
Now that we have the data
to nourish our computer brain,

00:09:45.954 --> 00:09:49.691
we're ready to come back
to the algorithms themselves.

00:09:49.691 --> 00:09:54.869
As it turned out, the wealth
of information provided by ImageNet

00:09:54.869 --> 00:09:59.675
was a perfect match to a particular class
of machine learning algorithms

00:09:59.675 --> 00:10:02.090
called convolutional neural network,

00:10:02.090 --> 00:10:07.338
pioneered by Kunihiko Fukushima,
Geoff Hinton, and Yann LeCun

00:10:07.338 --> 00:10:10.983
back in the 1970s and '80s.

00:10:10.983 --> 00:10:16.602
Just like the brain consists
of billions of highly connected neurons,

00:10:16.602 --> 00:10:20.456
a basic operating unit in a neural network

00:10:20.456 --> 00:10:22.871
is a neuron-like node.

00:10:22.871 --> 00:10:25.425
It takes input from other nodes

00:10:25.425 --> 00:10:28.143
and sends output to others.

00:10:28.143 --> 00:10:32.856
Moreover, these hundreds of thousands
or even millions of nodes

00:10:32.856 --> 00:10:36.083
are organized in hierarchical layers,

00:10:36.083 --> 00:10:38.637
also similar to the brain.

00:10:38.637 --> 00:10:43.420
In a typical neural network we use
to train our object recognition model,

00:10:43.420 --> 00:10:46.601
it has 24 million nodes,

00:10:46.601 --> 00:10:49.898
140 million parameters,

00:10:49.898 --> 00:10:52.661
and 15 billion connections.

00:10:52.661 --> 00:10:55.076
That's an enormous model.

00:10:55.076 --> 00:10:58.977
Powered by the massive data from ImageNet

00:10:58.977 --> 00:11:04.410
and the modern CPUs and GPUs
to train such a humongous model,

00:11:04.410 --> 00:11:06.779
the convolutional neural network

00:11:06.779 --> 00:11:10.215
blossomed in a way that no one expected.

00:11:10.215 --> 00:11:12.723
It became the winning architecture

00:11:12.723 --> 00:11:18.063
to generate exciting new results
in object recognition.

00:11:18.063 --> 00:11:20.873
This is a computer telling us

00:11:20.873 --> 00:11:23.173
this picture contains a cat

00:11:23.173 --> 00:11:25.076
and where the cat is.

00:11:25.076 --> 00:11:27.188
Of course there are more things than cats,

00:11:27.188 --> 00:11:29.626
so here's a computer algorithm telling us

00:11:29.626 --> 00:11:32.900
the picture contains
a boy and a teddy bear;

00:11:32.900 --> 00:11:37.266
a dog, a person, and a small kite
in the background;

00:11:37.266 --> 00:11:40.401
or a picture of very busy things

00:11:40.401 --> 00:11:45.045
like a man, a skateboard,
railings, a lampost, and so on.

00:11:45.045 --> 00:11:50.338
Sometimes, when the computer
is not so confident about what it sees,

00:11:51.498 --> 00:11:53.774
we have taught it to be smart enough

00:11:53.774 --> 00:11:57.652
to give us a safe answer
instead of committing too much,

00:11:57.652 --> 00:12:00.463
just like we would do,

00:12:00.463 --> 00:12:05.129
but other times our computer algorithm
is remarkable at telling us

00:12:05.129 --> 00:12:07.382
what exactly the objects are,

00:12:07.382 --> 00:12:10.818
like the make, model, year of the cars.

00:12:10.818 --> 00:12:16.204
We applied this algorithm to millions
of Google Street View images

00:12:16.204 --> 00:12:19.339
across hundreds of American cities,

00:12:19.339 --> 00:12:22.265
and we have learned something
really interesting:

00:12:22.265 --> 00:12:25.585
first, it confirmed our common wisdom

00:12:25.585 --> 00:12:28.875
that car prices correlate very well

00:12:28.875 --> 00:12:31.220
with household incomes.

00:12:31.220 --> 00:12:35.747
But surprisingly, car prices
also correlate well

00:12:35.747 --> 00:12:38.047
with crime rates in cities,

00:12:39.007 --> 00:12:42.970
or voting patterns by zip codes.

00:12:44.060 --> 00:12:46.266
So wait a minute. Is that it?

00:12:46.266 --> 00:12:51.419
Has the computer already matched
or even surpassed human capabilities?

00:12:51.419 --> 00:12:53.557
Not so fast.

00:12:53.557 --> 00:12:58.480
So far, we have just taught
the computer to see objects.

00:12:58.480 --> 00:13:03.124
This is like a small child
learning to utter a few nouns.

00:13:03.124 --> 00:13:05.794
It's an incredible accomplishment,

00:13:05.794 --> 00:13:08.254
but it's only the first step.

00:13:08.254 --> 00:13:12.016
Soon, another developmental
milestone will be hit,

00:13:12.016 --> 00:13:15.477
and children begin
to communicate in sentences.

00:13:15.477 --> 00:13:19.701
So instead of saying
this is a cat in the picture,

00:13:19.701 --> 00:13:24.903
you already heard the little girl
telling us this is a cat lying on a bed.

00:13:24.903 --> 00:13:30.498
So to teach a computer
to see a picture and generate sentences,

00:13:30.498 --> 00:13:34.446
the marriage between big data
and machine learning algorithm

00:13:34.446 --> 00:13:36.721
has to take another step.

00:13:36.721 --> 00:13:40.877
Now, the computer has to learn
from both pictures

00:13:40.877 --> 00:13:43.733
as well as natural language sentences

00:13:43.733 --> 00:13:47.055
generated by humans.

00:13:47.055 --> 00:13:50.908
Just like the brain integrates
vision and language,

00:13:50.908 --> 00:13:56.109
we developed a model
that connects parts of visual things

00:13:56.109 --> 00:13:58.013
like visual snippets

00:13:58.013 --> 00:14:02.216
with words and phrases in sentences.

00:14:02.216 --> 00:14:04.979
About four months ago,

00:14:04.979 --> 00:14:07.626
we finally tied all this together

00:14:07.626 --> 00:14:11.410
and produced one of the first
computer vision models

00:14:11.410 --> 00:14:15.404
that is capable of generating
a human-like sentence

00:14:15.404 --> 00:14:18.910
when it sees a picture for the first time.

00:14:18.910 --> 00:14:23.554
Now, I'm ready to show you
what the computer says

00:14:23.554 --> 00:14:25.529
when it sees the picture

00:14:25.529 --> 00:14:29.359
that the little girl saw
at the beginning of this talk.

00:14:31.519 --> 00:14:34.863
(Video) Computer: A man is standing
next to an elephant.

00:14:36.393 --> 00:14:40.027
A large airplane sitting on top
of an airport runway.

00:14:41.057 --> 00:14:45.269
FFL: Of course, we're still working hard
to improve our algorithms,

00:14:45.269 --> 00:14:47.865
and it still has a lot to learn.

00:14:47.865 --> 00:14:50.156
(Applause)

00:14:51.556 --> 00:14:54.877
And the computer still makes mistakes.

00:14:54.877 --> 00:14:58.268
(Video) Computer: A cat lying
on a bed in a blanket.

00:14:58.268 --> 00:15:00.821
FFL: So of course, when it sees
too many cats,

00:15:00.821 --> 00:15:03.747
it thinks everything
might look like a cat.

00:15:05.317 --> 00:15:08.181
(Video) Computer: A young boy
is holding a baseball bat.

00:15:08.181 --> 00:15:09.946
(Laughter)

00:15:09.946 --> 00:15:14.529
FFL: Or, if it hasn't seen a toothbrush,
it confuses it with a baseball bat.

00:15:15.309 --> 00:15:18.743
(Video) Computer: A man riding a horse
down a street next to a building.

00:15:18.743 --> 00:15:20.766
(Laughter)

00:15:20.766 --> 00:15:24.318
FFL: We haven't taught Art 101
to the computers.

00:15:25.768 --> 00:15:28.652
(Video) Computer: A zebra standing
in a field of grass.

00:15:28.652 --> 00:15:32.019
FFL: And it hasn't learned to appreciate
the stunning beauty of nature

00:15:32.019 --> 00:15:34.457
like you and I do.

00:15:34.457 --> 00:15:37.289
So it has been a long journey.

00:15:37.289 --> 00:15:41.515
To get from age zero to three was hard.

00:15:41.515 --> 00:15:47.111
The real challenge is to go
from three to 13 and far beyond.

00:15:47.111 --> 00:15:51.476
Let me remind you with this picture
of the boy and the cake again.

00:15:51.476 --> 00:15:55.540
So far, we have taught
the computer to see objects

00:15:55.540 --> 00:15:59.998
or even tell us a simple story
when seeing a picture.

00:15:59.998 --> 00:16:03.574
(Video) Computer: A person sitting
at a table with a cake.

00:16:03.574 --> 00:16:06.204
FFL: But there's so much more 
to this picture

00:16:06.204 --> 00:16:08.474
than just a person and a cake.

00:16:08.474 --> 00:16:12.941
What the computer doesn't see
is that this is a special Italian cake

00:16:12.941 --> 00:16:16.158
that's only served during Easter time.

00:16:16.158 --> 00:16:19.363
The boy is wearing his favorite t-shirt

00:16:19.363 --> 00:16:23.333
given to him as a gift by his father
after a trip to Sydney,

00:16:23.333 --> 00:16:27.141
and you and I can all tell how happy he is

00:16:27.141 --> 00:16:30.344
and what's exactly on his mind
at that moment.

00:16:31.214 --> 00:16:34.339
This is my son Leo.

00:16:34.339 --> 00:16:36.963
On my quest for visual intelligence,

00:16:36.963 --> 00:16:39.354
I think of Leo constantly

00:16:39.354 --> 00:16:42.257
and the future world he will live in.

00:16:42.257 --> 00:16:44.278
When machines can see,

00:16:44.278 --> 00:16:48.990
doctors and nurses will have
extra pairs of tireless eyes

00:16:48.990 --> 00:16:53.082
to help them to diagnose
and take care of patients.

00:16:53.082 --> 00:16:57.465
Cars will run smarter
and safer on the road.

00:16:57.465 --> 00:17:00.159
Robots, not just humans,

00:17:00.159 --> 00:17:05.008
will help us to brave the disaster zones
to save the trapped and wounded.

00:17:05.798 --> 00:17:09.594
We will discover new species, 
better materials,

00:17:09.594 --> 00:17:14.103
and explore unseen frontiers
with the help of the machines.

00:17:15.113 --> 00:17:19.280
Little by little, we're giving sight
to the machines.

00:17:19.280 --> 00:17:22.078
First, we teach them to see.

00:17:22.078 --> 00:17:24.841
Then, they help us to see better.

00:17:24.841 --> 00:17:29.006
For the first time, human eyes
won't be the only ones

00:17:29.006 --> 00:17:31.940
pondering and exploring our world.

00:17:31.940 --> 00:17:35.400
We will not only use the machines
for their intelligence,

00:17:35.400 --> 00:17:41.579
we will also collaborate with them
in ways that we cannot even imagine.

00:17:41.579 --> 00:17:43.740
This is my quest:

00:17:43.740 --> 00:17:46.452
to give computers visual intelligence

00:17:46.452 --> 00:17:51.583
and to create a better future
for Leo and for the world.

00:17:51.583 --> 00:17:53.394
Thank you.

00:17:53.394 --> 00:17:57.179
(Applause)

