WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: Timothée Parrique
Relecteur: Elisabeth Buffard

00:00:18.330 --> 00:00:23.330
Ce dont je veux vous parler aujourd'hui, c'est de la façon dont les robots envahissent nos vies

00:00:23.330 --> 00:00:26.330
à plusieurs niveaux, et sur différentes échelles de temps.

00:00:26.330 --> 00:00:30.330
Et quand j'imagine le futur, je ne peux imaginer un monde, dans 500 ans,

00:00:30.330 --> 00:00:32.330
où les robots ne seraient pas omniprésents,

00:00:32.330 --> 00:00:37.330
en supposant -- malgré toutes les prédictions pessimistes de beaucoup de gens sur notre avenir --

00:00:37.330 --> 00:00:41.330
en supposant que nous soyons toujours là, je n'imagine pas que le monde ne soit pas peuplé de robots.

00:00:41.330 --> 00:00:44.330
Alors la question est, s'ils sont partout dans 500 ans,

00:00:44.330 --> 00:00:46.330
ne le seront-ils pas déjà avant?

00:00:46.330 --> 00:00:48.330
Seront-ils là dans 50 ans?

00:00:48.330 --> 00:00:51.330
Oui, je pense que c'est possible -- Il va y avoir beaucoup de robots autour de nous.

00:00:51.330 --> 00:00:54.330
Et en fait, je pense que ce sera même plus tôt que ça.

00:00:54.330 --> 00:00:58.330
Je pense que nous en sommes au point où les robots sont devenus communs,

00:00:58.330 --> 00:01:04.330
et je pense que nous y sommes depuis les années 1978 ou 1980 soit depuis les ordinateurs personnels,

00:01:04.330 --> 00:01:07.330
lorsque les premiers robots sont apparus.

00:01:07.330 --> 00:01:11.330
D'une certaine manière, les ordinateurs sont apparus par le biais des jeux et des jouets.

00:01:11.330 --> 00:01:14.330
Et comme vous le savez, le premier ordinateur que la plupart des gens avaient à la maison

00:01:14.330 --> 00:01:16.330
devait être un ordinateur pour jouer à Pong,

00:01:16.330 --> 00:01:18.330
un petit microprocesseur embarqué,

00:01:18.330 --> 00:01:21.330
comme pour tous les jeux qui sont venus après ça.

00:01:21.330 --> 00:01:24.330
Et nous commençons à observer la même chose avec les robots:

00:01:24.330 --> 00:01:28.330
LEHO Mindstorms, Furbies -- qui ici -- est-ce que quelqu'un a un Furby?

00:01:28.330 --> 00:01:31.330
Oui, il s'en est vendu 38 millions à travers le monde.

00:01:31.330 --> 00:01:33.330
Ils sont très courants, en fait c'est un miniscule petit robot,

00:01:33.330 --> 00:01:35.330
un simple robot avec des capteurs.

00:01:35.330 --> 00:01:37.330
C'est une sorte de processus d'actionnement.

00:01:37.330 --> 00:01:40.330
Sur la droite c'est un autre robot poupée, que vous pouviez vous procurer il y a quelques années.

00:01:40.330 --> 00:01:42.330
Et comme aux premiers jours,

00:01:42.330 --> 00:01:47.330
lorsqu'il il y avait de nombreuses sortes d'interactions d'amateurs sur les ordinateurs,

00:01:47.330 --> 00:01:51.330
vous pouvez maintenant obtenir différents kits et livres pour les personnaliser.

00:01:51.330 --> 00:01:55.330
Et sur la gauche, il y a une plateforme de Evolution Robotics,

00:01:55.330 --> 00:01:58.330
où vous déposez un PC, et vous programmez cette chose avec un GUI

00:01:58.330 --> 00:02:01.330
pour qu'elle se déplace dans votre maison et réalise différentes tâches.

00:02:01.330 --> 00:02:04.330
Puis il y a plus cher, un genre de robots jouets --

00:02:04.330 --> 00:02:08.330
Le Aibo Sony. Et là sur la droite, en voilà un développé par NEC,

00:02:08.330 --> 00:02:11.330
le PaPeRo, mais je ne pense pas qu'ils vont le lancer sur le marché.

00:02:11.330 --> 00:02:14.330
Mais néanmoins, ce genre d'objets existe.

00:02:14.330 --> 00:02:18.330
Et ces derniers 2 ou 3 ans, nous avons vu des robots tondeurs de gazon,

00:02:18.330 --> 00:02:24.330
Husqvarna en bas, Friendly Robotics en haut, une entreprise Israëlienne.

00:02:24.330 --> 00:02:26.330
Puis ces 12 derniers mois environ

00:02:26.330 --> 00:02:30.330
nous avons vu apparaitre plusieurs robots de nettoyage domestique.

00:02:30.330 --> 00:02:33.330
En haut à gauche c'est un très joli robot de ménage d'intérieur

00:02:33.330 --> 00:02:37.330
d'une entreprise appellé Dyson, au Royaume-Uni. Sauf qu'il était si cher --

00:02:37.330 --> 00:02:39.330
3 500 dollars -- qu'ils ne l'ont pas lancé sur le marché.

00:02:39.330 --> 00:02:42.330
Mais en bas à gauche vous voyez Electrolux, qui est en vente.

00:02:42.330 --> 00:02:44.330
Un autre de Karcher.

00:02:44.330 --> 00:02:46.330
En bas à droite c'en est un que j'ai construit dans mon labo

00:02:46.330 --> 00:02:49.330
il y a 10 ans, et nous l'avons finalement produit.

00:02:49.330 --> 00:02:51.330
Et laissez moi juste vous montrer cela.

00:02:51.330 --> 00:02:55.330
Nous allons le distribuer, je pense que Chris l'a dit, après la présentation.

00:02:55.330 --> 00:03:01.330
Voici un robot que vous pouvez vous procurer vous-même, et il nettoiera vos sols.

00:03:05.330 --> 00:03:10.330
Et il commence par tourner en faisant des cercles de plus en plus larges.

00:03:10.330 --> 00:03:14.330
Si il heurte quelque chose -- vous voyez ça ?

00:03:14.330 --> 00:03:17.330
Maintenant il commence à suivre le mur, il fait le tour de mes pieds

00:03:17.330 --> 00:03:21.330
pour nettoyer. Voyons voir --

00:03:21.330 --> 00:03:26.330
oh, qui a volé volé mes céréales ?. Ils ont volé mes céréales

00:03:26.330 --> 00:03:32.330
(Rires)

00:03:32.330 --> 00:03:35.330
Pas d'inquiétude, détendez-vous, non, détendez-vous, il est intelligent.

00:03:35.330 --> 00:03:38.330
(Rires)

00:03:38.330 --> 00:03:42.330
Voyez, les enfants de 3 ans, ils ne préoccupent pas.

00:03:42.330 --> 00:03:44.330
Ce sont les adultes qui se mettent en colère.

00:03:44.330 --> 00:03:45.330
(Rires)

00:03:45.330 --> 00:03:47.330
On va juste mettre un peu de bordel ici.

00:03:47.330 --> 00:03:51.330
(Rires)

00:03:51.330 --> 00:03:53.330
D'accord.

00:03:53.330 --> 00:03:57.330
(Rires)

00:03:57.330 --> 00:04:00.330
Je ne sais pas si vous voyez -- alors, je mets un peu de céréales ici,

00:04:00.330 --> 00:04:07.330
Je mets des centimes, voyons s'il va nettoyer.

00:04:10.330 --> 00:04:12.330
Oui, d'accord. Alors --

00:04:12.330 --> 00:04:16.330
nous allons laisser ça pour plus tard.

00:04:16.330 --> 00:04:21.330
(Applaudissements)

00:04:22.330 --> 00:04:26.330
Le truc c'était en partie de construire un meilleur mécanisme de nettoyage en fait ;

00:04:26.330 --> 00:04:30.330
l'intelligence à l'intérieur était assez simple.

00:04:30.330 --> 00:04:32.330
Et c'est vrai pour de nombreux robots.

00:04:32.330 --> 00:04:36.330
Nous sommes tous devenus des programmateurs chauvins, je pense

00:04:36.330 --> 00:04:38.330
et nous pensons que la programmation fait tout,

00:04:38.330 --> 00:04:40.330
mais la mécanique reste encore importante.

00:04:40.330 --> 00:04:43.330
Voilà un autre robot, le PackBot,

00:04:43.330 --> 00:04:45.330
que nous avons construit il y a quelques années.

00:04:45.330 --> 00:04:51.330
C'est un robot de surveillance militaire, pour guider les troupes,

00:04:51.330 --> 00:04:54.330
regarder dans les grottes, par exemple.

00:04:54.330 --> 00:04:56.330
Mais nous devions le faire très résistant,

00:04:56.330 --> 00:05:03.330
beaucoup plus résistant que les robots que nous construisions dans nos labos.

00:05:03.330 --> 00:05:06.330
(Rires)

00:05:12.330 --> 00:05:16.330
A l'intérieur, ce robot est un PC sous Linux.

00:05:16.330 --> 00:05:22.330
Il peut résister à un choc de 400G. Le robot bénéficie d'une intelligence locale:

00:05:22.330 --> 00:05:28.330
il peut se retourner, il peut se mettre à portée de communication,

00:05:28.330 --> 00:05:31.330
il peut monter des marches tout seul, et cetera.

00:05:38.330 --> 00:05:42.330
D'accord, alors il navigue localement.

00:05:42.330 --> 00:05:48.330
Un soldat lui donne l'ordre d'aller en haut, et il s'exécute.

00:05:49.330 --> 00:05:52.330
Ce n'était pas une descente contrôlée.

00:05:52.330 --> 00:05:54.330
(Rires)

00:05:54.330 --> 00:05:56.330
Maintenant, il va partir.

00:05:56.330 --> 00:06:01.330
Et la grande perçée pour ces robots, s'est vraiment produite le 11 septembre.

00:06:01.330 --> 00:06:05.330
Nous avions ces robots au pied du World Trade Center tard ce soir là.

00:06:06.330 --> 00:06:08.330
Ils ne pouvaient pas faire grand chose dans cette pile de gravats,

00:06:08.330 --> 00:06:11.330
c'était trop pour eux -- il n'y avait plus rien à faire.

00:06:11.330 --> 00:06:16.330
Mais nous avons pu aller dans tous les immeubles aux alentours qui avaient été évacués,

00:06:16.330 --> 00:06:19.330
et chercher d'éventuels rescapés dans les immeubles

00:06:19.330 --> 00:06:21.330
dont l'accès était trop dangereux.

00:06:21.330 --> 00:06:23.330
Regardons la vidéo.

00:06:23.330 --> 00:06:26.330
Journaliste: ...Nos compagnons sur le champs de bataille nous aident à réduire les risques au combat.

00:06:26.330 --> 00:06:29.330
Nick Robertson connaît cette histoire.

00:06:31.330 --> 00:06:33.330
Rodney Brooks: Est-ce qu'on pourrait en avoir une autre?

00:06:38.330 --> 00:06:40.330
D'accord, entendu.

00:06:43.330 --> 00:06:46.330
Alors, c'est un caporal qui avait vu un robot deux semaines auparavant.

00:06:48.330 --> 00:06:52.330
Il envoie des robots dans des grottes, pour voir ce qui se passe.

00:06:52.330 --> 00:06:54.330
Le robot fait preuve de l'autonomie la plus totale.

00:06:54.330 --> 00:06:58.330
La pire chose qui est arrivée dans la grotte jusqu'ici

00:06:58.330 --> 00:07:01.330
était qu'un des robots a fait une chute de dix mètres.

00:07:08.330 --> 00:07:11.330
Alors il y a un an, l'armée américaine n'avait pas ces robots.

00:07:11.330 --> 00:07:13.330
Aujourd'hui ils sont en service en Afghanistan tous les jours.

00:07:13.330 --> 00:07:16.330
Et c'est l'une des raisons qui fait dire qu'une invasion de robots est en marche.

00:07:16.330 --> 00:07:20.330
Il y a une transformation radicale de l'évolution de la technologie.

00:07:20.330 --> 00:07:22.330
Merci.

00:07:23.330 --> 00:07:25.330
Et au cours des tout prochains mois,

00:07:25.330 --> 00:07:28.330
nous allons lancer la production de robots

00:07:28.330 --> 00:07:32.330
qui descendront dans les puits de pétrole en exploitation pour en tirer les dernières années de pétrole.

00:07:32.330 --> 00:07:36.330
Un environnement très hostile, 150 degrés, 10,000 PSI.

00:07:36.330 --> 00:07:40.330
Des robots autonomes qui descendent faire ce genre de boulot.

00:07:40.330 --> 00:07:43.330
Mais de tels robots sont un peu difficiles à programmer.

00:07:43.330 --> 00:07:45.330
Comment, dans le futur, allons-nous programmer nos robots

00:07:45.330 --> 00:07:47.330
pour les rendre plus faciles d'usage?

00:07:47.330 --> 00:07:50.330
Et en fait je voudrais utiliser un robot ici --

00:07:50.330 --> 00:07:55.330
un robot nommé Chris -- debout. Oui. Bien.

00:07:57.330 --> 00:08:01.330
Viens par ici. Maintenant regardez, il pense que les robots sont forcément un peu raide.

00:08:01.330 --> 00:08:04.330
Il l'est en quelques sortes. Mais je vais --

00:08:04.330 --> 00:08:06.330
Chris Anderson: Je suis simplement Anglais. RB: Oh.

00:08:06.330 --> 00:08:08.330
(Rires)

00:08:08.330 --> 00:08:10.330
(Applaudissements)

00:08:10.330 --> 00:08:13.330
Je vais montrer une tâche à ce robot. C'est une tâche très complexe.

00:08:13.330 --> 00:08:16.330
Maintenant regardez, il a fait un signe de la tête, il me donnait des indications

00:08:16.330 --> 00:08:19.330
il comprenait le flot de la communication.

00:08:19.330 --> 00:08:21.330
Et si j'avais dit quelque chose de complétement bizarre

00:08:21.330 --> 00:08:24.330
il m'aurait regarder avec méfiance, et aurait régulé la conversation.

00:08:24.330 --> 00:08:27.330
Alors maintenant, j'ai mis cela en face de lui.

00:08:27.330 --> 00:08:31.330
J'ai regardé ses yeux, et j'ai vu ses yeux regarder en haut de cette bouteille.

00:08:31.330 --> 00:08:33.330
Et je suis en train de réaliser cette tâche juste là, et il vérifie.

00:08:33.330 --> 00:08:36.330
Ses yeux font des aller-retour, m'épiant pour voir ce que je regarde,

00:08:36.330 --> 00:08:38.330
donc nous partageons de l'attention.

00:08:38.330 --> 00:08:41.330
Et alors je réalise cette tâche, et il regarde, et il me regarde

00:08:41.330 --> 00:08:45.330
pour voir ce qui va se passer après. Et maintenant je vais lui donner la bouteille,

00:08:45.330 --> 00:08:47.330
et nous allons voir comment il exécute la tâche. Peux-tu faire ça?

00:08:47.330 --> 00:08:50.330
(Rires)

00:08:50.330 --> 00:08:54.330
D'accord. Il est plutôt bon. Oui. Bien, bien, bien.

00:08:54.330 --> 00:08:56.330
Je ne t'ai pas montré comment faire ça.

00:08:56.330 --> 00:08:58.330
Maintenant regarde si tu peux tout mettre ensemble.

00:08:58.330 --> 00:09:00.330
(Rires)

00:09:00.330 --> 00:09:01.330
Et il pense qu'un robot doit obligatoirement être lent.

00:09:01.330 --> 00:09:03.330
Bon robot, c'est bien.

00:09:03.330 --> 00:09:05.330
Alors on a vu pas mal de choses ici.

00:09:06.330 --> 00:09:09.330
Nous avons vu que quand nous intéragissons,

00:09:09.330 --> 00:09:13.330
nous essayons de montrer à quelqu'un comment faire quelque chose, nous dirigeons leur attention visuelle.

00:09:13.330 --> 00:09:17.330
L'autre chose nous communique son état interne,

00:09:17.330 --> 00:09:20.330
si il comprend ou non, il régule l'intéraction sociale.

00:09:20.330 --> 00:09:22.330
Il y avait du partage d'attention lorsque l'on regardait le même genre de choses,

00:09:22.330 --> 00:09:26.330
et à la fin la reconnaissance d'un renforcement socialement communiqué.

00:09:26.330 --> 00:09:29.330
Et nous avons essayé d'intégrer ça dans nos robots de laboratoire

00:09:29.330 --> 00:09:33.330
parce que nous pensons que c'est ainsi que nous voulons interagir avec les robots dans le futur.

00:09:33.330 --> 00:09:35.330
J'aimerais seulement vous montrer un diagramme technique.

00:09:35.330 --> 00:09:39.330
Le plus important pour construire un robot avec lequel vous pouvez interagir socialement

00:09:39.330 --> 00:09:41.330
est son système d'attention visuelle.

00:09:41.330 --> 00:09:44.330
Parce qu'il prête attention à ce qu'il voit et

00:09:44.330 --> 00:09:47.330
à ce avec quoi il interagit, et à ce que vous comprenez qu'il fait.

00:09:47.330 --> 00:09:50.330
Alors dans les vidéos que je suis sur le point de vous montrer,

00:09:50.330 --> 00:09:54.330
vous allez voir un système d'attention visuelle sur un robot

00:09:54.330 --> 00:09:58.330
qui a -- il regarde les tons de couleur dans l'espace colorimétrique TSV,

00:09:58.330 --> 00:10:02.330
alors il passe en revue tout ça, vous savez, les colorants humains.

00:10:02.330 --> 00:10:04.330
Il recherche les couleurs à haute saturation, venant des jouets.

00:10:04.330 --> 00:10:06.330
Et il recherche des choses qui bougent.

00:10:06.330 --> 00:10:09.330
Et il pondère celles-ci ensemble dans une fenêtre d'attention,

00:10:09.330 --> 00:10:11.330
et il recherche le meilleur arrangement --

00:10:11.330 --> 00:10:13.330
l'endroit où les choses les plus intéressantes se produisent.

00:10:13.330 --> 00:10:17.330
Et c'est vers cet endroit que ses yeux se dirigent.

00:10:17.330 --> 00:10:19.330
Et il fixe cet endroit.

00:10:19.330 --> 00:10:22.330
En même temps, un genre d'approche descendante :

00:10:22.330 --> 00:10:25.330
il pourrait décider qu'il se sent seul et aller chercher une teinte de peau,

00:10:25.330 --> 00:10:28.330
ou pourrait décider qu'il s'ennuie et partir à la recherche d'un jouet.

00:10:28.330 --> 00:10:30.330
Et alors ces pondérations changent.

00:10:30.330 --> 00:10:32.330
Et juste ici sur la droite,

00:10:32.330 --> 00:10:35.330
c'est ce qu'on appelle le module à la mémoire de Steven Spielberg.

00:10:35.330 --> 00:10:37.330
Est-ce que les gens ont vu le film A.I. Intelligence Artificielle? Public: Oui.

00:10:37.330 --> 00:10:39.330
RB: Oui, c'était vraiment mauvais, mais --

00:10:39.330 --> 00:10:43.330
souvenez vous, le moment où Haley Joel Osment, le petit robot,

00:10:43.330 --> 00:10:47.330
regarda la fée bleue pendant 2,000 ans sans détourner son regard?

00:10:47.330 --> 00:10:49.330
Et bien, on se débarasse de ça,

00:10:49.330 --> 00:10:53.330
parce que c'est une accomodation Gaussienne qui devient négative,

00:10:53.330 --> 00:10:56.330
et de plus en plus intense quand il fixe quelque chose.

00:10:56.330 --> 00:10:59.330
Et il s'ennuie, alors il ira regarder quelque chose d'autre.

00:10:59.330 --> 00:11:03.330
Alors, une fois que vous avez compris ça -- et voici un robot, voici Kismet,

00:11:03.330 --> 00:11:07.330
à la recherche d'un jouet. Vous voyez ce qu'il regarde.

00:11:07.330 --> 00:11:12.330
Vous pouvez deviner la direction de son regard grâce aux globes oculaires qui couvrent sa caméra,

00:11:12.330 --> 00:11:15.330
et vous pouvez voir le moment exact où il repère vraiment le jouet.

00:11:15.330 --> 00:11:17.330
Et on remarque ici qu'il a une sorte de petite réaction émotionnelle.

00:11:17.330 --> 00:11:18.330
(Rires)

00:11:18.330 --> 00:11:20.330
Mais il va pourtant continuer à faire attention

00:11:20.330 --> 00:11:24.330
si quelque chose de plus important entre dans son champs de vision --

00:11:24.330 --> 00:11:28.330
comme par exemple Cynthia Breazeal, celle qui a construit ce robot -- par la droite.

00:11:28.330 --> 00:11:33.330
Il la voit, elle attire son attention.

00:11:33.330 --> 00:11:37.330
Kismet possède un espace émotionnel en trois dimensions sous-jacentes,

00:11:37.330 --> 00:11:40.330
un espace vectoriel, représentant son état émotionnel.

00:11:40.330 --> 00:11:45.330
Et à différents points dans cet espace, il exprime --

00:11:46.330 --> 00:11:48.330
est-ce qu'on peut avoir du son par ici?

00:11:48.330 --> 00:11:50.330
Est-ce que vous entendez ça, juste ici? Public: Oui.

00:11:50.330 --> 00:11:55.330
Kismet: Etes-vous vraiment certain? Etes-vous vraiment certain?

00:11:57.330 --> 00:11:59.330
Etes-vous vraiment certain?

00:12:00.330 --> 00:12:03.330
RB: Donc il exprime son émotion avec son visage

00:12:03.330 --> 00:12:05.330
et la prosodie dans sa voix.

00:12:05.330 --> 00:12:09.330
Et pendant que je m'occupais du robot ici,

00:12:09.330 --> 00:12:12.330
Chris, le robot, il était en train de mesurer la prosodie dans ma voix.

00:12:12.330 --> 00:12:17.330
et donc nous avons un robot qui mesure la prosodie pour quatre messages de base

00:12:17.330 --> 00:12:21.330
que les mères donnent de façon pre-linguistique à leurs enfants.

00:12:21.330 --> 00:12:24.330
Alors là nous avons de simples cobayes félicitant le robot,

00:12:26.330 --> 00:12:28.330
Voix: Gentil robot.

00:12:29.330 --> 00:12:31.330
Tu es vraiment un gentil petit robot.

00:12:31.330 --> 00:12:33.330
(Rires)

00:12:33.330 --> 00:12:35.330
Et le robot réagit de façon appropriée.

00:12:35.330 --> 00:12:39.330
Voix: ...très bien, Kismet.

00:12:40.330 --> 00:12:42.330
(Rires)

00:12:42.330 --> 00:12:44.330
Voix: Regarde mon sourire.

00:12:46.330 --> 00:12:49.330
RB: Il sourit. Elle imite le sourire. Cela se produit constamment.

00:12:49.330 --> 00:12:51.330
Ceux-ci sont de simples sujets.

00:12:51.330 --> 00:12:54.330
Ici nous leur avons demandé d'attirer l'attention du robot

00:12:54.330 --> 00:12:57.330
et d'indiquer quand ils l'avaient captée.

00:12:57.330 --> 00:13:01.330
Voix: Hey, Kismet, ah le voilà.

00:13:01.330 --> 00:13:05.330
RB: Alors elle se rend compte que l'attention du robot est portée sur elle.

00:13:08.330 --> 00:13:12.330
Voix: Kismet, aimes-tu le jouet? Oh.

00:13:13.330 --> 00:13:15.330
RB: Maintenant, voilà qu'on leur demande de prohiber le robot,

00:13:15.330 --> 00:13:19.330
et cette première femme pousse vraiment le robot dans une impasse émotionnelle .

00:13:19.330 --> 00:13:24.330
Voix: Non. Non. Tu ne dois pas faire ça. Non.

00:13:24.330 --> 00:13:27.330
(Rires)

00:13:27.330 --> 00:13:33.330
Voix: Ce n'est pas approprié. Non. Non.

00:13:33.330 --> 00:13:36.330
(Rires)

00:13:36.330 --> 00:13:38.330
RB: Je vais en rester là.

00:13:38.330 --> 00:13:40.330
On met ça en place. Et puis on met en place le tour de rôle.

00:13:40.330 --> 00:13:43.330
Quand nous parlons avec quelqu'un, nous parlons.

00:13:43.330 --> 00:13:47.330
Alors, on lève les sourcils, on bouge nos yeux,

00:13:47.330 --> 00:13:50.330
on donne à l'autre personne un signe pour lui dire que c'est à son tour de parler.

00:13:50.330 --> 00:13:54.330
Et alors, elle se met à parler, et après on se passe le bâton.

00:13:54.330 --> 00:13:56.330
Alors on intègre ça dans le robot.

00:13:56.330 --> 00:13:58.330
On a fait entrer quelques simples cobayes,

00:13:58.330 --> 00:14:00.330
on ne leur a rien dit à propos du robot,

00:14:00.330 --> 00:14:02.330
on les a fait asseoir en face du robot et dit, parlez au robot.

00:14:02.330 --> 00:14:04.330
Alors maintenant, ce qu'ils ne savaient pas était,

00:14:04.330 --> 00:14:06.330
que le robot ne comprenait pas un mot de ce qu'ils disaient,

00:14:06.330 --> 00:14:09.330
et que le robot ne parlait pas anglais.

00:14:09.330 --> 00:14:11.330
Il ne disait que des phonèmes anglais de manière aléatoire.

00:14:11.330 --> 00:14:13.330
Et je veux que vous regardiez bien attentivement, au début,

00:14:13.330 --> 00:14:17.330
le moment où cette personne, Ritchie, qui venait de parler pendant 25 minutes au robot --

00:14:17.330 --> 00:14:19.330
(Rires)

00:14:19.330 --> 00:14:21.330
-- dit, "J'aimerais te montrer quelque chose.

00:14:21.330 --> 00:14:23.330
J'aimerais te montrer ma montre".

00:14:23.330 --> 00:14:28.330
Et il amène la montre au centre, dans le champ de vision du robot,

00:14:28.330 --> 00:14:30.330
il la montre au robot, lui donne un signal émotionnel,

00:14:30.330 --> 00:14:32.330
et le robot regarde la montre assez efficacement.

00:14:32.330 --> 00:14:35.330
Nous ne savons pas si il comprenait ou non que le robot --

00:14:36.330 --> 00:14:38.330
Remarquez le passage de tour.

00:14:38.330 --> 00:14:41.330
Ritchie: OK, je veux vous montrer quelque chose. OK, ceci est une montre

00:14:41.330 --> 00:14:44.330
que ma petite amie ma donné.

00:14:44.330 --> 00:14:46.330
Robot: Oh, cool.

00:14:46.330 --> 00:14:50.330
Ritchie: Oui, regarde, il y a aussi une petite lumière bleue. J'ai presque failli la perdre cette semaine.

00:14:51.330 --> 00:14:55.330
(Rires)

00:14:55.330 --> 00:14:58.330
RB: Il garde le contact visuel avec lui, suivant ses yeux.

00:14:58.330 --> 00:15:00.330
Ritchie: Peux-tu faire la même chose? Robot: Oui, bien sur.

00:15:00.330 --> 00:15:02.330
RB: Et ils réussient à avoir cette communication efficace.

00:15:02.330 --> 00:15:06.330
Et voici un autre aspect du type de choses que Chris et moi faisions.

00:15:06.330 --> 00:15:08.330
Voici un autre robot, Cog.

00:15:08.330 --> 00:15:14.330
Ils ont établi un premier contact visuel, et après, quand Christie regarde son jouet,

00:15:14.330 --> 00:15:16.330
le robot estime la direction de son regard

00:15:16.330 --> 00:15:18.330
et regarde la même chose qu'elle regarde.

00:15:18.330 --> 00:15:19.330
(Rires)

00:15:19.330 --> 00:15:22.330
Nous allons voir de plus en plus de ce genre de robot

00:15:22.330 --> 00:15:24.330
dans les laboratoires dans les années à venir.

00:15:24.330 --> 00:15:29.330
Mais alors, les grandes questions, deux grandes questions que les gens me posent sont:

00:15:29.330 --> 00:15:31.330
si on rend ces robots de plus en plus humains,

00:15:31.330 --> 00:15:36.330
allons-nous les accepter, allons-nous -- auront-ils besoin de droits en fin de compte?

00:15:36.330 --> 00:15:39.330
Et l'autre question que les gens me posent est, vont-ils prendre le pouvoir?

00:15:39.330 --> 00:15:40.330
(Rires)

00:15:40.330 --> 00:15:43.330
Et au début -- vous savez, ça a été un grand thème à Hollywood

00:15:43.330 --> 00:15:46.330
avec de nombreux films. Vous reconnaissez probablement ces personnages --

00:15:46.330 --> 00:15:50.330
où dans chacun de ces cas, les robots veulent plus de respect.

00:15:50.330 --> 00:15:53.330
Et bien, avez-vous jamais besoin de donner du respect aux robots?

00:15:54.330 --> 00:15:56.330
Après tout, ce ne sont que des machines.

00:15:56.330 --> 00:16:00.330
Mais je pense, vous savez, nous devons accepter le fait que nous ne sommes que des machines.

00:16:00.330 --> 00:16:05.330
Après tout, c'est surement ce que dit la biologie moléculaire à propos de nous.

00:16:05.330 --> 00:16:08.330
Vous ne voyez pas de description de comment,

00:16:08.330 --> 00:16:12.330
la molécule A vient par là et s'amarre avec cette autre molécule.

00:16:12.330 --> 00:16:15.330
Et ça avance, propulsé par différentes charges,

00:16:15.330 --> 00:16:19.330
et alors l'âme entre en jeu et vient tirer ces molécules pour qu'elles se connectent.

00:16:19.330 --> 00:16:22.330
Tout cela est mécanique, nous sommes des mécanismes.

00:16:22.330 --> 00:16:25.330
Si nous sommes des machines, alors en principe du moins,

00:16:25.330 --> 00:16:29.330
nous devrions être capable de construire des machines avec d'autres trucs,

00:16:29.330 --> 00:16:33.330
qui sont au moins aussi vivant que nous le sommes.

00:16:33.330 --> 00:16:35.330
Mais je pense que pour que nous admettions cela,

00:16:35.330 --> 00:16:38.330
nous devons abandonner notre caractère spécial, d'une certaine façon.

00:16:38.330 --> 00:16:40.330
Et nous avons à de nombreuses reprises perdu contact avec cette spécificité

00:16:40.330 --> 00:16:43.330
sous les assauts de la science et de la technologie

00:16:43.330 --> 00:16:45.330
durant les cent dernières années, au moins.

00:16:45.330 --> 00:16:47.330
Il y a 500 ans, nous avons dû abandonner l'idée

00:16:47.330 --> 00:16:50.330
selon laquelle nous étions le centre de l'univers

00:16:50.330 --> 00:16:52.330
quand la terre commenca à tourner autour du soleil;

00:16:52.330 --> 00:16:57.330
il y a 150 ans, avec Darwin, nous avons dû abandonner l'idée selon laquelle nous étions différents des animaux.

00:16:57.330 --> 00:17:00.330
Et pour imaginer -- , c'est toujours difficile pour nous.

00:17:00.330 --> 00:17:03.330
Vous voyez, récemment nous avons été matraqué par l'idée que peut être

00:17:03.330 --> 00:17:05.330
nous n'avions même pas eu notre propre acte de création, ici sur Terre,

00:17:05.330 --> 00:17:08.330
ce que les gens n'aimaient pas beaucoup. Et puis le génome humain a dit,

00:17:08.330 --> 00:17:11.330
peut-être n'avons-nous seulement que 35,000 gènes. Et ce fut vraiment --

00:17:11.330 --> 00:17:14.330
les gens n'aimaient pas ça, nous avons plus de gènes que ça.

00:17:14.330 --> 00:17:17.330
Nous n'aimons pas abandonner notre spécificité, alors

00:17:17.330 --> 00:17:19.330
l'idée que les robots puissent ressentir des émotions,

00:17:19.330 --> 00:17:21.330
ou que les robots puissent être des créatures vivantes --

00:17:21.330 --> 00:17:23.330
je pense que ça va être dur pour nous de l'accepter.

00:17:23.330 --> 00:17:27.330
Mais nous finirons bien par l'accepter au cours des 50 prochaines années.

00:17:27.330 --> 00:17:30.330
Et la seconde question est, les machines veulent-elles prendre le pouvoir?

00:17:30.330 --> 00:17:35.330
Et pour cela, le scénario classique est que nous créons ces choses,

00:17:35.330 --> 00:17:38.330
elles se développent, on les élève, elles apprennent beaucoup grâce à nous,

00:17:38.330 --> 00:17:42.330
et alors elles commencent à décider que nous sommes trop ennuyeux, lents.

00:17:42.330 --> 00:17:44.330
Elles veulent nous prendre le pouvoir.

00:17:44.330 --> 00:17:47.330
Et pour ceux d'entre vous qui sont parents d'adolescents, vous savez ce que c'est.

00:17:47.330 --> 00:17:48.330
(Rires)

00:17:48.330 --> 00:17:51.330
Mais Hollywood l'élargit aux robots.

00:17:51.330 --> 00:17:54.330
Et la question est,

00:17:54.330 --> 00:17:58.330
quelqu'un va-t-il construire accidentellement un robot qui nous prendra le pouvoir?

00:17:58.330 --> 00:18:01.330
Et c'est un peu l'histoire du mec solidaire au fond de son jardin,

00:18:01.330 --> 00:18:04.330
et, "J'ai accidentellement construit un 747."

00:18:04.330 --> 00:18:06.330
Vous voyez, je ne pense que ça va se produire.

00:18:06.330 --> 00:18:08.330
Et je ne pense pas --

00:18:08.330 --> 00:18:09.330
(Rires)

00:18:09.330 --> 00:18:12.330
-- Je ne pense pas que nous allons construire sans faire exprès des robots

00:18:12.330 --> 00:18:14.330
avec lesquels nous ne serions pas à l'aise.

00:18:14.330 --> 00:18:16.330
Nous allons -- vous savez, on n'aura pas un robot très méchant.

00:18:16.330 --> 00:18:19.330
Avant ça, un robot moyennement méchant devra faire son apparition,

00:18:19.330 --> 00:18:21.330
et encore avant lui, un robot pas si méchant que ça.

00:18:21.330 --> 00:18:22.330
(Rires)

00:18:22.330 --> 00:18:24.330
Et nous n'allons pas laisser les choses se passer de cette façon.

00:18:24.330 --> 00:18:25.330
(Rires)

00:18:25.330 --> 00:18:31.330
Alors, je pense que je vais conclure là dessus: les robots arrivent,

00:18:31.330 --> 00:18:34.330
nous n'avons pas tellement d'inquiètudes à avoir, ça va être très marrant,

00:18:34.330 --> 00:18:38.330
et j'espère que vous allez tous apprécier le voyage pendant ces 50 prochaines années.

00:18:38.330 --> 00:18:40.330
(Applaudissements)

