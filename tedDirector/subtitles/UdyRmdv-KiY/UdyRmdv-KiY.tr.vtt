WEBVTT
Kind: captions
Language: tr

00:00:00.000 --> 00:00:07.000
Çeviri: Ozgur Ilkay Yalcin
Gözden geçirme: Ahmet Yükseltürk

00:00:18.330 --> 00:00:23.330
Bugün size, robotların farklı zamanlarda, farklı seviyelerde nasıl

00:00:23.330 --> 00:00:26.330
hayatımızı işgal etmeye başladıklarından bahsedeceğim.

00:00:26.330 --> 00:00:30.330
Bundan 500 yıl sonra her yanımızın robotla çevrili olmadığı bir dünya

00:00:30.330 --> 00:00:32.330
hayal edemiyorum.

00:00:32.330 --> 00:00:37.330
Tabii ki -- birçok insanın geleceğimiz için yaptığı dehşet verici tahminlere

00:00:37.330 --> 00:00:41.330
rağmen -- hâlâ ortalıkta olursak, robotlarla dolu olmayan bir dünya düşünemiyorum.

00:00:41.330 --> 00:00:44.330
Ardından şu soru geliyor: 500 sene sonra burada olacakları kesinse,

00:00:44.330 --> 00:00:46.330
daha önce de her yerde olabilirler mi?

00:00:46.330 --> 00:00:48.330
Mesela 50 yıl içinde?

00:00:48.330 --> 00:00:51.330
Evet, bence bu pekala mümkün. Her yerde oldukça fazla sayıda robot olacak.

00:00:51.330 --> 00:00:54.330
Ve aslına bakarsanız, ben bundan da çok önce olacağını düşünüyorum.

00:00:54.330 --> 00:00:58.330
Bence şu anda robotların yaygınlaşmasının dönüm noktasındayız.

00:00:58.330 --> 00:01:04.330
Kişisel bilgisayarların gelişimine göre, 1978 veya 1980'de olduğumuz yerdeyiz.

00:01:04.330 --> 00:01:07.330
Şu anda ilk birkaç robot daha yeni ortaya çıkmaya başlıyor.

00:01:07.330 --> 00:01:11.330
Bilgisayarlar hayatlarımıza oyunlar ve oyuncaklarla girdi sayılır.

00:01:11.330 --> 00:01:14.330
Ve bildiğiniz gibi, birçok insanın evindeki ilk bilgisayar

00:01:14.330 --> 00:01:16.330
Pong oynayan, içinde küçük bir mikroişlemcisi olan

00:01:16.330 --> 00:01:18.330
bilgisayar idi.

00:01:18.330 --> 00:01:21.330
Ardından diğer oyunlar geldi.

00:01:21.330 --> 00:01:24.330
Şu anda robotlarda da aynı şeyi görüyoruz:

00:01:24.330 --> 00:01:28.330
LEGO Mindstorms, Furbyler -- burada kimin -- aranızda Furby'si olan var mı?

00:01:28.330 --> 00:01:31.330
Eh tabi, dünya çapında 38 milyon adet satıldı.

00:01:31.330 --> 00:01:33.330
Oldukça yaygınlar. Küçük, ufacık bir robot bu.

00:01:33.330 --> 00:01:35.330
Birkaç sensörü olan basit bir robot.

00:01:35.330 --> 00:01:37.330
Birkaç hesaplanmış hareketi var.

00:01:37.330 --> 00:01:40.330
Sağda ise başka bir robot bebek var, birkaç yıl önce bunlardan satılıyordu.

00:01:40.330 --> 00:01:42.330
Ve aynı bilgisayarların ilk günlerindeki gibi,

00:01:42.330 --> 00:01:47.330
bilgisayarlarla etkileşimlerin amatör olduğu zamanlar, bugün kendi robotunuzu

00:01:47.330 --> 00:01:51.330
yapabileceğiniz kitler ve robot yapımıyla ilgili kitaplar satılıyor.

00:01:51.330 --> 00:01:55.330
Soldaki Evolution Robotics'in sattığı bir platform.

00:01:55.330 --> 00:01:58.330
Üzerine bir PC koyup, grafik arayüzüyle programlıyorsunuz.

00:01:58.330 --> 00:02:01.330
Böylece evin içinde gezip, çeşitli işler yapabiliyor.

00:02:01.330 --> 00:02:04.330
Bir de daha pahalı, oyuncak diyebileceğimiz, robotlar var.

00:02:04.330 --> 00:02:08.330
Mesela Sony Aibo. Ve hemen yanındaki de NEC'in geliştirdiği PaPeRo.

00:02:08.330 --> 00:02:11.330
Sanırım satışa sunmayacaklar.

00:02:11.330 --> 00:02:14.330
Ama yine de, bu tip şeyler şu anda var.

00:02:14.330 --> 00:02:18.330
Ve son iki ya da üç yıl içinde, çim biçen robotlar gördük:

00:02:18.330 --> 00:02:24.330
Alttaki Husqvarna, üstteki bir İsrail şirketi olan Friendly Robotics.

00:02:24.330 --> 00:02:26.330
Son 12 ay içinde ise birkaç tane ev temizlik

00:02:26.330 --> 00:02:30.330
robotunun piyasaya çıkışına şahit olduk.

00:02:30.330 --> 00:02:33.330
Sol üstteki Dyson diye İngiliz bir şirketin yaptığı, çok güzel bir

00:02:33.330 --> 00:02:37.330
ev temizlik robotu. Ama ne yazık ki çok pahalıya maloldu. 3.500$.

00:02:37.330 --> 00:02:39.330
Bu yüzden piyasaya sürmediler.

00:02:39.330 --> 00:02:42.330
Ama şu sol alttaki Electrolux, şu anda satışta.

00:02:42.330 --> 00:02:44.330
Bu da Karcher'nin yaptığı.

00:02:44.330 --> 00:02:46.330
Sağ alttakini ise 10 sene kadar önce ben laboratuvarımda

00:02:46.330 --> 00:02:49.330
yaptım ve sonunda bir ürüne dönüştürdük.

00:02:49.330 --> 00:02:51.330
Durun size göstereyim.

00:02:51.330 --> 00:02:55.330
Bunu birine hediye edeceğiz. Chris konuşmadan sonra demişti sanırım.

00:02:55.330 --> 00:03:01.330
Bu robotu gidip satın alıyorsunuz ve sizin yerlerinizi süpürüyor.

00:03:05.330 --> 00:03:10.330
İlk açıldığında, gittikçe büyüyen çemberler çizerek dönmeye başlıyor.

00:03:10.330 --> 00:03:14.330
Birşeye çarparsa -- gördünüz mü?

00:03:14.330 --> 00:03:17.330
Şu anda duvar takip algoritmasıyla ayağımın çevresinden dolanarak

00:03:17.330 --> 00:03:21.330
etrafını süpürüyor. Tamam, şimdi --

00:03:21.330 --> 00:03:26.330
Of, Rice Krispies'imi kim çaldı? Rice Krispies'imi çalmışlar.

00:03:26.330 --> 00:03:32.330
(Gülüşmeler)

00:03:32.330 --> 00:03:35.330
Sakin olun, rahatlayın, hayır, robot bu, akıllı.

00:03:35.330 --> 00:03:38.330
(Gülüşmeler)

00:03:38.330 --> 00:03:42.330
Üç yaşındakı çocuklar hiç robota bir şey olacak diye dertlenmiyor.

00:03:42.330 --> 00:03:44.330
Sadece yetişkinlere dokunuyor nedense.

00:03:44.330 --> 00:03:45.330
(Gülüşmeler)

00:03:45.330 --> 00:03:47.330
Buraya biraz çer çöp koyalım.

00:03:47.330 --> 00:03:51.330
(Gülüşmeler)

00:03:51.330 --> 00:03:53.330
Tamam.

00:03:53.330 --> 00:03:57.330
(Gülüşmeler)

00:03:57.330 --> 00:04:00.330
Görebiliyor musunuz bilmiyorum. Buraya biraz Rice Krispies döktüm.

00:04:00.330 --> 00:04:07.330
Birkaç bozuk para koydum. Bakalım ne yapacak, temizleyebilecek mi?

00:04:10.330 --> 00:04:12.330
Evet, işte.

00:04:12.330 --> 00:04:16.330
Tamam bunu şimdilik bırakalım.

00:04:16.330 --> 00:04:21.330
(Alkışlar)

00:04:22.330 --> 00:04:26.330
Aslında işin büyük kısmı daha iyi temizleme mekanizması geliştirmekti.

00:04:26.330 --> 00:04:30.330
Yapay zekası oldukça basit.

00:04:30.330 --> 00:04:32.330
Aslında bu birçok robot için böyle.

00:04:32.330 --> 00:04:36.330
Sanırım, hepimiz sayısal şovenist gibi bir şeylere dönüştük,

00:04:36.330 --> 00:04:38.330
hesaplamanın her şey olduğunu düşünüyoruz,

00:04:38.330 --> 00:04:40.330
ama mekanik hâlâ çok önemli.

00:04:40.330 --> 00:04:43.330
Bu da birkaç yıldır geliştirdiğimiz,

00:04:43.330 --> 00:04:45.330
başka bir robot, PackBot.

00:04:45.330 --> 00:04:51.330
Bir askeri istihbarat robotu. Birliklerin önünden gidip,

00:04:51.330 --> 00:04:54.330
mağaraları inceliyor mesela.

00:04:54.330 --> 00:04:56.330
Ama tabi bunu oldukça dayanıklı yapmamız gerekti.

00:04:56.330 --> 00:05:03.330
Daha önce laboratuvarda ürettiğimiz tüm robotlardan daha dayanıklı.

00:05:03.330 --> 00:05:06.330
(Gülüşmeler)

00:05:12.330 --> 00:05:16.330
Robotun beyni, üzerinde Linux çalışan bir PC.

00:05:16.330 --> 00:05:22.330
400G'lik şoklara dayanabiliyor. Dahili zekası var:

00:05:22.330 --> 00:05:28.330
kendini düz çevirebiliyor, kapsama alanından çıkarsa geri dönebiliyor,

00:05:28.330 --> 00:05:31.330
kendi kendine merdiven çıkabiliyor vs.

00:05:38.330 --> 00:05:42.330
İşte burada yerel navigasyon yapıyor.

00:05:42.330 --> 00:05:48.330
Bir asker, merdivenleri çıkma emrini verdi, o da çıkıyor.

00:05:49.330 --> 00:05:52.330
Bu pek kontrollü bir iniş sayılmaz.

00:05:52.330 --> 00:05:54.330
(Gülüşmeler)

00:05:54.330 --> 00:05:56.330
Şimdi yoluna devam edecek.

00:05:56.330 --> 00:06:01.330
Aslında bu robotların dönüm noktası 11 Eylül oldu.

00:06:01.330 --> 00:06:05.330
Akşam geç saatte robotları Dünya Ticaret Merkezi'ne götürdük.

00:06:06.330 --> 00:06:08.330
Ana enkazda pek yapabilecekleri bir şey yoktu.

00:06:08.330 --> 00:06:11.330
Orası bayağı -- yapılabilecek bir şey kalmamıştı.

00:06:11.330 --> 00:06:16.330
Ama çevredeki tüm boşaltılan binalara girerek, bir insanın

00:06:16.330 --> 00:06:19.330
girmesi için çok tehlikeli olan yerlerde kısılıp kalan

00:06:19.330 --> 00:06:21.330
felaketzede var mı diye kontrol ettik.

00:06:21.330 --> 00:06:23.330
Şu videoyu oynatalım.

00:06:23.330 --> 00:06:26.330
Muhabir: ...savaş alanı yardımcıları savaş risklerini düşürmekte yardımcı oluyorlar.

00:06:26.330 --> 00:06:29.330
Nick Robertson bildiriyor.

00:06:31.330 --> 00:06:33.330
Rodney Brooks: Bundan başka var mı bizde?

00:06:38.330 --> 00:06:40.330
Peki, güzel.

00:06:43.330 --> 00:06:46.330
Bu robotla iki hafta önce tanışmış olan bir onbaşı.

00:06:48.330 --> 00:06:52.330
Robotları mağaraların içine gönderip, ne olup bittiğine bakıyor.

00:06:52.330 --> 00:06:54.330
Robot tamamen kendi başına hareket ediyor.

00:06:54.330 --> 00:06:58.330
Şimdiye kadar mağarada başımıza gelen en kötü şey,

00:06:58.330 --> 00:07:01.330
robotlardan birinin 10 metre aşağıya düşmesi oldu.

00:07:08.330 --> 00:07:11.330
Bir yıl önce, Amerikan ordusu bu robotlara sahip değildi.

00:07:11.330 --> 00:07:13.330
Artık her gün Afganistan'da aktif görevde kullanılıyorlar.

00:07:13.330 --> 00:07:16.330
İşte bu da, bir robot istilası yaşıyoruz dememin sebeplerinden biri.

00:07:16.330 --> 00:07:20.330
Şu anda teknolojinin gittiği yönde inanılmaz bir değişim yaşanıyor.

00:07:20.330 --> 00:07:22.330
Teşekkürler.

00:07:23.330 --> 00:07:25.330
Önümüzdeki birkaç ay içinde

00:07:25.330 --> 00:07:28.330
çalışan petrol kuyularına girip son birkaç yıllık petrol rezervini

00:07:28.330 --> 00:07:32.330
yüzeye çıkartacak robotlar üreteceğiz.

00:07:32.330 --> 00:07:36.330
Oldukça ölümcül bir ortam, 150 derece sıcaklık, 10.000 PSI.

00:07:36.330 --> 00:07:40.330
Otonom robotlar inip, bu tip işleri yapacak.

00:07:40.330 --> 00:07:43.330
Ama bu tip robotları programlamak biraz zor.

00:07:43.330 --> 00:07:45.330
Gelecekte robotlarımızı nasıl programlayıp,

00:07:45.330 --> 00:07:47.330
kolay kullanılır hale getireceğiz?

00:07:47.330 --> 00:07:50.330
Bunu anlatmak için gerçek bir robot kullanacağım.

00:07:50.330 --> 00:07:55.330
Chris adında bir robot. Ayağa kalk. Tamam.

00:07:57.330 --> 00:08:01.330
Buraya gel. Bakın, robotların sırık yutmuş gibi durması

00:08:01.330 --> 00:08:04.330
gerektiğini düşünüyor. Ama ben --

00:08:04.330 --> 00:08:06.330
Chris Anderson: Ben İngilizim. RB: Ah.

00:08:06.330 --> 00:08:08.330
(Gülüşmeler)

00:08:08.330 --> 00:08:10.330
(Alkışlar)

00:08:10.330 --> 00:08:13.330
Şimdi bu robota bir görev göstereceğim. Oldukça karmaşık bir görev.

00:08:13.330 --> 00:08:16.330
Bakın, kafasını salladı. İletişimin akışını anladığına dair

00:08:16.330 --> 00:08:19.330
bana bir belirti gösterdi.

00:08:19.330 --> 00:08:21.330
Tamamen saçma bir şey söylemiş olsaydım eğer,

00:08:21.330 --> 00:08:24.330
bana yan yan bakıp iletişimi kontrol altına almaya çalışacaktı.

00:08:24.330 --> 00:08:27.330
Şimdi bunu görebileceği bir yere getiriyorum.

00:08:27.330 --> 00:08:31.330
Gözlerine baktım ve gözlerinin şişe kapağına baktığını gördüm.

00:08:31.330 --> 00:08:33.330
Burada bir iş yapıyorum, o da ne yaptığıma bakıyor.

00:08:33.330 --> 00:08:36.330
Gözleri sürekli bir bana, bir de yaptığım işe bakıyor.

00:08:36.330 --> 00:08:38.330
Müşterek bir ilgi odağına sahibiz.

00:08:38.330 --> 00:08:41.330
İşi yaparken izliyor, sonra da ne istediğimi anlamak için

00:08:41.330 --> 00:08:45.330
bana bakıyor. Şimdi şişeyi ona vereceğim.

00:08:45.330 --> 00:08:47.330
Bakalım o da yapabilecek mi? Bunu yapabilir misin?

00:08:47.330 --> 00:08:50.330
(Gülüşmeler)

00:08:50.330 --> 00:08:54.330
Tamam. Bu işte bayağı iyi. Evet. Aferin, aferin.

00:08:54.330 --> 00:08:56.330
Sana onun nasıl yapılacağını göstermedim.

00:08:56.330 --> 00:08:58.330
Bakalım şimdi tekrar birleştirebilecek misin?

00:08:58.330 --> 00:09:00.330
(Gülüşmeler)

00:09:00.330 --> 00:09:01.330
Robotların yavaş olması gerektiğini düşünüyor bir de.

00:09:01.330 --> 00:09:03.330
İyi robot, aferin.

00:09:03.330 --> 00:09:05.330
Evet burada birkaç şey yaptık.

00:09:06.330 --> 00:09:09.330
Birisine bir şeyin nasıl yapılacağını göstermeye çalışırken

00:09:09.330 --> 00:09:13.330
görsel dikkatini yönlendirdiğimizi gördük.

00:09:13.330 --> 00:09:17.330
Diğer nokta da, karşımızdaki bize kendi içsel durumunu,

00:09:17.330 --> 00:09:20.330
bizi anlayıp anlamadığını belirterek, sosyal etkileşimi yönlendirdi.

00:09:20.330 --> 00:09:22.330
Aynı şeye bakarken aramızda müşterek bir ilgi odağı oluştu.

00:09:22.330 --> 00:09:26.330
Ve son olarak da sosyal olarak aktarılan takdiri de algıladı.

00:09:26.330 --> 00:09:29.330
İşte laboratuvar robotlarımıza bunları yaptırmak istiyoruz,

00:09:29.330 --> 00:09:33.330
çünkü gelecekte robotlarla bu şekilde iletişim kurmak isteyeceğinizi düşünüyoruz.

00:09:33.330 --> 00:09:35.330
Burada size bir teknik çizim göstermek istiyorum.

00:09:35.330 --> 00:09:39.330
Sosyal olarak iletişim kurabilieceğiniz bir robotta en önemli şey,

00:09:39.330 --> 00:09:41.330
görsel dikkat sistemidir.

00:09:41.330 --> 00:09:44.330
Çünkü o sırada dikkatini yönelttiği şey, gördüğü ve

00:09:44.330 --> 00:09:47.330
etkileşimde bulunduğu şeydir. Ve bu sayede neyle ilgilendiğini anlayabilirsiniz.

00:09:47.330 --> 00:09:50.330
Şimdi size göstereceğim videolarda

00:09:50.330 --> 00:09:54.330
bir robotun görsel dikkat sistemini göreceksiniz.

00:09:54.330 --> 00:09:58.330
HSV renk uzayında ten rengini arıyor,

00:09:58.330 --> 00:10:02.330
tüm insan ten renklerini algılayabiliyor.

00:10:02.330 --> 00:10:04.330
Oyuncakların doygun renklerini arıyor.

00:10:04.330 --> 00:10:06.330
Ve hareket eden şeyleri arıyor.

00:10:06.330 --> 00:10:09.330
Bütün bunları, bir dikkat penceresi dahilinde belirli ağırlıklarla toplayıp

00:10:09.330 --> 00:10:11.330
en yüksek puanı alan, dolayısıyla

00:10:11.330 --> 00:10:13.330
en ilginç şeylerin olduğu alanı buluyor.

00:10:13.330 --> 00:10:17.330
Ve bakışını oraya yönlendirerek

00:10:17.330 --> 00:10:19.330
direkt oraya bakıyor.

00:10:19.330 --> 00:10:22.330
Bu sırada da yukarıdan aşağıya çalışan bir işlev

00:10:22.330 --> 00:10:25.330
yalnız olduğuna karar verip ten rengi aramaya,

00:10:25.330 --> 00:10:28.330
veya canının sıkıldığına karar verip bir oyuncak aramaya karar verebilir.

00:10:28.330 --> 00:10:30.330
Böylece ağırlıklar değişir.

00:10:30.330 --> 00:10:32.330
Ve burada sağdaki de

00:10:32.330 --> 00:10:35.330
Steven Spielberg hatıra modülü ismini verdiğimiz modül.

00:10:35.330 --> 00:10:37.330
AI filmini gördünüz mü? Seyirciler: Evet.

00:10:37.330 --> 00:10:39.330
RB: Evet, bayağı kötü bir filmdi ama --

00:10:39.330 --> 00:10:43.330
Küçük robot Haley Joel Osment'in gözlerini ayırmadan

00:10:43.330 --> 00:10:47.330
2.000 yıl boyunca mavi periye baktığını hatırlıyor musunuz?

00:10:47.330 --> 00:10:49.330
İşte bu, o problemi çözüyor.

00:10:49.330 --> 00:10:53.330
Aynı şeye baktığı sürece negatife düşüp genliği artan bir

00:10:53.330 --> 00:10:56.330
Gauss alışma fonksiyonu.

00:10:56.330 --> 00:10:59.330
Böylece baktığı şeyden bir süre sonra sıkılıp, başka bir şeye bakıyor.

00:10:59.330 --> 00:11:03.330
Böylece -- işte bir robot daha, işte Kismet.

00:11:03.330 --> 00:11:07.330
Bir oyuncak arıyor. Neye baktığını anlayabilirsiniz.

00:11:07.330 --> 00:11:12.330
Ne yöne baktığı, kamerasının önünde duran gözbebeklerinden belli oluyor.

00:11:12.330 --> 00:11:15.330
Oyuncağı ne zaman gördüğünü anlayabiliyorsunuz.

00:11:15.330 --> 00:11:17.330
Bakın, ufak bir duygusal tepki verdi.

00:11:17.330 --> 00:11:18.330
(Gülüşmeler)

00:11:18.330 --> 00:11:20.330
Ama hâlâ görüş alanına daha önemli bir şey girerse,

00:11:20.330 --> 00:11:24.330
dikkatini oraya yönlendirebilir.

00:11:24.330 --> 00:11:28.330
Mesela sağdan görüş alanına giren Cynthia Breazeal. Bu robotun yapımcısı.

00:11:28.330 --> 00:11:33.330
İşte onu görüyor ve dikkatini ona yönlendiriyor.

00:11:33.330 --> 00:11:37.330
Kismet'in altyapısında üç boyutlu bir duygu uzayı var.

00:11:37.330 --> 00:11:40.330
Duygusal olarak ne durumda olduğunu gösteren bir vektör uzayı.

00:11:40.330 --> 00:11:45.330
O uzayın farklı noktalarında, farklı --

00:11:46.330 --> 00:11:48.330
burada sesi biraz açabilir miyiz?

00:11:48.330 --> 00:11:50.330
Oradan duyabiliyor musunuz? Seyirciler: Evet.

00:11:50.330 --> 00:11:55.330
Kismet: Öyle mi düşünüyorsun? Öyle mi düşünüyorsun?

00:11:57.330 --> 00:11:59.330
Öyle mi düşünüyorsun?

00:12:00.330 --> 00:12:03.330
RB: Gördüğünüz gibi duygularını suratıyla ve

00:12:03.330 --> 00:12:05.330
sesindeki tonlama ile ifade ediyor.

00:12:05.330 --> 00:12:09.330
Ben de burada kendi robotum Chris'le uğraşırken,

00:12:09.330 --> 00:12:12.330
o da benim sesimdeki tonlamaya dikkat ediyordu.

00:12:12.330 --> 00:12:17.330
Burada, annelerin çocuklarına henüz dili anlamaya başlamadan önce

00:12:17.330 --> 00:12:21.330
verdikleri dört temel mesajı baz alıyoruz.

00:12:21.330 --> 00:12:24.330
Burada tecrübesiz denekler robotu övüyor.

00:12:26.330 --> 00:12:28.330
Ses: Tatlı robot.

00:12:29.330 --> 00:12:31.330
Sen çok şirin bir robotsun.

00:12:31.330 --> 00:12:33.330
(Gülüşmeler)

00:12:33.330 --> 00:12:35.330
Robot da ona göre tepki veriyor.

00:12:35.330 --> 00:12:39.330
Ses: ...aferin Kismet.

00:12:40.330 --> 00:12:42.330
(Gülüşmeler)

00:12:42.330 --> 00:12:44.330
Ses: Gülümsememe bak.

00:12:46.330 --> 00:12:49.330
RB: Aslında robot gülümsüyor, kadın da gülümsemeyi taklit ediyor. Bu çok oluyor.

00:12:49.330 --> 00:12:51.330
Bunlar tecrübesiz denekler.

00:12:51.330 --> 00:12:54.330
Burada robotun dikkatini çekmeye çalışmalarını

00:12:54.330 --> 00:12:57.330
ve dikkatini çektiklerini düşündüklerinde belirtmelerini istedik.

00:12:57.330 --> 00:13:01.330
Ses: Hey, Kismet. Ah, işte.

00:13:01.330 --> 00:13:05.330
RB: Robotun dikkatini çekebildiğini anladı.

00:13:08.330 --> 00:13:12.330
Ses: Kismet, oyuncağı sevdin mi? Oh.

00:13:13.330 --> 00:13:15.330
RB: Burada da robotu engellemelerini söyledik.

00:13:15.330 --> 00:13:19.330
Bu kadın ilk defa robotu gerçekten duygusal olarak köşeye sıkıştırdı.

00:13:19.330 --> 00:13:24.330
Ses: Hayır. Hayır. Onu yapmayacaksın. Hayır.

00:13:24.330 --> 00:13:27.330
(Gülüşmeler)

00:13:27.330 --> 00:13:33.330
Ses: Uygun değil. Hayır. Hayır.

00:13:33.330 --> 00:13:36.330
(Gülüşmeler)

00:13:36.330 --> 00:13:38.330
RB: Bu kadarı yeter.

00:13:38.330 --> 00:13:40.330
Bunları yaptık. Sonra da konuşma sırasını ekledik.

00:13:40.330 --> 00:13:43.330
Biriyle konuşurken, konuşuruz,

00:13:43.330 --> 00:13:47.330
sonra kaşlarımızı kaldırır, gözlerimizi oynatır,

00:13:47.330 --> 00:13:50.330
bir şekilde karşımızdaki insana sıranın kendisinde olduğunu hissettiririz.

00:13:50.330 --> 00:13:54.330
Sonra o konuşur, ve sırayla bayrağı elden ele veririz.

00:13:54.330 --> 00:13:56.330
İşte bunu da bu robota ekledik.

00:13:56.330 --> 00:13:58.330
Tecrübesiz denekler kullandık,

00:13:58.330 --> 00:14:00.330
onlara robot hakkında hiçbir şey anlatmadık,

00:14:00.330 --> 00:14:02.330
onları robotun karşısına oturttuk ve robotla konuşmalarını söyledik.

00:14:02.330 --> 00:14:04.330
Bilmedikleri şey,

00:14:04.330 --> 00:14:06.330
robotun onların dediklerini anlamaması

00:14:06.330 --> 00:14:09.330
ve robotun İngilizce konuşmuyor oluşuydu.

00:14:09.330 --> 00:14:11.330
Sadece rasgele İngilizce fonemler kullanıyordu.

00:14:11.330 --> 00:14:13.330
Şimdi dikkatlice izlemenizi istiyorum, başlangıçta,

00:14:13.330 --> 00:14:17.330
Ritchie, 25 dakikadır robotla konuşan kişi --

00:14:17.330 --> 00:14:19.330
(Gülüşmeler)

00:14:19.330 --> 00:14:21.330
-- diyor ki, "Sana bir şey göstermek istiyorum.

00:14:21.330 --> 00:14:23.330
Sana saatimi göstermek istiyorum."

00:14:23.330 --> 00:14:28.330
ve saati ortaya, robotun görüş alanına getiriyor,

00:14:28.330 --> 00:14:30.330
ona doğru tutuyor, bir duygu sinyali yolluyor

00:14:30.330 --> 00:14:32.330
ve robot saate oldukça başarılı bir şekilde bakıyor.

00:14:32.330 --> 00:14:35.330
Robotun durumunu anlayıp anlamadığı hakkında --

00:14:36.330 --> 00:14:38.330
kafasını çevirişine dikkat.

00:14:38.330 --> 00:14:41.330
Ritchie: Pekala, sana bir şey göstermek istiyorum. Bu bir saat

00:14:41.330 --> 00:14:44.330
kız arkadaşım vermişti.

00:14:44.330 --> 00:14:46.330
Robot: Oh, harika.

00:14:46.330 --> 00:14:50.330
Ritchie: Evet, bak, küçük mavi bir ışığı da var. Bunu geçen hafta az daha kaybediyordum.

00:14:51.330 --> 00:14:55.330
(Gülüşmeler)

00:14:55.330 --> 00:14:58.330
RB: İşte onunla göz teması kuruyor, gözlerini izliyor.

00:14:58.330 --> 00:15:00.330
Ritchie: Aynısını yapabilir misin? Robot: Tabi ki.

00:15:00.330 --> 00:15:02.330
RB: Ve başarılı bir şekilde iletişim kurmuş oluyorlar.

00:15:02.330 --> 00:15:06.330
Ve burada da Chris ve benim yapmakta olduğumuz şeyin başka bir şekli var.

00:15:06.330 --> 00:15:08.330
Bu başka bir robot, Cog.

00:15:08.330 --> 00:15:14.330
Önce göz temasını kuruyorlar, ardından Christie oyuncağa baktığı zaman,

00:15:14.330 --> 00:15:16.330
robot onun baktığı doğrultuyu tahmin ediyor

00:15:16.330 --> 00:15:18.330
ve baktığı şey ne ise ona doğru bakıyor.

00:15:18.330 --> 00:15:19.330
(Gülüşmeler)

00:15:19.330 --> 00:15:22.330
Bu çeşit robotları önümüzdeki 5 yıl içerisinde

00:15:22.330 --> 00:15:24.330
laboratuvarlarda daha fazla göreceğiz.

00:15:24.330 --> 00:15:29.330
Fakat bu durumda önemli sorular çıkıyor, insanların bana sorduğu iki önemli soru:

00:15:29.330 --> 00:15:31.330
eğer bu robotlar daha ve daha fazla insan özelliği taşıyacaksa,

00:15:31.330 --> 00:15:36.330
onları kabul edecek miyiz, haklara ihtiyaç duyacaklar mı?

00:15:36.330 --> 00:15:39.330
Bana sorulan öteki soru ise ileride ele geçirme isteklerinin olup olmayacağı.

00:15:39.330 --> 00:15:40.330
(Gülüşmeler)

00:15:40.330 --> 00:15:43.330
İlkine dönersek -- biliyorsunuz bu birçok filmde görülen

00:15:43.330 --> 00:15:46.330
bir Hollywood teması. Muhtemelen buradaki karakterleri anımsayacaksınız,

00:15:46.330 --> 00:15:50.330
robotlar bu filmlerin her birinde daha fazla saygınlık istiyordu.

00:15:50.330 --> 00:15:53.330
Peki, hiç robotlara daha fazla saygınlık verme ihtiyacı hissettiniz mi?

00:15:54.330 --> 00:15:56.330
Sonuçta onlar sadece makine.

00:15:56.330 --> 00:16:00.330
Fakat bence, bilirsiniz, bizler de sadece makineler olduğumuzu

00:16:00.330 --> 00:16:05.330
kabul etmeliyiz. Bu modern biyolojinin bizim hakkımızda söylediği şey.

00:16:05.330 --> 00:16:08.330
Nasıl olduğuna dair bir açıklama yok, sadece biliyorsunuz,

00:16:08.330 --> 00:16:12.330
A molekülü gelip başka bir molekülle bağ kuruyor.

00:16:12.330 --> 00:16:15.330
Ve çeşitli kuvvetlerce itilerek ileriye gidiyor,

00:16:15.330 --> 00:16:19.330
sonra ruh devreye giriyor ve molekülleri öyle değiştiriyor ki birbirlerine bağlanıyorlar.

00:16:19.330 --> 00:16:22.330
Tamamen mekaniksel, biz mekanizmalarız.

00:16:22.330 --> 00:16:25.330
Eğer biz makineler isek, en azından prensipte

00:16:25.330 --> 00:16:29.330
başka şeylerden en az bizim kadar canlı makineleri

00:16:29.330 --> 00:16:33.330
yapma yeteneğine sahip olmamız gerekir.

00:16:33.330 --> 00:16:35.330
Fakat bunu kabul etmek için,

00:16:35.330 --> 00:16:38.330
özel olduğumuz düşüncesinden bir yönüyle vazgeçmemiz gerekir.

00:16:38.330 --> 00:16:40.330
Son birkaç yüzyıldır

00:16:40.330 --> 00:16:43.330
bilim ve teknoloji duvarına çarptıkça,

00:16:43.330 --> 00:16:45.330
bu düşüncemizden defalarca taviz verdik.

00:16:45.330 --> 00:16:47.330
Evrenin merkezinde olduğumuz düşüncesini

00:16:47.330 --> 00:16:50.330
500 yıl önce dünya güneşin çevresinde

00:16:50.330 --> 00:16:52.330
dönmeye başladığında bırakmak zorundaydık.

00:16:52.330 --> 00:16:57.330
150 yıl önce Darwin sayesinde hayvanlardan ayrı olduğumuz düşüncesini bırakmak zorunda kaldık.

00:16:57.330 --> 00:17:00.330
Ve tahmin ettiğiniz gibi bu bizim için her zaman sancılı oldu.

00:17:00.330 --> 00:17:03.330
Burada, dünyada kendimize ait bir yaradılış olayının

00:17:03.330 --> 00:17:05.330
olmayabileceği fikri son zamanlarda bizi oldukça sarsmıştı.

00:17:05.330 --> 00:17:08.330
İnsanlar bundan hoşlanmadı. Sonra insan genomu bize

00:17:08.330 --> 00:17:11.330
sadece 35.000 genden ibaret olabileceğimizi söyledi. Bu gerçekten --

00:17:11.330 --> 00:17:14.330
insanlar bunu sevmediler, bundan daha fazla gene sahip olmalıydık.

00:17:14.330 --> 00:17:17.330
Özel olduğumuz düşüncesini bırakmayı sevmiyoruz, bu yüzden

00:17:17.330 --> 00:17:19.330
robotların gerçekten duyguları olabileceği

00:17:19.330 --> 00:17:21.330
ya da robotların yaşayan canlılar olabileceği

00:17:21.330 --> 00:17:23.330
fikrini bence kabullenmekte zorlanacağız.

00:17:23.330 --> 00:17:27.330
Fakat aşağı yukarı sonraki 50 yıl içinde bunu kabulleneceğiz.

00:17:27.330 --> 00:17:30.330
İkinci soru: makineler yönetimi ele geçirmek isteyecekler mi?

00:17:30.330 --> 00:17:35.330
Alışılmış senaryoya göre biz bunları yaparız,

00:17:35.330 --> 00:17:38.330
büyürler, onları besleriz, bizden çok şey öğrenirler

00:17:38.330 --> 00:17:42.330
ve sonra bizim oldukça sıkıcı ve yavaş olduğumuzu düşünmeye başlarlar.

00:17:42.330 --> 00:17:44.330
İktidarı bizden alırlar.

00:17:44.330 --> 00:17:47.330
Aranızda ergen çocukları olanlar ne demek istediğimi anlamıştır.

00:17:47.330 --> 00:17:48.330
(Gülüşmeler)

00:17:48.330 --> 00:17:51.330
Fakat Hollywood bunu robotlara taşıdı.

00:17:51.330 --> 00:17:54.330
Sorulan soru şu:

00:17:54.330 --> 00:17:58.330
birileri kazara iktidarı ele geçirmek isteyecek bir robot yapar mı?

00:17:58.330 --> 00:18:01.330
Bu arka bahçedeki şu yalnız çocuğu andırıyor,

00:18:01.330 --> 00:18:04.330
var ya "Kazara bir 747 inşa ettim."

00:18:04.330 --> 00:18:06.330
Bunun gerçekleşeceğini sanmıyorum

00:18:06.330 --> 00:18:08.330
ve zannetmiyorum ki --

00:18:08.330 --> 00:18:09.330
(Gülüşmeler)

00:18:09.330 --> 00:18:12.330
-- zannetmiyorum ki bile bile sorun yaratacak

00:18:12.330 --> 00:18:14.330
robotlar yapalım.

00:18:14.330 --> 00:18:16.330
Birden süper kötü bir robot yapılmayacaktır.

00:18:16.330 --> 00:18:19.330
Buna gelene kadar önce orta kötülükte bir robot,

00:18:19.330 --> 00:18:21.330
ondan önce de fazla kötülüğü olmayan bir robot.

00:18:21.330 --> 00:18:22.330
(Gülüşmeler)

00:18:22.330 --> 00:18:24.330
Bunun böyle gitmesine izin vermeyiz herhalde.

00:18:24.330 --> 00:18:25.330
(Gülüşmeler)

00:18:25.330 --> 00:18:31.330
Yani bu konuyu şuraya bağlayacağım: robotlar geliyorlar.

00:18:31.330 --> 00:18:34.330
Bunun hakkında fazla endişe etmeye gerek yok, oldukça eğlenceli olacak

00:18:34.330 --> 00:18:38.330
ve ümit ediyorum ki hepiniz sonraki 50 senelik yolculukta epeyce eğleneceksiniz.

00:18:38.330 --> 00:18:40.330
(Alkışlar)

