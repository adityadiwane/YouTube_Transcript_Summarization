WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Martino Caldarella
Revisore: Michele Gianella

00:00:18.330 --> 00:00:23.330
Vorrei parlarvi di come vedo i robot invadere le nostre vite,

00:00:23.330 --> 00:00:26.330
a vari livelli e su diverse scale temporali.

00:00:26.330 --> 00:00:30.330
Quando penso al futuro, ai prossimi 500 anni, non riesco a immaginare un mondo

00:00:30.330 --> 00:00:32.330
dove non ci siano robot dappertutto.

00:00:32.330 --> 00:00:37.330
Assumendo, malgrado tutte le funeste previsioni che molta gente ha fatto sul nostro avvenire,

00:00:37.330 --> 00:00:41.330
che ci saremo ancora, non riesco proprio a immaginare un mondo senza robot.

00:00:41.330 --> 00:00:44.330
Quindi la domanda è: se tra 500 anni avranno già invaso il mondo,

00:00:44.330 --> 00:00:46.330
li troveremo ovunque anche prima di allora?

00:00:46.330 --> 00:00:48.330
Si saranno già diffusi tra 50 anni?

00:00:48.330 --> 00:00:51.330
Penso che sì, sia abbastanza probabile. Avremo molti robot ovunque.

00:00:51.330 --> 00:00:54.330
Credo anzi che l'invasione accadrà molto prima:

00:00:54.330 --> 00:00:58.330
a mio avviso, la diffusione dei robot è imminente,

00:00:58.330 --> 00:01:04.330
come negli anni 1978-1980 lo era l'arrivo dei personal computer,

00:01:04.330 --> 00:01:07.330
e i primi robot stanno già cominciando ad apparire.

00:01:07.330 --> 00:01:11.330
I computer fecero il loro primo ingresso attraverso giochi e giocattoli,

00:01:11.330 --> 00:01:14.330
e il primo computer che la maggior parte della gente ha avuto in casa

00:01:14.330 --> 00:01:16.330
forse è stata la consolle per giocare a Pong,

00:01:16.330 --> 00:01:18.330
con un piccolo microprocessore inserito,

00:01:18.330 --> 00:01:21.330
e poi gli altri giochi che arrivarono in seguito.

00:01:21.330 --> 00:01:24.330
E stiamo cominciando a vedere lo stesso fenomeno con i robot:

00:01:24.330 --> 00:01:28.330
LEGO Mindstorms, Furbies... Nessuno ha un Furby, tra voi?

00:01:28.330 --> 00:01:31.330
Ne hanno venduti 38 milioni di esemplari nel mondo.

00:01:31.330 --> 00:01:33.330
Sono piuttosto comuni, e sono dei piccoli,

00:01:33.330 --> 00:01:35.330
semplici robot, con qualche sensore,

00:01:35.330 --> 00:01:37.330
che processano un po' di azioni.

00:01:37.330 --> 00:01:40.330
Sulla destra vedete un'altra bambola robot, in vendita un paio di anni fa.

00:01:40.330 --> 00:01:42.330
E proprio come ai primi tempi del computer,

00:01:42.330 --> 00:01:47.330
che videro molta sperimentazione amatoriale,

00:01:47.330 --> 00:01:51.330
adesso puoi procurarti kit e manuali per smanettare.

00:01:51.330 --> 00:01:55.330
A sinistra vedete una piattaforma della Evolution Robotics, alla quale potete

00:01:55.330 --> 00:01:58.330
collegare un PC e, tramite una GUI, programmare questo oggetto

00:01:58.330 --> 00:02:01.330
in modo che giri per casa vostra, facendo varie cose.

00:02:01.330 --> 00:02:04.330
C'è inoltre una categoria più costosa, una specie di giocattoli robot -

00:02:04.330 --> 00:02:08.330
Aibo della Sony. E sulla destra, uno sviluppato dalla NEC,

00:02:08.330 --> 00:02:11.330
il PaPeRo, che non credo abbiano intenzione di distribuire.

00:02:11.330 --> 00:02:14.330
Nondimeno, questo tipo di aggeggi esistono.

00:02:14.330 --> 00:02:18.330
Sono anche apparsi, negli ultimi 2 o 3 anni, robot tagliaerba:

00:02:18.330 --> 00:02:24.330
Husqvarna in basso, Friendly Robotics in alto, un'azienda israeliana.

00:02:24.330 --> 00:02:26.330
Negli ultimi 12 mesi circa, poi,

00:02:26.330 --> 00:02:30.330
sono usciti molti robot per le pulizie domestiche.

00:02:30.330 --> 00:02:33.330
In alto a sinistra ce n'è uno davvero ottimo, fatto

00:02:33.330 --> 00:02:37.330
da un'azienda chiamata Dyson, nel Regno Unito. Solo che era troppo costoso

00:02:37.330 --> 00:02:39.330
(3.500 dollari) e non l'hanno distribuito.

00:02:39.330 --> 00:02:42.330
In basso a sinistra potete vedere quello dell'Electrolux, in vendita.

00:02:42.330 --> 00:02:44.330
Un altro della Karcher. Quello in basso a destra

00:02:44.330 --> 00:02:46.330
l'ho costruito nel mio laboratorio

00:02:46.330 --> 00:02:49.330
circa 10 anni fa, e finalmente l'abbiamo messo in produzione.

00:02:49.330 --> 00:02:51.330
Fatemelo presentare.

00:02:51.330 --> 00:02:55.330
Cominceremo a distribuirlo, mi pare che Chris l'abbia già detto, dopo la presentazione.

00:02:55.330 --> 00:03:01.330
Questo è un robot in vendita. Pulisce il pavimento.

00:03:05.330 --> 00:03:10.330
Parte girando in tondo, in cerchi sempre crescenti.

00:03:10.330 --> 00:03:14.330
E se colpisce qualcosa... Avete visto?

00:03:14.330 --> 00:03:17.330
Adesso sta comincia ad aggirare il "muro", sta aggirando i miei piedi

00:03:17.330 --> 00:03:21.330
per pulire tutto intorno a me. Vediamo...

00:03:21.330 --> 00:03:26.330
Ehi, chi ha rubato i miei Rice Krispies? Mi hanno rubato i Rice Krispies!

00:03:26.330 --> 00:03:32.330
(Risate)

00:03:32.330 --> 00:03:35.330
Non preoccupatevi. È un robot intelligente.

00:03:35.330 --> 00:03:38.330
(Risate)

00:03:38.330 --> 00:03:42.330
I bambini di tre anni prendono confidenza subito.

00:03:42.330 --> 00:03:44.330
Sono i grandi, che si agitano.

00:03:44.330 --> 00:03:45.330
(Risate)

00:03:45.330 --> 00:03:47.330
Mettiamo qui un po' di schifezze...

00:03:47.330 --> 00:03:51.330
(Risate)

00:03:51.330 --> 00:03:53.330
Ok.

00:03:53.330 --> 00:03:57.330
(Risate)

00:03:57.330 --> 00:04:00.330
Non so se riuscite a vedere... Ho gettato una manciata di Rice Krispies

00:04:00.330 --> 00:04:07.330
e qualche moneta. Vediamo se li pulisce.

00:04:10.330 --> 00:04:12.330
Perfetto, ok. Quindi...

00:04:12.330 --> 00:04:16.330
Lo lascio lì per dopo.

00:04:16.330 --> 00:04:21.330
(Applausi)

00:04:22.330 --> 00:04:26.330
Parte del problema, in realtà, è stata la costruzione di un migliore meccanismo pulente;

00:04:26.330 --> 00:04:30.330
i meccanismi di rilevazione erano abbastanza semplici.

00:04:30.330 --> 00:04:32.330
E la stessa cosa vale per molti robot.

00:04:32.330 --> 00:04:36.330
Siamo tutti diventati, credo, un po' fanatici dell'informatica,

00:04:36.330 --> 00:04:38.330
e crediamo che la programmazione sia tutto.

00:04:38.330 --> 00:04:40.330
Ma la meccanica resta importante.

00:04:40.330 --> 00:04:43.330
Ecco un altro robot, il PackBot,

00:04:43.330 --> 00:04:45.330
che abbiamo prodotto per alcuni anni.

00:04:45.330 --> 00:04:51.330
È un robot di sorveglianza militare, da mandare in avanscoperta,

00:04:51.330 --> 00:04:54.330
ad esempio per esplorare le grotte,

00:04:54.330 --> 00:04:56.330
Ma abbiamo dovuto costruirlo abbastanza robusto,

00:04:56.330 --> 00:05:03.330
molto più robusto dei nostri robot di laboratorio.

00:05:03.330 --> 00:05:06.330
(Risate)

00:05:12.330 --> 00:05:16.330
Il robot monta un PC con sistema operativo Linux.

00:05:16.330 --> 00:05:22.330
Può resistere ad un impatto di 400G. Il robot ha un'intelligenza ambientale:

00:05:22.330 --> 00:05:28.330
può ribaltarsi da solo, connettersi alle linee di comunicazione,

00:05:28.330 --> 00:05:31.330
salire le scale da solo, eccetera.

00:05:38.330 --> 00:05:42.330
Ok, adesso sta esplorando la zona.

00:05:42.330 --> 00:05:48.330
Un soldato gli dà l'ordine di salire le scale, e lui lo fa.

00:05:49.330 --> 00:05:52.330
Quella non era una discesa controllata.

00:05:52.330 --> 00:05:54.330
(Risate)

00:05:54.330 --> 00:05:56.330
Ora ne sta venendo fuori.

00:05:56.330 --> 00:06:01.330
La vera svolta, per questi robot, è stata l'11 Settembre.

00:06:01.330 --> 00:06:05.330
I nostri robot si trovavano al World Trade Center già la sera tardi.

00:06:06.330 --> 00:06:08.330
Non potevano fare molto nella pila di macerie,

00:06:08.330 --> 00:06:11.330
le cose erano troppo... non c'era più niente da fare.

00:06:11.330 --> 00:06:16.330
Ma siamo andati in tutte le strutture circostanti, che erano state evacuate,

00:06:16.330 --> 00:06:19.330
e abbiamo cercato eventuali superstiti negli edifici

00:06:19.330 --> 00:06:21.330
dove era troppo pericoloso entrare.

00:06:21.330 --> 00:06:23.330
Lasciate che vi mostri questo video.

00:06:23.330 --> 00:06:26.330
Reporter: "..sul campo di battaglia, questi strumenti aiutano a ridurre

00:06:26.330 --> 00:06:29.330
i rischi di guerra. Dal nostro inviato Nick Robertson.

00:06:31.330 --> 00:06:33.330
Rodney Brooks: Possiamo vederne un altro?

00:06:38.330 --> 00:06:40.330
Ok, ottimo.

00:06:43.330 --> 00:06:46.330
Solo due settimane prima, il caporale non aveva ancora visto

00:06:48.330 --> 00:06:52.330
questi robot. Ora li sta mandando nelle grotte, a controllare cosa succede.

00:06:52.330 --> 00:06:54.330
Il robot è completamente autonomo.

00:06:54.330 --> 00:06:58.330
La peggior cosa successa ai robot dentro una grotta, finora,

00:06:58.330 --> 00:07:01.330
è stata una caduta da 10 metri.

00:07:08.330 --> 00:07:11.330
Un anno fa, l'esercito americano non aveva questi robot.

00:07:11.330 --> 00:07:13.330
Oggi, in Afghanistan, svolgono lavori importanti

00:07:13.330 --> 00:07:16.330
ogni giorno. Anche per questo parlo di invasione imminente dei robot.

00:07:16.330 --> 00:07:20.330
C'è un cambiamento di rotta su come -- dove la tecnologia sta andando.

00:07:20.330 --> 00:07:22.330
Grazie.

00:07:23.330 --> 00:07:25.330
E nei prossimi due mesi,

00:07:25.330 --> 00:07:28.330
manderemo dei robot all'interno

00:07:28.330 --> 00:07:32.330
di pozzi petroliferi perché estraggano l'ultimo petrolio disponibile.

00:07:32.330 --> 00:07:36.330
Un ambiente veramente ostile: 150 gradi centigradi e una pressione di 700 BAR.

00:07:36.330 --> 00:07:40.330
[Ma] questi robot sono autonomi, andranno giù e faranno il lavoro.

00:07:40.330 --> 00:07:43.330
Robot come questi, tuttavia, sono un po' difficili da programmare.

00:07:43.330 --> 00:07:45.330
Come programmeremo, in futuro, i nostri robot,

00:07:45.330 --> 00:07:47.330
e come li renderemo più facili da utilizzare?

00:07:47.330 --> 00:07:50.330
Be', voglio servirmi di un robot, ora...

00:07:50.330 --> 00:07:55.330
un robot di nome Chris... Alzati. Perfetto. Ok.

00:07:57.330 --> 00:08:01.330
Da questa parte. Adesso notate, lui pensa che i robot debbano essere dei musoni.

00:08:01.330 --> 00:08:04.330
Lui lo è, in un certo senso. Ma sto per...

00:08:04.330 --> 00:08:06.330
Chris Anderson: No, sono solo inglese. RB: Oh.

00:08:06.330 --> 00:08:08.330
(Risate)

00:08:08.330 --> 00:08:10.330
(Applausi)

00:08:10.330 --> 00:08:13.330
Sto per mostrare a questo robot un compito. Un compito veramente difficile.

00:08:13.330 --> 00:08:16.330
Attenzione ora, annuisce, mi sta facendo capire

00:08:16.330 --> 00:08:19.330
di comprendere il flusso di comunicazione.

00:08:19.330 --> 00:08:21.330
E se dicessi qualcosa di completamente bizzarro,

00:08:21.330 --> 00:08:24.330
mi guarderebbe di traverso, e adatterebbe la conversazione.

00:08:24.330 --> 00:08:27.330
Ora gli metto questa di fronte.

00:08:27.330 --> 00:08:31.330
Guardando i suoi occhi, ho visto che fissava la cima della bottiglia.

00:08:31.330 --> 00:08:33.330
Compio questa azione, e lui sta osservando.

00:08:33.330 --> 00:08:36.330
I suoi occhi si muovono avanti e indietro, per vedere cosa sto guardando,

00:08:36.330 --> 00:08:38.330
quindi siamo l'uno attento all'altro.

00:08:38.330 --> 00:08:41.330
Faccio questa azione, lui osserva, e osserva me

00:08:41.330 --> 00:08:45.330
per vedere cosa succederà dopo. Adesso gli consegno la bottiglia, e vediamo

00:08:45.330 --> 00:08:47.330
se riesce ad eseguire il compito. Riesci a farlo?

00:08:47.330 --> 00:08:50.330
(Risate)

00:08:50.330 --> 00:08:54.330
Ok. È abbastanza bravo. Bene, bene.

00:08:54.330 --> 00:08:56.330
Non ti ho mostrato come fare questo.

00:08:56.330 --> 00:08:58.330
Prova a rimetterlo a posto, ora.

00:08:58.330 --> 00:09:00.330
(Risate) Pensa che un robot

00:09:00.330 --> 00:09:01.330
debba essere lentissimo.

00:09:01.330 --> 00:09:03.330
Bravo robot, ottimo lavoro.

00:09:03.330 --> 00:09:05.330
Abbiamo visto alcune cose, dunque.

00:09:06.330 --> 00:09:09.330
Abbiamo visto che quando interagiamo,

00:09:09.330 --> 00:09:13.330
e proviamo a insegnare qualcosa a qualcuno, attiriamo la sua attenzione.

00:09:13.330 --> 00:09:17.330
L'altro ci comunica il suo stato interiore,

00:09:17.330 --> 00:09:20.330
se sta capendo o no, e modula un'interazione sociale.

00:09:20.330 --> 00:09:22.330
L'attenzione di entrambi era sullo stesso oggetto,

00:09:22.330 --> 00:09:26.330
e alla fine riconosce un rinforzo comunicato socialmente.

00:09:26.330 --> 00:09:29.330
Abbiamo cercato, in laboratorio, di inserire tutto questo nei nostri robot,

00:09:29.330 --> 00:09:33.330
perché pensiamo sia così che in futuro vorrete comunicare coi robot.

00:09:33.330 --> 00:09:35.330
Voglio mostrarvi un solo diagramma tecnico.

00:09:35.330 --> 00:09:39.330
Per costruire un robot con cui poter interagire socialmente, la cosa più importante

00:09:39.330 --> 00:09:41.330
è il suo sistema di attenzione visiva.

00:09:41.330 --> 00:09:44.330
Perché il robot presta attenzione a ciò che vede

00:09:44.330 --> 00:09:47.330
e con cui interagisce, e a quello che capisce che stai facendo.

00:09:47.330 --> 00:09:50.330
Nel video che sto per mostrarvi, quindi,

00:09:50.330 --> 00:09:54.330
vedrete un sistema di attenzione visiva in un robot

00:09:54.330 --> 00:09:58.330
che comprende -- cerca una tonalità pelle in uno spazio HSV,

00:09:58.330 --> 00:10:02.330
quindi funziona tramite tutte le colorazioni "umane".

00:10:02.330 --> 00:10:04.330
Cerca colori molto saturi, come i giocattoli.

00:10:04.330 --> 00:10:06.330
Cerca oggetti che si muovono intorno,

00:10:06.330 --> 00:10:09.330
pondera tutti questi oggetti in una finestra d'attenzione,

00:10:09.330 --> 00:10:11.330
e cerca quello col punteggio più alto,

00:10:11.330 --> 00:10:13.330
dove stanno accadendo le cose più interessanti.

00:10:13.330 --> 00:10:17.330
Ed è su quel punto che i suoi occhi si dirigono.

00:10:17.330 --> 00:10:19.330
E lo osserva.

00:10:19.330 --> 00:10:22.330
Nel contempo, possono sopraggiungere altre istanze:

00:10:22.330 --> 00:10:25.330
potrebbe decidere che si sente solo, e cercare una tonalità di pelle,

00:10:25.330 --> 00:10:28.330
o che è annoiato, e cercare un giocattolo con cui giocare.

00:10:28.330 --> 00:10:30.330
E così i pesi dell'equazione cambiano.

00:10:30.330 --> 00:10:32.330
Qui, sulla destra, abbiamo quello

00:10:32.330 --> 00:10:35.330
che chiamiamo "Modulo del ricordo di Steven Spielberg".

00:10:35.330 --> 00:10:37.330
Avete visto il film "AI"? Pubblico: Sì.

00:10:37.330 --> 00:10:39.330
RB: Sì, era davvero pessimo, ma...

00:10:39.330 --> 00:10:43.330
ricordate quando Haley Joel Osment, il piccolo robot,

00:10:43.330 --> 00:10:47.330
restava a guardare la fata turchina per 2000 anni senza distogliere lo sguardo?

00:10:47.330 --> 00:10:49.330
Questo robot ne fa a meno,

00:10:49.330 --> 00:10:53.330
perché ha una gaussiana dell'abitudine che diventa

00:10:53.330 --> 00:10:56.330
sempre più negativa, se osserva una cosa soltanto.

00:10:56.330 --> 00:10:59.330
Così si annoia, e guarda da un'altra parte.

00:10:59.330 --> 00:11:03.330
Ora che tutto è più chiaro... ecco il nostro robot, ecco Kismet

00:11:03.330 --> 00:11:07.330
che sta cercando un giocattolo. Si capisce cosa sta guardando.

00:11:07.330 --> 00:11:12.330
Si intuisce la direzione del suo sguardo guardando gli occhi che che gli coprono la telecamera,

00:11:12.330 --> 00:11:15.330
e quando sta guardando proprio il giocattolo, si capisce.

00:11:15.330 --> 00:11:17.330
Qui c'è una piccola risposta emotiva.

00:11:17.330 --> 00:11:18.330
(Risate)

00:11:18.330 --> 00:11:20.330
Ma continuerà comunque a prestare attenzione

00:11:20.330 --> 00:11:24.330
a qualcos'altro di più significativo, nel caso in cui entrasse nel suo campo visivo --

00:11:24.330 --> 00:11:28.330
come Cynthia Breazeal, che ha costruito questo robot -- sulla destra.

00:11:28.330 --> 00:11:33.330
La vede, le presta attenzione.

00:11:33.330 --> 00:11:37.330
A basso livello, Kismet ha uno "spazio emotivo" vettoriale

00:11:37.330 --> 00:11:40.330
tridimensionale, per elaborare le emozioni.

00:11:40.330 --> 00:11:45.330
E si esprime in punti differenti di questo spazio --

00:11:46.330 --> 00:11:48.330
possiamo alzare il volume?

00:11:48.330 --> 00:11:50.330
Potete sentire adesso, laggiù? Pubblico: Sì.

00:11:50.330 --> 00:11:55.330
Kismet: Lo pensi veramente? Lo pensi veramente?

00:11:57.330 --> 00:11:59.330
Lo pensi veramente?

00:12:00.330 --> 00:12:03.330
RB: Sta esprimendo le sue emozioni attraverso la faccia

00:12:03.330 --> 00:12:05.330
e la prosodia della voce.

00:12:05.330 --> 00:12:09.330
E Chris, il robot, mentre interagivo con lui

00:12:09.330 --> 00:12:12.330
stava misurando la prosodia nella mia voce,

00:12:12.330 --> 00:12:17.330
quindi il robot misura la prosodia in quattro messaggi basilari

00:12:17.330 --> 00:12:21.330
come quelli che le mamme trasmettono ai bambini prima che parlino.

00:12:21.330 --> 00:12:24.330
Alcune soggetti naive, qui, lodano il robot.

00:12:26.330 --> 00:12:28.330
Voce: Bravo robot.

00:12:29.330 --> 00:12:31.330
Sei proprio un piccolo bel robot.

00:12:31.330 --> 00:12:33.330
(Risate)

00:12:33.330 --> 00:12:35.330
E il robot reagisce a tono.

00:12:35.330 --> 00:12:39.330
Voce: ...molto bene, Kismet.

00:12:40.330 --> 00:12:42.330
(Risate)

00:12:42.330 --> 00:12:44.330
Voce: Guarda il mio sorriso.

00:12:46.330 --> 00:12:49.330
RB: Sorride. Sta imitando il sorriso. Questo succede spesso.

00:12:49.330 --> 00:12:51.330
Questi sono soggetti naive.

00:12:51.330 --> 00:12:54.330
In questo caso abbiamo chiesto loro di attirare l'attenzione del robot

00:12:54.330 --> 00:12:57.330
e indicare quando la ottengono.

00:12:57.330 --> 00:13:01.330
Voce: Ehi Kismet, ah, eccolo qua.

00:13:01.330 --> 00:13:05.330
RB: Ecco che capisce di avere la sua attenzione.

00:13:08.330 --> 00:13:12.330
Voce: Kismet, ti piace il giocattolo? Oh.

00:13:13.330 --> 00:13:15.330
RB: Qui abbiamo chiesto di vietare al robot

00:13:15.330 --> 00:13:19.330
qualcosa, e la prima donna chiude davvero il robot in un angolo emotivo.

00:13:19.330 --> 00:13:24.330
Voce: No. No. Non puoi fare questo. No.

00:13:24.330 --> 00:13:27.330
(Risate)

00:13:27.330 --> 00:13:33.330
Voce: Non va bene. No. No.

00:13:33.330 --> 00:13:36.330
(Risate)

00:13:36.330 --> 00:13:38.330
RB: Mi fermo qui. Abbiamo assemblato

00:13:38.330 --> 00:13:40.330
tutto questo, e poi abbiamo inserito i "turni".

00:13:40.330 --> 00:13:43.330
Quando discutiamo con qualcuno, prima parliamo noi,

00:13:43.330 --> 00:13:47.330
poi alziamo le sopracciglia, muoviamo gli occhi,

00:13:47.330 --> 00:13:50.330
e facciamo capire all'altra persona che è il suo turno di parlare.

00:13:50.330 --> 00:13:54.330
Allora parlano loro, e il testimone passa di mano.

00:13:54.330 --> 00:13:56.330
Abbiamo messo nei robot anche questo.

00:13:56.330 --> 00:13:58.330
Abbiamo chiamato alcuni soggetti naive,

00:13:58.330 --> 00:14:00.330
senza dir loro nulla del robot, facendoli sedere

00:14:00.330 --> 00:14:02.330
di fronte al robot e dicendo loro: "Parlategli".

00:14:02.330 --> 00:14:04.330
Loro non sapevano che il robot

00:14:04.330 --> 00:14:06.330
non capiva una parola di quel che dicevano,

00:14:06.330 --> 00:14:09.330
e non "parlava" inglese:

00:14:09.330 --> 00:14:11.330
stava soltanto pronunciando fonemi inglesi a caso.

00:14:11.330 --> 00:14:13.330
Vorrei che guardaste bene l'inizio di questa clip,

00:14:13.330 --> 00:14:17.330
dove questa persona, Ritchie, che ha parlato con il robot per 25 minuti --

00:14:17.330 --> 00:14:19.330
(Risate)

00:14:19.330 --> 00:14:21.330
-- dice: "Voglio mostrarti qualcosa.

00:14:21.330 --> 00:14:23.330
Voglio mostrarti il mio orologio."

00:14:23.330 --> 00:14:28.330
Quindi porta l'orologio al centro del campo visivo del robot,

00:14:28.330 --> 00:14:30.330
lo punta, gli dà un spunto emotivo,

00:14:30.330 --> 00:14:32.330
e il robot guarda l'orologio abbastanza bene.

00:14:32.330 --> 00:14:35.330
Non sappiamo se ha capito o no che il robot --

00:14:36.330 --> 00:14:38.330
Notate lo scambio dei "turni".

00:14:38.330 --> 00:14:41.330
R: Ok, voglio mostrarti qualcosa. Questo è un orologio

00:14:41.330 --> 00:14:44.330
che mi ha dato la mia ragazza.

00:14:44.330 --> 00:14:46.330
Robot: Oh, forte.

00:14:46.330 --> 00:14:50.330
R: Si, guarda, ha anche una piccola luce blu dentro. L'ho quasi perso questa settimana.

00:14:51.330 --> 00:14:55.330
(Risate)

00:14:55.330 --> 00:14:58.330
RB: Sta creando un contatto visivo, seguendo i suoi occhi.

00:14:58.330 --> 00:15:00.330
R: Puoi fare la stessa cosa? Robot: Certo, sicuro.

00:15:00.330 --> 00:15:02.330
RB: E riescono a comunicare, per così dire.

00:15:02.330 --> 00:15:06.330
Ecco ora un altro aspetto di ciò che io e Chris stavamo facendo.

00:15:06.330 --> 00:15:08.330
Questo è un altro robot, Cog.

00:15:08.330 --> 00:15:14.330
Prima creano un contatto visivo, e poi, quando Christie guarda questo giocattolo,

00:15:14.330 --> 00:15:16.330
il robot valuta la direzione del suo sguardo

00:15:16.330 --> 00:15:18.330
e guarda la stessa cosa che lei sta guardando.

00:15:18.330 --> 00:15:19.330
(Risate)

00:15:19.330 --> 00:15:22.330
Perciò vedremo nei laboratori sempre più robot

00:15:22.330 --> 00:15:24.330
come questi, nei prossimi anni.

00:15:24.330 --> 00:15:29.330
Ma la domanda importante, due importanti domande che la gente mi chiede sono:

00:15:29.330 --> 00:15:31.330
se costruiamo questi robot sempre più "umani",

00:15:31.330 --> 00:15:36.330
li accetteremo, avremo -- avranno diritti da rivendicare, ad un certo punto?

00:15:36.330 --> 00:15:39.330
E l'altra domanda che mi si fa è: "Vorranno sostituirsi a noi?"

00:15:39.330 --> 00:15:40.330
(Risate)

00:15:40.330 --> 00:15:43.330
La prima è una domanda molto "hollywoodiana",

00:15:43.330 --> 00:15:46.330
con molti film [sul tema]. Probabilmente riconoscete questi personaggi --

00:15:46.330 --> 00:15:50.330
in ciascuno di questi film, i robot chiedono più rispetto.

00:15:50.330 --> 00:15:53.330
Dovremo mai riconoscere ai robot più rispetto?

00:15:54.330 --> 00:15:56.330
Dopotutto, sono soltanto macchine...

00:15:56.330 --> 00:16:00.330
Be', penso si debba accettare il fatto che [anche] noi siamo soltanto macchine.

00:16:00.330 --> 00:16:05.330
È questo, dopotutto, quello che la biologia molecolare moderna dice su di noi.

00:16:05.330 --> 00:16:08.330
Non troverete mai una descrizione come, per esempio:

00:16:08.330 --> 00:16:12.330
"Compare la molecola A, si lega a quest'altra molecola,

00:16:12.330 --> 00:16:15.330
si muove in avanti, spinta da varie cariche...

00:16:15.330 --> 00:16:19.330
...poi subentra l'anima e pizzica queste molecole in modo che si uniscano."

00:16:19.330 --> 00:16:22.330
È tutto meccanicistico, siamo dei meccanismi.

00:16:22.330 --> 00:16:25.330
E se siamo macchine, allora almeno in linea di principio

00:16:25.330 --> 00:16:29.330
dovremmo poter costruire macchine

00:16:29.330 --> 00:16:33.330
vive quanto noi.

00:16:33.330 --> 00:16:35.330
Ma per ammettere questo, credo sia necessario

00:16:35.330 --> 00:16:38.330
abbandonare la nostra convinzione di essere speciali.

00:16:38.330 --> 00:16:40.330
La nostra "specialità" si è ridotta molte volte,

00:16:40.330 --> 00:16:43.330
almeno negli ultimi secoli, ad ogni progresso

00:16:43.330 --> 00:16:45.330
di scienza e tecnologia.

00:16:45.330 --> 00:16:47.330
500 anni fa abbiamo dovuto rinunciare all'idea

00:16:47.330 --> 00:16:50.330
di essere al centro dell'Universo, quando

00:16:50.330 --> 00:16:52.330
la Terra "cominciò" a girare intorno al Sole;

00:16:52.330 --> 00:16:57.330
150 anni fa, con Darwin, abbiamo dovuto rinunciare all'idea di essere diversi dagli animali.

00:16:57.330 --> 00:17:00.330
E ogni volta è un cambiamento difficile, per noi.

00:17:00.330 --> 00:17:03.330
Di recente, ha iniziato a circolare l'idea che forse non c'è neanche stata

00:17:03.330 --> 00:17:05.330
la Creazione, qui sulla Terra. Un'idea

00:17:05.330 --> 00:17:08.330
che la gente non ha molto amato. Inoltre, stando al genoma umano,

00:17:08.330 --> 00:17:11.330
forse abbiamo solo 35.000 geni. E quello a molta gente

00:17:11.330 --> 00:17:14.330
non è andato giù, [pensavano che] avessimo molti più geni.

00:17:14.330 --> 00:17:17.330
Non ci piace rinunciare alla nostra convinzione di essere speciali. Quindi

00:17:17.330 --> 00:17:19.330
l'idea che i robot possano realmente emozionarsi,

00:17:19.330 --> 00:17:21.330
o possano essere delle creature viventi

00:17:21.330 --> 00:17:23.330
sarà per noi dura da accettare, credo.

00:17:23.330 --> 00:17:27.330
Comunque impareremo ad accettarlo, nei prossimi 50 anni circa.

00:17:27.330 --> 00:17:30.330
E la seconda domanda è: "Le macchine vorranno sostituirci?"

00:17:30.330 --> 00:17:35.330
Lo scenario "classico", in queste riflessioni, è che creiamo queste cose,

00:17:35.330 --> 00:17:38.330
loro crescono, le alleviamo, imparano un sacco da noi...

00:17:38.330 --> 00:17:42.330
... poi loro decidono che siamo piuttosto noiosi, lenti,

00:17:42.330 --> 00:17:44.330
e vogliono prendere il nostro posto.

00:17:44.330 --> 00:17:47.330
Quelli, tra voi, che hanno figli adolescenti sanno di che cosa parlo.

00:17:47.330 --> 00:17:48.330
(Risate)

00:17:48.330 --> 00:17:51.330
Ma Hollywood estende il tema ai robot.

00:17:51.330 --> 00:17:54.330
E la domanda è:

00:17:54.330 --> 00:17:58.330
qualcuno costruirà accidentalmente un robot che ci sostituirà?

00:17:58.330 --> 00:18:01.330
È come se qualcuno, in giardino, da solo,

00:18:01.330 --> 00:18:04.330
dicesse: "Ho costruito un 747 per errore."

00:18:04.330 --> 00:18:06.330
Non penso che succederà mai.

00:18:06.330 --> 00:18:08.330
E non credo --

00:18:08.330 --> 00:18:09.330
(Risate)

00:18:09.330 --> 00:18:12.330
-- non credo che costruiremo deliberatamente robot

00:18:12.330 --> 00:18:14.330
che ci mettano a disagio.

00:18:14.330 --> 00:18:16.330
Non ci sarà un robot super cattivo:

00:18:16.330 --> 00:18:19.330
prima di quel robot, ne uscirà un altro moderatamente cattivo,

00:18:19.330 --> 00:18:21.330
e prima ancora uno non così cattivo.

00:18:21.330 --> 00:18:22.330
(Risate)

00:18:22.330 --> 00:18:24.330
E impediremo loro di prendere quella piega.

00:18:24.330 --> 00:18:25.330
(Risate)

00:18:25.330 --> 00:18:31.330
Quindi credo che concluderò dicendo: i robot stanno arrivando,

00:18:31.330 --> 00:18:34.330
non abbiamo molto di cui preoccuparci, ci sarà da divertirsi un sacco,

00:18:34.330 --> 00:18:38.330
e spero che vi godrete questo viaggio, nei prossimi 50 anni.

00:18:38.330 --> 00:18:40.330
(Applausi)

