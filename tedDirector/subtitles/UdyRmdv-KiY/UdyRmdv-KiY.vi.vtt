WEBVTT
Kind: captions
Language: vi

00:00:00.000 --> 00:00:07.000
Translator: Khoa Nguyễn
Reviewer: Yung Phuong

00:00:18.330 --> 00:00:23.330
Điều mà tôi muốn nói ngày hôm nay là cách mà
tôi nhận thấy sự chế ngự của robot trong cuộc sống chúng ta

00:00:23.330 --> 00:00:26.330
ở nhiều mức độ, nhiều khoảng thời gian.

00:00:26.330 --> 00:00:28.860
Và khi tôi nhìn vào tương lai, tôi 
không thể tưởng tượng được một thế giới

00:00:28.860 --> 00:00:32.330
500 năm sau mà không có robot ở mọi nơi.

00:00:32.330 --> 00:00:37.330
Giả sử -- mặc cho những dự đoán nghiêm trọng về
tương lai từ rất nhiều người --

00:00:37.330 --> 00:00:41.330
giả sử rằng chúng ta còn tồn tại, tôi không thể 
tưởng tượng được một thế giới thiếu robots.

00:00:41.330 --> 00:00:44.330
Và rồi câu hỏi sẽ là, vâng, nếu chúng
sẽ tồn tại trong 500 năm nữa,

00:00:44.330 --> 00:00:46.330
vậy chúng sẽ tràn ngập mọi nơi 
sớm hơn thế hay không?

00:00:46.330 --> 00:00:48.330
Chúng sẽ có mặt xung quanh ta trong vòng 
50 năm nữa hay không?

00:00:48.330 --> 00:00:51.330
Vâng, tôi nghĩ điều đó rất có thể xảy ra
-- sẽ có vô số robots ở mọi nơi.

00:00:51.330 --> 00:00:54.330
Và thực tế thì tôi nghĩ rằng điều đó sẽ 
xảy ra sớm hơn thế.

00:00:54.330 --> 00:00:58.330
Tôi nghĩ rằng chúng ta đang ở đỉnh điểm 
khi robots trở nên phổ biến hơn,

00:00:58.330 --> 00:01:04.330
và tôi nghĩ chúng ta đang ở khoảng 1978-1980
trong những năm của máy tính cá nhân,

00:01:04.330 --> 00:01:07.330
khi những robot đầu tiên bắt đầu xuất hiện.

00:01:07.330 --> 00:01:11.330
Máy tính trở nên phổ biến qua games và đồ chơi.

00:01:11.330 --> 00:01:14.330
Và bạn biết không, chiếc máy tính đầu tiên mà
hầu hết người dân có trong nhà

00:01:14.330 --> 00:01:16.330
có thể là một chiếc máy tính để chơi trò Pong,

00:01:16.330 --> 00:01:18.330
một bộ vi xử lý gắn bên trong,

00:01:18.330 --> 00:01:21.330
và sau đó thì nhiều trò chơi khác ra đời.

00:01:21.330 --> 00:01:24.330
Và chúng ta bắt đầu thấy robot cũng như vậy:

00:01:24.330 --> 00:01:28.330
LEGO Mindstorms, Furbies - ai ở đây 
có một con Furby?

00:01:28.330 --> 00:01:31.330
Vâng, có 38 triệu con Furbies được bán 
trên toàn thế giới.

00:01:31.330 --> 00:01:33.330
Chúng khá phổ biến. Và chúng là những con
robot nhỏ xíu,

00:01:33.330 --> 00:01:35.330
loại robot với vài cảm biến,

00:01:35.330 --> 00:01:37.330
một chút năng lực xử lý thông tin.

00:01:37.330 --> 00:01:40.330
Ở góc phải là một con búp bê robot, thứ mà
bạn có thể mua vài năm trước đây.

00:01:40.330 --> 00:01:42.330
Và cũng như những ngày đầu,

00:01:46.333 --> 00:01:47.330
khi có nhiều sự tương tác giữa 
những người nghiệp dư trên máy tính,

00:01:49.005 --> 00:01:51.330
bạn có thể mua nhiều bộ công cụ hack, 
những cuốn sách dạy hack.

00:01:51.330 --> 00:01:55.330
Và ở phía bên trái là một nền tảng 
từ Evolution Robotics,

00:01:55.330 --> 00:01:58.330
nơi bạn có thể cài đặt trên máy tính,
và viết chương trình với một giao diện đồ họa

00:01:58.330 --> 00:02:01.330
cho nó chạy vòng quanh nhà và 
làm nhiều trò khác.

00:02:01.330 --> 00:02:04.330
Và có những loại robot đồ chơi đắt tiền hơn,

00:02:04.330 --> 00:02:08.330
như Sony Aibo. Và ở bên phải là một robot
mà NEC phát triển,

00:02:08.330 --> 00:02:11.330
con PaPeRo. Tuy nhiên tôi không nghĩ họ sẽ 
đưa nó ra thị trường.

00:02:11.330 --> 00:02:14.330
Nhưng dù sao thì những thứ như thế này
đang ở ngoài kia.

00:02:14.330 --> 00:02:18.330
Và chúng ta đã thấy trong 2-3 năm trở lại đây,
những con robot cắt cỏ,

00:02:18.330 --> 00:02:24.330
Husqvarna ở phía dưới, Friendly Robotics 
ở phía trên, một công ty của Israel.

00:02:24.330 --> 00:02:26.330
Và trong vòng 12 tháng trở lại đây

00:02:26.330 --> 00:02:30.330
chúng ta đã bắt đầu thấy những 
robot dọn nhà xuất hiện.

00:02:30.330 --> 00:02:33.330
Ở góc trên bên trái là một robot lau dọn nhà
khá tốt,

00:02:33.330 --> 00:02:37.330
từ một công ty tên Dyson ở Anh. Chỉ có điều,
nó quá đắt --

00:02:37.330 --> 00:02:39.330
$3,500 -- họ không đưa nó ra thị trường.

00:02:39.330 --> 00:02:42.330
Nhưng ở phía dưới bên trái là Electrolux,
đang được bán trên thị trường.

00:02:42.330 --> 00:02:44.330
Một robot khác từ Karcher.

00:02:44.330 --> 00:02:46.330
Ở phía dưới bên phải là con robot mà tôi 
tạo ra trong phòng thí nghiệm của tôi

00:02:46.330 --> 00:02:49.330
khoảng 10 năm trước, và chúng tôi biến nó
thành một sản phẩm.

00:02:49.330 --> 00:02:51.330
Và hãy để tôi cho các bạn xem.

00:02:51.330 --> 00:02:55.330
Chúng tôi sẽ cho nó đi sau buổi nói chuyện,
Chris nói vậy.

00:02:55.330 --> 00:03:01.330
Đây là một robot bạn có thể mua,
và nó sẽ lau nhà cho bạn.

00:03:05.330 --> 00:03:10.330
Và nó bắt đầu bằng cách đi theo 
vòng tròn ngày một to dần.

00:03:10.330 --> 00:03:14.330
Nếu nó tông vào thứ gì đó -- bạn thấy
không?

00:03:14.330 --> 00:03:17.330
Bây giờ nó đang đi dọc theo tường, 
nó đang đi vòng quanh chân của tôi

00:03:17.330 --> 00:03:21.330
để lau sàn nhà xung quanh tôi. Để xem nào,

00:03:21.330 --> 00:03:26.330
ô, ai lấy Rice Krispies của tôi vậy? Họ 
ăn trộm Rice Krispies của tôi!

00:03:26.330 --> 00:03:32.330
(Cười)

00:03:32.330 --> 00:03:35.330
Đừng lo, thư giãn đi nào, nó là một robot,
nó thông minh mà!

00:03:35.330 --> 00:03:38.330
(Cười)

00:03:38.330 --> 00:03:42.330
Thấy không, những đứa trẻ 3 tuổi, chúng
không lo lắng về điều đó.

00:03:42.330 --> 00:03:44.330
Chỉ người lớn mới lo [con robot rớt xuống].

00:03:44.330 --> 00:03:45.330
(Cười).

00:03:45.330 --> 00:03:47.330
Chúng ta sẽ để một ít rác ở đây.

00:03:47.330 --> 00:03:51.330
(Cười).

00:03:51.330 --> 00:03:53.330
Được rồi.

00:03:53.330 --> 00:03:57.330
(Cười).

00:03:57.330 --> 00:04:00.330
Tôi không biết là các bạn có thấy được hay
không -- tôi để một ít Rice Krispies ở đây,

00:04:00.330 --> 00:04:07.330
một vài đồng xu, chỉ cần chụp hình tại đó, 
xem thử nó có lau dọn sạch không.

00:04:10.330 --> 00:04:12.330
Vâng, được rồi. Xem nào --

00:04:12.330 --> 00:04:16.330
chúng ta sẽ để đó sau.

00:04:16.330 --> 00:04:21.330
(Vỗ tay).

00:04:22.330 --> 00:04:26.330
Một phần của kỹ thuật này là
xây dựng một cơ chế lau dọn tốt hơn, thực ra

00:04:26.330 --> 00:04:30.330
phần 'thông minh' của robot khá đơn giản.

00:04:30.330 --> 00:04:32.330
Và điều đó thì đúng với khá nhiều robot.

00:04:32.330 --> 00:04:36.330
Tôi nghĩ hầu hết chúng ta là những người 
quá tin vào tính toán,

00:04:36.330 --> 00:04:38.330
và nghĩ rằng năng lực tính toán là tất cả,

00:04:38.330 --> 00:04:40.330
nhưng phần cơ khí vẫn rất quan trọng.

00:04:40.330 --> 00:04:43.330
Đây là một robot khác, con PackBot,

00:04:43.330 --> 00:04:45.330
mà chúng tôi đã làm việc với nó nhiều năm.

00:04:45.330 --> 00:04:51.330
Nó là một robot do thám quân sự, dùng để 
đi trước những người lính --

00:04:51.330 --> 00:04:54.330
ví dụ như kiểm tra các hang động.

00:04:55.152 --> 00:04:55.402
Nhưng chúng tôi phải làm cho nó linh hoạt,

00:04:56.330 --> 00:05:03.330
linh hoạt hơn những robot khác chúng tôi 
có trong phòng thí nghiệm.

00:05:03.330 --> 00:05:06.330
(Cười)

00:05:12.330 --> 00:05:16.330
mạch chủ của con robot đó là 
một máy tính chạy hệ điều hành Linux.

00:05:16.330 --> 00:05:22.330
Nó có thể chịu được một cú sốc 400G. Con 
robot có trí thông minh nhân tạo:

00:05:22.330 --> 00:05:28.330
nó có thể tự lật thẳng lại, có thể đưa 
bản thân vào vùng liên lạc,

00:05:28.330 --> 00:05:31.330
có thể tự mình đi lên cầu thang, v.v.

00:05:38.330 --> 00:05:42.330
Nó đang tự định hướng khu vực xung quanh.

00:05:42.330 --> 00:05:48.330
Một người lính cho nó một câu lệnh để 
đi lên cầu thang, và nó đi.

00:05:49.330 --> 00:05:52.330
Và đó không phải là một cú đáp xuống 
được điều khiển.

00:05:52.330 --> 00:05:54.330
(Cười)

00:05:54.330 --> 00:05:56.330
Bây giờ nó chuẩn bị rời đi.

00:05:56.330 --> 00:06:01.330
Và sự bứt phá của những con robot này
thực sự là vụ 11/9.

00:06:01.330 --> 00:06:05.330
Chúng tôi đưa lũ robot tới Trung tâm 
Thương mại Thế giới chiều tối hôm đó.

00:06:06.330 --> 00:06:08.330
Không thể làm gì nhiều trong 
đống đổ nát chính,

00:06:08.330 --> 00:06:11.330
mọi thứ quá -- không còn gì để làm cả.

00:06:11.330 --> 00:06:16.330
Nhưng chúng tôi vào những toà nhà 
xung quanh đã được di tản,

00:06:16.330 --> 00:06:19.330
và tìm kiếm những người sống sót
trong những toà nhà

00:06:19.330 --> 00:06:21.330
quá nguy hiểm cho con người để vào.

00:06:21.330 --> 00:06:23.330
Hãy bắt đầu đoạn video này.

00:06:23.330 --> 00:06:26.330
Phóng viên: ...Những phụ tá chiến trường
đang giúp giảm thiểu rủi ro.

00:06:26.330 --> 00:06:29.330
Sau đây là câu chuyện của Nick Robertson.

00:06:31.330 --> 00:06:33.330
Rodney Brooks: Chúng ta có thể thêm một
cái nữa được không?

00:06:38.330 --> 00:06:40.330
Được rồi, tốt.

00:06:43.330 --> 00:06:46.330
Đây là một hạ sĩ đã làm việc với một robot
hai tuần vừa qua.

00:06:48.330 --> 00:06:52.330
Anh ta đưa những con robot vào các
hang động, xem thử có gì đang diễn ra.

00:06:52.330 --> 00:06:54.330
Con robot đang hoàn toàn tự điều khiển .

00:06:54.330 --> 00:06:58.330
Điều tệ nhất xảy ra trong cái hang
tính tới nay,

00:06:58.330 --> 00:07:01.330
là việc một trong những con robot
rớt xuống từ độ cao 10m.

00:07:08.330 --> 00:07:11.330
Một năm trước, quân đội Mỹ không có những
con robot như thế này.

00:07:11.330 --> 00:07:13.330
Bây giờ chúng đang thực hiện nhiệm vụ ở 
Afghanistan hằng ngày.

00:07:13.330 --> 00:07:16.330
Và đó là một trong những lý do người ta nói
một cuộc xâm lấn bằng robot đang xảy ra.

00:07:16.330 --> 00:07:20.330
Có một biển thay đổi diễn ra ngay lúc này
-- cái đích công nghệ đang hướng tới.

00:07:20.330 --> 00:07:22.330
Xin cảm ơn.

00:07:23.330 --> 00:07:25.330
Và trong vài tháng tới,

00:07:25.330 --> 00:07:28.330
chúng tôi sẽ gửi robot đang trong 
quá trình sản xuất

00:07:28.330 --> 00:07:32.330
xuống những giếng dầu để lấy được những 
thùng dầu cuối cùng khỏi mặt đất.

00:07:32.330 --> 00:07:36.330
Những môi trường cực kỳ khắc nghiệt,
150˚ C, 10,000 PSI.

00:07:36.330 --> 00:07:40.330
Robot tự động đi xuống, làm những việc
đại loại thế.

00:07:40.330 --> 00:07:43.330
Nhưng robot như vậy thì hơi khó lập trình.

00:07:43.330 --> 00:07:45.330
Làm thế nào để trong tương lai, chúng ta
có thể lập trình robot

00:07:45.330 --> 00:07:47.330
và khiến chúng dễ sử dụng hơn?

00:07:47.330 --> 00:07:50.330
Và tôi muốn thực sự dùng một robot ở đây -

00:07:50.330 --> 00:07:55.330
con robot tên là Chris -- 
đứng lên nào. Đúng rồi.

00:07:57.330 --> 00:08:01.330
Đi lại đây nào. Hãy chú ý, anh ta
nghĩ là robot phải hơi cứng đơ như vậy.

00:08:01.330 --> 00:08:04.330
Anh ta làm đại loại thế. Nhưng tôi sẽ --

00:08:04.330 --> 00:08:06.330
Chris Anderson: Tôi chỉ là người Anh.
Rodney Brooks: Oh.

00:08:06.330 --> 00:08:08.330
(Cười)

00:08:08.330 --> 00:08:10.330
(Vỗ tay)

00:08:10.330 --> 00:08:13.330
Tôi sẽ đưa ra một nhiệm vụ cho robot này.
Nó khá là phức tạp đấy.

00:08:13.330 --> 00:08:16.330
Các bạn thấy không, anh ta gật đầu, 
ra hiệu cho tôi là

00:08:16.330 --> 00:08:19.330
anh ta hiểu được điều tôi đang giao tiếp.

00:08:19.330 --> 00:08:21.330
Và nếu tôi nói gì đó hoàn toàn kỳ cục,

00:08:21.330 --> 00:08:24.330
anh ta sẽ nhìn tôi ngờ vực, và điều chỉnh
lại cuộc hội thoại.

00:08:24.330 --> 00:08:27.330
Bây giờ tôi đưa ra thứ này trước mặt anh ta.

00:08:27.330 --> 00:08:31.330
Tôi nhìn vào mắt anh ta, và tôi thấy là
mắt anh ta cũng nhìn vào cái chai này.

00:08:31.330 --> 00:08:33.330
Và tôi đang làm việc này, và anh ta đang
quan sát.

00:08:33.330 --> 00:08:36.330
Mắt anh ta nhìn qua nhìn lại tôi, để thấy
những gì tôi thấy --

00:08:36.330 --> 00:08:38.330
vậy nên chúng tôi có cùng sự chú ý.

00:08:38.330 --> 00:08:41.330
Và tôi làm việc này, và anh ta nhìn, và
anh ta nhìn tôi

00:08:41.330 --> 00:08:45.330
để thấy cái gì sẽ diễn ra tiếp theo. Và 
bây giờ tôi sẽ đưa anh ta cái chai,

00:08:45.330 --> 00:08:47.330
và hãy xem thử anh ta có làm được không.
Anh có làm được không?

00:08:47.330 --> 00:08:50.330
(Cười)

00:08:50.330 --> 00:08:54.330
Được rồi. Anh ta khá là giỏi. Tốt, tốt, tốt.

00:08:54.330 --> 00:08:56.330
Tôi chưa từng chỉ anh làm việc đó.

00:08:56.330 --> 00:08:58.330
Hãy xem thử anh có thể lắp nó lại không.

00:08:58.330 --> 00:09:00.330
(Cười)

00:09:00.330 --> 00:09:01.330
Và anh ta nghĩ là robot thì phải thật chậm.

00:09:01.330 --> 00:09:03.330
Robot ngoan, tốt lắm.

00:09:03.330 --> 00:09:05.330
Chúng ta vừa thấy một số thứ ở đây.

00:09:06.330 --> 00:09:09.330
Chúng ta thấy khi chúng ta giao tiếp,

00:09:09.330 --> 00:09:13.330
khi chúng ta cố dạy ai đó cách làm gì đó,
chúng ta điều khiển sự chú ý bằng mắt của họ.

00:09:13.330 --> 00:09:17.330
Những thứ khác cho ta thấy tình trạng 
bên trong của họ,

00:09:17.330 --> 00:09:20.330
ví dụ như anh ta có hiểu hay không, 
điều khiển sự tương tác xã hội.

00:09:20.330 --> 00:09:22.330
Có sự chú ý tương đồng khi nhìn vào 
cùng một thứ,

00:09:22.330 --> 00:09:26.330
và cuối cùng nhận thức sự hỗ trợ 
được giao tiếp một cách xã hội.

00:09:26.330 --> 00:09:29.330
Và chúng tôi đã cố gắng đưa điều đó vào 
robot thí nghiệm của mình

00:09:29.330 --> 00:09:33.330
bởi vì chúng tôi nghĩ rằng đó là cách bạn 
muốn giao tiếp với robot trong tương lai.

00:09:33.330 --> 00:09:35.330
Tôi chỉ muốn cho các bạn thấy một bản vẽ
kỹ thuật ở đây.

00:09:35.330 --> 00:09:39.330
Điều quan trọng nhất khi xây dựng một robot
mà bạn có thể giao tiếp xã hội cùng

00:09:39.330 --> 00:09:41.330
là hệ thống chú ý bằng mắt của nó.

00:09:41.330 --> 00:09:44.330
Bởi cái mà nó chú ý tới là cái mà nó thấy

00:09:44.330 --> 00:09:47.330
và tương tác cùng, và đó là cái mà bạn
hiểu là nó đang làm.

00:09:47.330 --> 00:09:50.330
Trong những đoạn video mà tôi chuẩn bị 
cho các bạn xem,

00:09:50.330 --> 00:09:54.330
bạn sẽ thấy một hệ thống chú ý bằng mắt
trên một con robot --

00:09:54.330 --> 00:09:58.330
nó tìm màu da trong không gian HSV,

00:09:58.330 --> 00:10:02.330
vì vậy nó tìm kiếm trên mọi màu da.

00:10:02.330 --> 00:10:04.330
Nó tìm những màu bão hoà, từ đồ chơi.

00:10:04.330 --> 00:10:06.330
Và nó tìm những thứ đang di chuyển 
xung quanh.

00:10:06.330 --> 00:10:09.330
Và nó tính những thứ đó chung lại trong
một cửa sổ chú ý,

00:10:09.330 --> 00:10:11.330
và nó tìm nơi có điểm số cao nhất --

00:10:11.330 --> 00:10:13.330
nơi mà thứ thú vị nhất đang diễn ra --

00:10:13.330 --> 00:10:17.330
và đó là cái mà mắt của nó di chuyển đến.

00:10:17.330 --> 00:10:19.330
Và nó nhìn thẳng vào đó.

00:10:19.330 --> 00:10:22.330
Cùng lúc đó, một vài thứ kiểu định hướng

00:10:22.330 --> 00:10:25.330
có thể quyết định là nó đang cô đơn và tìm
màu da,

00:10:25.330 --> 00:10:28.330
hoặc là nó đang chán và tìm
một thứ đồ chơi để chơi.

00:10:28.330 --> 00:10:30.330
Và những yếu tố này sẽ thay đổi 
trọng lượng trong tính toán của nó.

00:10:30.330 --> 00:10:32.330
Và ở bên phải,

00:10:32.330 --> 00:10:35.330
là một thứ chúng ta gọi là bộ phận ký ức
Steven Spielberg.

00:10:35.330 --> 00:10:37.330
Các bạn đã xem bộ phim "AI" chưa? 
Khán giả: Rồi.

00:10:37.330 --> 00:10:39.330
Vâng, nó khá tệ, nhưng --

00:10:39.330 --> 00:10:43.330
các bạn có nhớ cái cảnh Haley Joel 
Osment, con robot nhỏ

00:10:43.330 --> 00:10:47.330
nhìn vào nàng tiên xanh suốt 2000 năm
mà không rời mắt?

00:10:47.330 --> 00:10:49.330
Vâng, chúng tôi loại bỏ điều đó,

00:10:49.330 --> 00:10:53.330
vì đây là một thói quen Gaussian 
khá tiêu cực,

00:10:53.330 --> 00:10:56.330
và ngày càng gay gắt hơn khi nó nhìn 
vào một thứ.

00:10:56.330 --> 00:10:59.330
Và nó trở nên chán, nên nó sẽ nhìn
một thứ khác.

00:10:59.330 --> 00:11:03.330
Vây nên, khi bạn hiểu điều đó -- và đây là
một robot, Kismet,

00:11:03.330 --> 00:11:07.330
nhìn xung quanh tìm đồ chơi. Bạn có thể 
nhận ra thứ mà nó đang nhìn vào.

00:11:07.330 --> 00:11:12.330
Bạn có thể ước tính hướng nhìn của nó từ
những con mắt giả che cái camera của nó,

00:11:12.330 --> 00:11:15.330
và bạn có thể nhận ra khi nó thực sự nhìn
thấy món đồ chơi.

00:11:15.330 --> 00:11:17.330
Và nó có một ít phản ứng cảm xúc ở đây.

00:11:17.330 --> 00:11:18.330
(Cười)

00:11:18.330 --> 00:11:20.330
Nhưng nó vẫn sẽ chú ý đến

00:11:20.330 --> 00:11:24.330
thứ gì đó quan trọng hơn di chuyển vào 
tầm nhìn của nó --

00:11:24.330 --> 00:11:28.330
ví dụ như Cynthia Breazeal, mẹ đẻ của nó,
từ bên phải.

00:11:28.330 --> 00:11:33.330
Nó thấy cô ấy, chú ý đến cô ấy.

00:11:33.330 --> 00:11:37.330
Kismet có một khoảng không gian cảm xúc 
3 chiều ở bên trong,

00:11:37.330 --> 00:11:40.330
một không gian vector cho cảm xúc của nó.

00:11:40.330 --> 00:11:45.330
Và ở những điểm khác nhau trong không gian
đó, nó thể hiện --

00:11:46.330 --> 00:11:48.330
chúng ta có thể vặn âm thanh to hơn không?

00:11:48.330 --> 00:11:50.330
Các bạn có nghe được chưa?
(Khán giả: Được)

00:11:50.330 --> 00:11:55.330
Kismet: Bạn thực sự nghĩ vậy à?

00:11:57.330 --> 00:11:59.330
Bạn thực sự nghĩ vậy à?

00:12:00.330 --> 00:12:03.330
Nó thể hiện cảm xúc qua khuôn mặt

00:12:03.330 --> 00:12:05.330
và âm điệu trong giọng nói của nó.

00:12:05.330 --> 00:12:09.330
Và khi tôi làm việc với con robot của tôi
ở đây, Chris,

00:12:09.330 --> 00:12:12.330
con robot ấy cũng nghe âm điệu trong
giọng nói của tôi,

00:12:12.330 --> 00:12:17.330
và chúng ta khiến robot đo được âm điệu 
cho 4 tín hiệu cơ bản

00:12:17.330 --> 00:12:21.330
mà các bà mẹ đưa ra cho trẻ con 
trước khi chúng biết nói.

00:12:21.330 --> 00:12:24.330
Ở đây chúng ta có những người ngây thơ
khen ngợi robot:

00:12:26.330 --> 00:12:28.330
Giọng nói: Robot giỏi.

00:12:29.330 --> 00:12:31.330
Bạn là một con robot rất dễ thương.

00:12:31.330 --> 00:12:33.330
(Cười)

00:12:33.330 --> 00:12:35.330
Và con robot phản ứng đúng mực.

00:12:35.330 --> 00:12:39.330
Giọng nói: ...tốt lắm, Kismet.

00:12:40.330 --> 00:12:42.330
(Cười)

00:12:42.330 --> 00:12:44.330
Giọng nói: Nhìn vào nụ cười của tôi này.

00:12:46.330 --> 00:12:49.330
Nó cười. Cô ấy cười.

00:12:49.330 --> 00:12:51.330
Họ là những người ngây thơ.

00:12:51.330 --> 00:12:54.330
Ở đây chúng tôi bảo họ cố gắng chiếm được
sự chú ý của con robot

00:12:54.330 --> 00:12:57.330
và cho chúng tôi biết khi họ đã có sự 
chú ý của nó.

00:12:57.330 --> 00:13:01.330
Giọng nói: Này Kismet, à, nó kìa.

00:13:01.330 --> 00:13:05.330
RB: Cô ấy nhận ra là cô ấy có được 
sự chú ý của con robot.

00:13:08.330 --> 00:13:12.330
Giọng nói: Kismet, bạn có thích đồ chơi
này không? Oh.

00:13:13.330 --> 00:13:15.330
RB: Bây giờ, họ được bảo phải ngăn 
con robot lại,

00:13:15.330 --> 00:13:19.330
và người phụ nữ đầu tiên này thực sự đẩy
con robot vào đường cùng về mặt cảm xúc.

00:13:19.330 --> 00:13:24.330
Giọng nói: Không. Bạn không được làm vậy.
Không.

00:13:24.330 --> 00:13:27.330
(Cười)

00:13:27.330 --> 00:13:33.330
Không đúng. Không.

00:13:33.330 --> 00:13:36.330
(Cười)

00:13:36.330 --> 00:13:38.330
RB: Tôi sẽ dừng tại đó.

00:13:38.330 --> 00:13:40.330
Chúng ta tạo ra [cuộc nói chuyện]. Sau đó
chúng ta nói theo lượt.

00:13:40.330 --> 00:13:43.330
Khi chúng ta nói chuyện với ai đó, 
chúng ta nói.

00:13:43.330 --> 00:13:47.330
Sau đó chúng ta đại loại nhíu lông mày,
di chuyển mắt,

00:13:47.330 --> 00:13:50.330
cho người kia biết là tới lượt họ nói.

00:13:50.330 --> 00:13:54.330
Và họ nói, rồi chúng ta cứ theo lượt 
như thế.

00:13:54.330 --> 00:13:56.330
Chúng tôi đưa điều này vào con robot.

00:13:56.330 --> 00:13:58.330
Chúng tôi có một số đối tượng thí nghiệm
ngây thơ,

00:13:58.330 --> 00:14:00.330
không nói gì với họ về con robot,

00:14:00.330 --> 00:14:02.330
đặt họ ngồi trước con robot và nói,
nói chuyện với con robot đi.

00:14:02.330 --> 00:14:04.330
Cái mà họ không biết là,

00:14:04.330 --> 00:14:06.330
con robot không hiểu một từ nào mà 
họ nói,

00:14:06.330 --> 00:14:09.330
và con robot không nói tiếng Anh.

00:14:09.330 --> 00:14:11.330
Nó chỉ nói những từ tiếng Anh ngẫu nhiên.

00:14:11.330 --> 00:14:13.330
Và tôi muốn các bạn xem kỹ phần đầu
của đoạn video này,

00:14:13.330 --> 00:14:17.330
khi Ritchie, người ngồi nói chuyện với 
con robot trong 25 phút --

00:14:17.330 --> 00:14:19.330
(Cười)

00:14:19.330 --> 00:14:21.330
-- nói, "Tôi muốn cho bạn xem cái này.

00:14:21.330 --> 00:14:23.330
Tôi muốn cho bạn xem đồng hồ của tôi."

00:14:23.330 --> 00:14:28.330
Và anh ta đưa cái mặt đồng hồ vào tầm nhìn
của con robot,

00:14:28.330 --> 00:14:30.330
chỉ vào đó, cho nó một dấu hiệu cử chỉ,

00:14:30.330 --> 00:14:32.330
và con robot nhìn vào cái đồng hồ một cách
khá thành công.

00:14:32.330 --> 00:14:35.330
Chúng ta không biết rằng liệu anh ta hiểu
được hay không rằng con robot --

00:14:36.330 --> 00:14:38.330
-- chú ý sự lần lượt.

00:14:38.330 --> 00:14:41.330
Ritchie: OK, tôi muốn cho bạn xem cái này.
OK, đây là một cái đồng hồ

00:14:41.330 --> 00:14:44.330
mà bạn gái tặng cho tôi.

00:14:44.330 --> 00:14:46.330
Robot: Oh, tuyệt.

00:14:46.330 --> 00:14:50.330
Ritchie: Nhìn này, nó có một cái đèn 
màu xanh bên trong nữa. Tôi suýt mất nó
tuần này.

00:14:51.330 --> 00:14:55.330
(Cười)

00:14:55.330 --> 00:14:58.330
RB: Nó đang tiếp xúc bằng ánh mắt với
anh ta, nhìn theo mắt anh ta.

00:14:58.330 --> 00:15:00.330
Ritchie: Bạn có làm được như vậy không?
Robot: Được thôi.

00:15:00.330 --> 00:15:02.330
RB: Và họ tha2h công khi có được sự giao tiếp
đó.

00:15:02.330 --> 00:15:06.330
Và đây là một khía cạnh khác của việc mà 
Chris và tôi vừa làm.

00:15:06.330 --> 00:15:08.330
Đây là một robot khác, Cog.

00:15:08.330 --> 00:15:14.330
Họ giao tiếp bằng mắt trước, rồi sau đó, 
khi Christie nhìn vào món đồ chơi này,

00:15:14.330 --> 00:15:16.330
con robot ước tính hướng nhìn của cô ấy

00:15:16.330 --> 00:15:18.330
và cùng nhìn vào thứ mà cô ấy đang nhìn.

00:15:18.330 --> 00:15:19.330
(Cười)

00:15:19.330 --> 00:15:22.330
Chúng ta sẽ thấy ngày càng nhiều hơn loại
robot như thế này

00:15:22.330 --> 00:15:24.330
trong vòng vài năm tới trong các phòng 
thí nghiệm.

00:15:24.330 --> 00:15:29.330
Nhưng khi đó, hai câu hỏi lớn mà người ta
hay hỏi tôi là:

00:15:29.330 --> 00:15:31.330
nếu chúng ta tạo ra những robot ngày càng 
giống con người,

00:15:31.330 --> 00:15:36.330
chúng ta có thể chấp nhận chúng không,
chúng có cần các quyền con người không?

00:15:36.330 --> 00:15:39.330
Và câu hỏi thứ 2 là, có khi nào chúng muốn
lật đổ chúng ta không?

00:15:39.330 --> 00:15:40.330
(Cười)

00:15:40.330 --> 00:15:43.330
Và câu hỏi đầu tiên -- nó là một chủ đề 
rất Hollywood

00:15:43.330 --> 00:15:46.330
với khá nhiều bộ phim. Các bạn có thể
nhận ra những nhân vật ở đây --

00:15:46.330 --> 00:15:50.330
-- trong từng trường hợp ở đây, các con 
robot muốn được tôn trọng nhiều hơn.

00:15:50.330 --> 00:15:53.330
Bạn có bao giờ cần phải tôn trọng robot 
không?

00:15:54.330 --> 00:15:56.330
Suy cho cùng, chúng chỉ là những cái máy.

00:15:56.330 --> 00:16:00.330
Nhưng tôi nghĩ rằng, chúng ta cũng cần 
chấp nhận rằng chính chúng ta cũng chỉ là
những cái máy.

00:16:00.330 --> 00:16:05.330
Suy cho cùng, đó là cái mà sinh học
hiện đại nói về chúng ta.

00:16:05.330 --> 00:16:08.330
Bạn không thấy một bản mô tả làm thế nào

00:16:08.330 --> 00:16:12.330
mà phân tử A liên kết với một phân tử khác.

00:16:12.330 --> 00:16:15.330
Và nó di chuyển tới trước, được đẩy bằng
nhiều lực khác nhau,

00:16:15.330 --> 00:16:19.330
và sau đó linh hồn bước vào và vặn vẹo
các phân tử đó để chúng liên kết.

00:16:19.330 --> 00:16:22.330
Tất cả điều đó thuộc về cơ khí. Chúng ta 
là những chiếc máy.

00:16:22.330 --> 00:16:25.330
Nếu chúng ta là máy móc, thì ít nhất 
trên lý thuyết,

00:16:25.330 --> 00:16:29.330
chúng ta có thể xây dựng máy móc từ những thứ khác.

00:16:29.330 --> 00:16:33.330
Chúng cũng sống như chúng ta.

00:16:33.330 --> 00:16:35.330
Nhưng tôi nghĩ nếu chúng ta thừa nhận
điều đó,

00:16:35.330 --> 00:16:38.330
chúng ta phải từ bỏ sự đặc biệt của mình
theo một cách nào đó.

00:16:38.330 --> 00:16:40.330
Và chúng ta đã có sự rút lui từ 
sự đặc biệt

00:16:40.330 --> 00:16:43.330
dưới rào cản của khoa học và công nghệ
khá nhiều lần

00:16:43.330 --> 00:16:45.330
trong vòng vài trăm năm trở lại đây.

00:16:45.330 --> 00:16:47.330
500 năm trước chúng ta phải từ bỏ ý nghĩ

00:16:47.330 --> 00:16:50.330
rằng chúng ta là trung tâm của vũ trụ

00:16:50.330 --> 00:16:52.330
khi Trái đất bắt đầu quay xung quanh 
Mặt trời;

00:16:52.330 --> 00:16:57.330
150 năm trước, với Darwin, chúng ta phải
từ bỏ ý nghĩ rằng chúng ta khác các loài vật.

00:16:57.330 --> 00:17:00.330
Và cứ tưởng tượng -- các bạn thấy đấy, 
nó khá khó cho chúng ta.

00:17:00.330 --> 00:17:03.330
Gần đây chúng ta đang đập vỡ ý nghĩ
rằng có lẽ

00:17:03.330 --> 00:17:05.330
chúng ta còn không có sự kiến tạo của 
riêng mình trên Trái đất.

00:17:05.330 --> 00:17:08.330
Nhiều người không hề thích thế. và sau đó
thì bộ gene của người nói,

00:17:08.330 --> 00:17:11.330
có lẽ chúng ta chỉ có 35,000 gene. Và đó
thực sự là --

00:17:11.330 --> 00:17:14.330
nhiều người không thích thế, chúng ta có 
nhiều gene hơn thế chứ.

00:17:14.330 --> 00:17:17.330
Chúng ta không thích từ bỏ sự đặc biệt của
chính mình, nên các bạn thấy đó,

00:17:17.330 --> 00:17:19.330
cái ý kiến rằng robot có thể có cảm xúc,

00:17:19.330 --> 00:17:21.330
hoặc rằng robot có thể là sinh vật sống,

00:17:21.330 --> 00:17:23.330
tôi nghĩ sẽ khá khó cho chúng ta chấp nhận
điều đó.

00:17:23.330 --> 00:17:27.330
Nhưng chúng ta sẽ chấp nhận nó trong vòng
50 năm tới.

00:17:27.330 --> 00:17:30.330
Và câu hỏi thứ 2 là, robot có muốn lật đổ
chúng ta không?

00:17:30.330 --> 00:17:35.330
Và ở đây kịch bản thường là chúng ta
tạo ra những thứ này,

00:17:35.330 --> 00:17:38.330
chúng phát triển, chúng ta nuôi dưỡng
chúng, chúng học hỏi từ chúng ta,

00:17:38.330 --> 00:17:42.330
và sau đó chúng quyết định rằng chúng ta
khá chậm và nhàm chán.

00:17:42.330 --> 00:17:44.330
Chúng muốn lật đổ chúng ta.

00:17:44.330 --> 00:17:47.330
Và nếu bạn có con tuổi vị thành niên thì
các bạn sẽ hiểu nó giống như thế nào.

00:17:47.330 --> 00:17:48.330
(Cười)

00:17:48.330 --> 00:17:51.330
Nhưng Hollywood mở rộng điều đó tới
lũ robot.

00:17:51.330 --> 00:17:54.330
Và câu hỏi là, bạn biết đấy,

00:17:54.330 --> 00:17:58.330
có khi nào ai đó vô tình tạo ra một robot
có thể lật đổ chúng ta không?

00:17:58.330 --> 00:18:01.330
Và điều đó giống như một anh chàng cô độc
ở sân sau,

00:18:01.330 --> 00:18:04.330
bạn biết đấy -- "Tôi vô tình tạo ra một 
chiếc 747."

00:18:04.330 --> 00:18:06.330
Tôi không nghĩ rằng điều đó sẽ xảy ra.

00:18:06.330 --> 00:18:08.330
Và tôi không nghĩ --

00:18:08.330 --> 00:18:09.330
(Cười)

00:18:09.330 --> 00:18:12.330
-- Tôi không nghĩ chúng ta sẽ cố tình 
tạo ra những robot

00:18:12.330 --> 00:18:14.330
mà chúng ta không cảm thấy dễ chịu
khi sống cùng.

00:18:14.330 --> 00:18:16.330
Chúng ta sẽ không có một con robot cực kỳ
độc ác.

00:18:16.330 --> 00:18:19.330
Trước đó phải có một con robot độc ác 
vừa vừa,

00:18:19.330 --> 00:18:21.330
và trước đó phải có một con robot không 
độc ác mấy.

00:18:21.330 --> 00:18:22.330
(Cười)

00:18:22.330 --> 00:18:24.330
Và chúng ta sẽ không để chúng đi theo
con đường đó.

00:18:24.330 --> 00:18:25.330
(Cười)

00:18:25.330 --> 00:18:31.330
Thế nên, tôi nghĩ tôi nên dừng ở đây: 
thời đại robots đang tới,

00:18:31.330 --> 00:18:34.330
chúng ta không phải lo quá nhiều về nó, 
nó sẽ mang lại nhiều sự vui thích,

00:18:34.330 --> 00:18:38.330
và tôi hi vọng tất cả các bạn tận hưởng
cuộc hành trình qua 50 năm tới.

00:18:38.330 --> 00:18:40.330
(Vỗ tay).

