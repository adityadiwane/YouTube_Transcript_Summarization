WEBVTT
Kind: captions
Language: cs

00:00:00.000 --> 00:00:07.000
Překladatel: Marek Vanžura
Korektor: Kristyna Zavadilova

00:00:18.330 --> 00:00:23.330
To, o čem vám chci dnes vyprávět, je, jak vidím pronikání robotů do našich životů

00:00:23.330 --> 00:00:26.330
na rozličných úrovních, přes mnoho časových stupňů.

00:00:26.330 --> 00:00:30.330
Když se podívám do budoucnosti, nedovedu si představit svět, dejme tomu za 500 let,

00:00:30.330 --> 00:00:32.330
kde bychom neměli všude roboty.

00:00:32.330 --> 00:00:37.330
Předpokládám -- navzdory všem negativistickým předpovědím mnoha lidí o naší budoucnosti --

00:00:37.330 --> 00:00:41.330
předpokládám, že jsme stále zde, nedovedu si představit svět, který by nebyl obydlen roboty.

00:00:41.330 --> 00:00:44.330
A pak je otázkou, když tu budou za pět set let

00:00:44.330 --> 00:00:46.330
zda tu všude nebudou již dříve?

00:00:46.330 --> 00:00:48.330
Budou tu už za 50 let?

00:00:48.330 --> 00:00:51.330
Ano, myslím si, že je to dost možné -- bude tu všude mnoho robotů.

00:00:51.330 --> 00:00:54.330
A ve skutečnosti si myslím, že to bude ještě mnohem dříve.

00:00:54.330 --> 00:00:58.330
Myslím si, že jsme na počátku doby, kdy se roboti stávají běžnými,

00:00:58.330 --> 00:01:04.330
myslím si, že se to dá přirovnat k době osobních počítačů v letech 1978 či 1980,

00:01:04.330 --> 00:01:07.330
kde se začínají objevovat první roboti.

00:01:07.330 --> 00:01:11.330
Počítače se rozšířily skrze hry a hračky.

00:01:11.330 --> 00:01:14.330
A jak víte, první počítač, který měla většina lidí doma,

00:01:14.330 --> 00:01:16.330
mohl být počítač na hraní hry Pong,

00:01:16.330 --> 00:01:18.330
s malým mikroprocesorem,

00:01:18.330 --> 00:01:21.330
a posléze se objevily i další hry.

00:01:21.330 --> 00:01:24.330
A všímáme si, že se to samé děje s roboty:

00:01:24.330 --> 00:01:28.330
LEGO Mindstorms, Furby -- kdo zde -- měl někdo zde Furbyho?

00:01:28.330 --> 00:01:31.330
Ano, po celém světě se jich prodalo 38 milionů.

00:01:31.330 --> 00:01:33.330
Jsou velmi běžní, jsou to malí roboti.

00:01:33.330 --> 00:01:35.330
Jednoduchý robot s pár senzory.

00:01:35.330 --> 00:01:37.330
Je to trocha zpracování podnětů.

00:01:37.330 --> 00:01:40.330
Zde vpravo je jiná robotická panenka, kterou jste si mohli před pár lety pořídit.

00:01:40.330 --> 00:01:42.330
A tak jako na počátcích,

00:01:42.330 --> 00:01:47.330
kdy se rozmohlo mnoho typů amatérské interakce s počítači,

00:01:47.330 --> 00:01:51.330
dnes můžete pořídit různé "bastlicí" soupravy, knihy "jak na to".

00:01:51.330 --> 00:01:55.330
A vlevo je platforma od Evolution Robotics,

00:01:55.330 --> 00:01:58.330
kam vložíte PC a programujete tuto věc skrze GUI (grafické uživatelské rozhraní),

00:01:58.330 --> 00:02:01.330
aby se pohybovala po vašem domě a dělala všemožné věci.

00:02:01.330 --> 00:02:04.330
A tady je něco kapku dražšího, robotické hračky --

00:02:04.330 --> 00:02:08.330
Sony Aibo. A tady vpravo je něco, co vyvinuli v NEC,

00:02:08.330 --> 00:02:11.330
jmenuje se PaPeRo, o kterém si ovšem nemyslím, že by s ním šli na trh.

00:02:11.330 --> 00:02:14.330
Nicméně tamti roboti jsou mezi lidmi.

00:02:14.330 --> 00:02:18.330
A viděli jsme před dvěma či třemi lety roboty na sečení trávníku,

00:02:18.330 --> 00:02:24.330
dole Husqvarna, nahoře izraelská společnost Friendly Robotics.

00:02:24.330 --> 00:02:26.330
A pak v posledních 12 měsících nebo tak nějak

00:02:26.330 --> 00:02:30.330
jsme si začali všímat expanze mnoha uklízecích robotů.

00:02:30.330 --> 00:02:33.330
Nahoře vlevo je velmi pěkný uklízecí robot

00:02:33.330 --> 00:02:37.330
od společnosti s názvem Dyson z Velké Británie. Byl ale velmi drahý --

00:02:37.330 --> 00:02:39.330
3 500 dolarů -- takže jej nedali na trh.

00:02:39.330 --> 00:02:42.330
Ale vlevo dole vidíte Electrolux, který je v prodeji.

00:02:42.330 --> 00:02:44.330
Další je od Karcheru.

00:02:44.330 --> 00:02:46.330
Vpravo dole je jeden, kterého jsem postavil ve své laboratoři

00:02:46.330 --> 00:02:49.330
před zhruba deseti lety a nakonec jsme z něj udělali produkt k prodeji.

00:02:49.330 --> 00:02:51.330
Dovolte mi jej vám ukázat.

00:02:51.330 --> 00:02:55.330
Tohle po přednášce někomu věnujeme, myslím, že Chris říkal, po přednášce.

00:02:55.330 --> 00:03:01.330
Toto je robot, kterého si můžete koupit, bude vám uklízet podlahu.

00:03:05.330 --> 00:03:10.330
Začíná na místě a postupně se točí ve stále větších kruzích.

00:03:10.330 --> 00:03:14.330
Jestliže do něčeho narazí -- vidíte to?

00:03:14.330 --> 00:03:17.330
Teď jezdí kolem mých nohou, jako kdyby objížděl zeď

00:03:17.330 --> 00:03:21.330
a uklízí kolem nich. Pojďme se podívat, pojďme --

00:03:21.330 --> 00:03:26.330
kdo mi ukradl rýžové křupky? Ukradli mi rýžové křupky.

00:03:26.330 --> 00:03:32.330
(Smích)

00:03:32.330 --> 00:03:35.330
Bez obav, v klidu, ne, v klidu, je to robot, je chytrý!

00:03:35.330 --> 00:03:38.330
(Smích)

00:03:38.330 --> 00:03:42.330
Vidíte, tříleté děti by se tím neznepokojovaly.

00:03:42.330 --> 00:03:44.330
Jsou to dospělí, kdo se tím rozrušují.

00:03:44.330 --> 00:03:45.330
(Smích)

00:03:45.330 --> 00:03:47.330
Uděláme tady trochu binec.

00:03:47.330 --> 00:03:51.330
(Smích)

00:03:51.330 --> 00:03:53.330
Fajn.

00:03:53.330 --> 00:03:57.330
(Smích)

00:03:57.330 --> 00:04:00.330
Nevím, jestli to vidíte -- takže, nasypal jsem tady hromádku rýžových křupek,

00:04:00.330 --> 00:04:07.330
přidal pár drobných, zaostřete sem kameru, podívejte, jestli to vyčistí.

00:04:10.330 --> 00:04:12.330
Jo, OK. Takže --

00:04:12.330 --> 00:04:16.330
necháme to na později.

00:04:16.330 --> 00:04:21.330
(Potlesk)

00:04:22.330 --> 00:04:26.330
Část triku byla v tom, postavit lepší čisticí mechanismus,

00:04:26.330 --> 00:04:30.330
inteligence stroje byla skutečně velice prostá.

00:04:30.330 --> 00:04:32.330
A je tomu tak u mnoha robotů.

00:04:32.330 --> 00:04:36.330
Všichni jsme se stali, myslím, výpočetními šovinisty

00:04:36.330 --> 00:04:38.330
a mysleli jsme si, že výpočty jsou všechno,

00:04:38.330 --> 00:04:40.330
ale mechanika stále hraje roli.

00:04:40.330 --> 00:04:43.330
Zde je jiný robot, PackBot,

00:04:43.330 --> 00:04:45.330
kterého jsme pár let vyráběli.

00:04:45.330 --> 00:04:51.330
Je to vojenský průzkumný robot, má jít v čele jednotek

00:04:51.330 --> 00:04:54.330
a například prozkoumávat jeskyně.

00:04:54.330 --> 00:04:56.330
Ale museli jsme jej postavit odolnějším,

00:04:56.330 --> 00:05:03.330
mnohem odolnějším než roboty, které ve svých laboratořích stavíme.

00:05:03.330 --> 00:05:06.330
(Smích)

00:05:12.330 --> 00:05:16.330
V tomto robotovi je PC, na kterém běží Linux.

00:05:16.330 --> 00:05:22.330
Dokáže vydržet přetížení až 400 G. Robot má lokální inteligenci:

00:05:22.330 --> 00:05:28.330
může se přetočit, může se sám dostat do oblasti komunikačního dosahu,

00:05:28.330 --> 00:05:31.330
může stoupat po schodech a podobně.

00:05:38.330 --> 00:05:42.330
Fajn, takže zde provádí lokální navigaci.

00:05:42.330 --> 00:05:48.330
Voják mu dává příkaz stoupat po schodech a on jej vykonává.

00:05:49.330 --> 00:05:52.330
Toto nebyl řízený sestup.

00:05:52.330 --> 00:05:54.330
(Smích)

00:05:54.330 --> 00:05:56.330
Teď se obrátí.

00:05:56.330 --> 00:06:01.330
Skutečný průlom pro tyto roboty bylo 11. září.

00:06:01.330 --> 00:06:05.330
Měli jsme roboty ve Světovém obchodním centru (WTC) ten den v pozdním večeru.

00:06:06.330 --> 00:06:08.330
Nemohli udělat mnoho v hlavních troskách,

00:06:08.330 --> 00:06:11.330
věci byly příliš -- nezbývalo zde nic k práci.

00:06:11.330 --> 00:06:16.330
Ale šli do okolních budov, které byly evakuovány

00:06:16.330 --> 00:06:19.330
a pátrali po možných přeživších v budovách,

00:06:19.330 --> 00:06:21.330
do kterých bylo příliš nebezpečné jít.

00:06:21.330 --> 00:06:23.330
Zapněme si toto video.

00:06:23.330 --> 00:06:26.330
Reportér: … pomocníci na bojišti pomáhají snižovat bojová rizika.

00:06:26.330 --> 00:06:29.330
Nick Robertson má tento příběh.

00:06:31.330 --> 00:06:33.330
Rodney Brooks: Můžeme mít další?

00:06:38.330 --> 00:06:40.330
Dobře, dobrá.

00:06:43.330 --> 00:06:46.330
Takže, toto je desátník, který se s robotem seznámil dva týdny předtím.

00:06:48.330 --> 00:06:52.330
Posílá roboty do jeskyní, aby zkoumali, co se tam děje.

00:06:52.330 --> 00:06:54.330
Roboti jsou zcela samostatní.

00:06:54.330 --> 00:06:58.330
Nejhorší věc, která se v jeskyni zatím stala,

00:06:58.330 --> 00:07:01.330
byla, že jeden z těchto robotů spadl z desetimetrové výšky.

00:07:08.330 --> 00:07:11.330
Před rokem americká armáda tyto roboty neměla.

00:07:11.330 --> 00:07:13.330
Nyní jsou v aktivní službě v Afghánistánu každý den.

00:07:13.330 --> 00:07:16.330
A toto je jeden z důvodů, proč se říká, že probíhá invaze robotů.

00:07:16.330 --> 00:07:20.330
Probíhá obrovská změna jak -- kde se technologie vyvíjí.

00:07:20.330 --> 00:07:22.330
Díky.

00:07:23.330 --> 00:07:25.330
A v dalších pár měsících

00:07:25.330 --> 00:07:28.330
jsme posílali roboty

00:07:28.330 --> 00:07:32.330
pod zem vykopávat ropné vrty k vydolování posledních zbytků ropy na těch pár let.

00:07:32.330 --> 00:07:36.330
Velmi nehostinné prostředí, 150 °C, 10 000 PSI.

00:07:36.330 --> 00:07:40.330
Autonomní roboti se spouští dolů, vykonávají tento typ práce.

00:07:40.330 --> 00:07:43.330
Ale roboti jako tito jsou trochu nároční na programování.

00:07:43.330 --> 00:07:45.330
Jak v budoucnosti budeme programovat naše roboty

00:07:45.330 --> 00:07:47.330
a činit je tak snadněji použitelnými?

00:07:47.330 --> 00:07:50.330
Chci použít robota zde --

00:07:50.330 --> 00:07:55.330
robot jménem Chris -- postav se. Jo. Fajn.

00:07:57.330 --> 00:08:01.330
Pojď sem. Teď si povšimněte, myslí si, že roboti musí být trochu toporný.

00:08:01.330 --> 00:08:04.330
On je toho příkladem. Ale hodlám --

00:08:04.330 --> 00:08:06.330
Chris Anderson: Jsem Brit. RB: Ach.

00:08:06.330 --> 00:08:08.330
(Smích)

00:08:08.330 --> 00:08:10.330
(Potlesk)

00:08:10.330 --> 00:08:13.330
Hodlám robotovi předvést úkol. Je to velmi komplexní úkol.

00:08:13.330 --> 00:08:16.330
Teď si povšimněte, přikývl, dával mi signál,

00:08:16.330 --> 00:08:19.330
že porozuměl toku komunikace.

00:08:19.330 --> 00:08:21.330
A kdybych řekl něco zcela bizarního,

00:08:21.330 --> 00:08:24.330
podíval by se na mne podezřívavě a usměrnil by konverzaci.

00:08:24.330 --> 00:08:27.330
Takže teď tohle před ním vytáhnu.

00:08:27.330 --> 00:08:31.330
Podíval bych se do jeho očí a viděl bych, že se dívá na vršek láhve.

00:08:31.330 --> 00:08:33.330
A já dělám tento úkon a on jej pozoruje.

00:08:33.330 --> 00:08:36.330
Jeho oči kmitají dozadu a dopředu, dívá se na mě, na co se dívám --

00:08:36.330 --> 00:08:38.330
takže sdílíme pozornost.

00:08:38.330 --> 00:08:41.330
A tak dělám tuto úlohu, on sleduje a dívá se na mě,

00:08:41.330 --> 00:08:45.330
co se bude dít dál. A teď mu dám láhev

00:08:45.330 --> 00:08:47.330
a podíváme se, jestli dokáže provést tento úkol. Dokážeš to udělat?

00:08:47.330 --> 00:08:50.330
(Smích)

00:08:50.330 --> 00:08:54.330
Fajn. Je vážně dobrý. Jo. Dobře, dobře, dobře.

00:08:54.330 --> 00:08:56.330
Neukázal jsem ti, jak tohle udělat.

00:08:56.330 --> 00:08:58.330
Teď sledujme, jestli to dokáže vrátit zpět dohromady.

00:08:58.330 --> 00:09:00.330
(Smích)

00:09:00.330 --> 00:09:01.330
A myslí si, že robot musí být skutečně pomalý.

00:09:01.330 --> 00:09:03.330
Dobrý robot, to je dobré.

00:09:03.330 --> 00:09:05.330
Takže jsme zde viděli mnoho věcí.

00:09:06.330 --> 00:09:09.330
Viděli jsme, že když jsme interagovali,

00:09:09.330 --> 00:09:13.330
pokoušeli jsme se ukázat někomu jak něco udělat, řídili jsme jeho vizuální pozornost.

00:09:13.330 --> 00:09:17.330
Jiná věc nám sděluje jejich vnitřní stavy,

00:09:17.330 --> 00:09:20.330
zda rozumí, nebo ne, reguluje sociální interakci.

00:09:20.330 --> 00:09:22.330
Byla zde sdílená pozornost sledující stejnou věc,

00:09:22.330 --> 00:09:26.330
na konci dávání najevo rozpoznání sociální komunikace.

00:09:26.330 --> 00:09:29.330
A snažili jsme se vložit tohle všechno do našich laboratorních robotů,

00:09:29.330 --> 00:09:33.330
protože si myslíme, že toto je to, jak chcete s roboty v budoucnu interagovat.

00:09:33.330 --> 00:09:35.330
Chci vám zde ukázat jeden technický diagram.

00:09:35.330 --> 00:09:39.330
Nejdůležitější věcí pro stavění robota, se kterým chcete sociálně komunikovat,

00:09:39.330 --> 00:09:41.330
je jeho systém vizuální pozornosti.

00:09:41.330 --> 00:09:44.330
Protože to, čemu věnuje pozornost, je to, co vidí

00:09:44.330 --> 00:09:47.330
a s čím interaguje, a čemu rozumíte, co dělá.

00:09:47.330 --> 00:09:50.330
Takže ve videích, které vám ukážu,

00:09:50.330 --> 00:09:54.330
uvidíte systém vizuální pozornosti na robotovi,

00:09:54.330 --> 00:09:58.330
který má -- dívá se po odstínu kůže v HSV prostoru,

00:09:58.330 --> 00:10:02.330
takže to funguje přes všechna lidská zbarvení.

00:10:02.330 --> 00:10:04.330
Dívá se po vysoce saturovaných barvách na hračkách.

00:10:04.330 --> 00:10:06.330
A dívá se po věcech, které se pohybují kolem.

00:10:06.330 --> 00:10:09.330
A váhuje to vše dohromady v okně pozornosti

00:10:09.330 --> 00:10:11.330
a hledá místo s nejvyšší hodnotou --

00:10:11.330 --> 00:10:13.330
tedy tam, kde se děje nejzajímavější věc --

00:10:13.330 --> 00:10:17.330
a sem upře své oči.

00:10:17.330 --> 00:10:19.330
A vypadá to přesně jako zde.

00:10:19.330 --> 00:10:22.330
Ve stejný čas ukázka jiných věcí:

00:10:22.330 --> 00:10:25.330
Může se rozhodnout, že je osamocený a porozhlédne se po odstínu kůže

00:10:25.330 --> 00:10:28.330
nebo se může rozhodnout, že je znuděný a porozhlédne se po hračce, se kterou si může hrát.

00:10:28.330 --> 00:10:30.330
A tak se tyto váhy změní.

00:10:30.330 --> 00:10:32.330
A tady vpravo

00:10:32.330 --> 00:10:35.330
je něco, co nazýváme památný modul Stevena Spielberga.

00:10:35.330 --> 00:10:37.330
Viděli jste film AI? (Publikum: Ano.)

00:10:37.330 --> 00:10:39.330
RB: Jo, ten byl hodně špatný, ale --

00:10:39.330 --> 00:10:43.330
vzpomínáte si na to, když se Haley Joel Osment, malý robot,

00:10:43.330 --> 00:10:47.330
díval na modrou vílu 2000 let aniž by z ní spustil oči?

00:10:47.330 --> 00:10:49.330
Nuže, toho se tento vyvaruje

00:10:49.330 --> 00:10:53.330
díky tomuto návykovému Gaussianu, který se stává záporným

00:10:53.330 --> 00:10:56.330
a stále více intenzivním, pokud se dívá na jednu věc.

00:10:56.330 --> 00:10:59.330
A začne se nudit, takže se začne dívat po něčem jiném.

00:10:59.330 --> 00:11:03.330
Tedy když už tomu rozumíte -- zde je robot, Kismet,

00:11:03.330 --> 00:11:07.330
rozhlížející se po hračce. Můžete říci, na co se dívá.

00:11:07.330 --> 00:11:12.330
Můžete odhadnout jeho směr pohledu z těchto očích bulv, které pokrývají jeho kamery,

00:11:12.330 --> 00:11:15.330
a tedy poznáte, kdy se dívá na hračku.

00:11:15.330 --> 00:11:17.330
A taky to dostalo trochu emocionální odezvy.

00:11:17.330 --> 00:11:18.330
(Smích)

00:11:18.330 --> 00:11:20.330
Ale stále dává pozor,

00:11:20.330 --> 00:11:24.330
zda se nenachází něco zajímavějšího v jeho zorném poli --

00:11:24.330 --> 00:11:28.330
jako třeba Cynthia Breazeal, stavitelka tohoto robta -- zde zprava.

00:11:28.330 --> 00:11:33.330
Vidí ji a věnuje jí pozornost.

00:11:33.330 --> 00:11:37.330
Kismet má zakladní třídimenzionální emocionální prostor,

00:11:37.330 --> 00:11:40.330
vektorový prostor, podle toho, kde se nachází.

00:11:40.330 --> 00:11:45.330
A na různých místech v tomto prostoru se vyjadřuje --

00:11:46.330 --> 00:11:48.330
můžete zde zesílit zvuk?

00:11:48.330 --> 00:11:50.330
Slyšíte to už? (Publikum: Ano.)

00:11:50.330 --> 00:11:55.330
Kismet: Skutečně si to myslíš? Skutečně si to myslíš?

00:11:57.330 --> 00:11:59.330
Skutečně si to myslíš?

00:12:00.330 --> 00:12:03.330
RB: Tedy vyjadřuje své emoce skrze tvář

00:12:03.330 --> 00:12:05.330
a hlasovou prozódii.

00:12:05.330 --> 00:12:09.330
A když jsem pracoval se svým robotem, tady je,

00:12:09.330 --> 00:12:12.330
Chris, jako robot, měřil prozódii mého hlasu,

00:12:12.330 --> 00:12:17.330
a tak máme robota, který měří prozódii ve čtyřech základních zprávách,

00:12:17.330 --> 00:12:21.330
které matky dávají svým dětem pre-lingvisticky.

00:12:21.330 --> 00:12:24.330
Tady máme jedince chválící robota.

00:12:26.330 --> 00:12:28.330
Hlas: Hodný robot.

00:12:29.330 --> 00:12:31.330
Jsi takový rozkošný malý robot.

00:12:31.330 --> 00:12:33.330
(Smích)

00:12:33.330 --> 00:12:35.330
RB: A robot adekvátně reaguje.

00:12:35.330 --> 00:12:39.330
Hlas: …velmi dobrý Kismet.

00:12:40.330 --> 00:12:42.330
(Smích)

00:12:42.330 --> 00:12:44.330
Hlas: Podívej se na můj úsměv.

00:12:46.330 --> 00:12:49.330
RB: Směje se. Imituje úsměv. To se stává často.

00:12:49.330 --> 00:12:51.330
Jsou to lidé, kteří nejsou seznámeni s účelem experimentu.

00:12:51.330 --> 00:12:54.330
Tady jsme je požádali, aby získali robotovu pozornost

00:12:54.330 --> 00:12:57.330
a označili, kdy robotovu pozornost získali.

00:12:57.330 --> 00:13:01.330
Hlas: Hej, Kismete, ach, tady je.

00:13:01.330 --> 00:13:05.330
RB: Takže si uvědomila, že má robotovu pozornost.

00:13:08.330 --> 00:13:12.330
Hlas: Kismete, máš rád hračku? Ach.

00:13:13.330 --> 00:13:15.330
RB: Teď jsme je požádali, aby robotovi něco zakázali,

00:13:15.330 --> 00:13:19.330
a první žena skutečně robota zatlačila do emocionálního rohu.

00:13:19.330 --> 00:13:24.330
Hlas: Ne. Ne. Tohle nedělej. Ne.

00:13:24.330 --> 00:13:27.330
(Smích)

00:13:27.330 --> 00:13:33.330
To je nevhodné. Ne. Ne.

00:13:33.330 --> 00:13:36.330
(Smích)

00:13:36.330 --> 00:13:38.330
RB: Tady bych to zanechal.

00:13:38.330 --> 00:13:40.330
Složíme si to dohromady. Pak si přidáme předávání slova.

00:13:40.330 --> 00:13:43.330
Když s někým mluvíme, mluvíme.

00:13:43.330 --> 00:13:47.330
A rovněž zvedáme obočí, pohybujeme očima,

00:13:47.330 --> 00:13:50.330
dáváme druhé osobě najevo, že se může ujmout slova.

00:13:50.330 --> 00:13:54.330
A pak mluví oni, předáváme si takto štafetu jeden druhému.

00:13:54.330 --> 00:13:56.330
A toto jsme vložili do robota.

00:13:56.330 --> 00:13:58.330
Pozvali jsme několik jedinců,

00:13:58.330 --> 00:14:00.330
neřekli jsme jim nic o robotovi,

00:14:00.330 --> 00:14:02.330
posadili jsme je před robota a řekli jim, ať si s robotem povídají.

00:14:02.330 --> 00:14:04.330
Co oni ale nevěděli, bylo,

00:14:04.330 --> 00:14:06.330
že robot jim nerozuměl ani slovo

00:14:06.330 --> 00:14:09.330
a že robot neuměl mluvit anglicky.

00:14:09.330 --> 00:14:11.330
Jen říkal nahodilé anglické fonémy.

00:14:11.330 --> 00:14:13.330
A chci, abyste si pozorně prohlédli začátek tohoto,

00:14:13.330 --> 00:14:17.330
kde si osoba, Ritchie, povídal s robotem 25 minut.

00:14:17.330 --> 00:14:19.330
(Smích)

00:14:19.330 --> 00:14:21.330
Říká: "Chci ti něco ukázat.

00:14:21.330 --> 00:14:23.330
Chci ti ukázat své hodinky.“

00:14:23.330 --> 00:14:28.330
A zvedá své hodinky do robotova zorného pole,

00:14:28.330 --> 00:14:30.330
ukazuje na ně, dává tak pohybové vodítko,

00:14:30.330 --> 00:14:32.330
a robot se tak dívá docela úspěšně na hodinky.

00:14:32.330 --> 00:14:35.330
Nevíme, jestli rozuměl, nebo ne, že robot --

00:14:36.330 --> 00:14:38.330
Všimněte si, jak přebírá slovo.

00:14:38.330 --> 00:14:41.330
Ritchie: OK, chci Ti něco ukázat. OK, toto jsou hodinky,

00:14:41.330 --> 00:14:44.330
které mi dala má přítelkyně.

00:14:44.330 --> 00:14:46.330
Robot: Ach, super.

00:14:46.330 --> 00:14:50.330
Ritchie: Jo, podívej, mají také malé modré světýlko. Skoro jsem je minulý týden ztratil.

00:14:51.330 --> 00:14:55.330
(Smích)

00:14:55.330 --> 00:14:58.330
RB: Takže udržuje s ním oční kontakt, sleduje jeho oči.

00:14:58.330 --> 00:15:00.330
Ritchie: Můžeš udělat tu stejnou věc? Robot: Jo, jasně.

00:15:00.330 --> 00:15:02.330
RB: A tak spolu úspěšně rozmlouvají.

00:15:02.330 --> 00:15:06.330
A zde je jiný druh věcí, které jsme Chris a já dělali.

00:15:06.330 --> 00:15:08.330
Toto je další robot, Cog.

00:15:08.330 --> 00:15:14.330
Nejprve naváže oční kontakt, posléze, když se Christie podívá na hračku,

00:15:14.330 --> 00:15:16.330
odhadne směr jejího pohledu

00:15:16.330 --> 00:15:18.330
a podívá se na stejnou věc jako se dívá ona.

00:15:18.330 --> 00:15:19.330
(Smích)

00:15:19.330 --> 00:15:22.330
Takže uvidíme stále více a více typů tohoto druhu robota

00:15:22.330 --> 00:15:24.330
v průběhu následujících pár let v laboratořích.

00:15:24.330 --> 00:15:29.330
Pak jsou ale velké otázky, dvě velké otázky, na které se mě lidé ptají:

00:15:29.330 --> 00:15:31.330
Pokud vytvoříme tyto roboty stále více podobné člověku,

00:15:31.330 --> 00:15:36.330
vezmeme je mezi sebe, budou vyžadovat vlastní práva?

00:15:36.330 --> 00:15:39.330
A druhá otázka, kterou mi lidé kladou, je: Budou nás chtít ovládnout?

00:15:39.330 --> 00:15:40.330
(Smích)

00:15:40.330 --> 00:15:43.330
Co se týče první, jak víte, byla velkým tématem v mnoha hollywoodských filmech.

00:15:43.330 --> 00:15:46.330
Pravděpodobně rozpoznáte tyto postavy zde --

00:15:46.330 --> 00:15:50.330
kde v každém z těchto případů chtěl robot více respektu.

00:15:50.330 --> 00:15:53.330
Nuže, budete někdy potřebovat projevovat robotům úctu?

00:15:54.330 --> 00:15:56.330
Jsou to jenom stroje.

00:15:56.330 --> 00:16:00.330
Ale myslím si, víte, že musíme přijmout, že my jsme také jen stroje.

00:16:00.330 --> 00:16:05.330
Po tom všem, co nám moderní molekulární biologie říká o nás samých.

00:16:05.330 --> 00:16:08.330
Nevidíte popis, jak se, víte,

00:16:08.330 --> 00:16:12.330
molekula A přiblíží k jiné molekule a spojí se s ní.

00:16:12.330 --> 00:16:15.330
A takto se pokračuje dále, poháněno různými náboji

00:16:15.330 --> 00:16:19.330
a vytváří se spojení mezi molekulami, takže se spojují.

00:16:19.330 --> 00:16:22.330
Všechno to je mechanické. My jsme mechanismy.

00:16:22.330 --> 00:16:25.330
Jestliže jsme stroje, pak bychom přinejmenším v principu

00:16:25.330 --> 00:16:29.330
měli být schopni stavět stroje z jiných materiálů,

00:16:29.330 --> 00:16:33.330
které by byly stejně živé jako jsme my.

00:16:33.330 --> 00:16:35.330
Ale myslím si, že abychom toto mohli přijmout,

00:16:35.330 --> 00:16:38.330
musíme rezignovat na naši výjimečnost.

00:16:38.330 --> 00:16:40.330
A musíme se vzdát své výjimečnosti

00:16:40.330 --> 00:16:43.330
pod palbou vědy a technologie mnohých dob

00:16:43.330 --> 00:16:45.330
za posledních pár stovek let,

00:16:45.330 --> 00:16:47.330
přinejmenším před 500 lety jsme se museli vzdát představy,

00:16:47.330 --> 00:16:50.330
že jsme ve středu vesmíru,

00:16:50.330 --> 00:16:52.330
když Země začala obíhat kolem Slunce.

00:16:52.330 --> 00:16:57.330
Před 150 lety, díky Darwinovi, jsme se museli vzdát představy, že jsme odlišní od zvířat.

00:16:57.330 --> 00:17:00.330
A to, jak víte, bylo vždy těžké si představit.

00:17:00.330 --> 00:17:03.330
V současnosti jsme vystaveni i představě,

00:17:03.330 --> 00:17:05.330
že náš vznik ani nespadá na planetu Zemi,

00:17:05.330 --> 00:17:08.330
což se lidem příliš nelíbí. A pak, lidský genom říká,

00:17:08.330 --> 00:17:11.330
že snad máme jen 35 000 genů. A toto bylo skutečně --

00:17:11.330 --> 00:17:14.330
lidem se tato představa nelíbila, musíme mít přece víc genů.

00:17:14.330 --> 00:17:17.330
Neradi se vzdáváme své výjimečnosti, takže, jak víte,

00:17:17.330 --> 00:17:19.330
myšlenka, že by roboti mohli mít skutečné emoce,

00:17:19.330 --> 00:17:21.330
či že by roboti mohli být živými tvory,

00:17:21.330 --> 00:17:23.330
je, myslím si, pro nás obtížně přijatelná.

00:17:23.330 --> 00:17:27.330
Ale v následujících přibližně 50 letech ji přijmeme.

00:17:27.330 --> 00:17:30.330
A druhá otázka je: Budou chtít stroje převzít vládu nad světem?

00:17:30.330 --> 00:17:35.330
A standardní vize je, že stvoříme takovéto věci,

00:17:35.330 --> 00:17:38.330
porostou, vychováme je, mnoho se od nás naučí

00:17:38.330 --> 00:17:42.330
a pak si pomyslí, že jsme pěkně nudní, pomalí.

00:17:42.330 --> 00:17:44.330
Budou chtít převzít vládu.

00:17:44.330 --> 00:17:47.330
A pro ty z vás, kdo máte doma náctileté, víte, jak to vypadá.

00:17:47.330 --> 00:17:48.330
(Smích)

00:17:48.330 --> 00:17:51.330
Ale Hollywood toto rozšiřuje na roboty.

00:17:51.330 --> 00:17:54.330
A otázka je:

00:17:54.330 --> 00:17:58.330
Vyrobí někdo náhodou robota, který nám převezme vládu?

00:17:58.330 --> 00:18:01.330
Něco na způsob osamělého chlapíka někde na dvorku,

00:18:01.330 --> 00:18:04.330
který si náhle uvědomí: "Náhodou jsem postavil (Boeing) 747.“

00:18:04.330 --> 00:18:06.330
Rozumíte, nemyslím si, že se to stane.

00:18:06.330 --> 00:18:08.330
A nemyslím si --

00:18:08.330 --> 00:18:09.330
(Smích)

00:18:09.330 --> 00:18:12.330
-- nemyslím si, že úmyslně vyrobíme roboty,

00:18:12.330 --> 00:18:14.330
se kterými bychom byli nespokojení.

00:18:14.330 --> 00:18:16.330
Nebudeme mít extra špatné roboty.

00:18:16.330 --> 00:18:19.330
Předtím musí, víte, přijít středně zlý robot

00:18:19.330 --> 00:18:21.330
a předtím ještě ne tak zlý robot.

00:18:21.330 --> 00:18:22.330
(Smích)

00:18:22.330 --> 00:18:24.330
A nenecháme to jít touto cestou.

00:18:24.330 --> 00:18:25.330
(Smích)

00:18:25.330 --> 00:18:31.330
Takže myslím, že to zanechám s tím, že roboti přicházejí,

00:18:31.330 --> 00:18:34.330
nemusíme se toho příliš obávat, bude to velká legrace

00:18:34.330 --> 00:18:38.330
a, doufám, že si všichni užijete cestu skrze následujících 50 let.

00:18:38.330 --> 00:18:40.330
(Potlesk)

