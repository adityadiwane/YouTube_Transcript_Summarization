WEBVTT
Kind: captions
Language: ja

00:00:00.000 --> 00:00:07.000
翻訳: Shungo Haraguchi
校正: Akiko Hicks

00:00:18.330 --> 00:00:23.330
本日お話ししたいのは
様々なレベルや時間尺度おいて

00:00:23.330 --> 00:00:26.330
ロボットが私たちの生活を
侵略していることついての私見です

00:00:26.330 --> 00:00:30.330
今から500年後の未来を考えると

00:00:30.330 --> 00:00:32.330
至る所にロボットが存在する
世界しか想像できません

00:00:32.330 --> 00:00:37.330
人類の運命に関する
悲観的な予測は別として

00:00:37.330 --> 00:00:41.330
我々がこの世に存在しているとすれば
ロボットもたくさんいるはずです

00:00:41.330 --> 00:00:44.330
疑問は500年後に
この様に存在するであろうロボットが

00:00:44.330 --> 00:00:46.330
それ以前に
至る所に存在するようになるか

00:00:46.330 --> 00:00:48.330
50年後にでも
既にそうなるかということです

00:00:48.330 --> 00:00:51.330
十分にありえると思います
ロボットはそこらじゅうに存在し

00:00:51.330 --> 00:00:54.330
実際 もっと早い時期に
そうなると考えています

00:00:54.330 --> 00:00:58.330
現在はロボット普及の
「幕開け」であるとも言えます

00:00:58.330 --> 00:01:04.330
丁度 1978年から1980年あたりの
パソコンがそうであったように

00:01:04.330 --> 00:01:07.330
ロボットが徐々に登場し始めると
思っています

00:01:07.330 --> 00:01:11.330
コンピューターは はじめ
ゲームや玩具を通してやってきました

00:01:11.330 --> 00:01:14.330
家庭に一番先にやってきたのは

00:01:14.330 --> 00:01:16.330
「Pong」が遊べる
コンピューターだったかもしれません

00:01:16.330 --> 00:01:18.330
小さなマイクロプロセッサー内蔵のものです

00:01:18.330 --> 00:01:21.330
他のゲームも次々に登場しました

00:01:21.330 --> 00:01:24.330
ロボットでも同じような事が
起こっています

00:01:24.330 --> 00:01:28.330
LEGOマインドストームやファービー
ファービーを持っていた人は？

00:01:28.330 --> 00:01:31.330
いますね
全世界で3800万個も売れました

00:01:31.330 --> 00:01:33.330
結構 流行っていました
これは とても小さな

00:01:33.330 --> 00:01:35.330
センサー数個の シンプルなロボットで

00:01:35.330 --> 00:01:37.330
ちょっとした情報処理や動きをします

00:01:37.330 --> 00:01:40.330
右側は数年前に売られていた
別の人形ロボットです

00:01:40.330 --> 00:01:42.330
コンピューターの初期

00:01:42.330 --> 00:01:47.330
マニアの人たちが
コンピューターをいじっていた頃のように

00:01:47.330 --> 00:01:51.330
様々なハッキング・キットや本も売っています

00:01:51.330 --> 00:01:55.330
左側はEvolution Robotics社の
プラットフォームです

00:01:55.330 --> 00:01:58.330
PCをのせGUIでプログラムし

00:01:58.330 --> 00:02:01.330
家の中をウロウロさせて
いろんな事ができます

00:02:01.330 --> 00:02:04.330
もっと高額な
ロボット玩具のようなものもあって

00:02:04.330 --> 00:02:08.330
ソニーのアイボ
右側はNECの開発した

00:02:08.330 --> 00:02:11.330
PaPeRoです
発売はされないと思いますが

00:02:11.330 --> 00:02:14.330
でも こういったものが存在しています

00:02:14.330 --> 00:02:18.330
ここ数年 芝刈りロボットも出てきました

00:02:18.330 --> 00:02:24.330
下はHusqvarna社製
上はイスラエルのFriendly Robotics社製

00:02:24.330 --> 00:02:26.330
そして 昨年あたりから

00:02:26.330 --> 00:02:30.330
たくさんの 家庭用掃除ロボットを
見るようになりました

00:02:30.330 --> 00:02:33.330
左上は とても素晴らしい
家庭用掃除ロボットで

00:02:33.330 --> 00:02:37.330
イギリスのDyson社製です
ただ とても高額で

00:02:37.330 --> 00:02:39.330
3,500ドルです
市場には出ませんでしたが

00:02:39.330 --> 00:02:42.330
でも左下のElectrolux社製のものは
販売されています

00:02:42.330 --> 00:02:44.330
Karcher社製の また別のものもあって

00:02:44.330 --> 00:02:46.330
右下は 私の研究室で

00:02:46.330 --> 00:02:49.330
10年ほど前に作ったもので
最近製品化されました

00:02:49.330 --> 00:02:51.330
これをお見せしましょう

00:02:51.330 --> 00:02:55.330
後でこれは誰かに差し上げるとか
クリスは言っています

00:02:55.330 --> 00:03:01.330
これは皆さんも購入できるロボットで
床を掃除します

00:03:05.330 --> 00:03:10.330
だんだん円を大きく描きながら動き

00:03:10.330 --> 00:03:14.330
何かにぶつかると…見えました？

00:03:14.330 --> 00:03:17.330
壁に沿って移動したり
私の足に沿って

00:03:17.330 --> 00:03:21.330
周りを掃除してくれています
ではここで...

00:03:21.330 --> 00:03:26.330
あれ？誰か僕のシリアルを盗みました？
シリアルが盗まれてしまいました！

00:03:26.330 --> 00:03:32.330
（笑）

00:03:32.330 --> 00:03:35.330
心配しないで 大丈夫ですよ
ロボットだから賢いんです！

00:03:35.330 --> 00:03:38.330
（笑）

00:03:38.330 --> 00:03:42.330
３歳の子供は心配しないんですよね

00:03:42.330 --> 00:03:44.330
大人だけが取り乱すんです

00:03:44.330 --> 00:03:45.330
（笑）

00:03:45.330 --> 00:03:47.330
では「ゴミ」を少しここに置いて

00:03:47.330 --> 00:03:51.330
（笑）

00:03:51.330 --> 00:03:53.330
はい

00:03:53.330 --> 00:03:57.330
（笑）

00:03:57.330 --> 00:04:00.330
見えにくいですが
ここにたくさんシリアルを置きました

00:04:00.330 --> 00:04:07.330
硬貨もいくつか置いて あれに向かって
動かしてみましょう 掃除するかどうか

00:04:10.330 --> 00:04:12.330
はい 大丈夫ですね　では…

00:04:12.330 --> 00:04:16.330
これはひとまず置いておきましょう

00:04:16.330 --> 00:04:21.330
（拍手）

00:04:22.330 --> 00:04:26.330
難しかったのは 良い掃除メカニズムの
デザインでした

00:04:26.330 --> 00:04:30.330
中の頭脳はかなり単純なものです

00:04:30.330 --> 00:04:32.330
概してこれは他のロボットでも同じです

00:04:32.330 --> 00:04:36.330
私たちはある意味で
コンピュータ優位論者であるようで

00:04:36.330 --> 00:04:38.330
コンピュータ処理が全てと考えがちです

00:04:38.330 --> 00:04:40.330
でも 機械部も大切なんです

00:04:40.330 --> 00:04:43.330
これは 別のロボット
PacBotというもので

00:04:43.330 --> 00:04:45.330
ここ何年も作っているものです

00:04:45.330 --> 00:04:51.330
軍事用の偵察ロボットで
兵隊に先立って

00:04:51.330 --> 00:04:54.330
例えば 洞窟を偵察したりするものですが

00:04:54.330 --> 00:04:56.330
かなり頑丈に作る必要がありました

00:04:56.330 --> 00:05:03.330
研究室で普段作るロボットよりも
かなり頑丈にね

00:05:03.330 --> 00:05:06.330
（笑）

00:05:12.330 --> 00:05:16.330
ロボットの頭脳はLinux搭載のPCでして

00:05:16.330 --> 00:05:22.330
400Gの衝撃に耐えることができます
ロボット自身が知能を持っていて

00:05:22.330 --> 00:05:28.330
自分を反転させたり 通信域に移動したり

00:05:28.330 --> 00:05:31.330
自力で階段を昇ったりすることなどができます

00:05:38.330 --> 00:05:42.330
ここでは 現場でのナビゲーションを
行っています

00:05:42.330 --> 00:05:48.330
兵士が階段を昇る指令を出すと
それに従います

00:05:49.330 --> 00:05:52.330
今のは意図的な落下ではありませんが…

00:05:52.330 --> 00:05:54.330
（笑）

00:05:54.330 --> 00:05:56.330
今度は回避します

00:05:56.330 --> 00:06:01.330
これらのロボットの大きな転換点は
９・１１の多発テロでした

00:06:01.330 --> 00:06:05.330
あの夜遅く ワールドトレードセンターに
出動させましたが

00:06:06.330 --> 00:06:08.330
中心の瓦礫の山では
大したことは出来ませんでした

00:06:08.330 --> 00:06:11.330
全てがとても…
できることはありませんでした

00:06:11.330 --> 00:06:16.330
しかし 避難済みの周囲の建物に
全て入って行って

00:06:16.330 --> 00:06:19.330
危険すぎて入ることができない建物の中で

00:06:19.330 --> 00:06:21.330
生存者の探索を行うことができました

00:06:21.330 --> 00:06:23.330
この映像をご覧ください

00:06:23.330 --> 00:06:26.330
戦場の友が
戦闘リスクの軽減に役立っています

00:06:26.330 --> 00:06:29.330
ニック・ロバートソンの報告です

00:06:31.330 --> 00:06:33.330
ロドニー：これをもうひとつもらえますか？

00:06:38.330 --> 00:06:40.330
ありがとう

00:06:43.330 --> 00:06:46.330
これは2週間前に
ロボットをはじめて見た伍長です

00:06:48.330 --> 00:06:52.330
ロボットを洞窟に送り込み
状況を確認しています

00:06:52.330 --> 00:06:54.330
ロボットは完全に自律して動きます

00:06:54.330 --> 00:06:58.330
過去 洞窟内で起きた最悪の出来事は

00:06:58.330 --> 00:07:01.330
ロボットの１つが10m落下したことでした

00:07:08.330 --> 00:07:11.330
米軍がこの様なロボットを
使うようになって まだ一年ですが

00:07:11.330 --> 00:07:13.330
現在アフガニスタンで
毎日のように活躍しています

00:07:13.330 --> 00:07:16.330
ロボットの侵略が起きていると
言われる理由のひとつです

00:07:16.330 --> 00:07:20.330
テクノロジーの未来もどんどん
変わって来ています

00:07:20.330 --> 00:07:22.330
ありがとう

00:07:23.330 --> 00:07:25.330
数ヶ月先には

00:07:25.330 --> 00:07:28.330
私達はロボットを油田に送り出し

00:07:28.330 --> 00:07:32.330
地中に残った数年分の石油を取り出すために
地下産出を行う予定です

00:07:32.330 --> 00:07:36.330
150℃ 圧力も10,000psiという
とても過酷な環境です

00:07:36.330 --> 00:07:40.330
自律型ロボットが地中に潜り
この種の仕事を行うのです

00:07:40.330 --> 00:07:43.330
しかし このようなロボットの制御は多少難しく

00:07:43.330 --> 00:07:45.330
将来 どの様にプログラムし

00:07:45.330 --> 00:07:47.330
ロボットを使いやすくするかが
課題になります

00:07:47.330 --> 00:07:50.330
ここで 実際にロボットを見てみましょう

00:07:50.330 --> 00:07:55.330
クリスという名前のロボットです
立ち上がって　はい OK

00:07:57.330 --> 00:08:01.330
こっちへ来て　ロボットだから 堅苦しく
しなくてはと思っているようですね

00:08:01.330 --> 00:08:04.330
そんな風に見えますが
ここで...

00:08:04.330 --> 00:08:06.330
単にイギリス人だからですよ
なるほど

00:08:06.330 --> 00:08:08.330
（笑）

00:08:08.330 --> 00:08:10.330
（拍手）

00:08:10.330 --> 00:08:13.330
このロボットにタスク（作業）を見せます
とても複雑なタスクです

00:08:13.330 --> 00:08:16.330
頷きましたね
ここで何かを私に伝えているわけです

00:08:16.330 --> 00:08:19.330
コミュニケーションの流れを
理解したのだとわかります

00:08:19.330 --> 00:08:21.330
私が突拍子もないことを言ったとすると

00:08:21.330 --> 00:08:24.330
顔をしかめて
会話を調整したでしょう

00:08:24.330 --> 00:08:27.330
ここで これを彼の前にかざしてみます

00:08:27.330 --> 00:08:31.330
彼の目を見て ボトルの頭を見たと
確認します

00:08:31.330 --> 00:08:33.330
そしてここでタスクを行い
彼はそれを見ています

00:08:33.330 --> 00:08:36.330
彼は 私の目と 私の見ているものを
交互に見ています

00:08:36.330 --> 00:08:38.330
つまり 注意を共有しているわけです

00:08:38.330 --> 00:08:41.330
タスクを置こうなうと 
それ見ると同時に 私のことも見て

00:08:41.330 --> 00:08:45.330
次に何が起こるか理解しようとしています
ここでボトルを渡します

00:08:45.330 --> 00:08:47.330
ここでタスクができるでしょうか
できますか？

00:08:47.330 --> 00:08:50.330
（笑）

00:08:50.330 --> 00:08:54.330
OK　上手ですね
はい 上手 上手

00:08:54.330 --> 00:08:56.330
それは教えてないよ

00:08:56.330 --> 00:08:58.330
では 元に戻せるか見てみましょう

00:08:58.330 --> 00:09:00.330
（笑）

00:09:00.330 --> 00:09:01.330
ロボットはゆっくり動くと
思っているみたいですね

00:09:01.330 --> 00:09:03.330
いいロボットだ　よくできました

00:09:03.330 --> 00:09:05.330
さあ これでいろいろ解りました

00:09:06.330 --> 00:09:09.330
相互のやりとりでは

00:09:09.330 --> 00:09:13.330
何かやり方を見せるとき
相手の視線の注意を引きます

00:09:13.330 --> 00:09:17.330
相手は自分の状態を伝え

00:09:17.330 --> 00:09:20.330
理解したかどうかとか
対話を調整します

00:09:20.330 --> 00:09:22.330
同じものを見ることで
注意が共有され

00:09:22.330 --> 00:09:26.330
最後には対話で
褒められたのを認識するのもわかりました

00:09:26.330 --> 00:09:29.330
現在 これを研究室のロボットに
取り入れようとしています

00:09:29.330 --> 00:09:33.330
これが将来ロボットとやりとりする
望ましい方法だと思います

00:09:33.330 --> 00:09:35.330
ここで技術的な図をひとつお見せします

00:09:35.330 --> 00:09:39.330
対話できるロボットをつくる上で最も重要なのが

00:09:39.330 --> 00:09:41.330
視覚的な注意喚起システムです

00:09:41.330 --> 00:09:44.330
なぜなら 注意を払っている対象は
それが見たり

00:09:44.330 --> 00:09:47.330
関連している対象であり
ロボットの行動を理解するものだからです

00:09:47.330 --> 00:09:50.330
今からお見せする映像では

00:09:50.330 --> 00:09:54.330
ロボットの視覚的な注意喚起システムを
ご覧いただきます

00:09:54.330 --> 00:09:58.330
これは…HSV色空間で
肌色を探すので

00:09:58.330 --> 00:10:02.330
全ての人種の色に対応していてます

00:10:02.330 --> 00:10:04.330
玩具の鮮やかなを見つけ出したり

00:10:04.330 --> 00:10:06.330
動くものを探します

00:10:06.330 --> 00:10:09.330
それらを視野の中で比較し

00:10:09.330 --> 00:10:11.330
最も高いスコアの箇所を見つけます

00:10:11.330 --> 00:10:13.330
最も興味深い出来事が起きている箇所に

00:10:13.330 --> 00:10:17.330
そして そこに目をすみやかに移し

00:10:17.330 --> 00:10:19.330
それを注視します

00:10:19.330 --> 00:10:22.330
同時に トップダウン的に

00:10:22.330 --> 00:10:25.330
寂しいので 肌色を探そうと判断したり

00:10:25.330 --> 00:10:28.330
退屈なので 遊ぶための玩具を
探そうと判断したりするので

00:10:28.330 --> 00:10:30.330
ウエイトがかわります

00:10:30.330 --> 00:10:32.330
そして この右側は

00:10:32.330 --> 00:10:35.330
私達がスティーブン・スピルバーグの
記念モジュールと呼ぶ…

00:10:35.330 --> 00:10:37.330
「AI」という映画をご覧になりました？
（観客：はい）

00:10:37.330 --> 00:10:39.330
ひどい映画でしたが

00:10:39.330 --> 00:10:43.330
特に ハーレイ・ジョエル・オスメントの扮した
小さなロボットが

00:10:43.330 --> 00:10:47.330
ひと時も目を離さずに 青い妖精を
2000年もの間 見続けたのも

00:10:47.330 --> 00:10:49.330
これは それに対処する答えです

00:10:49.330 --> 00:10:53.330
なぜなら これは負に作用する
ガウス的な馴化でありまして

00:10:53.330 --> 00:10:56.330
一つのものを見続けると

00:10:56.330 --> 00:10:59.330
結果的に 飽きてしまい
何か他のものを見るようになります

00:10:59.330 --> 00:11:03.330
簡単な説明でしたが
これがロボットの Kismetです

00:11:03.330 --> 00:11:07.330
おもちゃを探しています
何を見ているかわかりますね

00:11:07.330 --> 00:11:12.330
カメラを覆っている目玉から
目線の方向を推測できます

00:11:12.330 --> 00:11:15.330
おもちゃを見つける様子が
わかります

00:11:15.330 --> 00:11:17.330
ちょっと感情的な反応を示しましたね

00:11:17.330 --> 00:11:18.330
（笑）

00:11:18.330 --> 00:11:20.330
しかし 注意は継続しています

00:11:20.330 --> 00:11:24.330
もし もっと面白いものが視野に入れば

00:11:24.330 --> 00:11:28.330
例えば右にいる このロボットの
生みの親であるシンシア・ブリジールなどに

00:11:28.330 --> 00:11:33.330
気づくと そちらに注意を払います

00:11:33.330 --> 00:11:37.330
Kismetは内的な３次元の感情空間を持っていて

00:11:37.330 --> 00:11:40.330
それは感情の位置を示すベクトル空間で

00:11:40.330 --> 00:11:45.330
その空間のどこにいるかを表現します

00:11:46.330 --> 00:11:48.330
音声を出してもらえますか？

00:11:48.330 --> 00:11:50.330
聞こえますか？（観客：はい）

00:11:50.330 --> 00:11:55.330
本当にそう思う？本当にそう思う？

00:11:57.330 --> 00:11:59.330
本当にそう思う？

00:12:00.330 --> 00:12:03.330
表情と声の調子を通して

00:12:03.330 --> 00:12:05.330
感情を表現するのです

00:12:05.330 --> 00:12:09.330
ここで私がロボットとやりとりしていた際

00:12:09.330 --> 00:12:12.330
ロボットのクリスが私の声の調子を
測っていたように

00:12:12.330 --> 00:12:17.330
声の調子で表現される
４種の基本メッセージを測るようにしました

00:12:17.330 --> 00:12:21.330
これは言葉以前に
母親が子供に伝えるものです

00:12:21.330 --> 00:12:24.330
ここでは事前情報のない被験者が
ロボットを褒めています

00:12:26.330 --> 00:12:28.330
いいロボットね

00:12:29.330 --> 00:12:31.330
小さくてかわいいロボットね

00:12:31.330 --> 00:12:33.330
（笑）

00:12:33.330 --> 00:12:35.330
そして ロボットは適切に反応しています

00:12:35.330 --> 00:12:39.330
よくできたわ Kismet

00:12:40.330 --> 00:12:42.330
（笑）

00:12:42.330 --> 00:12:44.330
私の笑顔を見て

00:12:46.330 --> 00:12:49.330
笑顔になります 笑顔を真似するんです
これは頻繁に起こります

00:12:49.330 --> 00:12:51.330
これらは事前情報のない被験者です

00:12:51.330 --> 00:12:54.330
ロボットの気を引いて

00:12:54.330 --> 00:12:57.330
ロボットの気が引けたら
知らせるように頼みました

00:12:57.330 --> 00:13:01.330
Kismet はい そうね

00:13:01.330 --> 00:13:05.330
彼女はロボットの注意が
得られたとわかりました

00:13:08.330 --> 00:13:12.330
おもちゃが好き？

00:13:13.330 --> 00:13:15.330
さて ここではロボットを咎めるよう
頼みました

00:13:15.330 --> 00:13:19.330
この最初の女性はほんとうにロボットを
感情的に追い詰めます

00:13:19.330 --> 00:13:24.330
だめ　だめ
やっちゃいけません　だめ

00:13:24.330 --> 00:13:27.330
（笑）

00:13:27.330 --> 00:13:33.330
そんなのだめ　だめ　だめ

00:13:33.330 --> 00:13:36.330
（笑）

00:13:36.330 --> 00:13:38.330
これくらいにしておきましょう

00:13:38.330 --> 00:13:40.330
これらを組み合わせ
順番交替を追加しました

00:13:40.330 --> 00:13:43.330
誰かと話す際 まず話して

00:13:43.330 --> 00:13:47.330
次に 眉を上げたり 目を動かしたりして

00:13:47.330 --> 00:13:50.330
相手に会話の順番が来たと気づかせます

00:13:50.330 --> 00:13:54.330
そうして相手が話し そして交互に
かわるがわる話します

00:13:54.330 --> 00:13:56.330
これをロボットに組み込みました

00:13:56.330 --> 00:13:58.330
何も知らない被験者を
何人も用意して

00:13:58.330 --> 00:14:00.330
ロボットのことは何も教えず

00:14:00.330 --> 00:14:02.330
ロボットの前に座らせ
会話をしてもらいました

00:14:02.330 --> 00:14:04.330
彼らが知らないのは

00:14:04.330 --> 00:14:06.330
ロボットは実は言葉を全く理解せず

00:14:06.330 --> 00:14:09.330
話しているのも英語ではない
という事です

00:14:09.330 --> 00:14:11.330
ランダムな英語の音素を話すだけです

00:14:11.330 --> 00:14:13.330
この冒頭の部分を
良く見て頂きたいのですが

00:14:13.330 --> 00:14:17.330
この方 リッチーはロボットと
25分も会話をしました

00:14:17.330 --> 00:14:19.330
（笑）

00:14:19.330 --> 00:14:21.330
「見せたいものがあるんだ

00:14:21.330 --> 00:14:23.330
この時計を見せたいんだ」と言って

00:14:23.330 --> 00:14:28.330
彼は時計をロボットの
視界の中心に持ってきて

00:14:28.330 --> 00:14:30.330
指さし 動かして示し

00:14:30.330 --> 00:14:32.330
ロボットに時計を見せる事に成功します

00:14:32.330 --> 00:14:35.330
気が付いていたかわかりませんが

00:14:36.330 --> 00:14:38.330
ロボットは順番交替もしています

00:14:38.330 --> 00:14:41.330
「見せたいものがあるんだ
これは時計

00:14:41.330 --> 00:14:44.330
僕の彼女がくれたんだ」

00:14:44.330 --> 00:14:46.330
「あら、いい」

00:14:46.330 --> 00:14:50.330
「そうだろ　見て 中に青いライトも
あるんだ 先週失くしそうになったよ」

00:14:51.330 --> 00:14:55.330
（笑）

00:14:55.330 --> 00:14:58.330
彼の目を追いかけて
彼とアイ・コンタクトをとっています

00:14:58.330 --> 00:15:00.330
「まねできる？」
「ええ もちろん」

00:15:00.330 --> 00:15:02.330
こんな具合で 
コミュニケーションに成功しました

00:15:02.330 --> 00:15:06.330
クリスと私がやった
また別のこともお見せします

00:15:06.330 --> 00:15:08.330
これは別の「コグ」というロボットで

00:15:08.330 --> 00:15:14.330
最初にアイ・コンタクトをして 
次に クリスティーが玩具に目をやると

00:15:14.330 --> 00:15:16.330
ロボットは彼女の視線を推測して

00:15:16.330 --> 00:15:18.330
彼女が見ているのと同じ物を見ます

00:15:18.330 --> 00:15:19.330
（笑）

00:15:19.330 --> 00:15:22.330
この種のロボットが さらに多く

00:15:22.330 --> 00:15:24.330
研究されるようになるでしょ

00:15:24.330 --> 00:15:29.330
そこで大きな疑問が出てきます
私が聞かれる２つの大きな疑問は

00:15:29.330 --> 00:15:31.330
これらのロボットが更にもっと
人間に近づいたら

00:15:31.330 --> 00:15:36.330
彼らを受け入れられるでしょうか？
将来 彼らにも権利が必要になるでしょうか？

00:15:36.330 --> 00:15:39.330
もう一つ良く訊かれるのが
ロボットは人間にとって代わろうとするか？

00:15:39.330 --> 00:15:40.330
（笑）

00:15:40.330 --> 00:15:43.330
最初の疑問は
ハリウッドの映画によくある

00:15:43.330 --> 00:15:46.330
テーマです
これらのキャラクターはお馴染みですが

00:15:46.330 --> 00:15:50.330
いずれの場合も
ロボット達は尊厳を求めています

00:15:50.330 --> 00:15:53.330
ロボットに権利を与える必要があるでしょうか？

00:15:54.330 --> 00:15:56.330
たかが機械です

00:15:56.330 --> 00:16:00.330
でも 良く考えれば
私たちだって機械です

00:16:00.330 --> 00:16:05.330
分子科学者の目でみると
そうなります

00:16:05.330 --> 00:16:08.330
例えば「A」という分子がやってきて

00:16:08.330 --> 00:16:12.330
他の分子と結合するなんて
説明はありませんが

00:16:12.330 --> 00:16:15.330
いろいろな力がはたらいて
進んできて

00:16:15.330 --> 00:16:19.330
そこに魂がやってきて分子が
きちんとつながる様になっている

00:16:19.330 --> 00:16:22.330
全て機械的なのです
私たちは機械です

00:16:22.330 --> 00:16:25.330
もし我々が機械なら
少なくとも原則的には

00:16:25.330 --> 00:16:29.330
他のものから機械を作って

00:16:29.330 --> 00:16:33.330
私たちの様に生きてるものを
作れるはずです

00:16:33.330 --> 00:16:35.330
でも それを認めるには

00:16:35.330 --> 00:16:38.330
自分たちが 特別な存在である事を
あきらめなければなりません

00:16:38.330 --> 00:16:40.330
これまでも この特別性から
後退してきました

00:16:40.330 --> 00:16:43.330
少なくとも過去数百年渡り
科学と技術の攻撃を受け何度もです

00:16:43.330 --> 00:16:45.330
少なくとも過去数百年渡り
科学と技術の攻撃を受け何度もです

00:16:45.330 --> 00:16:47.330
500年前には宇宙の中心であるという考えを

00:16:47.330 --> 00:16:50.330
捨てなければなりませんでした

00:16:50.330 --> 00:16:52.330
地球が太陽の中心を周りはじめたときにです

00:16:52.330 --> 00:16:57.330
150年前には ダーウィンによって 
他の動物と違うという考えを
捨てなければなりませんでした

00:16:57.330 --> 00:17:00.330
そして想像するに…いつもながら厳しいことですが

00:17:00.330 --> 00:17:03.330
近年 こんな考えもつきつけられています

00:17:03.330 --> 00:17:05.330
我々は地球で生まれたのでは
ないかもしれない

00:17:05.330 --> 00:17:08.330
これは皆嫌います
そして人間の遺伝子は

00:17:08.330 --> 00:17:11.330
3500個しかないなんて言われると

00:17:11.330 --> 00:17:14.330
そんなはずでない
もっとあるはずだと感じるものです

00:17:14.330 --> 00:17:17.330
このように人間の特別性を
あきらめたくないので

00:17:17.330 --> 00:17:19.330
ロボットが本当に感情を持つ可能性や

00:17:19.330 --> 00:17:21.330
生き物と考えられるとなると

00:17:21.330 --> 00:17:23.330
受け入れがたいものになるでしょう

00:17:23.330 --> 00:17:27.330
でも ここ50年ぐらいで
これを受け入れるようになるでしょう

00:17:27.330 --> 00:17:30.330
次の疑問は 機械が我々に
とって代わるかということですが

00:17:30.330 --> 00:17:35.330
一般的なシナリオとしては
我々が彼らを創造し

00:17:35.330 --> 00:17:38.330
彼らが育ち 我々が育成し
彼らが我々から多くを学習し

00:17:38.330 --> 00:17:42.330
いつかしら我々をのろまで
退屈だと判断するようになる

00:17:42.330 --> 00:17:44.330
我々にとって代わりたいとなるわけです

00:17:44.330 --> 00:17:47.330
10代のお子さんをお持ちなら
よくわかると思います

00:17:47.330 --> 00:17:48.330
（笑）

00:17:48.330 --> 00:17:51.330
ハリウッドでは この感情を
ロボットに延長するわけですが

00:17:51.330 --> 00:17:54.330
でも ここで不思議に思うのは

00:17:54.330 --> 00:17:58.330
一体誰が 人間をのっとる
ロボットを間違って作るかということです

00:17:58.330 --> 00:18:01.330
庭で一人でゴチャゴチャやって

00:18:01.330 --> 00:18:04.330
「間違って747を作っちまった！」という感じで

00:18:04.330 --> 00:18:06.330
それは起きないでしょう

00:18:06.330 --> 00:18:08.330
そして…

00:18:08.330 --> 00:18:09.330
（笑）

00:18:09.330 --> 00:18:12.330
故意に危険なロボットを作るということは

00:18:12.330 --> 00:18:14.330
あり得ないでしょう

00:18:14.330 --> 00:18:16.330
すごく悪いロボットが登場する前に

00:18:16.330 --> 00:18:19.330
なんとなく悪いロボットが登場するはずですし

00:18:19.330 --> 00:18:21.330
その前には大して悪くはないロボットが
いるはずです

00:18:21.330 --> 00:18:22.330
（笑）

00:18:22.330 --> 00:18:24.330
だから これを放っておくわけありません

00:18:24.330 --> 00:18:25.330
（笑）

00:18:25.330 --> 00:18:31.330
結論としては ロボットはやってきます

00:18:31.330 --> 00:18:34.330
でも心配する程の事はありません
楽しいものになるでしょう

00:18:34.330 --> 00:18:38.330
これからの50年の旅を
楽しみましょう

00:18:38.330 --> 00:18:40.330
（拍手）

