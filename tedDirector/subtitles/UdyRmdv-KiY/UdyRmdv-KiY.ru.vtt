WEBVTT
Kind: captions
Language: ru

00:00:00.000 --> 00:00:07.000
Переводчик: Anna Zagrebelna
Редактор: Larisa Larionova

00:00:18.330 --> 00:00:23.330
Я хочу поделиться своими мыслями о внедрении роботов в нашу жизнь

00:00:23.330 --> 00:00:26.330
на разных уровнях и временных масштабах.

00:00:26.330 --> 00:00:30.330
Когда я думаю о будущем, то не могу представить мир через 500 лет

00:00:30.330 --> 00:00:32.330
без роботов повсюду.

00:00:32.330 --> 00:00:37.330
Несмотря на мрачные прогнозы многих людей насчёт нашего будущего,

00:00:37.330 --> 00:00:41.330
я не вижу мир без кучи роботов.

00:00:41.330 --> 00:00:44.330
Тогда возникает вопрос: если через 500 лет они будут повсюду,

00:00:44.330 --> 00:00:46.330
может ли это произойти раньше?

00:00:46.330 --> 00:00:48.330
Может ли это случиться через 50 лет?

00:00:48.330 --> 00:00:51.330
Да, думаю, это вполне вероятно — роботы на каждом углу.

00:00:51.330 --> 00:00:54.330
На самом деле, думаю, нам не придётся ждать так долго.

00:00:54.330 --> 00:00:58.330
Можно сказать, мы приближаемся к пришествию роботов,

00:00:58.330 --> 00:01:04.330
сегодняшняя ситуация напоминает 1978 или 1980 года, времена персональных компьютеров,

00:01:04.330 --> 00:01:07.330
когда начали появляться первые роботы.

00:01:07.330 --> 00:01:11.330
Можно сказать, компьютеры распространились благодаря играм.

00:01:11.330 --> 00:01:14.330
Как вы знаете, первым компьютером в доме многих людей

00:01:14.330 --> 00:01:16.330
была игрушка Pong,

00:01:16.330 --> 00:01:18.330
с маленьким микропроцессором внутри,

00:01:18.330 --> 00:01:21.330
а затем стали доступны и другие игры.

00:01:21.330 --> 00:01:24.330
И мы видим, то же самое происходит и с роботами:

00:01:24.330 --> 00:01:28.330
LEGO Mindstorm, Furby... У кого-нибудь здесь есть Furby?

00:01:28.330 --> 00:01:31.330
Да, их продали уже 38 миллионов во всем мире.

00:01:31.330 --> 00:01:33.330
Они встречаются довольно часто. Это крошечный робот,

00:01:33.330 --> 00:01:35.330
простой робот с несколькими сенсорами,

00:01:35.330 --> 00:01:37.330
слегка проявляющий обратную активность.

00:01:37.330 --> 00:01:40.330
Справа — кукла-робот, которую можно было приобрести пару лет назад.

00:01:40.330 --> 00:01:42.330
И так же, как и в первые дни компьютеров,

00:01:42.330 --> 00:01:47.330
когда было множество компьютерщиков-любителей,

00:01:47.330 --> 00:01:51.330
сейчас вы можете раздобыть различные хакерские пособия и ПО.

00:01:51.330 --> 00:01:55.330
Слева вы видите платформу от Evolution Robotics,

00:01:55.330 --> 00:01:58.330
которую можно подключить к ПК и запрограммировать, используя графический интерфейс,

00:01:58.330 --> 00:02:01.330
чтобы он ходил по дому и делал разные вещи.

00:02:01.330 --> 00:02:04.330
А тут робот-игрушка высшей ценовой категории — Sony Aibo.

00:02:04.330 --> 00:02:08.330
Справа робот, разработаный NEC,

00:02:08.330 --> 00:02:11.330
PaPeRo, который, как мне кажется, они не собираются выпускать.

00:02:11.330 --> 00:02:14.330
Тем не менее, вещи такого рода есть.

00:02:14.330 --> 00:02:18.330
В последние 2 или 3 года мы увидели роботов-газонокосильщиков,

00:02:18.330 --> 00:02:24.330
Husqvarna снизу и Friendly Robotics сверху, Израильской компании.

00:02:24.330 --> 00:02:26.330
А затем за последние 12 месяцев

00:02:26.330 --> 00:02:30.330
мы увидели, как начали появляться роботы, которые убирают в доме.

00:02:30.330 --> 00:02:33.330
Сверху слева — очень хороший робот-уборщик британской компании Dyson.

00:02:33.330 --> 00:02:37.330
Единственное, он оказался настолько дорогим —

00:02:37.330 --> 00:02:39.330
3,500 долларов, — что они его так и не выпустили.

00:02:39.330 --> 00:02:42.330
Но снизу слева вы видите Electrolux, который есть в продаже.

00:02:42.330 --> 00:02:44.330
Еще один от Karcher.

00:02:44.330 --> 00:02:46.330
Снизу справа — созданный мной в лаборатории

00:02:46.330 --> 00:02:49.330
около 10 лет назад, и наконец, он стал готовым продуктом.

00:02:49.330 --> 00:02:51.330
Позвольте мне сейчас его продемонстрировать.

00:02:51.330 --> 00:02:55.330
Я думаю, после выступления мы дадим желающим с ним поиграть.

00:02:55.330 --> 00:03:01.330
Этого робота вы можете купить для уборки пола.

00:03:05.330 --> 00:03:10.330
Он начинает работу с обычной прогулки, наматывая круги.

00:03:10.330 --> 00:03:14.330
Если он на что-то натыкается... Вы видели это?

00:03:14.330 --> 00:03:17.330
Теперь он движется вдоль преграды, в данном случае, вокруг моей ноги,

00:03:17.330 --> 00:03:21.330
чтобы убрать возле меня. Давайте посмотрим...

00:03:21.330 --> 00:03:26.330
Ой, кто украл мои рисовые хлебцы? Это они!

00:03:26.330 --> 00:03:32.330
(Смех)

00:03:32.330 --> 00:03:35.330
Не волнуйтесь, просто успокойтесь, это робот, он умный!

00:03:35.330 --> 00:03:38.330
(Смех)

00:03:38.330 --> 00:03:42.330
Видите, трёхлетних детей это не волнует.

00:03:42.330 --> 00:03:44.330
А вот взрослых это действительно расстраивает.

00:03:44.330 --> 00:03:45.330
(Смех)

00:03:45.330 --> 00:03:47.330
Сейчас мы немного здесь намусорим.

00:03:47.330 --> 00:03:51.330
(Смех)

00:03:51.330 --> 00:03:53.330
Так.

00:03:53.330 --> 00:03:57.330
(Смех)

00:03:57.330 --> 00:04:00.330
Не знаю, видите ли вы, я рассыпал там немного рисовых хлебцев

00:04:00.330 --> 00:04:07.330
и бросил немного монет, посмотрим, уберёт ли он это.

00:04:10.330 --> 00:04:12.330
Да, хорошо. Итак,

00:04:12.330 --> 00:04:16.330
оставим это на потом.

00:04:16.330 --> 00:04:21.330
(Аплодисменты)

00:04:22.330 --> 00:04:26.330
На самом деле, основной упор был сделан на улучшенном механизме очистки;

00:04:26.330 --> 00:04:30.330
искусственный интеллект довольно простой.

00:04:30.330 --> 00:04:32.330
И это касается многих роботов.

00:04:32.330 --> 00:04:36.330
Думаю, мы все стали чем-то вроде вычислительных шовинистов,

00:04:36.330 --> 00:04:38.330
думаем, что вычисление - наше всё,

00:04:38.330 --> 00:04:40.330
но механика всё ещё важна.

00:04:40.330 --> 00:04:43.330
Вот ещё один робот, PackBot,

00:04:43.330 --> 00:04:45.330
которого мы конструируем уже много лет.

00:04:45.330 --> 00:04:51.330
Это робот для военной разведки, чтобы идти впереди военных,

00:04:51.330 --> 00:04:54.330
осматривая пещеры, например.

00:04:54.330 --> 00:04:56.330
Но мы должны были сделать его достаточно надёжным,

00:04:56.330 --> 00:05:03.330
намного надёжнее роботов, которых мы строим в наших лабораториях.

00:05:03.330 --> 00:05:06.330
(Смех)

00:05:12.330 --> 00:05:16.330
В этого робота встроен персональный компьютер с ОС Linux.

00:05:16.330 --> 00:05:22.330
Он может выдержать удар силой 400G. У робота есть локальный интеллект:

00:05:22.330 --> 00:05:28.330
он может кувыркнуться, найти и переместиться в зону связи с ним,

00:05:28.330 --> 00:05:31.330
может сам подниматься по лестнице и так далее.

00:05:38.330 --> 00:05:42.330
Итак, он способен на местную разведку.

00:05:42.330 --> 00:05:48.330
Солдат отдаёт ему приказ подняться по лестнице, и он это делает.

00:05:49.330 --> 00:05:52.330
Это был неконтролируемый спуск.

00:05:52.330 --> 00:05:54.330
(Смех)

00:05:54.330 --> 00:05:56.330
Сейчас он очухается.

00:05:56.330 --> 00:06:01.330
И большим прорывом для этих роботов стали события 11 сентября.

00:06:01.330 --> 00:06:05.330
Тем вечером мы отправили роботов во Всемирный Торговый Центр.

00:06:06.330 --> 00:06:08.330
Многого мы этим не добились,

00:06:08.330 --> 00:06:11.330
там уже просто ничего нельзя было сделать.

00:06:11.330 --> 00:06:16.330
Но мы заходили во все эвакуированные дома неподалёку

00:06:16.330 --> 00:06:19.330
и искали выживших в тех домах,

00:06:19.330 --> 00:06:21.330
в которые было слишком небезопасно входить.

00:06:21.330 --> 00:06:23.330
Давайте посмотрим видео.

00:06:23.330 --> 00:06:26.330
Репортёр: ...боевые товарищи помогают снизить потери.

00:06:26.330 --> 00:06:29.330
Эту историю расскажет Ник Робертсон.

00:06:31.330 --> 00:06:33.330
OK

00:06:38.330 --> 00:06:40.330
Хорошо.

00:06:43.330 --> 00:06:46.330
Итак, это капрал, который не видел своих роботов уже две недели.

00:06:48.330 --> 00:06:52.330
Он посылает роботов в пещеры проверить, что там происходит.

00:06:52.330 --> 00:06:54.330
Роботы полностью автономны.

00:06:54.330 --> 00:06:58.330
Самое худшее из того, что случилось — это когда робот упал с высоты 10 метров.

00:06:58.330 --> 00:07:01.330
Солдат: у нас есть камеры, которые позволяют мне видеть всё, что видит робот.

00:07:08.330 --> 00:07:11.330
Итак, год назад у американских военных не было этих роботов.

00:07:11.330 --> 00:07:13.330
Сейчас они каждый день находятся на службе в Афганистане.

00:07:13.330 --> 00:07:16.330
И это одна из причин говорить о начале нашествия роботов.

00:07:16.330 --> 00:07:20.330
Происходят значительные изменения в способе их применения.

00:07:20.330 --> 00:07:22.330
Спасибо.

00:07:23.330 --> 00:07:25.330
За ближайшие пару месяцев

00:07:25.330 --> 00:07:28.330
мы собираемся пустить роботов в производство

00:07:28.330 --> 00:07:32.330
для добычи нефти из нефтяных скважин под землёй.

00:07:32.330 --> 00:07:36.330
Там очень агрессивная среда, 150˚ C, давление 10,000 PSI.

00:07:36.330 --> 00:07:40.330
Автономный робот будет спускаться вниз и делать эту работу.

00:07:40.330 --> 00:07:43.330
Но таких роботов несколько трудно программировать.

00:07:43.330 --> 00:07:45.330
Как в будущем мы собираемся программировать наших роботов

00:07:45.330 --> 00:07:47.330
и делать их проще в использовании?

00:07:47.330 --> 00:07:50.330
На самом деле, я хочу испытать робота прямо здесь,

00:07:50.330 --> 00:07:55.330
робота по имени Крис. Встань. Да. Хорошо.

00:07:57.330 --> 00:08:01.330
Иди сюда. Заметьте, он думает, что роботы должны быть слегка неуклюжими.

00:08:01.330 --> 00:08:04.330
Он-таки немного неуклюж. Но я собираюсь...

00:08:04.330 --> 00:08:06.330
Крис Андерсон: Просто я из Британии. РБ: Ох.

00:08:06.330 --> 00:08:08.330
(Смех)

00:08:08.330 --> 00:08:10.330
(Аплодисменты)

00:08:10.330 --> 00:08:13.330
Я собираюсь дать этому роботу задание. Это очень сложное задание.

00:08:13.330 --> 00:08:16.330
Заметьте, он кивнул, этим он даёт понять,

00:08:16.330 --> 00:08:19.330
что понимает, что к нему обращаются.

00:08:19.330 --> 00:08:21.330
И если бы я сказал что-то совсем бессмысленное,

00:08:21.330 --> 00:08:24.330
он бы косо на меня глянул и попытался наладить разговор.

00:08:24.330 --> 00:08:27.330
Итак, я провёл перед ним бутылкой.

00:08:27.330 --> 00:08:31.330
Я посмотрел ему в глаза и увидел, что его глаза смотрят на вершину бутылки.

00:08:31.330 --> 00:08:33.330
И я делаю это, а он проверяет.

00:08:33.330 --> 00:08:36.330
Его глаза следят за мной, чтобы понять, на что я смотрю —

00:08:36.330 --> 00:08:38.330
так мы обрели совместное внимание.

00:08:38.330 --> 00:08:41.330
Итак, я делаю это, и он смотрит, смотрит на меня,

00:08:41.330 --> 00:08:45.330
чтобы увидеть, что будет дальше. А сейчас я дам ему бутылку,

00:08:45.330 --> 00:08:47.330
и мы посмотрим, сможет ли он повторить. Ты можешь открыть?

00:08:47.330 --> 00:08:50.330
(Смех)

00:08:50.330 --> 00:08:54.330
Да. Он хорош. Очень хорош.

00:08:54.330 --> 00:08:56.330
Я не показывал тебе, как это сделать.

00:08:56.330 --> 00:08:58.330
Теперь посмотрим, сможешь ли ты её закрыть.

00:08:58.330 --> 00:09:00.330
(Смех)

00:09:00.330 --> 00:09:01.330
Он думает, что робот должен быть очень медленным.

00:09:01.330 --> 00:09:03.330
Хороший робот, молодец.

00:09:03.330 --> 00:09:05.330
Таким образом, мы увидели многое.

00:09:06.330 --> 00:09:09.330
Мы увидели, что когда мы общаемся, когда мы пытаемся показать кому-то,

00:09:09.330 --> 00:09:13.330
как что-то сделать, мы привлекаем его зрительное внимание.

00:09:13.330 --> 00:09:17.330
Он же сообщает нам о его отношении к нам,

00:09:17.330 --> 00:09:20.330
понимает ли он нас; это регулирует социальное общение.

00:09:20.330 --> 00:09:22.330
Присутствовало совместное внимание через взгляд на одно и то же

00:09:22.330 --> 00:09:26.330
и распознавание установки контакта в конце.

00:09:26.330 --> 00:09:29.330
И мы пытались научить всему этому наших лабораторных роботов,

00:09:29.330 --> 00:09:33.330
потому что мы думаем, именно так вы хотели бы общаться с роботами в будущем.

00:09:33.330 --> 00:09:35.330
Сейчас я хочу показать вам одну техническую диаграмму.

00:09:35.330 --> 00:09:39.330
Самое важное при проектировании робота, который сможет общаться, —

00:09:39.330 --> 00:09:41.330
это его система визуального внимания.

00:09:41.330 --> 00:09:44.330
Потому что то, на что он обращает внимание - это то, что он видит

00:09:44.330 --> 00:09:47.330
и с чем общается, а также понимает, что оно делает.

00:09:47.330 --> 00:09:50.330
На видео я вам покажу

00:09:50.330 --> 00:09:54.330
систему визуального внимания робота,

00:09:54.330 --> 00:09:58.330
Он различает тона кожи с помощью цветовой модели HSV,

00:09:58.330 --> 00:10:02.330
поэтому он работает с любыми оттенками кожи человека.

00:10:02.330 --> 00:10:04.330
Он ищет насыщенные цвета, характерные для игрушек.

00:10:04.330 --> 00:10:06.330
И он ищет вокруг движущиеся объекты.

00:10:06.330 --> 00:10:09.330
Он сравнивает все эти объекты в окне внимания

00:10:09.330 --> 00:10:11.330
и определяет наиболее значимый,

00:10:11.330 --> 00:10:13.330
наиболее интересный объект.

00:10:13.330 --> 00:10:17.330
Вот почему его взгляд направляется именно на него.

00:10:17.330 --> 00:10:19.330
И он смотрит прямо на него.

00:10:19.330 --> 00:10:22.330
Вместе с тем, некоторые наиболее незначимые объекты:

00:10:22.330 --> 00:10:25.330
он может решить, что ему одиноко, и искать оттенки кожи,

00:10:25.330 --> 00:10:28.330
или может решить, что ему скучно, и будет искать игрушку, чтобы поиграть.

00:10:28.330 --> 00:10:30.330
И поэтому веса изменяются.

00:10:30.330 --> 00:10:32.330
А вот здесь справа то,

00:10:32.330 --> 00:10:35.330
что мы называем модулем в память о Стивене Спилберге.

00:10:35.330 --> 00:10:37.330
Кто-нибудь смотрел фильм «Искусственный разум»? (Зал: Да.)

00:10:37.330 --> 00:10:39.330
РБ: Да, он очень грустный, но

00:10:39.330 --> 00:10:43.330
помните, когда Хэйли Джоэл Осмент, маленький робот,

00:10:43.330 --> 00:10:47.330
смотрел на голубую фею целые 2000 лет и не мог оторвать от неё глаза?

00:10:47.330 --> 00:10:49.330
Данный модуль позволяет этого избежать,

00:10:49.330 --> 00:10:53.330
потому что это Гауссовское привыкание, которое становится негативным,

00:10:53.330 --> 00:10:56.330
тем более интенсивно, чем дольше робот смотрит на одно и то же.

00:10:56.330 --> 00:10:59.330
В итоге ему становится скучно, и он смотрит на что-нибудь другое.

00:10:59.330 --> 00:11:03.330
Как только мы это поняли — и вот, робот готов — Кисмет,

00:11:03.330 --> 00:11:07.330
который ищет взглядом игрушку. Вы можете сказать, на что он смотрит.

00:11:07.330 --> 00:11:12.330
Можно проследить направление от его глазных яблок, под которыми скрывается камера,

00:11:12.330 --> 00:11:15.330
и сказать, когда он увидит игрушку.

00:11:15.330 --> 00:11:17.330
Вот он даже проявил немного свои эмоции.

00:11:17.330 --> 00:11:18.330
(Смех)

00:11:18.330 --> 00:11:20.330
Но он всё равно будет обращать внимание,

00:11:20.330 --> 00:11:24.330
если на глаза попадётся что-нибудь более значимое,

00:11:24.330 --> 00:11:28.330
например, Синтия Бризил, которая его построила, справа.

00:11:28.330 --> 00:11:33.330
Он видит её, обращает на неё внимание.

00:11:33.330 --> 00:11:37.330
У Кисмет имеется основное, трёхмерное эмоциональное пространство,

00:11:37.330 --> 00:11:40.330
векторное пространство эмоциональности.

00:11:40.330 --> 00:11:45.330
И в разных местах этого пространства он выражает...

00:11:46.330 --> 00:11:48.330
Можно включить звук?

00:11:48.330 --> 00:11:50.330
Хорошо слышно? (Зал: Да.)

00:11:50.330 --> 00:11:55.330
Кисмет: Вы действительно так считаете? Вы действительно так считаете?

00:11:57.330 --> 00:11:59.330
Вы действительно так считаете?

00:12:00.330 --> 00:12:03.330
РБ: Итак, он выражает свои эмоции через лицо

00:12:03.330 --> 00:12:05.330
и просодию в голосе.

00:12:05.330 --> 00:12:09.330
И когда я имел дело с моим роботом Крисом только что,

00:12:09.330 --> 00:12:12.330
он измерял просодию в моем голосе,

00:12:12.330 --> 00:12:17.330
мы научили их этому для четырёх основных типов сообщений,

00:12:17.330 --> 00:12:21.330
которые матери используют в общении с детьми.

00:12:21.330 --> 00:12:24.330
Сейчас мы просто похвалим робота:

00:12:26.330 --> 00:12:28.330
Голос: Хороший робот.

00:12:29.330 --> 00:12:31.330
Такой милый маленький робот.

00:12:31.330 --> 00:12:33.330
(Смех)

00:12:33.330 --> 00:12:35.330
РБ: И робот реагирует соответствующим образом.

00:12:35.330 --> 00:12:39.330
Голос: ...очень хорошо, Кисмет.

00:12:40.330 --> 00:12:42.330
(Смех)

00:12:42.330 --> 00:12:44.330
Голос: Посмотри на мою улыбку.

00:12:46.330 --> 00:12:49.330
РБ: Она улыбается. Она имитирует улыбку. Такое часто встречается.

00:12:49.330 --> 00:12:51.330
Это обычные элементы общения.

00:12:51.330 --> 00:12:54.330
Теперь мы попросили привлечь внимание робота

00:12:54.330 --> 00:12:57.330
и указать, когда он обратит на них внимание.

00:12:57.330 --> 00:13:01.330
Голос: Эй, Кисмет, да, вот так.

00:13:01.330 --> 00:13:05.330
РБ: Итак, она поняла, что привлекла внимание робота.

00:13:08.330 --> 00:13:12.330
Голос: Кисмет, ты любишь игрушки? О.

00:13:13.330 --> 00:13:15.330
РБ: Только что их попросили отругать робота,

00:13:15.330 --> 00:13:19.330
и эта женщина эмоционально загоняет робота в угол.

00:13:19.330 --> 00:13:24.330
Голос: Нет. Нет. Не делай этого. Нет.

00:13:24.330 --> 00:13:27.330
(Смех)

00:13:27.330 --> 00:13:33.330
Неправильно. Нет, нет.

00:13:33.330 --> 00:13:36.330
(Смех)

00:13:36.330 --> 00:13:38.330
РБ: На этом мы остановимся.

00:13:38.330 --> 00:13:40.330
Мы соединили всё это вместе. Затем мы добавили очерёдность общения.

00:13:40.330 --> 00:13:43.330
В общении с кем-нибудь сначала говорим мы.

00:13:43.330 --> 00:13:47.330
Потом мы или поднимаем брови, или двигаем глазами,

00:13:47.330 --> 00:13:50.330
давая понять этим другому человеку, что его очередь говорить.

00:13:50.330 --> 00:13:54.330
Затем говорит он, и мы передаём эстафету туда и обратно между собой.

00:13:54.330 --> 00:13:56.330
Итак, мы научили этому робота.

00:13:56.330 --> 00:13:58.330
Мы научили его повседневным темам,

00:13:58.330 --> 00:14:00.330
мы ничего не рассказывали людям о роботе,

00:14:00.330 --> 00:14:02.330
посадили напротив него и сказали, чтоб говорили с роботом.

00:14:02.330 --> 00:14:04.330
Они не знали, что

00:14:04.330 --> 00:14:06.330
робот не понимал ни слова из сказанного ими,

00:14:06.330 --> 00:14:09.330
и что робот не говорил по-английски.

00:14:09.330 --> 00:14:11.330
Он просто произносил случайные английские фонемы.

00:14:11.330 --> 00:14:13.330
Я хочу, чтобы вы внимательно посмотрели,

00:14:13.330 --> 00:14:17.330
как человек по имени Риччи, который проговорил с роботом 25 минут,

00:14:17.330 --> 00:14:19.330
(Смех)

00:14:19.330 --> 00:14:21.330
говорит: «Я хочу кое-что тебе показать.

00:14:21.330 --> 00:14:23.330
Я хочу показать свои часы».

00:14:23.330 --> 00:14:28.330
И он подносит часы в поле зрение робота,

00:14:28.330 --> 00:14:30.330
указывает на них, двигает ими,

00:14:30.330 --> 00:14:32.330
и, конечно, робот смотрит на них.

00:14:32.330 --> 00:14:35.330
Мы не знаем, понял ли он, что робот...

00:14:36.330 --> 00:14:38.330
Обратите внимание на очерёдность общения.

00:14:38.330 --> 00:14:41.330
Риччи: Так, я хочу тебе кое-что показать. Это часы,

00:14:41.330 --> 00:14:44.330
которые дала мне моя девушка.

00:14:44.330 --> 00:14:46.330
Робот: Ух-ты.

00:14:46.330 --> 00:14:50.330
Риччи: Да, смотри, у них ещё есть голубая подсветка. Я чуть не потерял их на этой неделе.

00:14:51.330 --> 00:14:55.330
(Смех)

00:14:55.330 --> 00:14:58.330
РБ: Итак, он налаживает визуальный контакт, следит за его глазами.

00:14:58.330 --> 00:15:00.330
Риччи: Можешь сделать то же самое? Робот: Да, конечно.

00:15:00.330 --> 00:15:02.330
РБ: Так они и общались.

00:15:02.330 --> 00:15:06.330
А вот ещё другой пример из тех вещей, которыми мы с Крисом занимались.

00:15:06.330 --> 00:15:08.330
Это другой робот, Ког.

00:15:08.330 --> 00:15:14.330
Сначала они налаживают визуальный контакт, затем Кристи смотрит на игрушку,

00:15:14.330 --> 00:15:16.330
робот прослеживает направление её взгляда

00:15:16.330 --> 00:15:18.330
и смотрит на ту же вещь, что и она.

00:15:18.330 --> 00:15:19.330
(Смех)

00:15:19.330 --> 00:15:22.330
Итак, мы будем видеть все больше таких роботов

00:15:22.330 --> 00:15:24.330
на протяжении следующих нескольких лет в лабораториях.

00:15:24.330 --> 00:15:29.330
Большими вопросами, двумя большими вопросами, которые мне часто задают, являются:

00:15:29.330 --> 00:15:31.330
если мы будем делать этих роботов всё более похожими на людей,

00:15:31.330 --> 00:15:36.330
примем ли мы их, будут ли они, наконец, нуждаться в правах?

00:15:36.330 --> 00:15:39.330
А другой вопрос: захотят ли они нас поработить?

00:15:39.330 --> 00:15:40.330
(Смех)

00:15:40.330 --> 00:15:43.330
По первому вопросу: знаете, эту тему любит Голливуд,

00:15:43.330 --> 00:15:46.330
снято много фильмов. Наверняка, вы узнаете этих героев,

00:15:46.330 --> 00:15:50.330
в каждом из этих случаев роботы хотят больше уважения.

00:15:50.330 --> 00:15:53.330
Должны ли мы будем когда-нибудь уважать роботов?

00:15:54.330 --> 00:15:56.330
В конце концов, они просто машины.

00:15:56.330 --> 00:16:00.330
Но знаете, я думаю, мы должны признать, что и мы просто машины.

00:16:00.330 --> 00:16:05.330
В конце концов, это то, что говорит о нас современная молекулярная биология.

00:16:05.330 --> 00:16:08.330
Вы не видите описания того, как

00:16:08.330 --> 00:16:12.330
молекула А подходит и стыкуется с другой молекулой.

00:16:12.330 --> 00:16:15.330
И они приводятся в движение различными зарядами,

00:16:15.330 --> 00:16:19.330
а затем входит душа и заставляет эти молекулы соединиться.

00:16:19.330 --> 00:16:22.330
Это всё механика. Мы механизмы.

00:16:22.330 --> 00:16:25.330
Если мы машины, тогда, в принципе,

00:16:25.330 --> 00:16:29.330
мы должны уметь строить машины из других материалов,

00:16:29.330 --> 00:16:33.330
которые так же живы, как мы.

00:16:33.330 --> 00:16:35.330
Но чтобы признать это,

00:16:35.330 --> 00:16:38.330
мы должны забыть о нашей исключительности, в определённом смысле.

00:16:38.330 --> 00:16:40.330
И мы уже много раз уступали часть нашей исключительности

00:16:40.330 --> 00:16:43.330
под шквалом науки и техники,

00:16:43.330 --> 00:16:45.330
по крайней мере, последние несколько сотен лет.

00:16:45.330 --> 00:16:47.330
500 лет назад мы были вынуждены отказаться от идеи,

00:16:47.330 --> 00:16:50.330
что мы пуп Вселенной,

00:16:50.330 --> 00:16:52.330
когда Земля стала вращаться вокруг Солнца;

00:16:52.330 --> 00:16:57.330
150 лет назад благодаря Дарвину нам пришлось отказаться от идеи, что мы отличны от животных.

00:16:57.330 --> 00:17:00.330
И, знаете ли, для нас это всегда сложно.

00:17:00.330 --> 00:17:03.330
Недавно мы повержены идеей, что у нас даже не было

00:17:03.330 --> 00:17:05.330
момента сотворения, здесь на Земле,

00:17:05.330 --> 00:17:08.330
эта идея очень не нравилась людям. А затем человеческий геном сообщил,

00:17:08.330 --> 00:17:11.330
что, возможно, у нас есть всего лишь 35000 генов. И правда,

00:17:11.330 --> 00:17:14.330
людям это не понравилось, у нас же больше генов.

00:17:14.330 --> 00:17:17.330
Мы не хотели отказываться от нашей исключительности,

00:17:17.330 --> 00:17:19.330
и мысль о том, что роботы могли бы иметь эмоции,

00:17:19.330 --> 00:17:21.330
или те же роботы могли быть живыми существами...

00:17:21.330 --> 00:17:23.330
Я думаю, для нас будет непросто с этим смириться.

00:17:23.330 --> 00:17:27.330
Но мы движемся к тому, чтобы принять это лет через 50.

00:17:27.330 --> 00:17:30.330
И второй вопрос: захотят ли машины поработить нас?

00:17:30.330 --> 00:17:35.330
Стандартный сценарий: мы создаём эти вещи,

00:17:35.330 --> 00:17:38.330
они растут, мы их развиваем, они многому от нас учатся,

00:17:38.330 --> 00:17:42.330
а затем они решают, что мы довольно скучны и медленны.

00:17:42.330 --> 00:17:44.330
И они хотят взять верх над нами.

00:17:44.330 --> 00:17:47.330
Для тех, у кого есть подростки, вы понимаете, о чём я.

00:17:47.330 --> 00:17:48.330
(Смех)

00:17:48.330 --> 00:17:51.330
Но Голливуд сводит это к роботам.

00:17:51.330 --> 00:17:54.330
И вопрос в том,

00:17:54.330 --> 00:17:58.330
построит ли кто-нибудь случайно робота, который захватит мир?

00:17:58.330 --> 00:18:01.330
Как если бы какой-то одинокий парень у себя на заднем дворе

00:18:01.330 --> 00:18:04.330
случайно построил Боинг 747.

00:18:04.330 --> 00:18:06.330
Я не думаю, что это случится.

00:18:06.330 --> 00:18:08.330
И я не думаю...

00:18:08.330 --> 00:18:09.330
(Смех)

00:18:09.330 --> 00:18:12.330
...я не думаю, что мы сознательно будем строить роботов,

00:18:12.330 --> 00:18:14.330
с которыми нам некомфортно.

00:18:14.330 --> 00:18:16.330
Никто не будет строить супер-плохих роботов.

00:18:16.330 --> 00:18:19.330
Перед этим они должны стать просто-плохими роботами,

00:18:19.330 --> 00:18:21.330
а перед этими не такими уж плохими.

00:18:21.330 --> 00:18:22.330
(Смех)

00:18:22.330 --> 00:18:24.330
И мы не собираемся их отпускать так просто.

00:18:24.330 --> 00:18:25.330
(Смех)

00:18:25.330 --> 00:18:31.330
Итак, думаю, можно закончить следующим: роботы наступают,

00:18:31.330 --> 00:18:34.330
но нам не о чем волноваться, это будет очень весело,

00:18:34.330 --> 00:18:38.330
и, надеюсь, вам понравится ваше путешествие в следующие 50 лет.

00:18:38.330 --> 00:18:40.330
(Аплодисменты)

