WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Paul Vrancken
Nagekeken door: Peter van de Ven

00:00:12.896 --> 00:00:17.096
Van Roy Price hebben de meesten van jullie
waarschijnlijk nog nooit gehoord,

00:00:17.120 --> 00:00:19.616
hoewel hij verantwoordelijk
kan zijn geweest

00:00:19.650 --> 00:00:26.216
voor 22 middelmatige minuten
van je leven, op 19 april 2013.

00:00:26.591 --> 00:00:29.736
Hij kan ook verantwoordelijk zijn
geweest voor 22 amusante minuten,

00:00:29.767 --> 00:00:31.806
maar niet voor velen van jullie.

00:00:32.131 --> 00:00:34.186
Dat had alles te maken met een beslissing

00:00:34.218 --> 00:00:36.320
die Roy zo'n drie jaar geleden
moest maken.

00:00:36.354 --> 00:00:40.816
Roy Price is senior manager
bij de Amazon Studios,

00:00:40.855 --> 00:00:43.836
het televisieproductiebedrijf van Amazon.

00:00:43.877 --> 00:00:47.196
Hij is 47 jaar, slank, heeft stekelhaar

00:00:47.231 --> 00:00:51.976
en omschrijft zichzelf op Twitter
als "film, tv, technologie, taco's".

00:00:53.477 --> 00:00:55.723
Roy Price heeft
een hele verantwoordelijke baan,

00:00:55.743 --> 00:00:58.520
want hij moet ervoor zorgen
de goede shows te kiezen,

00:00:58.550 --> 00:01:00.980
de originele producties
die Amazon gaat uitbrengen.

00:01:01.290 --> 00:01:03.616
Dat is natuurlijk
een zeer concurrerend terrein.

00:01:03.913 --> 00:01:06.496
Er zijn al zoveel televisie-shows

00:01:06.535 --> 00:01:08.576
dat Roy niet zomaar een show kan kiezen.

00:01:08.754 --> 00:01:12.466
Hij moet shows vinden
die echt heel goed zijn.

00:01:12.748 --> 00:01:15.536
Met andere woorden, 
hij moet shows vinden

00:01:15.560 --> 00:01:17.936
die aan de goede kant
van deze curve zitten.

00:01:18.274 --> 00:01:20.616
Deze curve toont de
waarderingsverdeling

00:01:20.643 --> 00:01:25.016
van zo'n 2500 tv-shows
op de IMDb-website

00:01:25.043 --> 00:01:27.936
en de waardering loopt van 1 tot 10.

00:01:28.165 --> 00:01:30.936
De hoogte hier toont
hoeveel shows die waardering krijgen.

00:01:31.484 --> 00:01:35.611
Als je show dus een waardering krijgt
van 9 punten of meer, dat is een topper.

00:01:35.631 --> 00:01:37.496
Dan hoort je show tot de top 2 procent.

00:01:37.520 --> 00:01:41.416
Dat zijn shows als 'Breaking Bad',
'Game of Thrones' en 'The Wire',

00:01:41.442 --> 00:01:43.706
dus al die shows die verslavend zijn,

00:01:43.736 --> 00:01:46.706
shows waarvan je hersenen
aan het einde van het seizoen zeggen:

00:01:46.736 --> 00:01:48.776
"Waar kan ik nog meer afleveringen zien?"

00:01:49.130 --> 00:01:50.420
Zo'n soort show.

00:01:51.084 --> 00:01:53.486
Links, voor de duidelijkheid,
hier aan dit einde,

00:01:53.512 --> 00:01:56.616
heb je een show getiteld
'Toddlers and Tiaras' --

00:01:57.075 --> 00:01:58.966
(Gelach)

00:01:59.486 --> 00:02:00.856
-- dan weet je direct

00:02:00.881 --> 00:02:02.841
wat er aan dat eind
van de curve gebeurt.

00:02:03.908 --> 00:02:07.256
Roy Price maakt zich geen zorgen
om links op de curve te komen,

00:02:07.270 --> 00:02:10.189
omdat je volgens mij
heel intelligent moet zijn

00:02:10.199 --> 00:02:12.326
om onder 'Toddlers and Tiaras' te scoren.

00:02:12.650 --> 00:02:16.056
Waar hij zich dus zorgen om maakt,
is deze bult in het midden,

00:02:16.087 --> 00:02:17.846
de bult van gemiddelde tv,

00:02:17.866 --> 00:02:20.236
de shows die niet
echt goed of heel slecht zijn.

00:02:20.256 --> 00:02:22.515
Je raakt er niet echt opgewonden van.

00:02:22.535 --> 00:02:27.156
Hij moet er dus voor zorgen
dat hij aan de rechterkant komt.

00:02:27.185 --> 00:02:28.956
De druk is dus hoog

00:02:28.984 --> 00:02:31.246
en het is natuurlijk ook de eerste keer

00:02:31.260 --> 00:02:33.176
dat Amazon iets dergelijks doet.

00:02:34.287 --> 00:02:36.406
Roy Price wil dus geen risico lopen.

00:02:36.704 --> 00:02:39.086
Hij wil succes creëren.

00:02:39.111 --> 00:02:41.076
Hij wil gegarandeerd succes

00:02:41.104 --> 00:02:43.416
en wat hij dus doet,
is een wedstrijd houden.

00:02:43.542 --> 00:02:46.716
Hij neemt een aantal ideeën voor tv-shows

00:02:46.746 --> 00:02:48.996
en door evaluatie

00:02:49.021 --> 00:02:52.586
kiezen ze acht kandidaten voor tv-shows.

00:02:53.143 --> 00:02:56.356
Dan maakt hij de eerste aflevering
van elk van deze shows

00:02:56.381 --> 00:02:59.146
en zet ze gratis online,
zodat iedereen ze kan zien.

00:02:59.516 --> 00:03:01.826
Als Amazon dingen voor niks weggeeft,

00:03:01.855 --> 00:03:03.596
dan wil je het hebben ook, toch?

00:03:04.706 --> 00:03:07.816
Dus zien miljoenen kijkers
die afleveringen.

00:03:08.583 --> 00:03:11.796
Maar wat ze niet beseffen is dat,
terwijl ze zitten te kijken,

00:03:11.821 --> 00:03:13.856
zij zelf ook bekeken worden.

00:03:14.045 --> 00:03:16.336
Ze worden bekeken
door Roy Price en zijn team,

00:03:16.359 --> 00:03:17.754
die alles opslaan.

00:03:17.774 --> 00:03:21.136
Ze slaan op wanneer iemand
op 'afspelen' of op 'pauze' drukt,

00:03:21.155 --> 00:03:23.696
welke stukken ze overslaan,
welke worden herhaald.

00:03:23.802 --> 00:03:25.976
Ze verzamelen miljoenen gegevens,

00:03:26.000 --> 00:03:28.096
omdat ze die data willen hebben

00:03:28.117 --> 00:03:30.616
om te kunnen beslissen
welke show ze moeten maken.

00:03:30.941 --> 00:03:32.655
Dus verzamelen ze die data

00:03:32.675 --> 00:03:35.716
en als die data zijn geanalyseerd
rolt daar een antwoord uit,

00:03:35.736 --> 00:03:36.876
en dat antwoord is:

00:03:36.894 --> 00:03:41.536
"Amazon moet een serie maken
over vier Republikeinse senatoren".

00:03:42.632 --> 00:03:43.656
En dat deden ze.

00:03:44.248 --> 00:03:45.920
Weet iemand de naam van de show?

00:03:46.262 --> 00:03:47.916
(Publiek) 'Alpha House'.

00:03:48.239 --> 00:03:49.716
Ja, 'Alpha House',

00:03:49.736 --> 00:03:53.626
maar het lijkt erop dat niet veel mensen
zich die show herinneren,

00:03:53.651 --> 00:03:55.586
hij pakte dan ook niet erg goed uit.

00:03:55.611 --> 00:03:57.526
Eigenlijk is het maar een doorsnee show,

00:03:57.573 --> 00:04:02.136
letterlijk, omdat het gemiddelde
van deze curve hier 7,4 is

00:04:02.170 --> 00:04:04.536
en 'Alpha House' kwam op 7,5,

00:04:04.550 --> 00:04:06.546
dus net boven het gemiddelde,

00:04:06.569 --> 00:04:09.400
zeker niet waar Roy Price
en zijn team op mikten.

00:04:10.493 --> 00:04:13.176
In de tussentijd echter,
ongeveer tegelijkertijd,

00:04:13.210 --> 00:04:14.776
bij een ander bedrijf,

00:04:14.799 --> 00:04:19.096
slaagde een andere manager erin
een topproductie te maken met data-analyse

00:04:19.118 --> 00:04:20.676
en zijn naam is Ted.

00:04:20.698 --> 00:04:24.056
Ted Sarandos is bij Netflix
hoofd 'eigen productie'

00:04:24.074 --> 00:04:26.416
en net als Roy is hij
op een constante missie

00:04:26.432 --> 00:04:27.966
die geweldige tv-show te vinden;

00:04:27.988 --> 00:04:29.776
hij gebruikt daarbij ook data,

00:04:29.837 --> 00:04:31.815
alleen doet hij het een beetje anders.

00:04:31.856 --> 00:04:35.576
In plaats van een competitie te houden
keken hij -- en zijn team natuurlijk --

00:04:35.607 --> 00:04:39.246
naar alle data die ze al hadden
over Netflix-kijkers,

00:04:39.249 --> 00:04:41.176
dus de waarderingscijfers die ze geven,

00:04:41.199 --> 00:04:43.976
waar ze meestal naar kijken,
wat ze leuk vinden, enz.

00:04:43.986 --> 00:04:45.814
Vervolgens gebruikten ze die data

00:04:45.834 --> 00:04:48.616
om elk detail
over het publiek te ontdekken:

00:04:48.636 --> 00:04:50.406
welke shows ze leuk vinden,

00:04:50.436 --> 00:04:52.136
welke producers, welke acteurs.

00:04:52.756 --> 00:04:54.836
Zodra ze al die details bij elkaar hadden,

00:04:54.860 --> 00:04:56.526
namen ze een sprong in het diepe

00:04:56.555 --> 00:05:01.145
en besloten niet te kiezen
voor een programma over vier senatoren

00:05:01.165 --> 00:05:04.310
maar voor een dramaserie over één senator.

00:05:04.774 --> 00:05:06.416
Kennen jullie die serie?

00:05:06.646 --> 00:05:07.586
(Gelach)

00:05:07.890 --> 00:05:11.496
Ja, 'House of Cards', en Netflix
had een voltreffer met die show,

00:05:11.512 --> 00:05:13.806
in ieder geval
voor de eerste twee seizoenen.

00:05:14.286 --> 00:05:17.326
(Gelach) (Applaus)

00:05:17.939 --> 00:05:20.966
'House of Cards' scoort 9.1 op deze curve,

00:05:20.980 --> 00:05:24.056
precies waar ze wilden zitten.

00:05:24.336 --> 00:05:26.476
De vraag is nu natuurlijk:
wat gebeurde hier?

00:05:26.669 --> 00:05:29.576
Je hebt twee concurrerende
data-bewuste bedrijven.

00:05:29.576 --> 00:05:32.266
Ze koppelen al deze miljoenen gegevens

00:05:32.299 --> 00:05:34.726
en dan pakt dat heel goed uit voor de een,

00:05:34.737 --> 00:05:36.406
maar niet voor de ander.

00:05:36.420 --> 00:05:37.656
Waarom eigenlijk?

00:05:37.674 --> 00:05:41.226
Het lijkt zo vanzelfsprekend
dat dit altijd zou moeten werken.

00:05:41.250 --> 00:05:43.646
Ik bedoel, als je miljoenen
gegevens verzamelt

00:05:43.666 --> 00:05:45.486
voor een beslissing die je gaat nemen,

00:05:45.516 --> 00:05:48.196
dan zou je toch een goede beslissing
moeten kunnen nemen.

00:05:48.227 --> 00:05:50.276
Je kunt steunen op 200 jaar statistiek.

00:05:50.276 --> 00:05:53.286
Je versterkt het nog
met hele krachtige computers.

00:05:53.312 --> 00:05:56.520
Dan mag je toch in ieder geval
wel goede televisie verwachten, niet?

00:05:58.036 --> 00:06:00.600
Mocht data-analyse zo niet werken

00:06:01.717 --> 00:06:03.696
dan wordt het een beetje griezelig,

00:06:03.709 --> 00:06:07.506
want we leven in een tijd
waarin we steeds meer op data afgaan

00:06:07.533 --> 00:06:11.920
om serieuze beslissingen te nemen
die televisie ver te boven gaan.

00:06:12.954 --> 00:06:16.000
Kent iemand hier het bedrijf
Multi-Health Systems?

00:06:17.249 --> 00:06:18.736
Niemand. OK, gelukkig maar.

00:06:19.095 --> 00:06:22.246
Multi-Health Systems
is een software-bedrijf

00:06:22.264 --> 00:06:24.966
en ik hoop dat niemand hier in deze zaal

00:06:24.985 --> 00:06:28.006
ooit in contact komt met die software,

00:06:28.026 --> 00:06:30.518
want anders betekent het
dat je in de gevangenis zit.

00:06:30.538 --> 00:06:31.396
(Gelach)

00:06:31.413 --> 00:06:35.096
Als iemand in de VS in de gevangenis zit
en voorwaardelijk vrij wil komen,

00:06:35.104 --> 00:06:39.416
dan is het hoogstwaarschijnlijk
dat data-analysesoftware van dat bedrijf

00:06:39.446 --> 00:06:42.946
gebruikt wordt om te bepalen
of die aanvraag wordt gehonoreerd.

00:06:42.976 --> 00:06:45.456
Het is dus hetzelfde principe
als bij Amazon en Netflix,

00:06:45.480 --> 00:06:50.296
maar in plaats van te beslissen
of een tv-show het goed zal doen,

00:06:50.323 --> 00:06:53.016
beslis je nu of een persoon
het goed of slecht gaat doen.

00:06:55.380 --> 00:06:58.766
Middelmatige tv, 22 minuten lang,
kan heel slecht zijn,

00:06:58.786 --> 00:07:01.700
maar meer tijd in de gevangenis
zelfs slechter, gok ik.

00:07:03.298 --> 00:07:06.716
Jammer genoeg zijn er zelfs bewijzen
dat deze data-analyse,

00:07:06.727 --> 00:07:10.736
ondanks de beschikbaarheid van veel data,
niet altijd de optimale resultaten geeft.

00:07:11.011 --> 00:07:13.702
Dat komt niet omdat een bedrijf
als Multi-Health Systems

00:07:13.727 --> 00:07:15.373
niet met data om kan gaan.

00:07:15.387 --> 00:07:17.826
Zelfs de slimste data-analisten
kunnen fout zitten.

00:07:17.826 --> 00:07:19.880
Ja, zelfs Google zit soms fout.

00:07:20.948 --> 00:07:25.626
In 2009 berichtte Google
dat ze met data-analyse

00:07:25.650 --> 00:07:29.546
griep-epidemieën konden voorspellen,
het vervelende soort griep,

00:07:29.562 --> 00:07:32.886
door data-analyse los te laten
op wat mensen op Google opzochten.

00:07:33.404 --> 00:07:37.116
Het pakte wonderwel goed uit
en het werd een hit in het nieuws,

00:07:37.142 --> 00:07:39.576
tot en met het toppunt van
wetenschappelijk succes:

00:07:39.586 --> 00:07:41.656
een publicatie in het tijdschrift Nature.

00:07:41.879 --> 00:07:45.356
Eerst werkte het goed,
jaar na jaar na jaar,

00:07:45.371 --> 00:07:47.236
tot het een bepaald jaar niet werkte.

00:07:47.256 --> 00:07:49.416
Niemand kon precies zeggen waarom.

00:07:49.436 --> 00:07:51.257
Het werkte dat jaar gewoon niet

00:07:51.277 --> 00:07:53.246
en dat haalde weer het nieuws natuurlijk,

00:07:53.256 --> 00:07:54.854
inclusief het terugtrekken

00:07:54.854 --> 00:07:57.440
van een publicatie
in het tijdschrift Nature.

00:07:58.596 --> 00:08:02.046
Dus zelfs de grootste data-verzamelaars,
Amazon en Google,

00:08:02.067 --> 00:08:03.976
hebben het soms mis.

00:08:04.988 --> 00:08:07.146
Ondanks al die mislukkingen

00:08:07.163 --> 00:08:11.086
neemt het gebruik van data snel toe
bij beslissingen in het echte leven:

00:08:11.099 --> 00:08:12.906
op de werkvloer,

00:08:12.921 --> 00:08:14.726
bij wetshandhaving,

00:08:14.744 --> 00:08:15.910
de geneeskunde.

00:08:16.601 --> 00:08:19.836
We kunnen er dus maar beter voor zorgen
dat die data ook helpen.

00:08:19.864 --> 00:08:23.136
Zelf heb ik veel gesteggel gezien
bij het gebruiken van data,

00:08:23.161 --> 00:08:25.066
omdat ik werk in de computer-genetica,

00:08:25.086 --> 00:08:27.566
wat ook een terrein is
waar veel slimme mensen

00:08:27.602 --> 00:08:31.256
ongelooflijke hoeveelheden data gebruiken
om serieuze beslissingen te nemen,

00:08:31.256 --> 00:08:34.930
zoals over een kankertherapie
of het ontwikkelen van een medicijn.

00:08:35.716 --> 00:08:37.936
Door de jaren heb ik
een patroon zien ontstaan,

00:08:37.966 --> 00:08:41.156
of een soort regel als je wilt,
over wat het verschil maakt

00:08:41.176 --> 00:08:43.476
tussen succesvolle beslissingen
op basis van data

00:08:43.496 --> 00:08:45.116
en niet-succesvolle beslissingen.

00:08:45.136 --> 00:08:48.640
Ik vind dit een patroon dat ik wil delen
en het gaat als volgt.

00:08:50.755 --> 00:08:52.835
Als je een complex probleem wilt oplossen,

00:08:52.865 --> 00:08:54.416
doe je in wezen twee dingen.

00:08:54.432 --> 00:08:57.242
Eerst deel je het probleem op
in kleine stukjes,

00:08:57.272 --> 00:09:00.576
zodat je die onderdelen
grondig kunt analyseren,

00:09:00.602 --> 00:09:02.586
en dan zet je natuurlijk de tweede stap:

00:09:02.599 --> 00:09:05.176
je doet al die stukjes weer bij elkaar

00:09:05.188 --> 00:09:06.596
en je komt tot een conclusie.

00:09:06.604 --> 00:09:08.686
Soms moet je het nog een keer doen,

00:09:08.716 --> 00:09:10.726
maar steeds draait het om twee dingen:

00:09:10.746 --> 00:09:12.720
uit elkaar halen en terug zetten.

00:09:14.464 --> 00:09:16.126
Het cruciale is

00:09:16.147 --> 00:09:19.116
dat voor data en data-analyse

00:09:19.119 --> 00:09:21.136
alleen het eerste deel werkt.

00:09:21.441 --> 00:09:23.706
Data en data-analyse,
hoe indrukwekkend ook,

00:09:23.734 --> 00:09:27.826
helpen je alleen een probleem
te ontrafelen en details te begrijpen.

00:09:28.278 --> 00:09:31.576
Het is niet geschikt om die stukjes
weer bij elkaar te brengen

00:09:31.597 --> 00:09:33.496
en dan tot een conclusie te komen.

00:09:33.688 --> 00:09:36.496
Een ander hulpmiddel kan dat wel,
en we hebben het allemaal:

00:09:36.506 --> 00:09:37.806
het brein.

00:09:37.831 --> 00:09:39.586
Waar het brein echt goed in is,

00:09:39.606 --> 00:09:41.956
is stukjes weer bij elkaar brengen,

00:09:41.981 --> 00:09:44.066
zelfs als je onvolledige informatie hebt,

00:09:44.076 --> 00:09:45.706
en tot een goede conclusie komen,

00:09:45.736 --> 00:09:48.416
zeker als het het brein van een expert is.

00:09:48.664 --> 00:09:51.356
Daarom geloof ik
dat Netflix zo'n succes had,

00:09:51.385 --> 00:09:54.946
omdat ze de data en het brein gebruikten
waar ze in het proces thuishoren.

00:09:54.966 --> 00:09:58.336
Ze gebruiken data om eerst veel details
van hun publiek te begrijpen,

00:09:58.357 --> 00:10:01.466
details die ze anders nooit zo grondig
hadden kunnen begrijpen.

00:10:01.956 --> 00:10:04.576
Maar de beslissing
om al deze losse stukjes

00:10:04.596 --> 00:10:07.686
weer bijeen te brengen
en een show als House of Cards te maken,

00:10:07.706 --> 00:10:09.241
dat stond nergens in de data.

00:10:09.261 --> 00:10:13.136
Ted Sarandos en zijn team namen 
de beslissing om die serie goed te keuren,

00:10:13.153 --> 00:10:17.901
waarmee ze trouwens ook
een groot persoonlijk risico namen.

00:10:18.696 --> 00:10:21.546
Bij Amazon deden ze
het echter omgekeerd, dus fout.

00:10:21.578 --> 00:10:24.466
Ze gebruikten steeds data
om hun beslissing te sturen,

00:10:24.478 --> 00:10:26.896
eerst toen ze hun wedstrijd
van tv-ideeën hielden,

00:10:26.915 --> 00:10:30.376
en later toen ze besloten
'Alpha House' te maken.

00:10:30.677 --> 00:10:33.056
Dat was voor hen
een hele veilige beslissing,

00:10:33.066 --> 00:10:35.443
omdat ze altijd konden wijzen
naar de data en zeggen:

00:10:35.453 --> 00:10:37.096
"Dit zeggen de data ons."

00:10:37.180 --> 00:10:38.490
Maar het leidde niet

00:10:38.510 --> 00:10:41.500
tot de uitzonderlijke resultaten
die ze hadden gehoopt.

00:10:42.390 --> 00:10:47.136
Data zijn dus een enorm nuttig middel
om betere beslissingen te nemen,

00:10:47.152 --> 00:10:49.586
maar ik denk dat dingen fout gaan

00:10:49.599 --> 00:10:52.096
zodra data die beslissingen
beginnen te sturen.

00:10:52.339 --> 00:10:56.146
Hoe sterk ze ook zijn,
data zijn slechts een hulpmiddel

00:10:56.170 --> 00:10:59.256
en met dat in je achterhoofd
vind ik dit ding hier heel nuttig.

00:10:59.284 --> 00:11:00.716
Velen van jullie zullen .....

00:11:00.726 --> 00:11:01.506
(Gelach)

00:11:01.527 --> 00:11:03.076
Voordat er data waren,

00:11:03.087 --> 00:11:05.856
was dit het hulpmiddel
om beslissingen te nemen.

00:11:05.996 --> 00:11:07.036
(Gelach)

00:11:07.175 --> 00:11:08.766
Velen van jullie kennen het.

00:11:08.789 --> 00:11:10.693
Dit speeltje hier heet de Magic 8 Ball,

00:11:10.723 --> 00:11:11.876
heel verbazingwekkend,

00:11:11.876 --> 00:11:14.556
omdat als je een besluit moet nemen,
een ja of nee vraag,

00:11:14.577 --> 00:11:18.376
je alleen de bal maar hoeft te schudden
en dan krijg je het antwoord

00:11:18.394 --> 00:11:21.336
-- "Hoogstwaarschijnlijk" --
hier in dit venster, hier en nu.

00:11:21.336 --> 00:11:23.596
Ik laat hem straks
rondgaan ter demonstratie.

00:11:23.786 --> 00:11:24.686
(Gelach)

00:11:24.968 --> 00:11:28.446
Wat ik natuurlijk wil zeggen is
dat ik besluiten heb genomen in mijn leven

00:11:28.466 --> 00:11:31.366
waarbij ik achteraf toch naar de bal
had moeten luisteren.

00:11:32.292 --> 00:11:34.816
Maar als je de data
tot je beschikking hebt,

00:11:34.828 --> 00:11:37.536
wil je zo'n bal door iets
veel geavanceerders vervangen,

00:11:37.557 --> 00:11:41.176
zoals data-analyse,
om tot een besluit te komen.

00:11:41.972 --> 00:11:44.296
Maar fundamenteel verandert er niets.

00:11:44.313 --> 00:11:47.206
De bal kan slimmer
en slimmer en slimmer worden,

00:11:47.225 --> 00:11:50.136
maar ik denk dat wij nog steeds
de beslissingen moeten nemen

00:11:50.152 --> 00:11:53.056
als we iets buitengewoons willen bereiken

00:11:53.078 --> 00:11:54.706
aan de rechterkant van de curve.

00:11:56.455 --> 00:11:59.596
Ik vind dat eigenlijk
een hele bemoedigende boodschap,

00:11:59.613 --> 00:12:03.576
dat het zelfs onder het oog
van grote hoeveelheden data

00:12:03.607 --> 00:12:07.496
loont om besluiten te nemen,

00:12:07.531 --> 00:12:10.346
om expert te zijn bij wat je doet

00:12:10.364 --> 00:12:12.086
en om risico's te nemen.

00:12:12.511 --> 00:12:14.933
Want uiteindelijk zijn het niet de data

00:12:14.963 --> 00:12:19.080
maar de risico's die je doen belanden
aan de rechterzijde van de curve.

00:12:19.952 --> 00:12:21.056
Dank je wel.

00:12:21.252 --> 00:12:23.820
(Applaus)

