WEBVTT
Kind: captions
Language: sv

00:00:00.000 --> 00:00:07.000
Översättare: Annika Bidner
Granskare: Anders Björk

00:00:12.820 --> 00:00:17.096
Roy Price är en man som de flesta av er
förmodligen aldrig hört talas om,

00:00:17.120 --> 00:00:19.616
även om han kan ha varit ansvarig

00:00:19.640 --> 00:00:26.400
för 22 ganska mediokra minuter
av ditt liv den 19 april 2013.

00:00:26.400 --> 00:00:29.846
Han kan också ha varit ansvarig
för 22 väldigt underhållande minuter,

00:00:29.846 --> 00:00:32.016
men inte för så många av er.

00:00:32.040 --> 00:00:33.680
Och allt beror på ett beslut

00:00:33.680 --> 00:00:36.020
som Roy var tvungen att ta
för ungefär tre år sen.

00:00:36.020 --> 00:00:40.816
Ni förstår, Roy Price är en hög chef
inom Amazon Studios.

00:00:40.840 --> 00:00:43.856
Det är Amazons produktionsbolag för tv.

00:00:43.880 --> 00:00:47.136
Han är 47 år gammal,
smal, med taggigt hår,

00:00:47.160 --> 00:00:51.976
beskriver sig på Twitter
som "film, tv, teknik, tacos".

00:00:52.000 --> 00:00:57.176
Roy Price har ett ansvarsfullt jobb,
för det är hans ansvar att välja

00:00:57.200 --> 00:01:01.256
vilka serier, vilket originalinnehåll
som Amazon ska ta fram.

00:01:01.280 --> 00:01:03.616
Självklart innebär det hög konkurrens.

00:01:03.640 --> 00:01:06.376
Det görs så många tv-serier,

00:01:06.400 --> 00:01:08.576
så Roy kan inte välja
vilken serie som helst.

00:01:08.600 --> 00:01:12.696
Han måste hitta
en riktigt, riktigt bra serie.

00:01:12.720 --> 00:01:15.536
Med andra ord måste han hitta serier

00:01:15.560 --> 00:01:17.936
som ligger längst ut till höger
på den här kurvan.

00:01:17.960 --> 00:01:20.616
Den här kurvan är betygsfördelningen

00:01:20.640 --> 00:01:25.016
för ungefär 2 500 tv-serier
i IMDBs databas,

00:01:25.040 --> 00:01:27.936
och betygssnittet
kan vara mellan 1 och 10,

00:01:27.960 --> 00:01:30.936
och höjden här visar
hur många serier som får det betyget.

00:01:30.960 --> 00:01:35.520
Så om en serie får ett snittbetyg
på 9 poäng eller högre är den en vinnare.

00:01:35.520 --> 00:01:37.496
Då har man en serie bland de 2 procenten.

00:01:37.520 --> 00:01:41.416
Det är serier som "Breaking Bad",
"Game of Thrones", "The Wire".

00:01:41.440 --> 00:01:43.736
De här serierna är beroendeframkallande,

00:01:43.760 --> 00:01:46.560
så när man har sett en säsong
säger ens hjärna liksom,

00:01:46.560 --> 00:01:49.016
"Var kan jag hitta fler
sådana här avsnitt?"

00:01:49.040 --> 00:01:50.650
Den sortens serie.

00:01:50.920 --> 00:01:53.416
Till vänster, här borta,
för att vara tydlig,

00:01:53.440 --> 00:01:56.616
finns en serie som heter
"Toddles and Tiaras" -

00:01:56.640 --> 00:01:59.296
(Skratt)

00:01:59.320 --> 00:02:00.856
- vilket borde säga nog om

00:02:00.880 --> 00:02:03.071
vad som händer på den sidan av kurvan.

00:02:03.465 --> 00:02:07.256
Roy Price är inte orolig för
att hamna på den sidan av kurvan,

00:02:07.280 --> 00:02:09.970
för jag tror att man behöver ha
en riktigt skarp hjärna

00:02:09.970 --> 00:02:11.996
för att bli sämre
än "Toddlers and Tiaras".

00:02:11.996 --> 00:02:15.896
Vad han oroar sig för är klumpen i mitten,

00:02:15.920 --> 00:02:17.736
klumpen av halvbra tv,

00:02:17.760 --> 00:02:20.616
ni vet, sådana där serier
som varken är bra eller dåliga,

00:02:20.639 --> 00:02:22.295
som inte gör någon exalterad.

00:02:22.320 --> 00:02:27.110
Så han behöver bli säker på
att han verkligen hamnar rätt.

00:02:27.110 --> 00:02:28.826
Det finns ett tryck på att lyckas,

00:02:28.826 --> 00:02:30.976
och det är förstås också första gången

00:02:31.000 --> 00:02:33.176
som Amazon ens gör något sånt här,

00:02:33.200 --> 00:02:36.536
så Roy Price vill inte ta några risker.

00:02:36.560 --> 00:02:39.016
Han vill bygga framgång.

00:02:39.040 --> 00:02:40.816
Han behöver en garanterad succé,

00:02:40.840 --> 00:02:43.416
så han anordnar en tävling.

00:02:43.440 --> 00:02:46.576
Han tar ett antal tv-seriekoncept

00:02:46.600 --> 00:02:48.896
och genom att utvärdera dem

00:02:48.920 --> 00:02:52.800
tar de ut åtta kandidater till tv-serier,

00:02:52.800 --> 00:02:56.256
och sen gör han det första avsnittet
av var och en av dessa tv-serier

00:02:56.280 --> 00:02:59.416
och lägger ut dem gratis online
så att alla kan se dem.

00:02:59.440 --> 00:03:01.696
Och när Amazon delar ut saker gratis

00:03:01.720 --> 00:03:03.256
vill man ha dem, eller hur?

00:03:03.280 --> 00:03:08.416
Så miljoner människor tittar på avsnitten.

00:03:08.440 --> 00:03:11.656
Vad de inte inser är
att när de tittar på sina serier

00:03:11.680 --> 00:03:13.976
är det de som blir betraktade.

00:03:14.000 --> 00:03:16.336
De betraktas av Roy Price och hans team,

00:03:16.360 --> 00:03:17.736
som spelar in allt.

00:03:17.760 --> 00:03:21.136
De spelar in när någon trycker play,
när någon pausar,

00:03:21.160 --> 00:03:23.696
vilka delar de hoppar över,
vilka delar de ser igen.

00:03:23.720 --> 00:03:25.976
De samlar in miljontals datapunkter,

00:03:26.000 --> 00:03:28.096
för de vill ha dem

00:03:28.120 --> 00:03:30.816
när de bestämmer
vilken tv-serie de ska göra.

00:03:30.840 --> 00:03:33.016
Så de samlar in datan,

00:03:33.040 --> 00:03:35.616
de bearbetar informationen,
och ett svar träder fram,

00:03:35.640 --> 00:03:36.856
och svaret är,

00:03:36.880 --> 00:03:42.416
"Amazon borde göra en komedi
om fyra republikanska senatorer i USA."

00:03:42.440 --> 00:03:43.656
De gjorde den serien.

00:03:43.680 --> 00:03:45.840
Vet någon vad serien heter?

00:03:46.720 --> 00:03:48.016
(Publiken: "Alpha House")

00:03:48.040 --> 00:03:49.496
Ja, "Alpha House",

00:03:49.520 --> 00:03:53.616
men det verkar faktiskt inte vara
så många av er som minns den serien,

00:03:53.640 --> 00:03:55.496
för den blev inte så bra.

00:03:55.520 --> 00:03:57.376
Det blev bara en medioker serie,

00:03:57.400 --> 00:04:01.976
rent bokstavligen,
för mitten på kurvan är 7,4,

00:04:02.000 --> 00:04:04.416
och "Alpha House" landade på 7,5,

00:04:04.440 --> 00:04:06.456
en serie strax över genomsnittet,

00:04:06.480 --> 00:04:09.700
men det var verkligen inte
vad Roy Price och hans team siktade på.

00:04:10.320 --> 00:04:13.176
Men ungefär samtidigt

00:04:13.200 --> 00:04:14.776
på ett annat företag

00:04:14.800 --> 00:04:19.016
lyckades en annan hög chef ro i land
en toppserie med hjälp av dataanalys,

00:04:19.040 --> 00:04:20.616
och han heter Ted,

00:04:20.640 --> 00:04:24.056
Ted Sarandos, som är
innehållschef på Netflix,

00:04:24.080 --> 00:04:26.216
och precis som Roy letar han ständigt

00:04:26.240 --> 00:04:27.736
efter den stora tv-serien,

00:04:27.760 --> 00:04:29.730
och han använder data för att göra det,

00:04:29.730 --> 00:04:31.815
men han gör det
på ett lite annorlunda sätt.

00:04:31.839 --> 00:04:35.576
Så istället för att hålla en tävling,

00:04:35.600 --> 00:04:39.136
tittade han och hans team på den data
som de redan hade om Netflixtittare,

00:04:39.160 --> 00:04:41.090
som de betyg de gett till deras serier,

00:04:41.090 --> 00:04:43.976
tittarhistoriken, vilka serier
de gillade, och så vidare.

00:04:44.000 --> 00:04:45.896
De använde datan för att upptäcka

00:04:45.920 --> 00:04:48.420
alla små detaljer om sin publik:

00:04:48.420 --> 00:04:49.900
vilka slags serier de gillade,

00:04:49.900 --> 00:04:52.266
vilka slags producenter,
vilka slags skådespelare.

00:04:52.266 --> 00:04:54.736
Och när de väl hade satt ihop alla delar

00:04:54.760 --> 00:04:56.416
gjorde de en chansning

00:04:56.440 --> 00:04:58.536
och bestämde sig för att skapa

00:04:58.560 --> 00:05:01.016
inte en komedi om fyra senatorer,

00:05:01.040 --> 00:05:03.920
utan en dramaserie om en enda senator.

00:05:04.760 --> 00:05:06.416
Vet ni vilken serie?

00:05:06.440 --> 00:05:07.736
(Skratt)

00:05:07.760 --> 00:05:11.496
Ja, "House of Cards", och Netflix
slog förstås huvudet på spiken med den,

00:05:11.520 --> 00:05:13.656
iallafall de första två säsongerna.

00:05:13.680 --> 00:05:17.656
(Skratt) (Applåder)

00:05:17.680 --> 00:05:20.856
"House of Cards" får 9,1
i snittbetyg på kurvan,

00:05:20.880 --> 00:05:24.056
så det är precis där de ville vara.

00:05:24.080 --> 00:05:26.440
Nu är frågan, vad hände här?

00:05:26.440 --> 00:05:29.176
Vi har två väldigt tävlingsinriktade,
datakunniga företag.

00:05:29.200 --> 00:05:32.056
De kombinerar miljontals datapunkter,

00:05:32.080 --> 00:05:34.456
och sen går det utmärkt för en av dem,

00:05:34.480 --> 00:05:36.336
och det fungerar inte för den andra.

00:05:36.360 --> 00:05:37.576
Varför?

00:05:37.600 --> 00:05:41.056
För logiken säger
att det borde fungera varje gång.

00:05:41.080 --> 00:05:43.536
Om man samlar ihop miljontals datapunkter

00:05:43.560 --> 00:05:45.296
om ett beslut man ska fatta

00:05:45.320 --> 00:05:47.936
så borde det bli ett ganska bra beslut.

00:05:47.960 --> 00:05:50.176
Det finns 200 år av statistik
att luta sig mot.

00:05:50.200 --> 00:05:53.216
Den förstärks med kraftfulla datorer.

00:05:53.240 --> 00:05:56.520
Det minsta man kan begära
är bra tv, eller hur?

00:05:57.880 --> 00:06:00.780
Om dataanalys inte fungerar på det sättet

00:06:01.520 --> 00:06:03.576
så blir det lite skrämmande,

00:06:03.600 --> 00:06:07.416
för vi lever i en tid
där vi allt oftare lutar oss mot data

00:06:07.440 --> 00:06:11.920
för att fatta allvarliga beslut
som går långt bortom tv.

00:06:12.760 --> 00:06:16.000
Känner någon här till
företaget Multi-Health Systems?

00:06:17.080 --> 00:06:18.736
Ingen. OK, det är faktiskt bra.

00:06:18.760 --> 00:06:21.976
Multi-Health Systems
är ett mjukvaruföretag,

00:06:22.000 --> 00:06:24.816
och jag hoppas att ingen i det här rummet

00:06:24.840 --> 00:06:28.016
någonsin kommer i kontakt
med deras mjukvara,

00:06:28.040 --> 00:06:30.136
för det betyder att du sitter i fängelse.

00:06:30.160 --> 00:06:31.320
(Skratt)

00:06:31.320 --> 00:06:34.896
Om någon här i USA sitter i fängelse
och de ansöker om villkorlig frigivning

00:06:34.920 --> 00:06:37.960
är det väldigt sannolikt
att dataanalysprogram

00:06:37.960 --> 00:06:42.856
från det företaget kommer att användas
för att pröva frigivningen.

00:06:42.880 --> 00:06:45.456
Så det är samma princip
som för Amazon och Netflix,

00:06:45.480 --> 00:06:50.096
men istället för att bestämma
om en tv-serie ska bli bra eller dålig

00:06:50.120 --> 00:06:53.016
bestämmer man om en person
ska bli bra eller dålig.

00:06:53.040 --> 00:06:58.536
Och 22 minuter av medioker tv
kan vara ganska dåligt,

00:06:58.560 --> 00:07:01.200
men jag antar att fler år
i fängelse är ännu värre.

00:07:02.360 --> 00:07:06.496
Oturligt nog finns det faktiskt
en del bevis för att den här dataanalysen,

00:07:06.520 --> 00:07:10.400
även om den har massor av data,
inte alltid producerar optimala resultat.

00:07:10.400 --> 00:07:13.296
Det beror inte på att ett företag
som Multi-Health Systems

00:07:13.296 --> 00:07:15.293
inte vet vad de ska göra
med informationen.

00:07:15.293 --> 00:07:17.456
Även datakunniga företag gör fel.

00:07:17.480 --> 00:07:20.050
Ja, till och med Google har fel ibland.

00:07:20.680 --> 00:07:25.176
2009 sa Google att de
med hjälp av dataanalys

00:07:25.200 --> 00:07:29.336
kunde förutsäga utbrott av influensa,
den elaka sortens förkylning,

00:07:29.360 --> 00:07:33.136
genom att genomföra dataanalys
av sina Google-sökningar.

00:07:33.160 --> 00:07:36.710
Och det fungerade fint,
vilket gav stor uppmärksamhet i medierna,

00:07:36.710 --> 00:07:39.356
inklusive det yttersta beviset
på vetenskaplig framgång:

00:07:39.356 --> 00:07:41.656
en artikel i tidskriften "Nature".

00:07:41.680 --> 00:07:45.190
Det fungerade fint i flera år,

00:07:45.190 --> 00:07:47.096
tills det ett år inte fungerade längre.

00:07:47.096 --> 00:07:49.256
Och ingen kunde ens säga riktigt varför.

00:07:49.280 --> 00:07:50.910
Det fungerade bara inte det året,

00:07:50.910 --> 00:07:53.046
och det fick förstås
också mycket publicitet,

00:07:53.046 --> 00:07:54.576
inklusive ett tillbakadragande

00:07:54.600 --> 00:07:57.440
av artikeln i "Nature".

00:07:58.480 --> 00:08:00.960
Så till och med de med
de datakunniga företagen

00:08:00.960 --> 00:08:03.976
som Amazon och Google har ibland fel.

00:08:04.000 --> 00:08:06.936
Och trots alla dessa misslyckanden

00:08:06.960 --> 00:08:10.816
får data snabbt ett större inflytande
över beslut i verkliga livet -

00:08:10.840 --> 00:08:12.656
på arbetsplatsen,

00:08:12.680 --> 00:08:14.496
inom rättsväsendet,

00:08:14.520 --> 00:08:15.720
inom medicin.

00:08:16.400 --> 00:08:19.736
Så vi borde verkligen ta reda på
ifall data verkligen hjälper oss.

00:08:19.760 --> 00:08:22.730
Jag har personligen sett
en stor del av de här problemen,

00:08:22.730 --> 00:08:24.896
för jag arbetar inom databeräknad genetik,

00:08:24.920 --> 00:08:27.416
vilken också är ett fält
där många smarta människor

00:08:27.440 --> 00:08:31.096
använder oerhörda mängder data
för att fatta ganska allvarliga beslut,

00:08:31.120 --> 00:08:34.820
som att välja cancerbehandling
eller utveckla en ny medicin.

00:08:35.520 --> 00:08:37.896
Över åren har jag noterat
ett slags mönster,

00:08:37.920 --> 00:08:40.290
eller en slags regel,
kan man säga, om skillnaden

00:08:40.290 --> 00:08:43.096
mellan framgångsrikt
och icke framgångsrikt

00:08:43.120 --> 00:08:44.736
beslutsfattande med data

00:08:44.760 --> 00:08:48.640
och jag har hittat ett mönster
som är värt att dela med sig av.

00:08:50.520 --> 00:08:52.655
När man löser ett komplext problem

00:08:52.679 --> 00:08:54.290
gör man i grunden två saker.

00:08:54.290 --> 00:08:55.360
Den första är

00:08:55.360 --> 00:09:00.256
att plocka isär problemet i små bitar
så att man kan analysera bitarna

00:09:00.280 --> 00:09:02.180
och sen gör man det andra steget.

00:09:02.180 --> 00:09:04.900
Men sätter ihop bitarna igen

00:09:04.900 --> 00:09:06.336
för att komma till slutsatsen.

00:09:06.360 --> 00:09:08.560
Ibland måste man göra om det,

00:09:08.560 --> 00:09:10.376
men det handlar alltid de två sakerna:

00:09:10.400 --> 00:09:13.240
plocka isär och sätta ihop saker igen.

00:09:14.280 --> 00:09:15.896
Det viktiga är

00:09:15.920 --> 00:09:18.816
att data och dataanalys

00:09:18.840 --> 00:09:21.170
bara är bra för det första steget.

00:09:21.170 --> 00:09:24.296
Hur kraftfulla data och dataanalys än är,
kan bara hjälpa till med

00:09:24.296 --> 00:09:28.056
att plocka isär ett problem
och förstå dess delar.

00:09:28.080 --> 00:09:31.576
Den passar inte för
att sätta ihop delarna igen

00:09:31.600 --> 00:09:33.340
för att komma till en slutsats.

00:09:33.340 --> 00:09:35.460
Det finns ett annat verktyg
som kan göra det,

00:09:35.460 --> 00:09:37.716
vi har det allihop, och det är hjärnan.

00:09:37.716 --> 00:09:39.470
Om det finns något hjärnan är bra på

00:09:39.470 --> 00:09:41.610
så är att det att sätta ihop
små delar igen,

00:09:41.610 --> 00:09:43.896
även när den inte har all information,

00:09:43.896 --> 00:09:45.456
och kan nå en bra slutsats,

00:09:45.480 --> 00:09:48.290
speciellt om det är en experts hjärna.

00:09:48.290 --> 00:09:51.156
Jag tror att det är därför
Netflix blev så framgångsrika,

00:09:51.156 --> 00:09:54.696
för att de använde data och hjärnor
där de passade i processen.

00:09:54.720 --> 00:09:58.256
De använder data för att först förstå
många små detaljer om sin publik

00:09:58.280 --> 00:10:01.696
som de annars inte skulle
ha kunnat förstå på samma djup,

00:10:01.720 --> 00:10:04.336
men beslutet om hur de olika detaljerna

00:10:04.360 --> 00:10:07.560
skulle sättas ihop igen
för att bli en serie som "House of Cards"

00:10:07.560 --> 00:10:09.136
fanns ingenstans i deras data.

00:10:09.160 --> 00:10:13.136
Ted Sarandos och hans team
tog beslutet att godkänna tv-serien,

00:10:13.160 --> 00:10:15.415
vilket förresten också betydde

00:10:15.415 --> 00:10:18.486
att de tog en ganska stor personlig risk
när de tog det beslutet.

00:10:18.486 --> 00:10:21.110
Och Amazon, å andra sidan,
de gjorde saken på fel sätt.

00:10:21.110 --> 00:10:23.360
De använde data
för allt sitt beslutsfattande,

00:10:23.360 --> 00:10:26.280
först när de höll tävlingen
för tv-koncept,

00:10:26.280 --> 00:10:30.376
och sen när de valde "Alpha House"
till den serie de skulle göra.

00:10:30.400 --> 00:10:32.896
Vilket självklart var
ett säkert val för dem,

00:10:32.920 --> 00:10:35.180
för de kunde alltid peka på data och säga

00:10:35.180 --> 00:10:37.156
"Vår data säger det här."

00:10:37.156 --> 00:10:41.360
Men det ledde inte till
de enastående resultat som de hoppades på.

00:10:41.820 --> 00:10:45.190
Så data är förstås
ett oerhört kraftfullt verktyg

00:10:45.190 --> 00:10:47.210
för att fatta bättre beslut,

00:10:47.210 --> 00:10:52.096
men jag tror att saker går fel
när data börjar styra besluten.

00:10:52.120 --> 00:10:55.820
Hur kraftfull den än är,
så är data bara ett verktyg,

00:10:55.820 --> 00:10:59.256
och för att hålla det i minnet tycker jag
den här saken är användbar.

00:10:59.280 --> 00:11:00.496
Många av er kommer ...

00:11:00.520 --> 00:11:01.570
(Skratt)

00:11:01.570 --> 00:11:03.526
Innan det fanns data, var det här

00:11:03.526 --> 00:11:05.856
beslutsstödet som användes.

00:11:05.880 --> 00:11:07.136
(Skratt)

00:11:07.160 --> 00:11:08.496
Många känner nog igen den.

00:11:08.520 --> 00:11:10.473
Den här leksaken heter Magic 8 Ball,

00:11:10.497 --> 00:11:11.650
och den är fantastisk,

00:11:11.650 --> 00:11:14.390
för om du har ett beslut att fatta,
en ja- eller nejfråga,

00:11:14.400 --> 00:11:18.376
behöver du bara skaka bollen
för att få ett svar -

00:11:18.400 --> 00:11:21.216
"Förmodligen" - just här
i den här stunden i realtid.

00:11:21.240 --> 00:11:23.336
Jag kan dema den senare.

00:11:23.360 --> 00:11:24.576
(Skratt)

00:11:24.600 --> 00:11:28.030
Så här är det förstås,
att jag har fattat några beslut i mitt liv

00:11:28.030 --> 00:11:31.266
där jag i efterhand har förstått
att jag borde ha lyssnat på bollen.

00:11:31.266 --> 00:11:34.456
Men om man har data tillgängliga

00:11:34.480 --> 00:11:37.536
vill man såklart ersätta den här
med något lite mer sofistikerat,

00:11:37.560 --> 00:11:41.176
till exempel dataanalys,
för att fatta ett bättre beslut.

00:11:41.200 --> 00:11:43.816
Men det ändrar inte
de grundläggande förutsättningarna.

00:11:43.840 --> 00:11:47.016
Så bollen kan bli allt smartare

00:11:47.040 --> 00:11:49.856
men jag tror att vi fortfarande
måste fatta besluten

00:11:49.880 --> 00:11:52.896
om vi vill åstadkomma
något utöver det vanliga,

00:11:52.920 --> 00:11:54.856
längst till höger på kurvan.

00:11:54.880 --> 00:11:59.376
Och jag tycker faktiskt att det är
ett väldigt uppmuntrande budskap,

00:11:59.400 --> 00:12:03.376
att även när vi står inför
enorma mängder data

00:12:03.400 --> 00:12:07.496
lönar det sig fortfarande
att fatta beslut,

00:12:07.520 --> 00:12:10.176
att vara en expert på det man gör,

00:12:10.200 --> 00:12:12.296
och att ta risker.

00:12:12.320 --> 00:12:15.096
För i slutändan är det inte data

00:12:15.120 --> 00:12:19.450
utan risker som kommer att ta en
längst ut till höger på kurvan.

00:12:19.690 --> 00:12:21.056
Tack.

00:12:21.080 --> 00:12:24.070
(Applåder)

