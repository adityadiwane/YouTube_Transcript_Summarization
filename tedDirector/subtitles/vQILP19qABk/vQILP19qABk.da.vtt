WEBVTT
Kind: captions
Language: da

00:00:00.000 --> 00:00:07.000
Translator: Morten Villadsen
Reviewer: Simon Djernæs

00:00:12.820 --> 00:00:17.096
Roy Price er en mand som de fleste af jer 
nok aldrig har hørt om,

00:00:17.120 --> 00:00:19.616
selvom han måske er ansvarlig

00:00:19.640 --> 00:00:26.536
for 22 mere eller mindre middelmådige 
minutter af jeres liv den 19. april 2013.

00:00:26.560 --> 00:00:29.736
Han kan også have været ansvarlig for 22
meget underholdende minutter,

00:00:29.760 --> 00:00:32.016
men ikke for særligt mange af jer.

00:00:32.040 --> 00:00:33.936
Og alt det stammer fra en beslutning

00:00:33.960 --> 00:00:35.960
som Roy var nød til at tage
omkring tre år siden.

00:00:35.984 --> 00:00:40.816
Ser i, Roy Price 
er en overordnet leder hos Amazon Studios.

00:00:40.840 --> 00:00:43.856
Det er Amazons TV produktionsselskab.

00:00:43.880 --> 00:00:47.136
Han er 47 år gammel, slank, strithår,

00:00:47.160 --> 00:00:51.976
beskriver sig selv på Twitter 
som "film, TV, teknologi, taco."

00:00:52.000 --> 00:00:57.176
Og Roy Price har et meget ansvarsfuldt job,
fordi det er hans ansvar

00:00:57.200 --> 00:01:01.256
at vælge de serier, det originale indhold
som Amazon skal producere.

00:01:01.280 --> 00:01:03.616
Og det er selvfølgelig 
et meget konkurrerende miljø.

00:01:03.640 --> 00:01:06.376
Det er jo allerede 
så mange TV-serier,

00:01:06.400 --> 00:01:08.576
så Roy kan ikke bare vælge en hvilket som helst serie.

00:01:08.600 --> 00:01:12.696
Han bliver nød til at finde serier 
som er rigtig, rigtig gode.

00:01:12.720 --> 00:01:15.536
Med andre ord, skal han finde serier

00:01:15.560 --> 00:01:17.936
som er helt til højre på denne kurve her.

00:01:17.960 --> 00:01:20.616
Denne kurve her er 
fordeling af bedømmelser

00:01:20.640 --> 00:01:25.016
af omkring 2.500 TV serier 
på hjemmesiden IMDB,

00:01:25.040 --> 00:01:27.936
og bedømmelserne går fra et til 10,

00:01:27.960 --> 00:01:30.936
og højden her viser hvor mange serier 
der får den bedømmelse.

00:01:30.960 --> 00:01:35.656
Så hvis din serie får en bedømmelse på
ni point eller højere er det en vinder.

00:01:35.680 --> 00:01:37.496
Så har du en top to procent serie.

00:01:37.520 --> 00:01:41.416
Det er serier som "Breaking Bad," 
"Game of Thrones," "The Wire,"

00:01:41.440 --> 00:01:43.736
Altså alle de her serier 
som er vanedannende,

00:01:43.760 --> 00:01:46.816
hvor når du har set en sæson,
siger din hjerne bare,

00:01:46.840 --> 00:01:49.016
"Hvor kan jeg få flere af de her afsnit?"

00:01:49.040 --> 00:01:50.240
Den slags serier.

00:01:50.920 --> 00:01:53.416
På venstre side, for at gøre det klart, 
i den her side,

00:01:53.440 --> 00:01:56.616
er der serier som hedder
"Toddlers and Tiaras" -

00:01:56.640 --> 00:01:59.296
(Latter)

00:01:59.320 --> 00:02:00.856
- hvilket burde sige det hele

00:02:00.880 --> 00:02:03.071
omkring hvad der sker i den ende
af kurven.

00:02:03.095 --> 00:02:07.256
Roy Price er ikke bekymret for at ende 
på den venstre side af kurven,

00:02:07.280 --> 00:02:10.216
fordi jeg tror at du virkelig 
skal have noget tankevirksomhed

00:02:10.240 --> 00:02:11.936
for at komme under 
"Toddlers and Tiaras."

00:02:11.960 --> 00:02:15.896
Så det han er bekymret omkring
er bulen her i midten,

00:02:15.920 --> 00:02:17.736
bulen med gennemsnitlig TV,

00:02:17.760 --> 00:02:20.616
I ved, den slags serier som ikke er 
rigtig gode eller rigtig dårlige

00:02:20.639 --> 00:02:22.295
- de begejstrer ikke rigtig.

00:02:22.320 --> 00:02:27.176
Så han bliver nød til at sikre sig, 
at han er på den rigtige side af denne.

00:02:27.200 --> 00:02:28.776
Så der er pres på,

00:02:28.800 --> 00:02:30.976
og det er selvfølgelig også første gang,

00:02:31.000 --> 00:02:33.176
at Amazon overhovedet laver sådan noget,

00:02:33.200 --> 00:02:36.536
så Roy Price vil ikke tage nogle chancer.

00:02:36.560 --> 00:02:39.016
Han vil skabe succes.

00:02:39.040 --> 00:02:40.816
Han har brug for en garanteret succes,

00:02:40.840 --> 00:02:43.416
og derfor afholder han en konkurrence.

00:02:43.440 --> 00:02:46.576
Han tager en bunke idéer til TV-serier

00:02:46.600 --> 00:02:48.896
og gennem en evaluering af de idéer

00:02:48.920 --> 00:02:53.016
bliver otte kandidater til TV-serier valgt

00:02:53.040 --> 00:02:56.256
og så laver han kun den 
første episode til hver serie

00:02:56.280 --> 00:02:59.416
og lægger dem online 
så alle kan se dem gratis.

00:02:59.440 --> 00:03:01.696
Og når Amazon giver dig noget gratis

00:03:01.720 --> 00:03:03.256
så tager du imod det, ikke?

00:03:03.280 --> 00:03:08.416
Så millioner af seere ser disse episoder.

00:03:08.440 --> 00:03:11.656
Hvad de ikke indser er 
at mens de ser deres serie

00:03:11.680 --> 00:03:13.976
bliver de faktisk selv iagttaget.

00:03:14.000 --> 00:03:16.336
De bliver iagttaget af Roy Price
og hans hold

00:03:16.360 --> 00:03:17.736
som optager alting,

00:03:17.760 --> 00:03:21.136
De optager når nogen trykker play.
når nogen trykker pause,

00:03:21.160 --> 00:03:23.696
hvilke dele de springer over,
hvilke dele de ser igen.

00:03:23.720 --> 00:03:25.976
Så de samler millioner af data point,

00:03:26.000 --> 00:03:28.096
fordi de vil have de data point

00:03:28.120 --> 00:03:30.816
til når de skal beslutte hvilken serie de vil lave.

00:03:30.840 --> 00:03:33.016
Som sagt så gjort,
de samlede al data,

00:03:33.040 --> 00:03:35.616
de analyserede denne
og et svar dukkede op,

00:03:35.640 --> 00:03:36.856
og det svar er,

00:03:36.880 --> 00:03:42.416
"Amazon bør lave en komedieserie 
om fire republikanske senatorer."

00:03:42.440 --> 00:03:43.656
De lavede den serie.

00:03:43.680 --> 00:03:45.840
Er der nogen der kender navnet på den serie?

00:03:46.720 --> 00:03:48.016
(Publikum: "Alpha House.")

00:03:48.040 --> 00:03:49.496
Ja, "Alpha House,"

00:03:49.520 --> 00:03:53.616
men det virker som om der ikke er så 
mange af jer som faktisk husker den serie,

00:03:53.640 --> 00:03:55.496
fordi den endte med ikke 
at blive så god.

00:03:55.520 --> 00:03:57.376
Det er faktisk kun 
en gennemsnitlig serie

00:03:57.400 --> 00:04:01.976
endda bogstavelig talt, 
fordi gennemsnittet på denne kurve er 7,4

00:04:02.000 --> 00:04:04.416
og "Alpha House" er på 7,5,

00:04:04.440 --> 00:04:06.456
så en lige over gennemsnittet serie,

00:04:06.480 --> 00:04:09.400
men helt sikkert ikke hvad Roy Price
og hans hold gik efter.

00:04:10.320 --> 00:04:13.176
I mellemtiden,

00:04:13.200 --> 00:04:14.776
i et andet firma,

00:04:14.800 --> 00:04:19.016
lykkedes det en anden leder at skaffe en 
top serie ved hjælp af data analysering,

00:04:19.040 --> 00:04:20.616
og hans navn er Ted,

00:04:20.640 --> 00:04:24.056
Ted Sarandos, som er 
Chief Content Officer hos Netflix.

00:04:24.080 --> 00:04:26.216
og ligesom Roy, er han på 
en konstant mission

00:04:26.240 --> 00:04:27.736
for at finde en god TV-serie,

00:04:27.760 --> 00:04:29.776
og til det bruger han også data,

00:04:29.800 --> 00:04:31.815
bortset fra, 
at han gør det lidt anderledes.

00:04:31.839 --> 00:04:35.576
I stedet for at afholde en konkurrence, 
han - og hans hold selvfølgelig -

00:04:35.600 --> 00:04:39.136
så på al den data 
de allerede havde om Netflix seere.

00:04:39.160 --> 00:04:41.256
I ved, de bedømmelser 
de giver deres serier,

00:04:41.280 --> 00:04:43.976
afspilningshistorik, 
hvilke serier folk kan lide, osv.

00:04:44.000 --> 00:04:45.896
Og så bruger de den data til at opdage

00:04:45.920 --> 00:04:48.536
alle disse små dele 
af informationer om seererne:

00:04:48.560 --> 00:04:50.016
hvilken slags serier,

00:04:50.040 --> 00:04:52.136
producere, skuespillere de kan lide.

00:04:52.160 --> 00:04:54.736
Og når de havde samlet alle disse dele,

00:04:54.760 --> 00:04:56.416
tog de en chance,

00:04:56.440 --> 00:04:58.536
og de besluttede at lave

00:04:58.560 --> 00:05:01.016
- ikke en komedieserie om fire senatorer -

00:05:01.040 --> 00:05:03.920
men en drama serie om en enkelt senator.

00:05:04.760 --> 00:05:06.416
Kender i denne serie?

00:05:06.440 --> 00:05:07.736
(Latter)

00:05:07.760 --> 00:05:11.496
Ja, "House of Cards," og Netflix 
selvfølgelig ramte rigtig med den serie,

00:05:11.520 --> 00:05:13.656
i hvert fald de første to sæsoner,

00:05:13.680 --> 00:05:17.656
(Latter) (Klapsalver)

00:05:17.680 --> 00:05:20.856
"House of Cards" får 9,1 på denne kurve,

00:05:20.880 --> 00:05:24.056
så det er præcis der hvor 
de gerne ville have den skulle være.

00:05:24.080 --> 00:05:26.496
Så er spørgsmålet selvfølgelig 
hvad skete der her?

00:05:26.520 --> 00:05:29.176
Du har to konkurrencedygtige,
data-kløgtige firmaer.

00:05:29.200 --> 00:05:32.056
De samler alle de her 
millioner af data point,

00:05:32.080 --> 00:05:34.456
Og det fungerer fantastisk for en af dem

00:05:34.480 --> 00:05:36.336
og det virker ikke for den anden.

00:05:36.360 --> 00:05:37.576
Hvorfor?

00:05:37.600 --> 00:05:41.056
Fordi logisk set burde det 
egentlig fungerer hver gang.

00:05:41.080 --> 00:05:43.536
Hvis du samler millioner af data point

00:05:43.560 --> 00:05:45.296
til en beslutning du skal tage,

00:05:45.320 --> 00:05:47.936
så burde du kunne tage 
en ret god beslutning.

00:05:47.960 --> 00:05:50.176
Du har 200 års statistik 
at falde tilbage på.

00:05:50.200 --> 00:05:53.216
Det forstærker du 
med kraftfulde computere.

00:05:53.240 --> 00:05:56.520
Det mindste du kan forvente 
er vel god TV, ikke?

00:05:57.880 --> 00:06:00.600
Og hvis data analyse 
ikke virker på den måde,

00:06:01.520 --> 00:06:03.576
så er det faktisk lidt skræmmende,

00:06:03.600 --> 00:06:07.416
fordi vi lever i en tid 
hvor vi bruger data mere og mere

00:06:07.440 --> 00:06:11.920
til at tage seriøse valg langt udover TV.

00:06:12.760 --> 00:06:16.000
Er der nogen her der kender firmaet 
Multi-Health Systems?

00:06:17.080 --> 00:06:18.736
Ingen. Okay, det er faktisk godt.

00:06:18.760 --> 00:06:21.976
Okay, så Multi-Health Systems
er et software firma,

00:06:22.000 --> 00:06:24.816
og jeg håber ikke at nogen i dette lokale

00:06:24.840 --> 00:06:28.016
nogensinde kommer i kontakt 
med den software,

00:06:28.040 --> 00:06:30.136
fordi så betyder det at I er i fængsel.

00:06:30.160 --> 00:06:31.336
(Latter)

00:06:31.360 --> 00:06:34.896
Hvis nogen her i USA er i fængsel og
ansøger om prøveløsladelse,

00:06:34.920 --> 00:06:39.216
så er det meget sandsynligt, 
at data analyse software fra det firma

00:06:39.240 --> 00:06:42.856
vil blive brugt til at bestemme om 
der skal gives prøveløsladelse.

00:06:42.880 --> 00:06:45.456
Så det er det samme princip
som Amazon og Netflix,

00:06:45.480 --> 00:06:50.096
men i stedet for at bestemme om
en TV-serie bliver god eller dårlig,

00:06:50.120 --> 00:06:53.016
bestemmer man om en fange
bliver god eller dårlig.

00:06:53.040 --> 00:06:58.536
Og middelmådig TV, 22 minutter,
det kan være ret dårligt,

00:06:58.560 --> 00:07:01.200
men flere år i fængsel,
går jeg udfra, er endnu værre.

00:07:02.360 --> 00:07:06.496
Og uheldigvis er der faktisk bevis for.
at denne data analyse,

00:07:06.520 --> 00:07:10.736
på trods af masser af date, 
ikke altid producerer optimale resultater.

00:07:10.760 --> 00:07:13.482
Og det er ikke fordi et firma
som Multi-Health Systems

00:07:13.506 --> 00:07:15.133
ikke bruger den data korrekt.

00:07:15.158 --> 00:07:17.456
Selv de mest data-kyndige
firmaer fejler.

00:07:17.480 --> 00:07:19.880
Ja, selv Google fejler noglegange.

00:07:20.680 --> 00:07:25.176
I 2009 annoncerede Google,
at de var i stand til, med data analyse,

00:07:25.200 --> 00:07:29.336
at forudse udbrud ad influenza,
den slemme slags,

00:07:29.360 --> 00:07:33.136
ved at lave data analyse
på deres Google søgninger.

00:07:33.160 --> 00:07:37.016
Og det virkede fantastisk, og det
blev en stor historie i nyhederne,

00:07:37.040 --> 00:07:39.176
inklusiv højdepunktet
i videnskabelig succes:

00:07:39.200 --> 00:07:41.656
en udgivelse i tidskriftet "Nature."

00:07:41.680 --> 00:07:45.296
Det virkede fantastisk
år efter år efter år,

00:07:45.320 --> 00:07:46.976
indtil det et år fejlede.

00:07:47.000 --> 00:07:49.256
Og ingen kunne forklare præcis hvorfor.

00:07:49.280 --> 00:07:50.976
Det virkede bare ikke det år,

00:07:51.000 --> 00:07:52.936
og det blev selvfølgelig også en nyhed,

00:07:52.960 --> 00:07:54.576
med efterfølgende tilbagetrækning

00:07:54.600 --> 00:07:57.440
af udgivelsen i tidskriftet "Nature."

00:07:58.480 --> 00:08:01.816
Så selv de mest data-kyndige firmaer,
Amazon og Google,

00:08:01.840 --> 00:08:03.976
fejler sommetider.

00:08:04.000 --> 00:08:06.936
Og på trods af disse fiaskoer,

00:08:06.960 --> 00:08:10.816
rykker data hastigt ind det virkelig livs
beslutningstagen -

00:08:10.840 --> 00:08:12.656
ind på arbejdspladsen,

00:08:12.680 --> 00:08:14.496
retshåndhævelsen,

00:08:14.520 --> 00:08:15.720
lægevidenskab.

00:08:16.400 --> 00:08:19.736
Så vi må hellere være sikker på.
at data hjælper.

00:08:19.760 --> 00:08:22.896
Personligt har jeg set megen af denne 
kamp med data selv,

00:08:22.920 --> 00:08:24.896
da jeg arbejder med databehandletgenetik,

00:08:24.920 --> 00:08:27.416
hvilket også er et felt
hvor mange meget smart folk

00:08:27.440 --> 00:08:31.096
bruger utrolige mængder data til 
at træffe nogle ret seriøse beslutninger,

00:08:31.120 --> 00:08:34.680
såsom valg vedrørende kræft terapi 
eller udvikle et medikament.

00:08:35.520 --> 00:08:37.896
Og i årenes løb 
har jeg lagt mærke til et mønster

00:08:37.920 --> 00:08:40.376
eller en slags regel, om du vil,
om forskellen

00:08:40.400 --> 00:08:43.096
mellem succesfuld 
beslutningstagen med data

00:08:43.120 --> 00:08:44.736
og fejlende beslutningstagen,

00:08:44.760 --> 00:08:48.640
og jeg fandt dette mønster værd at dele,
og det er sådan her.

00:08:50.520 --> 00:08:52.655
Hver gang du løser 
et kompleks problem,

00:08:52.679 --> 00:08:54.416
gør du i virkeligheden to ting.

00:08:54.440 --> 00:08:57.736
Den første er at du deler problemet 
op i mindre stykker

00:08:57.760 --> 00:09:00.256
så du kan analysere disse stykker i dybden

00:09:00.280 --> 00:09:02.296
og så laver du selvfølgelig 
den anden del.

00:09:02.320 --> 00:09:04.976
Du samler alle disse stykker igen 
for at komme

00:09:05.000 --> 00:09:06.336
frem til din konklusion.

00:09:06.360 --> 00:09:08.696
Og noglegange skal du begynde forfra,

00:09:08.720 --> 00:09:10.376
men det er altid disse to ting:

00:09:10.400 --> 00:09:12.720
skille det ad
og samle det igen.

00:09:14.280 --> 00:09:15.896
Og den vigtige del er,

00:09:15.920 --> 00:09:18.816
at data og data analyse

00:09:18.840 --> 00:09:21.336
er kun brugbart til den første del.

00:09:21.360 --> 00:09:23.576
Data og data analyse, 
uanset hvor stærk,

00:09:23.600 --> 00:09:28.056
kan kun hjælpe med at skille problemet ad
og forstå stykkerne.

00:09:28.080 --> 00:09:31.576
Det er ikke lavet til at samle
stykkerne igen

00:09:31.600 --> 00:09:33.496
og komme frem til en konklusion.

00:09:33.520 --> 00:09:36.256
Der er et andet værktøj der kan gøre det
og alle har det,

00:09:36.280 --> 00:09:37.576
og det værktøj er hjernen.

00:09:37.600 --> 00:09:39.536
Hvis det er en ting hjernen er god til,

00:09:39.560 --> 00:09:41.816
så er det at samle stykker sammen igen,

00:09:41.840 --> 00:09:43.856
selv hvis du ikke har al informationen,

00:09:43.880 --> 00:09:45.456
og nå en god konklusion,

00:09:45.480 --> 00:09:48.416
især hvis det er en eksperts hjerne.

00:09:48.440 --> 00:09:51.096
Og det er derfor jeg tror,
at Netflix var så succesfulde

00:09:51.120 --> 00:09:54.696
fordi de brugte data og hjerne
der hvor de passede i processen.

00:09:54.720 --> 00:09:58.256
De brugte først data til at forstå
en masse stykker af deres seere

00:09:58.280 --> 00:10:01.696
som de ellers ikke kunne have
forstået på sådan et niveau,

00:10:01.720 --> 00:10:04.336
men beslutningen om at tage
alle disse stykker

00:10:04.360 --> 00:10:07.696
og samle dem igen
og lave en serie som "House of Cards,"

00:10:07.720 --> 00:10:09.136
var ikke i nærheden af data.

00:10:09.160 --> 00:10:13.136
Ted Sandaros og hans hold
tog beslutningen om at lave den serie,

00:10:13.160 --> 00:10:15.541
hvilket i øvrigt også betød, 
at de løb

00:10:15.565 --> 00:10:18.416
en ret stor personlig risiko
med den beslutning.

00:10:18.440 --> 00:10:21.456
Og Amazon, på den anden side,
de gjorde det på den forkerte led.

00:10:21.480 --> 00:10:24.216
De brugte data hele vejen
i deres beslutningstagen,

00:10:24.240 --> 00:10:26.656
først da de afholdte konkurrencen 
med TV idéer

00:10:26.680 --> 00:10:30.376
senere da de valgte at lave 
"Alpha House" til en serie.

00:10:30.400 --> 00:10:32.896
Hvilket selvfølgelig var
en sikker beslutning for dem

00:10:32.920 --> 00:10:35.376
fordi de altid kunne 
pege på dataen og sige:

00:10:35.400 --> 00:10:37.096
"Dette er hvad dataen fortalte os."

00:10:37.120 --> 00:10:41.360
Men det første ikke til det exceptionelle 
resultat som de håbede på.

00:10:42.120 --> 00:10:47.096
Data er selvfølgelig et enormt brugbart
værktøj til at tage bedre valg

00:10:47.120 --> 00:10:49.496
men jeg tror, at det går galt

00:10:49.520 --> 00:10:52.096
når data begynder at styre de valg.

00:10:52.120 --> 00:10:55.896
Uanset hvor stærk data er, 
er det kun et værktøj

00:10:55.920 --> 00:10:59.256
og for at huske på dette,
finder jeg denne her meget brugbar.

00:10:59.280 --> 00:11:00.496
Mange af jer vil ...

00:11:00.520 --> 00:11:01.736
(Latter)

00:11:01.760 --> 00:11:02.976
Før der var data,

00:11:03.000 --> 00:11:05.856
var dette beslutningstager-enheden
man brugte.

00:11:05.880 --> 00:11:07.136
(Latter)

00:11:07.160 --> 00:11:08.496
Mange af kender denne.

00:11:08.520 --> 00:11:10.473
Dette legetøj her hedder en magisk 8-ball

00:11:10.497 --> 00:11:11.696
og den er helt utrolig,

00:11:11.720 --> 00:11:14.616
fordi hvis du har et valg du skal tage.
et ja/nej spørgsmål,

00:11:14.640 --> 00:11:18.376
det eneste du skal gøre er 
at ryste kuglen og så får du et svar -

00:11:18.400 --> 00:11:21.216
"Højst sandsynlig" - lige her
i dette vindue i realtid.

00:11:21.240 --> 00:11:23.336
Jeg vil demonstrere derude senere.

00:11:23.360 --> 00:11:24.576
(Latter)

00:11:24.600 --> 00:11:28.176
Sagen er, at jeg har taget 
nogle valg i mit liv

00:11:28.200 --> 00:11:31.096
hvor jeg skulle have lyttet 
til kuglen, set i bakspejlet.

00:11:31.120 --> 00:11:34.456
Men, I ved, hvis man har data til rådighed

00:11:34.480 --> 00:11:37.536
vil man erstatte den 
med noget langt mere sofistikeret,

00:11:37.560 --> 00:11:41.176
såsom data analyse 
for at komme frem til en bedre beslutning.

00:11:41.200 --> 00:11:43.816
Men det ændrer ikke den basale opsætning.

00:11:43.840 --> 00:11:47.016
Kuglen bliver måske klogere 
og klogere og klogere,

00:11:47.040 --> 00:11:49.856
men jeg mener stadig, 
at vi skal tage beslutningerne

00:11:49.880 --> 00:11:52.896
hvis vi vil opnå noget ekstraordinært,

00:11:52.920 --> 00:11:54.856
i den højre ende af kurven.

00:11:54.880 --> 00:11:59.376
Og det mener jeg faktisk 
er en meget opmuntrende besked,

00:11:59.400 --> 00:12:03.376
at selv overfor masser af data

00:12:03.400 --> 00:12:07.496
betaler det sig stadig 
at tage beslutninger,

00:12:07.520 --> 00:12:10.176
at være en ekspert til det du laver

00:12:10.200 --> 00:12:12.296
og take chancer.

00:12:12.320 --> 00:12:15.096
For når alt kommer til alt, 
er det ikke data

00:12:15.120 --> 00:12:19.080
det er chancer der vil føre dig 
til den højre ende af kurven.

00:12:19.840 --> 00:12:21.056
Tak.

00:12:21.080 --> 00:12:24.760
(Klapsalver)

