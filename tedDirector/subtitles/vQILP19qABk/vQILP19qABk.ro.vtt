WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Razvan Cristian Duia
Corector: Delia Bogdan

00:00:12.820 --> 00:00:17.096
Probabil că majoritatea
n-ați auzit de Roy Price,

00:00:17.120 --> 00:00:19.616
deși el se poate să fie răspunzător

00:00:19.640 --> 00:00:26.536
pentru 22 de minute mediocre
din viaţa voastră, pe 19 aprilie 2013.

00:00:26.560 --> 00:00:29.736
S-ar putea să fie răspunzător
pentru 22 minute foarte amuzante,

00:00:29.760 --> 00:00:32.016
dar nu pentru foarte mulţi dintre voi.

00:00:32.040 --> 00:00:35.686
Totul a început cu decizia pe care Roy
a trebuit să o ia acum trei ani.

00:00:35.984 --> 00:00:40.816
Roy Price e director executiv
la Studiourile Amazon,

00:00:40.840 --> 00:00:43.856
compania de producţii TV a Amazon.

00:00:43.880 --> 00:00:47.136
E un tip de 47 de ani, zvelt, păr ţepos,

00:00:47.160 --> 00:00:51.976
se descrie pe contul Twitter
ca „filme, TV, tehnologie, tacos.”

00:00:52.970 --> 00:00:55.880
Roy Price are o mare răspundere.

00:00:55.880 --> 00:00:58.280
El răspunde de alegerea programelor,

00:00:58.280 --> 00:01:01.280
de conţinutul original pe care Amazon
urmează să îl producă.

00:01:01.280 --> 00:01:03.616
Concurenţa este foarte mare.

00:01:03.640 --> 00:01:06.376
Sunt deja atât de multe 
producţii TV pe piaţă,

00:01:06.400 --> 00:01:08.576
încât Roy nu poate alege orice program.

00:01:08.600 --> 00:01:12.696
El trebuie să găsească programe
care sunt foarte, foarte bune.

00:01:12.720 --> 00:01:17.856
Adică trebuie să găsească spectacole
din dreapta acestei curbe.

00:01:17.960 --> 00:01:20.616
Curba reprezintă distribuția ratingului

00:01:20.640 --> 00:01:25.016
pentru cam 2.500 producţii TV
pe site-ul IMDB.

00:01:25.040 --> 00:01:27.936
Ratingul merge de la 1 la 10,

00:01:27.960 --> 00:01:30.936
iar pe verticală e numărul producţiilor
care obţin acel rating.

00:01:30.960 --> 00:01:35.656
Dacă producţia ta obţine un rating
de 9 puncte sau mai mare, e un succes.

00:01:35.680 --> 00:01:37.496
Apoi sunt cele mai bune 2% producţii.

00:01:37.520 --> 00:01:41.416
Sunt producţii ca „Breaking Bad",
„Game of Thrones", „The Wire".

00:01:41.440 --> 00:01:43.736
Aceste seriale dau dependenţă,

00:01:43.760 --> 00:01:46.816
dupa ce urmăreşti un sezon,
creierul tău se întreabă:

00:01:46.840 --> 00:01:49.016
„De unde iau mai multe episoade?"

00:01:49.040 --> 00:01:50.240
Genul ăsta de producţii.

00:01:50.920 --> 00:01:53.606
În partea stângă, ca să fie clar,
aici în margine,

00:01:53.606 --> 00:01:56.616
aveţi un serial numit
„Toddlers and Tiaras"...

00:01:56.640 --> 00:01:59.296
(Râsete)

00:01:59.320 --> 00:02:02.526
... care sugerează clar despre ce-i vorba
la acel capăt al curbei.

00:02:03.095 --> 00:02:07.256
Roy Price nu este îngrijorat
că ajunge la capătul din stânga al curbei,

00:02:07.280 --> 00:02:11.926
pentru că îţi trebuie multă inteligenţă
să te plasezi sub „Toddlers and Tiaras”.

00:02:11.960 --> 00:02:15.896
El e îngrijorat de
umflătura asta din mijloc,

00:02:15.920 --> 00:02:17.736
cea a producţiilor TV medii,

00:02:17.760 --> 00:02:20.616
acele producţii care nu sunt
nici prea bune nici prea rele,

00:02:20.639 --> 00:02:22.295
care nu ajung să te impresioneze.

00:02:22.320 --> 00:02:27.176
El trebuie să se asigure
că se află în marginea din dreapta.

00:02:27.200 --> 00:02:28.776
Presiunea este mare.

00:02:28.800 --> 00:02:33.126
De-asemenea e prima dată
când Amazon face așa ceva,

00:02:33.200 --> 00:02:36.536
deci Roy Price nu vrea să rişte.

00:02:36.560 --> 00:02:39.016
Vrea să proiecteze succesul.

00:02:39.040 --> 00:02:43.166
Are nevoie de succes garantat,
aşa că organizează un concurs:

00:02:43.440 --> 00:02:46.576
ia un număr de idei de producţii TV

00:02:46.600 --> 00:02:48.896
şi, evaluând aceste idei,

00:02:48.920 --> 00:02:53.016
selectează opt candidaţi 
pentru producţii TV,

00:02:53.040 --> 00:02:56.256
apoi face doar primul episod
pentru fiecare din aceste producţii

00:02:56.280 --> 00:02:59.416
şi le difuzează gratis online.

00:02:59.440 --> 00:03:03.216
Când Amazon oferă lucruri gratuite,
le vei lua, nu-i aşa?

00:03:03.280 --> 00:03:08.416
Astfel, milioane de persoane
urmăresc aceste episoade.

00:03:08.440 --> 00:03:11.656
Ei nu realizează că, în timp ce
urmăresc spectacolele,

00:03:11.680 --> 00:03:13.976
sunt la rândul lor urmăriţi.

00:03:14.000 --> 00:03:17.496
Sunt urmăriţi de Roy Price şi echipa lui,
care înregistrează tot.

00:03:17.760 --> 00:03:21.136
Înregistrează când cineva apasă play,
când apasă pauză,

00:03:21.160 --> 00:03:23.696
ce părţi sar, ce părţi urmăresc din nou.

00:03:23.720 --> 00:03:25.976
Se colectează milioane
de astfel de parametri,

00:03:26.000 --> 00:03:28.096
pentru că vor să aibă aceşti parametri

00:03:28.120 --> 00:03:30.816
ca să decidă apoi
ce producţie să continue.

00:03:30.840 --> 00:03:33.016
Aşa că ei colectează aceste informaţii,

00:03:33.040 --> 00:03:35.616
le procesează şi primesc un răspuns,

00:03:35.640 --> 00:03:36.856
iar răspunsul este:

00:03:36.880 --> 00:03:42.416
„Amazon ar trebui să facă un serial
de comedie despre 4 senatori republicani".

00:03:42.440 --> 00:03:43.656
Au făcut acest serial.

00:03:43.680 --> 00:03:45.840
Ştie cineva numele serialului?

00:03:46.720 --> 00:03:49.466
(Audienţa: „Alpha House”)
Da, „Alpha House”,

00:03:49.520 --> 00:03:53.616
dar se pare că puţini dintre voi
îşi amintesc acel serial,

00:03:53.640 --> 00:03:55.496
pentru că nu a fost chiar aşa de bun.

00:03:55.520 --> 00:03:57.376
E doar un serial de nivel mediu,

00:03:57.400 --> 00:04:01.976
Literalmente mediu, pentru că media
acestui grafic este la 7,4,

00:04:02.000 --> 00:04:04.416
şi „Alpha House" aterizează la 7,5,

00:04:04.440 --> 00:04:06.456
deci puţin deasupra mediei,

00:04:06.480 --> 00:04:09.400
dar sigur nu e ce şi-au dorit
Roy Price şi echipa lui.

00:04:10.320 --> 00:04:13.176
Între timp, cam în aceeaşi perioadă,

00:04:13.200 --> 00:04:14.776
la o altă companie,

00:04:14.800 --> 00:04:19.016
un alt director a făcut o producţie de top
folosind analiza datelor,

00:04:19.040 --> 00:04:20.616
iar numele lui este Ted,

00:04:20.640 --> 00:04:24.056
Ted Sarandos –
directorul de programe de la Netflix.

00:04:24.080 --> 00:04:27.726
Ca și Roy, e într-o continuă căutare
a acelei mari producţii TV.

00:04:27.760 --> 00:04:31.616
Şi el foloseşte informatica în acest scop,
numai că o face puţin diferit.

00:04:31.839 --> 00:04:35.576
În loc să organizeze o competiţie,
el şi echipa lui

00:04:35.600 --> 00:04:39.136
au analizat informaţiile pe care
le aveau deja despre utilizatorii Netflix,

00:04:39.160 --> 00:04:41.256
notele pe care le dădeau producţiilor,

00:04:41.280 --> 00:04:43.976
istoricul vizionărilor,
programele care le plac etc.

00:04:44.000 --> 00:04:48.366
Folosesc apoi informaţiile să afle
toate amănuntele despre public:

00:04:48.560 --> 00:04:50.016
ce tip de producţii agrează,

00:04:50.040 --> 00:04:52.136
ce tip de producători,
ce tip de actori.

00:04:52.160 --> 00:04:54.736
După ce-au analizat aceste informaţii,

00:04:54.760 --> 00:05:00.656
s-au hotărât și au decis să producă
nu o comedie despre patru senatori,

00:05:01.040 --> 00:05:03.920
ci un serial dramatic
despre un singur senator.

00:05:04.760 --> 00:05:06.416
Știţi serialul?

00:05:06.440 --> 00:05:07.736
(Râsete)

00:05:07.760 --> 00:05:11.496
Da, „House of Cards” şi Netflix
a dat lovitura cu acel serial,

00:05:11.520 --> 00:05:13.656
cel puţin pentru primele două sezoane.

00:05:13.680 --> 00:05:17.656
(Râsete)
(Aplauze)

00:05:17.680 --> 00:05:20.856
„House of Cards” are un rating
de 9,1 pe acest grafic,

00:05:20.880 --> 00:05:24.056
deci este exact
unde îşi doreau să fie.

00:05:24.080 --> 00:05:26.496
Acum, întrebarea este:
ce s-a întâmplat aici?

00:05:26.520 --> 00:05:29.176
Avem două companii foarte bune
în procesarea datelor,

00:05:29.200 --> 00:05:32.056
care coroborează milioane de parametri,

00:05:32.080 --> 00:05:34.456
iar apoi totul merge frumos
pentru una din ele,

00:05:34.480 --> 00:05:36.336
dar nu funcţionează pentru cealaltă.

00:05:36.360 --> 00:05:37.576
De ce?

00:05:37.600 --> 00:05:41.056
Logic ar fi să funcţioneze mereu.

00:05:41.080 --> 00:05:45.176
Când colectezi milioane de măsurători
pentru a lua o decizie,

00:05:45.320 --> 00:05:47.936
ar trebui să poţi lua
o decizie destul de bună.

00:05:47.960 --> 00:05:50.176
Ai 200 de ani de statistică
pe care te bazezi.

00:05:50.200 --> 00:05:53.216
O amplifici cu computere foarte puternice.

00:05:53.240 --> 00:05:56.520
Nu te-ai aştepta să obţii
rezultate mediocre, nu-i aşa?

00:05:57.880 --> 00:06:00.600
Daca analiza datelor
nu funcţionează aşa,

00:06:01.520 --> 00:06:03.576
lucrurile devin chiar
puţin înfricoşătoare,

00:06:03.600 --> 00:06:07.416
pentru că în zilele noastre
apelăm tot mai mult la informatică

00:06:07.440 --> 00:06:11.920
pentru a lua decizii mult mai importante
decât emisiunile TV.

00:06:12.760 --> 00:06:16.000
Cunoaşte cineva compania
Multi-Health Systems?

00:06:17.080 --> 00:06:18.736
Nimeni. Ăsta chiar e un lucru bun.

00:06:18.760 --> 00:06:21.976
Multi-Health Systems
e o companie care produce softuri

00:06:22.000 --> 00:06:24.816
şi sper ca nimeni din această sală

00:06:24.840 --> 00:06:28.016
să nu vină în contact cu acele softuri,

00:06:28.040 --> 00:06:30.136
că ar însemna că sunteţi la închisoare.

00:06:30.160 --> 00:06:31.336
(Râsete)

00:06:31.360 --> 00:06:34.896
Dacă cineva, aici în SUA, e la închisoare
şi cere eliberarea condiţionată,

00:06:34.920 --> 00:06:39.216
atunci e foarte probabil ca programul
de analiză a datelor de la acea companie

00:06:39.240 --> 00:06:42.856
să fie folosit în evaluarea
acordării eliberării condiţionate.

00:06:42.880 --> 00:06:45.456
E acelaşi principiu ca cel
de la Amazon şi Netflix,

00:06:45.480 --> 00:06:50.096
dar acum, în loc să stabileşti dacă
un serial TV va fi bun sau rău,

00:06:50.120 --> 00:06:53.016
decizi dacă o persoană
va fi bună sau rea.

00:06:53.040 --> 00:06:58.536
O producţie TV mediocră de 22 minute
poate fi un rezultat destul de rău,

00:06:58.560 --> 00:07:01.200
dar mai mulţi ani la închisoare
cred că e chiar mai rău.

00:07:02.360 --> 00:07:06.496
Din păcate, sunt dovezi
că această analiză informatică,

00:07:06.520 --> 00:07:10.736
cu toate că include mulţi parametri,
nu dă mereu rezultate optime.

00:07:10.760 --> 00:07:13.482
Asta nu se întâmplă pentru că
Multi-Health Systems

00:07:13.506 --> 00:07:15.133
nu ştie ce să facă cu datele.

00:07:15.158 --> 00:07:17.456
Chiar şi cei mai buni
în domeniu greşesc.

00:07:17.480 --> 00:07:19.880
Da, chiar şi Google greşeşte uneori.

00:07:20.680 --> 00:07:25.176
În 2009, Google anunţa că poate,
prin analize statistice,

00:07:25.200 --> 00:07:29.336
să prezică epidemiile de gripă,
gripa aviară,

00:07:29.360 --> 00:07:33.136
analizând căutările
utilizatorilor pe Google.

00:07:33.160 --> 00:07:37.016
A funcţionat frumos
şi a făcut vâlvă la ştiri,

00:07:37.040 --> 00:07:39.176
și a atins culmea succesului ştiinţific:

00:07:39.200 --> 00:07:41.656
un articol în revista Nature.

00:07:41.680 --> 00:07:45.296
A funcţionat frumos an după an,

00:07:45.320 --> 00:07:46.976
până când a picat.

00:07:47.000 --> 00:07:49.256
Şi nimeni nu putea măcar să spună de ce.

00:07:49.280 --> 00:07:50.976
Pur şi simplu nu a mers în acel an.

00:07:51.000 --> 00:07:54.596
Sigur că asta a ţinut iar capul de afiş,
incluzând acum o retractare

00:07:54.600 --> 00:07:57.440
într-o ediţie a revistei Nature.

00:07:58.480 --> 00:08:01.816
Chiar şi companiile tari
în operarea datelor, Amazon şi Google,

00:08:01.840 --> 00:08:03.976
greşesc câteodată.

00:08:04.000 --> 00:08:06.936
În ciuda acestor eşecuri,

00:08:06.960 --> 00:08:10.816
informatica îşi face loc rapid
în luarea deciziilor din lumea reală:

00:08:10.840 --> 00:08:12.656
la locul de muncă,

00:08:12.680 --> 00:08:14.496
în sistemul judiciar,

00:08:14.520 --> 00:08:15.720
medicină.

00:08:16.400 --> 00:08:19.736
Aşa că ar fi mai bine să ne asigurăm
că informatica ajută.

00:08:19.760 --> 00:08:22.896
Eu însumi am văzut mult
din lupta asta cu informatica,

00:08:22.920 --> 00:08:24.896
pentru că lucrez în domeniul
geneticii informatizate,

00:08:24.920 --> 00:08:27.416
un domeniu în care 
mulţi oameni foarte deştepţi

00:08:27.440 --> 00:08:31.096
utilizează cantităţi inimaginabile
de date ca să ia decizii importante

00:08:31.120 --> 00:08:34.680
precum un tratament împotriva cancerului
sau crearea unui medicament.

00:08:35.520 --> 00:08:40.236
În decursul anilor am observat un model,
sau o regulă, privind diferenţa

00:08:40.400 --> 00:08:44.486
dintre deciziile de succes și cele proaste
luate cu ajutorul statisticii

00:08:44.760 --> 00:08:48.790
şi cred că acest model merită împărtăşit.
E cam aşa:

00:08:50.520 --> 00:08:54.225
Când rezolvi o problemă complexă,
faci în esenţă două lucruri:

00:08:54.440 --> 00:08:57.736
primul pas e să descompui problema
în componentele sale

00:08:57.760 --> 00:09:00.256
ca să poţi analiza atent
acele componente

00:09:00.280 --> 00:09:02.296
şi apoi, al doilea pas:

00:09:02.320 --> 00:09:06.236
reasamblezi componentele
ca să ajungi la o concluzie.

00:09:06.360 --> 00:09:10.346
Câteodată trebuie să faci asta iar,
dar mereu sunt astea două lucruri:

00:09:10.400 --> 00:09:12.720
descompunerea şi reclădirea.

00:09:14.280 --> 00:09:15.896
Crucial este

00:09:15.920 --> 00:09:18.816
că datele şi analiza 
computerizată a acestora

00:09:18.840 --> 00:09:21.336
sunt bune numai pentru prima parte.

00:09:21.360 --> 00:09:23.576
Informatica, oricât de puternică e,

00:09:23.600 --> 00:09:28.056
ajută doar la descompunerea problemei
şi la înţelegerea componentelor.

00:09:28.080 --> 00:09:33.346
Nu e potrivită pentru reasamblarea
acestor componente pentru o concluzie.

00:09:33.520 --> 00:09:37.496
O altă unealtă face asta şi o avem toţi.
E vorba de creier.

00:09:37.600 --> 00:09:41.676
Dacă e ceva la care creierul e bun,
e să refacă întregul din componente,

00:09:41.840 --> 00:09:45.356
chiar dacă informaţiile sunt incomplete
și să tragă o concluzie corectă.

00:09:45.480 --> 00:09:48.416
Mai ales când e creierul unui expert.

00:09:48.440 --> 00:09:51.096
Cred că de asta a avut Netflix succes,

00:09:51.120 --> 00:09:54.696
fiindcă au folosit informatica
şi creierul la locul potrivit.

00:09:54.720 --> 00:09:58.256
Au folosit întâi informatica
să afle cât mai multe despre publicul lor,

00:09:58.280 --> 00:10:01.696
pe care altfel nu l-ar fi putut
înţelege atât de bine,

00:10:01.720 --> 00:10:04.336
dar decizia de a lua
piesele acestui puzzle,

00:10:04.360 --> 00:10:07.696
şi de a le recompune pentru a face
un serial ca „House of Cards”,

00:10:07.720 --> 00:10:09.136
nu a venit de la computer.

00:10:09.160 --> 00:10:13.136
Ted Sarandos şi echipa lui
au luat decizia de a produce acel serial,

00:10:13.160 --> 00:10:15.891
ceea ce însemna și că îşi asumau
prin acea decizie,

00:10:15.891 --> 00:10:18.416
un risc personal destul de mare.

00:10:18.440 --> 00:10:21.456
Amazon, în schimb,
au mers pe calea greşită.

00:10:21.480 --> 00:10:24.216
Au folosit statistica în tot procesul
de luare a deciziei,

00:10:24.240 --> 00:10:26.656
întâi când au organizat
concursul pentru idei,

00:10:26.680 --> 00:10:30.376
şi apoi când au selectat „Alpha House"
ca şi câştigător.

00:10:30.400 --> 00:10:32.896
Asta a fost desigur
o decizie fără riscuri pentru ei,

00:10:32.920 --> 00:10:35.376
pentru că mereu puteau
blama informatica, spunând:

00:10:35.400 --> 00:10:37.096
„Asta ne spun datele."

00:10:37.120 --> 00:10:41.360
Dar asta nu a condus la rezultatele
excepţionale la care sperau.

00:10:42.120 --> 00:10:47.096
Informatica e desigur un mijloc excelent
ca ajutor pentru decizii mai bune

00:10:47.120 --> 00:10:51.926
dar cred că lucrurile merg rău
când conduce luarea deciziilor.

00:10:52.120 --> 00:10:55.896
Oricât de puternică,
informatica e doar o unealtă.

00:10:55.920 --> 00:10:59.256
Cred că acest dispozitiv e foarte util
să îmi reamintească asta.

00:10:59.280 --> 00:11:00.496
Mulţi veţi crede la fel.

00:11:00.520 --> 00:11:01.736
(Râsete)

00:11:01.760 --> 00:11:05.636
Înaintea statisticii ăsta era dispozitivul
pentru luarea deciziilor.

00:11:05.880 --> 00:11:07.136
(Râsete)

00:11:07.160 --> 00:11:08.496
Mulţi îl ştiţi.

00:11:08.520 --> 00:11:11.643
Această jucărie se numeşte
Magic 8 Ball şi e chiar uimitoare,

00:11:11.720 --> 00:11:14.616
pentru că daca trebuie să decizi,
prin „da” sau „nu”,

00:11:14.640 --> 00:11:18.376
trebuie doar să scuturi bila
şi obţii răspunsul:

00:11:18.400 --> 00:11:21.216
„Foarte probabil”
care-ți apare în fereastră, chiar acum.

00:11:21.240 --> 00:11:23.336
O să fac mai târziu demonstraţii tehnice.

00:11:23.360 --> 00:11:24.576
(Râsete)

00:11:24.600 --> 00:11:28.176
Desigur, am luat
câteva decizii în viaţa mea

00:11:28.200 --> 00:11:31.096
când, privind retrospectiv,
ar fi trebuit să ascult bila.

00:11:31.120 --> 00:11:34.456
Dar când ai la dispoziţie informatica,

00:11:34.480 --> 00:11:37.536
vrei să înlocuieşti asta cu ceva
mult mai sofisticat,

00:11:37.560 --> 00:11:41.176
ca analiza datelor,
pentru a face o alegere mai bună,

00:11:41.200 --> 00:11:43.816
dar asta nu schimbă
miezul problemei:

00:11:43.840 --> 00:11:47.016
bila poate deveni
din ce în ce mai „deşteaptă",

00:11:47.040 --> 00:11:49.856
dar cred că tot noi
ar trebui să luăm deciziile

00:11:49.880 --> 00:11:52.896
dacă vrem să obţinem ceva extraordinar,

00:11:52.920 --> 00:11:54.856
la marginea din dreapta a curbei.

00:11:54.880 --> 00:11:59.376
Cred că un mesaj foarte încurajator

00:11:59.400 --> 00:12:03.376
e că şi dacă ai acces la
cantităţi imense de date procesate,

00:12:03.400 --> 00:12:07.496
merită să iei tu deciziile,

00:12:07.520 --> 00:12:10.176
să fii un expert în ceea ce faci

00:12:10.200 --> 00:12:12.296
şi să îţi asumi riscuri.

00:12:12.320 --> 00:12:15.096
Pentru că la final, nu statistica,
ci asumarea riscurilor

00:12:15.120 --> 00:12:19.080
o să te plaseze
în zona dorită a graficului.

00:12:19.840 --> 00:12:21.056
Mulţumesc.

00:12:21.080 --> 00:12:24.760
(Aplauze)

