WEBVTT
Kind: captions
Language: en

00:00:15.285 --> 00:00:20.236
Okay, now I don't want
to alarm anybody in this room,

00:00:20.260 --> 00:00:24.236
but it's just come to my attention
that the person to your right is a liar.

00:00:24.260 --> 00:00:26.236
(Laughter)

00:00:26.260 --> 00:00:29.236
Also, the person to your left is a liar.

00:00:29.260 --> 00:00:32.236
Also the person sitting
in your very seats is a liar.

00:00:32.260 --> 00:00:34.236
We're all liars.

00:00:34.260 --> 00:00:36.236
What I'm going to do today

00:00:36.260 --> 00:00:39.836
is I'm going to show you what the research
says about why we're all liars,

00:00:39.860 --> 00:00:41.436
how you can become a liespotter

00:00:41.460 --> 00:00:44.236
and why you might want
to go the extra mile

00:00:44.260 --> 00:00:47.236
and go from liespotting to truth seeking,

00:00:47.260 --> 00:00:49.236
and ultimately to trust building.

00:00:49.260 --> 00:00:52.236
Now, speaking of trust,

00:00:52.260 --> 00:00:55.236
ever since I wrote
this book, "Liespotting,"

00:00:55.260 --> 00:00:58.236
no one wants to meet me in person
anymore, no, no, no, no, no.

00:00:58.260 --> 00:01:01.236
They say, "It's okay, we'll email you."

00:01:01.260 --> 00:01:03.236
(Laughter)

00:01:03.260 --> 00:01:07.236
I can't even get
a coffee date at Starbucks.

00:01:07.260 --> 00:01:09.236
My husband's like, "Honey, deception?

00:01:09.260 --> 00:01:12.451
Maybe you could have focused on cooking.
How about French cooking?"

00:01:12.475 --> 00:01:14.618
So before I get started,
what I'm going to do

00:01:14.642 --> 00:01:17.236
is I'm going to clarify my goal for you,

00:01:17.260 --> 00:01:19.236
which is not to teach a game of Gotcha.

00:01:19.260 --> 00:01:21.236
Liespotters aren't those nitpicky kids,

00:01:21.260 --> 00:01:24.594
those kids in the back of the room
that are shouting, "Gotcha! Gotcha!

00:01:24.618 --> 00:01:27.236
Your eyebrow twitched.
You flared your nostril.

00:01:27.260 --> 00:01:30.236
I watch that TV show 'Lie To Me.'
I know you're lying."

00:01:30.260 --> 00:01:32.236
No, liespotters are armed

00:01:32.260 --> 00:01:35.236
with scientific knowledge
of how to spot deception.

00:01:35.260 --> 00:01:37.236
They use it to get to the truth,

00:01:37.260 --> 00:01:39.356
and they do what mature
leaders do everyday;

00:01:39.380 --> 00:01:42.236
they have difficult conversations
with difficult people,

00:01:42.260 --> 00:01:44.236
sometimes during very difficult times.

00:01:44.260 --> 00:01:48.236
And they start up that path
by accepting a core proposition,

00:01:48.260 --> 00:01:50.236
and that proposition is the following:

00:01:50.260 --> 00:01:52.728
Lying is a cooperative act.

00:01:54.037 --> 00:01:57.236
Think about it, a lie has no power
whatsoever by its mere utterance.

00:01:57.260 --> 00:01:59.236
Its power emerges

00:01:59.260 --> 00:02:01.356
when someone else agrees
to believe the lie.

00:02:01.380 --> 00:02:03.356
So I know it may sound like tough love,

00:02:03.380 --> 00:02:07.236
but look, if at some point
you got lied to,

00:02:07.260 --> 00:02:09.236
it's because you agreed to get lied to.

00:02:09.260 --> 00:02:12.236
Truth number one about lying:
Lying's a cooperative act.

00:02:12.260 --> 00:02:14.236
Now not all lies are harmful.

00:02:14.260 --> 00:02:17.236
Sometimes we're willing
participants in deception

00:02:17.260 --> 00:02:20.236
for the sake of social dignity,

00:02:20.260 --> 00:02:23.236
maybe to keep a secret that should
be kept secret, secret.

00:02:23.260 --> 00:02:25.236
We say, "Nice song."

00:02:25.260 --> 00:02:28.236
"Honey, you don't look fat in that, no."

00:02:28.260 --> 00:02:30.236
Or we say, favorite of the digiratti,

00:02:30.260 --> 00:02:33.236
"You know, I just fished
that email out of my Spam folder.

00:02:33.260 --> 00:02:36.236
So sorry."

00:02:36.260 --> 00:02:39.499
But there are times when we are unwilling
participants in deception.

00:02:39.523 --> 00:02:42.236
And that can have dramatic costs for us.

00:02:42.260 --> 00:02:45.236
Last year saw 997 billion dollars

00:02:45.260 --> 00:02:48.839
in corporate fraud alone
in the United States.

00:02:49.593 --> 00:02:51.608
That's an eyelash
under a trillion dollars.

00:02:51.632 --> 00:02:53.236
That's seven percent of revenues.

00:02:53.260 --> 00:02:55.236
Deception can cost billions.

00:02:55.260 --> 00:02:58.236
Think Enron, Madoff, the mortgage crisis.

00:02:58.260 --> 00:03:01.236
Or in the case
of double agents and traitors,

00:03:01.260 --> 00:03:03.236
like Robert Hanssen or Aldrich Ames,

00:03:03.260 --> 00:03:05.236
lies can betray our country,

00:03:05.260 --> 00:03:08.260
they can compromise our security,
they can undermine democracy,

00:03:08.284 --> 00:03:11.236
they can cause the deaths
of those that defend us.

00:03:11.260 --> 00:03:14.236
Deception is actually serious business.

00:03:14.260 --> 00:03:18.236
This con man, Henry Oberlander,
he was such an effective con man,

00:03:18.260 --> 00:03:20.236
British authorities say

00:03:20.260 --> 00:03:23.736
he could have undermined the entire
banking system of the Western world.

00:03:23.760 --> 00:03:26.936
And you can't find this guy on Google;
you can't find him anywhere.

00:03:26.960 --> 00:03:29.436
He was interviewed once,
and he said the following.

00:03:29.460 --> 00:03:31.136
He said, "Look, I've got one rule."

00:03:31.160 --> 00:03:33.236
And this was Henry's rule, he said,

00:03:33.260 --> 00:03:35.636
"Look, everyone is willing
to give you something.

00:03:35.660 --> 00:03:39.232
They're ready to give you something
for whatever it is they're hungry for."

00:03:39.256 --> 00:03:40.636
And that's the crux of it.

00:03:40.660 --> 00:03:43.089
If you don't want to be
deceived, you have to know,

00:03:43.113 --> 00:03:44.789
what is it that you're hungry for?

00:03:44.813 --> 00:03:47.236
And we all kind of hate to admit it.

00:03:47.260 --> 00:03:50.236
We wish we were
better husbands, better wives,

00:03:50.260 --> 00:03:54.236
smarter, more powerful, taller, richer --

00:03:54.260 --> 00:03:56.236
the list goes on.

00:03:56.260 --> 00:03:58.236
Lying is an attempt to bridge that gap,

00:03:58.260 --> 00:04:00.236
to connect our wishes and our fantasies

00:04:00.260 --> 00:04:03.236
about who we wish we were,
how we wish we could be,

00:04:03.260 --> 00:04:06.236
with what we're really like.

00:04:06.260 --> 00:04:09.499
And boy are we willing to fill in
those gaps in our lives with lies.

00:04:09.523 --> 00:04:12.236
On a given day, studies show
that you may be lied to

00:04:12.260 --> 00:04:14.236
anywhere from 10 to 200 times.

00:04:14.260 --> 00:04:17.236
Now granted, many of those are white lies.

00:04:17.260 --> 00:04:19.236
But in another study,

00:04:19.260 --> 00:04:21.236
it showed that strangers lied three times

00:04:21.260 --> 00:04:23.641
within the first 10 minutes
of meeting each other.

00:04:23.665 --> 00:04:25.236
(Laughter)

00:04:25.260 --> 00:04:28.236
Now when we first hear
this data, we recoil.

00:04:28.260 --> 00:04:30.236
We can't believe how prevalent lying is.

00:04:30.260 --> 00:04:32.236
We're essentially against lying.

00:04:32.260 --> 00:04:36.236
But if you look more closely,
the plot actually thickens.

00:04:36.260 --> 00:04:39.236
We lie more to strangers
than we lie to coworkers.

00:04:39.260 --> 00:04:43.236
Extroverts lie more than introverts.

00:04:43.260 --> 00:04:48.236
Men lie eight times more about themselves
than they do other people.

00:04:48.260 --> 00:04:51.236
Women lie more to protect other people.

00:04:51.260 --> 00:04:54.236
If you're an average married couple,

00:04:54.260 --> 00:04:58.236
you're going to lie to your spouse
in one out of every 10 interactions.

00:04:58.260 --> 00:05:00.236
Now, you may think that's bad.

00:05:00.260 --> 00:05:02.546
If you're unmarried,
that number drops to three.

00:05:02.570 --> 00:05:04.236
Lying's complex.

00:05:04.260 --> 00:05:07.260
It's woven into the fabric
of our daily and our business lives.

00:05:07.284 --> 00:05:09.236
We're deeply ambivalent about the truth.

00:05:09.260 --> 00:05:11.236
We parse it out on an as-needed basis,

00:05:11.260 --> 00:05:13.236
sometimes for very good reasons,

00:05:13.260 --> 00:05:16.451
other times just because
we don't understand the gaps in our lives.

00:05:16.475 --> 00:05:18.236
That's truth number two about lying.

00:05:18.260 --> 00:05:20.236
We're against lying,

00:05:20.260 --> 00:05:22.236
but we're covertly for it

00:05:22.260 --> 00:05:26.260
in ways that our society has sanctioned
for centuries and centuries and centuries.

00:05:26.284 --> 00:05:28.236
It's as old as breathing.

00:05:28.260 --> 00:05:30.689
It's part of our culture,
it's part of our history.

00:05:30.713 --> 00:05:36.236
Think Dante, Shakespeare,
the Bible, News of the World.

00:05:36.260 --> 00:05:38.236
(Laughter)

00:05:38.260 --> 00:05:40.546
Lying has evolutionary value
to us as a species.

00:05:40.570 --> 00:05:44.236
Researchers have long known
that the more intelligent the species,

00:05:44.260 --> 00:05:46.236
the larger the neocortex,

00:05:46.260 --> 00:05:48.236
the more likely it is to be deceptive.

00:05:48.260 --> 00:05:50.236
Now you might remember Koko.

00:05:50.260 --> 00:05:53.499
Does anybody remember Koko the gorilla
who was taught sign language?

00:05:53.523 --> 00:05:56.236
Koko was taught to communicate
via sign language.

00:05:56.260 --> 00:05:58.236
Here's Koko with her kitten.

00:05:58.260 --> 00:06:01.236
It's her cute little, fluffy pet kitten.

00:06:01.260 --> 00:06:05.236
Koko once blamed her pet kitten
for ripping a sink out of the wall.

00:06:05.260 --> 00:06:07.236
(Laughter)

00:06:07.260 --> 00:06:09.451
We're hardwired to become
leaders of the pack.

00:06:09.475 --> 00:06:11.236
It's starts really, really early.

00:06:11.260 --> 00:06:13.236
How early?

00:06:13.260 --> 00:06:15.236
Well babies will fake a cry,

00:06:15.260 --> 00:06:17.236
pause, wait to see who's coming

00:06:17.260 --> 00:06:19.236
and then go right back to crying.

00:06:19.260 --> 00:06:21.236
One-year-olds learn concealment.

00:06:21.260 --> 00:06:23.236
(Laughter)

00:06:23.260 --> 00:06:25.236
Two-year-olds bluff.

00:06:25.260 --> 00:06:27.236
Five-year-olds lie outright.

00:06:27.260 --> 00:06:29.236
They manipulate via flattery.

00:06:29.260 --> 00:06:32.236
Nine-year-olds, masters of the cover-up.

00:06:32.260 --> 00:06:34.236
By the time you enter college,

00:06:34.260 --> 00:06:37.636
you're going to lie to your mom
in one out of every five interactions.

00:06:37.660 --> 00:06:40.536
By the time we enter this work world
and we're breadwinners,

00:06:40.560 --> 00:06:44.236
we enter a world that is just cluttered
with Spam, fake digital friends,

00:06:44.260 --> 00:06:46.236
partisan media,

00:06:46.260 --> 00:06:48.236
ingenious identity thieves,

00:06:48.260 --> 00:06:50.236
world-class Ponzi schemers,

00:06:50.260 --> 00:06:52.236
a deception epidemic --

00:06:52.260 --> 00:06:57.237
in short, what one author calls
a post-truth society.

00:06:57.261 --> 00:07:01.226
It's been very confusing
for a long time now.

00:07:03.925 --> 00:07:05.236
What do you do?

00:07:05.260 --> 00:07:09.236
Well, there are steps we can take
to navigate our way through the morass.

00:07:09.260 --> 00:07:12.236
Trained liespotters get to the truth
90 percent of the time.

00:07:12.260 --> 00:07:15.236
The rest of us,
we're only 54 percent accurate.

00:07:15.260 --> 00:07:17.236
Why is it so easy to learn?

00:07:17.260 --> 00:07:19.475
There are good liars and bad liars.

00:07:19.499 --> 00:07:21.136
There are no real original liars.

00:07:21.160 --> 00:07:24.136
We all make the same mistakes.
We all use the same techniques.

00:07:24.160 --> 00:07:27.789
So what I'm going to do is I'm going
to show you two patterns of deception.

00:07:27.813 --> 00:07:30.012
And then we're going
to look at the hot spots

00:07:30.036 --> 00:07:31.889
and see if we can find them ourselves.

00:07:31.913 --> 00:07:33.536
We're going to start with speech.

00:07:33.560 --> 00:07:35.894
(Video) Bill Clinton:
I want you to listen to me.

00:07:35.918 --> 00:07:37.336
I'm going to say this again.

00:07:37.360 --> 00:07:44.236
I did not have sexual relations
with that woman, Miss Lewinsky.

00:07:44.260 --> 00:07:48.236
I never told anybody to lie,
not a single time, never.

00:07:48.260 --> 00:07:51.236
And these allegations are false.

00:07:51.260 --> 00:07:53.832
And I need to go back to work
for the American people.

00:07:53.856 --> 00:07:55.832
Thank you.

00:07:55.856 --> 00:07:57.368
(Applause)

00:07:58.260 --> 00:08:01.236
Pamela Meyer: Okay,
what were the telltale signs?

00:08:01.260 --> 00:08:05.236
Well first we heard what's known
as a non-contracted denial.

00:08:05.260 --> 00:08:08.260
Studies show that people
who are overdetermined in their denial

00:08:08.284 --> 00:08:11.236
will resort to formal rather
than informal language.

00:08:11.260 --> 00:08:14.236
We also heard
distancing language: "that woman."

00:08:14.260 --> 00:08:16.975
We know that liars will unconsciously
distance themselves

00:08:16.999 --> 00:08:18.236
from their subject,

00:08:18.260 --> 00:08:21.236
using language as their tool.

00:08:21.260 --> 00:08:24.308
Now if Bill Clinton had said,
"Well, to tell you the truth ..."

00:08:24.332 --> 00:08:26.623
or Richard Nixon's favorite,
"In all candor ..."

00:08:26.647 --> 00:08:28.336
he would have been a dead giveaway

00:08:28.360 --> 00:08:30.236
for any liespotter that knows

00:08:30.260 --> 00:08:33.689
that qualifying language, as it's called,
qualifying language like that,

00:08:33.713 --> 00:08:35.236
further discredits the subject.

00:08:35.260 --> 00:08:38.236
Now if he had repeated
the question in its entirety,

00:08:38.260 --> 00:08:42.236
or if he had peppered his account
with a little too much detail --

00:08:42.260 --> 00:08:44.451
and we're all really glad
he didn't do that --

00:08:44.475 --> 00:08:46.475
he would have further discredited himself.

00:08:46.499 --> 00:08:48.236
Freud had it right.

00:08:48.260 --> 00:08:51.236
Freud said, look,
there's much more to it than speech:

00:08:51.260 --> 00:08:54.236
"No mortal can keep a secret.

00:08:54.260 --> 00:08:57.236
If his lips are silent,
he chatters with his fingertips."

00:08:57.260 --> 00:09:00.236
And we all do it no matter
how powerful you are.

00:09:00.260 --> 00:09:02.236
We all chatter with our fingertips.

00:09:02.260 --> 00:09:05.236
I'm going to show you
Dominique Strauss-Kahn with Obama

00:09:05.260 --> 00:09:08.236
who's chattering with his fingertips.

00:09:08.260 --> 00:09:11.236
(Laughter)

00:09:11.260 --> 00:09:17.236
Now this brings us to our next pattern,
which is body language.

00:09:17.260 --> 00:09:20.236
With body language,
here's what you've got to do.

00:09:20.260 --> 00:09:23.236
You've really got to just throw
your assumptions out the door.

00:09:23.260 --> 00:09:25.689
Let the science temper
your knowledge a little bit.

00:09:25.713 --> 00:09:28.236
Because we think liars
fidget all the time.

00:09:28.260 --> 00:09:32.022
Well guess what, they're known to freeze
their upper bodies when they're lying.

00:09:32.046 --> 00:09:34.236
We think liars won't look you in the eyes.

00:09:34.260 --> 00:09:37.136
Well guess what, they look
you in the eyes a little too much

00:09:37.160 --> 00:09:38.736
just to compensate for that myth.

00:09:38.760 --> 00:09:42.236
We think warmth and smiles
convey honesty, sincerity.

00:09:42.260 --> 00:09:46.236
But a trained liespotter
can spot a fake smile a mile away.

00:09:46.260 --> 00:09:49.260
Can you all spot the fake smile here?

00:09:50.260 --> 00:09:55.236
You can consciously contract
the muscles in your cheeks.

00:09:55.260 --> 00:09:58.236
But the real smile's in the eyes,
the crow's feet of the eyes.

00:09:58.260 --> 00:10:00.236
They cannot be consciously contracted,

00:10:00.260 --> 00:10:02.236
especially if you overdid the Botox.

00:10:02.260 --> 00:10:05.236
Don't overdo the Botox;
nobody will think you're honest.

00:10:05.260 --> 00:10:07.236
Now we're going to look at the hot spots.

00:10:07.260 --> 00:10:09.546
Can you tell what's happening
in a conversation?

00:10:09.570 --> 00:10:12.236
Can you start to find the hot spots

00:10:12.260 --> 00:10:14.236
to see the discrepancies

00:10:14.260 --> 00:10:16.451
between someone's words
and someone's actions?

00:10:16.475 --> 00:10:18.236
Now, I know it seems really obvious,

00:10:18.260 --> 00:10:23.236
but when you're having a conversation
with someone you suspect of deception,

00:10:23.260 --> 00:10:26.336
attitude is by far the most overlooked
but telling of indicators.

00:10:26.360 --> 00:10:28.556
An honest person
is going to be cooperative.

00:10:28.580 --> 00:10:30.628
They're going to show
they're on your side.

00:10:30.652 --> 00:10:32.236
They're going to be enthusiastic.

00:10:32.260 --> 00:10:35.536
They're going to be willing and helpful
to getting you to the truth.

00:10:35.560 --> 00:10:38.336
They're going to be willing
to brainstorm, name suspects,

00:10:38.360 --> 00:10:39.636
provide details.

00:10:39.660 --> 00:10:41.236
They're going to say,

00:10:41.260 --> 00:10:44.436
"Hey, maybe it was those guys in payroll
that forged those checks."

00:10:44.460 --> 00:10:47.736
They're going to be infuriated
if they sense they're wrongly accused

00:10:47.760 --> 00:10:50.936
throughout the entire course
of the interview, not just in flashes;

00:10:50.960 --> 00:10:54.199
they'll be infuriated throughout
the entire course of the interview.

00:10:54.223 --> 00:10:55.636
And if you ask someone honest

00:10:55.660 --> 00:10:58.236
what should happen
to whomever did forge those checks,

00:10:58.260 --> 00:11:00.036
an honest person is much more likely

00:11:00.060 --> 00:11:03.236
to recommend strict rather
than lenient punishment.

00:11:03.260 --> 00:11:05.927
Now let's say you're having
that exact same conversation

00:11:05.951 --> 00:11:07.236
with someone deceptive.

00:11:07.260 --> 00:11:09.236
That person may be withdrawn,

00:11:09.260 --> 00:11:11.236
look down, lower their voice,

00:11:11.260 --> 00:11:13.236
pause, be kind of herky-jerky.

00:11:13.260 --> 00:11:15.308
Ask a deceptive person
to tell their story,

00:11:15.332 --> 00:11:18.236
they're going to pepper it
with way too much detail

00:11:18.260 --> 00:11:21.236
in all kinds of irrelevant places.

00:11:21.260 --> 00:11:24.736
And then they're going to tell their story
in strict chronological order.

00:11:24.760 --> 00:11:26.536
And what a trained interrogator does

00:11:26.560 --> 00:11:30.236
is they come in and in very subtle ways
over the course of several hours,

00:11:30.260 --> 00:11:33.236
they will ask that person
to tell that story backwards,

00:11:33.260 --> 00:11:35.236
and then they'll watch them squirm,

00:11:35.260 --> 00:11:38.689
and track which questions produce
the highest volume of deceptive tells.

00:11:38.713 --> 00:11:41.236
Why do they do that?
Well, we all do the same thing.

00:11:41.260 --> 00:11:43.236
We rehearse our words,

00:11:43.260 --> 00:11:45.236
but we rarely rehearse our gestures.

00:11:45.260 --> 00:11:47.236
We say "yes," we shake our heads "no."

00:11:47.260 --> 00:11:50.356
We tell very convincing stories,
we slightly shrug our shoulders.

00:11:50.380 --> 00:11:52.236
We commit terrible crimes,

00:11:52.260 --> 00:11:55.236
and we smile at the delight
in getting away with it.

00:11:55.260 --> 00:11:58.236
Now, that smile is known
in the trade as "duping delight."

00:11:58.260 --> 00:12:01.236
And we're going to see that
in several videos moving forward,

00:12:01.260 --> 00:12:04.336
but we're going to start --
for those of you who don't know him,

00:12:04.360 --> 00:12:06.436
this is presidential
candidate John Edwards

00:12:06.460 --> 00:12:09.236
who shocked America by fathering
a child out of wedlock.

00:12:09.260 --> 00:12:12.236
We're going to see him talk
about getting a paternity test.

00:12:12.260 --> 00:12:16.260
See now if you can spot him
saying, "yes" while shaking his head "no,"

00:12:16.284 --> 00:12:18.236
slightly shrugging his shoulders.

00:12:18.260 --> 00:12:20.936
(Video) John Edwards: I'd be happy
to participate in one.

00:12:20.960 --> 00:12:23.836
I know that it's not possible
that this child could be mine,

00:12:23.860 --> 00:12:25.436
because of the timing of events.

00:12:25.460 --> 00:12:27.236
So I know it's not possible.

00:12:27.260 --> 00:12:31.236
Happy to take a paternity test,
and would love to see it happen.

00:12:31.260 --> 00:12:34.308
Interviewer: Are you going to do
that soon? Is there somebody --

00:12:34.332 --> 00:12:37.236
JE: Well, I'm only one side.
I'm only one side of the test.

00:12:37.260 --> 00:12:39.864
But I'm happy to participate in one.

00:12:41.055 --> 00:12:43.489
PM: Okay, those head shakes
are much easier to spot

00:12:43.513 --> 00:12:45.036
once you know to look for them.

00:12:45.060 --> 00:12:49.036
There are going to be times
when someone makes one expression

00:12:49.060 --> 00:12:52.236
while masking another that just
kind of leaks through in a flash.

00:12:52.260 --> 00:12:54.236
Murderers are known to leak sadness.

00:12:54.260 --> 00:12:56.836
Your new joint venture partner
might shake your hand,

00:12:56.860 --> 00:13:01.236
celebrate, go out to dinner with you
and then leak an expression of anger.

00:13:01.260 --> 00:13:04.836
And we're not all going to become
facial expression experts overnight here,

00:13:04.860 --> 00:13:07.338
but there's one I can teach you
that's very dangerous

00:13:07.362 --> 00:13:08.575
and it's easy to learn,

00:13:08.599 --> 00:13:10.436
and that's the expression of contempt.

00:13:10.460 --> 00:13:13.460
Now with anger, you've got
two people on an even playing field.

00:13:13.484 --> 00:13:15.675
It's still somewhat
of a healthy relationship.

00:13:15.699 --> 00:13:19.236
But when anger turns to contempt,
you've been dismissed.

00:13:19.260 --> 00:13:21.236
It's associated with moral superiority.

00:13:21.260 --> 00:13:24.236
And for that reason, it's very,
very hard to recover from.

00:13:24.260 --> 00:13:26.236
Here's what it looks like.

00:13:26.260 --> 00:13:30.236
It's marked by one lip corner
pulled up and in.

00:13:30.260 --> 00:13:33.236
It's the only asymmetrical expression.

00:13:33.260 --> 00:13:37.236
And in the presence of contempt,
whether or not deception follows --

00:13:37.260 --> 00:13:39.236
and it doesn't always follow --

00:13:39.260 --> 00:13:41.308
look the other way,
go the other direction,

00:13:41.332 --> 00:13:43.236
reconsider the deal,

00:13:43.260 --> 00:13:47.236
say, "No thank you. I'm not coming up
for just one more nightcap. Thank you."

00:13:47.260 --> 00:13:51.236
Science has surfaced
many, many more indicators.

00:13:51.260 --> 00:13:53.236
We know, for example,

00:13:53.260 --> 00:13:55.260
we know liars will shift their blink rate,

00:13:55.284 --> 00:13:57.236
point their feet towards an exit.

00:13:57.260 --> 00:13:59.236
They will take barrier objects

00:13:59.260 --> 00:14:02.689
and put them between themselves
and the person that is interviewing them.

00:14:02.713 --> 00:14:04.236
They'll alter their vocal tone,

00:14:04.260 --> 00:14:07.236
often making their vocal tone much lower.

00:14:07.260 --> 00:14:09.236
Now here's the deal.

00:14:09.260 --> 00:14:12.236
These behaviors are just behaviors.

00:14:12.260 --> 00:14:14.236
They're not proof of deception.

00:14:14.260 --> 00:14:16.236
They're red flags.

00:14:16.260 --> 00:14:18.236
We're human beings.

00:14:18.260 --> 00:14:21.536
We make deceptive flailing gestures
all over the place all day long.

00:14:21.560 --> 00:14:23.751
They don't mean anything
in and of themselves.

00:14:23.775 --> 00:14:26.336
But when you see clusters
of them, that's your signal.

00:14:26.360 --> 00:14:29.236
Look, listen, probe,
ask some hard questions,

00:14:29.260 --> 00:14:32.236
get out of that very comfortable
mode of knowing,

00:14:32.260 --> 00:14:35.236
walk into curiosity mode,
ask more questions,

00:14:35.260 --> 00:14:38.636
have a little dignity, treat the person
you're talking to with rapport.

00:14:38.660 --> 00:14:42.236
Don't try to be like those folks
on "Law &amp; Order" and those other TV shows

00:14:42.260 --> 00:14:44.308
that pummel their subjects
into submission.

00:14:44.332 --> 00:14:46.336
Don't be too aggressive, it doesn't work.

00:14:47.379 --> 00:14:50.736
Now, we've talked a little bit
about how to talk to someone who's lying

00:14:50.760 --> 00:14:52.236
and how to spot a lie.

00:14:52.260 --> 00:14:55.736
And as I promised, we're now going
to look at what the truth looks like.

00:14:55.760 --> 00:14:57.536
But I'm going to show you two videos,

00:14:57.560 --> 00:15:00.236
two mothers -- one is lying,
one is telling the truth.

00:15:00.260 --> 00:15:04.356
And these were surfaced by researcher
David Matsumoto in California.

00:15:04.380 --> 00:15:08.236
And I think they're an excellent example
of what the truth looks like.

00:15:08.260 --> 00:15:10.236
This mother, Diane Downs,

00:15:10.260 --> 00:15:12.236
shot her kids at close range,

00:15:12.260 --> 00:15:16.236
drove them to the hospital
while they bled all over the car,

00:15:16.260 --> 00:15:18.236
claimed a scraggy-haired stranger did it.

00:15:18.260 --> 00:15:20.236
And you'll see when you see the video,

00:15:20.260 --> 00:15:22.594
she can't even pretend
to be an agonizing mother.

00:15:22.618 --> 00:15:26.236
What you want to look for here
is an incredible discrepancy

00:15:26.260 --> 00:15:30.236
between horrific events that she describes
and her very, very cool demeanor.

00:15:30.260 --> 00:15:33.736
And if you look closely, you'll see
duping delight throughout this video.

00:15:33.760 --> 00:15:36.236
(Video) Diane Downs:
At night when I close my eyes,

00:15:36.260 --> 00:15:39.356
I can see Christie reaching
her hand out to me while I'm driving,

00:15:39.380 --> 00:15:41.636
and the blood just kept
coming out of her mouth.

00:15:41.660 --> 00:15:43.803
And that -- maybe
it'll fade too with time --

00:15:43.827 --> 00:15:45.236
but I don't think so.

00:15:45.260 --> 00:15:48.260
That bothers me the most.

00:15:55.260 --> 00:15:57.236
PM: Now I'm going to show you a video

00:15:57.260 --> 00:15:59.308
of an actual grieving mother,
Erin Runnion,

00:15:59.332 --> 00:16:03.236
confronting her daughter's murderer
and torturer in court.

00:16:03.260 --> 00:16:05.260
Here you're going to see no false emotion,

00:16:05.284 --> 00:16:08.236
just the authentic expression
of a mother's agony.

00:16:08.260 --> 00:16:10.351
(Video) Erin Runnion:
I wrote this statement

00:16:10.375 --> 00:16:13.036
on the third anniversary
of the night you took my baby,

00:16:13.060 --> 00:16:14.336
and you hurt her,

00:16:14.360 --> 00:16:16.236
and you crushed her,

00:16:16.260 --> 00:16:20.236
you terrified her until her heart stopped.

00:16:20.260 --> 00:16:23.236
And she fought, and I know she fought you.

00:16:23.260 --> 00:16:27.236
But I know she looked at you
with those amazing brown eyes,

00:16:27.260 --> 00:16:30.236
and you still wanted to kill her.

00:16:30.260 --> 00:16:32.236
And I don't understand it,

00:16:32.260 --> 00:16:33.807
and I never will.

00:16:35.910 --> 00:16:39.236
PM: Okay, there's no doubting
the veracity of those emotions.

00:16:39.260 --> 00:16:42.236
Now the technology
around what the truth looks like

00:16:42.260 --> 00:16:45.236
is progressing on, the science of it.

00:16:45.260 --> 00:16:47.236
We know, for example,

00:16:47.260 --> 00:16:50.403
that we now have specialized eye trackers
and infrared brain scans,

00:16:50.427 --> 00:16:53.236
MRI's that can decode the signals
that our bodies send out

00:16:53.260 --> 00:16:55.236
when we're trying to be deceptive.

00:16:55.260 --> 00:16:58.236
And these technologies are going
to be marketed to all of us

00:16:58.260 --> 00:17:00.236
as panaceas for deceit,

00:17:00.260 --> 00:17:03.236
and they will prove
incredibly useful some day.

00:17:03.260 --> 00:17:05.499
But you've got to ask yourself
in the meantime:

00:17:05.523 --> 00:17:07.619
Who do you want on your side
of the meeting,

00:17:07.643 --> 00:17:10.236
someone who's trained
in getting to the truth

00:17:10.260 --> 00:17:13.336
or some guy who's going to drag
a 400-pound electroencephalogram

00:17:13.360 --> 00:17:14.636
through the door?

00:17:14.660 --> 00:17:18.236
Liespotters rely on human tools.

00:17:18.260 --> 00:17:20.236
They know, as someone once said,

00:17:20.260 --> 00:17:22.236
"Character's who you are in the dark."

00:17:22.260 --> 00:17:26.236
And what's kind of interesting
is that today, we have so little darkness.

00:17:26.260 --> 00:17:29.236
Our world is lit up 24 hours a day.

00:17:29.260 --> 00:17:33.236
It's transparent
with blogs and social networks

00:17:33.260 --> 00:17:35.936
broadcasting the buzz
of a whole new generation of people

00:17:35.960 --> 00:17:38.536
that have made a choice to live
their lives in public.

00:17:38.560 --> 00:17:42.236
It's a much more noisy world.

00:17:42.260 --> 00:17:46.236
So one challenge we have is to remember,

00:17:46.260 --> 00:17:49.236
oversharing, that's not honesty.

00:17:49.260 --> 00:17:53.236
Our manic tweeting and texting
can blind us

00:17:53.260 --> 00:17:56.836
to the fact that the subtleties
of human decency -- character integrity --

00:17:56.860 --> 00:17:59.908
that's still what matters,
that's always what's going to matter.

00:17:59.932 --> 00:18:01.436
So in this much noisier world,

00:18:01.460 --> 00:18:03.236
it might make sense for us

00:18:03.260 --> 00:18:08.236
to be just a little bit more explicit
about our moral code.

00:18:08.260 --> 00:18:10.836
When you combine the science
of recognizing deception

00:18:10.860 --> 00:18:12.536
with the art of looking, listening,

00:18:12.560 --> 00:18:15.236
you exempt yourself
from collaborating in a lie.

00:18:15.260 --> 00:18:19.236
You start up that path
of being just a little bit more explicit,

00:18:19.260 --> 00:18:21.260
because you signal to everyone around you,

00:18:21.284 --> 00:18:26.236
you say, "Hey, my world, our world,
it's going to be an honest one.

00:18:26.260 --> 00:18:28.880
My world is going to be
one where truth is strengthened

00:18:28.904 --> 00:18:31.236
and falsehood is recognized
and marginalized."

00:18:31.260 --> 00:18:33.236
And when you do that,

00:18:33.260 --> 00:18:36.236
the ground around you starts
to shift just a little bit.

00:18:36.260 --> 00:18:39.236
And that's the truth. Thank you.

00:18:39.260 --> 00:18:44.260
(Applause)

