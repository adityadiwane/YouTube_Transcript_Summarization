WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Augusto Incio
Revisor: Sebastian Betti

00:00:12.811 --> 00:00:16.324
Hemos evolucionado con las 
herramientas y estas con nosotros.

00:00:16.384 --> 00:00:21.407
Nuestros ancestros crearon estas
hachas de mano hace 1,5 millones de años,

00:00:21.431 --> 00:00:24.453
moldeándolas no solo para ajustar
una tarea a las manos,

00:00:24.477 --> 00:00:25.945
sino también a "sus" manos.

00:00:26.747 --> 00:00:28.347
Sin embargo, con los años,

00:00:28.351 --> 00:00:30.881
estas se han especializado
cada vez más.

00:00:31.293 --> 00:00:35.130
Estas herramientas de esculpir
han evolucionado con el uso,

00:00:35.154 --> 00:00:38.716
y cada una tiene una forma diferente
que corresponde a su función.

00:00:38.740 --> 00:00:41.408
Y aprovechan la destreza
de nuestras manos

00:00:41.432 --> 00:00:44.561
para manipular cosas
con mucha más precisión.

00:00:45.338 --> 00:00:48.404
Pero como las herramientas se han 
vuelto cada vez más complejas,

00:00:48.428 --> 00:00:52.306
necesitamos controles más complejos
para manejarlas.

00:00:52.714 --> 00:00:57.158
Los diseñadores se han vuelto
hábiles para crear interfaces

00:00:57.182 --> 00:01:00.920
que nos permitan manipular parámetros
mientras atendemos otras cosas,

00:01:00.944 --> 00:01:03.823
como tomar una fotografía 
y cambiar el enfoque,

00:01:03.847 --> 00:01:05.383
o la apertura.

00:01:05.918 --> 00:01:10.137
Pero la PC ha cambiado fundamentalmente
la forma en que vemos las herramientas

00:01:10.161 --> 00:01:12.175
porque la computación es dinámica.

00:01:12.564 --> 00:01:14.715
Así que uno puede hacer
un millón de cosas diferentes

00:01:14.739 --> 00:01:17.087
y ejecutar un millón de 
aplicaciones diferentes.

00:01:17.111 --> 00:01:20.857
Sin embargo, la PC tiene
la misma forma física estática

00:01:20.881 --> 00:01:22.817
para todas esas diferentes aplicaciones

00:01:22.841 --> 00:01:25.618
y los mismos elementos de 
una interfaz también estática.

00:01:25.976 --> 00:01:28.396
Y creo que esto es
fundamentalmente un problema,

00:01:28.420 --> 00:01:31.416
porque realmente no nos permite
interactuar con las manos

00:01:31.440 --> 00:01:35.127
y capturar toda la destreza
que tenemos en el cuerpo.

00:01:36.026 --> 00:01:40.562
Mi idea es que, por ende, necesitamos
un nuevo tipo de interfaces

00:01:40.586 --> 00:01:44.345
que pueda capturar estas
ricas capacidades que tenemos

00:01:44.369 --> 00:01:46.739
y que puedan adaptarse
físicamente a nosotros

00:01:46.763 --> 00:01:49.013
y permitirnos interactuar
en nuevas formas.

00:01:49.037 --> 00:01:51.624
Y eso es lo que he estado 
haciendo en el Media Lab del MIT

00:01:51.648 --> 00:01:52.972
y ahora en Stanford.

00:01:53.901 --> 00:01:57.512
Así que, con mis colegas
Daniel Leithinger y Hiroshi Ishii,

00:01:57.536 --> 00:01:58.925
creamos inFORM,

00:01:58.949 --> 00:02:01.447
donde la interfaz puede
de hecho salir de la pantalla

00:02:01.471 --> 00:02:03.747
y se puede manipular físicamente.

00:02:03.771 --> 00:02:06.514
O se puede visualizar físicamente
información en 3D

00:02:06.538 --> 00:02:10.382
y tocarla y sentirla para
entenderla de nuevas formas.

00:02:15.889 --> 00:02:19.965
O se puede interactuar a través 
de gestos y deformaciones directas

00:02:19.989 --> 00:02:22.936
para esculpir en plastilina digital.

00:02:26.474 --> 00:02:29.555
O pueden surgir de la superficie
elementos de la interfaz

00:02:29.579 --> 00:02:30.951
y cambiar según la demanda.

00:02:30.975 --> 00:02:33.483
Y la idea es que para
cada aplicación individual,

00:02:33.507 --> 00:02:36.807
la forma física se puede
ajustar a la aplicación.

00:02:37.196 --> 00:02:39.301
Y creo que esto representa
una nueva forma

00:02:39.325 --> 00:02:41.275
de interactuar con la información,

00:02:41.299 --> 00:02:42.728
haciéndola física.

00:02:43.142 --> 00:02:45.357
Así que la pregunta es,
¿cómo usaremos esto?

00:02:45.810 --> 00:02:49.500
Tradicionalmente, los urbanistas
y arquitectos construyen modelos físicos

00:02:49.524 --> 00:02:52.334
de ciudades y edificios
para entenderlos mejor.

00:02:52.358 --> 00:02:56.573
Con Tony Tang en el Media Lab, creamos 
una interfaz construida en inFORM

00:02:56.597 --> 00:03:01.580
para permitir a los urbanistas
diseñar y ver ciudades enteras.

00:03:01.604 --> 00:03:05.861
Y ahora se la puede recorrer,
pero es dinámica, es física,

00:03:05.885 --> 00:03:07.585
hasta pueden interactuar en directo.

00:03:07.609 --> 00:03:09.347
O pueden ver diferentes vistas,

00:03:09.371 --> 00:03:12.188
como información de población 
o de tránsito,

00:03:12.212 --> 00:03:14.034
pero de manera física.

00:03:14.996 --> 00:03:18.806
Creemos también que esta forma dinámica
muestra que se pueden cambiar

00:03:18.830 --> 00:03:21.790
las formas de colaborar
remotamente con la gente.

00:03:21.814 --> 00:03:24.117
Así, cuando trabajamos
juntos presencialmente,

00:03:24.141 --> 00:03:25.799
no solo los miro frente a frente

00:03:25.823 --> 00:03:28.861
sino que también estoy gestualizando
y manipulando objetos.

00:03:28.885 --> 00:03:32.675
Y eso es realmente difícil de hacer
con herramientas como Skype.

00:03:33.905 --> 00:03:36.891
Con inFORM, pueden acceder 
desde la pantalla

00:03:36.915 --> 00:03:39.027
y manipular cosas a cierta distancia.

00:03:39.051 --> 00:03:42.226
Y se usan pines de visualización
para representar las manos,

00:03:42.250 --> 00:03:47.546
permitiendo de hecho tocar
y manipular objetos a distancia.

00:03:50.519 --> 00:03:54.793
Además, se puede manipular y también
colaborar en conjuntos de datos 3D.

00:03:54.817 --> 00:03:58.486
Así que también les pueden
hacer gestos y manipularlos.

00:03:58.510 --> 00:04:02.900
Y eso permite a la gente colaborar
en estos nuevos tipos de información 3D

00:04:02.924 --> 00:04:06.535
de forma más rica de lo que podría
ser con los recursos tradicionales.

00:04:07.870 --> 00:04:10.623
Y luego también pueden
traer objetos existentes

00:04:10.647 --> 00:04:13.861
y capturarlos por un lado
y transmitirlos por otro.

00:04:13.885 --> 00:04:16.671
O pueden tener un objeto 
vinculado en dos lugares.

00:04:16.695 --> 00:04:18.779
Así, cuando muevo un balón en un lado,

00:04:18.803 --> 00:04:21.160
el balón también se mueve en el otro.

00:04:22.278 --> 00:04:25.381
Y hacemos esto capturando
al usuario remoto

00:04:25.405 --> 00:04:28.209
con una cámara espacio-sensorial
como la Kinect, de Microsoft.

00:04:28.757 --> 00:04:31.774
Ahora, se podrían estar preguntando
cómo funciona todo esto,

00:04:31.798 --> 00:04:35.450
y esencialmente, son 
900 accionadores en línea

00:04:35.474 --> 00:04:37.760
conectados a estas conexiones mecánicas

00:04:37.784 --> 00:04:41.530
que permiten que la acción de aquí abajo
se propague a estos pines de arriba.

00:04:41.554 --> 00:04:45.121
No es complejo comparado
a lo que sucede en el CERN,

00:04:45.145 --> 00:04:47.471
pero construirlo nos llevó mucho tiempo.

00:04:47.495 --> 00:04:49.750
Empezamos con un solo motor,

00:04:49.774 --> 00:04:51.419
un solo accionador lineal,

00:04:51.816 --> 00:04:54.979
y luego tuvimos que diseñar una placa 
de circuito a medida para controlarlos.

00:04:55.003 --> 00:04:57.055
Más tarde tuvimos que hacer muchos más.

00:04:57.079 --> 00:05:00.693
Y el problema de hacer 900 de estos,

00:05:00.717 --> 00:05:03.837
es que hay que hacer cada paso 900 veces.

00:05:03.861 --> 00:05:06.218
Por eso había mucho por hacer.

00:05:06.242 --> 00:05:09.974
Y, por así decirlo, pusimos una 
mini planta explotadora en Media Lab,

00:05:09.998 --> 00:05:13.710
trajimos universitarios y los 
convencimos de hacer "investigación".

00:05:13.734 --> 00:05:14.748
(Risas)

00:05:14.772 --> 00:05:17.790
Tuvimos madrugadas de películas y pizza,

00:05:17.814 --> 00:05:19.642
atornillando miles de tuercas.

00:05:19.666 --> 00:05:20.864
Ya saben, investigación.

00:05:20.888 --> 00:05:22.435
(Risas)

00:05:22.459 --> 00:05:25.777
Como sea, pienso que 
nos entusiasmaron mucho las cosas

00:05:25.801 --> 00:05:27.497
que nos permitió hacer inFORM.

00:05:27.521 --> 00:05:31.721
Estamos usando, cada vez más, equipos
móviles, e interactuando donde sea.

00:05:31.745 --> 00:05:34.424
Pero estos dispositivos, 
tanto como las PC's,

00:05:34.448 --> 00:05:36.759
son usados para muchas
aplicaciones diferentes.

00:05:36.783 --> 00:05:38.776
Se usan para hablar por teléfono,

00:05:38.800 --> 00:05:41.956
para navegar en la web,
jugar videojuegos, tomar fotos,

00:05:41.980 --> 00:05:43.689
e incluso para miles de otras cosas.

00:05:43.713 --> 00:05:46.697
Pero, una vez más, tienen
la misma forma física estática

00:05:46.721 --> 00:05:48.839
para cada una de estas aplicaciones.

00:05:48.863 --> 00:05:52.226
Por ello, queríamos llegar a tomar
algunas de las mismas interacciones

00:05:52.250 --> 00:05:53.933
que desarrollamos para inFORM

00:05:53.957 --> 00:05:55.845
y llevarlas a dispositivos móviles.

00:05:56.427 --> 00:06:00.074
Así que, en Stanford, creamos
esta pantalla de borde háptico;

00:06:00.098 --> 00:06:03.275
es un equipo móvil con una 
matriz de actuadores lineales

00:06:03.299 --> 00:06:04.646
que pueden cambiar de forma,

00:06:04.670 --> 00:06:08.567
pueden sentir en las manos dónde 
se está mientras se lee un libro.

00:06:09.058 --> 00:06:12.795
O se pueden sentir en el bolsillo
nuevos tipos de sensaciones táctiles,

00:06:12.819 --> 00:06:14.621
más variadas que la vibración.

00:06:14.645 --> 00:06:17.880
O botones que pueden emerger de 
un lado, permitiendo interactuar

00:06:17.904 --> 00:06:20.362
donde uno quiera que estén.

00:06:21.334 --> 00:06:24.731
O pueden jugar videojuegos
y tener botones reales.

00:06:25.786 --> 00:06:27.302
Y pudimos hacer esto

00:06:27.326 --> 00:06:32.080
insertando 40 pequeños actuadores
lineales dentro del dispositivo.

00:06:32.104 --> 00:06:34.159
Eso permite no solo tocarlos

00:06:34.183 --> 00:06:36.417
sino regresarlos también a su lugar.

00:06:36.911 --> 00:06:41.089
También hemos observado otras formas
de crear cambios de forma más complejas.

00:06:41.113 --> 00:06:44.505
Así que hemos usado un actuador neumático
para crear un equipo mutante

00:06:44.529 --> 00:06:48.394
donde se puede ir de un modo
muy similar a un teléfono,

00:06:48.418 --> 00:06:50.648
a una pulsera en el proceso.

00:06:51.720 --> 00:06:54.559
Así que junto con Ken Nakagaki
en el Media Lab,

00:06:54.583 --> 00:06:57.137
creamos esta nueva versión
de alta resolución

00:06:57.161 --> 00:07:03.111
que usa un rayo de servomotores para 
pasar de una pulsera interactiva

00:07:03.135 --> 00:07:06.263
a un dispositivo de acceso táctil,

00:07:06.287 --> 00:07:07.532
a un teléfono.

00:07:07.556 --> 00:07:09.504
(Risas)

00:07:10.104 --> 00:07:12.276
También estamos interesados
en buscar formas

00:07:12.300 --> 00:07:14.927
en las que los usuarios 
puedan deformar la interfaz

00:07:14.951 --> 00:07:17.839
para darle formas en dispositivos
que ellos quieran usar.

00:07:17.863 --> 00:07:20.263
Así, pueden hacer algo como 
un controlador de juego,

00:07:20.273 --> 00:07:22.725
y luego el sistema entenderá
en qué forma está

00:07:22.809 --> 00:07:25.219
y cambiar a ese modo.

00:07:25.899 --> 00:07:27.538
Así que, ¿a dónde apunta esto?

00:07:27.568 --> 00:07:29.530
¿Cómo avanzamos a partir de aquí?

00:07:29.588 --> 00:07:32.216
Creo, realmente, que hoy estamos

00:07:32.218 --> 00:07:34.993
en esta nueva era de 
la Internet de las Cosas,

00:07:35.023 --> 00:07:36.807
donde hay PC's por doquier,

00:07:36.837 --> 00:07:38.688
en nuestros bolsillos, en las paredes,

00:07:38.688 --> 00:07:42.476
están en casi todos los dispositivos que
comprarán en los siguientes cinco años.

00:07:42.584 --> 00:07:45.430
Pero ¿qué pasaría si dejáramos
de pensar en dispositivos

00:07:45.468 --> 00:07:47.939
y en vez de eso pensáramos en ambientes?

00:07:48.049 --> 00:07:50.603
Y en cómo podemos tener
muebles inteligentes

00:07:50.607 --> 00:07:53.789
o habitaciones inteligentes,
o ambientes inteligentes,

00:07:53.873 --> 00:07:56.849
o ciudades que puedan adaptarse 
a nosotros físicamente,

00:07:56.953 --> 00:08:00.995
y nos permitan tener nuevas formas
de colaboración con la gente

00:08:01.019 --> 00:08:03.220
y hacer nuevos tipos de tareas.

00:08:03.384 --> 00:08:06.882
Así, para la Semana del Diseño
de Milán, hemos creado TRANSFORM,

00:08:06.956 --> 00:08:10.620
una mesa interactiva a escala
de estos visualizadores de forma

00:08:10.770 --> 00:08:13.542
que puede mover objetos reales
en la superficie y, por ejemplo,

00:08:13.552 --> 00:08:15.565
recordarles llevar sus llaves.

00:08:15.683 --> 00:08:20.770
Pero pueden transformarse también para 
ajustarse a distintas interacciones.

00:08:20.930 --> 00:08:22.222
Así, si uno quiere trabajar,

00:08:22.232 --> 00:08:25.229
pueden cambiar y adaptarse
al sistema de trabajo.

00:08:25.297 --> 00:08:27.259
Y mientras uno lleve 
el dispositivo consigo,

00:08:27.259 --> 00:08:29.890
este creará todas las 
prestaciones necesarias

00:08:30.028 --> 00:08:34.796
y otros objetos para ayudar
a cumplir esos objetivos.

00:08:37.383 --> 00:08:38.863
Así que, en conclusión,

00:08:38.933 --> 00:08:42.724
realmente pienso que tenemos que 
pensar una forma nueva, muy diferente,

00:08:42.818 --> 00:08:44.967
de interactuar con las PC's.

00:08:45.557 --> 00:08:48.794
Necesitamos PC's que puedan 
adaptarse físicamente a nosotros

00:08:48.794 --> 00:08:51.419
y adaptarse a las formas
en las que necesitamos usarlas

00:08:51.482 --> 00:08:55.554
y realmente aprovechar 
la destreza de las manos,

00:08:55.693 --> 00:09:00.391
y la facultad de pensar espacialmente
la información, haciéndola física.

00:09:00.611 --> 00:09:04.643
Pero anticipándonos, creo que necesitamos
ir más allá de los dispositivos,

00:09:04.747 --> 00:09:08.243
para pensar realmente 
nuevas formas de unir a la gente,

00:09:08.403 --> 00:09:11.306
de brindar nuestra información al mundo,

00:09:11.350 --> 00:09:15.228
y pensar ambientes inteligentes que
se adapten físicamente a nosotros.

00:09:15.368 --> 00:09:16.695
Y con eso, me despido.

00:09:16.735 --> 00:09:18.013
Muchas gracias.

00:09:18.227 --> 00:09:19.878
(Aplausos)

