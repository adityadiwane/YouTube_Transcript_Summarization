WEBVTT
Kind: captions
Language: en

00:00:15.260 --> 00:00:17.260
It's the Second World War.

00:00:17.260 --> 00:00:20.260
A German prison camp.

00:00:20.260 --> 00:00:23.260
And this man,

00:00:23.260 --> 00:00:26.260
Archie Cochrane,

00:00:26.260 --> 00:00:29.260
is a prisoner of war and a doctor,

00:00:29.260 --> 00:00:32.260
and he has a problem.

00:00:32.260 --> 00:00:35.260
The problem is that the men under his care

00:00:35.260 --> 00:00:37.260
are suffering

00:00:37.260 --> 00:00:40.260
from an excruciating and debilitating condition

00:00:40.260 --> 00:00:43.260
that Archie doesn't really understand.

00:00:43.260 --> 00:00:45.260
The symptoms

00:00:45.260 --> 00:00:48.260
are this horrible swelling up of fluids under the skin.

00:00:48.260 --> 00:00:51.260
But he doesn't know whether it's an infection, whether it's to do with malnutrition.

00:00:51.260 --> 00:00:53.260
He doesn't know how to cure it.

00:00:53.260 --> 00:00:56.260
And he's operating in a hostile environment.

00:00:56.260 --> 00:00:58.260
And people do terrible things in wars.

00:00:58.260 --> 00:01:01.260
The German camp guards, they've got bored.

00:01:01.260 --> 00:01:03.260
They've taken to just firing into the prison camp at random

00:01:03.260 --> 00:01:05.260
for fun.

00:01:05.260 --> 00:01:07.260
On one particular occasion,

00:01:07.260 --> 00:01:10.260
one of the guards threw a grenade into the prisoners' lavatory

00:01:10.260 --> 00:01:13.260
while it was full of prisoners.

00:01:13.260 --> 00:01:15.260
He said he heard suspicious laughter.

00:01:15.260 --> 00:01:18.260
And Archie Cochrane, as the camp doctor,

00:01:18.260 --> 00:01:20.260
was one of the first men in

00:01:20.260 --> 00:01:22.260
to clear up the mess.

00:01:22.260 --> 00:01:24.260
And one more thing:

00:01:24.260 --> 00:01:27.260
Archie was suffering from this illness himself.

00:01:27.260 --> 00:01:30.260
So the situation seemed pretty desperate.

00:01:30.260 --> 00:01:32.260
But Archie Cochrane

00:01:32.260 --> 00:01:35.260
was a resourceful person.

00:01:35.260 --> 00:01:38.260
He'd already smuggled vitamin C into the camp,

00:01:38.260 --> 00:01:40.260
and now he managed

00:01:40.260 --> 00:01:42.260
to get hold of supplies of marmite

00:01:42.260 --> 00:01:44.260
on the black market.

00:01:44.260 --> 00:01:47.260
Now some of you will be wondering what marmite is.

00:01:47.260 --> 00:01:50.260
Marmite is a breakfast spread beloved of the British.

00:01:50.260 --> 00:01:52.260
It looks like crude oil.

00:01:52.260 --> 00:01:54.260
It tastes ...

00:01:54.260 --> 00:01:56.260
zesty.

00:01:56.260 --> 00:01:58.260
And importantly,

00:01:58.260 --> 00:02:00.260
it's a rich source

00:02:00.260 --> 00:02:02.260
of vitamin B12.

00:02:02.260 --> 00:02:05.260
So Archie splits the men under his care as best he can

00:02:05.260 --> 00:02:07.260
into two equal groups.

00:02:07.260 --> 00:02:09.260
He gives half of them vitamin C.

00:02:09.260 --> 00:02:12.260
He gives half of them vitamin B12.

00:02:12.260 --> 00:02:15.260
He very carefully and meticulously notes his results

00:02:15.260 --> 00:02:17.260
in an exercise book.

00:02:17.260 --> 00:02:19.260
And after just a few days,

00:02:19.260 --> 00:02:21.260
it becomes clear

00:02:21.260 --> 00:02:24.260
that whatever is causing this illness,

00:02:24.260 --> 00:02:27.260
marmite is the cure.

00:02:27.260 --> 00:02:30.260
So Cochrane then goes to the Germans who are running the prison camp.

00:02:30.260 --> 00:02:32.260
Now you've got to imagine at the moment --

00:02:32.260 --> 00:02:34.260
forget this photo, imagine this guy

00:02:34.260 --> 00:02:37.260
with this long ginger beard and this shock of red hair.

00:02:37.260 --> 00:02:40.260
He hasn't been able to shave -- a sort of Billy Connolly figure.

00:02:40.260 --> 00:02:42.260
Cochrane, he starts ranting at these Germans

00:02:42.260 --> 00:02:44.260
in this Scottish accent --

00:02:44.260 --> 00:02:47.260
in fluent German, by the way, but in a Scottish accent --

00:02:47.260 --> 00:02:50.260
and explains to them how German culture was the culture

00:02:50.260 --> 00:02:52.260
that gave Schiller and Goethe to the world.

00:02:52.260 --> 00:02:54.260
And he can't understand

00:02:54.260 --> 00:02:56.260
how this barbarism can be tolerated,

00:02:56.260 --> 00:02:59.260
and he vents his frustrations.

00:02:59.260 --> 00:03:02.260
And then he goes back to his quarters,

00:03:02.260 --> 00:03:05.260
breaks down and weeps

00:03:05.260 --> 00:03:08.260
because he's convinced that the situation is hopeless.

00:03:10.260 --> 00:03:13.260
But a young German doctor

00:03:13.260 --> 00:03:16.260
picks up Archie Cochrane's exercise book

00:03:16.260 --> 00:03:20.260
and says to his colleagues,

00:03:20.260 --> 00:03:25.260
"This evidence is incontrovertible.

00:03:25.260 --> 00:03:28.260
If we don't supply vitamins to the prisoners,

00:03:28.260 --> 00:03:30.260
it's a war crime."

00:03:30.260 --> 00:03:32.260
And the next morning,

00:03:32.260 --> 00:03:35.260
supplies of vitamin B12 are delivered to the camp,

00:03:35.260 --> 00:03:38.260
and the prisoners begin to recover.

00:03:39.260 --> 00:03:41.260
Now I'm not telling you this story

00:03:41.260 --> 00:03:43.260
because I think Archie Cochrane is a dude,

00:03:43.260 --> 00:03:47.260
although Archie Cochrane is a dude.

00:03:47.260 --> 00:03:49.260
I'm not even telling you the story

00:03:49.260 --> 00:03:51.260
because I think we should be running

00:03:51.260 --> 00:03:53.260
more carefully controlled randomized trials

00:03:53.260 --> 00:03:55.260
in all aspects of public policy,

00:03:55.260 --> 00:03:59.260
although I think that would also be completely awesome.

00:03:59.260 --> 00:04:01.260
I'm telling you this story

00:04:01.260 --> 00:04:04.260
because Archie Cochrane, all his life,

00:04:04.260 --> 00:04:08.260
fought against a terrible affliction,

00:04:08.260 --> 00:04:12.260
and he realized it was debilitating to individuals

00:04:12.260 --> 00:04:14.260
and it was corrosive to societies.

00:04:14.260 --> 00:04:16.260
And he had a name for it.

00:04:16.260 --> 00:04:19.260
He called it the God complex.

00:04:19.260 --> 00:04:23.260
Now I can describe the symptoms of the God complex very, very easily.

00:04:23.260 --> 00:04:26.260
So the symptoms of the complex

00:04:26.260 --> 00:04:29.260
are, no matter how complicated the problem,

00:04:29.260 --> 00:04:32.260
you have an absolutely overwhelming belief

00:04:32.260 --> 00:04:36.260
that you are infallibly right in your solution.

00:04:36.260 --> 00:04:38.260
Now Archie was a doctor,

00:04:38.260 --> 00:04:40.260
so he hung around with doctors a lot.

00:04:40.260 --> 00:04:43.260
And doctors suffer from the God complex a lot.

00:04:43.260 --> 00:04:45.260
Now I'm an economist, I'm not a doctor,

00:04:45.260 --> 00:04:47.260
but I see the God complex around me all the time

00:04:47.260 --> 00:04:49.260
in my fellow economists.

00:04:49.260 --> 00:04:51.260
I see it in our business leaders.

00:04:51.260 --> 00:04:53.260
I see it in the politicians we vote for --

00:04:53.260 --> 00:04:57.260
people who, in the face of an incredibly complicated world,

00:04:57.260 --> 00:05:00.260
are nevertheless absolutely convinced

00:05:00.260 --> 00:05:03.260
that they understand the way that the world works.

00:05:03.260 --> 00:05:06.260
And you know, with the future billions that we've been hearing about,

00:05:06.260 --> 00:05:08.260
the world is simply far too complex

00:05:08.260 --> 00:05:10.260
to understand in that way.

00:05:10.260 --> 00:05:12.260
Well let me give you an example.

00:05:12.260 --> 00:05:14.260
Imagine for a moment

00:05:14.260 --> 00:05:16.260
that, instead of Tim Harford in front of you,

00:05:16.260 --> 00:05:19.260
there was Hans Rosling presenting his graphs.

00:05:19.260 --> 00:05:21.260
You know Hans:

00:05:21.260 --> 00:05:23.260
the Mick Jagger of TED.

00:05:23.260 --> 00:05:25.260
(Laughter)

00:05:25.260 --> 00:05:27.260
And he'd be showing you these amazing statistics,

00:05:27.260 --> 00:05:29.260
these amazing animations.

00:05:29.260 --> 00:05:31.260
And they are brilliant; it's wonderful work.

00:05:31.260 --> 00:05:33.260
But a typical Hans Rosling graph:

00:05:33.260 --> 00:05:36.260
think for a moment, not what it shows,

00:05:36.260 --> 00:05:39.260
but think instead about what it leaves out.

00:05:39.260 --> 00:05:42.260
So it'll show you GDP per capita,

00:05:42.260 --> 00:05:44.260
population, longevity,

00:05:44.260 --> 00:05:46.260
that's about it.

00:05:46.260 --> 00:05:48.260
So three pieces of data for each country --

00:05:48.260 --> 00:05:50.260
three pieces of data.

00:05:50.260 --> 00:05:52.260
Three pieces of data is nothing.

00:05:52.260 --> 00:05:54.260
I mean, have a look at this graph.

00:05:54.260 --> 00:05:56.260
This is produced by the physicist Cesar Hidalgo.

00:05:56.260 --> 00:05:58.260
He's at MIT.

00:05:58.260 --> 00:06:00.260
Now you won't be able to understand a word of it,

00:06:00.260 --> 00:06:02.260
but this is what it looks like.

00:06:02.260 --> 00:06:04.260
Cesar has trolled the database

00:06:04.260 --> 00:06:07.260
of over 5,000 different products,

00:06:07.260 --> 00:06:12.260
and he's used techniques of network analysis

00:06:12.260 --> 00:06:14.260
to interrogate this database

00:06:14.260 --> 00:06:16.260
and to graph relationships between the different products.

00:06:16.260 --> 00:06:18.260
And it's wonderful, wonderful work.

00:06:18.260 --> 00:06:21.260
You show all these interconnections, all these interrelations.

00:06:21.260 --> 00:06:23.260
And I think it'll be profoundly useful

00:06:23.260 --> 00:06:26.260
in understanding how it is that economies grow.

00:06:26.260 --> 00:06:28.260
Brilliant work.

00:06:28.260 --> 00:06:30.260
Cesar and I tried to write a piece for The New York Times Magazine

00:06:30.260 --> 00:06:32.260
explaining how this works.

00:06:32.260 --> 00:06:34.260
And what we learned

00:06:34.260 --> 00:06:36.260
is Cesar's work is far too good to explain

00:06:36.260 --> 00:06:38.260
in The New York Times Magazine.

00:06:40.260 --> 00:06:43.260
Five thousand products --

00:06:43.260 --> 00:06:45.260
that's still nothing.

00:06:45.260 --> 00:06:47.260
Five thousand products --

00:06:47.260 --> 00:06:49.260
imagine counting every product category

00:06:49.260 --> 00:06:51.260
in Cesar Hidalgo's data.

00:06:51.260 --> 00:06:53.260
Imagine you had one second

00:06:53.260 --> 00:06:55.260
per product category.

00:06:55.260 --> 00:06:58.260
In about the length of this session,

00:06:58.260 --> 00:07:00.260
you would have counted all 5,000.

00:07:00.260 --> 00:07:02.260
Now imagine doing the same thing

00:07:02.260 --> 00:07:05.260
for every different type of product on sale in Walmart.

00:07:05.260 --> 00:07:08.260
There are 100,000 there. It would take you all day.

00:07:08.260 --> 00:07:10.260
Now imagine trying to count

00:07:10.260 --> 00:07:13.260
every different specific product and service

00:07:13.260 --> 00:07:15.260
on sale in a major economy

00:07:15.260 --> 00:07:17.260
such as Tokyo, London or New York.

00:07:17.260 --> 00:07:19.260
It's even more difficult in Edinburgh

00:07:19.260 --> 00:07:22.260
because you have to count all the whisky and the tartan.

00:07:22.260 --> 00:07:24.260
If you wanted to count every product and service

00:07:24.260 --> 00:07:26.260
on offer in New York --

00:07:26.260 --> 00:07:28.260
there are 10 billion of them --

00:07:28.260 --> 00:07:31.260
it would take you 317 years.

00:07:31.260 --> 00:07:34.260
This is how complex the economy we've created is.

00:07:34.260 --> 00:07:36.260
And I'm just counting toasters here.

00:07:36.260 --> 00:07:38.260
I'm not trying to solve the Middle East problem.

00:07:39.260 --> 00:07:42.260
The complexity here is unbelievable.

00:07:42.260 --> 00:07:44.260
And just a piece of context --

00:07:44.260 --> 00:07:46.260
the societies in which our brains evolved

00:07:46.260 --> 00:07:48.260
had about 300 products and services.

00:07:48.260 --> 00:07:51.260
You could count them in five minutes.

00:07:51.260 --> 00:07:54.260
So this is the complexity of the world that surrounds us.

00:07:54.260 --> 00:07:56.260
This perhaps is why

00:07:56.260 --> 00:07:59.260
we find the God complex so tempting.

00:07:59.260 --> 00:08:02.260
We tend to retreat and say, "We can draw a picture,

00:08:02.260 --> 00:08:04.260
we can post some graphs,

00:08:04.260 --> 00:08:07.260
we get it, we understand how this works."

00:08:07.260 --> 00:08:09.260
And we don't.

00:08:09.260 --> 00:08:11.260
We never do.

00:08:11.260 --> 00:08:13.260
Now I'm not trying to deliver a nihilistic message here.

00:08:13.260 --> 00:08:15.260
I'm not trying to say we can't solve

00:08:15.260 --> 00:08:17.260
complicated problems in a complicated world.

00:08:17.260 --> 00:08:19.260
We clearly can.

00:08:19.260 --> 00:08:21.260
But the way we solve them

00:08:21.260 --> 00:08:23.260
is with humility --

00:08:23.260 --> 00:08:25.260
to abandon the God complex

00:08:25.260 --> 00:08:28.260
and to actually use a problem-solving technique that works.

00:08:28.260 --> 00:08:31.260
And we have a problem-solving technique that works.

00:08:31.260 --> 00:08:33.260
Now you show me

00:08:33.260 --> 00:08:35.260
a successful complex system,

00:08:35.260 --> 00:08:38.260
and I will show you a system

00:08:38.260 --> 00:08:40.260
that has evolved through trial and error.

00:08:40.260 --> 00:08:42.260
Here's an example.

00:08:42.260 --> 00:08:45.260
This baby was produced through trial and error.

00:08:46.260 --> 00:08:49.260
I realize that's an ambiguous statement.

00:08:49.260 --> 00:08:51.260
Maybe I should clarify it.

00:08:51.260 --> 00:08:54.260
This baby is a human body: it evolved.

00:08:54.260 --> 00:08:56.260
What is evolution?

00:08:56.260 --> 00:08:59.260
Over millions of years, variation and selection,

00:08:59.260 --> 00:09:02.260
variation and selection --

00:09:02.260 --> 00:09:04.260
trial and error,

00:09:04.260 --> 00:09:07.260
trial and error.

00:09:07.260 --> 00:09:09.260
And it's not just biological systems

00:09:09.260 --> 00:09:11.260
that produce miracles through trial and error.

00:09:11.260 --> 00:09:13.260
You could use it in an industrial context.

00:09:13.260 --> 00:09:15.260
So let's say you wanted to make detergent.

00:09:15.260 --> 00:09:17.260
Let's say you're Unilever

00:09:17.260 --> 00:09:20.260
and you want to make detergent in a factory near Liverpool.

00:09:20.260 --> 00:09:22.260
How do you do it?

00:09:22.260 --> 00:09:25.260
Well you have this great big tank full of liquid detergent.

00:09:25.260 --> 00:09:27.260
You pump it at a high pressure through a nozzle.

00:09:27.260 --> 00:09:30.260
You create a spray of detergent.

00:09:30.260 --> 00:09:32.260
Then the spray dries. It turns into powder.

00:09:32.260 --> 00:09:34.260
It falls to the floor.

00:09:34.260 --> 00:09:36.260
You scoop it up. You put it in cardboard boxes.

00:09:36.260 --> 00:09:38.260
You sell it at a supermarket.

00:09:38.260 --> 00:09:40.260
You make lots of money.

00:09:40.260 --> 00:09:43.260
How do you design that nozzle?

00:09:43.260 --> 00:09:46.260
It turns out to be very important.

00:09:46.260 --> 00:09:48.260
Now if you ascribe to the God complex,

00:09:48.260 --> 00:09:51.260
what you do is you find yourself a little God.

00:09:51.260 --> 00:09:54.260
You find yourself a mathematician; you find yourself a physicist --

00:09:54.260 --> 00:09:57.260
somebody who understands the dynamics of this fluid.

00:09:57.260 --> 00:10:00.260
And he will, or she will,

00:10:00.260 --> 00:10:03.260
calculate the optimal design of the nozzle.

00:10:03.260 --> 00:10:05.260
Now Unilever did this and it didn't work --

00:10:05.260 --> 00:10:07.260
too complicated.

00:10:07.260 --> 00:10:10.260
Even this problem, too complicated.

00:10:10.260 --> 00:10:13.260
But the geneticist Professor Steve Jones

00:10:13.260 --> 00:10:16.260
describes how Unilever actually did solve this problem --

00:10:16.260 --> 00:10:18.260
trial and error,

00:10:18.260 --> 00:10:20.260
variation and selection.

00:10:20.260 --> 00:10:22.260
You take a nozzle

00:10:22.260 --> 00:10:26.260
and you create 10 random variations on the nozzle.

00:10:26.260 --> 00:10:29.260
You try out all 10; you keep the one that works best.

00:10:29.260 --> 00:10:31.260
You create 10 variations on that one.

00:10:31.260 --> 00:10:34.260
You try out all 10. You keep the one that works best.

00:10:34.260 --> 00:10:36.260
You try out 10 variations on that one.

00:10:36.260 --> 00:10:38.260
You see how this works, right?

00:10:38.260 --> 00:10:40.260
And after 45 generations,

00:10:40.260 --> 00:10:42.260
you have this incredible nozzle.

00:10:42.260 --> 00:10:44.260
It looks a bit like a chess piece --

00:10:44.260 --> 00:10:47.260
functions absolutely brilliantly.

00:10:47.260 --> 00:10:49.260
We have no idea

00:10:49.260 --> 00:10:51.260
why it works,

00:10:51.260 --> 00:10:53.260
no idea at all.

00:10:53.260 --> 00:10:55.260
And the moment you step back from the God complex --

00:10:55.260 --> 00:10:57.260
let's just try to have a bunch of stuff;

00:10:57.260 --> 00:11:00.260
let's have a systematic way of determining what's working and what's not --

00:11:00.260 --> 00:11:02.260
you can solve your problem.

00:11:02.260 --> 00:11:04.260
Now this process of trial and error

00:11:04.260 --> 00:11:07.260
is actually far more common in successful institutions

00:11:07.260 --> 00:11:09.260
than we care to recognize.

00:11:09.260 --> 00:11:12.260
And we've heard a lot about how economies function.

00:11:12.260 --> 00:11:16.260
The U.S. economy is still the world's greatest economy.

00:11:16.260 --> 00:11:19.260
How did it become the world's greatest economy?

00:11:19.260 --> 00:11:21.260
I could give you all kinds of facts and figures

00:11:21.260 --> 00:11:23.260
about the U.S. economy,

00:11:23.260 --> 00:11:26.260
but I think the most salient one is this:

00:11:26.260 --> 00:11:29.260
ten percent of American businesses

00:11:29.260 --> 00:11:32.260
disappear every year.

00:11:32.260 --> 00:11:35.260
That is a huge failure rate.

00:11:35.260 --> 00:11:37.260
It's far higher than the failure rate of, say, Americans.

00:11:37.260 --> 00:11:40.260
Ten percent of Americans don't disappear every year.

00:11:40.260 --> 00:11:42.260
Which leads us to conclude

00:11:42.260 --> 00:11:45.260
American businesses fail faster than Americans,

00:11:45.260 --> 00:11:48.260
and therefore American businesses are evolving faster than Americans.

00:11:48.260 --> 00:11:51.260
And eventually, they'll have evolved to such a high peak of perfection

00:11:51.260 --> 00:11:54.260
that they will make us all their pets --

00:11:54.260 --> 00:11:56.260
(Laughter)

00:11:56.260 --> 00:11:59.260
if, of course, they haven't already done so.

00:11:59.260 --> 00:12:02.260
I sometimes wonder.

00:12:02.260 --> 00:12:04.260
But it's this process of trial and error

00:12:04.260 --> 00:12:08.260
that explains this great divergence,

00:12:08.260 --> 00:12:11.260
this incredible performance of Western economies.

00:12:11.260 --> 00:12:14.260
It didn't come because you put some incredibly smart person in charge.

00:12:14.260 --> 00:12:16.260
It's come through trial and error.

00:12:16.260 --> 00:12:18.260
Now I've been sort of banging on about this

00:12:18.260 --> 00:12:20.260
for the last couple of months,

00:12:20.260 --> 00:12:22.260
and people sometimes say to me,

00:12:22.260 --> 00:12:24.260
"Well Tim, it's kind of obvious.

00:12:24.260 --> 00:12:26.260
Obviously trial and error is very important.

00:12:26.260 --> 00:12:28.260
Obviously experimentation is very important.

00:12:28.260 --> 00:12:31.260
Now why are you just wandering around saying this obvious thing?"

00:12:31.260 --> 00:12:33.260
So I say, okay, fine.

00:12:33.260 --> 00:12:35.260
You think it's obvious?

00:12:35.260 --> 00:12:37.260
I will admit it's obvious

00:12:37.260 --> 00:12:39.260
when schools

00:12:39.260 --> 00:12:42.260
start teaching children

00:12:42.260 --> 00:12:45.260
that there are some problems that don't have a correct answer.

00:12:45.260 --> 00:12:48.260
Stop giving them lists of questions

00:12:48.260 --> 00:12:50.260
every single one of which has an answer.

00:12:50.260 --> 00:12:52.260
And there's an authority figure in the corner

00:12:52.260 --> 00:12:54.260
behind the teacher's desk who knows all the answers.

00:12:54.260 --> 00:12:56.260
And if you can't find the answers,

00:12:56.260 --> 00:12:58.260
you must be lazy or stupid.

00:12:58.260 --> 00:13:00.260
When schools stop doing that all the time,

00:13:00.260 --> 00:13:02.260
I will admit that, yes,

00:13:02.260 --> 00:13:04.260
it's obvious that trial and error is a good thing.

00:13:04.260 --> 00:13:07.260
When a politician stands up

00:13:07.260 --> 00:13:09.260
campaigning for elected office

00:13:09.260 --> 00:13:11.260
and says, "I want to fix our health system.

00:13:11.260 --> 00:13:13.260
I want to fix our education system.

00:13:13.260 --> 00:13:16.260
I have no idea how to do it.

00:13:16.260 --> 00:13:18.260
I have half a dozen ideas.

00:13:18.260 --> 00:13:21.260
We're going to test them out. They'll probably all fail.

00:13:21.260 --> 00:13:23.260
Then we'll test some other ideas out.

00:13:23.260 --> 00:13:25.260
We'll find some that work. We'll build on those.

00:13:25.260 --> 00:13:27.260
We'll get rid of the ones that don't." --

00:13:27.260 --> 00:13:30.260
when a politician campaigns on that platform,

00:13:30.260 --> 00:13:33.260
and more importantly, when voters like you and me

00:13:33.260 --> 00:13:35.260
are willing to vote for that kind of politician,

00:13:35.260 --> 00:13:37.260
then I will admit

00:13:37.260 --> 00:13:40.260
that it is obvious that trial and error works, and that -- thank you.

00:13:40.260 --> 00:13:44.260
(Applause)

00:13:44.260 --> 00:13:47.260
Until then, until then

00:13:47.260 --> 00:13:49.260
I'm going to keep banging on about trial and error

00:13:49.260 --> 00:13:52.260
and why we should abandon the God complex.

00:13:52.260 --> 00:13:55.260
Because it's so hard

00:13:55.260 --> 00:13:57.260
to admit our own fallibility.

00:13:57.260 --> 00:13:59.260
It's so uncomfortable.

00:13:59.260 --> 00:14:02.260
And Archie Cochrane understood this as well as anybody.

00:14:02.260 --> 00:14:04.260
There's this one trial he ran

00:14:04.260 --> 00:14:06.260
many years after World War II.

00:14:06.260 --> 00:14:09.260
He wanted to test out

00:14:09.260 --> 00:14:11.260
the question of, where is it

00:14:11.260 --> 00:14:13.260
that patients should recover

00:14:13.260 --> 00:14:15.260
from heart attacks?

00:14:15.260 --> 00:14:18.260
Should they recover in a specialized cardiac unit in hospital,

00:14:18.260 --> 00:14:21.260
or should they recover at home?

00:14:21.260 --> 00:14:24.260
All the cardiac doctors tried to shut him down.

00:14:24.260 --> 00:14:27.260
They had the God complex in spades.

00:14:27.260 --> 00:14:30.260
They knew that their hospitals were the right place for patients,

00:14:30.260 --> 00:14:32.260
and they knew it was very unethical

00:14:32.260 --> 00:14:35.260
to run any kind of trial or experiment.

00:14:35.260 --> 00:14:37.260
Nevertheless, Archie managed to get permission to do this.

00:14:37.260 --> 00:14:39.260
He ran his trial.

00:14:39.260 --> 00:14:41.260
And after the trial had been running for a little while,

00:14:41.260 --> 00:14:43.260
he gathered together all his colleagues

00:14:43.260 --> 00:14:45.260
around his table,

00:14:45.260 --> 00:14:47.260
and he said, "Well, gentlemen,

00:14:47.260 --> 00:14:49.260
we have some preliminary results.

00:14:49.260 --> 00:14:51.260
They're not statistically significant.

00:14:51.260 --> 00:14:54.260
But we have something.

00:14:54.260 --> 00:14:57.260
And it turns out that you're right and I'm wrong.

00:14:57.260 --> 00:14:59.260
It is dangerous for patients

00:14:59.260 --> 00:15:01.260
to recover from heart attacks at home.

00:15:01.260 --> 00:15:04.260
They should be in hospital."

00:15:04.260 --> 00:15:06.260
And there's this uproar, and all the doctors start pounding the table

00:15:06.260 --> 00:15:09.260
and saying, "We always said you were unethical, Archie.

00:15:09.260 --> 00:15:12.260
You're killing people with your clinical trials. You need to shut it down now.

00:15:12.260 --> 00:15:14.260
Shut it down at once."

00:15:14.260 --> 00:15:16.260
And there's this huge hubbub.

00:15:16.260 --> 00:15:18.260
Archie lets it die down.

00:15:18.260 --> 00:15:20.260
And then he says, "Well that's very interesting, gentlemen,

00:15:20.260 --> 00:15:23.260
because when I gave you the table of results,

00:15:23.260 --> 00:15:27.260
I swapped the two columns around.

00:15:27.260 --> 00:15:29.260
It turns out your hospitals are killing people,

00:15:29.260 --> 00:15:31.260
and they should be at home.

00:15:31.260 --> 00:15:34.260
Would you like to close down the trial now,

00:15:34.260 --> 00:15:37.260
or should we wait until we have robust results?"

00:15:38.260 --> 00:15:40.260
Tumbleweed

00:15:40.260 --> 00:15:43.260
rolls through the meeting room.

00:15:43.260 --> 00:15:46.260
But Cochrane would do that kind of thing.

00:15:46.260 --> 00:15:48.260
And the reason he would do that kind of thing

00:15:48.260 --> 00:15:50.260
is because he understood

00:15:50.260 --> 00:15:52.260
it feels so much better

00:15:52.260 --> 00:15:54.260
to stand there and say,

00:15:54.260 --> 00:15:56.260
"Here in my own little world,

00:15:56.260 --> 00:15:58.260
I am a god, I understand everything.

00:15:58.260 --> 00:16:00.260
I do not want to have my opinions challenged.

00:16:00.260 --> 00:16:03.260
I do not want to have my conclusions tested."

00:16:03.260 --> 00:16:05.260
It feels so much more comfortable

00:16:05.260 --> 00:16:08.260
simply to lay down the law.

00:16:08.260 --> 00:16:10.260
Cochrane understood

00:16:10.260 --> 00:16:12.260
that uncertainty, that fallibility,

00:16:12.260 --> 00:16:14.260
that being challenged, they hurt.

00:16:14.260 --> 00:16:18.260
And you sometimes need to be shocked out of that.

00:16:18.260 --> 00:16:21.260
Now I'm not going to pretend that this is easy.

00:16:21.260 --> 00:16:23.260
It isn't easy.

00:16:23.260 --> 00:16:25.260
It's incredibly painful.

00:16:25.260 --> 00:16:27.260
And since I started talking about this subject

00:16:27.260 --> 00:16:29.260
and researching this subject,

00:16:29.260 --> 00:16:31.260
I've been really haunted by something

00:16:31.260 --> 00:16:33.260
a Japanese mathematician said on the subject.

00:16:33.260 --> 00:16:35.260
So shortly after the war,

00:16:35.260 --> 00:16:38.260
this young man, Yutaka Taniyama,

00:16:38.260 --> 00:16:40.260
developed this amazing conjecture

00:16:40.260 --> 00:16:42.260
called the Taniyama-Shimura Conjecture.

00:16:42.260 --> 00:16:45.260
It turned out to be absolutely instrumental

00:16:45.260 --> 00:16:47.260
many decades later

00:16:47.260 --> 00:16:49.260
in proving Fermat's Last Theorem.

00:16:49.260 --> 00:16:51.260
In fact, it turns out it's equivalent

00:16:51.260 --> 00:16:53.260
to proving Fermat's Last Theorem.

00:16:53.260 --> 00:16:57.260
You prove one, you prove the other.

00:16:57.260 --> 00:17:00.260
But it was always a conjecture.

00:17:00.260 --> 00:17:03.260
Taniyama tried and tried and tried

00:17:03.260 --> 00:17:06.260
and he could never prove that it was true.

00:17:06.260 --> 00:17:09.260
And shortly before his 30th birthday in 1958,

00:17:09.260 --> 00:17:13.260
Yutaka Taniyama killed himself.

00:17:13.260 --> 00:17:15.260
His friend, Goro Shimura --

00:17:15.260 --> 00:17:17.260
who worked on the mathematics with him --

00:17:17.260 --> 00:17:20.260
many decades later, reflected on Taniyama's life.

00:17:22.260 --> 00:17:25.260
He said,

00:17:25.260 --> 00:17:27.260
"He was not a very careful person

00:17:27.260 --> 00:17:29.260
as a mathematician.

00:17:29.260 --> 00:17:32.260
He made a lot of mistakes.

00:17:32.260 --> 00:17:36.260
But he made mistakes in a good direction.

00:17:36.260 --> 00:17:39.260
I tried to emulate him,

00:17:39.260 --> 00:17:41.260
but I realized

00:17:41.260 --> 00:17:43.260
it is very difficult

00:17:43.260 --> 00:17:46.260
to make good mistakes."

00:17:46.260 --> 00:17:48.260
Thank you.

00:17:48.260 --> 00:18:00.260
(Applause)

