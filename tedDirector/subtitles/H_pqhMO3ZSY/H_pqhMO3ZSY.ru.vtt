WEBVTT
Kind: captions
Language: ru

00:00:00.000 --> 00:00:07.000
Переводчик: Max Siz
Редактор: Maria Golec

00:00:12.641 --> 00:00:14.995
Я хотел бы рассказать вам историю,

00:00:14.995 --> 00:00:18.171
которая объединяет пресловутый случай

00:00:18.171 --> 00:00:20.940
с участием Адама и Евы

00:00:20.940 --> 00:00:24.386
и ту поразительную перемену границы

00:00:24.386 --> 00:00:27.072
между публичным и личным,
которая произошла

00:00:27.072 --> 00:00:28.842
за последние 10 лет.

00:00:28.842 --> 00:00:30.140
Случай вам известен.

00:00:30.140 --> 00:00:33.470
Как-то раз в Эдемском саду Адам и Ева

00:00:33.470 --> 00:00:35.313
поняли, что они голые.

00:00:35.313 --> 00:00:36.813
Они пришли в ужас.

00:00:36.813 --> 00:00:39.570
А остальное — уже история.

00:00:39.570 --> 00:00:41.758
Сегодня Адам и Ева

00:00:41.758 --> 00:00:44.119
вели бы себя по-другому.

00:00:44.119 --> 00:00:46.387
@Адам: Прошлая ночь удалась!
Прикольное яблочко LOL

00:00:46.387 --> 00:00:48.260
@Ева: да...детка, знаешь,
что случилось с моими штанами?

00:00:48.260 --> 00:00:50.896
Мы действительно раскрываем
значительно больше информации

00:00:50.896 --> 00:00:54.230
о самих себе,
чем когда-либо раньше,

00:00:54.230 --> 00:00:55.934
и гораздо больше информации о нас

00:00:55.934 --> 00:00:58.158
собирается организациями.

00:00:58.158 --> 00:01:01.440
Сегодня можно получить
много полезного

00:01:01.440 --> 00:01:03.886
из анализа персональных данных

00:01:03.886 --> 00:01:05.832
или большого объёма информации,

00:01:05.832 --> 00:01:08.470
но так же приходится идти
на ряд непростых компромиссов

00:01:08.470 --> 00:01:11.568
из-за потери нашей конфиденциальности.

00:01:11.568 --> 00:01:15.591
Мой рассказ об этих компромиссах.

00:01:15.591 --> 00:01:18.175
Начнём мы с наблюдения,
результат которого, по моему мнению,

00:01:18.175 --> 00:01:21.502
становится всё более ясным
за последние несколько лет,

00:01:21.502 --> 00:01:23.599
а именно то, что любая
персональная информация

00:01:23.599 --> 00:01:25.884
может стать деликатной.

00:01:25.884 --> 00:01:30.009
Ещё в 2000 году в мире было сделано

00:01:30.009 --> 00:01:31.921
около 100 миллиардов фото,

00:01:31.921 --> 00:01:34.986
но лишь мизерная их часть

00:01:34.986 --> 00:01:36.869
была действительно загружена онлайн.

00:01:36.869 --> 00:01:40.230
В 2010 году только
на Facebook ежемесячно

00:01:40.230 --> 00:01:43.500
загружалось 2,5 миллиарда фотографий,

00:01:43.500 --> 00:01:45.382
и большинство из них идентифицированы.

00:01:45.382 --> 00:01:47.262
В то же самое время,

00:01:47.262 --> 00:01:52.132
способность компьютеров
распознавать людей на фото

00:01:52.132 --> 00:01:55.740
улучшилась на три порядка.

00:01:55.740 --> 00:01:57.622
Что же происходит, когда вы соединяете

00:01:57.622 --> 00:01:59.123
эти технологии вместе:

00:01:59.123 --> 00:02:01.781
увеличение доступности
персональных данных;

00:02:01.781 --> 00:02:05.429
улучшение компьютерного распознания лиц;

00:02:05.429 --> 00:02:07.611
а так же облачные вычисления,

00:02:07.611 --> 00:02:09.499
которые дают любому в этом зале

00:02:09.499 --> 00:02:11.059
такую вычислительную мощность,

00:02:11.059 --> 00:02:12.945
которая ещё несколько лет назад была

00:02:12.945 --> 00:02:14.727
только у спецслужб;

00:02:14.727 --> 00:02:16.105
и распределённые вычисления,

00:02:16.105 --> 00:02:18.997
которые позволяют моему телефону,
не будучи суперкомпьютером,

00:02:18.997 --> 00:02:20.668
подключаться к интернету

00:02:20.668 --> 00:02:23.002
и просматривать там сотни тысяч

00:02:23.002 --> 00:02:25.641
метрик лица за несколько секунд?

00:02:25.641 --> 00:02:28.269
Ну, мы предполагаем, что результат

00:02:28.269 --> 00:02:30.333
такой комбинации технологий

00:02:30.333 --> 00:02:33.221
радикально изменит наши понятия

00:02:33.221 --> 00:02:35.478
о конфиденциальности и анонимности.

00:02:35.478 --> 00:02:37.471
Чтобы проверить это,
мы провели эксперимент

00:02:37.471 --> 00:02:39.592
на кампусе университета Карнеги-Меллон.

00:02:39.592 --> 00:02:41.691
Мы попросили проходящих мимо студентов

00:02:41.691 --> 00:02:43.470
участвовать в исследовании,

00:02:43.470 --> 00:02:46.032
потом мы сфотографировали
их на вебкамеру

00:02:46.032 --> 00:02:48.814
и попросили заполнить
опросник на компьютере.

00:02:48.814 --> 00:02:50.793
Пока они отвечали на вопросы,

00:02:50.793 --> 00:02:53.590
мы загрузили их фото
в облачный вычислительный кластер

00:02:53.590 --> 00:02:55.317
и запустили процесс распознавания лица,

00:02:55.317 --> 00:02:57.722
чтобы сравнить сделанные
снимки с базой данных

00:02:57.722 --> 00:03:00.115
из нескольких сот тысяч изображений,

00:03:00.115 --> 00:03:03.711
которые мы загрузили
из анкет на Facebook.

00:03:03.711 --> 00:03:06.970
К тому времени как субъект доходил
до последней страницы опросника,

00:03:06.970 --> 00:03:10.317
страница была динамически обновлена

00:03:10.317 --> 00:03:12.630
10-ю самыми похожими фото,

00:03:12.630 --> 00:03:14.915
обнаруженными программой;

00:03:14.915 --> 00:03:16.653
и мы просили опрашиваемого указать,

00:03:16.653 --> 00:03:20.773
находит ли он или она себя на этих фото.

00:03:20.773 --> 00:03:24.472
Вы видите субъекта?

00:03:24.472 --> 00:03:27.317
Компьютер видел,
и по факту идентифицировал

00:03:27.317 --> 00:03:29.466
одного из трёх опрошенных.

00:03:29.466 --> 00:03:32.650
Соответственно, мы можем
начать с неизвестного лица,

00:03:32.650 --> 00:03:36.134
оффлайн или онлайн, мы можем
использовать систему распознавания лиц,

00:03:36.134 --> 00:03:38.494
чтобы определить имя неизвестного

00:03:38.494 --> 00:03:40.602
благодаря данным из социальных сетей.

00:03:40.602 --> 00:03:42.474
А несколько лет назад
мы делали кое-что другое.

00:03:42.474 --> 00:03:44.297
Мы начинали с данных
из социальных сетей,

00:03:44.297 --> 00:03:47.348
статистически комбинировали
их с данными

00:03:47.348 --> 00:03:49.450
социальных служб правительства США,

00:03:49.450 --> 00:03:52.774
и мы доходили до предсказания
номеров карточек социального страхования,

00:03:52.774 --> 00:03:54.286
которые в Соединённых Штатах

00:03:54.286 --> 00:03:56.326
являются чрезвычайно
конфиденциальной информацией.

00:03:56.326 --> 00:03:58.419
Понимаете, к чему я клоню?

00:03:58.419 --> 00:04:01.341
Итак, если вы объедините
эти два исследования вместе,

00:04:01.341 --> 00:04:02.853
то возникает вопрос,

00:04:02.853 --> 00:04:05.573
можно ли начать с лица,

00:04:05.573 --> 00:04:07.884
используя систему распознавания,
определить имя

00:04:07.884 --> 00:04:10.553
и общедоступную информацию

00:04:10.553 --> 00:04:12.485
о лице и этом человеке,

00:04:12.485 --> 00:04:14.733
и через эту общедоступную информацию

00:04:14.733 --> 00:04:16.775
сделать предположение
о личной информации,

00:04:16.775 --> 00:04:18.381
гораздо более конфиденциальной

00:04:18.381 --> 00:04:19.873
и связать её с этим лицом?

00:04:19.873 --> 00:04:21.789
И ответ — да, мы можем
и уже сделали это.

00:04:21.789 --> 00:04:24.357
Конечно, точность снижается.

00:04:24.357 --> 00:04:25.301
[определяются 27% первых 5 цифр номера карточки
социального страхования (с 4 попыток)]

00:04:25.301 --> 00:04:29.128
Но на самом деле, мы даже решили
разработать приложение для iPhone,

00:04:29.128 --> 00:04:31.843
которое использует
встроенную камеру телефона,

00:04:31.843 --> 00:04:33.443
чтобы сделать фото человека,

00:04:33.443 --> 00:04:34.930
потом загрузить его в облако

00:04:34.930 --> 00:04:37.592
и после сделать то,
что я описал в реальном времени:

00:04:37.592 --> 00:04:39.680
найти совпадения,
используя публичную информацию,

00:04:39.680 --> 00:04:41.410
попытаться связать
с конфиденциальной информацией

00:04:41.410 --> 00:04:44.001
и потом послать обратно на телефон

00:04:44.001 --> 00:04:47.610
полученную таким образом
информацию об этом человеке,

00:04:47.610 --> 00:04:49.511
как пример дополненной реальности,

00:04:49.511 --> 00:04:51.962
возможно, ужасный пример
дополненной реальности.

00:04:51.962 --> 00:04:55.301
Мы не разработали это приложение,
чтобы сделать его доступным,

00:04:55.301 --> 00:04:57.223
а лишь в качестве доказательства идеи.

00:04:57.223 --> 00:04:59.536
Просто возьмите эти технологии

00:04:59.536 --> 00:05:01.373
и преувеличьте их возможности.

00:05:01.373 --> 00:05:04.092
Вообразите будущее, в котором
незнакомые люди вокруг вас

00:05:04.092 --> 00:05:06.403
будут смотреть на вас
через Google Glass

00:05:06.403 --> 00:05:08.710
или, однажды, через контактные линзы

00:05:08.710 --> 00:05:12.730
и использовать 7 или 8
источников информации о вас,

00:05:12.730 --> 00:05:15.312
чтобы узнать, что ещё

00:05:15.312 --> 00:05:17.915
может быть известно о вас.

00:05:17.915 --> 00:05:22.709
Как вам такое будущее без секретов?

00:05:22.709 --> 00:05:24.673
И должны ли мы беспокоиться?

00:05:24.673 --> 00:05:26.564
Возможно нам хотелось бы верить,

00:05:26.564 --> 00:05:29.604
что будущее с таким огромным
количеством данных,

00:05:29.604 --> 00:05:32.118
будет лишено предвзятости,

00:05:32.118 --> 00:05:35.701
но на самом деле, обладание
таким количеством информации

00:05:35.701 --> 00:05:37.892
совершенно не означает,
что мы будем принимать

00:05:37.892 --> 00:05:39.598
более объективные решения.

00:05:39.598 --> 00:05:42.158
В другом эксперименте,
мы представляли нашим испытуемым

00:05:42.158 --> 00:05:44.404
информацию о потенциальном
соискателе работы.

00:05:44.404 --> 00:05:47.582
Мы включали в эту информацию
некоторые ссылки

00:05:47.582 --> 00:05:50.228
на кое-какую забавную,
абсолютно легальную,

00:05:50.228 --> 00:05:52.693
но, пожалуй, слегка неловкую информацию,

00:05:52.693 --> 00:05:54.713
которую этот человек
разместил о себе в сети.

00:05:54.713 --> 00:05:57.079
Интересно то, что среди наших испытуемых

00:05:57.079 --> 00:06:00.162
кто-то разместил о себе
сопоставимую информацию,

00:06:00.162 --> 00:06:02.524
а кто-то нет.

00:06:02.524 --> 00:06:04.473
Как вы думаете, какая из групп

00:06:04.473 --> 00:06:09.025
получила более строгое осуждение?

00:06:09.025 --> 00:06:10.982
Парадоксально, но это была группа,

00:06:10.982 --> 00:06:12.715
которая предоставляла
сходную информацию, —

00:06:12.715 --> 00:06:15.657
пример морального диссонанса.

00:06:15.657 --> 00:06:17.407
Теперь вы, может быть, думаете,

00:06:17.407 --> 00:06:19.109
что к вам это не применимо,

00:06:19.109 --> 00:06:21.271
потому что вам нечего скрывать.

00:06:21.271 --> 00:06:23.753
Но ведь на самом деле, частная жизнь —

00:06:23.753 --> 00:06:27.429
это не наличие чего-либо негативного,
что нужно скрывать.

00:06:27.429 --> 00:06:29.783
Представим, что вы директор по кадрам

00:06:29.783 --> 00:06:32.730
некой организации, и вы получаете резюме

00:06:32.730 --> 00:06:35.203
и хотите узнать больше
об этих кандидатах.

00:06:35.203 --> 00:06:37.663
Поэтому вы ищете их имена через Google

00:06:37.663 --> 00:06:39.903
и в каком-то месте

00:06:39.903 --> 00:06:41.911
вы найдёте эту информацию.

00:06:41.911 --> 00:06:46.348
Или в другом месте вы
обнаружите другую информацию.

00:06:46.348 --> 00:06:49.065
Вы думаете, что вы равно вероятно

00:06:49.065 --> 00:06:51.868
вызовете каждого из кандидатов
на собеседование?

00:06:51.868 --> 00:06:54.150
Если вы так думаете, то вы не похожи

00:06:54.150 --> 00:06:56.732
на тех работодателей США,
которые фактически

00:06:56.732 --> 00:07:00.039
стали частью нашего эксперимента,
а именно мы сделали вот что.

00:07:00.039 --> 00:07:03.221
Мы создали страницы на Facebook,
изменив характерные черты,

00:07:03.221 --> 00:07:06.072
и начали рассылать резюме
в компании США,

00:07:06.072 --> 00:07:07.980
и мы следили, наблюдали,

00:07:07.980 --> 00:07:10.373
будут ли они искать наших кандидатов,

00:07:10.373 --> 00:07:12.205
и воспользуются ли они информацией

00:07:12.205 --> 00:07:14.143
найденной в соцсетях.
И они делали это.

00:07:14.143 --> 00:07:16.244
Через социальные сети
произошла дискриминация

00:07:16.244 --> 00:07:19.317
кандидатов с одинаковыми навыками.

00:07:19.317 --> 00:07:23.892
Маркетологи убеждают нас в том,

00:07:23.892 --> 00:07:26.161
что вся информация о нас всегда

00:07:26.161 --> 00:07:29.434
используется
только в наших интересах.

00:07:29.434 --> 00:07:33.149
Но задумаемся вновь.
Почему это всегда должно быть так?

00:07:33.149 --> 00:07:35.813
В фильме «Особое мнение»,
который вышел в прокат

00:07:35.813 --> 00:07:38.366
несколько лет назад,
была знаменитая сцена,

00:07:38.366 --> 00:07:40.942
в которой Том Круз
идёт по торговому центру

00:07:40.942 --> 00:07:44.718
и голографическая
персонализированная реклама

00:07:44.718 --> 00:07:46.553
возникает вокруг него.

00:07:46.553 --> 00:07:49.780
Действия фильма
происходят в 2054 году,

00:07:49.780 --> 00:07:51.422
спустя 40 лет,

00:07:51.422 --> 00:07:54.330
но как бы захватывающе
не выглядела та технология,

00:07:54.330 --> 00:07:56.976
она уже существенно недооценивает

00:07:56.976 --> 00:07:59.116
то количество информации,
которую организации

00:07:59.116 --> 00:08:01.599
могут собирать о нас,
и как они могут её использовать,

00:08:01.599 --> 00:08:04.997
чтобы влиять на нас способом,
который мы даже не замечаем.

00:08:04.997 --> 00:08:07.100
Как пример — ещё один эксперимент,

00:08:07.100 --> 00:08:09.373
который мы уже запустили,
но ещё не завершили.

00:08:09.373 --> 00:08:11.692
Представим, что организация
имеет доступ

00:08:11.692 --> 00:08:13.748
к списку ваших друзей на Facebook,

00:08:13.748 --> 00:08:15.520
и, через особого рода алгоритм,

00:08:15.520 --> 00:08:19.254
они могут выделить двух друзей,
наиболее вам симпатичных.

00:08:19.254 --> 00:08:21.534
И потом они создают
в реальном времени,

00:08:21.534 --> 00:08:24.376
фоторобот из лиц этих двух друзей.

00:08:24.376 --> 00:08:27.445
Исследования, проведённые до нас,
показали, что люди уже

00:08:27.445 --> 00:08:30.330
не узнают даже самих себя

00:08:30.330 --> 00:08:32.792
по фотороботу, но они реагируют

00:08:32.792 --> 00:08:34.909
на такие составные
изображения позитивно.

00:08:34.909 --> 00:08:38.324
В следующий раз, когда вы
будете искать определённый товар,

00:08:38.324 --> 00:08:40.883
появится объявление
с предложением купить его,

00:08:40.883 --> 00:08:43.790
и это будет не просто
персонаж рекламы.

00:08:43.790 --> 00:08:46.103
Это будет один из ваших друзей,

00:08:46.103 --> 00:08:49.406
а вы даже не узнаете,
что это случилось.

00:08:49.406 --> 00:08:51.819
Проблема сейчас в том,

00:08:51.819 --> 00:08:54.338
что существующие правила,
которыми мы располагаем

00:08:54.338 --> 00:08:57.776
для защиты себя от злоупотреблений
личными данными,

00:08:57.776 --> 00:09:00.760
напоминают то, когда
для перестрелки приносят нож.

00:09:00.760 --> 00:09:03.673
Один из таких механизмов —
это прозрачность,

00:09:03.673 --> 00:09:06.873
объяснение людям того,
что собираются делать с их данными.

00:09:06.873 --> 00:09:08.979
И в принципе, это очень хорошая вещь.

00:09:08.979 --> 00:09:12.646
Это необходимо, но не достаточно.

00:09:12.646 --> 00:09:16.344
Прозрачность может быть притворной.

00:09:16.344 --> 00:09:18.448
Вы можете рассказывать людям,
что вы собираетесь делать,

00:09:18.448 --> 00:09:20.680
а после всё равно вынудить их раскрыть

00:09:20.680 --> 00:09:23.303
какое-то количество
их персональных данных

00:09:23.303 --> 00:09:26.189
Так в ещё одном эксперименте
с участием студентов

00:09:26.189 --> 00:09:29.247
мы просили их предоставить информацию

00:09:29.247 --> 00:09:31.060
о их поведении в учебном заведении,

00:09:31.060 --> 00:09:34.000
включая довольно деликатные вопросы,
такие как:

00:09:34.000 --> 00:09:34.621
[Вы когда-нибудь
списывали на экзаменах?]

00:09:34.621 --> 00:09:36.921
Одной группе испытуемых было сказано:

00:09:36.921 --> 00:09:39.762
«Только остальные студенты
будут видеть ваши ответы».

00:09:39.762 --> 00:09:41.341
Другой группе студентов мы сказали:

00:09:41.341 --> 00:09:44.902
«Студенты и преподаватели
будут видеть ваши ответы».

00:09:44.902 --> 00:09:47.493
Прозрачность. Уведомление.
И, конечно, это сработало,

00:09:47.493 --> 00:09:48.900
в том смысле,
что первая группа студентов

00:09:48.900 --> 00:09:51.468
гораздо более охотно
признавалась, чем вторая.

00:09:51.468 --> 00:09:52.988
Это логично, верно?

00:09:52.988 --> 00:09:54.478
А потом мы добавили уловку.

00:09:54.478 --> 00:09:57.238
Мы повторили эксперимент
с теми же двумя группами,

00:09:57.238 --> 00:09:59.665
добавив в этот раз задержку

00:09:59.665 --> 00:10:02.600
между тем моментом,
когда мы сказали ребятам,

00:10:02.600 --> 00:10:04.680
как мы будем использовать их данные,

00:10:04.680 --> 00:10:09.068
и моментом времени, когда они начали
действительно отвечать на вопросы.

00:10:09.068 --> 00:10:11.629
Как вы думаете, насколько
продолжительную задержку мы добавили,

00:10:11.629 --> 00:10:16.242
чтобы свести на нет тормозящее действие

00:10:16.242 --> 00:10:19.653
того факта, что преподаватели
будут видеть их ответы?

00:10:19.653 --> 00:10:21.433
10 минут?

00:10:21.433 --> 00:10:23.224
5 минут?

00:10:23.224 --> 00:10:25.000
Одна минута?

00:10:25.000 --> 00:10:27.049
Как насчёт 15 секунд?

00:10:27.049 --> 00:10:29.717
Пятнадцать секунд
было достаточно для того,

00:10:29.717 --> 00:10:31.285
чтобы две группы раскрыли
одинаковое количество информации,

00:10:31.285 --> 00:10:34.031
и вторая группа больше
не беспокоилась о том,

00:10:34.031 --> 00:10:36.687
что преподаватели читают их ответы.

00:10:36.687 --> 00:10:40.023
Сейчас я могу допустить,
что этот разговор до сих пор

00:10:40.023 --> 00:10:42.503
может показаться излишне мрачным,

00:10:42.503 --> 00:10:44.224
но я не это хочу сказать.

00:10:44.224 --> 00:10:46.923
В действительности, я хочу
поделиться с вами тем фактом,

00:10:46.923 --> 00:10:48.695
что альтернативы существуют.

00:10:48.695 --> 00:10:51.194
То, как мы ведём дела сейчас —
не единственный путь

00:10:51.194 --> 00:10:54.231
и совершенно точно не самый лучший

00:10:54.231 --> 00:10:56.258
из возможных.

00:10:56.258 --> 00:11:00.429
Когда кто-либо говорит вам: «Люди
не заботятся о тайне частной жизни», —

00:11:00.429 --> 00:11:03.071
примите во внимание,
что игра разработана

00:11:03.071 --> 00:11:05.795
и инсценирована так, что они не могут
заботиться о тайне частной жизни;

00:11:05.795 --> 00:11:09.057
и приходя к осознанию того,
что эти манипуляции происходят,

00:11:09.057 --> 00:11:10.664
вы уже на полпути к тому,

00:11:10.664 --> 00:11:12.922
чтобы суметь защитить себя самим.

00:11:12.922 --> 00:11:16.632
Когда кто-то говорит вам,
что тайна частной жизни несовместима

00:11:16.632 --> 00:11:18.481
с преимуществами «больших данных»,

00:11:18.481 --> 00:11:20.954
примите во внимание,
что за последние 20 лет,

00:11:20.954 --> 00:11:22.871
исследователи создали технологии,

00:11:22.871 --> 00:11:26.189
позволяющие практически
любую электронную покупку

00:11:26.189 --> 00:11:29.938
производить более безопасным образом.

00:11:29.938 --> 00:11:32.493
Мы можем анонимно
искать информацию в интернете.

00:11:32.493 --> 00:11:35.171
Мы можем посылать электронные письма,
которые могут быть прочитаны

00:11:35.171 --> 00:11:38.880
только получателем, а не Управлением
национальной безопасности.

00:11:38.880 --> 00:11:41.877
Можно даже вести интеллектуальный анализ
данных сохраняя конфиденциальность.

00:11:41.877 --> 00:11:45.771
Другими словами, мы можем пользоваться
преимуществом «больших данных»

00:11:45.771 --> 00:11:47.903
сохраняя конфиденциальность
частной жизни.

00:11:47.903 --> 00:11:51.694
Конечно, эти технологии
подразумевают перераспределение

00:11:51.694 --> 00:11:53.240
стоимости и доходов

00:11:53.240 --> 00:11:55.347
между владельцами и субъектами данных,

00:11:55.347 --> 00:11:58.800
именно поэтому, возможно,
вы мало знаете о них.

00:11:58.800 --> 00:12:02.506
Это возвращает меня к саду Эдема.

00:12:02.506 --> 00:12:05.286
Существует второе
толкование частной жизни

00:12:05.286 --> 00:12:07.095
в истории Эдемского сада,

00:12:07.095 --> 00:12:09.191
которая не имеет отношения
к вопросу о том,

00:12:09.191 --> 00:12:11.416
как Адам и Ева ощутили себя голыми

00:12:11.416 --> 00:12:13.797
и испытали стыд за это.

00:12:13.797 --> 00:12:16.578
Вы можете найти отголоски этой трактовки

00:12:16.578 --> 00:12:19.360
в книге Джона Милтона «Потерянный рай».

00:12:19.360 --> 00:12:23.557
В этом саду Адам и Ева
удовлетворены материально.

00:12:23.557 --> 00:12:25.661
Они счастливы. Они довольны.

00:12:25.661 --> 00:12:27.954
Однако, им также не хватает знаний

00:12:27.954 --> 00:12:29.594
и самосознания.

00:12:29.594 --> 00:12:32.913
Момент, когда они вкусили яблоко, —
называемое, кстати,

00:12:32.913 --> 00:12:34.206
плодом познания, —

00:12:34.206 --> 00:12:36.811
это момент, когда они
открывают сами себя.

00:12:36.811 --> 00:12:40.842
Они начинают осознавать.
Они получают независимость.

00:12:40.842 --> 00:12:43.968
Однако приходится платить
уходом из сада.

00:12:43.968 --> 00:12:47.849
Так и тайна частной жизни,
в некотором роде и возможность

00:12:47.849 --> 00:12:50.811
и цена, которую нужно
платить за свободу.

00:12:50.811 --> 00:12:53.581
И вновь маркетологи говорят нам,

00:12:53.581 --> 00:12:56.600
что «большие данные»
и социальные сети —

00:12:56.600 --> 00:12:59.579
это не только их райская прибыль,

00:12:59.579 --> 00:13:02.036
но и Эдемский сад для всех остальных.

00:13:02.036 --> 00:13:03.274
Мы получаем бесплатный контент.

00:13:03.274 --> 00:13:06.397
Мы получаем игру в Angry Birds.
Мы получаем целевые приложения.

00:13:06.397 --> 00:13:09.294
Но через несколько лет организации

00:13:09.294 --> 00:13:10.903
будут знать о нас так много,

00:13:10.903 --> 00:13:13.613
что они будут в состоянии
делать выводы о наших желаниях

00:13:13.613 --> 00:13:15.817
ещё до того, как мы
их сформировали и, возможно,

00:13:15.817 --> 00:13:18.264
покупать продукты от нашего имени

00:13:18.264 --> 00:13:20.538
ещё до того, как мы узнаем,
что нуждаемся в них.

00:13:20.538 --> 00:13:23.775
Был один английский писатель,

00:13:23.775 --> 00:13:26.820
который предвидел такое будущее,

00:13:26.820 --> 00:13:28.225
где мы будем разменивать

00:13:28.225 --> 00:13:31.773
нашу независимость и свободу на комфорт.

00:13:31.773 --> 00:13:33.934
В большей мере, чем Джордж Оруэлл,

00:13:33.934 --> 00:13:36.695
таким автором был,
конечно, Олдос Хаксли.

00:13:36.695 --> 00:13:39.549
В своём романе «О дивный новый мир»
он придумал мир,

00:13:39.549 --> 00:13:41.720
в котором технологии, созданные нами

00:13:41.720 --> 00:13:43.579
первоначально для свободы,

00:13:43.579 --> 00:13:46.146
в конечном итоге поработили нас.

00:13:46.146 --> 00:13:50.937
Однако в своей книге,
он также предлагает и выход

00:13:50.937 --> 00:13:54.375
для того общества, схожий с путём,

00:13:54.375 --> 00:13:58.330
которым последовали
Адам и Ева покинув сад.

00:13:58.330 --> 00:14:00.477
Словами Дикаря [Джона],

00:14:00.477 --> 00:14:03.546
вернуть независимость
и свободу возможно,

00:14:03.546 --> 00:14:06.225
хотя и цена этого непомерно высока.

00:14:06.225 --> 00:14:11.940
Я действительно верю,
что одной из предстоящих битв

00:14:11.940 --> 00:14:14.503
нашего времени станет битва

00:14:14.503 --> 00:14:16.890
за контроль над персональными данными,

00:14:16.890 --> 00:14:20.397
битва за то, станут ли «большие данные»

00:14:20.397 --> 00:14:21.686
силами свободы,

00:14:21.686 --> 00:14:26.432
или же силами, которые будут
скрыто нами манипулировать.

00:14:26.432 --> 00:14:29.025
Прямо сейчас многие из нас

00:14:29.025 --> 00:14:31.778
даже не подозревают,
что эта битва уже идёт,

00:14:31.778 --> 00:14:34.450
и это так,
нравится ли вам это или нет.

00:14:34.450 --> 00:14:37.254
И, рискуя показаться змеем,

00:14:37.254 --> 00:14:40.151
я скажу вам, что средства
для этой битвы здесь,

00:14:40.151 --> 00:14:43.160
в понимании того, что происходит,

00:14:43.160 --> 00:14:44.515
и [это средство] в ваших руках,

00:14:44.515 --> 00:14:48.255
всего лишь в нескольких кликах.

00:14:48.255 --> 00:14:49.737
Спасибо!

00:14:49.737 --> 00:14:54.214
(Аплодисменты)

