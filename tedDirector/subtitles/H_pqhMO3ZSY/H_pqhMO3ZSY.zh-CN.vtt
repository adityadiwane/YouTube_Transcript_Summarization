WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:07.000
翻译人员: xuan wang
校对人员: Jing Peng

00:00:12.641 --> 00:00:14.995
我想跟大家分享一个

00:00:14.995 --> 00:00:18.171
将亚当和夏娃的

00:00:18.171 --> 00:00:20.940
臭名昭著的隐私事件

00:00:20.940 --> 00:00:24.386
和过去十年发生的

00:00:24.386 --> 00:00:27.072
公共和隐私领域里的显著变迁

00:00:27.072 --> 00:00:28.842
相结合的故事。

00:00:28.842 --> 00:00:30.140
大家都知道这个事件吧。

00:00:30.140 --> 00:00:33.470
在伊甸园里有一天亚当和夏娃

00:00:33.470 --> 00:00:35.313
意识到了他们是赤裸的。

00:00:35.313 --> 00:00:36.813
他们吓坏了。

00:00:36.813 --> 00:00:39.570
然后剩下的就是历史了。

00:00:39.570 --> 00:00:41.758
换作现在的话，亚当和夏娃

00:00:41.758 --> 00:00:44.119
可能会有不同的举动。

00:00:44.119 --> 00:00:46.387
（推特）［＠亚当，昨天太销魂了！我好爱那个苹果啊。］

00:00:46.387 --> 00:00:48.260
［＠夏娃，是啊，宝贝儿，知道我裤子变成什么样了吗？］

00:00:48.260 --> 00:00:50.896
我们确实比以往任何时候都开放,

00:00:50.896 --> 00:00:54.230
把大量关于自己的信息放在网上传播。

00:00:54.230 --> 00:00:55.934
而且这么多有关我们的信息

00:00:55.934 --> 00:00:58.158
正在被各种机构收集起来。

00:00:58.158 --> 00:01:01.440
当今,通过对这些大量

00:01:01.440 --> 00:01:03.886
个人信息的研究,

00:01:03.886 --> 00:01:05.832
我们从中受益非浅;

00:01:05.832 --> 00:01:08.470
但是在放弃我们的隐私的同时

00:01:08.470 --> 00:01:11.568
也要付出很多的代价。

00:01:11.568 --> 00:01:15.591
而我的故事就是关于这些代价的。

00:01:15.591 --> 00:01:18.175
让我们首先看看一个我认为

00:01:18.175 --> 00:01:21.502
在过去几年已经变得越来越清晰的现象,

00:01:21.502 --> 00:01:23.599
那就是任何个人信息

00:01:23.599 --> 00:01:25.884
都可能变成敏感信息。

00:01:25.884 --> 00:01:30.009
在2000年的时候，全球大约拍摄了1000亿

00:01:30.009 --> 00:01:31.921
的照片，

00:01:31.921 --> 00:01:34.986
但是只有非常微不足道的一部分

00:01:34.986 --> 00:01:36.869
被放在了网上。

00:01:36.869 --> 00:01:40.230
到了2010年，仅仅在脸书上，一个月

00:01:40.230 --> 00:01:43.500
就上传了25亿张照片，

00:01:43.500 --> 00:01:45.382
大部分都是可确认的。

00:01:45.382 --> 00:01:47.262
同时，

00:01:47.262 --> 00:01:52.132
计算机在照片中识别面孔的能力

00:01:52.132 --> 00:01:55.740
提高了三个数量级。

00:01:55.740 --> 00:01:57.622
当你把这些技术结合起来后

00:01:57.622 --> 00:01:59.123
会发生什么呢？

00:01:59.123 --> 00:02:01.781
不断增加的脸部信息可用性;

00:02:01.781 --> 00:02:05.429
不断增强的计算机面部识别能力；

00:02:05.429 --> 00:02:07.611
同时还有云计算，

00:02:07.611 --> 00:02:09.499
让在座的任何人

00:02:09.499 --> 00:02:11.059
都拥有了

00:02:11.059 --> 00:02:12.945
几年前只有情报机构才有的

00:02:12.945 --> 00:02:14.727
计算能力；

00:02:14.727 --> 00:02:16.105
同时还有普适计算，

00:02:16.105 --> 00:02:18.997
让我的手机，

00:02:18.997 --> 00:02:20.668
和互联网相连接

00:02:20.668 --> 00:02:23.002
然后可以在几秒内进行

00:02:23.002 --> 00:02:25.641
成百上千的面部数据测算。

00:02:25.641 --> 00:02:28.269
我们预测

00:02:28.269 --> 00:02:30.333
这些技术的结合体

00:02:30.333 --> 00:02:33.221
会对我们所谓的隐私和匿名

00:02:33.221 --> 00:02:35.478
产生非常巨大的影响。

00:02:35.478 --> 00:02:37.471
为了证明这个想法，我们在

00:02:37.471 --> 00:02:39.592
卡内基·梅隆大学校园里做了一个测试。

00:02:39.592 --> 00:02:41.691
我们让过路的学生们

00:02:41.691 --> 00:02:43.470
参与一项研究，

00:02:43.470 --> 00:02:46.032
我们用摄像头给他们照了相，

00:02:46.032 --> 00:02:48.814
然后我们让他们在电脑上填写一张调查问卷。

00:02:48.814 --> 00:02:50.793
在此同时,

00:02:50.793 --> 00:02:53.590
我们把他们的照片上传到一个云计算节点上，

00:02:53.590 --> 00:02:55.317
然后我们开始用一个面部识别程序来

00:02:55.317 --> 00:02:57.722
把那张照片和一个有

00:02:57.722 --> 00:03:00.115
成百上千张照片的数据库相比较对照

00:03:00.115 --> 00:03:03.711
这些照片都是我们从脸书上下载下来的。

00:03:03.711 --> 00:03:06.970
当被研究对象做到问卷的最后一页时,

00:03:06.970 --> 00:03:10.317
那页已经自动显示我们找到的

00:03:10.317 --> 00:03:12.630
10张由识别程序找到的

00:03:12.630 --> 00:03:14.915
最相似的图片，

00:03:14.915 --> 00:03:16.653
然后我们让被研究对象确认

00:03:16.653 --> 00:03:20.773
那些照片到底是不是自己。

00:03:20.773 --> 00:03:24.472
大家看到被研究对象了吗？

00:03:24.472 --> 00:03:27.317
电脑做到了，实际上它的准确率是

00:03:27.317 --> 00:03:29.466
三分之一。

00:03:29.466 --> 00:03:32.650
基本上，我们可以从一张匿名的面孔开始，

00:03:32.650 --> 00:03:36.134
线下或线上，然后我们可以用脸部识别技术

00:03:36.134 --> 00:03:38.494
找到那个人。

00:03:38.494 --> 00:03:40.602
这多亏了社交媒体的数据。

00:03:40.602 --> 00:03:42.474
但是几年前，我们做了些其他事情。

00:03:42.474 --> 00:03:44.297
我们从社交媒体数据出发，

00:03:44.297 --> 00:03:47.348
然后我们把它和美国政府的

00:03:47.348 --> 00:03:49.450
社会安全机构里的数据相对照，

00:03:49.450 --> 00:03:52.774
我们最终可以预测一个人的社会保险号码，

00:03:52.774 --> 00:03:54.286
这个号码在美国

00:03:54.286 --> 00:03:56.326
是极其敏感的信息。

00:03:56.326 --> 00:03:58.419
大家明白我的意思了吗？

00:03:58.419 --> 00:04:01.341
如果你把这两个研究相结合，

00:04:01.341 --> 00:04:02.853
问题就来了，

00:04:02.853 --> 00:04:05.573
你可不可以从一张面孔出发，

00:04:05.573 --> 00:04:07.884
然后通过面部识别找到这个人

00:04:07.884 --> 00:04:10.553
和有关此人的

00:04:10.553 --> 00:04:12.485
各种公共信息，

00:04:12.485 --> 00:04:14.733
从这些公共信息里，

00:04:14.733 --> 00:04:16.775
可以推断出未公开的信息，

00:04:16.775 --> 00:04:18.381
即那些关于此人

00:04:18.381 --> 00:04:19.873
更敏感的信息呢？

00:04:19.873 --> 00:04:21.789
答案是，可以的，我们也做到了。

00:04:21.789 --> 00:04:24.357
当然，准确率也变糟了。

00:04:24.357 --> 00:04:25.301
［27％的调查对象的社会保障号头5个数字
可以通过4次尝试得到］

00:04:25.301 --> 00:04:29.128
但实际上，我们甚至决定开发一个苹果应用,

00:04:29.128 --> 00:04:31.843
这个应用使用手机内置的相机给

00:04:31.843 --> 00:04:33.443
研究对象拍照

00:04:33.443 --> 00:04:34.930
然后把照片上传到云端

00:04:34.930 --> 00:04:37.592
然后实时地进行我刚才描述的计算：

00:04:37.592 --> 00:04:39.680
寻找匹配，公共信息，

00:04:39.680 --> 00:04:41.410
尝试推测敏感信息，

00:04:41.410 --> 00:04:44.001
然后把这些信息传送回手机

00:04:44.001 --> 00:04:47.610
然后把这些信息列到研究对象的图像旁边,

00:04:47.610 --> 00:04:49.511
这是个夸张现实的例子，

00:04:49.511 --> 00:04:51.962
大概也是一个令人毛骨悚然的现实。

00:04:51.962 --> 00:04:55.301
实际上，我们没有开发这个应用，

00:04:55.301 --> 00:04:57.223
这只是一个概念验证。

00:04:57.223 --> 00:04:59.536
事实是，让我们把这些技术推进到

00:04:59.536 --> 00:05:01.373
逻辑的极限。

00:05:01.373 --> 00:05:04.092
设想一下未来你周围的陌生人

00:05:04.092 --> 00:05:06.403
可以通过他们的谷歌眼镜

00:05:06.403 --> 00:05:08.710
或者，他们的隐形眼镜，

00:05:08.710 --> 00:05:12.730
并通过你身上的7、8个数据点

00:05:12.730 --> 00:05:15.312
就可以推测出

00:05:15.312 --> 00:05:17.915
任何与你有关的信息。

00:05:17.915 --> 00:05:22.709
这个没有任何秘密的未来会是怎样的？

00:05:22.709 --> 00:05:24.673
而我们该不该关心这个问题？

00:05:24.673 --> 00:05:26.564
我们可能会倾向于相信

00:05:26.564 --> 00:05:29.604
这个有这么丰富的数据的未来

00:05:29.604 --> 00:05:32.118
会是一个不再有偏见的未来,

00:05:32.118 --> 00:05:35.701
但实际上，拥有这么多的信息

00:05:35.701 --> 00:05:37.892
并不意味着我们就会做出

00:05:37.892 --> 00:05:39.598
更理性的选择。

00:05:39.598 --> 00:05:42.158
在另一个试验里，我们给研究对象

00:05:42.158 --> 00:05:44.404
关于一个工作应征者的信息。

00:05:44.404 --> 00:05:47.582
上传信息里同时也包括了一些

00:05:47.582 --> 00:05:50.228
有趣并且绝对合法，

00:05:50.228 --> 00:05:52.693
但毕竟有些

00:05:52.693 --> 00:05:54.713
尴尬的内容。

00:05:54.713 --> 00:05:57.079
有趣的是，

00:05:57.079 --> 00:06:00.162
一部分研究对象发布了类似的信息，

00:06:00.162 --> 00:06:02.524
有些没有。

00:06:02.524 --> 00:06:04.473
大家认为哪个组

00:06:04.473 --> 00:06:09.025
会更有可能质疑他人呢？

00:06:09.025 --> 00:06:10.982
自相矛盾的是，

00:06:10.982 --> 00:06:12.715
那是发布了类似信息的组，

00:06:12.715 --> 00:06:15.657
这就是一个与个人道德相悖的例子。

00:06:15.657 --> 00:06:17.407
大家可能现在会想，

00:06:17.407 --> 00:06:19.109
这跟我无关，

00:06:19.109 --> 00:06:21.271
因为我没有什么可隐藏的。

00:06:21.271 --> 00:06:23.753
但实际上，隐私不是说

00:06:23.753 --> 00:06:27.429
你有什么坏事情要隐藏。

00:06:27.429 --> 00:06:29.783
想象一下你是某机构人事部的主管，

00:06:29.783 --> 00:06:32.730
你收到一些简历，

00:06:32.730 --> 00:06:35.203
然后你决定寻找更多的关于这些应征者的信息。

00:06:35.203 --> 00:06:37.663
然后，你就在谷歌上搜他们的名字

00:06:37.663 --> 00:06:39.903
在某种情形下，

00:06:39.903 --> 00:06:41.911
你找到这个信息。

00:06:41.911 --> 00:06:46.348
或者在一个平行的空间里，你找到了这个信息。

00:06:46.348 --> 00:06:49.065
你认为你会公平的

00:06:49.065 --> 00:06:51.868
给任何一个应征者面试的机会吗？

00:06:51.868 --> 00:06:54.150
如果你是这样想的话，

00:06:54.150 --> 00:06:56.732
那么你与美国的老板们不同,

00:06:56.732 --> 00:07:00.039
实际上，我们就是用了这些老板做的这个试验。

00:07:00.039 --> 00:07:03.221
我们建立了一些脸书帐号，编制了一些信息，

00:07:03.221 --> 00:07:06.072
然后我们开始给他们发简历，

00:07:06.072 --> 00:07:07.980
此后我们监控着,

00:07:07.980 --> 00:07:10.373
到底这些公司会不会搜索我们的应征者，

00:07:10.373 --> 00:07:12.205
他们有没有对他们在社交网络上找到的信息

00:07:12.205 --> 00:07:14.143
有所举动。实际上他们确实这样做了。

00:07:14.143 --> 00:07:16.244
对同等条件的应征者的歧视

00:07:16.244 --> 00:07:19.317
是正从社交网络收集的信息开始的。

00:07:19.317 --> 00:07:23.892
现在营销人员希望我们相信

00:07:23.892 --> 00:07:26.161
关于我们的所有信息

00:07:26.161 --> 00:07:29.434
永远都会以我们喜欢的方式被使用。

00:07:29.434 --> 00:07:33.149
但是想想看,凭什么总会是这样？

00:07:33.149 --> 00:07:35.813
在几年前出品的一部电影里，

00:07:35.813 --> 00:07:38.366
“少数派报告”，一个著名的镜头里

00:07:38.366 --> 00:07:40.942
是汤姆·克鲁斯在一个大厦里走着

00:07:40.942 --> 00:07:44.718
然后全息个性化的广告

00:07:44.718 --> 00:07:46.553
出现在他周围。

00:07:46.553 --> 00:07:49.780
那部电影的背景年代是2054年，

00:07:49.780 --> 00:07:51.422
大约离现在还有40年，

00:07:51.422 --> 00:07:54.330
就像那个技术显示的一样让人兴奋，

00:07:54.330 --> 00:07:56.976
它已经大大低估了

00:07:56.976 --> 00:07:59.116
各种机构可以搜集到的

00:07:59.116 --> 00:08:01.599
关于你自己的信息，以及他们如何能利用这些信息

00:08:01.599 --> 00:08:04.997
以一种你自己都无法预测到的方式来影响你。

00:08:04.997 --> 00:08:07.100
举个例子，这是另一个

00:08:07.100 --> 00:08:09.373
我们正在做的未完成的试验。

00:08:09.373 --> 00:08:11.692
想象一下某个机构有

00:08:11.692 --> 00:08:13.748
你的脸书朋友信息，

00:08:13.748 --> 00:08:15.520
通过某种算法

00:08:15.520 --> 00:08:19.254
他们可以找到两个你最喜欢的朋友。

00:08:19.254 --> 00:08:21.534
然后，他们的即时创建出

00:08:21.534 --> 00:08:24.376
这两个朋友的脸部信息结合体。

00:08:24.376 --> 00:08:27.445
在我们之前的研究显示

00:08:27.445 --> 00:08:30.330
人们在合成的脸部图片中

00:08:30.330 --> 00:08:32.792
甚至不会识别出自己，

00:08:32.792 --> 00:08:34.909
但是他们却对这些合成图片有好感。

00:08:34.909 --> 00:08:38.324
那么下次你在浏览某个产品的时候，

00:08:38.324 --> 00:08:40.883
同时有个广告建议你买它，

00:08:40.883 --> 00:08:43.790
这就不会是一个标准的推销员,

00:08:43.790 --> 00:08:46.103
却会变成你的朋友，

00:08:46.103 --> 00:08:49.406
而且你都不会意识到正在发生着什么。

00:08:49.406 --> 00:08:51.819
现在的问题是

00:08:51.819 --> 00:08:54.338
我们当下的保护个人信息

00:08:54.338 --> 00:08:57.776
不被滥用的政策法规

00:08:57.776 --> 00:09:00.760
还十分薄弱。

00:09:00.760 --> 00:09:03.673
其中的一个法规是透明性，

00:09:03.673 --> 00:09:06.873
要告诉人们你将怎样使用这些数据。

00:09:06.873 --> 00:09:08.979
理论上，这是非常好的事情。

00:09:08.979 --> 00:09:12.646
这是必要的，但是却不完善。

00:09:12.646 --> 00:09:16.344
透明性也会被误导。

00:09:16.344 --> 00:09:18.448
你会告诉人们你要做什么，

00:09:18.448 --> 00:09:20.680
然后你仍然试图诱导他们

00:09:20.680 --> 00:09:23.303
给你任意数量的个人信息。

00:09:23.303 --> 00:09:26.189
那么在另一个实验里，这次我们让

00:09:26.189 --> 00:09:29.247
学生们给我们他们的

00:09:29.247 --> 00:09:31.060
学校表现信息

00:09:31.060 --> 00:09:34.000
这包括一些非常敏感的信息，比如这个。

00:09:34.000 --> 00:09:34.621
［你有没有在考试中做过弊？］

00:09:34.621 --> 00:09:36.921
对其中一个组，我们告诉他们，

00:09:36.921 --> 00:09:39.762
“只有其他的学生会看到你的答案。”

00:09:39.762 --> 00:09:41.341
而对另一组学生，我们说，

00:09:41.341 --> 00:09:44.902
“学生和系里会看到你们的答案。”

00:09:44.902 --> 00:09:47.493
透明度。预先声明。当然，这个奏效了，

00:09:47.493 --> 00:09:48.900
第一组学生

00:09:48.900 --> 00:09:51.468
比第二组更愿意说出实情。

00:09:51.468 --> 00:09:52.988
很合理吧，不是吗？

00:09:52.988 --> 00:09:54.478
但是我们加了下面的误导。

00:09:54.478 --> 00:09:57.238
我们在两组中重复做了这个实验，

00:09:57.238 --> 00:09:59.665
这次我们

00:09:59.665 --> 00:10:02.600
在告诉他们我们如何

00:10:02.600 --> 00:10:04.680
使用这些数据

00:10:04.680 --> 00:10:09.068
和让他们实际开始回答问题之间增加了一点延迟。

00:10:09.068 --> 00:10:11.629
大家认为这个延迟需要多久

00:10:11.629 --> 00:10:16.242
能让我们抵消掉之前的“系里也会看你们的答案”

00:10:16.242 --> 00:10:19.653
带来的抑制作用？

00:10:19.653 --> 00:10:21.433
十分钟？

00:10:21.433 --> 00:10:23.224
五分钟？

00:10:23.224 --> 00:10:25.000
一分钟？

00:10:25.000 --> 00:10:27.049
15秒怎么样？

00:10:27.049 --> 00:10:29.717
只要15秒就会让两组

00:10:29.717 --> 00:10:31.285
提供同样数量的数据，

00:10:31.285 --> 00:10:34.031
就好像第二组不再关心

00:10:34.031 --> 00:10:36.687
系里会不会看他们的答案一样。

00:10:36.687 --> 00:10:40.023
到此为止，我得承认这个演讲

00:10:40.023 --> 00:10:42.503
可能显得非常的郁闷,

00:10:42.503 --> 00:10:44.224
但是这不是我的重点。

00:10:44.224 --> 00:10:46.923
实际上，我想分享的是我们还是有

00:10:46.923 --> 00:10:48.695
其他办法的。

00:10:48.695 --> 00:10:51.194
我们现在的处理方式不是唯一的，

00:10:51.194 --> 00:10:54.231
也绝对不是最好的。

00:10:54.231 --> 00:10:56.258
也绝对不是最好的。

00:10:56.258 --> 00:11:00.429
当有人对你说，“大家不用关心隐私，”

00:11:00.429 --> 00:11:03.071
想想是不是因为事情已经被扭曲到

00:11:03.071 --> 00:11:05.795
他们不能再关心个人隐私了，

00:11:05.795 --> 00:11:09.057
然后我们才意识到一切已被人操纵,

00:11:09.057 --> 00:11:10.664
已经逐渐侵入到

00:11:10.664 --> 00:11:12.922
自我保护的整个过程中。

00:11:12.922 --> 00:11:16.632
当有人说隐私和大量信息带来的好处

00:11:16.632 --> 00:11:18.481
无法兼得时，

00:11:18.481 --> 00:11:20.954
想想过去的20年里，

00:11:20.954 --> 00:11:22.871
研究人员已经发明了

00:11:22.871 --> 00:11:26.189
理论上使任何电子转帐

00:11:26.189 --> 00:11:29.938
更加安全保密的方式来进行的技术。

00:11:29.938 --> 00:11:32.493
我们可以匿名的浏览网页。

00:11:32.493 --> 00:11:35.171
我们可以发送连美国国家安全局都不可以

00:11:35.171 --> 00:11:38.880
读取的个人电子邮件，

00:11:38.880 --> 00:11:41.877
我们甚至可以有保护隐私的数据挖掘。

00:11:41.877 --> 00:11:45.771
换句话说，我们可以在得到大量数据的同时

00:11:45.771 --> 00:11:47.903
仍能保护个人隐私。

00:11:47.903 --> 00:11:51.694
当然，这些技术的应用意味着

00:11:51.694 --> 00:11:53.240
在数据拥有者们和

00:11:53.240 --> 00:11:55.347
数据对象们之间将有花费和收入的变化，

00:11:55.347 --> 00:11:58.800
也许这可能就是我们为什么没怎么听说过这些技术的原因。

00:11:58.800 --> 00:12:02.506
让我再回到伊甸园。

00:12:02.506 --> 00:12:05.286
关于伊甸园的故事

00:12:05.286 --> 00:12:07.095
还有第二个关于隐私的解释

00:12:07.095 --> 00:12:09.191
这跟亚当和夏娃

00:12:09.191 --> 00:12:11.416
的赤裸和羞耻

00:12:11.416 --> 00:12:13.797
没有任何关系。

00:12:13.797 --> 00:12:16.578
大家可以在

00:12:16.578 --> 00:12:19.360
约翰·弥尔顿的“失乐园”里看到类似的解释。

00:12:19.360 --> 00:12:23.557
在伊甸园里，亚当和夏娃是物质上的满足。

00:12:23.557 --> 00:12:25.661
他们很开心，也很满足。

00:12:25.661 --> 00:12:27.954
但是，他们没有知识

00:12:27.954 --> 00:12:29.594
和自觉性。

00:12:29.594 --> 00:12:32.913
当他们吃到

00:12:32.913 --> 00:12:34.206
智慧之果时，

00:12:34.206 --> 00:12:36.811
其实是他们发现自我的时刻。

00:12:36.811 --> 00:12:40.842
他们变得自觉，实现了自主。

00:12:40.842 --> 00:12:43.968
但是代价却是，离开伊甸园。

00:12:43.968 --> 00:12:47.849
那么，隐私，换句话说，就是

00:12:47.849 --> 00:12:50.811
为了得到自由必须付出的代价。

00:12:50.811 --> 00:12:53.581
再次，营销人员告诉我们

00:12:53.581 --> 00:12:56.600
大量数据和社交网络

00:12:56.600 --> 00:12:59.579
并不仅仅是为他们谋福利的天堂，

00:12:59.579 --> 00:13:02.036
同时也是我们所有人的伊甸园。

00:13:02.036 --> 00:13:03.274
我们得到免费的信息。

00:13:03.274 --> 00:13:06.397
我们可以玩愤怒的小鸟。我们得到适合自己的应用。

00:13:06.397 --> 00:13:09.294
但实际上，在几年内，各种机构

00:13:09.294 --> 00:13:10.903
就会因为知道这么多关于我们的信息，

00:13:10.903 --> 00:13:13.613
进而可以在我们知道自己想要做什么之前

00:13:13.613 --> 00:13:15.817
就可以诱导我们的想法，或许

00:13:15.817 --> 00:13:18.264
在我们知道自己是不是真的需要某个商品之前

00:13:18.264 --> 00:13:20.538
就以我们自己的名义把它买下来了。

00:13:20.538 --> 00:13:23.775
有一个英国作家

00:13:23.775 --> 00:13:26.820
预测到了这种未来

00:13:26.820 --> 00:13:28.225
就是我们会用自己的自主

00:13:28.225 --> 00:13:31.773
和自由来换来舒适安逸。

00:13:31.773 --> 00:13:33.934
甚至超过了乔治·奥威尔，

00:13:33.934 --> 00:13:36.695
这个作家当然是赫胥黎。

00:13:36.695 --> 00:13:39.549
在“美丽新世界”里，他想象了一个社会:

00:13:39.549 --> 00:13:41.720
人们发明了原本是为了得到

00:13:41.720 --> 00:13:43.579
自由的一种技术,

00:13:43.579 --> 00:13:46.146
最终反被此技术所奴役。

00:13:46.146 --> 00:13:50.937
然而，在这本书里，他同样给我们指出了一条

00:13:50.937 --> 00:13:54.375
突破这个社会的道路，

00:13:54.375 --> 00:13:58.330
跟亚当和夏娃不得不离开伊甸园的道路类似。

00:13:58.330 --> 00:14:00.477
用野人的话说，

00:14:00.477 --> 00:14:03.546
重获自主和自由是可能的，

00:14:03.546 --> 00:14:06.225
尽管代价惨重。

00:14:06.225 --> 00:14:11.940
因此我相信当今

00:14:11.940 --> 00:14:14.503
具有决定性的战役之一

00:14:14.503 --> 00:14:16.890
就是控制个人信息之战，

00:14:16.890 --> 00:14:20.397
决定大量数据是否会变成帮助获得自由

00:14:20.397 --> 00:14:21.686
的武器，

00:14:21.686 --> 00:14:26.432
还是暗中操纵我们的工具。

00:14:26.432 --> 00:14:29.025
现在，我们中的大多数

00:14:29.025 --> 00:14:31.778
甚至不知道战斗已经打响了，

00:14:31.778 --> 00:14:34.450
但这是真的，不管你喜欢不喜欢。

00:14:34.450 --> 00:14:37.254
冒着打草惊蛇的危险，

00:14:37.254 --> 00:14:40.151
我告诉大家战斗的武器就在这里，

00:14:40.151 --> 00:14:43.160
那就是意识到正在发生着什么，

00:14:43.160 --> 00:14:44.515
就在你手中，

00:14:44.515 --> 00:14:48.255
只需几次点击。

00:14:48.255 --> 00:14:49.737
谢谢大家。

00:14:49.737 --> 00:14:54.214
（掌声）

