WEBVTT
Kind: captions
Language: sr

00:00:00.000 --> 00:00:07.000
Prevodilac: Ivana Korom
Lektor: Mile Živković

00:00:12.641 --> 00:00:14.995
Želim da vam ispričam jednu priču

00:00:14.995 --> 00:00:18.171
koja povezuje čuveni incident
u vezi sa privatnošću,

00:00:18.171 --> 00:00:20.940
koji uključuje Adama i Evu,

00:00:20.940 --> 00:00:24.386
sa neverovatnim promenama u granicama

00:00:24.386 --> 00:00:26.583
između privatnog i javnog života

00:00:26.583 --> 00:00:28.842
koje su se desile u poslednjih 10 godina.

00:00:28.842 --> 00:00:30.140
Svi znate za taj incident.

00:00:30.140 --> 00:00:33.470
Adam i Eva, jednoga dana u Raju

00:00:33.470 --> 00:00:35.313
shvate da su nagi.

00:00:35.313 --> 00:00:36.813
Polude.

00:00:36.813 --> 00:00:39.570
A ostatak priče pripada istoriji.

00:00:39.570 --> 00:00:41.758
Danas bi Adam i Eva

00:00:41.758 --> 00:00:44.119
verovatno drugačije reagovali.

00:00:44.119 --> 00:00:46.657
[@Adam Sinoć je bila ludnica!
jabuka je super LOL]

00:00:46.657 --> 00:00:48.880
[@Eva Aha..
dušo, znaš li gde su mi pantalone?

00:00:48.880 --> 00:00:51.236
Mnogo više informacija o sebi

00:00:51.236 --> 00:00:54.230
otkrivamo na internetu,
nego ikad ranije,

00:00:54.230 --> 00:00:55.974
i sve više i više informacija o nama

00:00:55.974 --> 00:00:58.158
prikupljaju razne organizacije.

00:00:58.158 --> 00:01:01.440
Mnogo toga možemo da dobijemo

00:01:01.440 --> 00:01:03.886
od ove masivne analize ličnih podataka,

00:01:03.886 --> 00:01:05.832
ili "velikih podataka",

00:01:05.832 --> 00:01:08.470
ali odavanjem svoje privatnosti

00:01:08.470 --> 00:01:11.568
stupamo u kompleksnu razmenu.

00:01:11.568 --> 00:01:15.591
Priča koju vam pričam
je upravo o toj razmeni.

00:01:15.591 --> 00:01:18.175
Počinjemo sa opservacijom koja je,
po meni,

00:01:18.175 --> 00:01:21.502
postala sve jasnija u poslednjih
nekoliko godina,

00:01:21.502 --> 00:01:23.599
da bilo koja lična informacija

00:01:23.599 --> 00:01:25.884
lako može postati osetljiva informacija.

00:01:25.884 --> 00:01:30.009
2000. godine je slikano
oko 100 milijardi fotografija

00:01:30.009 --> 00:01:31.921
širom sveta,

00:01:31.921 --> 00:01:34.986
ali je samo mali deo njih

00:01:34.986 --> 00:01:36.869
postavljen na internet.

00:01:36.869 --> 00:01:40.230
2010, samo na Fejsbuk
tokom jednog meseca

00:01:40.230 --> 00:01:43.500
postavljeno je 2,5 milijarde fotografija,

00:01:43.500 --> 00:01:45.502
a većina njih je bila sa identifikacijom.

00:01:45.502 --> 00:01:47.262
U istom periodu,

00:01:47.262 --> 00:01:52.132
mogućnost kompjutera
da prepoznaje ljude na slikama

00:01:52.132 --> 00:01:55.740
se povećala tri puta.

00:01:55.740 --> 00:01:57.622
Šta se dešava kad kombinujemo

00:01:57.622 --> 00:01:59.123
ove tehnologije:

00:01:59.123 --> 00:02:01.781
uvećanu dostupnost facijalnih podataka,

00:02:01.781 --> 00:02:05.429
povećanu sposobnost kompjutera
da prepoznaju lica,

00:02:05.429 --> 00:02:07.611
ali i informacije u oblaku,

00:02:07.611 --> 00:02:09.499
što svakome u ovoj prostoriji

00:02:09.499 --> 00:02:11.059
daje moć računara

00:02:11.059 --> 00:02:13.245
koja je do pre nekoliko godina
bila svojstvena

00:02:13.245 --> 00:02:15.147
samo agencijama
sa troslovnim akronimom;

00:02:15.147 --> 00:02:16.815
i sveprisutno korišćenje računara,

00:02:16.815 --> 00:02:19.427
koje dozvoljava mom telefonu,
koji nije superkompjuter,

00:02:19.427 --> 00:02:20.668
da se poveže na internet

00:02:20.668 --> 00:02:23.002
i obavlja stotine hiljada

00:02:23.002 --> 00:02:25.641
prepoznavanja lica u nekoliko sekundi?

00:02:25.641 --> 00:02:28.269
Pa, nagađamo da će rezultat

00:02:28.269 --> 00:02:30.333
ove kombinacije tehnologija

00:02:30.333 --> 00:02:33.221
uneti radikalnu promenu
u našim shvatanjima

00:02:33.221 --> 00:02:35.478
privatnosti i anonimnosti.

00:02:35.478 --> 00:02:37.701
Da bismo to testirali,
sproveli smo eksperiment

00:02:37.701 --> 00:02:39.592
na kampusu Karnegi Melon univerziteta.

00:02:39.592 --> 00:02:41.691
Zamolili smo studente u prolazu

00:02:41.691 --> 00:02:43.470
da učestvuju u ispitivanju,

00:02:43.470 --> 00:02:46.032
fotografisali smo ih veb kamerom

00:02:46.032 --> 00:02:48.814
i zamolili ih da na laptopu
popune jedan upitnik.

00:02:48.814 --> 00:02:50.703
Dok su to radili,

00:02:50.703 --> 00:02:53.680
mi smo ubacili njihovu fotografiju
na računarsku mrežu u oblaku

00:02:53.680 --> 00:02:55.487
i pokrenuli program prepoznavanja lica

00:02:55.487 --> 00:02:57.722
kako bismo povezali tu fotografiju

00:02:57.722 --> 00:03:00.115
sa bazom od stotina hiljada slika

00:03:00.115 --> 00:03:03.711
koje smo poskidali sa Fejsbuk profila.

00:03:03.711 --> 00:03:07.360
Do trenutka kada je ispitanik
stigao do poslednje strane upitnika,

00:03:07.360 --> 00:03:10.317
stranica je automatski ažurirana

00:03:10.317 --> 00:03:12.630
sa deset najpribližnijih fotografija

00:03:12.630 --> 00:03:14.915
koje je program pronašao,

00:03:14.915 --> 00:03:16.653
i zamolili smo ispitanike da naznače

00:03:16.653 --> 00:03:20.773
ako su se prepoznali na fotografijama.

00:03:20.773 --> 00:03:24.472
Da li vidite ispitanika?

00:03:24.472 --> 00:03:27.317
Pa, računar je video,

00:03:27.317 --> 00:03:29.466
u stvari uspeo je u jednom od tri slučaja.

00:03:29.466 --> 00:03:32.650
U osnovi, možemo početi od anonimnog lica,

00:03:32.650 --> 00:03:36.134
na internetu ili van njega,
i možemo koristiti prepoznavanje lica

00:03:36.134 --> 00:03:38.494
da imenujemo to nepoznato lice

00:03:38.494 --> 00:03:40.602
zahvaljujući podacima
sa društvenih medija.

00:03:40.602 --> 00:03:43.064
Ali nekoliko godina ranije,
uradili smo nešto drugo.

00:03:43.064 --> 00:03:45.177
Počeli smo od podataka
sa društvenih medija,

00:03:45.177 --> 00:03:47.348
pomešali ih statistički sa podacima

00:03:47.348 --> 00:03:49.450
iz socijalnog osiguranja vlade SAD-a,

00:03:49.450 --> 00:03:52.774
i na kraju smo predviđali
brojeve socijalnog osiguranja,

00:03:52.774 --> 00:03:54.286
koji su u Sjedinjenim Državama

00:03:54.286 --> 00:03:56.326
izuzetno osetljiva informacija.

00:03:56.326 --> 00:03:58.419
Da li primećujete kuda idem s ovim?

00:03:58.419 --> 00:04:01.341
Dakle, ako spojite ta dva istraživanja,

00:04:01.341 --> 00:04:02.853
onda pitanje postaje,

00:04:02.853 --> 00:04:05.573
možete li početi od lica

00:04:05.573 --> 00:04:07.884
i koristeći prepoznavanje lica,
pronaći ime

00:04:07.884 --> 00:04:10.553
i javno dostupne informacije

00:04:10.553 --> 00:04:12.485
o tom imenu i toj osobi,

00:04:12.485 --> 00:04:14.733
i iz tih javno dostupnih informacija

00:04:14.733 --> 00:04:16.775
izvući one koje nisu javno dostupne,

00:04:16.775 --> 00:04:18.381
one mnogo osetljivije,

00:04:18.381 --> 00:04:20.013
koje možete povezati sa tim licem?

00:04:20.013 --> 00:04:22.039
Odgovor je da, možemo, i to smo i uradili.

00:04:22.039 --> 00:04:24.357
Naravno, preciznost se smanjuje.

00:04:24.357 --> 00:04:26.751
[4 pokušaja; identifikovano prvih 5 cifara
broja SO kod 27% ispitanika]

00:04:26.751 --> 00:04:29.128
Ali odlučili smo i da razvijemo aplikaciju

00:04:29.128 --> 00:04:31.843
koja koristi ugrađenu telefonsku kameru

00:04:31.843 --> 00:04:33.443
da fotografiše ispitanika

00:04:33.443 --> 00:04:34.930
i potom ubaci sliku na oblak

00:04:34.930 --> 00:04:37.592
i uradi u realnom vremenu
ono što sam vam opisao:

00:04:37.592 --> 00:04:39.680
traži podudaranje,
nalazi javne informacije,

00:04:39.680 --> 00:04:41.720
pokušava da otkrije osetljive informacije,

00:04:41.720 --> 00:04:44.001
i šalje sve nazad telefonu

00:04:44.001 --> 00:04:47.610
tako da se prikaže preko lica ispitanika,

00:04:47.610 --> 00:04:49.511
kao proširena stvarnost,

00:04:49.511 --> 00:04:51.962
verovatno jezivi primer
proširene stvarnosti.

00:04:51.962 --> 00:04:55.301
Zapravo, nismo razvili aplikaciju
koja bi bila dostupna,

00:04:55.301 --> 00:04:57.223
nego samo kao dokaz ideje.

00:04:57.223 --> 00:04:59.536
U stvari, uzmite ove tehnologije

00:04:59.536 --> 00:05:01.703
i gurnite ih
do njihovog logičnog ekstrema.

00:05:01.703 --> 00:05:04.252
Zamislite budućnost
u kojoj će vas stranci u okolini

00:05:04.252 --> 00:05:06.403
gledati kroz Gugl naočare,

00:05:06.403 --> 00:05:08.710
ili jednog dana kroz kontaktna sočiva,

00:05:08.710 --> 00:05:12.730
i koristiti sedam ili osam podataka o vama

00:05:12.730 --> 00:05:15.312
da pronađu bilo šta

00:05:15.312 --> 00:05:17.915
što je možda o vama poznato.

00:05:17.915 --> 00:05:22.709
Kako će izgledati ta budućnost bez tajni?

00:05:22.709 --> 00:05:24.673
I da li bi trebalo da nas je briga?

00:05:24.673 --> 00:05:26.564
Možda nam se sviđa da verujemo

00:05:26.564 --> 00:05:29.604
da će ta budućnost sa obiljem podataka

00:05:29.604 --> 00:05:32.118
biti nepolarizovana budućnost,

00:05:32.118 --> 00:05:35.701
ali zapravo,
posedovanje toliko informacija

00:05:35.701 --> 00:05:39.582
ne znači da ćemo donositi
objektivnije odluke.

00:05:39.598 --> 00:05:42.478
U jednom drugom eksperimentu,
ispitanicima smo predstavili

00:05:42.478 --> 00:05:44.704
informacije o potencijalnom
kandidatu za posao.

00:05:44.704 --> 00:05:47.582
Tu smo uključili i neke

00:05:47.582 --> 00:05:50.228
zabavne, potpuno legalne,

00:05:50.228 --> 00:05:52.693
ali možda donekle
ponižavajuće informacije

00:05:52.693 --> 00:05:54.713
koje je subjekat postavio na internet.

00:05:54.713 --> 00:05:57.079
Zanimljivo je da su neki ispitanici

00:05:57.079 --> 00:06:00.162
postavili slične informacije,

00:06:00.162 --> 00:06:02.524
a drugi nisu.

00:06:02.524 --> 00:06:04.473
Šta mislite, koja grupa

00:06:04.473 --> 00:06:09.025
je bila sklonija
da oštro prosuđuje o našem subjektu?

00:06:09.025 --> 00:06:10.982
Paradoksalno, ona grupa

00:06:10.982 --> 00:06:12.835
koja je postavila slične informacije,

00:06:12.835 --> 00:06:15.657
to je primer moralne disonance.

00:06:15.657 --> 00:06:17.407
Možda mislite

00:06:17.407 --> 00:06:19.109
da se to ne odnosi na vas,

00:06:19.109 --> 00:06:21.271
jer nemate šta da krijete.

00:06:21.271 --> 00:06:23.753
Ali u stvari, kod privatnosti

00:06:23.753 --> 00:06:27.429
se ne radi o tome
da krijete nešto negativno.

00:06:27.429 --> 00:06:30.013
Zamislite da ste direktor
odeljenja za ljudske resurse

00:06:30.013 --> 00:06:32.730
u nekoj organizaciji i primate biografije,

00:06:32.730 --> 00:06:35.343
i odlučite da pronađete
više informacija o kandidatima.

00:06:35.343 --> 00:06:37.663
Ukucate njihova imena u Gugl,

00:06:37.663 --> 00:06:39.903
i u nekom univerzumu,

00:06:39.903 --> 00:06:41.911
pronađete ovu informaciju.

00:06:41.911 --> 00:06:46.348
Ili u nekom paralelnom univerzumu,
pronađete ovu informaciju.

00:06:46.348 --> 00:06:49.065
Da li mislite da biste podjednako
bili skloni

00:06:49.065 --> 00:06:51.868
da pozovete jednog
od ova dva kandidata na razgovor?

00:06:51.868 --> 00:06:54.150
Ako to mislite, onda se razlikujete

00:06:54.150 --> 00:06:56.732
od poslodavaca u SAD-u,
koji su u stvari

00:06:56.732 --> 00:07:00.039
deo našeg eksperimenta,
znači da smo upravo to uradili.

00:07:00.039 --> 00:07:03.221
Napravili smo profile na Fejsbuku,
izmislili osobine,

00:07:03.221 --> 00:07:06.072
a potom smo počeli da šaljemo biografije
kompanijama u SAD,

00:07:06.072 --> 00:07:07.980
i pratili smo

00:07:07.980 --> 00:07:10.373
da li proveravaju naše kandidate

00:07:10.373 --> 00:07:13.465
i da li reaguju na informacije
koje nalaze na društvenim medijima.

00:07:13.465 --> 00:07:14.563
I reagovali su.

00:07:14.563 --> 00:07:16.814
Kroz društvene medije,
kandidati istih veština

00:07:16.814 --> 00:07:19.317
bili su diskriminisani.

00:07:19.317 --> 00:07:23.892
Marketari bi želeli da verujemo

00:07:23.892 --> 00:07:26.161
kako će sve informacije o nama

00:07:26.161 --> 00:07:29.434
uvek biti korišćene u našu korist.

00:07:29.434 --> 00:07:33.149
Razmislite još jednom.
Zašto bi to uvek bilo tako?

00:07:33.149 --> 00:07:35.813
U jednom filmu od pre nekoliko godina,

00:07:35.813 --> 00:07:38.366
"Suvišni izveštaj", u poznatoj sceni

00:07:38.366 --> 00:07:40.942
Tom Kruz ulazi u tržni centar

00:07:40.942 --> 00:07:44.718
i holografske personalizovane reklame

00:07:44.718 --> 00:07:46.553
se pojavljuju oko njega.

00:07:46.553 --> 00:07:49.780
Radnja tog filma smeštena je u 2054,

00:07:49.780 --> 00:07:51.422
oko 40 godina od danas,

00:07:51.422 --> 00:07:54.330
i koliko god ta tehnologija
uzbudljivo izgledala,

00:07:54.330 --> 00:07:56.976
ona već izuzetno potcenjuje

00:07:56.976 --> 00:07:59.116
količinu informacija koje organizacije

00:07:59.116 --> 00:08:01.599
mogu da skupe o vama,
i kako mogu da ih koriste

00:08:01.599 --> 00:08:04.997
da utiču na vas na načine
koje nećete ni primetiti.

00:08:04.997 --> 00:08:07.100
Kao ilustracija,
ovo je još jedan eksperiment

00:08:07.100 --> 00:08:09.373
koji sprovodimo, koji nije još završen.

00:08:09.373 --> 00:08:11.692
Zamislite da neka organizacija ima pristup

00:08:11.692 --> 00:08:13.748
listi vaših Fejsbuk prijatelja,

00:08:13.748 --> 00:08:15.520
i preko nekakvog algoritma

00:08:15.520 --> 00:08:19.254
može da otkrije
vaša dva najdraža prijatelja.

00:08:19.254 --> 00:08:21.534
I potom u realnom vremenu kreira

00:08:21.534 --> 00:08:24.376
lice od sklopa lica ta dva prijatelja.

00:08:24.376 --> 00:08:27.445
E sad, studije pre naše su dokazale

00:08:27.445 --> 00:08:30.136
da u takvim sklopovima

00:08:30.136 --> 00:08:32.617
ljudi više ne prepoznaju ni sebe,

00:08:32.617 --> 00:08:34.909
ali reaguju pozitivno na njih.

00:08:34.909 --> 00:08:38.324
Sledeći put kad budete tražili
neki proizvod,

00:08:38.324 --> 00:08:40.883
i pojavi se oglas
koji vam sugeriše da ga kupite,

00:08:40.883 --> 00:08:43.790
to neće biti neki standardni prodavac.

00:08:43.790 --> 00:08:46.103
Biće to jedan od vaših prijatelja,

00:08:46.103 --> 00:08:49.406
a vi nećete ni znati da se to dešava.

00:08:49.406 --> 00:08:51.819
Problem je u tome

00:08:51.819 --> 00:08:54.338
što trenutni mehanizmi zaštite

00:08:54.338 --> 00:08:57.776
protiv zloupotrebe ličnih informacija

00:08:57.776 --> 00:09:00.760
liče na srljanje grlom u jagode.

00:09:00.760 --> 00:09:03.673
Jedan od tih mehanizama
je transparentnost,

00:09:03.673 --> 00:09:06.873
obaveštavanje ljudi o tome
šta ćete uraditi s njihovim podacima.

00:09:06.873 --> 00:09:08.979
U osnovi je to veoma dobra stvar.

00:09:08.979 --> 00:09:12.646
Neophodna je, ali nije dovoljna.

00:09:12.646 --> 00:09:16.344
Transparentnost može biti
pogrešno usmerena.

00:09:16.344 --> 00:09:18.448
Možete reći ljudima šta ćete uraditi,

00:09:18.448 --> 00:09:20.680
i onda ih ipak navesti da otkriju

00:09:20.680 --> 00:09:23.303
proizvoljne količine ličnih informacija.

00:09:23.303 --> 00:09:26.189
U još jednom eksperimentu,
ovaj put sa studentima,

00:09:26.189 --> 00:09:29.247
tražili smo da daju informacije

00:09:29.247 --> 00:09:31.060
o svom ponašanju na kampusu,

00:09:31.060 --> 00:09:33.674
uključujući i dosta osetljiva pitanja,
poput ovog:

00:09:33.674 --> 00:09:35.331
[Da li ste ikad varali na ispitu?]

00:09:35.331 --> 00:09:37.311
Jednoj grupi studenata smo rekli:

00:09:37.311 --> 00:09:39.762
"Vaše odgovore će videti
samo drugi studenti".

00:09:39.762 --> 00:09:41.341
Drugoj grupi studenata smo rekli:

00:09:41.341 --> 00:09:44.902
"Vaše odgovore će videti
studenti i nastavno osoblje".

00:09:44.902 --> 00:09:47.493
Transparentnost. Obaveštenje.
I ovo je upalilo,

00:09:47.493 --> 00:09:49.190
u smislu da je prva grupa studenata

00:09:49.190 --> 00:09:51.468
bila spremnija da odgovori od druge.

00:09:51.468 --> 00:09:52.988
Ima smisla, zar ne?

00:09:52.988 --> 00:09:54.918
Ali onda amo dodali
obmanjujuće uputstvo.

00:09:54.918 --> 00:09:57.238
Ponovili smo eksperiment
sa iste dve grupe,

00:09:57.238 --> 00:09:59.665
ovog puta dodajući vreme

00:09:59.665 --> 00:10:02.600
između trenutka kad ih obaveštavamo

00:10:02.600 --> 00:10:04.680
na koji način ćemo koristiti
njihove podatke

00:10:04.680 --> 00:10:09.068
i trenutka kad počinjemo
da odgovaramo na pitanja.

00:10:09.068 --> 00:10:11.629
Šta mislite, koliko vremena
smo morali da dodamo

00:10:11.629 --> 00:10:16.242
da bismo poništili inhibitorni efekat

00:10:16.242 --> 00:10:19.653
saznanja da će nastavno osoblje
videti vaše odgovore?

00:10:19.653 --> 00:10:21.433
Deset minuta?

00:10:21.433 --> 00:10:23.224
Pet minuta?

00:10:23.224 --> 00:10:25.000
Minut?

00:10:25.000 --> 00:10:27.049
Kako zvuči 15 sekundi?

00:10:27.049 --> 00:10:29.717
15 sekundi je bilo dovoljno da obe grupe

00:10:29.717 --> 00:10:31.485
otkriju istu količinu informacija,

00:10:31.485 --> 00:10:34.031
kao da drugoj grupi više nije važno

00:10:34.031 --> 00:10:36.687
što će nastavno osoblje
čitati njihove odgovore.

00:10:36.687 --> 00:10:38.927
Moram da priznam

00:10:38.927 --> 00:10:42.503
da ovaj govor do sada
zvuči izuzetno mračno,

00:10:42.503 --> 00:10:44.224
ali to mi nije cilj.

00:10:44.224 --> 00:10:46.923
Zapravo, želim sa vama
da podelim činjenicu

00:10:46.923 --> 00:10:48.695
da postoje alternative.

00:10:48.695 --> 00:10:51.194
Način na koji sada radimo

00:10:51.194 --> 00:10:54.551
nije jedini i sigurno nije najbolji.

00:10:56.258 --> 00:11:00.429
Kada vam neko kaže
da ljudima nije stalo do privatnosti,

00:11:00.429 --> 00:11:03.071
razmislite o tome da je igra osmišljena

00:11:03.071 --> 00:11:05.795
i napravljena tako
da ne mogu da brinu o privatnosti,

00:11:05.795 --> 00:11:09.057
i shvatanje da se ovakve manipulacije
dešavaju,

00:11:09.057 --> 00:11:10.664
je već polovina pređenog puta

00:11:10.664 --> 00:11:12.922
u procesu da se zaštitite.

00:11:12.922 --> 00:11:16.111
Kada vam neko kaže da se privatnost

00:11:16.111 --> 00:11:18.481
ne slaže sa koristima "velikih podataka",

00:11:18.481 --> 00:11:20.954
uzmite u obzir da su
u poslednjih 20 godina

00:11:20.954 --> 00:11:22.871
istraživači stvorili tehnologije

00:11:22.871 --> 00:11:26.189
koje dozvoljavaju da se skoro svaka
elektronska transakcija izvrši

00:11:26.189 --> 00:11:29.938
na način koji omogućava
bolje čuvanje privatnosti.

00:11:29.938 --> 00:11:32.493
Možemo anonimno da pretražujemo internet.

00:11:32.493 --> 00:11:35.171
Možemo da šaljemo imejlove
koje može da pročita

00:11:35.171 --> 00:11:38.880
samo primalac, ali ne i NSA.

00:11:38.880 --> 00:11:41.877
Možemo čak i da prikupljamo podatke
uz očuvanje privatnosti.

00:11:41.877 --> 00:11:45.771
Drugim rečima, možemo imati koristi
od "velikih podataka"

00:11:45.771 --> 00:11:47.903
uz očuvanje privatnosti.

00:11:47.903 --> 00:11:50.753
Naravno, ove tehnologije

00:11:50.753 --> 00:11:53.240
nagoveštavaju promenu troškova i zarade

00:11:53.240 --> 00:11:55.777
između onih koji imaju
i onih koji traže podatke,

00:11:55.777 --> 00:11:58.800
što je verovatno razlog
zašto ne znate više o njima.

00:11:58.800 --> 00:12:02.506
I to me vraća rajskom vrtu.

00:12:02.506 --> 00:12:05.286
Postoji i druga interpretacija privatnosti

00:12:05.286 --> 00:12:07.095
u priči o rajskom vrtu,

00:12:07.095 --> 00:12:09.191
koja ne mora biti u vezi sa činjenicom

00:12:09.191 --> 00:12:12.676
da se Adam i Eva osećaju
golo i posramljeno.

00:12:13.797 --> 00:12:16.578
Odjeke ove interpretacije možete naći

00:12:16.578 --> 00:12:19.360
u "Izgubljenom raju", Džona Miltona.

00:12:19.360 --> 00:12:23.557
U raju, Adam i Eva
su materijalno zadovoljni.

00:12:23.557 --> 00:12:25.661
Srećni su i zadovoljni.

00:12:25.661 --> 00:12:27.954
Međutim, nedostaje im znanje

00:12:27.954 --> 00:12:29.594
i samosvest.

00:12:29.594 --> 00:12:32.103
U trenutku kada pojedu

00:12:32.103 --> 00:12:34.206
prigodno nazvano, voće znanja,

00:12:34.206 --> 00:12:36.811
oni otkrivaju sebe.

00:12:36.811 --> 00:12:40.842
Postaju svesni. Postižu nezavisnost.

00:12:40.842 --> 00:12:43.968
Međutim, cena koju plaćaju
je napuštanje raja.

00:12:43.968 --> 00:12:47.849
Dakle, privatnost je i sredstvo

00:12:47.849 --> 00:12:50.811
i cena koja se plaća za slobodu.

00:12:50.811 --> 00:12:53.581
Opet, stručnjaci kažu

00:12:53.581 --> 00:12:56.600
da "veliki podaci" i društveni mediji

00:12:56.600 --> 00:12:59.579
za njih nisu samo raj profita,

00:12:59.579 --> 00:13:02.036
nego i Rajski vrt za nas ostale.

00:13:02.036 --> 00:13:03.574
Dobijamo besplatan sadržaj.

00:13:03.574 --> 00:13:06.397
Možemo da igramo "Angry Birds".
Dobijamo ciljane aplikacije.

00:13:06.397 --> 00:13:08.518
Ali u stvari, za nekoliko godina,

00:13:08.518 --> 00:13:10.903
organizacije će znati toliko o nama,

00:13:10.903 --> 00:13:13.613
da će biti u mogućnosti
da zaključe o našim željama

00:13:13.613 --> 00:13:15.817
pre nego što ih mi uobličimo,

00:13:15.817 --> 00:13:18.264
i možda da kupuju proizvode za nas,

00:13:18.264 --> 00:13:20.538
pre nego što i znamo da su nam potrebni.

00:13:20.538 --> 00:13:23.775
Postojao je jedan engleski autor

00:13:23.775 --> 00:13:26.820
koji je predvideo ovakvu budućnost

00:13:26.820 --> 00:13:30.035
gde menjamo svoju autonomiju i slobodu

00:13:30.035 --> 00:13:31.773
za udobnost.

00:13:31.773 --> 00:13:33.934
Čak i više nego Džordž Orvel,

00:13:33.934 --> 00:13:36.695
taj autor je, naravno, Oldos Haksli.

00:13:36.695 --> 00:13:39.549
U "Vrlom novom svetu"
on predstavlja društvo

00:13:39.549 --> 00:13:41.720
gde nas tehnologije,

00:13:41.720 --> 00:13:44.119
koje smo stvorili pre svega za slobodu,

00:13:44.119 --> 00:13:46.146
na kraju zarobe.

00:13:46.146 --> 00:13:50.937
Međutim, on u knjizi nudi
i izlaz iz takvog društva,

00:13:50.937 --> 00:13:54.375
sličan putu

00:13:54.375 --> 00:13:58.330
kojim su Adam i Eva morali da krenu
da bi izašli iz vrta.

00:13:58.330 --> 00:14:00.477
Prema rečima Divljaka,

00:14:00.477 --> 00:14:03.546
moguće je povratiti autonomiju i slobodu,

00:14:03.546 --> 00:14:06.225
ali je cena koja se plaća visoka.

00:14:06.225 --> 00:14:11.940
Verujem da će jedna od definišućih borbi
našeg vremena

00:14:11.940 --> 00:14:14.503
biti borba

00:14:14.503 --> 00:14:16.890
za kontrolu naših ličnih informacija,

00:14:16.890 --> 00:14:19.944
borba oko pitanja da li će "veliki podaci"

00:14:19.944 --> 00:14:21.686
biti sila slobode

00:14:21.686 --> 00:14:26.432
ili sila koja će u potaji
manipulisati nama.

00:14:26.432 --> 00:14:29.025
Trenutno, mnogi od nas

00:14:29.025 --> 00:14:31.778
ni ne znaju da se vodi borba,

00:14:31.778 --> 00:14:34.450
ali vodi se, sviđalo vam se to ili ne.

00:14:34.450 --> 00:14:37.254
Uz rizik da preuzmem ulogu zmije,

00:14:37.254 --> 00:14:40.861
reći ću vam da su alati te borbe ovde,

00:14:40.861 --> 00:14:43.160
svest o tome šta se dešava,

00:14:43.160 --> 00:14:44.515
i u vašim rukama,

00:14:44.515 --> 00:14:48.255
na samo nekoliko klikova od vas.

00:14:48.255 --> 00:14:49.737
Hvala.

00:14:49.737 --> 00:14:54.214
(Aplauz)

