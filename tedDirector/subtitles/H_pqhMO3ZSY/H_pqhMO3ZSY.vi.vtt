WEBVTT
Kind: captions
Language: vi

00:00:00.000 --> 00:00:07.000
Translator: Hanh Lan Hoang Thi
Reviewer: Thanh Nguyen Cong

00:00:12.641 --> 00:00:14.995
Tôi muốn kể 1 câu chuyện

00:00:14.995 --> 00:00:18.171
kết nối 1 sự việc riêng tư rất nổi tiếng

00:00:18.171 --> 00:00:20.940
giữa Adam và Eve

00:00:20.940 --> 00:00:24.386
với sự thay đổi to lớn về giới hạn

00:00:24.386 --> 00:00:27.072
giữa đời sống công cộng và riêng tư

00:00:27.072 --> 00:00:28.842
trong 10 năm vừa qua.

00:00:28.842 --> 00:00:30.140
Các bạn đều biết sự việc này.

00:00:30.140 --> 00:00:33.470
Một ngày trong Vườn Địa Đàng,

00:00:33.470 --> 00:00:35.313
Adam và Eve nhận ra họ đang trần truồng.

00:00:35.313 --> 00:00:36.813
Cả hai đều bối rối lo sợ.

00:00:36.813 --> 00:00:39.570
Và phần còn lại là lịch sử.

00:00:39.570 --> 00:00:41.758
Thời nay, có lẽ Adam và Eve

00:00:41.758 --> 00:00:44.119
sẽ hành động rất khác.

00:00:44.119 --> 00:00:46.387
[@Adam: Đêm qua thật tuyệt vời! 
Em thích quả táo của anh lol]

00:00:46.387 --> 00:00:48.260
[@Eve: uhm... em yêu, 
em có biết quần anh đâu rồi ko?

00:00:48.260 --> 00:00:50.896
Chúng ta tiết lộ nhiều thông tin

00:00:50.896 --> 00:00:54.230
về bản thân mình online hơn bao giờ hết

00:00:54.230 --> 00:00:55.934
và rất nhiều thông tin đó

00:00:55.934 --> 00:00:58.158
đang được các tổ chức thu thập.

00:00:58.158 --> 00:01:01.440
Có rất nhiều lợi ích

00:01:01.440 --> 00:01:03.886
từ việc phân tích thông tin cá nhân ở quy mô lớn

00:01:03.886 --> 00:01:05.832
hay còn gọi là "dữ liệu khổng lồ"

00:01:05.832 --> 00:01:08.470
nhưng cũng có những tổn hại phức tạp

00:01:08.470 --> 00:01:11.568
do việc từ bỏ riêng tư cá nhân.

00:01:11.568 --> 00:01:15.591
Và câu chuyện của tôi là về những tổn hại đó.

00:01:15.591 --> 00:01:18.175
Chúng ta bắt đầu với một quan sát mà theo tôi

00:01:18.175 --> 00:01:21.502
càng ngày càng trở nên rõ ràng trong vài năm qua

00:01:21.502 --> 00:01:23.599
đó là: bất kì thông tin cá nhân nào

00:01:23.599 --> 00:01:25.884
cũng có thể trở thành thông tin nhạy cảm.

00:01:25.884 --> 00:01:30.009
Năm 2000, toàn thế giới

00:01:30.009 --> 00:01:31.921
chụp khoảng 100 tỷ bức ảnh

00:01:31.921 --> 00:01:34.986
nhưng chỉ có 1 phần rất nhỏ trong đó

00:01:34.986 --> 00:01:36.869
được chia sẻ online.

00:01:36.869 --> 00:01:40.230
Năm 2010, tính riêng trên Facebook, trong 1 tháng

00:01:40.230 --> 00:01:43.500
có 2.5 tỷ bức ảnh được chia sẻ online

00:01:43.500 --> 00:01:45.382
và hầu hết đều có tên.

00:01:45.382 --> 00:01:47.262
Trong cùng thời gian đó,

00:01:47.262 --> 00:01:52.132
khả năng nhận dạng người qua ảnh của máy tính

00:01:52.132 --> 00:01:55.740
được cải thiện hơn 1000 lần.

00:01:55.740 --> 00:01:57.622
Chuyện gì sẽ xảy ra

00:01:57.622 --> 00:01:59.123
khi những công nghệ này kết hợp lại?

00:01:59.123 --> 00:02:01.781
dữ liệu khuôn mặt nhiều lên và sẵn có,

00:02:01.781 --> 00:02:05.429
công nghệ nhận dạng ngày càng phát triển,

00:02:05.429 --> 00:02:07.611
và cả điện toán đám mây -

00:02:07.611 --> 00:02:09.499
1 mô hình sẽ mang đến cho
bất kì ai trong khán phòng này

00:02:09.499 --> 00:02:11.059
năng lực máy tính vượt trội

00:02:11.059 --> 00:02:12.945
mà mới chỉ vài năm trước

00:02:12.945 --> 00:02:14.727
chỉ các cơ quan chính phủ mới có,

00:02:14.727 --> 00:02:16.105
và công nghệ tin học rộng khắp

00:02:16.105 --> 00:02:18.997
làm cho điện thoại di động,
cho dù không phải siêu máy tính

00:02:18.997 --> 00:02:20.668
vẫn có thể kết nối Internet

00:02:20.668 --> 00:02:23.002
và làm hàng trăm nghìn

00:02:23.002 --> 00:02:25.641
phép nhận dạng trong vòng vài giây?

00:02:25.641 --> 00:02:28.269
Chúng tôi dự đoán rằng

00:02:28.269 --> 00:02:30.333
hậu quả của sự kết hợp các công nghê này

00:02:30.333 --> 00:02:33.221
là một thay đổi triệt để trong nhận thức chúng ta

00:02:33.221 --> 00:02:35.478
về riêng tư cá nhân và sự ẩn danh.

00:02:35.478 --> 00:02:37.471
Để kiểm tra, chúng tôi làm 1 thí nghiệm

00:02:37.471 --> 00:02:39.592
tại trường Đại Học Carnegie Mellon.

00:02:39.592 --> 00:02:41.691
Sinh viên của trường được chọn ngẫu nhiên

00:02:41.691 --> 00:02:43.470
để tham gia một nghiên cứu.

00:02:43.470 --> 00:02:46.032
Chúng tôi chụp ảnh họ bằng webcam

00:02:46.032 --> 00:02:48.814
và yêu cầu họ điền vào bảng câu hỏi trên laptop.

00:02:48.814 --> 00:02:50.793
Trong khi họ trả lời câu hỏi,

00:02:50.793 --> 00:02:53.590
chúng tôi tải những bức ảnh vừa chụp 
lên 1 đám mây điện toán

00:02:53.590 --> 00:02:55.317
và dùng 1 phần mềm nhận dạng khuôn mặt

00:02:55.317 --> 00:02:57.722
để kết nối bức ảnh đó với cơ sở dữ liệu

00:02:57.722 --> 00:03:00.115
của hàng trăm ngàn bức ảnh

00:03:00.115 --> 00:03:03.711
chúng tôi tải về từ vô vàn Facebook cá nhân.

00:03:03.711 --> 00:03:06.970
Cho đến lúc các sinh viên trả lời đến trang cuối,

00:03:06.970 --> 00:03:10.317
trang web đã được update liên tục

00:03:10.317 --> 00:03:12.630
và cho ra 10 bức ảnh gần giống nhất

00:03:12.630 --> 00:03:14.915
mà phần mềm nhận dạng tìm được

00:03:14.915 --> 00:03:16.653
rồi chúng tôi hỏi các sinh viên

00:03:16.653 --> 00:03:20.773
họ có thấy mình trong các bức ảnh đó không.

00:03:20.773 --> 00:03:24.472
Các bạn có nhận ra người trong bức ảnh không?

00:03:24.472 --> 00:03:27.317
Máy tính thì có,

00:03:27.317 --> 00:03:29.466
và nhận dạng thành công 1 trong 3 sinh viên.

00:03:29.466 --> 00:03:32.650
Tức là, có thể bắt đầu với 1 khuôn mặt vô danh

00:03:32.650 --> 00:03:36.134
offline hoặc online, rồi dùng công nghê nhận dạng

00:03:36.134 --> 00:03:38.494
để tìm ra tên cho khuôn mặt ấy

00:03:38.494 --> 00:03:40.602
nhờ vào dữ liệu từ mạng xã hội.

00:03:40.602 --> 00:03:42.474
Vài năm trước, chúng tôi làm 1 thí nghiệm khác.

00:03:42.474 --> 00:03:44.297
Chúng tôi bắt đầu từ dữ liệu trên mạng xã hội.

00:03:44.297 --> 00:03:47.348
rồi kết hợp thống kê với dữ liệu

00:03:47.348 --> 00:03:49.450
từ bảo hiểm xã hội của chính phủ Mỹ

00:03:49.450 --> 00:03:52.774
để phỏng đoán số bảo hiểm xã hội của mỗi người -

00:03:52.774 --> 00:03:54.286
đó là thông tin hết sức nhạy cảm

00:03:54.286 --> 00:03:56.326
ở Mỹ.

00:03:56.326 --> 00:03:58.419
Bạn có đoán được tôi muốn dẫn đến cái gì không?

00:03:58.419 --> 00:04:01.341
Kết hợp 2 nghiên cứu trên,

00:04:01.341 --> 00:04:02.853
và câu hỏi trở thành

00:04:02.853 --> 00:04:05.573
liệu chúng ta có thể bắt đầu từ 1 khuôn mặt

00:04:05.573 --> 00:04:07.884
dùng công nghê nhận dạng, tìm ra tên

00:04:07.884 --> 00:04:10.553
và các thông tin công khai khác

00:04:10.553 --> 00:04:12.485
về cái tên đó và con người đó

00:04:12.485 --> 00:04:14.733
rồi từ các thông tin công khai đó

00:04:14.733 --> 00:04:16.775
suy luận ra các thông tin cá nhân

00:04:16.775 --> 00:04:18.381
cực kì nhạy cảm

00:04:18.381 --> 00:04:19.873
rồi kết nối chúng với khuôn mặt đó?

00:04:19.873 --> 00:04:21.789
Câu trả lời là: chúng ta làm được, và đã làm thế.

00:04:21.789 --> 00:04:24.357
Đương nhiên, độ chính xác giảm dần.

00:04:24.357 --> 00:04:25.301
[Tìm ra 27% trong 5 chữ số đầu tiên trong số bảo hiểm xã hội của chủ thể sau 4 lần]

00:04:25.301 --> 00:04:29.128
Thật ra, chúng tôi còn viết 1 ứng dụng iPhone

00:04:29.128 --> 00:04:31.843
dùng camera của máy

00:04:31.843 --> 00:04:33.443
để chụp ảnh chủ thể

00:04:33.443 --> 00:04:34.930
rồi tải lên 1 đám mây

00:04:34.930 --> 00:04:37.592
và làm như những gì tôi đã miêu tả:

00:04:37.592 --> 00:04:39.680
tìm kết nối, tìm thông tin công khai,

00:04:39.680 --> 00:04:41.410
suy luận các thông tin nhạy cảm

00:04:41.410 --> 00:04:44.001
và gửi lại về máy di động

00:04:44.001 --> 00:04:47.610
thế là trên ảnh của chủ thể

00:04:47.610 --> 00:04:49.511
sẽ là 1 ví dụ của thực tại tăng cường,

00:04:49.511 --> 00:04:51.962
có lẽ là 1 ví dụ lạnh gáy của
thực tiễn đã được phóng đại lên.

00:04:51.962 --> 00:04:55.301
Thực ra, chúng tôi không viết ứng dụng này để bán,

00:04:55.301 --> 00:04:57.223
mà chỉ để chứng minh quan điểm của mình.

00:04:57.223 --> 00:04:59.536
Hơn nữa, thử đẩy những công nghệ này

00:04:59.536 --> 00:05:01.373
đến mức cực đoan.

00:05:01.373 --> 00:05:04.092
Tưởng tượng rằng trong tương lai, 
những người lạ quanh bạn

00:05:04.092 --> 00:05:06.403
sẽ nhìn bạn qua Kính Google

00:05:06.403 --> 00:05:08.710
hoặc 1 ngày nào đó, kính áp tròng,

00:05:08.710 --> 00:05:12.730
và dùng 7-8 điểm dữ liệu về bạn

00:05:12.730 --> 00:05:15.312
để suy luận bất kì thông tin gì khác

00:05:15.312 --> 00:05:17.915
về bạn.

00:05:17.915 --> 00:05:22.709
Tương lai không bí mật này sẽ như thế nào?

00:05:22.709 --> 00:05:24.673
Và liệu chúng ta có cần quan tâm?

00:05:24.673 --> 00:05:26.564
Chúng ta muốn tin rằng

00:05:26.564 --> 00:05:29.604
tương lai với dữ liệu sẵn có như vậy

00:05:29.604 --> 00:05:32.118
sẽ là một tương lai không có thành kiến.

00:05:32.118 --> 00:05:35.701
Tuy nhiên, sự thật là, có nhiều thông tin hơn

00:05:35.701 --> 00:05:37.892
không giúp chúng ta quyết định

00:05:37.892 --> 00:05:39.598
một cách khách quan hơn.

00:05:39.598 --> 00:05:42.158
Trong một thí nghiệm khác, chúng tôi 
cung cấp cho chủ thể thông tin

00:05:42.158 --> 00:05:44.404
về 1 ứng viên tiềm năng cho 1 công việc.

00:05:44.404 --> 00:05:47.582
Chúng tôi thêm vào 1 vài liên kết

00:05:47.582 --> 00:05:50.228
đến những thông tin khôi hài, hoàn toàn hợp pháp

00:05:50.228 --> 00:05:52.693
nhưng có thể hơi đáng xấu hổ

00:05:52.693 --> 00:05:54.713
mà ứng viên này đã chia sẻ online.

00:05:54.713 --> 00:05:57.079
Điều thú vị là, trong các chủ thể của thí nghiệm này

00:05:57.079 --> 00:06:00.162
có người đã từng chia sẻ thông tin tương tự

00:06:00.162 --> 00:06:02.524
và có người chưa từng.

00:06:02.524 --> 00:06:04.473
Các bạn đoán nhóm nào sẽ

00:06:04.473 --> 00:06:09.025
đánh giá ứng viên này nghiêm khắc hơn?

00:06:09.025 --> 00:06:10.982
Nghịch lí xảy ra: đó là nhóm đã

00:06:10.982 --> 00:06:12.715
chia sẻ thông tin tương tự -

00:06:12.715 --> 00:06:15.657
1 ví dụ về mâu thuẫn đạo đức.

00:06:15.657 --> 00:06:17.407
Bạn có thể nghĩ là

00:06:17.407 --> 00:06:19.109
tôi không như vậy,

00:06:19.109 --> 00:06:21.271
vì tôi chẳng có gì phải giấu giiếm.

00:06:21.271 --> 00:06:23.753
Tuy nhiên, riêng tư cá nhân không phải là

00:06:23.753 --> 00:06:27.429
có những tiêu cực cần che giấu.

00:06:27.429 --> 00:06:29.783
Tưởng tượng bạn là giám đốc nhân sự

00:06:29.783 --> 00:06:32.730
của 1 tổ chức, bạn nhận hồ sơ và

00:06:32.730 --> 00:06:35.203
muốn tìm hiểu thêm thông tin về các ứng viên.

00:06:35.203 --> 00:06:37.663
Vì thế, bạn Google tên của họ

00:06:37.663 --> 00:06:39.903
và trong 1 trường hợp,

00:06:39.903 --> 00:06:41.911
bạn tìm thấy thông tin này.

00:06:41.911 --> 00:06:46.348
Hoặc trong trường hợp khác, 
bạn thấy thông tin này.

00:06:46.348 --> 00:06:49.065
Bạn có nghĩ rằng bạn sẽ gọi 2 ứng viên này

00:06:49.065 --> 00:06:51.868
vào vòng phỏng vấn với xác suất như nhau không?

00:06:51.868 --> 00:06:54.150
Nếu bạn nghĩ vậy, thì bạn không giống

00:06:54.150 --> 00:06:56.732
các nhà tuyển dụng Mỹ, những người

00:06:56.732 --> 00:07:00.039
đã tham gia thí nghiệm của chúng tôi.

00:07:00.039 --> 00:07:03.221
Chúng tôi lập nhiều trang Facebook cá nhân,
tạo dựng đặc điểm tính cách

00:07:03.221 --> 00:07:06.072
và bắt đầu gửi hồ sơ đến các công ty ở Mỹ.

00:07:06.072 --> 00:07:07.980
Chúng tôi phát hiện, và giám sát xem

00:07:07.980 --> 00:07:10.373
họ có tìm và đánh giá ứng viên

00:07:10.373 --> 00:07:12.205
dựa vào thông tin trên mạng xã hội

00:07:12.205 --> 00:07:14.143
và họ đã làm như thế.

00:07:14.143 --> 00:07:16.244
Phân biệt đối xử xảy ra qua mạng xã hội

00:07:16.244 --> 00:07:19.317
đối với các ứng viên có khả năng tương đương.

00:07:19.317 --> 00:07:23.892
Nhà quảng cáo muốn chúng ta tin rằng

00:07:23.892 --> 00:07:26.161
thông tin cá nhân sẽ luôn được sử dụng

00:07:26.161 --> 00:07:29.434
để mang lại lợi ích cho chúng ta.

00:07:29.434 --> 00:07:33.149
Hãy nghĩ lại. Tại sao luôn luôn như vậy?

00:07:33.149 --> 00:07:35.813
Trong một bộ phim vài năm trước,

00:07:35.813 --> 00:07:38.366
"Minority Report", 1 cảnh nổi tiếng

00:07:38.366 --> 00:07:40.942
có Tom Cruise đi trong siêu thị

00:07:40.942 --> 00:07:44.718
và biển quảng cáo 3D cá nhân hóa

00:07:44.718 --> 00:07:46.553
hiện ra xung quanh anh ấy.

00:07:46.553 --> 00:07:49.780
Bộ phim đó được đặt trong bối cảnh năm 2054,

00:07:49.780 --> 00:07:51.422
40 năm nữa tính từ bây giờ,

00:07:51.422 --> 00:07:54.330
và cho dù công nghệ đó 
xem ra đã gây chấn động vô cùng,

00:07:54.330 --> 00:07:56.976
nó vẫn đánh giá quá thấp

00:07:56.976 --> 00:07:59.116
số lượng thông tin về bạn mà các tổ chức

00:07:59.116 --> 00:08:01.599
thu thập được, và cách họ có thể sử dụng nó

00:08:01.599 --> 00:08:04.997
để chi phối bạn mà bạn cũng không phát hiện ra.

00:08:04.997 --> 00:08:07.100
Một ví dụ nữa, đây là một thí nghiệm vẫn đang

00:08:07.100 --> 00:08:09.373
trong quá trình, chưa hoàn thành.

00:08:09.373 --> 00:08:11.692
Tưởng tượng rằng 1 tổ chức có thể truy cập

00:08:11.692 --> 00:08:13.748
vào danh sách bạn bè Facebook của bạn,

00:08:13.748 --> 00:08:15.520
và bằng thuật toán nào đó

00:08:15.520 --> 00:08:19.254
có thể tìm ra 2 người bạn mà bạn quý nhất.

00:08:19.254 --> 00:08:21.534
Và họ tạo ra, trong thực tế,

00:08:21.534 --> 00:08:24.376
1 khuôn mặt kết hợp 2 người bạn này.

00:08:24.376 --> 00:08:27.445
Nhiều nghiên cứu trước chúng tôi đã chỉ ra

00:08:27.445 --> 00:08:30.330
con người không thể nhận ra chính họ

00:08:30.330 --> 00:08:32.792
trong các khuôn mặt tổng hợp này,

00:08:32.792 --> 00:08:34.909
nhưng vẫn phản ứng tích cực với chúng.

00:08:34.909 --> 00:08:38.324
Vậy nên lần tới khi bạn đang tìm mua 1 sản phẩm

00:08:38.324 --> 00:08:40.883
và có 1 quảng cáo mời bạn mua

00:08:40.883 --> 00:08:43.790
đó sẽ không chỉ là một phát ngôn viên bất kì.

00:08:43.790 --> 00:08:46.103
Đó sẽ là 1 người trong số bạn bè của bạn,

00:08:46.103 --> 00:08:49.406
và bạn thậm chí sẽ không biết điều này đang xảy ra.

00:08:49.406 --> 00:08:51.819
Vấn đề bây giờ là

00:08:51.819 --> 00:08:54.338
cơ chế chính sách hiện có

00:08:54.338 --> 00:08:57.776
để bảo vệ chúng ta khỏi lạm dụng thông tin cá nhân

00:08:57.776 --> 00:09:00.760
chỉ giống như là dao đấu với súng.

00:09:00.760 --> 00:09:03.673
Một trong những cơ chế đó là sự minh bạch

00:09:03.673 --> 00:09:06.873
nói rõ bạn sẽ làm gì với 
thông tin cá nhân của người khác.

00:09:06.873 --> 00:09:08.979
Trên lý thuyết, đó là điều rất tốt.

00:09:08.979 --> 00:09:12.646
Nó là cần thiết, nhưng chưa đủ.

00:09:12.646 --> 00:09:16.344
Sự minh bạch có thể lạc lối.

00:09:16.344 --> 00:09:18.448
Bạn có thể nói với mọi người bạn sẽ làm gì

00:09:18.448 --> 00:09:20.680
và vẫn tiếp tục dụ họ nói ra

00:09:20.680 --> 00:09:23.303
thông tin cá nhân một cách ngẫu nhiên.

00:09:23.303 --> 00:09:26.189
Trong một thí nghiệm nữa, lần này với sinh viên

00:09:26.189 --> 00:09:29.247
chúng tôi đề nghị họ cung cấp thông tin

00:09:29.247 --> 00:09:31.060
về hoạt động trong trường của họ

00:09:31.060 --> 00:09:34.000
bao gồm cả những câu hỏi nhạy cảm, ví dụ:

00:09:34.000 --> 00:09:34.621
[Bạn đã bao giờ gian lận trong thi cử chưa?]

00:09:34.621 --> 00:09:36.921
Với 1 nhóm sinh viên, chúng tôi nói với họ

00:09:36.921 --> 00:09:39.762
"Chỉ có các sinh viên khác 
được xem câu trả lời của bạn."

00:09:39.762 --> 00:09:41.341
Với 1 nhóm khác, chúng tôi nói là

00:09:41.341 --> 00:09:44.902
"Sinh viên cũng như giáo viên 
sẽ xem câu trả lời của bạn."

00:09:44.902 --> 00:09:47.493
Minh bạch. Thông báo. 
Chắc chắn là nó phải hiệu quả,

00:09:47.493 --> 00:09:48.900
vì nhóm đầu tiên tiết lộ thông tin với tỉ lệ

00:09:48.900 --> 00:09:51.468
cao hơn nhiều so với nhóm thứ hai.

00:09:51.468 --> 00:09:52.988
Có lý, phải không?

00:09:52.988 --> 00:09:54.478
Nhưng chúng tôi thêm vào một chỉ dẫn gây rối

00:09:54.478 --> 00:09:57.238
Chúng tôi thực hiện lại thí nghiệm với 2 nhóm đó

00:09:57.238 --> 00:09:59.665
lần này thêm vào một khoảng chờ đợi

00:09:59.665 --> 00:10:02.600
giữa lúc chúng tôi nói với chủ thể

00:10:02.600 --> 00:10:04.680
cách chúng tôi sử dụng dữ liệu

00:10:04.680 --> 00:10:09.068
và lúc họ bắt đầu trả lời câu hỏi.

00:10:09.068 --> 00:10:11.629
Bạn nghĩ rằng phải chậm bao lâu

00:10:11.629 --> 00:10:16.242
để vô hiệu hóa tác dụng ngăn cản

00:10:16.242 --> 00:10:19.653
khi chủ thể biết là giáo viên sẽ
xem câu trả lời của họ?

00:10:19.653 --> 00:10:21.433
10 phút?

00:10:21.433 --> 00:10:23.224
5 phút?

00:10:23.224 --> 00:10:25.000
1 phút?

00:10:25.000 --> 00:10:27.049
15 giây thì sao?

00:10:27.049 --> 00:10:29.717
15 giây là đủ để cả 2 nhóm

00:10:29.717 --> 00:10:31.285
tiết lộ lượng thông tin như nhau

00:10:31.285 --> 00:10:34.031
như thể là nhóm thứ 2 không quan tâm

00:10:34.031 --> 00:10:36.687
giáo viên có đọc câu trả lời của họ hay không.

00:10:36.687 --> 00:10:40.023
Bây giờ tôi phải thừa nhận là cuộc nói chuyện này

00:10:40.023 --> 00:10:42.503
có vẻ cực kì u ám,

00:10:42.503 --> 00:10:44.224
nhưng đó không phải là tôi muốn nói.

00:10:44.224 --> 00:10:46.923
Thực ra, tôi muốn chia sẻ với các bạn

00:10:46.923 --> 00:10:48.695
những khả năng khác.

00:10:48.695 --> 00:10:51.194
Cách chúng ta làm việc hiện giờ không phải

00:10:51.194 --> 00:10:54.231
cách duy nhất, và chắc chắn 
không phải là cách tốt nhất

00:10:54.231 --> 00:10:56.258
để làm điều đó.

00:10:56.258 --> 00:11:00.429
Khi ai đó nói với bạn:
"Con người không quan tâm đến riêng tư,"

00:11:00.429 --> 00:11:03.071
hãy nghĩ xem có phải cuộc chơi đã được thiết kế

00:11:03.071 --> 00:11:05.795
và sắp đặt để họ không thể quan tâm đến riêng tư

00:11:05.795 --> 00:11:09.057
và nhận ra những mánh khóe này

00:11:09.057 --> 00:11:10.664
đã là nửa đường trên quá trình

00:11:10.664 --> 00:11:12.922
bảo vệ bản thân bạn.

00:11:12.922 --> 00:11:16.632
Khi ai đó nói rằng sự riêng tư là đối nghịch với

00:11:16.632 --> 00:11:18.481
ích lợi của dữ liệu khổng lồ,

00:11:18.481 --> 00:11:20.954
hãy nghĩ xem trong 20 năm qua

00:11:20.954 --> 00:11:22.871
nhà nghiên cứu đã tạo ra công nghệ

00:11:22.871 --> 00:11:26.189
để đảm bảo thanh toán điện tử

00:11:26.189 --> 00:11:29.938
giữ được quyền riêng tư cá nhân hơn.

00:11:29.938 --> 00:11:32.493
Chúng ta có thể lướt web ẩn danh

00:11:32.493 --> 00:11:35.171
gửi emails mà chỉ có người nhận mới đọc được

00:11:35.171 --> 00:11:38.880
còn cả Cục An ninh Quốc gia cũng không đọc được

00:11:38.880 --> 00:11:41.877
Chúng ta thậm chí có thể khai thác dữ liệu 
mà vẫn bảo đảm riêng tư

00:11:41.877 --> 00:11:45.771
Nói cách khác, chúng ta có thể hưởng ích lợi của

00:11:45.771 --> 00:11:47.903
dữ liệu khổng lồ mà vẫn bảo đảm riêng tư.

00:11:47.903 --> 00:11:51.694
Tất nhiên, những công nghệ này gợi ý

00:11:51.694 --> 00:11:53.240
một sự chuyển biến về chi phí và thu nhập

00:11:53.240 --> 00:11:55.347
giữa người nắm giữ dữ liệu 
và người cung cấp dữ liệu.

00:11:55.347 --> 00:11:58.800
Đó có lẽ là lí do bạn không biết nhiều về họ.

00:11:58.800 --> 00:12:02.506
Và điều này mang tôi quay lại Vườn Địa Đàng.

00:12:02.506 --> 00:12:05.286
Có một cách hiểu khác về sự riêng tư

00:12:05.286 --> 00:12:07.095
trong câu chuyện trong Vườn Địa Đàng

00:12:07.095 --> 00:12:09.191
mà không liên quan đến việc

00:12:09.191 --> 00:12:11.416
Adam và Eve khỏa thân

00:12:11.416 --> 00:12:13.797
và cảm thấy xấu hổ.

00:12:13.797 --> 00:12:16.578
Bạn có thể tìm hiểu về cách hiểu này

00:12:16.578 --> 00:12:19.360
trong cuốn "Paradise Lost" của John Milton.

00:12:19.360 --> 00:12:23.557
Trong Vườn Địa Đàng, Adam and Eve
thỏa mãn về vật chất.

00:12:23.557 --> 00:12:25.661
Họ hạnh phúc và hài lòng.

00:12:25.661 --> 00:12:27.954
Tuy nhiên, họ thiếu hiểu biết

00:12:27.954 --> 00:12:29.594
và nhận thức về bản thân.

00:12:29.594 --> 00:12:32.913
Khoảnh khắc họ ăn

00:12:32.913 --> 00:12:34.206
"trái cây trí tuệ"

00:12:34.206 --> 00:12:36.811
là lúc họ phát hiện bản thân.

00:12:36.811 --> 00:12:40.842
Họ ý thức được bản thân. 
Họ đạt được quyền tự quyết.

00:12:40.842 --> 00:12:43.968
Cái giá phải trả, tuy nhiên, là rời khỏi khu vườn.

00:12:43.968 --> 00:12:47.849
Nên sự riêng tư, 1 cách nào đó, vừa là phương tiện

00:12:47.849 --> 00:12:50.811
vừa là cái giá của tự do.

00:12:50.811 --> 00:12:53.581
Một lần nữa, nhà quảng cáo nói với chúng ta

00:12:53.581 --> 00:12:56.600
dữ liệu khổng lồ và mạng xã hội

00:12:56.600 --> 00:12:59.579
không chỉ là thiên đường lợi nhuận cho họ

00:12:59.579 --> 00:13:02.036
mà còn là Vườn Địa Đàng cho tất cả chúng ta.

00:13:02.036 --> 00:13:03.274
Chúng ta được nội dung miễn phí

00:13:03.274 --> 00:13:06.397
được chơi Angry Birds, 
nhận ứng dụng nhắm đến chúng ta.

00:13:06.397 --> 00:13:09.294
Nhưng thực ra, trong vài năm tới, các tổ chức

00:13:09.294 --> 00:13:10.903
sẽ biết quá nhiều về chúng ta,

00:13:10.903 --> 00:13:13.613
đến mức có thể suy luận ham muốn của chúng ta

00:13:13.613 --> 00:13:15.817
trước cả khi chúng ta có mong muốn đó,

00:13:15.817 --> 00:13:18.264
và có lẽ mua sản phẩm hộ chúng ta

00:13:18.264 --> 00:13:20.538
trước cả khi chúng ta biết mình cần sản phẩm đó.

00:13:20.538 --> 00:13:23.775
Có một nhà văn người Anh

00:13:23.775 --> 00:13:26.820
đã tiên đoán tương lai như thế này

00:13:26.820 --> 00:13:28.225
khi mà chúng ta đánh đổi

00:13:28.225 --> 00:13:31.773
quyền tự do tự quyết để lấy sự thoải mái

00:13:31.773 --> 00:13:33.934
Thậm chí hơn cả George Orwell,

00:13:33.934 --> 00:13:36.695
nhà văn đó, đương nhiên, là Aldous Huxley.

00:13:36.695 --> 00:13:39.549
Trong cuốn "Brave New World", 
ông tưởng tượng một xã hội

00:13:39.549 --> 00:13:41.720
nơi những công nghệ chúng ta chế tạo

00:13:41.720 --> 00:13:43.579
vốn để hướng đến tự do

00:13:43.579 --> 00:13:46.146
cuối cùng lại kìm buộc chúng ta.

00:13:46.146 --> 00:13:50.937
Tuy nhiên, trong cuốn sách đó, ông cũng đưa ra

00:13:50.937 --> 00:13:54.375
lối thoát khỏi xã hội như thế, giống như con đường

00:13:54.375 --> 00:13:58.330
Adam và Eve phải đi để rời khỏi Vườn Địa Đàng.

00:13:58.330 --> 00:14:00.477
Như Savage đã nói,

00:14:00.477 --> 00:14:03.546
chúng ta có thể lấy lại quyền tự quyết và tự do

00:14:03.546 --> 00:14:06.225
mặc dù cái giá phải trả sẽ rất đắt.

00:14:06.225 --> 00:14:11.940
Tôi tin rằng, một trong những cuộc chiến điển hình

00:14:11.940 --> 00:14:14.503
của thời nay sẽ là cuộc chiến

00:14:14.503 --> 00:14:16.890
giành quyền điều khiển thông tin cá nhân

00:14:16.890 --> 00:14:20.397
để quyết định dữ liệu khổng lồ sẽ trở thành

00:14:20.397 --> 00:14:21.686
thế lực cho tự do

00:14:21.686 --> 00:14:26.432
chứ không phải là thế lực 
ngấm ngầm chi phối chúng ta .

00:14:26.432 --> 00:14:29.025
Ngay bây giờ, rất nhiều trong số chúng ta

00:14:29.025 --> 00:14:31.778
thậm chí không biết cuộc chiến này đang diễn ra

00:14:31.778 --> 00:14:34.450
nhưng nó đang diễn ra, dù bạn muốn hay không.

00:14:34.450 --> 00:14:37.254
Và trước nguy cơ đùa với rắn hổ mang,

00:14:37.254 --> 00:14:40.151
tôi sẽ nói cho bạn biết rằng
công cụ cho cuộc chiến

00:14:40.151 --> 00:14:43.160
là ở ngay đây, trong nhận thức 
về những gì đang diễn ra

00:14:43.160 --> 00:14:44.515
và ở trong tay bạn,

00:14:44.515 --> 00:14:48.255
chỉ cách bạn một vài clicks chuột.

00:14:48.255 --> 00:14:49.737
Xin cảm ơn!

00:14:49.737 --> 00:14:54.214
(Vỗ tay)

