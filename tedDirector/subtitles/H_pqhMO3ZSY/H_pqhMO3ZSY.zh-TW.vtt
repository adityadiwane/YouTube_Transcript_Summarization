WEBVTT
Kind: captions
Language: zh-TW

00:00:00.000 --> 00:00:07.000
譯者: Bert Chen
審譯者: Kuo-Hsien Chiang

00:00:12.641 --> 00:00:14.995
我想告訴各位一則故事

00:00:14.995 --> 00:00:18.171
是著名的亞當和夏娃隱私事件

00:00:18.171 --> 00:00:20.940
是著名的亞當和夏娃隱私事件

00:00:20.940 --> 00:00:24.386
以及這10年來, 在公眾與個人之間分界的重大改變

00:00:24.386 --> 00:00:27.072
以及這10年來, 在公眾與個人之間分界的重大改變

00:00:27.072 --> 00:00:28.842
以及這10年來, 在公眾與個人之間分界的重大改變

00:00:28.842 --> 00:00:30.140
你知道這起事件

00:00:30.140 --> 00:00:33.470
有一天亞當和夏娃在伊甸園

00:00:33.470 --> 00:00:35.313
發現他們都沒穿衣服

00:00:35.313 --> 00:00:36.813
他們嚇壞了

00:00:36.813 --> 00:00:39.570
其餘的部分你們都知道了

00:00:39.570 --> 00:00:41.758
換做是現在的話, 亞當和夏娃

00:00:41.758 --> 00:00:44.119
可能會有不同的反應

00:00:44.119 --> 00:00:46.387
(twitter)@亞當 昨晚的表現真是精采! 愛死那顆蘋果了

00:00:46.387 --> 00:00:48.260
(twitter)@夏娃 寶貝你知道我的褲子怎麼了嗎?

00:00:48.260 --> 00:00:50.896
在網路上, 我們都比從前透露出更多關於自己的訊息

00:00:50.896 --> 00:00:54.230
在網路上, 我們都比從前透露出更多關於自己的訊息

00:00:54.230 --> 00:00:55.934
而這些有關我們的訊息

00:00:55.934 --> 00:00:58.158
正被許多政府機構收集起來

00:00:58.158 --> 00:01:01.440
現在可以從分析個人資訊或是巨量資料中得到許多利益

00:01:01.440 --> 00:01:03.886
現在可以從分析個人資訊或是巨量資料中得到許多利益

00:01:03.886 --> 00:01:05.832
現在可以從分析個人資訊或是巨量資料中得到許多利益

00:01:05.832 --> 00:01:08.470
但是在捨棄隱私權的同時, 也伴隨著複雜的得失交換

00:01:08.470 --> 00:01:11.568
但是在捨棄隱私權的同時, 也伴隨著複雜的得失交換

00:01:11.568 --> 00:01:15.591
我要講的故事是有關這些得失交換

00:01:15.591 --> 00:01:18.175
我們先從觀察開始

00:01:18.175 --> 00:01:21.502
在我看來, 過去幾年中, 這個情況已經變得越來越明確

00:01:21.502 --> 00:01:23.599
任何個人資訊

00:01:23.599 --> 00:01:25.884
都能變成敏感的訊息

00:01:25.884 --> 00:01:30.009
回朔到西元2000年的時候,

00:01:30.009 --> 00:01:31.921
全世界上所有人約拍出1000億張照片

00:01:31.921 --> 00:01:34.986
但是只有極少數的照片

00:01:34.986 --> 00:01:36.869
被上傳到網路上

00:01:36.869 --> 00:01:40.230
在2010年 光是一個月, Facebook用戶就上傳25億張照片

00:01:40.230 --> 00:01:43.500
在2010年時 光是一個月, Facebook用戶就上傳25億張照片

00:01:43.500 --> 00:01:45.382
而多數照片上的人都可以被辨識出來

00:01:45.382 --> 00:01:47.262
在這段時間裡

00:01:47.262 --> 00:01:52.132
辨認照片內人物的電腦運算能力

00:01:52.132 --> 00:01:55.740
也加快了1000倍

00:01:55.740 --> 00:01:57.622
如果將這些技術結合起來

00:01:57.622 --> 00:01:59.123
會發生什麼事?

00:01:59.123 --> 00:02:01.781
取得了更多的臉部資料

00:02:01.781 --> 00:02:05.429
改善了電腦臉部辨識的能力

00:02:05.429 --> 00:02:07.611
還有雲端運算

00:02:07.611 --> 00:02:09.499
這會給與現場任何一個人

00:02:09.499 --> 00:02:11.059
一種運算能力

00:02:11.059 --> 00:02:12.945
而這種運算能力在幾年前只專屬於

00:02:12.945 --> 00:02:14.727
那些政府機構

00:02:14.727 --> 00:02:16.105
這種普及的運算能力

00:02:16.105 --> 00:02:18.997
能讓我的普通手機

00:02:18.997 --> 00:02:20.668
連上網際網路

00:02:20.668 --> 00:02:23.002
在幾秒之內進行數十萬次的人臉辨識

00:02:23.002 --> 00:02:25.641
在幾秒之內進行數十萬次的人臉辨識

00:02:25.641 --> 00:02:28.269
我們推測這些

00:02:28.269 --> 00:02:30.333
技術結合的結果

00:02:30.333 --> 00:02:33.221
會顛覆我們

00:02:33.221 --> 00:02:35.478
對於隱私權與匿名性最初的想法

00:02:35.478 --> 00:02:37.471
為了進行測試 我們做了一項實驗

00:02:37.471 --> 00:02:39.592
在卡內基美隆大學的校園裡

00:02:39.592 --> 00:02:41.691
我們找路過的學生

00:02:41.691 --> 00:02:43.470
來參與這項研究

00:02:43.470 --> 00:02:46.032
我們拿視訊攝影機拍照

00:02:46.032 --> 00:02:48.814
請他們用筆電填寫問卷調查

00:02:48.814 --> 00:02:50.793
他們在填寫問卷的時候

00:02:50.793 --> 00:02:53.590
上傳他們的照片到一個雲端運算群組

00:02:53.590 --> 00:02:55.317
使用一個臉部辨識系統

00:02:55.317 --> 00:02:57.722
將這組照片拿去與

00:02:57.722 --> 00:03:00.115
一個約有數十萬張圖像的資料庫比對

00:03:00.115 --> 00:03:03.711
這些圖像是我們從Facebook的個人簡介下載下來的

00:03:03.711 --> 00:03:06.970
等到受測者填寫到問卷最後一頁的時候

00:03:06.970 --> 00:03:10.317
畫面會更新成辨識器找出的10張最相符的照片

00:03:10.317 --> 00:03:12.630
畫面會更新成辨識器找出的10張最相符的照片

00:03:12.630 --> 00:03:14.915
畫面會更新成辨識器找出的10張最相符的照片

00:03:14.915 --> 00:03:16.653
我們要求受測者指出

00:03:16.653 --> 00:03:20.773
是否有在這些照片中找到他們自己

00:03:20.773 --> 00:03:24.472
你有看到這名受測者嗎?

00:03:24.472 --> 00:03:27.317
是的, 電腦有找到

00:03:27.317 --> 00:03:29.466
三人之中就有一人被找到

00:03:29.466 --> 00:03:32.650
基本上 我們能夠從一張不知名的臉開始,

00:03:32.650 --> 00:03:36.134
不管是離線或在線 我們都能利用臉部辨識

00:03:36.134 --> 00:03:38.494
讓一張不知名的臉找到它的名字

00:03:38.494 --> 00:03:40.602
這都是拜社群媒體資料庫所賜

00:03:40.602 --> 00:03:42.474
但是幾年前 我們又做其他的事情

00:03:42.474 --> 00:03:44.297
我們從社群媒體開始著手-

00:03:44.297 --> 00:03:47.348
我們將它與美國社會安全局的資料做結合

00:03:47.348 --> 00:03:49.450
我們將它與美國社會安全局的資料做結合

00:03:49.450 --> 00:03:52.774
我們可以猜出個人的社會安全號碼

00:03:52.774 --> 00:03:54.286
這在美國是一項極度敏感的個人資訊

00:03:54.286 --> 00:03:56.326
這在美國是一項極度敏感的個人資訊

00:03:56.326 --> 00:03:58.419
你知道我在講什麼嗎?

00:03:58.419 --> 00:04:01.341
所以如果你們將兩種研究結果加在一起,

00:04:01.341 --> 00:04:02.853
那這個問題就會變成

00:04:02.853 --> 00:04:05.573
你能從一張臉開始

00:04:05.573 --> 00:04:07.884
利用臉部辨識技術 找到他的名字

00:04:07.884 --> 00:04:10.553
找到這個人的公開資訊

00:04:10.553 --> 00:04:12.485
找到這個人的公開資訊

00:04:12.485 --> 00:04:14.733
再從公開資訊

00:04:14.733 --> 00:04:16.775
推測出那些更加敏感的非公開資訊

00:04:16.775 --> 00:04:18.381
推測出那些更加敏感的非公開資訊

00:04:18.381 --> 00:04:19.873
然後你再回想起這張臉嗎?

00:04:19.873 --> 00:04:21.789
答案是可以的, 而且我們也做到了

00:04:21.789 --> 00:04:24.357
當然, 準確度還不是很好

00:04:24.357 --> 00:04:25.301
在四次嘗試中, 可以辨識出27%受測者的社會安全號碼前五碼

00:04:25.301 --> 00:04:29.128
但事實上 我們甚至決定做一個 iPhone app

00:04:29.128 --> 00:04:31.843
利用手機內建像機

00:04:31.843 --> 00:04:33.443
幫受測者拍一張照片

00:04:33.443 --> 00:04:34.930
然後上傳至雲端網路

00:04:34.930 --> 00:04:37.592
接下來馬上就像我對大家描述的一樣

00:04:37.592 --> 00:04:39.680
即時找出相符的臉, 找出公開資訊

00:04:39.680 --> 00:04:41.410
試著推斷敏感的私人資訊

00:04:41.410 --> 00:04:44.001
然後傳回手機

00:04:44.001 --> 00:04:47.610
這些資訊會顯示在受測者的臉部照片旁

00:04:47.610 --> 00:04:49.511
這是一個擴增實境的例子

00:04:49.511 --> 00:04:51.962
也許是一個會令人毛骨悚然的擴增實境案例

00:04:51.962 --> 00:04:55.301
事實上我們並沒有讓這個app上市

00:04:55.301 --> 00:04:57.223
只是做為一種觀念的證明

00:04:57.223 --> 00:04:59.536
事實上, 利用這些科技到極致的時候

00:04:59.536 --> 00:05:01.373
事實上, 利用這些科技到極致的時候

00:05:01.373 --> 00:05:04.092
想像一下未來, 你身旁的陌生人

00:05:04.092 --> 00:05:06.403
能透過Google眼鏡來看你

00:05:06.403 --> 00:05:08.710
或者有一天 隱形眼鏡也能做到同樣的事情

00:05:08.710 --> 00:05:12.730
使用七或八個有關於你的資訊

00:05:12.730 --> 00:05:15.312
去推測其他

00:05:15.312 --> 00:05:17.915
可能與你相關的事

00:05:17.915 --> 00:05:22.709
沒有秘密的未來會是什麼樣子?

00:05:22.709 --> 00:05:24.673
我們應該關心這個嗎?

00:05:24.673 --> 00:05:26.564
我們可能比較願意去相信

00:05:26.564 --> 00:05:29.604
一個有這麼多數據資料的未來

00:05:29.604 --> 00:05:32.118
會是一個沒有偏差的未來

00:05:32.118 --> 00:05:35.701
但是, 事實上, 擁有這麼多資訊

00:05:35.701 --> 00:05:37.892
不表示我們能夠做出

00:05:37.892 --> 00:05:39.598
更客觀的決定

00:05:39.598 --> 00:05:42.158
在另一個實驗裡 我們把求職者的資訊給受測者看

00:05:42.158 --> 00:05:44.404
在另一個實驗裡 我們把求職者的資訊給受測者看

00:05:44.404 --> 00:05:47.582
我們的資料含括

00:05:47.582 --> 00:05:50.228
關於一些有趣, 絕對合法

00:05:50.228 --> 00:05:52.693
但也許稍微有點尷尬的訊息

00:05:52.693 --> 00:05:54.713
這些都是受測者張貼在網路上的資訊

00:05:54.713 --> 00:05:57.079
有趣的是 我們實驗的對象中

00:05:57.079 --> 00:06:00.162
有些人也發表了類似的訊息

00:06:00.162 --> 00:06:02.524
但有些人則沒有

00:06:02.524 --> 00:06:04.473
你認為哪一組人

00:06:04.473 --> 00:06:09.025
比較可能嚴厲批評我們的受測者?

00:06:09.025 --> 00:06:10.982
答案出乎意料的是

00:06:10.982 --> 00:06:12.715
那些發表類似訊息的人

00:06:12.715 --> 00:06:15.657
這也是種道德觀念不一致的例子

00:06:15.657 --> 00:06:17.407
現在你可能正在想

00:06:17.407 --> 00:06:19.109
這對我來說沒用

00:06:19.109 --> 00:06:21.271
因為我沒有什麼要藏的東西

00:06:21.271 --> 00:06:23.753
但事實上 隱私不只是

00:06:23.753 --> 00:06:27.429
有什麼不好的東西要藏起來而已

00:06:27.429 --> 00:06:29.783
想像你是某個組織的人事主管

00:06:29.783 --> 00:06:32.730
你收到應徵者寄來的履歷

00:06:32.730 --> 00:06:35.203
你決定要找出更多該名應徵者的訊息

00:06:35.203 --> 00:06:37.663
因此 你就在google上搜尋他們的名字

00:06:37.663 --> 00:06:39.903
在特定時空

00:06:39.903 --> 00:06:41.911
你可以找到這筆資訊

00:06:41.911 --> 00:06:46.348
或是在平行時空 你找到這筆資訊

00:06:46.348 --> 00:06:49.065
你認為你會同樣的

00:06:49.065 --> 00:06:51.868
打電話通知應徵者前來面試嗎?

00:06:51.868 --> 00:06:54.150
如果你這麼認為,

00:06:54.150 --> 00:06:56.732
那你就不像美國雇主

00:06:56.732 --> 00:07:00.039
事實上, 他們也在我們的實驗當中

00:07:00.039 --> 00:07:03.221
我們創造了一些Facebook個人簡介,

00:07:03.221 --> 00:07:06.072
然後寄送履歷到美國各家公司

00:07:06.072 --> 00:07:07.980
然後我們偵查、監控

00:07:07.980 --> 00:07:10.373
看是否他們正在上網搜尋我們的應徵者

00:07:10.373 --> 00:07:12.205
並且依照這些社群媒體上找到的資訊做事.

00:07:12.205 --> 00:07:14.143
他們真的這麼作.

00:07:14.143 --> 00:07:16.244
透過社群媒體, 對技能相當的應徵者們來說

00:07:16.244 --> 00:07:19.317
也會發生不公平待遇的事情

00:07:19.317 --> 00:07:23.892
現在行銷的人想讓我們相信

00:07:23.892 --> 00:07:26.161
所有關於我們的個人資訊都會

00:07:26.161 --> 00:07:29.434
用在對我們有利的面向

00:07:29.434 --> 00:07:33.149
但是再想想, 真的會這樣嗎?

00:07:33.149 --> 00:07:35.813
幾年前上映的一部電影

00:07:35.813 --> 00:07:38.366
「關鍵報告」裡一個著名的場景

00:07:38.366 --> 00:07:40.942
就是湯姆克‧魯斯走進一間賣場

00:07:40.942 --> 00:07:44.718
有一個個人化的雷射投影廣告

00:07:44.718 --> 00:07:46.553
出現在他旁邊

00:07:46.553 --> 00:07:49.780
那部電影的時空背景設定於2054年

00:07:49.780 --> 00:07:51.422
從現在算起 大約是40年之後

00:07:51.422 --> 00:07:54.330
那種技術看起來很精彩

00:07:54.330 --> 00:07:56.976
它已經大大低估

00:07:56.976 --> 00:07:59.116
各組織能夠匯集起有關你個人的資料量

00:07:59.116 --> 00:08:01.599
與他們是如何運用這些資料

00:08:01.599 --> 00:08:04.997
以某一個你無法查覺的方式, 對你造成影響

00:08:04.997 --> 00:08:07.100
還有一個例子 這是另一項實驗

00:08:07.100 --> 00:08:09.373
是我們正在進行中的實驗, 還沒有完成

00:08:09.373 --> 00:08:11.692
想像一個組織能夠進入

00:08:11.692 --> 00:08:13.748
你的Facebook好友清單

00:08:13.748 --> 00:08:15.520
透過某種運算規則

00:08:15.520 --> 00:08:19.254
他們可以偵測到你最喜歡的兩個好友

00:08:19.254 --> 00:08:21.534
然後他們就能即時創造出

00:08:21.534 --> 00:08:24.376
由這兩個好友所組成的臉部合成照

00:08:24.376 --> 00:08:27.445
在我們之前有研究已經顯示

00:08:27.445 --> 00:08:30.330
人們在看臉部合成照, 連他們自己都認不出來

00:08:30.330 --> 00:08:32.792
人們在看臉部合成照, 連他們自己都認不出來

00:08:32.792 --> 00:08:34.909
但是他們對那些合成照有正面評價

00:08:34.909 --> 00:08:38.324
所以下次你在找某項產品

00:08:38.324 --> 00:08:40.883
此時有一個建議購買的廣告

00:08:40.883 --> 00:08:43.790
廣告將不會是一個固定的代言人

00:08:43.790 --> 00:08:46.103
他很可能是你其中一位朋友

00:08:46.103 --> 00:08:49.406
你甚至不知道這種事正發生在你的生活中

00:08:49.406 --> 00:08:51.819
現在問題就是

00:08:51.819 --> 00:08:54.338
目前政策機制是我們必須

00:08:54.338 --> 00:08:57.776
保護我們自己免於個人資料遭到濫用

00:08:57.776 --> 00:09:00.760
這就像是以卵擊石

00:09:00.760 --> 00:09:03.673
其中一項機制就是資訊透明化

00:09:03.673 --> 00:09:06.873
你必須告訴人們你想拿他們資料做什麼

00:09:06.873 --> 00:09:08.979
原則上 這是一件非常好的事情

00:09:08.979 --> 00:09:12.646
這是應該的, 但是這麼做還不夠

00:09:12.646 --> 00:09:16.344
資訊透明化的方向可能會被誤導

00:09:16.344 --> 00:09:18.448
你可以告訴大家你想做什麼

00:09:18.448 --> 00:09:20.680
然後你促使他人揭露

00:09:20.680 --> 00:09:23.303
或多或少的個人資訊

00:09:23.303 --> 00:09:26.189
在另一項實驗中, 實驗對象是學生

00:09:26.189 --> 00:09:29.247
我們要求他們提供個人資訊

00:09:29.247 --> 00:09:31.060
關於他們在學校裡做的事

00:09:31.060 --> 00:09:34.000
包括一些相當敏感的問題 就像這一個

00:09:34.000 --> 00:09:34.621
在考試的時候 你有作弊過嗎?

00:09:34.621 --> 00:09:36.921
對其中一組受測者, 我們告訴他們

00:09:36.921 --> 00:09:39.762
只有其他的同學會看到你的答案

00:09:39.762 --> 00:09:41.341
對另一組受測者 我們告訴他們

00:09:41.341 --> 00:09:44.902
所有學生和教職員都會看到你的答案

00:09:44.902 --> 00:09:47.493
透明化 告知. 這真的有用.

00:09:47.493 --> 00:09:48.900
第一組受測者

00:09:48.900 --> 00:09:51.468
比第二組受測者更有可能公佈事實

00:09:51.468 --> 00:09:52.988
合理吧?

00:09:52.988 --> 00:09:54.478
但是之後我們加入誤導手段

00:09:54.478 --> 00:09:57.238
我們對相同兩組學生重覆進行實驗

00:09:57.238 --> 00:09:59.665
這次在不同的時間告訴受測者我們是如何使用他們的資料

00:09:59.665 --> 00:10:02.600
這次在不同的時間告訴受測者我們是如何使用他們的資料

00:10:02.600 --> 00:10:04.680
這次在不同的時間告訴受測者我們是如何使用他們的資料

00:10:04.680 --> 00:10:09.068
現在我們知道了

00:10:09.068 --> 00:10:11.629
你認為我們必須要延遲多久時間

00:10:11.629 --> 00:10:16.242
為使這種抑制效應無效

00:10:16.242 --> 00:10:19.653
而這種效應就是知道教職員會看見你的答案?

00:10:19.653 --> 00:10:21.433
10分鐘?

00:10:21.433 --> 00:10:23.224
5分鐘?

00:10:23.224 --> 00:10:25.000
1分鐘?

00:10:25.000 --> 00:10:27.049
15秒怎樣?

00:10:27.049 --> 00:10:29.717
15秒就足夠讓兩組人

00:10:29.717 --> 00:10:31.285
透露出相同資訊量

00:10:31.285 --> 00:10:34.031
就好像第二組人現在不再關心教職員會看他們的答案

00:10:34.031 --> 00:10:36.687
就好像第二組人現在不再關心教職員會看他們的答案

00:10:36.687 --> 00:10:40.023
現在我必須承認目前為止我說的這些話

00:10:40.023 --> 00:10:42.503
可能聽起來非常沉悶

00:10:42.503 --> 00:10:44.224
但我要說的不是這個

00:10:44.224 --> 00:10:46.923
事實上 我想與大家分享的是

00:10:46.923 --> 00:10:48.695
還有替代方案

00:10:48.695 --> 00:10:51.194
我們現在實驗的方式

00:10:51.194 --> 00:10:54.231
並不是唯一可行的方式

00:10:54.231 --> 00:10:56.258
當然也不是最好的辦法

00:10:56.258 --> 00:11:00.429
有人告訴你 「沒人會在乎他的隱私」

00:11:00.429 --> 00:11:03.071
想想看是否這場遊戲已經遭到設計

00:11:03.071 --> 00:11:05.795
暗中操作 所以他們才不在意隱私權

00:11:05.795 --> 00:11:09.057
逐漸發現這些操作手段的已經入侵到那些能夠能夠保護你的方法中

00:11:09.057 --> 00:11:10.664
逐漸發現這些操作手段的已經入侵到那些能夠能夠保護你的方法中

00:11:10.664 --> 00:11:12.922
逐漸發現這些操作手段的已經入侵到那些能夠能夠保護你的方法中

00:11:12.922 --> 00:11:16.632
有人告訴你隱私

00:11:16.632 --> 00:11:18.481
與巨量資料所帶來的利益是無法共存的

00:11:18.481 --> 00:11:20.954
想想看近20年

00:11:20.954 --> 00:11:22.871
研究人員已經研發出數套技術

00:11:22.871 --> 00:11:26.189
讓幾乎所有電子交易

00:11:26.189 --> 00:11:29.938
能夠在有更高度的隱私環境下進行

00:11:29.938 --> 00:11:32.493
我們可以匿名瀏覽網頁

00:11:32.493 --> 00:11:35.171
傳送唯讀電子郵件

00:11:35.171 --> 00:11:38.880
這些電子郵件僅能由指定的收件者閱讀
就連國家安全局都沒辦法查看

00:11:38.880 --> 00:11:41.877
我們甚至能在隱私受到保護的情況下
進行資料開採

00:11:41.877 --> 00:11:45.771
另一方面, 在保護隱私權的同時, 我們仍擁有巨量資料所帶來的好處

00:11:45.771 --> 00:11:47.903
另一方面, 在保護隱私權的同時, 我們仍擁有巨量資料所帶來的好處

00:11:47.903 --> 00:11:51.694
當然 這些技術也可以看出,

00:11:51.694 --> 00:11:53.240
在資料持有人與資料提供者之間

00:11:53.240 --> 00:11:55.347
利益的變化

00:11:55.347 --> 00:11:58.800
這也許是為什麼你沒有聽過太多有關這些技術的事情

00:11:58.800 --> 00:12:02.506
就讓我將話題轉回伊甸園

00:12:02.506 --> 00:12:05.286
有第二種

00:12:05.286 --> 00:12:07.095
對伊甸園故事的隱私解釋

00:12:07.095 --> 00:12:09.191
這與亞當和夏娃

00:12:09.191 --> 00:12:11.416
覺得全身赤裸

00:12:11.416 --> 00:12:13.797
和感到羞恥沒有關係

00:12:13.797 --> 00:12:16.578
你可以在約翰·密爾頓的《失樂園》裡發現對於這個解釋的迴響

00:12:16.578 --> 00:12:19.360
你可以在約翰·密爾頓的《失樂園》裡發現對於這個解釋的迴響

00:12:19.360 --> 00:12:23.557
在伊甸園裡 亞當和夏娃只是物品

00:12:23.557 --> 00:12:25.661
他們很快樂 很滿足

00:12:25.661 --> 00:12:27.954
然而 他們也缺乏知識

00:12:27.954 --> 00:12:29.594
和自覺

00:12:29.594 --> 00:12:32.913
此刻他們恰好吃下名叫

00:12:32.913 --> 00:12:34.206
「知識」的水果

00:12:34.206 --> 00:12:36.811
就在那時他們才發現自我

00:12:36.811 --> 00:12:40.842
他們開始擁有自覺和自主能力

00:12:40.842 --> 00:12:43.968
然而 所付出的代價就是必須離開伊甸園

00:12:43.968 --> 00:12:47.849
所以, 隱私權是自由的意義也是代價

00:12:47.849 --> 00:12:50.811
所以, 隱私權是自由的意義也是代價

00:12:50.811 --> 00:12:53.581
市場商人告訴我們

00:12:53.581 --> 00:12:56.600
巨量資料與社群媒體

00:12:56.600 --> 00:12:59.579
不只對於他們是獲利的天堂

00:12:59.579 --> 00:13:02.036
對我們其餘的人也是座伊甸園

00:13:02.036 --> 00:13:03.274
我們可以得到免費的內容

00:13:03.274 --> 00:13:06.397
我們可以玩憤怒鳥 使用挑選好的app

00:13:06.397 --> 00:13:09.294
實際上,在幾年之內

00:13:09.294 --> 00:13:10.903
政府機構將知道許多關於我們的資訊

00:13:10.903 --> 00:13:13.613
他們能在我們想到之前推斷我們想做的事情

00:13:13.613 --> 00:13:15.817
他們能在我們想到之前推斷我們想做的事情

00:13:15.817 --> 00:13:18.264
也許在我們知道我們需要這些東西之前, 就替我們購買產品

00:13:18.264 --> 00:13:20.538
也許在我們知道我們需要這些東西之前, 就替我們購買產品

00:13:20.538 --> 00:13:23.775
現在有一名英國作家

00:13:23.775 --> 00:13:26.820
考慮到未來可能會發生這種情況

00:13:26.820 --> 00:13:28.225
到時候我們可能會為了過舒適的生活

00:13:28.225 --> 00:13:31.773
而賤賣我們的自主能力與自由

00:13:31.773 --> 00:13:33.934
其著作比喬治·歐威爾還多

00:13:33.934 --> 00:13:36.695
這名作家當然就是奧爾德斯·赫胥黎

00:13:36.695 --> 00:13:39.549
在《美麗新世界》書中 他想像出一個社會

00:13:39.549 --> 00:13:41.720
那裡的科技是

00:13:41.720 --> 00:13:43.579
我們為了自由而創造的技術

00:13:43.579 --> 00:13:46.146
最後我們反被科技奴役

00:13:46.146 --> 00:13:50.937
然而 在書中 他也提供我們一個逃離

00:13:50.937 --> 00:13:54.375
那個社會的方式 與那條路很像

00:13:54.375 --> 00:13:58.330
就是亞當和夏娃離開伊甸園的那條路

00:13:58.330 --> 00:14:00.477
就「野蠻人」這個詞而言

00:14:00.477 --> 00:14:03.546
重新找回自主能力和自由是可行的

00:14:03.546 --> 00:14:06.225
雖然需要付出的代價實在太高

00:14:06.225 --> 00:14:11.940
所以我相信我們這個時代的

00:14:11.940 --> 00:14:14.503
其中一個決定性的戰鬥將會是

00:14:14.503 --> 00:14:16.890
為掌控個人資訊而戰

00:14:16.890 --> 00:14:20.397
不管巨量資料是否將成為一股迎向自由的力量

00:14:20.397 --> 00:14:21.686
這場戰鬥終將結束

00:14:21.686 --> 00:14:26.432
而不會成為一股暗中操縱我們的力量-

00:14:26.432 --> 00:14:29.025
現在 我們當中許多人

00:14:29.025 --> 00:14:31.778
甚至都不知道 戰鬥正在進行

00:14:31.778 --> 00:14:34.450
不管你喜不喜歡 這就是現況

00:14:34.450 --> 00:14:37.254
冒著玩弄魔鬼的危險

00:14:37.254 --> 00:14:40.151
我告訴各位, 這場戰爭的工具就在這裡

00:14:40.151 --> 00:14:43.160
了解現在發生什麼事

00:14:43.160 --> 00:14:44.515
就掌握在你手裡

00:14:44.515 --> 00:14:48.255
只要用滑鼠點幾下就行了

00:14:48.255 --> 00:14:49.737
謝謝大家

00:14:49.737 --> 00:14:54.214
(掌聲)

