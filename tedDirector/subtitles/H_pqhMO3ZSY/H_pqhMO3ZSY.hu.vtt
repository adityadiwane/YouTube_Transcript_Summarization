WEBVTT
Kind: captions
Language: hu

00:00:00.000 --> 00:00:07.000
Fordító: Judit Szabo
Lektor: Anna Patai

00:00:12.641 --> 00:00:14.995
Szeretnék elmesélni egy történetet,

00:00:14.995 --> 00:00:18.171
amely összekapcsolja a közismert

00:00:18.171 --> 00:00:20.940
Ádám és Éva magánjogi esetet

00:00:20.940 --> 00:00:24.386
és az elmúlt tíz évben megfigyelhető

00:00:24.386 --> 00:00:27.072
nyilvánosság és magánügy közötti

00:00:27.072 --> 00:00:28.842
határeltolódást.

00:00:28.842 --> 00:00:30.140
Ismerik a történetet.

00:00:30.140 --> 00:00:33.470
Ádám és Éva az Édenkertben egy nap rájöttek,

00:00:33.470 --> 00:00:35.313
hogy meztelenek.

00:00:35.313 --> 00:00:36.813
Kiborultak.

00:00:36.813 --> 00:00:39.570
A többi már történelem.

00:00:39.570 --> 00:00:41.758
Manapság Ádám és Éva

00:00:41.758 --> 00:00:44.119
valószínűleg máshogy reagálna.

00:00:44.119 --> 00:00:46.387
@Adam: Király volt az este! Kösz az almát LOL

00:00:46.387 --> 00:00:48.260
@Eve: Jaja! Nem tudod hol a gatyám?

00:00:48.260 --> 00:00:50.896
Sokkal több információt osztunk meg

00:00:50.896 --> 00:00:54.230
magunkról online, mint valaha,

00:00:54.230 --> 00:00:55.934
és sokkal több információt

00:00:55.934 --> 00:00:58.158
gyűjtenek rólunk különböző szervezetek.

00:00:58.158 --> 00:01:01.440
Namármost, rengeteget lehet nyerni

00:01:01.440 --> 00:01:03.886
egy ilyen hatalmas személyi adathalmaz

00:01:03.886 --> 00:01:05.832
elemzéséből,

00:01:05.832 --> 00:01:08.470
de bonyolult kompromisszumokat is kötünk ám azzal,

00:01:08.470 --> 00:01:11.568
hogy lemondunk a magánjogainkról.

00:01:11.568 --> 00:01:15.591
Az én történetem ezekről a kompromisszumokról szól.

00:01:15.591 --> 00:01:18.175
Azzal a megállapítással kezdeném, ami számomra

00:01:18.175 --> 00:01:21.502
egyre és egyre világosabbá vált az elmúlt pár évben,

00:01:21.502 --> 00:01:23.599
mégpedig hogy a személyi adatok

00:01:23.599 --> 00:01:25.884
érzékeny adatokká válhatnak.

00:01:25.884 --> 00:01:30.009
2000-ben 100 milliárd fotó készült

00:01:30.009 --> 00:01:31.921
szerte a világon,

00:01:31.921 --> 00:01:34.986
de csak elenyésző részük

00:01:34.986 --> 00:01:36.869
került fel a netre.

00:01:36.869 --> 00:01:40.230
2010-ben, csak a Facebookon, egyetlen hónap alatt

00:01:40.230 --> 00:01:43.500
2,5 milliárd fotót töltenek fel,

00:01:43.500 --> 00:01:45.382
melyek nagy része beazonosított.

00:01:45.382 --> 00:01:47.262
Ez idő alatt

00:01:47.262 --> 00:01:52.132
a számítógépek arcfelismerési képessége

00:01:52.132 --> 00:01:55.740
három nagyságrenddel megugrott.

00:01:55.740 --> 00:01:57.622
Mi történik, ha összeadjuk

00:01:57.622 --> 00:01:59.123
e két technológiát:

00:01:59.123 --> 00:02:01.781
az egyre több rendelkezésre álló adatot,

00:02:01.781 --> 00:02:05.429
az egyre jobb arcfelismerő képességet,

00:02:05.429 --> 00:02:07.611
illetve a felhő alapú számítástechnikát,

00:02:07.611 --> 00:02:09.499
ami ezen a színtéren mindenkinek

00:02:09.499 --> 00:02:11.059
olyan számítási erőt biztosít,

00:02:11.059 --> 00:02:12.945
ami pár éve csak a hárombetűs intézmények

00:02:12.945 --> 00:02:14.727
kiváltsága volt;

00:02:14.727 --> 00:02:16.105
és a mindent elárasztó technológiát,

00:02:16.105 --> 00:02:18.997
amely által még a telefonom is, 
ami nem egy szuperszámítógép,

00:02:18.997 --> 00:02:20.668
csatlakozni tud az internethez

00:02:20.668 --> 00:02:23.002
és ott többezer arcbemérést

00:02:23.002 --> 00:02:25.641
tud elvégezni másodpercek alatt?

00:02:25.641 --> 00:02:28.269
Nos, kitalálhatjuk, hogy ennek

00:02:28.269 --> 00:02:30.333
a kombinációnak az eredménye

00:02:30.333 --> 00:02:33.221
radikálisan meg fogja változtatni, 
hogy hogyan gondolkodunk

00:02:33.221 --> 00:02:35.478
a magánjogokról és a névtelenségről.

00:02:35.478 --> 00:02:37.471
Elvégeztünk egy kísérletet ennek igazolására

00:02:37.471 --> 00:02:39.592
a Carnegie Mellon egyetemen.

00:02:39.592 --> 00:02:41.691
Arra járó hallgatókat megkértünk,

00:02:41.691 --> 00:02:43.470
hogy vegyenek részt egy felmérésben,

00:02:43.470 --> 00:02:46.032
lefotóztuk őket egy webkamerával,

00:02:46.032 --> 00:02:48.814
majd egy laptopon kitöltettünk velük egy kérdőívet.

00:02:48.814 --> 00:02:50.793
Miközben adták a válaszokat,

00:02:50.793 --> 00:02:53.590
feltöltöttük a fotóikat a felhőbe,

00:02:53.590 --> 00:02:55.317
majd lefuttattunk egy arcfelismerőt,

00:02:55.317 --> 00:02:57.722
hogy megkeresse az adott fotót

00:02:57.722 --> 00:03:00.115
többszázezer kép között,

00:03:00.115 --> 00:03:03.711
amelyeket Facebook adatlapokról töltöttünk le.

00:03:03.711 --> 00:03:06.970
Mire a válaszadó az utolsó oldalra ért

00:03:06.970 --> 00:03:10.317
a kérdőíven, az oldal dinamikusan frissítődött,

00:03:10.317 --> 00:03:12.630
feldobva a 10 legjobb találatot

00:03:12.630 --> 00:03:14.915
amire az arcfelismerő rábukkant,

00:03:14.915 --> 00:03:16.653
majd megkérdeztük a tesztalanyokat,

00:03:16.653 --> 00:03:20.773
hogy megtalálják-e magukat a fotón.

00:03:20.773 --> 00:03:24.472
Látják a tesztalanyt?

00:03:24.472 --> 00:03:27.317
Hát a számítógép látta, tulajdonképpen

00:03:27.317 --> 00:03:29.466
három esetből egyben.

00:03:29.466 --> 00:03:32.650
Alapvetően tehát kiindulhatunk egy névtelen arcból,

00:03:32.650 --> 00:03:36.134
offline vagy online, és arcfelismeréssel

00:03:36.134 --> 00:03:38.494
nevet tudunk rendelni ahhoz a képhez

00:03:38.494 --> 00:03:40.602
a közösségi oldalaknak köszönhetően.

00:03:40.602 --> 00:03:42.474
Pár évvel ezelőtt azonban mással próbálkoztunk.

00:03:42.474 --> 00:03:44.297
A közösségi oldalak adatait

00:03:44.297 --> 00:03:47.348
statisztikailag összekapcsoltuk

00:03:47.348 --> 00:03:49.450
az amerikai társadalombiztosítási rendszerrel,

00:03:49.450 --> 00:03:52.774
és így eljutottunk a TB-számokig,

00:03:52.774 --> 00:03:54.286
amik Amerikában

00:03:54.286 --> 00:03:56.326
különlegesen érzékeny információk.

00:03:56.326 --> 00:03:58.419
Látjátok, hova akarok kilyukadni ezzel?

00:03:58.419 --> 00:04:01.341
Tehát ha összefésülsz két kutatást,

00:04:01.341 --> 00:04:02.853
akkor a kérdés így hangzik:

00:04:02.853 --> 00:04:05.573
lehet-e egy arcképből kiindulva

00:04:05.573 --> 00:04:07.884
arcfelismeréssel megtalálni a nevet

00:04:07.884 --> 00:04:10.553
és egyéb nyilvános adatokat

00:04:10.553 --> 00:04:12.485
arról a névről és személyről,

00:04:12.485 --> 00:04:14.733
és a nyilvános adatokból

00:04:14.733 --> 00:04:16.775
kikövetkeztethetünk-e személyes adatokat,

00:04:16.775 --> 00:04:18.381
-- sokkal titkosabbakat --

00:04:18.381 --> 00:04:19.873
amik az archoz kapcsolódnak?

00:04:19.873 --> 00:04:21.789
A válasz igen, lehet, meg is tettük.

00:04:21.789 --> 00:04:24.357
A pontosság természetesen romlik.

00:04:24.357 --> 00:04:25.301
[4 próbálkozásból 27%-os találati 
arány a TB-szám első 5 jegyére]

00:04:25.301 --> 00:04:29.128
Egy iPhone appot is fejlesztettünk,

00:04:29.128 --> 00:04:31.843
amely a telefon belső kamerájával

00:04:31.843 --> 00:04:33.443
fotót készít az egyénről,

00:04:33.443 --> 00:04:34.930
majd feltölti a felhőbe

00:04:34.930 --> 00:04:37.592
és pontosan azt csinálja valós időben, 
amit most elmeséltem:

00:04:37.592 --> 00:04:39.680
képet egyeztet, nyilvános adatot keres,

00:04:39.680 --> 00:04:41.410
próbál személyes adatot kideríteni,

00:04:41.410 --> 00:04:44.001
majd visszaküldi a telefonnak,

00:04:44.001 --> 00:04:47.610
ahol a célszemély arcképe felett megjelenik mindez,

00:04:47.610 --> 00:04:49.511
jó példaként,

00:04:49.511 --> 00:04:51.962
ijesztő példaként, a kiterjesztett valóságra.

00:04:51.962 --> 00:04:55.301
Igazából nem azért csináltuk az appot, 
hogy terjesszük,

00:04:55.301 --> 00:04:57.223
csupán hogy igazoljuk vele a koncepciót.

00:04:57.223 --> 00:04:59.536
Vegyük ezeket a technológiákat,

00:04:59.536 --> 00:05:01.373
és képzeljük el ezeknek a végleteit.

00:05:01.373 --> 00:05:04.092
Képzeld el a jövőt, ahol körülötted az idegenek

00:05:04.092 --> 00:05:06.403
rádnéznek a Google szemüvegen keresztül,

00:05:06.403 --> 00:05:08.710
vagy egy nap kontaktlencsén keresztül,

00:05:08.710 --> 00:05:12.730
és hét vagy nyolc adatpontból

00:05:12.730 --> 00:05:15.312
bármi mást kitalálnak rólad,

00:05:15.312 --> 00:05:17.915
amit csak tudni lehet.

00:05:17.915 --> 00:05:22.709
Milyen lesz ez a titkok nélküli jövő?

00:05:22.709 --> 00:05:24.673
Érdekel ez minket?

00:05:24.673 --> 00:05:26.564
Lehet, hogy szeretjük azt hinni,

00:05:26.564 --> 00:05:29.604
hogy az adatbőség jövőjében

00:05:29.604 --> 00:05:32.118
nem lesznek előítéletek,

00:05:32.118 --> 00:05:35.701
de ilyen mennyiségű információ

00:05:35.701 --> 00:05:37.892
még nem jelenti azt, hogy a döntéseink

00:05:37.892 --> 00:05:39.598
tárgyilagosabbak lesznek.

00:05:39.598 --> 00:05:42.158
Egy másik kísérletben a tesztalanyok

00:05:42.158 --> 00:05:44.404
álláskeresőkről kaptak információkat.

00:05:44.404 --> 00:05:47.582
Ennek részeként belekerültek

00:05:47.582 --> 00:05:50.228
vicces, teljesen törvényes,

00:05:50.228 --> 00:05:52.693
de lehet, hogy kicsit ciki dolgok,

00:05:52.693 --> 00:05:54.713
amiket az alany online megosztott.

00:05:54.713 --> 00:05:57.079
Érdekes módon a tesztalanyok között is volt olyan,

00:05:57.079 --> 00:06:00.162
aki hasonló információkat osztott meg,

00:06:00.162 --> 00:06:02.524
és olyan is, aki nem.

00:06:02.524 --> 00:06:04.473
Mit gondoltok, melyik csoport

00:06:04.473 --> 00:06:09.025
ítélte el jobban az alanyokat?

00:06:09.025 --> 00:06:10.982
Ellentmondásosan hangozhat, de pont az,

00:06:10.982 --> 00:06:12.715
amelyik hasonló információkat osztott meg --

00:06:12.715 --> 00:06:15.657
jó példa a morális disszonanciára.

00:06:15.657 --> 00:06:17.407
Most talán azt gondoljátok,

00:06:17.407 --> 00:06:19.109
hogy ez rám nem vonatkozik,

00:06:19.109 --> 00:06:21.271
mert nincs mit takargatnom.

00:06:21.271 --> 00:06:23.753
De a magántitok nem arról szól,

00:06:23.753 --> 00:06:27.429
hogy valami negatív dolgot elrejtsünk.

00:06:27.429 --> 00:06:29.783
Tegyük fel, hogy HR igazgató vagy

00:06:29.783 --> 00:06:32.730
egy bizonyos cégnél, önéletrajzokat fogadsz,

00:06:32.730 --> 00:06:35.203
és elhatározod, hogy többet akarsz 
tudni a jelentkezőkről.

00:06:35.203 --> 00:06:37.663
Rákeresel a nevükre,

00:06:37.663 --> 00:06:39.903
és egy bizonyos világban

00:06:39.903 --> 00:06:41.911
rábukkansz erre az információra.

00:06:41.911 --> 00:06:46.348
Egy párhuzamos világban pedig ezt találod.

00:06:46.348 --> 00:06:49.065
Gondolod, hogy ugyanolyan eséllyel

00:06:49.065 --> 00:06:51.868
hívod be mindkét jelentkezőt interjúra?

00:06:51.868 --> 00:06:54.150
Ha igen, akkor nem olyan vagy,

00:06:54.150 --> 00:06:56.732
mint az amerikai munkáltatók, akiket

00:06:56.732 --> 00:07:00.039
kísérletünk részeként pontosan így teszteltünk.

00:07:00.039 --> 00:07:03.221
Facebook profilokat csináltunk
a jellemzők manipulálásával,

00:07:03.221 --> 00:07:06.072
majd szétküldtük az önéletrajzokat 
amerikai cégeknek,

00:07:06.072 --> 00:07:07.980
figyeltük, követtük

00:07:07.980 --> 00:07:10.373
hogy rákeresnek-e a jelentkezőkre,

00:07:10.373 --> 00:07:12.205
és hogy befolyásolja-e a döntéseiket az információ,

00:07:12.205 --> 00:07:14.143
amit a közösségi oldalakon találtak. És igen.

00:07:14.143 --> 00:07:16.244
A közösségi oldalakon keresztül diszkriminálták

00:07:16.244 --> 00:07:19.317
a hasonló képességű jelentkezőket.

00:07:19.317 --> 00:07:23.892
A marketingesek szeretnék elhitetni velünk,

00:07:23.892 --> 00:07:26.161
hogy ez a sok rólunk szóló adat mindig

00:07:26.161 --> 00:07:29.434
ránk nézve kedvezően lesz felhasználva.

00:07:29.434 --> 00:07:33.149
De gondoljunk bele. Miért lenne ez mindig igaz?

00:07:33.149 --> 00:07:35.813
Pár évvel ezelőtt játszották

00:07:35.813 --> 00:07:38.366
a Különvéleményt, ahol az egyik híres jelenetben

00:07:38.366 --> 00:07:40.942
Tom Cruise egy plázában sétál,

00:07:40.942 --> 00:07:44.718
és személyreszabott hologram hirdetések

00:07:44.718 --> 00:07:46.553
jelennek meg körülötte.

00:07:46.553 --> 00:07:49.780
Ez a film 2054-ben játszódik,

00:07:49.780 --> 00:07:51.422
nagyjából 40 év múlva,

00:07:51.422 --> 00:07:54.330
s bár izgalmasnak tűnik ez a technológia,

00:07:54.330 --> 00:07:56.976
máris jóval alulbecsüli

00:07:56.976 --> 00:07:59.116
azt az adatmennyiséget, amit a szervezetek

00:07:59.116 --> 00:08:01.599
gyűjtenek rólunk, és hogy azt hogyan használhatják

00:08:01.599 --> 00:08:04.997
észrevehetetlen befolyásolásra.

00:08:04.997 --> 00:08:07.100
Ismét álljon itt egy példa, egy másik kísérlet,

00:08:07.100 --> 00:08:09.373
ez még most is folyik, nincs még befejezve.

00:08:09.373 --> 00:08:11.692
Tegyük fel, hogy egy szervezet hozzáfér

00:08:11.692 --> 00:08:13.748
a Facebook ismerőseink listájához

00:08:13.748 --> 00:08:15.520
és valamilyen módszerrel

00:08:15.520 --> 00:08:19.254
kitalálják, hogy melyik két barátodat 
kedveled a legjobban.

00:08:19.254 --> 00:08:21.534
Valós időben generálnak

00:08:21.534 --> 00:08:24.376
egy arcot a két ismerősödből.

00:08:24.376 --> 00:08:27.445
Korábbi kutatások igazolják, hogy az emberek

00:08:27.445 --> 00:08:30.330
nem ismerik fel saját magukat sem

00:08:30.330 --> 00:08:32.792
összetett arcokon,

00:08:32.792 --> 00:08:34.909
de pozitívan reagálnak az összemosott képekre.

00:08:34.909 --> 00:08:38.324
Úgyhogy legközelebb, ha keresel egy terméket,

00:08:38.324 --> 00:08:40.883
és belefutsz egy reklámba,

00:08:40.883 --> 00:08:43.790
nem csak egy tipikus eladót látsz majd.

00:08:43.790 --> 00:08:46.103
Hanem az egyik ismerősödet --

00:08:46.103 --> 00:08:49.406
és nem is fogod tudni, hogy mi folyik.

00:08:49.406 --> 00:08:51.819
Az a gond,

00:08:51.819 --> 00:08:54.338
hogy a jelenlegi szabályozás mellett

00:08:54.338 --> 00:08:57.776
a személyes adatokkal való 
visszaélés ellen harcolni olyan,

00:08:57.776 --> 00:09:00.760
mint bicskával szállni be egy háborúba.

00:09:00.760 --> 00:09:03.673
Az egyik ilyen módszer az átláthatóság,

00:09:03.673 --> 00:09:06.873
tájékoztatni az embereket arról, 
hogy mi történik az adataikkal.

00:09:06.873 --> 00:09:08.979
Elvileg ez nagyon jó dolog.

00:09:08.979 --> 00:09:12.646
Szükséges, de nem elégséges.

00:09:12.646 --> 00:09:16.344
Az átláthatóság félrevezető lehet.

00:09:16.344 --> 00:09:18.448
Megmondod az embereknek, hogy mit fogsz csinálni,

00:09:18.448 --> 00:09:20.680
de még egy kicsit ösztönzöd őket arra,

00:09:20.680 --> 00:09:23.303
hogy további személyes adatokat adjanak ki.

00:09:23.303 --> 00:09:26.189
Egy újabb kísérletet hallgatókkal végeztünk,

00:09:26.189 --> 00:09:29.247
megkérdeztük őket

00:09:29.247 --> 00:09:31.060
a viselkedésükről az egyetemen,

00:09:31.060 --> 00:09:34.000
személyes kérdéseket feltéve, mint például ezt:
Puskáztál már valaha?

00:09:34.000 --> 00:09:34.621
személyes kérdéseket feltéve, mint például ezt:
Puskáztál már valaha?

00:09:34.621 --> 00:09:36.921
Az egyik csoportnak azt mondtuk,

00:09:36.921 --> 00:09:39.762
hogy csak a többi hallgató fogja látni a válaszaikat.

00:09:39.762 --> 00:09:41.341
A másik csoportnak azt mondtuk,

00:09:41.341 --> 00:09:44.902
hogy a többi hallgató és a tanszék is 
látni fogja a válaszokat.

00:09:44.902 --> 00:09:47.493
Átláthatóság. Tájékoztatás. És ez bizony működött is,

00:09:47.493 --> 00:09:48.900
abban az értelemben, hogy az első csoport

00:09:48.900 --> 00:09:51.468
sokkal hajlandóbb volt kiadni 
az információt, mint a második.

00:09:51.468 --> 00:09:52.988
Logikus, nem?

00:09:52.988 --> 00:09:54.478
De ekkor egy kis megtévesztést csempésztünk bele.

00:09:54.478 --> 00:09:57.238
Ugyanazzal a két csoporttal folytattuk a kísérletet,

00:09:57.238 --> 00:09:59.665
immár egy kis késést iktatva aközé,

00:09:59.665 --> 00:10:02.600
amikor elmondtuk nekik,

00:10:02.600 --> 00:10:04.680
hogyan lesznek felhasználva az adataik,

00:10:04.680 --> 00:10:09.068
és amikor elkezdtük megválaszolni a kérdéseket.

00:10:09.068 --> 00:10:11.629
Mit gondoltok, mekkora késleltetés kellett ahhoz,

00:10:11.629 --> 00:10:16.242
hogy teljesen elvesszen az a gátló hatás,

00:10:16.242 --> 00:10:19.653
amelyet a tanszék bevonásának tudata okozott?

00:10:19.653 --> 00:10:21.433
Tíz perc?

00:10:21.433 --> 00:10:23.224
Öt perc?

00:10:23.224 --> 00:10:25.000
Egy perc?

00:10:25.000 --> 00:10:27.049
Esetleg tizenöt másodperc?

00:10:27.049 --> 00:10:29.717
Tizenöt másodperc elég volt ahhoz,

00:10:29.717 --> 00:10:31.285
hogy mindkét csoport hasonló 
mennyiségű adatot osszon meg,

00:10:31.285 --> 00:10:34.031
mintha a másodiknak nem számítana,

00:10:34.031 --> 00:10:36.687
hogy a tanszék látja-e a válaszaikat.

00:10:36.687 --> 00:10:40.023
Belátom, ez az előadás eddig

00:10:40.023 --> 00:10:42.503
egy kicsit lehangoló lehet,

00:10:42.503 --> 00:10:44.224
de nem ez a lényeg.

00:10:44.224 --> 00:10:46.923
Sőt, azt szeretném elmondani nektek,

00:10:46.923 --> 00:10:48.695
hogy vannak atlernatívák.

00:10:48.695 --> 00:10:51.194
Ahogy most mennek a dolgok, 
az nem az egyetlen megoldás,

00:10:51.194 --> 00:10:54.231
és egész biztosan nem a legjobb

00:10:54.231 --> 00:10:56.258
megoldás.

00:10:56.258 --> 00:11:00.429
Ha valaki azt mondja, "Senkit nem 
érdekelnek a magánjogok",

00:11:00.429 --> 00:11:03.071
gondolj arra, hogy a játékszabályok 
vannak úgy megírva,

00:11:03.071 --> 00:11:05.795
hogy ne tudjanak foglalkozni a személyiségi jogokkal,

00:11:05.795 --> 00:11:09.057
és ennek a befolyásolásnak a felismerése

00:11:09.057 --> 00:11:10.664
már önmagában fél siker afelé,

00:11:10.664 --> 00:11:12.922
hogy megvédd magad.

00:11:12.922 --> 00:11:16.632
Ha valaki azt mondja, hogy a magánjogok

00:11:16.632 --> 00:11:18.481
és a nagy mennyiségű adat nem egyeztethető össze,

00:11:18.481 --> 00:11:20.954
gondolj arra, hogy az elmúlt 20 évben

00:11:20.954 --> 00:11:22.871
a fejlesztők megteremtették a lehetőséget arra,

00:11:22.871 --> 00:11:26.189
hogy szinte minden elektronikus tranzakció

00:11:26.189 --> 00:11:29.938
a személyiségi jogok megóvásával történhessen.

00:11:29.938 --> 00:11:32.493
Lehet névtelenül internetezni.

00:11:32.493 --> 00:11:35.171
Tudunk olyan emaileket küldeni,

00:11:35.171 --> 00:11:38.880
amit csak a címzett tud 
elolvasni, és még az NSA sem.

00:11:38.880 --> 00:11:41.877
Még az adatbányászat is történhet 
magánjogok megsértése nélkül.

00:11:41.877 --> 00:11:45.771
Másszóval kihasználhatjuk a tömeges adatokat úgy,

00:11:45.771 --> 00:11:47.903
hogy közben megóvjuk a személyiségi jogokat.

00:11:47.903 --> 00:11:51.694
Természetesen ezek a technológiák

00:11:51.694 --> 00:11:53.240
költség és bevétel eltolódást jelentenek

00:11:53.240 --> 00:11:55.347
az adattulajdonosok és alanyok között,

00:11:55.347 --> 00:11:58.800
valószínűleg ezért nem hallunk róluk.

00:11:58.800 --> 00:12:02.506
Ezzel vissza is térnék az Édenkerthez.

00:12:02.506 --> 00:12:05.286
Van egy másik magánjogi értelmezése

00:12:05.286 --> 00:12:07.095
az Édenkert-történetnek,

00:12:07.095 --> 00:12:09.191
amelynek nincs köze

00:12:09.191 --> 00:12:11.416
Ádám és Éva meztelenségéhez

00:12:11.416 --> 00:12:13.797
és szégyenérzetéhez.

00:12:13.797 --> 00:12:16.578
Ennek az értelmezésnek 
a visszhangjai találhatóak meg

00:12:16.578 --> 00:12:19.360
John Milton Elveszett Paradicsomában.

00:12:19.360 --> 00:12:23.557
Az Édenkertben Ádám és Éva 
anyagi szempontból elégedett.

00:12:23.557 --> 00:12:25.661
Boldogak. Elégedettek.

00:12:25.661 --> 00:12:27.954
Viszont nincs tudásuk

00:12:27.954 --> 00:12:29.594
és öntudatuk.

00:12:29.594 --> 00:12:32.913
Amint megeszik a találóan elnevezett

00:12:32.913 --> 00:12:34.206
tudás gyümölcsét,

00:12:34.206 --> 00:12:36.811
rögtön magukra eszmélnek.

00:12:36.811 --> 00:12:40.842
Tudatra ébrednek. Önállóak lesznek.

00:12:40.842 --> 00:12:43.968
Mindennek az ára azonban a kiűzetés.

00:12:43.968 --> 00:12:47.849
A magánjogok bizonyos értelemben tehát

00:12:47.849 --> 00:12:50.811
a szabadság módját és árát jelentik.

00:12:50.811 --> 00:12:53.581
Ismétlem, a marketingesek meg akarnak győzni,

00:12:53.581 --> 00:12:56.600
hogy a tömegadat és a közösségi média

00:12:56.600 --> 00:12:59.579
nem csak számukra profitparadicsom,

00:12:59.579 --> 00:13:02.036
hanem számunkra is Édenkert.

00:13:02.036 --> 00:13:03.274
Ingyen tartalmakat kapunk.

00:13:03.274 --> 00:13:06.397
Játszhatunk az Angry Birds-zel. 
Személyreszabott appokhoz jutunk.

00:13:06.397 --> 00:13:09.294
De éveken belül a szervezetek

00:13:09.294 --> 00:13:10.903
annyi mindent fognak tudni rólunk,

00:13:10.903 --> 00:13:13.613
hogy kitalálják a vágyainkat

00:13:13.613 --> 00:13:15.817
még mielőtt azok bennünk megszületnének,

00:13:15.817 --> 00:13:18.264
és talán még vásárolnak is a nevünkben,

00:13:18.264 --> 00:13:20.538
még mielőtt nekünk bármire szükségünk lenne.

00:13:20.538 --> 00:13:23.775
Volt egy angol író,

00:13:23.775 --> 00:13:26.820
aki előre látta ezt a fajta jövőt,

00:13:26.820 --> 00:13:28.225
ahol eladjuk

00:13:28.225 --> 00:13:31.773
a függetlenségünket és 
szabadságunkat a kényelemért.

00:13:31.773 --> 00:13:33.934
Még George Orwellen is túlmutatva --

00:13:33.934 --> 00:13:36.695
az író, természetesen, Aldous Huxley.

00:13:36.695 --> 00:13:39.549
A Szép Új Világban egy olyan társadalmat ír le,

00:13:39.549 --> 00:13:41.720
amelyben a technológiák,

00:13:41.720 --> 00:13:43.579
melyek eredetileg a szabadságot szolgálták,

00:13:43.579 --> 00:13:46.146
végül kényszerré válnak.

00:13:46.146 --> 00:13:50.937
Könyvében azonban egy kiutat is kínál

00:13:50.937 --> 00:13:54.375
ebből a társadalomból, hasonlóan ahhoz,

00:13:54.375 --> 00:13:58.330
ahogy Ádám és Éva elhagyta a Kertet.

00:13:58.330 --> 00:14:00.477
A Vadember szavaival élve,

00:14:00.477 --> 00:14:03.546
az önállóság és szabadság visszaszerzése lehetséges,

00:14:03.546 --> 00:14:06.225
de hatalmas ára van.

00:14:06.225 --> 00:14:11.940
Azt hiszem, korunk egyik meghatározó harca

00:14:11.940 --> 00:14:14.503
az a csata lesz,

00:14:14.503 --> 00:14:16.890
amelyet a személyiségi jogok 
feletti hatalomért vívunk,

00:14:16.890 --> 00:14:20.397
amely eldönti, hogy a tömeges adatok

00:14:20.397 --> 00:14:21.686
a szabadság

00:14:21.686 --> 00:14:26.432
vagy a rejtett manipuláció eszközei lesznek.

00:14:26.432 --> 00:14:29.025
Jelenleg sokan

00:14:29.025 --> 00:14:31.778
nem is tudják, hogy folyik ez a harc,

00:14:31.778 --> 00:14:34.450
de folyik, ha tetszik, ha nem.

00:14:34.450 --> 00:14:37.254
Lehet, hogy én leszek a kígyó,

00:14:37.254 --> 00:14:40.151
de elmondom, hogy a harc eszközei

00:14:40.151 --> 00:14:43.160
itt vannak: annak felismerése, 
hogy mi megy a háttérben,

00:14:43.160 --> 00:14:44.515
a ti kezetekben van,

00:14:44.515 --> 00:14:48.255
csupán pár kattintásra.

00:14:48.255 --> 00:14:49.737
Köszönöm.

00:14:49.737 --> 00:14:54.214
(Taps)

