WEBVTT
Kind: captions
Language: bg

00:00:00.000 --> 00:00:07.000
Translator: Preslav Nikolov
Reviewer: Yavor Ivanov

00:00:12.641 --> 00:00:14.995
Бих искал да ви разкажа история

00:00:14.995 --> 00:00:18.171
за всеизвестния инцидент за поверителността

00:00:18.171 --> 00:00:20.940
при Адам и Ева

00:00:20.940 --> 00:00:24.386
и невероятната промяна на границата

00:00:24.386 --> 00:00:27.072
между публичното и личното, настъпила

00:00:27.072 --> 00:00:28.842
през последните 10 години.

00:00:28.842 --> 00:00:30.140
Случката ви е позната.

00:00:30.140 --> 00:00:33.470
Един ден в Райската градина

00:00:33.470 --> 00:00:35.313
Адам и Ева осъзнали, че са голи.

00:00:35.313 --> 00:00:36.813
И откачили.

00:00:36.813 --> 00:00:39.570
Останалото е история.

00:00:39.570 --> 00:00:41.758
В днешно време

00:00:41.758 --> 00:00:44.119
Адам и Ева сигурно ще реагират различно.

00:00:44.119 --> 00:00:46.387
[@Адам, снощи беше невероятно! Влюбих се в тази ябълка LOL]

00:00:46.387 --> 00:00:48.260
[@Ева, да.. скъпа, да знаеш какво е станало с гащите ми?]

00:00:48.260 --> 00:00:50.896
Разкриваме много повече информация

00:00:50.896 --> 00:00:54.230
за себе си онлайн от когато и да било

00:00:54.230 --> 00:00:55.934
и много повече информация за нас самите

00:00:55.934 --> 00:00:58.158
се събира от различни организации.

00:00:58.158 --> 00:01:01.440
В днешно време могат да се извлекат много ползи

00:01:01.440 --> 00:01:03.886
от непрестанния анализ на лична информация,

00:01:03.886 --> 00:01:05.832
значима информация,

00:01:05.832 --> 00:01:08.470
но има и големи компромиси, които правим

00:01:08.470 --> 00:01:11.568
когато се отказваме от своето лично пространство.

00:01:11.568 --> 00:01:15.591
Моята история е за тези компромиси.

00:01:15.591 --> 00:01:18.175
Започваме с наблюдението, което, според мен,

00:01:18.175 --> 00:01:21.502
става все по-ясно и по-ясно през последните няколко години,

00:01:21.502 --> 00:01:23.599
а именно че личната информация

00:01:23.599 --> 00:01:25.884
можа да е важна информация.

00:01:25.884 --> 00:01:30.009
През 2000 година за били направени около 100 милиарда снимки

00:01:30.009 --> 00:01:31.921
по целия свят,

00:01:31.921 --> 00:01:34.986
но много малка част от тях

00:01:34.986 --> 00:01:36.869
са били качени онлайн.

00:01:36.869 --> 00:01:40.230
През 2010г., само във Facebook, само за един месец,

00:01:40.230 --> 00:01:43.500
са били качени повече от 2,5 милиарда снимки,

00:01:43.500 --> 00:01:45.382
повечето от тях с ясна идентификация.

00:01:45.382 --> 00:01:47.262
За същия период от време

00:01:47.262 --> 00:01:52.132
възможностите на компютрите да разпознават хора на снимки

00:01:52.132 --> 00:01:55.740
се е подобрила цели три пъти.

00:01:55.740 --> 00:01:57.622
Какво се случва

00:01:57.622 --> 00:01:59.123
когато комбинирате следните технологии:

00:01:59.123 --> 00:02:01.781
по-лесен достъп до идентифициращи данни;

00:02:01.781 --> 00:02:05.429
подобрена способност на компютрите за разпознаване на лица;

00:02:05.429 --> 00:02:07.611
също това клауд компютинг,

00:02:07.611 --> 00:02:09.499
който дава на всеки в тази зала

00:02:09.499 --> 00:02:11.059
такива изчислителни способности,

00:02:11.059 --> 00:02:12.945
каквито преди няколко години са били достъпни

00:02:12.945 --> 00:02:14.727
само на трибуквени агенции;

00:02:14.727 --> 00:02:16.105
както и повсеместен компютинг,

00:02:16.105 --> 00:02:18.997
който позволява на телефона ми, който не е суперкомпютър,

00:02:18.997 --> 00:02:20.668
да се свърже с Интернет

00:02:20.668 --> 00:02:23.002
и да извърши стотици хиляди

00:02:23.002 --> 00:02:25.641
лицеви анализи за секунди?

00:02:25.641 --> 00:02:28.269
Според нас резултатът

00:02:28.269 --> 00:02:30.333
от това комбиниране на технологии

00:02:30.333 --> 00:02:33.221
ще доведе до радикална промяна

00:02:33.221 --> 00:02:35.478
в разбиранията ни за лично пространство и анонимност.

00:02:35.478 --> 00:02:37.471
За да тестваме хипотезата си проведохме експеримент

00:02:37.471 --> 00:02:39.592
в университета „Карнеги Мелън“.

00:02:39.592 --> 00:02:41.691
Поканихме преминаващи покрай нас студенти

00:02:41.691 --> 00:02:43.470
да вземат участие в изследване,

00:02:43.470 --> 00:02:46.032
след което ги снимахме с уебкамера

00:02:46.032 --> 00:02:48.814
и ги помолихме да попълнят анкета на лаптоп.

00:02:48.814 --> 00:02:50.793
Докато попълваха анкетата

00:02:50.793 --> 00:02:53.590
ние качихме снимката им в клауд компютинг клъстър

00:02:53.590 --> 00:02:55.317
и използвайки програма за лицево разпознаване

00:02:55.317 --> 00:02:57.722
започнахме да сравняваме снимката с база данни,

00:02:57.722 --> 00:03:00.115
включваща няколко стотин хиляди образа

00:03:00.115 --> 00:03:03.711
свалени предварително от Facebook.

00:03:03.711 --> 00:03:06.970
За времето, за което субектите стигаха до последната страница на анкетата,

00:03:06.970 --> 00:03:10.317
тя вече беше обновена

00:03:10.317 --> 00:03:12.630
с десетте най-близки съвпадения на снимки,

00:03:12.630 --> 00:03:14.915
които програмата за разпознаване бе открила

00:03:14.915 --> 00:03:16.653
и помолихме субектите да споделят

00:03:16.653 --> 00:03:20.773
дали виждат себе си на снимките.

00:03:20.773 --> 00:03:24.472
Виждате ли субекта?

00:03:24.472 --> 00:03:27.317
Компютърът го разпознаваше и то правилно

00:03:27.317 --> 00:03:29.466
за един от трима участници.

00:03:29.466 --> 00:03:32.650
На кратко, можем да започнем със снимка на анонимно лице,

00:03:32.650 --> 00:03:36.134
онлайн или не, и да използваме лицево разпознаване,

00:03:36.134 --> 00:03:38.494
за да сложим име на лицето,

00:03:38.494 --> 00:03:40.602
благодарение на данни от социалните медии.

00:03:40.602 --> 00:03:42.474
Няколко години по-рано обаче направихме нещо различно.

00:03:42.474 --> 00:03:44.297
Започнахме с данни от социалните медии,

00:03:44.297 --> 00:03:47.348
свързахме ги статистически с данни

00:03:47.348 --> 00:03:49.450
от Управлението за социално осигуряване на САЩ

00:03:49.450 --> 00:03:52.774
и успяхме да предвидим Номера за социално осигуряване,

00:03:52.774 --> 00:03:54.286
коeто в САЩ

00:03:54.286 --> 00:03:56.326
e изключително поверителна информация.

00:03:56.326 --> 00:03:58.419
Разбирате ли накъде отивам с това?

00:03:58.419 --> 00:04:01.341
Ако комбинирате двете изследвания

00:04:01.341 --> 00:04:02.853
въпросът, който се питаме, е

00:04:02.853 --> 00:04:05.573
дали може да се започне с лицето,

00:04:05.573 --> 00:04:07.884
използвайки лицево разпознаване да се намери име

00:04:07.884 --> 00:04:10.553
и публично достъпна информация

00:04:10.553 --> 00:04:12.485
за името и самия човек

00:04:12.485 --> 00:04:14.733
и от тази публично достъпна информация

00:04:14.733 --> 00:04:16.775
да се направи извод за информация, която не е със свободен достъп,

00:04:16.775 --> 00:04:18.381
много по-значима информация,

00:04:18.381 --> 00:04:19.873
която да се свърже обратно с лицето?

00:04:19.873 --> 00:04:21.789
И отговорът е да, можем да го направим.

00:04:21.789 --> 00:04:24.357
Разбира се точността става все по-лоша.

00:04:24.357 --> 00:04:25.301
[В 27% от случаите първите 5 цифри на Номера за социално осигуряване са разпознати (от 4 опита)]

00:04:25.301 --> 00:04:29.128
Всъщност, дори разработихме и апликация за iPhone,

00:04:29.128 --> 00:04:31.843
която използва вградената камера на телефона,

00:04:31.843 --> 00:04:33.443
за да направи снимка на субекта,

00:04:33.443 --> 00:04:34.930
да я качи в информационен облак

00:04:34.930 --> 00:04:37.592
и да извърши това, което току-що обясних:

00:04:37.592 --> 00:04:39.680
търси съвпадение, намира публично достъпна информация,

00:04:39.680 --> 00:04:41.410
прави опит за извеждане на поверителна информация,

00:04:41.410 --> 00:04:44.001
след което я изпраща обратно до телефона,

00:04:44.001 --> 00:04:47.610
който я налага върху лицето на субекта,

00:04:47.610 --> 00:04:49.511
пример за добавена реалност,

00:04:49.511 --> 00:04:51.962
вероятно зловещ пример за такава.

00:04:51.962 --> 00:04:55.301
Реално не създадохме апликацията, за да я предоставим на потребители,

00:04:55.301 --> 00:04:57.223
а само като доказване на концепция.

00:04:57.223 --> 00:04:59.536
Замислете се, вземете тези технологии

00:04:59.536 --> 00:05:01.373
и ги доведете до екстремност.

00:05:01.373 --> 00:05:04.092
Представете си бъдеще, в което непознати

00:05:04.092 --> 00:05:06.403
ви гледат през Гугъл очила

00:05:06.403 --> 00:05:08.710
или, някой ден, контактните си лещи

00:05:08.710 --> 00:05:12.730
и използват седем или осем факта за вас

00:05:12.730 --> 00:05:15.312
и правят извод за всичко останало,

00:05:15.312 --> 00:05:17.915
което може да се знае за вас.

00:05:17.915 --> 00:05:22.709
Как ще изглежда такова бъдеще без тайни?

00:05:22.709 --> 00:05:24.673
И трябва ли да ни интересува?

00:05:24.673 --> 00:05:26.564
Бихме искали да вярваме,

00:05:26.564 --> 00:05:29.604
че бъдеще с такова изобилие от данни

00:05:29.604 --> 00:05:32.118
ще е бъдеще без предразсъдъци,

00:05:32.118 --> 00:05:35.701
но всъщност достъпът до толкова много информация

00:05:35.701 --> 00:05:37.892
не означава, че ще взимаме

00:05:37.892 --> 00:05:39.598
по-обективни решения.

00:05:39.598 --> 00:05:42.158
В друг експеримент представихме на субектите си информация

00:05:42.158 --> 00:05:44.404
за потенциален кандидат за работа.

00:05:44.404 --> 00:05:47.582
В предоставената информация имаше и препратки

00:05:47.582 --> 00:05:50.228
към забавна, напълно законна,

00:05:50.228 --> 00:05:52.693
но може би малко засрамваща информация,

00:05:52.693 --> 00:05:54.713
която кандидатите бяха публикували онлайн.

00:05:54.713 --> 00:05:57.079
Интересното е, че сред нашите субекти имаше такива,

00:05:57.079 --> 00:06:00.162
които бяха публикували сходна информация,

00:06:00.162 --> 00:06:02.524
и такива, които не бяха.

00:06:02.524 --> 00:06:04.473
Коя група според вас

00:06:04.473 --> 00:06:09.025
бе по-критична към кандидата за работа?

00:06:09.025 --> 00:06:10.982
Парадоксално, това бе групата,

00:06:10.982 --> 00:06:12.715
в която хората бяха публикували сходна информация,

00:06:12.715 --> 00:06:15.657
пример за морално несъответствие.

00:06:15.657 --> 00:06:17.407
Може би си мислите

00:06:17.407 --> 00:06:19.109
"Това не се отнася до мен,

00:06:19.109 --> 00:06:21.271
защото нямам какво да крия".

00:06:21.271 --> 00:06:23.753
Фактите са, че при поверителността

00:06:23.753 --> 00:06:27.429
не е задължително да криете нещо лошо.

00:06:27.429 --> 00:06:29.783
Представете си, че сте на чело на отдел човешки ресурси

00:06:29.783 --> 00:06:32.730
в дадена организация и получавате резюмета,

00:06:32.730 --> 00:06:35.203
и решавате да потърсите по-подробна информация за кандидатите.

00:06:35.203 --> 00:06:37.663
Следователно търсите имената им в Гугъл

00:06:37.663 --> 00:06:39.903
и в една реалност

00:06:39.903 --> 00:06:41.911
откривате тази информация.

00:06:41.911 --> 00:06:46.348
А в друга реалност откривате тази информация.

00:06:46.348 --> 00:06:49.065
Мислите ли, че ще бъдете еднакво склонен

00:06:49.065 --> 00:06:51.868
да се обадите на някоя от кандидатките за интервю?

00:06:51.868 --> 00:06:54.150
Ако мислите така, значи сте различни

00:06:54.150 --> 00:06:56.732
от американските работодатели, които са, всъщност,

00:06:56.732 --> 00:07:00.039
част от нашия експеримент, т.е. направихме точно това.

00:07:00.039 --> 00:07:03.221
Създадохме профили във Facebook, изменяйки дадени характеристики,

00:07:03.221 --> 00:07:06.072
след което започнахме да изпращаме резюмета до работодатели в САЩ

00:07:06.072 --> 00:07:07.980
и следяхме

00:07:07.980 --> 00:07:10.373
дали търсят кандидатите ни

00:07:10.373 --> 00:07:12.205
и дали взимаха под внимание информацията,

00:07:12.205 --> 00:07:14.143
намерена в социалните медии. Правеха точно това.

00:07:14.143 --> 00:07:16.244
Кандидати с еднакви способности бяха дискриминирани

00:07:16.244 --> 00:07:19.317
на база социални медии.

00:07:19.317 --> 00:07:23.892
Маркетолозите искат да вярваме,

00:07:23.892 --> 00:07:26.161
че всяка информация за нас

00:07:26.161 --> 00:07:29.434
винаги ще се използва в наша полза.

00:07:29.434 --> 00:07:33.149
Помислете отново. Защо мислите, че винаги ще е така?

00:07:33.149 --> 00:07:35.813
Във филм отпреди няколко години,

00:07:35.813 --> 00:07:38.366
"Специален доклад", в известна сцена

00:07:38.366 --> 00:07:40.942
Том Круз влиза в мол

00:07:40.942 --> 00:07:44.718
и персонализирани холограмни реклами

00:07:44.718 --> 00:07:46.553
се появяват около него.

00:07:46.553 --> 00:07:49.780
Действието се случва през 2054г.,

00:07:49.780 --> 00:07:51.422
след около 40 години,

00:07:51.422 --> 00:07:54.330
и колкото и вълнуваща да изглежда тази технология

00:07:54.330 --> 00:07:56.976
тя вече подценява

00:07:56.976 --> 00:07:59.116
количеството информация, което организациите

00:07:59.116 --> 00:08:01.599
могат да съберат за вас, и как могат да я използват,

00:08:01.599 --> 00:08:04.997
за да ви повлияят по начин, който дори няма да осъзнаете.

00:08:04.997 --> 00:08:07.100
Като пример ще ви дам друг експеримент,

00:08:07.100 --> 00:08:09.373
който провеждаме, все още незавършен.

00:08:09.373 --> 00:08:11.692
Представете си, че някоя организация има достъп

00:08:11.692 --> 00:08:13.748
до списъка ви с приятели във Facebook

00:08:13.748 --> 00:08:15.520
и използвайки някакъв алгоритъм

00:08:15.520 --> 00:08:19.254
може да открие двамата приятели, които харесвате най-много.

00:08:19.254 --> 00:08:21.534
Също така може, в реално време, да направят

00:08:21.534 --> 00:08:24.376
нереално съчетание от тези двама приятели.

00:08:24.376 --> 00:08:27.445
Проведени изследвания преди нашето са показали,

00:08:27.445 --> 00:08:30.330
че хората не разпознават дори себе си

00:08:30.330 --> 00:08:32.792
в лицеви компилации, но реагират

00:08:32.792 --> 00:08:34.909
на компилациите по положителен начин.

00:08:34.909 --> 00:08:38.324
И следващият път когато търсите определен продукт

00:08:38.324 --> 00:08:40.883
и има реклама, която ви предлага да го купите,

00:08:40.883 --> 00:08:43.790
няма да е просто обикновеният говорител.

00:08:43.790 --> 00:08:46.103
Ще бъде един от приятелите ви,

00:08:46.103 --> 00:08:49.406
а вие дори няма да осъзнавате, че се случва нещо подобно.

00:08:49.406 --> 00:08:51.819
Проблемът идва от това,

00:08:51.819 --> 00:08:54.338
че механизмите, които имаме

00:08:54.338 --> 00:08:57.776
за защита от експлоатация на личните ни данни

00:08:57.776 --> 00:09:00.760
са като нож по средата на престрелка.

00:09:00.760 --> 00:09:03.673
Един от тези механизми е прозрачност,

00:09:03.673 --> 00:09:06.873
да се казва на хората за какво ще се използват данните им.

00:09:06.873 --> 00:09:08.979
По принцип това е нещо много хубаво.

00:09:08.979 --> 00:09:12.646
Нужно е, но не е достатъчно.

00:09:12.646 --> 00:09:16.344
Прозрачността може да е подвеждаща.

00:09:16.344 --> 00:09:18.448
Можеш да кажеш на човек какво ще направиш,

00:09:18.448 --> 00:09:20.680
след което да го подканваш да сподели

00:09:20.680 --> 00:09:23.303
произволен набор лична информация.

00:09:23.303 --> 00:09:26.189
В един друг експеримент, проведен със студенти,

00:09:26.189 --> 00:09:29.247
ги помолихме да споделят информация

00:09:29.247 --> 00:09:31.060
за поведението си в университета,

00:09:31.060 --> 00:09:34.000
включително доста чувствителни въпроси като този.

00:09:34.000 --> 00:09:34.621
[Преписвали ли сте на изпит?]

00:09:34.621 --> 00:09:36.921
На една от групите студенти казахме:

00:09:36.921 --> 00:09:39.762
"Само други студенти ще видят отговорите ви."

00:09:39.762 --> 00:09:41.341
На друга група студенти казахме:

00:09:41.341 --> 00:09:44.902
"Студенти и преподаватели ще видят отговорите ви."

00:09:44.902 --> 00:09:47.493
Прозрачност. Информиране. И естествено, проработи

00:09:47.493 --> 00:09:48.900
в смисъла, че студентите в първата група

00:09:48.900 --> 00:09:51.468
бяха много по-склонни да си признаят от тези във втората.

00:09:51.468 --> 00:09:52.988
Има смисъл, нали?

00:09:52.988 --> 00:09:54.478
После обаче добавихме и заблуда.

00:09:54.478 --> 00:09:57.238
Повторихме експеримента със същите две групи,

00:09:57.238 --> 00:09:59.665
но прибавихме забавяне

00:09:59.665 --> 00:10:02.600
между момента, в който казахме на участниците

00:10:02.600 --> 00:10:04.680
как ще използваме данните им, и момента,

00:10:04.680 --> 00:10:09.068
в който реално започнахме да им задаваме въпроси.

00:10:09.068 --> 00:10:11.629
Колко време трябваше да добавим, според вас,

00:10:11.629 --> 00:10:16.242
за да премахнем задръжките

00:10:16.242 --> 00:10:19.653
от факта, че преподаватели ще видят отговорите?

00:10:19.653 --> 00:10:21.433
Десет минути?

00:10:21.433 --> 00:10:23.224
Пет минути?

00:10:23.224 --> 00:10:25.000
Една минута?

00:10:25.000 --> 00:10:27.049
Какво ще кажете за 15 секунди?

00:10:27.049 --> 00:10:29.717
Петнадесет секунди бяха достатъчни, за да се изравни

00:10:29.717 --> 00:10:31.285
количеството информация, споделено от двете групи,

00:10:31.285 --> 00:10:34.031
сякаш втората група вече не се интересуваше,

00:10:34.031 --> 00:10:36.687
че преподаватели ще прочетат отговорите им.

00:10:36.687 --> 00:10:40.023
Трябва да си призная, че до момента тази лекция

00:10:40.023 --> 00:10:42.503
звучи изключително мрачно,

00:10:42.503 --> 00:10:44.224
но не това е идеята ми.

00:10:44.224 --> 00:10:46.923
Всъщност бих искал да споделя с вас,

00:10:46.923 --> 00:10:48.695
че има и алтернативи.

00:10:48.695 --> 00:10:51.194
Начинът, по който вършим нещата сега, не е единственият начин,

00:10:51.194 --> 00:10:54.231
по който могат да се свършат, и със сигурност

00:10:54.231 --> 00:10:56.258
не е най-добрият.

00:10:56.258 --> 00:11:00.429
Когато някой ви каже, че "хората не ги е грижа поверителността им"

00:11:00.429 --> 00:11:03.071
замислете се дали играта не е проектирана

00:11:03.071 --> 00:11:05.795
и изкривена по такъв начин, че хората да не могат да са загрижени

00:11:05.795 --> 00:11:09.057
и осъзнавайки, че тези манипулации вече са на лице

00:11:09.057 --> 00:11:10.664
е половината от това

00:11:10.664 --> 00:11:12.922
да защитите личната си информация.

00:11:12.922 --> 00:11:16.632
Когато някой ви каже, че поверителност и ползата от големи бази данни

00:11:16.632 --> 00:11:18.481
не вървят ръка за ръка,

00:11:18.481 --> 00:11:20.954
обмислете факта, че през последните 20 години

00:11:20.954 --> 00:11:22.871
изследователите са създали технологии,

00:11:22.871 --> 00:11:26.189
които позволяват практически всеки вид електронна транзакция

00:11:26.189 --> 00:11:29.938
да бъде извършена по начин, запазващ поверителността ѝ.

00:11:29.938 --> 00:11:32.493
Можем да сърфираме в Интернет анонимно.

00:11:32.493 --> 00:11:35.171
Можем да изпращаме е-писма, които да бъдат прочетени

00:11:35.171 --> 00:11:38.880
само от избрания получател, защитени дори от Агенцията по национална сигурност.

00:11:38.880 --> 00:11:41.877
Можем дори да търсим данни без да нарушаваме нечие лично пространство.

00:11:41.877 --> 00:11:45.771
С други думи можем да съчетаем

00:11:45.771 --> 00:11:47.903
голямото количество данни и поверителността.

00:11:47.903 --> 00:11:51.694
Разбира се, тези технологии биха предизвикали промяна

00:11:51.694 --> 00:11:53.240
в цената и прихода

00:11:53.240 --> 00:11:55.347
за собствениците на данни и субектите на тези данни,

00:11:55.347 --> 00:11:58.800
което е причината, вероятно, да не се говори за тези технологии.

00:11:58.800 --> 00:12:02.506
Което ме връща отново към Райската градина.

00:12:02.506 --> 00:12:05.286
Има и друга интерпретация на поверителността

00:12:05.286 --> 00:12:07.095
в историята за Райската градина,

00:12:07.095 --> 00:12:09.191
която не разглежда проблема

00:12:09.191 --> 00:12:11.416
за голотата и срама

00:12:11.416 --> 00:12:13.797
на Адам и Ева.

00:12:13.797 --> 00:12:16.578
Отзвук от тази интерпретация може да се открие

00:12:16.578 --> 00:12:19.360
в поемата на Джон Милтън "Изгубеният рай".

00:12:19.360 --> 00:12:23.557
В градината Адам и Ева са материално удовлетворени.

00:12:23.557 --> 00:12:25.661
Щастливи са. Задоволени са.

00:12:25.661 --> 00:12:27.954
От друга страна им липсва знание

00:12:27.954 --> 00:12:29.594
и себе-осъзнатост.

00:12:29.594 --> 00:12:32.913
Моментът, в който изяждат, уместно наречения,

00:12:32.913 --> 00:12:34.206
плод на знанието,

00:12:34.206 --> 00:12:36.811
е моментът, в който откриват себе си.

00:12:36.811 --> 00:12:40.842
Осъзнават. Постигат автономност.

00:12:40.842 --> 00:12:43.968
Цената, която плащат обаче, е напускането на градината.

00:12:43.968 --> 00:12:47.849
Следва, че поверителността е както средството,

00:12:47.849 --> 00:12:50.811
така и цената на свободата.

00:12:50.811 --> 00:12:53.581
И отново, маркетолозите ни казват,

00:12:53.581 --> 00:12:56.600
че изобилието от данни и социалните медии

00:12:56.600 --> 00:12:59.579
са не просто рай за тях,

00:12:59.579 --> 00:13:02.036
но и Райска градина за всички нас.

00:13:02.036 --> 00:13:03.274
Получаваме безплатни неща.

00:13:03.274 --> 00:13:06.397
Можем да играем Angry Birds. Рекламите са насочени точно към нас.

00:13:06.397 --> 00:13:09.294
Всъщност, след няколко години

00:13:09.294 --> 00:13:10.903
организациите ще знаят толкова много за нас,

00:13:10.903 --> 00:13:13.613
че ще предвиждат желанията ни

00:13:13.613 --> 00:13:15.817
преди дори да ги имаме и вероятно

00:13:15.817 --> 00:13:18.264
ще купуват продукти от наше име

00:13:18.264 --> 00:13:20.538
преди дори да осъзнаем, че ни трябват.

00:13:20.538 --> 00:13:23.775
Имаше един английски автор,

00:13:23.775 --> 00:13:26.820
който очакваше такова бъдеще,

00:13:26.820 --> 00:13:28.225
в което ще се отказваме

00:13:28.225 --> 00:13:31.773
от автономност и свобода в замяна на удобство.

00:13:31.773 --> 00:13:33.934
Повече дори от Джордж Оруел,

00:13:33.934 --> 00:13:36.695
този автор е, разбира се, Олдъс Хъксли.

00:13:36.695 --> 00:13:39.549
В „Прекрасният нов свят“ той си представя общество,

00:13:39.549 --> 00:13:41.720
в което технологиите, разработени от нас

00:13:41.720 --> 00:13:43.579
по начало за по-голяма свобода,

00:13:43.579 --> 00:13:46.146
в крайна сметка ни управляват.

00:13:46.146 --> 00:13:50.937
В книгата обаче авторът ни показва и пътя

00:13:50.937 --> 00:13:54.375
водещ извън това общество, подобен на пътя,

00:13:54.375 --> 00:13:58.330
който Адам и Ева поемат, за да излязат от градината.

00:13:58.330 --> 00:14:00.477
По думите на Дивака,

00:14:00.477 --> 00:14:03.546
възвръщането на автономност и свобода е възможно,

00:14:03.546 --> 00:14:06.225
дори цената да е висока.

00:14:06.225 --> 00:14:11.940
Така че аз вярвам, че една от определящите битки на нашето време

00:14:11.940 --> 00:14:14.503
ще бъде битката за контрол

00:14:14.503 --> 00:14:16.890
върху личната информация,

00:14:16.890 --> 00:14:20.397
битката за определяне на голямото количество информация

00:14:20.397 --> 00:14:21.686
като сила за освобождаване

00:14:21.686 --> 00:14:26.432
или инструмент за манипулиране.

00:14:26.432 --> 00:14:29.025
В момента много от нас

00:14:29.025 --> 00:14:31.778
дори не знаят, че битката е започнала,

00:14:31.778 --> 00:14:34.450
но тя започна, дори това да не ни харесва.

00:14:34.450 --> 00:14:37.254
И с риск да вляза в ролята на змията

00:14:37.254 --> 00:14:40.151
ще ви кажа, че оръжията за битката са тук,

00:14:40.151 --> 00:14:43.160
осъзнаване на случващото се,

00:14:43.160 --> 00:14:44.515
и във вашите ръце,

00:14:44.515 --> 00:14:48.255
само на няколко клика разстояние.

00:14:48.255 --> 00:14:49.737
Благодаря ви.

00:14:49.737 --> 00:14:54.214
(Аплодисменти)

