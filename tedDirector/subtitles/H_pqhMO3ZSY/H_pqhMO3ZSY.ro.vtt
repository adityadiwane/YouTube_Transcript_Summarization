WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Cristina Nedelcu
Corector: Ariana Bleau Lugo

00:00:12.641 --> 00:00:14.995
A dori să vă împărtășesc o poveste

00:00:14.995 --> 00:00:18.171
care leagă binecunoscutul fapt al intimității,

00:00:18.171 --> 00:00:20.940
care îi include pe Adam și pe Eva,

00:00:20.940 --> 00:00:24.386
și remarcabila schimbare între frontierele

00:00:24.386 --> 00:00:27.072
dintre public și privat, care a avut loc

00:00:27.072 --> 00:00:28.842
în ultimii 10 ani.

00:00:28.842 --> 00:00:30.140
Cunoașteți incidentul.

00:00:30.140 --> 00:00:33.470
Adam și Eva erau într-o zi în gradina Eden

00:00:33.470 --> 00:00:35.313
și au realizat ca sunt goi.

00:00:35.313 --> 00:00:36.813
S-au panicat.

00:00:36.813 --> 00:00:39.570
Iar restul este istorie.

00:00:39.570 --> 00:00:41.758
În zilele noastre, Adam și Eva

00:00:41.758 --> 00:00:44.119
s-ar comporta probabil diferit.

00:00:44.119 --> 00:00:46.387
[@Adam Aseară a fost o nebunie! mi-a plăcut mărul LOL]

00:00:46.387 --> 00:00:48.260
@ Eva dap..pui, știi ce s-a întâmplat cu pantalonii mei totuși?

00:00:48.260 --> 00:00:50.896
Dezvăluim mai multe informații

00:00:50.896 --> 00:00:54.230
despre noi online ca niciodată

00:00:54.230 --> 00:00:55.934
și atât de multe informații despre noi

00:00:55.934 --> 00:00:58.158
sunt adunate de diferite organizații.

00:00:58.158 --> 00:01:01.440
Sunt multe lucruri de câștigat de pe urma cărora beneficiezi

00:01:01.440 --> 00:01:03.886
din această masivă analiză a datelor personale,

00:01:03.886 --> 00:01:05.832
sau big data,

00:01:05.832 --> 00:01:08.470
dar există și complexe compromisuri care rezultă

00:01:08.470 --> 00:01:11.568
din distribuirea intimității.

00:01:11.568 --> 00:01:15.591
Povestea mea este despre aceste compromisuri.

00:01:15.591 --> 00:01:18.175
Începem cu o observație care, în mintea mea,

00:01:18.175 --> 00:01:21.502
a devenit din ce în ce mai clară în ultimii ani,

00:01:21.502 --> 00:01:23.599
și anume că orice date personale

00:01:23.599 --> 00:01:25.884
pot deveni informații susceptibile.

00:01:25.884 --> 00:01:30.009
În anul 2000, aproximativ 100 de miliarde de poze

00:01:30.009 --> 00:01:31.921
au fost făcute pe glob,

00:01:31.921 --> 00:01:34.986
dar numai o minusculă parte

00:01:34.986 --> 00:01:36.869
au fost încărcate online.

00:01:36.869 --> 00:01:40.230
În 2010, doar pe Facebook, într-o singură lună,

00:01:40.230 --> 00:01:43.500
2.5 miliarde de poze au fost încărcate,

00:01:43.500 --> 00:01:45.382
cele mai multe identificate.

00:01:45.382 --> 00:01:47.262
În același interval de timp,

00:01:47.262 --> 00:01:52.132
capacitatea calculatoarelor de a recunoaște persoane în poze

00:01:52.132 --> 00:01:55.740
s-a îmbunătățit cu trei ordine de mărire.

00:01:55.740 --> 00:01:57.622
Ce se întâmplă când combini

00:01:57.622 --> 00:01:59.123
aceste trei tehnologii:

00:01:59.123 --> 00:02:01.781
crește disponibilitatea datelor feței;

00:02:01.781 --> 00:02:05.429
se îmbunătățește abilitatea recunoașterii faciale a calculatoarelor;

00:02:05.429 --> 00:02:07.611
și, de asemenea, cloud computing,

00:02:07.611 --> 00:02:09.499
care dă oricui în acest ansamblu

00:02:09.499 --> 00:02:11.059
genul de putere cibernetică

00:02:11.059 --> 00:02:12.945
care în urma cu câțiva ani era doar domeniul

00:02:12.945 --> 00:02:14.727
agențiilor din trei litere;

00:02:14.727 --> 00:02:16.105
și informatica omniprezentă,

00:02:16.105 --> 00:02:18.997
care permite telefonului meu, care nu e un supercalculator,

00:02:18.997 --> 00:02:20.668
să se conecteze la internet

00:02:20.668 --> 00:02:23.002
și să facă sute de mii

00:02:23.002 --> 00:02:25.641
de măsurători faciale în câteva secunde?

00:02:25.641 --> 00:02:28.269
Ei bine, presupunem că rezultatul

00:02:28.269 --> 00:02:30.333
acestei combinații de tehnologii

00:02:30.333 --> 00:02:33.221
va fi o schimbare radicală în propriile noțiuni

00:02:33.221 --> 00:02:35.478
de intimitate și anonimitate.

00:02:35.478 --> 00:02:37.471
Pentru a testa, am făcut un experiment

00:02:37.471 --> 00:02:39.592
în campusul Universității Carnegie Mellon.

00:02:39.592 --> 00:02:41.691
Am rugat studenții care treceau pe langă noi

00:02:41.691 --> 00:02:43.470
să participe la un studiu,

00:02:43.470 --> 00:02:46.032
și am făcut o poză cu o cameră web,

00:02:46.032 --> 00:02:48.814
i-am rugat să completeze un formular pe un laptop.

00:02:48.814 --> 00:02:50.793
În timp ce ei completau formularul,

00:02:50.793 --> 00:02:53.590
noi am încărcat poza într-un grup cloud computer,

00:02:53.590 --> 00:02:55.317
și am folosit un program de recunoaștere facială

00:02:55.317 --> 00:02:57.722
pentru a potrivi poza cu baza de date

00:02:57.722 --> 00:03:00.115
a câtorva sute de mii de imagini

00:03:00.115 --> 00:03:03.711
pe care le-am descărcat de pe profilurile de Facebook.

00:03:03.711 --> 00:03:06.970
Până voluntarul ajungea la ultima pagină

00:03:06.970 --> 00:03:10.317
a formularului, pagina era actualizată dinamic

00:03:10.317 --> 00:03:12.630
cu 10 dintre cele mai bune poze care se potriveau

00:03:12.630 --> 00:03:14.915
pe care le-a găsit programul de recunoaștere

00:03:14.915 --> 00:03:16.653
și am întrebat voluntarii să ne arate

00:03:16.653 --> 00:03:20.773
dacă se regăseau în poză.

00:03:20.773 --> 00:03:24.472
Vedeți individul?

00:03:24.472 --> 00:03:27.317
Ei bine,computerul a reușit

00:03:27.317 --> 00:03:29.466
pentru unul din trei voluntari.

00:03:29.466 --> 00:03:32.650
Așadar, putem porni de la un portret anonim,

00:03:32.650 --> 00:03:36.134
offline sau online și putem folosi recunoașterea facială

00:03:36.134 --> 00:03:38.494
pentru a da un nume chipului anonim,

00:03:38.494 --> 00:03:40.602
asta mulțumită datelor sociale mass-media.

00:03:40.602 --> 00:03:42.474
Dar în urmă cu câțiva ani, am făcut altceva.

00:03:42.474 --> 00:03:44.297
Am început de la datele sociale mass-media,

00:03:44.297 --> 00:03:47.348
le-am combinat statistic cu date

00:03:47.348 --> 00:03:49.450
de la securitatea socială a guvernului Statelor Unite

00:03:49.450 --> 00:03:52.774
și am ajuns să prezicem numerele securității sociale,

00:03:52.774 --> 00:03:54.286
care în Statele Unite

00:03:54.286 --> 00:03:56.326
reprezintă informații sensibile.

00:03:56.326 --> 00:03:58.419
Vedeți unde vreau să ajung cu asta?

00:03:58.419 --> 00:04:01.341
Așadar, dacă punem cele două studii împreună,

00:04:01.341 --> 00:04:02.853
întrebarea devine --

00:04:02.853 --> 00:04:05.573
poți începe cu o față, și,

00:04:05.573 --> 00:04:07.884
folosind recunoașterea facială să găsești un nume

00:04:07.884 --> 00:04:10.553
și informații publice disponibile

00:04:10.553 --> 00:04:12.485
despre numele și aceea persoană,

00:04:12.485 --> 00:04:14.733
iar de la acele informații publice disponibile

00:04:14.733 --> 00:04:16.775
să deduci informații private

00:04:16.775 --> 00:04:18.381
mult mai sensibile decât cele

00:04:18.381 --> 00:04:19.873
pe care le asociezi chipului?

00:04:19.873 --> 00:04:21.789
Iar răspunsul este da, putem, și chiar am făcut acest lucru.

00:04:21.789 --> 00:04:24.357
Desigur, acuratețea devine din ce în ce mai slabă.

00:04:24.357 --> 00:04:25.301
[27% dintre primele 5 cifre SSN identificate ale voluntarilor( cu 4 încercări)]

00:04:25.301 --> 00:04:29.128
De fapt, ne-am decis să dezvoltăm o aplicație pentru iPhone

00:04:29.128 --> 00:04:31.843
care utilizează camera internă a telefonului

00:04:31.843 --> 00:04:33.443
pentru a face o poză subiectului

00:04:33.443 --> 00:04:34.930
și pentru a o încărca într-un nor,

00:04:34.930 --> 00:04:37.592
iar apoi să facă ceea ce tocmai v-am descris în timp real:

00:04:37.592 --> 00:04:39.680
căutând o potrivire, găsind informații publice,

00:04:39.680 --> 00:04:41.410
să caute informații sensibile

00:04:41.410 --> 00:04:44.001
și apoi să le trimită înapoi în telefon

00:04:44.001 --> 00:04:47.610
pentru a fi suprapus pe chipul subiectului,

00:04:47.610 --> 00:04:49.511
un exemplu de realitate sporită,

00:04:49.511 --> 00:04:51.962
probabil un exemplu înfiorător de realitate sporită.

00:04:51.962 --> 00:04:55.301
De fapt, nu am dezvoltat aplicația pentru a o face disponibilă,

00:04:55.301 --> 00:04:57.223
ci doar ca dovadă a conceptului.

00:04:57.223 --> 00:04:59.536
De fapt, luați aceste tehnologii

00:04:59.536 --> 00:05:01.373
și împingeți-le până la logica lor extremă.

00:05:01.373 --> 00:05:04.092
Imaginați-vă un viitor în care străinii din jurul vostru

00:05:04.092 --> 00:05:06.403
se vor uita la voi prin Google Glasses,

00:05:06.403 --> 00:05:08.710
sau, într-o zi, prin lentilele lor de contact,

00:05:08.710 --> 00:05:12.730
și vor folosi șapte sau opt puncte de date despre voi

00:05:12.730 --> 00:05:15.312
pentru a deduce altceva

00:05:15.312 --> 00:05:17.915
care ar putea fi știut despre voi.

00:05:17.915 --> 00:05:22.709
Cum ar arăta viitorul fără secrete?

00:05:22.709 --> 00:05:24.673
Ar trebui să ne pese?

00:05:24.673 --> 00:05:26.564
Poate ne-ar plăcea să credem

00:05:26.564 --> 00:05:29.604
că viitorul cu atâta bogăție de date

00:05:29.604 --> 00:05:32.118
ar putea fi un viitor fără părtiniri,

00:05:32.118 --> 00:05:35.701
dar de fapt, având atât de multe informații

00:05:35.701 --> 00:05:37.892
nu înseamnă că vom lua decizii

00:05:37.892 --> 00:05:39.598
care vor fi mai obiective.

00:05:39.598 --> 00:05:42.158
În cadrul unui alt experiment, am prezentat subiecților

00:05:42.158 --> 00:05:44.404
informații despre un potențial candidat la o slujbă

00:05:44.404 --> 00:05:47.582
Am inclus în aceste informații niște referințe,

00:05:47.582 --> 00:05:50.228
unele informații amuzante, absolut legale,

00:05:50.228 --> 00:05:52.693
dar poate puțin rușinoase

00:05:52.693 --> 00:05:54.713
pe care subiectul le-a postat online.

00:05:54.713 --> 00:05:57.079
Interesant, dintre subiecți,

00:05:57.079 --> 00:06:00.162
unii au postat informații comparabile,

00:06:00.162 --> 00:06:02.524
iar alții nu.

00:06:02.524 --> 00:06:04.473
Care grup credeți că,

00:06:04.473 --> 00:06:09.025
cel mai probabil, au judecat mai aspru subiectul nostru?

00:06:09.025 --> 00:06:10.982
Paradoxal, a fost grupul

00:06:10.982 --> 00:06:12.715
care a postat informați asemănătoare,

00:06:12.715 --> 00:06:15.657
un exemplu de disonanță morală.

00:06:15.657 --> 00:06:17.407
Acum, s-ar putea să vă gândiți

00:06:17.407 --> 00:06:19.109
că asta nu se aplică și în cazul meu,

00:06:19.109 --> 00:06:21.271
deoarece eu nu am nimic de ascuns.

00:06:21.271 --> 00:06:23.753
Dar, de fapt, intimitatea nu se rezumă

00:06:23.753 --> 00:06:27.429
la a avea ceva negativ de ascuns.

00:06:27.429 --> 00:06:29.783
Imaginați-vă că sunteți Directorul de Resurse Umane

00:06:29.783 --> 00:06:32.730
al unei anumite organizații și primiți CV-uri,

00:06:32.730 --> 00:06:35.203
și decideți să căutați mai multe date despre candidați.

00:06:35.203 --> 00:06:37.663
Așadar, căutați pe Google numele lor

00:06:37.663 --> 00:06:39.903
și într-un anumit univers,

00:06:39.903 --> 00:06:41.911
găsiți aceste informații.

00:06:41.911 --> 00:06:46.348
Sau, într-un univers paralel, găsiți aceste informații.

00:06:46.348 --> 00:06:49.065
Credeți că ați chema

00:06:49.065 --> 00:06:51.868
vreunul dintre candidați pentru interviu?

00:06:51.868 --> 00:06:54.150
Dacă așa credeți, atunci nu sunteți

00:06:54.150 --> 00:06:56.732
precum angajatorii americani, care, de fapt,

00:06:56.732 --> 00:07:00.039
sunt o parte din experimentul nostru, 
ceea ce înseamnă că am făcut exact asta.

00:07:00.039 --> 00:07:03.221
Am creat profile de Facebook, manipulând trăsături,

00:07:03.221 --> 00:07:06.072
apoi am început să trimitem CV-urile companiilor din Statele Unite,

00:07:06.072 --> 00:07:07.980
și am detectat, am monitorizat,

00:07:07.980 --> 00:07:10.373
dacă îi căutau pe candidați,

00:07:10.373 --> 00:07:12.205
și dacă acționau pe baza informațiilor

00:07:12.205 --> 00:07:14.143
găsite în mass-media social. Și chiar făceau asta.

00:07:14.143 --> 00:07:16.244
Discriminarea se petrecea prin mass-media social

00:07:16.244 --> 00:07:19.317
între candidați cu calificări similare.

00:07:19.317 --> 00:07:23.892
Marketerii doresc să credem

00:07:23.892 --> 00:07:26.161
că toate informațiile despre noi vor fi întotdeauna

00:07:26.161 --> 00:07:29.434
folosite într-o manieră avantajoasă pentru noi.

00:07:29.434 --> 00:07:33.149
Mai gândiți-vă. De ce ar trebui să fie cazul de fiecare dată?

00:07:33.149 --> 00:07:35.813
Într-un film care a apărut acum câțiva ani,

00:07:35.813 --> 00:07:38.366
„Raport Special", o scenă celebră,

00:07:38.366 --> 00:07:40.942
îl avea pe Tom Cruise într-un mall,

00:07:40.942 --> 00:07:44.718
iar o reclamă holografică personalizată

00:07:44.718 --> 00:07:46.553
apărea în jurul său

00:07:46.553 --> 00:07:49.780
Filmul se desfășoară în anul 2054,

00:07:49.780 --> 00:07:51.422
cam peste 40 de ani,

00:07:51.422 --> 00:07:54.330
și pe cât de captivantă pare acea tehnologie,

00:07:54.330 --> 00:07:56.976
deja subestimează enorm

00:07:56.976 --> 00:07:59.116
cantitatea de informații pe care organizațiile

00:07:59.116 --> 00:08:01.599
o pot aduna despre tine și cum o pot folosi

00:08:01.599 --> 00:08:04.997
să te influențeze într-o manieră de care nici nu îți vei da seama.

00:08:04.997 --> 00:08:07.100
Ca și exemplu, acesta este un alt experiment

00:08:07.100 --> 00:08:09.373
încă în desfășurare, nu este terminat.

00:08:09.373 --> 00:08:11.692
Imaginați-vă că o organizație ar avea acces

00:08:11.692 --> 00:08:13.748
la lista prietenilor tăi de pe Facebook,

00:08:13.748 --> 00:08:15.520
iar printr-un fel de algoritm

00:08:15.520 --> 00:08:19.254
pot detecta pe cei doi prieteni pe care îi placi cel mai mult.

00:08:19.254 --> 00:08:21.534
Și creează în viața reală

00:08:21.534 --> 00:08:24.376
un compozit facial al acestor doi prieteni.

00:08:24.376 --> 00:08:27.445
Studiile prioritare față de ale noastre au demonstrat că oamenii

00:08:27.445 --> 00:08:30.330
nu se mai recunosc pe ei înșiși

00:08:30.330 --> 00:08:32.792
în compozitele faciale, dar reacționează

00:08:32.792 --> 00:08:34.909
la acele compozite în mod pozitiv

00:08:34.909 --> 00:08:38.324
Așadar, data viitoare când căutați un anume produs

00:08:38.324 --> 00:08:40.883
și este o reclamă care vă sugerează să îl cumpărați,

00:08:40.883 --> 00:08:43.790
nu va fi doar un purtător de cuvânt obișnuit.

00:08:43.790 --> 00:08:46.103
Va fi unul dintre prietenii tăi,

00:08:46.103 --> 00:08:49.406
iar tu nici măcar nu vei ști că acest lucru se întâmplă.

00:08:49.406 --> 00:08:51.819
Acum, problema este că

00:08:51.819 --> 00:08:54.338
mecanismele poliței curente pe care le avem

00:08:54.338 --> 00:08:57.776
pentru a ne proteja de abuzul informațiilor personale

00:08:57.776 --> 00:09:00.760
sunt precum cuțitul împotriva unui pistol.

00:09:00.760 --> 00:09:03.673
Unul dintre aceste mecanisme este transparența,

00:09:03.673 --> 00:09:06.873
să le spui oamenilor ce vei face cu informațiile lor.

00:09:06.873 --> 00:09:08.979
Și în principiu, acesta e un lucru foarte bun.

00:09:08.979 --> 00:09:12.646
E necesar, dar nu suficient.

00:09:12.646 --> 00:09:16.344
Transparența poate fi rău direcționată.

00:09:16.344 --> 00:09:18.448
Poți spune oamenilor ce vei face,

00:09:18.448 --> 00:09:20.680
și apoi tot îi împingi să dezvăluie

00:09:20.680 --> 00:09:23.303
anumite informații personale.

00:09:23.303 --> 00:09:26.189
Așadar, într-un alt experiment cu studenți,

00:09:26.189 --> 00:09:29.247
i-am rugat să ne furnizeze informații

00:09:29.247 --> 00:09:31.060
despre comportamentul lor în campus,

00:09:31.060 --> 00:09:34.000
incluzând întrebări sensibile, precum aceasta.

00:09:34.000 --> 00:09:34.621
[Ați copiat vreodată la vreun examen?]

00:09:34.621 --> 00:09:36.921
Unui grup de indivizi le-am spus

00:09:36.921 --> 00:09:39.762
„Doar alți studenți vor vedea răspunsurile voastre."

00:09:39.762 --> 00:09:41.341
Unui alt grup le-am spus:

00:09:41.341 --> 00:09:44.902
„Studenții și facultatea vor vedea răspunsurile voastre."

00:09:44.902 --> 00:09:47.493
Transparență. Notificare. Și destul de sigur, a funcționat

00:09:47.493 --> 00:09:48.900
în sensul că primul grup de studenți

00:09:48.900 --> 00:09:51.468
era mai predispus să dezvăluie decât cel de-al doilea grup.

00:09:51.468 --> 00:09:52.988
Logic, nu?

00:09:52.988 --> 00:09:54.478
Apoi am adăugat o îndrumare greșită.

00:09:54.478 --> 00:09:57.238
Am repetat experimentul cu aceleași două grupuri,

00:09:57.238 --> 00:09:59.665
de data aceasta adăugând un timp

00:09:59.665 --> 00:10:02.600
între momentul când le-am spus subiecților

00:10:02.600 --> 00:10:04.680
cum le vom folosi informațiile

00:10:04.680 --> 00:10:09.068
și momentul când am început de fapt să răspundem la întrebări.

00:10:09.068 --> 00:10:11.629
Cât timp credeți că a trebuit să adăugăm

00:10:11.629 --> 00:10:16.242
pentru a elimina efectul inhibitor

00:10:16.242 --> 00:10:19.653
de a ști că facultatea îți va vedea răspunsurile?

00:10:19.653 --> 00:10:21.433
Zece minute?

00:10:21.433 --> 00:10:23.224
Cinci minute?

00:10:23.224 --> 00:10:25.000
Un minut?

00:10:25.000 --> 00:10:27.049
Ce ziceți de 15 secunde?

00:10:27.049 --> 00:10:29.717
Cincisprezece secunde au fost suficiente pentru ca cele două grupuri

00:10:29.717 --> 00:10:31.285
să dezvăluie aceleași informații,

00:10:31.285 --> 00:10:34.031
ca și cum celui de-al doilea grup nici nu-i mai păsa

00:10:34.031 --> 00:10:36.687
că facultatea le citește răspunsurile.

00:10:36.687 --> 00:10:40.023
Trebuie să admit că acest discurs până acum

00:10:40.023 --> 00:10:42.503
poate suna extrem de sumbru,

00:10:42.503 --> 00:10:44.224
dar nu asta vreau să spun.

00:10:44.224 --> 00:10:46.923
De fapt, vreau să împărtășesc cu voi faptul că

00:10:46.923 --> 00:10:48.695
există alternative.

00:10:48.695 --> 00:10:51.194
Modul în care facem lucrurile astăzi nu e singura modalitate

00:10:51.194 --> 00:10:54.231
în care se pot face și cu siguranță nu cea mai bună cale

00:10:54.231 --> 00:10:56.258
prin care pot fi făcute.

00:10:56.258 --> 00:11:00.429
Când cineva își spune că, „Oamenilor nu le pasă de intimitate,"

00:11:00.429 --> 00:11:03.071
gândește-te dacă jocul a fost creat

00:11:03.071 --> 00:11:05.795
și falsificat pentru ca lor să nu le mai pese de intimitate,

00:11:05.795 --> 00:11:09.057
și au ajuns să realizeze că apariția acestor manipulări

00:11:09.057 --> 00:11:10.664
este deja la jumătatea drumului

00:11:10.664 --> 00:11:12.922
de a fi capabil să te protejezi singur.

00:11:12.922 --> 00:11:16.632
Când cineva îți spune că intimitatea e incompatibilă

00:11:16.632 --> 00:11:18.481
cu beneficiile datelor uriașe,

00:11:18.481 --> 00:11:20.954
consideră că în ultimii 20 de ani,

00:11:20.954 --> 00:11:22.871
cercetătorii au creat tehnologii

00:11:22.871 --> 00:11:26.189
care permit desfășurarea virtuală a oricărei tranzacții

00:11:26.189 --> 00:11:29.938
într-o manieră mult mai eficientă de conservare a intimității.

00:11:29.938 --> 00:11:32.493
Putem să navigăm pe internet în mod anonim.

00:11:32.493 --> 00:11:35.171
Putem trimite emailuri care pot fi citite doar

00:11:35.171 --> 00:11:38.880
de destinatarul intenționat, nici măcar de ANS.

00:11:38.880 --> 00:11:41.877
Putem avea chiar și exploatare a datelor într-o manieră de prezervare a intimității.

00:11:41.877 --> 00:11:45.771
Cu alte cuvinte, putem avea beneficiile datelor uriașe

00:11:45.771 --> 00:11:47.903
în timp ce ne protejăm intimitatea.

00:11:47.903 --> 00:11:51.694
Desigur, aceste tehnologii presupun o deplasare

00:11:51.694 --> 00:11:53.240
de costuri și venituri

00:11:53.240 --> 00:11:55.347
între deținătorii de date și persoanele vizate,

00:11:55.347 --> 00:11:58.800
motiv pentru care nu auziți mai multe despre ei.

00:11:58.800 --> 00:12:02.506
Lucru care mă readuce la Grădina Eden.

00:12:02.506 --> 00:12:05.286
Există o a doua interpretare a inimității

00:12:05.286 --> 00:12:07.095
poveștii din Grădina Edenului,

00:12:07.095 --> 00:12:09.191
care n-are legătură cu această problemă

00:12:09.191 --> 00:12:11.416
a lui Adam și Eva de a se simți dezbrăcați

00:12:11.416 --> 00:12:13.797
și de a se simți rușinați.

00:12:13.797 --> 00:12:16.578
Puteți găsi variante ale acestei interpretări

00:12:16.578 --> 00:12:19.360
în „Paradisul pierdut" a lui John Milton.

00:12:19.360 --> 00:12:23.557
În grădină, Adam și Eva sunt conținut material.

00:12:23.557 --> 00:12:25.661
Sunt fericiți. Sunt satisfăcuți.

00:12:25.661 --> 00:12:27.954
Dar le lipsește cunoștința

00:12:27.954 --> 00:12:29.594
și conștiința de sine.

00:12:29.594 --> 00:12:32.913
În momentul în care mănâncă fructul, numit pe bună dreptate,

00:12:32.913 --> 00:12:34.206
al cunoștinței,

00:12:34.206 --> 00:12:36.811
atunci se descoperă pe sine.

00:12:36.811 --> 00:12:40.842
Devin conștienți. Ating autonomia.

00:12:40.842 --> 00:12:43.968
Prețul care trebuie plătit, totuși, este părăsirea grădinii.

00:12:43.968 --> 00:12:47.849
Așadar intimitatea, într-un fel, este și modalitatea

00:12:47.849 --> 00:12:50.811
și prețul care trebuie plătit pentru libertate.

00:12:50.811 --> 00:12:53.581
Din nou, marketerii ne spun

00:12:53.581 --> 00:12:56.600
că big data și mass-media socială

00:12:56.600 --> 00:12:59.579
nu sunt doar un paradis de profit pentru ei,

00:12:59.579 --> 00:13:02.036
dar și o Grădină a Edenului pentru restul dintre noi.

00:13:02.036 --> 00:13:03.274
Obținem conținut gratuit.

00:13:03.274 --> 00:13:06.397
Putem să jucăm Angry Birds. Putem să luăm aplicații vizate.

00:13:06.397 --> 00:13:09.294
Dar de fapt, în câțiva ani, organizațiile

00:13:09.294 --> 00:13:10.903
care cunosc atât de multe despre noi,

00:13:10.903 --> 00:13:13.613
vor putea să deducă dorințele noastre

00:13:13.613 --> 00:13:15.817
înainte ca noi să ni le formăm, și poate

00:13:15.817 --> 00:13:18.264
să cumpere produse în contul nostru

00:13:18.264 --> 00:13:20.538
înainte ca noi să fim conștienți că avem nevoie de ele.

00:13:20.538 --> 00:13:23.775
A fost un autor englez

00:13:23.775 --> 00:13:26.820
care a anticipat acest gen de viitor

00:13:26.820 --> 00:13:28.225
unde ne vom vinde

00:13:28.225 --> 00:13:31.773
autonomia și libertatea pentru confort.

00:13:31.773 --> 00:13:33.934
Chiar mai neașteptat decât George Orwell,

00:13:33.934 --> 00:13:36.695
autorul este, desigur, Aldous Huxley.

00:13:36.695 --> 00:13:39.549
În „Brave New World", el își imaginează o societate

00:13:39.549 --> 00:13:41.720
unde tehnologiile pe care le-am creat

00:13:41.720 --> 00:13:43.579
inițial pentru libertate,

00:13:43.579 --> 00:13:46.146
ne vor constrânge.

00:13:46.146 --> 00:13:50.937
Totuși, în carte, el oferă de asemenea o cale de ieșire

00:13:50.937 --> 00:13:54.375
din acea societate, asemănătoare cu drumul

00:13:54.375 --> 00:13:58.330
pe care Adam și Eva au trebuit să îl urmeze pentru a părăsi grădina.

00:13:58.330 --> 00:14:00.477
În limba băștinașilor,

00:14:00.477 --> 00:14:03.546
recâștigarea autonomiei și a libertății este posibilă,

00:14:03.546 --> 00:14:06.225
dar prețul care trebuie plătit este piperat.

00:14:06.225 --> 00:14:11.940
Așadar, una dintre bătăliile definitorii

00:14:11.940 --> 00:14:14.503
ale timpului nostru ar fi lupta

00:14:14.503 --> 00:14:16.890
pentru controlul informațiilor personale,

00:14:16.890 --> 00:14:20.397
lupta pentru big data va deveni o forță

00:14:20.397 --> 00:14:21.686
pentru libertate,

00:14:21.686 --> 00:14:26.432
decât o forță care ne va manipula în tăcere.

00:14:26.432 --> 00:14:29.025
Acum, mulți dintre noi

00:14:29.025 --> 00:14:31.778
nu suntem conștienți că lupta are loc,

00:14:31.778 --> 00:14:34.450
dar are, chiar dacă vă place sau nu.

00:14:34.450 --> 00:14:37.254
Iar cu riscul de a juca rolul șarpelui,

00:14:37.254 --> 00:14:40.151
vă voi spune că instrumentele pentru luptă

00:14:40.151 --> 00:14:43.160
sunt aici, conștientizarea a ceea ce se întâmplă,

00:14:43.160 --> 00:14:44.515
iar în mâinile voastre,

00:14:44.515 --> 00:14:48.255
doar la câteva click-uri distanță.

00:14:48.255 --> 00:14:49.737
Mulțumesc.

00:14:49.737 --> 00:14:54.214
(Aplauze)

