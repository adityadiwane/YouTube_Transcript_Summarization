WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Lidia Cámara de la Fuente
Revisor: Ciro Gomez

00:00:12.787 --> 00:00:16.632
¿Pastel favorito en EEUU?

00:00:16.632 --> 00:00:20.138
Audiencia: El de manzana. 
Kenneth Cukier: De manzana. Por supuesto.

00:00:20.138 --> 00:00:21.369
¿Cómo lo sabemos?

00:00:21.369 --> 00:00:24.122
Por los datos.

00:00:24.122 --> 00:00:26.188
Se miran las ventas en supermercados.

00:00:26.188 --> 00:00:29.054
Se miran las ventas en supermercados 
de pasteles de 30 cm

00:00:29.054 --> 00:00:33.129
congelados, y los de manzana 
ganan, sin rival.

00:00:33.129 --> 00:00:38.309
La mayoría de las ventas son 
los de manzana.

00:00:38.309 --> 00:00:41.273
Pero los supermercados 
comenzaron a vender

00:00:41.273 --> 00:00:43.856
pasteles más pequeños, de 11 cm,

00:00:43.856 --> 00:00:48.030
y de repente, el de manzana 
cayó al 4º o 5º lugar.

00:00:48.030 --> 00:00:50.905
¿Por qué? ¿Qué paso?

00:00:50.905 --> 00:00:53.723
Bueno, piensen en ello.

00:00:53.723 --> 00:00:57.571
Cuando compramos un pastel de 30 cm,

00:00:57.571 --> 00:00:59.832
toda la familia tiene 
que estar de acuerdo,

00:00:59.832 --> 00:01:03.623
y el de manzana es el segundo 
favorito de todos.

00:01:03.623 --> 00:01:05.558
(Risas)

00:01:05.558 --> 00:01:09.173
Pero si uno compra 
un pastel de 11 cm individual,

00:01:09.173 --> 00:01:12.918
puede comprar el que desee.

00:01:12.918 --> 00:01:16.933
Puede comprar su primera opción.

00:01:16.933 --> 00:01:18.574
Tenemos más datos.

00:01:18.574 --> 00:01:20.128
Podemos ver algo

00:01:20.128 --> 00:01:21.260
que no se podía ver

00:01:21.260 --> 00:01:25.213
cuando solo había menor 
cantidad de datos.

00:01:25.213 --> 00:01:27.688
Ahora, el punto es que 
muchos más datos

00:01:27.688 --> 00:01:29.971
no solo nos permiten ver más,

00:01:29.971 --> 00:01:31.825
más de lo mismo 
que ya veíamos.

00:01:31.825 --> 00:01:35.438
Más datos nos permiten 
ver cosas nuevas.

00:01:35.438 --> 00:01:38.532
Nos permiten ver mejor.

00:01:38.532 --> 00:01:42.188
Nos permiten ver 
de forma diferente.

00:01:42.188 --> 00:01:45.361
En este caso, nos permiten ver

00:01:45.361 --> 00:01:48.274
que el pastel favorito de EEUU es:

00:01:48.274 --> 00:01:50.816
no el de manzana.

00:01:50.816 --> 00:01:54.223
Puede que todos hayan oído escuchado 
el término "Datos masivos".

00:01:54.223 --> 00:01:56.927
De hecho, es probable que 
estén hartos de escucharlo

00:01:56.927 --> 00:01:58.117
"Datos masivos".

00:01:58.117 --> 00:02:01.447
Es cierto que se exagera 
mucho el término,

00:02:01.447 --> 00:02:03.779
y eso es muy lamentable,

00:02:03.779 --> 00:02:06.825
porque los datos masivos 
son una herramienta muy importante

00:02:06.825 --> 00:02:10.559
para que la sociedad avance.

00:02:10.559 --> 00:02:14.120
En el pasado, solíamos observar 
pequeñas cantidades de datos

00:02:14.120 --> 00:02:15.824
y pensar qué significarían

00:02:15.824 --> 00:02:17.406
para tratar de entender el mundo.

00:02:17.406 --> 00:02:19.311
Ahora tenemos mucho más de ello,

00:02:19.311 --> 00:02:22.032
más de lo que podía existir antes.

00:02:22.032 --> 00:02:23.996
Lo que encontramos es que 
cuando tenemos

00:02:23.996 --> 00:02:26.740
una gran cantidad de datos, 
podemos hacer cosas

00:02:26.740 --> 00:02:29.910
que no podíamos hacer 
teniendo solo cantidades más pequeñas.

00:02:29.910 --> 00:02:32.551
Los datos masivos son importantes 
y es algo nuevo,

00:02:32.551 --> 00:02:34.328
y cuando se piensa en ello,

00:02:34.328 --> 00:02:36.544
la única forma en que 
este planeta afronte

00:02:36.544 --> 00:02:38.399
sus desafíos mundiales, esto es,

00:02:38.399 --> 00:02:41.870
alimentar a la gente, 
ofrecer atención médica,

00:02:41.870 --> 00:02:44.680
suministrar energía, electricidad,

00:02:44.680 --> 00:02:46.589
y asegurarse de que 
no nos achicharramos

00:02:46.589 --> 00:02:48.326
debido al calentamiento global,

00:02:48.326 --> 00:02:51.902
es utilizando de forma eficaz los datos.

00:02:51.902 --> 00:02:55.772
Entonces, ¿qué es lo nuevo de 
los datos masivos? ¿Cuál es la gran cosa?

00:02:55.772 --> 00:02:58.289
Bueno, para responder a esto, 
pensaremos en

00:02:58.289 --> 00:03:00.185
cómo se veía la información,

00:03:00.185 --> 00:03:03.219
físicamente en el pasado.

00:03:03.219 --> 00:03:06.830
En 1908 en la isla de Creta,

00:03:06.830 --> 00:03:11.565
los arqueólogos descubrieron 
un disco de arcilla.

00:03:11.565 --> 00:03:15.684
Datan del año 2000 aC, 
así que tienen 4000 años de antigüedad.

00:03:15.684 --> 00:03:17.628
Hay inscripciones en este disco,

00:03:17.628 --> 00:03:19.168
pero, no sabemos 
qué significan.

00:03:19.168 --> 00:03:21.426
Es un completo misterio, 
pero el punto es que

00:03:21.426 --> 00:03:23.061
así solía verse la información

00:03:23.061 --> 00:03:25.070
hace 4000 años.

00:03:25.070 --> 00:03:27.618
Esta es la forma en que 
la sociedad almacenaba

00:03:27.618 --> 00:03:31.142
y transmitía la información.

00:03:31.142 --> 00:03:35.302
Ahora, la sociedad no ha avanzado tanto.

00:03:35.302 --> 00:03:38.776
Todavía guardamos 
la información en discos,

00:03:38.776 --> 00:03:41.960
pero ahora podemos almacenar 
mucha más información,

00:03:41.960 --> 00:03:43.220
más que nunca.

00:03:43.220 --> 00:03:46.313
Buscar es más fácil. Copiar es más fácil.

00:03:46.313 --> 00:03:49.813
El compartir es más fácil. 
El procesamiento es más fácil.

00:03:49.813 --> 00:03:52.579
Y podemos volver 
a utilizar esta información

00:03:52.579 --> 00:03:54.413
para usos que nunca 
nos imaginamos

00:03:54.413 --> 00:03:57.608
cuando se recogieron los primeros datos.

00:03:57.608 --> 00:03:59.860
A este respecto, los datos 
han evolucionado

00:03:59.860 --> 00:04:03.392
de un almacén a un flujo,

00:04:03.392 --> 00:04:07.330
de algo que es estacionario y estático

00:04:07.330 --> 00:04:10.939
a algo que es fluido y dinámico.

00:04:10.939 --> 00:04:15.042
Hay, si quieren, 
una liquidez de información.

00:04:15.502 --> 00:04:18.436
El disco descubierto fuera de Creta

00:04:18.436 --> 00:04:22.200
que tiene 4000 años 
de antigüedad, es pesado,

00:04:22.200 --> 00:04:24.162
no almacena gran cantidad de información,

00:04:24.162 --> 00:04:27.278
y esa información no es modificable.

00:04:27.278 --> 00:04:31.289
Por el contrario, todos los archivos

00:04:31.289 --> 00:04:33.149
que Edward Snowden tomó

00:04:33.149 --> 00:04:35.771
de la Agencia de Seguridad Nacional 
de EEUU

00:04:35.771 --> 00:04:38.190
caben en un dispositivo 
de memoria extraíble

00:04:38.190 --> 00:04:41.200
del tamaño de una uña,

00:04:41.200 --> 00:04:45.945
y pueden compartirse 
a la velocidad de la luz.

00:04:45.945 --> 00:04:50.740
Más datos. Más.

00:04:50.740 --> 00:04:53.174
Una razón para tener tantos datos 
hoy en el mundo

00:04:53.174 --> 00:04:54.606
es que recolectamos cosas

00:04:54.606 --> 00:04:57.886
sobre las que siempre 
hemos recopilado información,

00:04:57.886 --> 00:05:00.542
pero otra razón es que 
estamos tomando cosas

00:05:00.542 --> 00:05:03.354
que siempre han sido informacionales

00:05:03.354 --> 00:05:05.893
pero nunca se habían convertido 
a un formato de datos

00:05:05.893 --> 00:05:08.259
y las estamos convirtiendo en datos.

00:05:08.259 --> 00:05:11.567
Piensen, por ejemplo, 
en la cuestión de la ubicación.

00:05:11.567 --> 00:05:13.816
Tomemos, por ejemplo, Martín Lutero.

00:05:13.816 --> 00:05:15.653
Si hubiéramos querido 
saber en 1500

00:05:15.653 --> 00:05:18.080
donde estaba Martín Lutero,

00:05:18.080 --> 00:05:20.512
habríamos tenido que seguirlo 
en todo momento,

00:05:20.512 --> 00:05:22.362
quizá con pluma y tintero,

00:05:22.362 --> 00:05:23.985
y anotarlo.

00:05:23.985 --> 00:05:26.168
Pero piensen cómo es hoy en día.

00:05:26.168 --> 00:05:28.010
Uds. saben que en algún lugar,

00:05:28.010 --> 00:05:31.116
quizá en la base de datos 
de una empresa de telecomunicaciones,

00:05:31.116 --> 00:05:33.772
hay una hoja de cálculo o 
entrada de base de datos

00:05:33.772 --> 00:05:35.860
donde se registra su información

00:05:35.860 --> 00:05:37.923
de donde han estado 
en todo momento.

00:05:37.923 --> 00:05:39.283
Si tienen celular,

00:05:39.283 --> 00:05:42.130
y el teléfono tiene GPS, 
pero incluso si no tiene GPS,

00:05:42.130 --> 00:05:44.515
se puede registrar su información.

00:05:44.515 --> 00:05:48.599
En este sentido, la localización 
ha sido un campo de datos.

00:05:48.599 --> 00:05:53.200
Ahora piensen, por ejemplo, 
en el tema de la postura,

00:05:53.200 --> 00:05:55.291
la forma en que están 
sentados ahora,

00:05:55.291 --> 00:05:56.788
la forma en Ud. está sentado,

00:05:56.788 --> 00:05:59.259
la de Ud., la de Ud.

00:05:59.259 --> 00:06:02.760
Todas diferentes, en función 
de la longitud de las piernas,

00:06:02.760 --> 00:06:03.989
la espalda y su contorno,

00:06:03.989 --> 00:06:05.987
y si pusiera censores, 
tal vez 100

00:06:05.987 --> 00:06:07.753
en todos los asientos ahora,

00:06:07.753 --> 00:06:11.353
podría crear un índice 
que es único para cada uno,

00:06:11.353 --> 00:06:15.762
algo así como una huella digital, 
que no es del dedo.

00:06:15.762 --> 00:06:18.731
Y entonces, 
¿qué podemos hacer con esto?

00:06:18.731 --> 00:06:21.128
Los investigadores en Tokio 
están utilizando

00:06:21.128 --> 00:06:25.516
como un dispositivo potencial 
antirobo en los autos.

00:06:25.516 --> 00:06:28.440
La idea es que el ladrón
se siente al volante,

00:06:28.440 --> 00:06:30.544
intente encenderlo, 
pero el auto reconoce

00:06:30.544 --> 00:06:32.906
que un conductor no autorizado 
está en el auto

00:06:32.906 --> 00:06:35.070
y, tal vez el motor se detiene, 
a menos que

00:06:35.070 --> 00:06:38.247
escriba una contraseña 
en el salpicadero

00:06:38.247 --> 00:06:42.905
para decir, "Tengo la autorización 
para conducir". Estupendo.

00:06:42.905 --> 00:06:45.458
¿Qué pasaría si cada automóvil 
en Europa

00:06:45.458 --> 00:06:46.915
tuviera esta tecnología?

00:06:46.915 --> 00:06:50.080
¿Qué podemos hacer entonces?

00:06:50.080 --> 00:06:52.320
Tal vez, si agregamos los datos,

00:06:52.320 --> 00:06:56.134
tal vez podríamos identificar 
signos reveladores

00:06:56.134 --> 00:06:58.843
que predijeran mejor 
que un accidente de auto

00:06:58.843 --> 00:07:04.736
tendrá lugar en los próximos 
cinco segundos.

00:07:04.736 --> 00:07:07.293
Y entonces, 
la base de datos que tendremos

00:07:07.293 --> 00:07:09.076
es la fatiga del conductor,

00:07:09.076 --> 00:07:12.160
y el servicio se activaría 
cuando los sensores del automóvil

00:07:12.160 --> 00:07:14.847
detectaran que la persona 
reposa en esa posición,

00:07:14.847 --> 00:07:18.841
y automáticamente 
se activa una alarma interna

00:07:18.841 --> 00:07:21.120
que haría vibrar el volante, 
sonar una alarma

00:07:21.120 --> 00:07:22.587
para decir, "Despierta,

00:07:22.587 --> 00:07:24.491
presta más atención a la carretera".

00:07:24.491 --> 00:07:26.510
Este es el tipo de cosas 
que podemos hacer

00:07:26.510 --> 00:07:29.451
cuando tomamos datos 
en más aspectos de nuestras vidas.

00:07:29.451 --> 00:07:32.840
Entonces, ¿cuál es el valor 
de los datos masivos?

00:07:32.840 --> 00:07:35.030
Bueno, piensen en ello.

00:07:35.030 --> 00:07:37.442
Tienen más información.

00:07:37.442 --> 00:07:40.783
Pueden hacer cosas que antes 
no se podían hacer.

00:07:40.783 --> 00:07:42.459
Una de las zonas más impresionantes

00:07:42.459 --> 00:07:44.234
donde este concepto se ve aplicado

00:07:44.234 --> 00:07:47.495
es en el área del 
aprendizaje automático.

00:07:47.495 --> 00:07:50.758
El aprendizaje automático es una rama 
de la inteligencia artificial,

00:07:50.758 --> 00:07:53.950
que en sí es una rama de la informática.

00:07:53.950 --> 00:07:55.579
La idea general es que en lugar de

00:07:55.579 --> 00:07:57.610
enseñar a un equipo algo,

00:07:57.610 --> 00:08:00.230
simplemente transferiremos 
datos al problema

00:08:00.230 --> 00:08:03.436
para decirle a la computadora 
que lo averigüe sola.

00:08:03.436 --> 00:08:05.213
Y nos ayude a entenderlo

00:08:05.213 --> 00:08:08.765
al ver sus orígenes.

00:08:08.765 --> 00:08:11.279
En la década de 1950, 
un científico de computación

00:08:11.279 --> 00:08:14.745
en IBM llamado Arthur Samuel 
al que le gustaba jugar a damas,

00:08:14.745 --> 00:08:16.147
por eso escribió 
un programa

00:08:16.147 --> 00:08:18.960
para poder jugar contra la computadora.

00:08:18.960 --> 00:08:21.671
Jugó. Ganó.

00:08:21.671 --> 00:08:23.774
Jugó. Ganó.

00:08:23.774 --> 00:08:26.789
Jugó. Ganó,

00:08:26.789 --> 00:08:28.567
porque el equipo solo sabía

00:08:28.567 --> 00:08:30.794
lo que era un movimiento legal.

00:08:30.794 --> 00:08:32.881
Arthur Samuel sabía algo más.

00:08:32.881 --> 00:08:37.510
Arthur Samuel sabía estrategia.

00:08:37.510 --> 00:08:39.906
Así que escribió un pequeño subprograma

00:08:39.906 --> 00:08:41.880
operando en el fondo. 
Y todo lo que hizo

00:08:41.880 --> 00:08:43.697
fue anotar la probabilidad

00:08:43.697 --> 00:08:46.260
de que una configuración 
del tablero condujera

00:08:46.260 --> 00:08:49.169
a un tablero ganador frente 
a un tablero perdedor

00:08:49.169 --> 00:08:51.678
después de cada movimiento.

00:08:51.678 --> 00:08:54.828
Él jugó contra el equipo. 
Él ganó.

00:08:54.828 --> 00:08:57.336
Él jugó contra el equipo. 
Él ganó.

00:08:57.336 --> 00:09:01.067
Él jugó contra el equipo. 
Él ganó.

00:09:01.067 --> 00:09:03.344
Y luego Arthur Samuel dejó 
que la computadora

00:09:03.344 --> 00:09:05.571
jugara sola.

00:09:05.571 --> 00:09:09.080
Juega sola. Y recoge más datos.

00:09:09.080 --> 00:09:13.389
Recoge más datos. 
Aumenta la precisión de su predicción.

00:09:13.389 --> 00:09:15.493
Y luego Arthur Samuel vuelve al equipo

00:09:15.493 --> 00:09:17.811
juega y pierde.

00:09:17.811 --> 00:09:19.880
Y juega y pierde.

00:09:19.880 --> 00:09:21.927
Y juega y pierde.

00:09:21.927 --> 00:09:24.526
Y Arthur Samuel ha creado una máquina

00:09:24.526 --> 00:09:30.814
que supera su capacidad 
en una tarea que él enseñó.

00:09:30.814 --> 00:09:33.312
Y esta idea de aprendizaje automático

00:09:33.312 --> 00:09:37.239
irá a todas partes.

00:09:37.239 --> 00:09:40.388
¿Cómo creen que tenemos 
autos autodirigidos?

00:09:40.388 --> 00:09:42.525
¿Estamos mejor como sociedad

00:09:42.525 --> 00:09:45.810
almacenando todas las reglas 
de la carretera en un software?

00:09:45.810 --> 00:09:48.408
No. La memoria es más barata. No.

00:09:48.408 --> 00:09:52.402
Los algoritmos son más rápidos. No. 
Los procesadores son mejores. No.

00:09:52.402 --> 00:09:55.174
Todas esas cosas importan, 
pero no es por eso.

00:09:55.174 --> 00:09:58.315
Es porque hemos cambiado 
la naturaleza del problema.

00:09:58.315 --> 00:09:59.991
Hemos cambiado 
el problema de uno

00:09:59.991 --> 00:10:02.343
en el que intentábamos 
abierta y explícitamente

00:10:02.343 --> 00:10:04.671
explicar a la computadora 
cómo conducir,

00:10:04.671 --> 00:10:05.987
a uno en la que decimos,

00:10:05.987 --> 00:10:08.396
"Aquí hay una gran cantidad 
de datos del vehículo.

00:10:08.396 --> 00:10:09.396
Haz los números.

00:10:09.396 --> 00:10:11.396
Te diste cuenta de que eso es un semáforo,

00:10:11.396 --> 00:10:13.344
que está en rojo 
y no verde,

00:10:13.344 --> 00:10:15.358
eso significa que tienes 
que detenerte

00:10:15.358 --> 00:10:18.401
y no seguir".

00:10:18.401 --> 00:10:20.398
El aprendizaje automático está en la base

00:10:20.398 --> 00:10:22.826
de muchas cosas 
que hacemos en línea:

00:10:22.826 --> 00:10:23.807
motores de búsqueda,

00:10:23.807 --> 00:10:27.608
el algoritmo de personalización 
de Amazon,

00:10:27.608 --> 00:10:29.820
la traducción automática 
por computadora,

00:10:29.820 --> 00:10:34.110
los sistemas de reconocimiento de voz.

00:10:34.110 --> 00:10:37.231
Recientemente, 
los investigadores han examinado

00:10:37.231 --> 00:10:40.140
la cuestión de biopsias,

00:10:40.140 --> 00:10:42.907
biopsias de cáncer,

00:10:42.907 --> 00:10:45.222
y han usado la computadora 
para identificar,

00:10:45.222 --> 00:10:47.693
mirando los datos y 
las tasas de supervivencia,

00:10:47.693 --> 00:10:52.360
si las células son en realidad

00:10:52.360 --> 00:10:54.904
cancerosas o no,

00:10:54.904 --> 00:10:56.682
y claro, al trasferir 
los datos

00:10:56.682 --> 00:10:58.729
por un algoritmo 
de aprendizaje automático,

00:10:58.729 --> 00:11:00.606
la máquina fue capaz de identificar

00:11:00.606 --> 00:11:02.968
los 12 signos reveladores 
que mejor predicen

00:11:02.968 --> 00:11:06.167
si en esta biopsia de 
células de cáncer de mama,

00:11:06.167 --> 00:11:09.385
hay, en efecto, cáncer.

00:11:09.385 --> 00:11:11.883
El problema: la literatura médica

00:11:11.883 --> 00:11:14.672
solo sabía nueve de ellos.

00:11:14.672 --> 00:11:16.472
Tres de los rasgos eran de

00:11:16.472 --> 00:11:19.447
los que las personas no buscan,

00:11:19.447 --> 00:11:23.417
pero que la máquina descubrió.

00:11:26.351 --> 00:11:30.829
También hay lados oscuros 
en los datos masivos.

00:11:30.829 --> 00:11:32.977
Mejorará nuestras vidas, 
pero hay problemas

00:11:32.977 --> 00:11:35.617
de los que tenemos que 
ser conscientes,

00:11:35.617 --> 00:11:38.240
y el primero es la idea

00:11:38.240 --> 00:11:40.926
de que podemos ser castigados 
por las predicciones,

00:11:40.926 --> 00:11:44.796
que la policía puede utilizar 
datos masivos para sus fines,

00:11:44.796 --> 00:11:47.147
un poco como "Minority Report".

00:11:47.147 --> 00:11:49.554
Es un término conocido como 
policial predictiva,

00:11:49.554 --> 00:11:51.824
o criminología algorítmica,

00:11:51.824 --> 00:11:54.130
y la idea es que, 
con gran cantidad de datos,

00:11:54.130 --> 00:11:56.219
por ejemplo, donde hubo 
crímenes antes,

00:11:56.219 --> 00:11:58.669
sabremos dónde enviar 
a las patrullas.

00:11:58.669 --> 00:12:00.804
Tiene sentido, pero, 
el problema, claro,

00:12:00.804 --> 00:12:05.348
es que no solo se quedarán 
en los datos de ubicación,

00:12:05.348 --> 00:12:08.307
irán al nivel del individuo.

00:12:08.307 --> 00:12:10.557
¿Por qué no usamos 
los datos de personas

00:12:10.557 --> 00:12:12.785
con un alto expediente académico?

00:12:12.785 --> 00:12:14.319
Tal vez utilizar 
el hecho de que

00:12:14.319 --> 00:12:16.500
estén sin empleo, 
su record crediticio,

00:12:16.500 --> 00:12:17.972
su comportamiento en la web,

00:12:17.972 --> 00:12:19.804
si están despiertos 
tarde en la noche.

00:12:19.804 --> 00:12:23.910
Su controlador físico digital, 
cuando identifique datos bioquímicos,

00:12:23.910 --> 00:12:27.201
mostrará si tienen 
pensamientos agresivos.

00:12:27.201 --> 00:12:29.422
Podemos tener algoritmos 
que pueden predecir

00:12:29.422 --> 00:12:31.055
lo que estamos a punto de hacer,

00:12:31.055 --> 00:12:32.299
y podemos ser responsables

00:12:32.299 --> 00:12:34.889
antes de que realmente 
hayamos actuado.

00:12:34.889 --> 00:12:36.734
la privacidad era el desafío principal

00:12:36.734 --> 00:12:39.501
en la era de los datos pequeños.

00:12:39.501 --> 00:12:41.650
En la era de los datos masivos,

00:12:41.650 --> 00:12:46.173
el reto será salvaguardar 
el libre albedrío,

00:12:46.173 --> 00:12:49.952
la elección moral, 
la voluntad humana,

00:12:49.952 --> 00:12:53.020
la acción humana.

00:12:54.540 --> 00:12:56.765
Hay otro problema:

00:12:56.765 --> 00:13:00.321
los datos masivos nos quitarán 
nuestros puestos de trabajo.

00:13:00.321 --> 00:13:03.833
Los datos masivos y algoritmos desafiarán

00:13:03.833 --> 00:13:06.894
los conocimientos profesionales de gestión

00:13:06.894 --> 00:13:08.547
en el siglo XXI

00:13:08.547 --> 00:13:11.334
de la misma manera que 
la automatización de las fábricas

00:13:11.334 --> 00:13:13.196
y las cadenas de montaje

00:13:13.196 --> 00:13:16.196
desafiaron el trabajo 
de los obreros en el siglo XX.

00:13:16.196 --> 00:13:18.288
Piensen en un técnico de laboratorio

00:13:18.288 --> 00:13:19.783
que mira en un microscopio

00:13:19.783 --> 00:13:21.321
una biopsia de cáncer

00:13:21.321 --> 00:13:23.958
para determinar si es cáncer o no.

00:13:23.958 --> 00:13:25.930
La persona que fue a la universidad.

00:13:25.930 --> 00:13:27.360
En el que compra propiedades.

00:13:27.360 --> 00:13:29.101
Él o ella vota.

00:13:29.101 --> 00:13:32.767
Él o ella es un constituyente 
de la sociedad.

00:13:32.767 --> 00:13:34.161
Y el trabajo de esa persona,

00:13:34.161 --> 00:13:35.770
así como toda una flota

00:13:35.770 --> 00:13:37.739
de profesionales como esa persona,

00:13:37.739 --> 00:13:40.889
se encontrará que sus puestos de trabajo 
han cambiado radicalmente

00:13:40.889 --> 00:13:43.246
o, en realidad, se han eliminado 
completamente.

00:13:43.246 --> 00:13:44.530
Ahora, nos gusta pensar

00:13:44.530 --> 00:13:47.717
que la tecnología crea 
puestos de trabajo

00:13:47.717 --> 00:13:51.182
después de un corto período 
de dislocación temporal,

00:13:51.182 --> 00:13:53.123
y es cierto para el marco de referencia

00:13:53.123 --> 00:13:55.265
de la Revolución Industrial, 
que vivimos,

00:13:55.265 --> 00:13:57.593
porque eso es precisamente lo que ocurrió.

00:13:57.593 --> 00:13:59.926
Pero nos olvidamos de algo en el análisis:

00:13:59.926 --> 00:14:01.756
Hay algunas categorías de empleos

00:14:01.756 --> 00:14:05.176
que simplemente se eliminan y 
no se crean nunca más.

00:14:05.176 --> 00:14:07.180
La Revolución Industrial no era muy buena

00:14:07.180 --> 00:14:10.735
si eras un caballo.

00:14:11.182 --> 00:14:13.237
Así que tendremos 
que tener cuidado

00:14:13.237 --> 00:14:16.751
y tomar datos masivos 
y ajustarlos a nuestras necesidades,

00:14:16.751 --> 00:14:19.936
a nuestras necesidades muy humanas.

00:14:19.936 --> 00:14:22.249
Tenemos que ser los dueños 
de esta tecnología,

00:14:22.249 --> 00:14:23.546
no sus siervos.

00:14:23.546 --> 00:14:26.504
Estamos justo en el comienzo 
de la era de los datos masivos,

00:14:26.504 --> 00:14:29.654
y honestamente, 
no somos muy buenos

00:14:29.654 --> 00:14:33.861
en el manejo de todos los datos 
que ahora podemos recoger.

00:14:33.861 --> 00:14:37.117
No es solo un problema para 
la Agencia de Seguridad Nacional.

00:14:37.117 --> 00:14:40.415
Las empresas recogen muchos datos, 
y también, hacen mal uso de ellos,

00:14:40.415 --> 00:14:43.896
y tenemos que mejorar en esto, 
y esto tomará tiempo.

00:14:43.896 --> 00:14:45.891
Es un poco como 
el desafío que enfrentó

00:14:45.891 --> 00:14:48.125
el hombre primitivo y el fuego.

00:14:48.125 --> 00:14:50.010
Es una herramienta, 
pero que,

00:14:50.010 --> 00:14:53.682
a menos que seamos cuidadosos, 
nos va a quemar.

00:14:56.008 --> 00:14:59.128
Los datos masivos transformarán 
la manera en que vivimos,

00:14:59.128 --> 00:15:01.929
cómo trabajamos y 
cómo pensamos.

00:15:01.929 --> 00:15:03.818
Nos ayudarán con nuestras carreras

00:15:03.818 --> 00:15:07.452
y a llevar una vida de satisfacción 
y esperanza

00:15:07.452 --> 00:15:10.444
y felicidad y salud,

00:15:10.444 --> 00:15:13.750
pero en el pasado, frecuentemente, 
vimos esa tecnología

00:15:13.750 --> 00:15:15.958
y nuestros ojos solo han visto la T

00:15:15.958 --> 00:15:17.644
la tecnología, el hardware,

00:15:17.644 --> 00:15:19.906
porque eso es físico.

00:15:19.906 --> 00:15:22.830
Ahora tenemos que reformular 
nuestra mirada a la I,

00:15:22.830 --> 00:15:24.210
la información,

00:15:24.210 --> 00:15:25.583
que es menos tangible,

00:15:25.583 --> 00:15:29.345
pero en algunos aspectos 
mucho más importante.

00:15:29.692 --> 00:15:33.157
La humanidad finalmente 
puede aprender de la información

00:15:33.157 --> 00:15:35.575
que puede recoger,

00:15:35.575 --> 00:15:37.690
como parte de nuestra búsqueda eterna

00:15:37.690 --> 00:15:40.849
para entender el mundo y 
nuestro lugar en él,

00:15:40.849 --> 00:15:45.055
y por eso los datos masivos 
es un gran asunto.

00:15:46.681 --> 00:15:50.048
(Aplausos)

