WEBVTT
Kind: captions
Language: sv

00:00:00.000 --> 00:00:07.000
Översättare: Annika Bidner
Granskare: Lisbeth Pekkari

00:00:12.850 --> 00:00:16.136
Vilken är USA:s favoritpaj?

00:00:16.622 --> 00:00:20.138
Publiken: Äpple.
Kenneth Cukier: Äpple såklart.

00:00:20.138 --> 00:00:21.369
Hur vet vi det?

00:00:21.369 --> 00:00:23.752
Tack vare data.

00:00:24.122 --> 00:00:26.188
Om man ser på stormarknadsförsäljning.

00:00:26.188 --> 00:00:29.894
Om man ser på säljsiffror
för 30 centimeters frysta pajer

00:00:29.894 --> 00:00:33.129
så vinner äpple utan konkurrens.

00:00:33.129 --> 00:00:36.119
Majoriteten av försäljningen är äpple.

00:00:38.549 --> 00:00:43.453
Men sen började stormarknader
sälja mindre, 11 cm:s pajer,

00:00:43.453 --> 00:00:45.266
och plötsligt föll äpple

00:00:45.266 --> 00:00:47.408
till fjärde eller femte plats.

00:00:48.030 --> 00:00:50.432
Varför? Vad hände?

00:00:50.905 --> 00:00:52.814
OK, fundera på det.

00:00:53.723 --> 00:00:57.096
När man köper en 30 centimeters paj

00:00:57.571 --> 00:00:59.832
så behöver hela familjen samsas,

00:00:59.832 --> 00:01:03.623
och äpple är då allas andrahandsval.

00:01:03.623 --> 00:01:05.558
(Skratt)

00:01:05.558 --> 00:01:09.173
Men när man köper
en enskild 11 centimeters paj

00:01:09.173 --> 00:01:12.531
så kan man köpa den man vill ha.

00:01:12.918 --> 00:01:15.784
Du kan få ditt förstahandsval.

00:01:16.933 --> 00:01:18.574
Vi har mer data

00:01:18.574 --> 00:01:21.108
Vi kan se något som vi inte kunde se

00:01:21.108 --> 00:01:24.328
när vi hade mindre mängder av det.

00:01:25.213 --> 00:01:27.688
Poängen här är att mer data

00:01:27.688 --> 00:01:29.971
inte bara låter oss se mera,

00:01:29.971 --> 00:01:31.825
mer av samma sak vi tittar på.

00:01:31.825 --> 00:01:35.438
Mer data låter oss att se nytt.

00:01:35.438 --> 00:01:38.532
Det låter oss att se bättre.

00:01:38.532 --> 00:01:41.938
Det låter oss att se annorlunda.

00:01:42.188 --> 00:01:45.361
I detta fall, så låter det oss att se

00:01:45.361 --> 00:01:48.004
vad USA:s favoritpaj är:

00:01:48.004 --> 00:01:49.973
inte äpple.

00:01:50.816 --> 00:01:54.190
Ni har troligen hört termen big data.

00:01:54.190 --> 00:01:57.627
Ni är troligen trötta på
att höra termen big data.

00:01:57.627 --> 00:02:01.487
Det är sant att termen har blivit trendig

00:02:01.487 --> 00:02:03.329
och det är väldigt synd,

00:02:03.859 --> 00:02:06.825
för big data är
ett väldigt viktigt verktyg

00:02:06.825 --> 00:02:09.711
för samhällsutvecklingen.

00:02:10.559 --> 00:02:14.120
Tidigare har vi tittat på mindre data

00:02:14.120 --> 00:02:17.204
och funderat på vad den betyder
för att försöka förstå världen,

00:02:17.320 --> 00:02:19.311
och nu har vi mycket mer av det,

00:02:19.311 --> 00:02:21.742
mer än vi någonsin hade innan.

00:02:22.033 --> 00:02:23.910
Vad vi upptäcker när vi har

00:02:23.910 --> 00:02:26.634
en stor mängd med data,
är att vi kan i grunden göra saker

00:02:26.634 --> 00:02:29.910
som inte gick när vi hade mindre mängder.

00:02:29.910 --> 00:02:32.551
Big data är viktigt 
och big data är nytt,

00:02:32.551 --> 00:02:34.328
och när du tänker på det

00:02:34.328 --> 00:02:36.544
är det enda sättet som planeten 
kommer hantera

00:02:36.544 --> 00:02:38.333
sina globala utmaningar på -

00:02:38.333 --> 00:02:41.870
att ge människor mat,
förse dem med sjukvård,

00:02:41.870 --> 00:02:44.680
förse dem med energi, elektricitet,

00:02:44.680 --> 00:02:48.239
se till att dom inte blir knaperstekta
på grund av global uppvärmning -

00:02:48.239 --> 00:02:51.463
är med hjälp av effektiv dataanvändning.

00:02:51.902 --> 00:02:53.671
Så vad är nytt med big data?

00:02:53.671 --> 00:02:55.902
Vad är den stora grejen?

00:02:55.902 --> 00:02:58.289
För att besvara frågan, fundera på

00:02:58.289 --> 00:03:00.745
hur information såg ut fysiskt,

00:03:00.745 --> 00:03:03.038
hur den såg ut förr i tiden.

00:03:04.299 --> 00:03:06.830
1908, på ön Kreta

00:03:06.830 --> 00:03:11.565
hittade arkeologer en lerskiva.

00:03:11.565 --> 00:03:15.624
Dom daterade skivan till 2 000 år f.Kr., 
så den är 4 000 år gammal.

00:03:15.624 --> 00:03:18.958
Det finns inskriptioner på skivan,
men vi vet inte vad de betyder.

00:03:18.958 --> 00:03:21.053
Det är ett mysterium, men poängen är

00:03:21.053 --> 00:03:22.981
att så här brukade information se ut

00:03:22.981 --> 00:03:25.070
för 4 000 år sedan.

00:03:25.070 --> 00:03:27.618
Detta är hur samhället lagrade

00:03:27.618 --> 00:03:29.963
och överförde information.

00:03:31.142 --> 00:03:34.849
Samhället har inte utvecklats så mycket.

00:03:35.302 --> 00:03:38.099
Vi lagrar fortfarande
information på skivor,

00:03:38.776 --> 00:03:41.960
men nu kan vi lagra
väldigt mycket mera information,

00:03:41.960 --> 00:03:43.220
mer än någonsin tidigare.

00:03:43.220 --> 00:03:46.313
Det är lättare att söka och kopiera den.

00:03:46.313 --> 00:03:49.813
Det är lättare att dela och bearbeta den.

00:03:49.813 --> 00:03:52.579
Och vi kan återanvända informationen

00:03:52.579 --> 00:03:54.413
inom områden vi inte ens drömt om

00:03:54.413 --> 00:03:57.316
när vi först samlade informationen.

00:03:57.608 --> 00:03:59.860
I detta avseende så har data gått

00:03:59.860 --> 00:04:03.392
från ett lager till ett flöde,

00:04:03.392 --> 00:04:07.330
från att vara stationärt och statiskt

00:04:07.330 --> 00:04:10.669
till att vara flytande och dynamiskt.

00:04:10.669 --> 00:04:14.738
Man kan säga att information
har blivit mer flytande.

00:04:14.962 --> 00:04:18.436
Skivan som upptäcktes nära Kreta,

00:04:18.436 --> 00:04:21.428
som är 4 000 år gammal, är tung,

00:04:21.850 --> 00:04:24.162
den lagrar inte så mycket information,

00:04:24.162 --> 00:04:26.784
och den informationen är oföränderlig.

00:04:27.278 --> 00:04:31.289
Som kontrast kunde alla filerna

00:04:31.289 --> 00:04:33.150
som Edward Snowden tog

00:04:33.150 --> 00:04:35.771
från National Security Agency i USA

00:04:35.771 --> 00:04:38.190
få plats på en minnessticka

00:04:38.190 --> 00:04:40.895
lika stor som en fingernagel

00:04:41.050 --> 00:04:44.447
och den kan delas med ljusets hastighet.

00:04:46.425 --> 00:04:49.590
Mer data, mer.

00:04:50.460 --> 00:04:53.134
En orsak till att vi har 
så mycket data i världen i dag

00:04:53.134 --> 00:04:54.606
är att vi samlar på saker

00:04:54.606 --> 00:04:57.886
som vi alltid samlat information om

00:04:57.886 --> 00:05:00.542
men en annan anledning är att vi tar saker

00:05:00.542 --> 00:05:03.354
som alltid haft mycket information

00:05:03.354 --> 00:05:05.840
men som aldrig har gjorts i ett dataformat

00:05:05.840 --> 00:05:08.259
och vi lägger till det bland våra data.

00:05:08.259 --> 00:05:11.567
Tänk till exempel på frågan om plats.

00:05:11.567 --> 00:05:13.816
Ta till exempel Martin Luther.

00:05:13.816 --> 00:05:15.413
Om vi på 1500-talet ville veta

00:05:15.413 --> 00:05:17.519
var Martin Luther var,

00:05:18.080 --> 00:05:20.172
så behöver vi följa efter honom hela tiden

00:05:20.172 --> 00:05:23.509
kanske med en fjäderpenna
och ett bläckhorn, för att skriva ner det,

00:05:23.835 --> 00:05:26.168
men tänk nu på hur det ser ut idag.

00:05:26.168 --> 00:05:28.290
Du vet att någonstans,

00:05:28.290 --> 00:05:30.736
antagligen i en teleoperatörs databas,

00:05:30.736 --> 00:05:33.772
finns det ett kalkylblad,
eller minst en databaspost

00:05:33.772 --> 00:05:35.860
som sparar din information

00:05:35.860 --> 00:05:37.923
om var du varit hela tiden.

00:05:37.923 --> 00:05:39.283
Om du har en mobiltelefon

00:05:39.283 --> 00:05:42.130
och mobiltelefonen har GPS,
men även om den inte har GPS,

00:05:42.130 --> 00:05:44.515
så kan den spara din information.

00:05:44.515 --> 00:05:48.284
I detta avseende har plats
blivit digitaliserat.

00:05:48.599 --> 00:05:52.840
Tänk till exempel på frågan 
om kroppshållning,

00:05:52.840 --> 00:05:54.845
det sätt som ni alla sitter på just nu,

00:05:54.845 --> 00:05:56.515
hur du sitter,

00:05:56.515 --> 00:05:58.776
hur du sitter, hur du sitter.

00:05:58.956 --> 00:06:01.403
Alla sätt är olika
och de beror på din benlängd

00:06:01.403 --> 00:06:03.456
och din rygg och din ryggs konturer,

00:06:03.456 --> 00:06:05.987
och om jag skulle sätta sensorer,
kanske 100 sensorer

00:06:05.987 --> 00:06:07.753
på alla era stolar just nu,

00:06:07.753 --> 00:06:11.130
så skulle jag kunna skapa ett index 
som är ganska unikt för dig,

00:06:11.130 --> 00:06:15.104
ungefär som ett fingeravtryck, 
men som inte är ditt finger.

00:06:15.762 --> 00:06:18.038
Så vad kan vi göra med detta?

00:06:18.731 --> 00:06:20.958
Forskare i Tokyo använder det

00:06:20.958 --> 00:06:24.881
som ett potentiellt stöldskydd till bilar.

00:06:25.516 --> 00:06:28.440
Idén är att biltjuven sitter bakom ratten,

00:06:28.440 --> 00:06:30.544
försöker köra iväg, men bilen känner igen

00:06:30.544 --> 00:06:32.906
att en icke-godkänd förare 
sitter bakom ratten,

00:06:32.906 --> 00:06:35.070
kanske stannar motorn, fram tills du

00:06:35.070 --> 00:06:38.247
skriver in ett lösenord 
på instrumentbrädan

00:06:38.247 --> 00:06:40.650
för att säga: "Hej,
jag har rätt att köra".

00:06:40.650 --> 00:06:42.365
Bra.

00:06:42.665 --> 00:06:45.458
Tänk om varje bil i Europa

00:06:45.458 --> 00:06:46.915
hade den här tekniken?

00:06:46.915 --> 00:06:49.082
Vad skulle vi kunna göra då?

00:06:50.080 --> 00:06:52.120
Om vi kombinerade all data

00:06:52.120 --> 00:06:56.134
kanske vi kunde
identifiera varningstecknen

00:06:56.134 --> 00:06:58.843
som bäst förutsäger att en bilolycka

00:06:58.843 --> 00:07:03.553
kommer att ske inom fem sekunder.

00:07:04.736 --> 00:07:08.613
Och vad vi då har fastställt
är förartrötthet,

00:07:09.076 --> 00:07:11.410
och tjänsten skulle handla om
att bilen känner av

00:07:11.410 --> 00:07:14.054
att personen tappar sin hållning,

00:07:14.847 --> 00:07:18.485
automatiskt vet och ställer in
ett internt alarm

00:07:18.485 --> 00:07:21.456
som får ratten att vibrera
och tutar inuti bilen för att säga,

00:07:21.456 --> 00:07:24.160
"Hallå, vakna upp,
fokusera mera på vägen."

00:07:24.491 --> 00:07:26.344
Detta är den typ av saker vi kan göra

00:07:26.344 --> 00:07:28.965
när vi digitaliserar
fler delar av våra liv.

00:07:29.165 --> 00:07:32.380
Så vad är värdet av big data?

00:07:32.840 --> 00:07:35.030
Tja, tänk på det.

00:07:35.030 --> 00:07:37.252
Vi har mer information.

00:07:37.252 --> 00:07:40.346
Vi kan göra saker som inte gick tidigare.

00:07:40.783 --> 00:07:44.189
Ett av det mest imponerande ställen
där detta begrepp vinner mark

00:07:44.189 --> 00:07:47.245
är inom området för maskininlärning.

00:07:47.245 --> 00:07:50.572
Maskininlärning är den gren 
av artificiell intelligens,

00:07:50.572 --> 00:07:53.370
som i sig är en gren av datavetenskap.

00:07:53.370 --> 00:07:54.868
Det går ut på

00:07:54.868 --> 00:07:57.700
att istället för att instruera en dator
om vad den ska göra,

00:07:57.700 --> 00:08:00.230
ger vi den helt enkelt data om ett problem

00:08:00.230 --> 00:08:03.239
och säger åt datorn
att lista ut lösningen själv.

00:08:03.436 --> 00:08:05.213
Det hjälper er att förstå det

00:08:05.213 --> 00:08:07.901
genom att se källan.

00:08:08.765 --> 00:08:11.733
En datavetare på IBM på 50-talet

00:08:11.733 --> 00:08:14.745
som hette Arthur Samuel
gillade att spela dam,

00:08:14.745 --> 00:08:16.147
så han skrev ett dataprogram

00:08:16.147 --> 00:08:18.367
så han kunde spela mot datorn.

00:08:18.960 --> 00:08:21.671
Han spelade. Han vann.

00:08:21.671 --> 00:08:23.774
Han spelade. Han vann.

00:08:23.774 --> 00:08:25.871
Han spelade. Han vann,

00:08:26.789 --> 00:08:28.567
eftersom datorn visste bara

00:08:28.567 --> 00:08:30.544
vad ett giltigt drag var.

00:08:30.794 --> 00:08:32.881
Arthur Samuel kunde något annat.

00:08:32.881 --> 00:08:36.912
Arthur Samuel kunde använda strategi.

00:08:37.510 --> 00:08:39.746
Så han skrev ett mindre underprogram

00:08:39.746 --> 00:08:42.180
som arbetade i bakgrunden,
och allt det gjorde var

00:08:42.180 --> 00:08:43.697
att poängsätta sannolikheten

00:08:43.697 --> 00:08:46.260
att en viss brädkonfiguration
sannolikt skulle leda

00:08:46.260 --> 00:08:49.170
till ett vinnande bräde
jämfört med ett förlorande bräde

00:08:49.170 --> 00:08:51.234
efter varje drag.

00:08:51.678 --> 00:08:54.828
Han spelade mot datorn. Han vinner.

00:08:54.828 --> 00:08:57.336
Han spelade mot datorn. Han vinner.

00:08:57.336 --> 00:08:59.747
Han spelade mot datorn. Han vinner.

00:09:01.067 --> 00:09:03.344
Sedan lämnar Arthur Samuel datorn

00:09:03.344 --> 00:09:05.159
så den spelar mot sig själv.

00:09:05.571 --> 00:09:08.729
Den spelar själv. Den samlar mer data.

00:09:09.080 --> 00:09:10.397
Den samlar mer data.

00:09:10.397 --> 00:09:13.354
Den ökar noggrannheten
i dess förutsägelser.

00:09:13.354 --> 00:09:15.493
Sedan går Arthur Samuel 
tillbaka till datorn

00:09:15.493 --> 00:09:17.811
och spelar själv mot den, 
och han förlorar.

00:09:17.811 --> 00:09:19.880
och han spelar, och han förlorar,

00:09:19.880 --> 00:09:21.927
och han spelar, och han förlorar,

00:09:21.927 --> 00:09:24.526
och Arthur Samuel har skapat en maskin

00:09:24.526 --> 00:09:29.766
som överträffar hans förmåga
i en uppgift som han lärde den.

00:09:30.814 --> 00:09:33.312
Och maskininlärning

00:09:33.312 --> 00:09:36.038
kommer att finnas överallt.

00:09:37.239 --> 00:09:40.388
Hur tror du att vi har fått
självkörande bilar?

00:09:40.388 --> 00:09:42.525
Är vi ett bättre samhälle

00:09:42.525 --> 00:09:46.200
för att vi lägger in
alla trafikregler i mjukvara? Nej.

00:09:46.780 --> 00:09:48.408
Minne är billigt. Nej.

00:09:48.408 --> 00:09:49.880
Algoritmerna är snabbare. Nej.

00:09:49.880 --> 00:09:51.855
Processorerna är bättre. Nej.

00:09:52.398 --> 00:09:55.174
Dom sakerna gör skillnad,
men det är inte därför.

00:09:55.174 --> 00:09:58.145
Det är för att vi ändrat problemets natur.

00:09:58.145 --> 00:10:00.545
Vi ändrade problemets art
från en där vi försökt

00:10:00.545 --> 00:10:04.080
att öppet och tydligt förklara
för datorn hur man kör

00:10:04.091 --> 00:10:05.987
till en där vi säger,

00:10:05.987 --> 00:10:07.863
"Här är en massa data om fordonet.

00:10:07.863 --> 00:10:09.396
Du kan räkna ut det.

00:10:09.396 --> 00:10:11.263
Räkna ut att det finns ett trafikljus,

00:10:11.263 --> 00:10:13.214
att trafikljuset är rött och inte grönt,

00:10:13.214 --> 00:10:15.358
att det betyder att du måste stanna

00:10:15.358 --> 00:10:17.235
och inte köra framåt."

00:10:18.441 --> 00:10:19.959
Maskininlärning är grunden

00:10:19.959 --> 00:10:21.950
till många saker vi gör online:

00:10:21.950 --> 00:10:23.807
sökmotorer,

00:10:23.807 --> 00:10:26.331
Amazons algoritm för personalisering,

00:10:27.608 --> 00:10:29.752
datoröversättning,

00:10:29.752 --> 00:10:32.191
röstigenkänningssystem.

00:10:34.110 --> 00:10:36.945
Forskare har nyligen kollat på

00:10:36.945 --> 00:10:39.900
frågan om biopsier,

00:10:39.900 --> 00:10:42.037
cancerbiopsier

00:10:42.727 --> 00:10:45.222
och dom bad en dator att identifiera,

00:10:45.222 --> 00:10:47.693
genom att se på data 
och överlevnadsstatistik

00:10:47.693 --> 00:10:52.001
för att bedöma om celler är

00:10:52.731 --> 00:10:54.665
drabbade av cancer eller inte,

00:10:54.665 --> 00:10:56.562
och visst, när man kastar data på den

00:10:56.562 --> 00:10:58.729
genom en algoritm för maskininlärning

00:10:58.729 --> 00:11:00.426
så kunde datorn identifiera

00:11:00.426 --> 00:11:02.868
de 12 varningssignalerna 
som bäst förutspådde

00:11:02.868 --> 00:11:06.167
att biopsin av bröstcancerceller

00:11:06.167 --> 00:11:08.674
verkligen är cancer.

00:11:09.385 --> 00:11:11.883
Problemet var att medicinsk facklitteratur

00:11:11.883 --> 00:11:14.249
bara kände till nio av dom.

00:11:14.672 --> 00:11:16.472
Tre av egenskaperna var sådana

00:11:16.472 --> 00:11:19.287
som folk inte behövde leta efter,

00:11:19.287 --> 00:11:21.892
men som datorn upptäckte.

00:11:25.818 --> 00:11:30.396
Men det finns också
mörka sidor av big data

00:11:30.523 --> 00:11:32.977
Den förbättrar våra liv, 
men det finns problem

00:11:32.977 --> 00:11:35.091
som vi måste vara medvetna om,

00:11:35.447 --> 00:11:37.980
och den första är tanken

00:11:37.980 --> 00:11:40.926
att vi kan straffas för förutsägelser,

00:11:40.926 --> 00:11:44.796
att polisen får använda 
big data för sina syften,

00:11:44.796 --> 00:11:46.897
lite som i "Minority Report."

00:11:46.897 --> 00:11:49.678
Det finns en term som kallas 
för prediktivt polisarbete,

00:11:49.678 --> 00:11:51.721
eller algoritmisk kriminologi,

00:11:51.721 --> 00:11:53.987
och idén är att om vi tar en massa data,

00:11:53.987 --> 00:11:56.146
till exempel om
var tidigare brott har skett,

00:11:56.146 --> 00:11:58.232
vet vi vart vi ska skicka patruller.

00:11:58.689 --> 00:12:00.804
Det är vettigt, men problemet
är naturligtvis

00:12:00.804 --> 00:12:04.958
att det inte bara kommer
att stanna vid platsuppgifter,

00:12:05.348 --> 00:12:08.307
det kommer att gå ner till individnivå.

00:12:08.307 --> 00:12:11.977
Varför använder vi inte uppgifter 
om personens gymnasiebetyg?

00:12:12.265 --> 00:12:13.836
Vi kanske ska använda det faktum

00:12:13.836 --> 00:12:16.444
att de är arbetslösa eller inte,
deras kreditvärdering,

00:12:16.444 --> 00:12:17.976
deras beteende på internet,

00:12:17.976 --> 00:12:19.684
huruvida de är uppe sent på natten.

00:12:19.684 --> 00:12:22.965
Deras fitnessklocka,
när den kan kontrollera biokemin,

00:12:22.965 --> 00:12:26.287
kommer visa att de har 
aggressiva tankar.

00:12:27.061 --> 00:12:29.422
Vi kan ha algoritmer
som sannolikt kommer förutse

00:12:29.422 --> 00:12:31.055
vad vi kommer att göra,

00:12:31.055 --> 00:12:34.489
och vi kan hållas ansvariga
innan vi faktiskt har agerat.

00:12:34.709 --> 00:12:36.621
Sekretess var den centrala utmaningen

00:12:36.621 --> 00:12:38.812
i eran av små datamängder.

00:12:39.501 --> 00:12:42.130
I big data-åldern är utmaningen

00:12:42.130 --> 00:12:45.790
att värna om den fria viljan,

00:12:46.173 --> 00:12:49.579
moraliskt val, mänsklig vilja,

00:12:49.952 --> 00:12:52.427
mänsklig inverkan.

00:12:54.540 --> 00:12:56.519
Det finns ett problem till:

00:12:56.765 --> 00:12:59.750
Big data kommer att stjäla våra jobb.

00:13:00.321 --> 00:13:03.833
Big data och algoritmer kommer att utmana

00:13:03.833 --> 00:13:06.894
tjänstemäns yrkesmässiga kunskapsarbete

00:13:06.894 --> 00:13:08.377
på 2000-talet

00:13:08.377 --> 00:13:10.981
på samma sätt som fabriksautomation

00:13:10.981 --> 00:13:13.170
och monteringslinjen

00:13:13.170 --> 00:13:16.196
utmanade industriarbetaren på 1900-talet.

00:13:16.196 --> 00:13:18.288
Tänk på labbteknikern

00:13:18.288 --> 00:13:19.767
som tittar genom ett mikroskop

00:13:19.767 --> 00:13:21.321
på en cancerbiopsi

00:13:21.321 --> 00:13:23.958
och bestämmer om det är cancer eller inte.

00:13:23.958 --> 00:13:25.930
Personen har gått på universitetet.

00:13:25.930 --> 00:13:27.360
Personen köper egendom.

00:13:27.360 --> 00:13:29.101
Han eller hon röstar.

00:13:29.101 --> 00:13:32.295
Han eller hon är nu en samhällsaktör.

00:13:32.767 --> 00:13:34.161
Och den personens jobb,

00:13:34.161 --> 00:13:35.770
samt en hel flotta

00:13:35.770 --> 00:13:37.739
av proffs som den personen,

00:13:37.739 --> 00:13:40.889
kommer att finna att deras jobb
har förändrats radikalt

00:13:40.889 --> 00:13:43.246
eller faktiskt helt elimineras.

00:13:43.246 --> 00:13:44.530
Vi vill gärna tro

00:13:44.530 --> 00:13:47.717
att tekniken skapar arbetstillfällen
under en tid efter

00:13:47.717 --> 00:13:51.182
en kort, tillfällig period av störning,

00:13:51.182 --> 00:13:53.043
och det är sant för den referensram

00:13:53.043 --> 00:13:55.495
som vi alla lever i,
den industriella revolutionen,

00:13:55.495 --> 00:13:57.258
för det är precis vad som hände.

00:13:57.433 --> 00:13:59.926
Men vi glömmer något i den analysen:

00:13:59.926 --> 00:14:01.756
Det finns vissa kategorier av jobb

00:14:01.756 --> 00:14:04.698
som helt enkelt försvinner
och aldrig kommer tillbaka.

00:14:04.896 --> 00:14:06.440
Den industriella revolutionen

00:14:06.440 --> 00:14:08.654
var inte särskilt bra för hästar.

00:14:11.182 --> 00:14:13.237
Så vi måste vara försiktiga

00:14:13.237 --> 00:14:16.751
och ta big data och anpassa den
efter våra behov,

00:14:16.751 --> 00:14:19.280
våra väldigt mänskliga behov.

00:14:19.936 --> 00:14:21.890
Vi måste vara herre över denna teknik,

00:14:21.890 --> 00:14:23.256
inte dess tjänare.

00:14:23.256 --> 00:14:26.504
Vi är bara i början av big data-eran,

00:14:26.504 --> 00:14:29.654
och ärligt talat så är vi inte så bra

00:14:29.654 --> 00:14:33.220
på att hantera all den data 
som vi nu samlar in.

00:14:33.641 --> 00:14:37.191
Det är inte bara ett problem
för National Security Agency.

00:14:37.191 --> 00:14:40.229
Företagen samlar massor av data,
och de missbrukar den också,

00:14:40.229 --> 00:14:43.896
och vi måste bli bättre på detta,
och det kommer att ta tid.

00:14:43.896 --> 00:14:47.768
Det är lite som utmaningen
när den primitiva människan mötte eld.

00:14:47.935 --> 00:14:49.849
Detta är ett verktyg, men ett verktyg

00:14:49.849 --> 00:14:52.845
som om det inte hanteras försiktigt 
kommer att skada oss.

00:14:56.008 --> 00:14:59.128
Big data kommer omvandla hur vi lever,

00:14:59.128 --> 00:15:01.929
hur vi arbetar och hur vi tänker.

00:15:01.929 --> 00:15:03.948
Det kommer hjälpa oss hantera våra karriär

00:15:03.948 --> 00:15:07.452
och leva liv som innehåller
tillfredsställelse och hopp,

00:15:07.452 --> 00:15:09.723
lycka och hälsa,

00:15:10.444 --> 00:15:13.750
men i det förflutna har vi ofta 
sett på informationsteknik

00:15:13.750 --> 00:15:15.958
och vi har bara sett T:et,

00:15:15.958 --> 00:15:17.644
tekniken, hårdvaran,

00:15:17.644 --> 00:15:19.706
eftersom det är vad som fanns fysiskt

00:15:19.706 --> 00:15:22.830
Nu måste vi rikta blicken mot I:et,

00:15:22.830 --> 00:15:24.070
informationen,

00:15:24.070 --> 00:15:25.583
vilken är mindre uppenbart,

00:15:25.583 --> 00:15:28.613
men på vissa sätt mycket viktigare.

00:15:29.692 --> 00:15:33.157
Mänskligheten kan äntligen 
lära sig saker från informationen

00:15:33.157 --> 00:15:35.200
som den samlar in,

00:15:35.575 --> 00:15:37.690
som en del i ett tidlöst uppdrag

00:15:37.690 --> 00:15:40.287
att förstå världen och vår plats i den,

00:15:40.849 --> 00:15:44.696
och det är därför big data är en stor sak.

00:15:45.920 --> 00:15:48.888
(Applåder)

