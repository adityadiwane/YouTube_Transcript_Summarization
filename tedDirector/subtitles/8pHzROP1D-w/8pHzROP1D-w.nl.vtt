WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Dick Stada
Nagekeken door: Els De Keyser

00:00:12.787 --> 00:00:16.632
Wat is de lievelingstaart van Amerika?

00:00:16.632 --> 00:00:20.138
Publiek: Appel.
Kenneth Cukier: Appel, natuurlijk.

00:00:20.138 --> 00:00:21.369
Hoe weten we dat?

00:00:21.369 --> 00:00:24.122
Door gegevens.

00:00:24.122 --> 00:00:26.188
Je kijkt naar de supermarktverkoop.

00:00:26.188 --> 00:00:28.201
Je kijkt naar omzetcijfers

00:00:28.201 --> 00:00:30.814
van diepvriestaart van 30 centimeter

00:00:30.814 --> 00:00:33.129
en appel wint zeker.

00:00:33.129 --> 00:00:37.519
Appel is het meest verkocht.

00:00:38.309 --> 00:00:42.273
Toen gingen supermarkten ook
kleinere taarten verkopen

00:00:42.273 --> 00:00:43.856
van 11 centimeter.

00:00:43.856 --> 00:00:48.030
Dan komt appel
op de vierde of vijfde plaats.

00:00:48.030 --> 00:00:50.905
Hoezo? Hoe komt dat nou?

00:00:50.905 --> 00:00:53.723
Denk eens goed na.

00:00:53.723 --> 00:00:57.571
Als je een taart van 30 centimeter koopt,

00:00:57.571 --> 00:00:59.832
moet het hele gezin het eens zijn.

00:00:59.832 --> 00:01:03.623
Appel staat bij iedereen
op de tweede plaats.

00:01:03.623 --> 00:01:05.558
(Gelach)

00:01:05.558 --> 00:01:09.173
Maar als je een eenpersoonstaart
van 11 centimeter koopt,

00:01:09.173 --> 00:01:12.918
kan je kopen wat je zelf wilt.

00:01:12.918 --> 00:01:16.933
Je kan je eerste keus nemen.

00:01:16.933 --> 00:01:18.574
Je hebt meer gegevens.

00:01:18.574 --> 00:01:21.248
Je ziet iets dat je eerst niet zag

00:01:21.260 --> 00:01:25.213
toen er nog niet zoveel gegevens waren.

00:01:25.213 --> 00:01:27.688
Het gaat erom dat je met meer gegevens

00:01:27.688 --> 00:01:31.381
niet alleen meer ziet, meer van hetzelfde.

00:01:31.825 --> 00:01:35.438
Met meer gegevens zien we nieuwe dingen.

00:01:35.438 --> 00:01:38.532
Je krijgt er een betere kijk op.

00:01:38.532 --> 00:01:42.188
Je gaat er anders tegenaan kijken.

00:01:42.188 --> 00:01:45.361
In dit geval onthult het

00:01:45.361 --> 00:01:48.274
wat de lievelingstaart van Amerika is:

00:01:48.274 --> 00:01:50.816
geen appel.

00:01:50.816 --> 00:01:54.430
Je hebt vast wel gehoord
van de kreet 'big data'.

00:01:54.430 --> 00:01:56.487
Je wordt vast doodziek

00:01:56.487 --> 00:01:58.117
van de kreet 'big data'.

00:01:58.117 --> 00:02:01.447
Het is inderdaad een hype

00:02:01.447 --> 00:02:03.779
en dat is erg jammer,

00:02:03.779 --> 00:02:06.825
omdat big data
een enorm belangrijk middel is

00:02:06.825 --> 00:02:10.559
waarmee de maatschappij opgestuwd wordt.

00:02:10.559 --> 00:02:15.430
In het verleden keken we naar 'small data'
en dachten we daarover na.

00:02:15.430 --> 00:02:17.424
Zo poogden we de wereld te snappen.

00:02:17.424 --> 00:02:19.311
Nu hebben we veel meer gegevens.

00:02:19.311 --> 00:02:22.033
Meer dan we ooit hebben gehad.

00:02:22.033 --> 00:02:23.910
We ontdekken dat we

00:02:23.910 --> 00:02:26.634
met een grote hoeveelheid gegevens
dingen kunnen doen

00:02:26.634 --> 00:02:29.910
die we niet konden doen
met kleinere hoeveelheden.

00:02:29.910 --> 00:02:32.551
Big data is belangrijk en nieuw.

00:02:32.551 --> 00:02:34.328
Ga maar na:

00:02:34.328 --> 00:02:36.544
de enige manier waarmee 
deze aarde om kan gaan

00:02:36.544 --> 00:02:38.333
met wereldwijde uitdagingen --

00:02:38.333 --> 00:02:41.870
de wereld voeden,
medische verzorging geven,

00:02:41.870 --> 00:02:44.680
van energie voorzien, van elektriciteit,

00:02:44.680 --> 00:02:47.689
en zorgen dat we niet verbranden
door opwarming van de aarde --

00:02:47.689 --> 00:02:51.902
is door effectief gebruik van gegevens.

00:02:51.902 --> 00:02:55.772
Wat is nieuw aan big data?
Wat is het bijzondere?

00:02:55.772 --> 00:02:58.289
Om daar antwoord op te geven,
moet je eens bedenken

00:02:58.289 --> 00:03:00.185
hoe informatie eruitzag.

00:03:00.185 --> 00:03:03.219
Hoe het er ooit fysiek uitzag.

00:03:03.219 --> 00:03:06.830
In 1908, op het eiland Kreta,

00:03:06.830 --> 00:03:11.565
ontdekten archeologen een schijf van klei.

00:03:11.565 --> 00:03:15.624
Ze dateerden die op 2.000 voor Christus,
dus 4.000 jaar oud.

00:03:15.624 --> 00:03:18.948
Er staan inscripties op die schijf,
maar die kunnen we niet lezen.

00:03:18.955 --> 00:03:21.053
Het is een raadsel, maar het gaat erom

00:03:21.053 --> 00:03:25.071
dat informatie er
4.000 jaar geleden zo uitzag.

00:03:25.071 --> 00:03:30.108
Zo bewaarde en communiceerde
de maatschappij informatie.

00:03:31.142 --> 00:03:35.302
De maatschappij is niet zoveel veranderd.

00:03:35.302 --> 00:03:38.776
We bewaren informatie
nog steeds op schijven,

00:03:38.776 --> 00:03:41.960
maar nu kunnen we
veel meer informatie bewaren.

00:03:41.960 --> 00:03:43.220
Meer dan ooit.

00:03:43.220 --> 00:03:46.313
Zoeken is makkelijker.
KopiÃ«ren is makkelijker.

00:03:46.313 --> 00:03:49.813
Delen en verwerken zijn makkelijker.

00:03:49.813 --> 00:03:52.579
We kunnen deze informatie hergebruiken

00:03:52.579 --> 00:03:54.413
voor dingen waar we nooit aan dachten

00:03:54.413 --> 00:03:57.608
toen we die informatie verzamelden.

00:03:57.608 --> 00:03:59.860
In dit verband zijn de gegevens gegaan

00:03:59.860 --> 00:04:03.392
van een stapel naar een stroom.

00:04:03.392 --> 00:04:07.330
Van iets bewegingsloos en statisch

00:04:07.330 --> 00:04:10.939
naar iets dat vloeiend en dynamisch is.

00:04:10.939 --> 00:04:15.112
Je kan stellen dat informatie vloeibaar is.

00:04:15.112 --> 00:04:21.166
De schijf die 4.000 jaar geleden 
op Kreta werd ontdekt, is zwaar.

00:04:22.200 --> 00:04:24.162
Er staat weinig informatie op,

00:04:24.162 --> 00:04:27.278
en die informatie is niet te wijzigen.

00:04:27.278 --> 00:04:31.289
Aan de andere kant pasten alle bestanden

00:04:31.289 --> 00:04:33.150
die Edward Snowden pikte

00:04:33.150 --> 00:04:35.771
van de NSA in de VS

00:04:35.771 --> 00:04:38.190
op een geheugenstick

00:04:38.190 --> 00:04:41.200
met de grootte van een vingernagel.

00:04:41.200 --> 00:04:45.945
De informatie kan worden gedeeld
met lichtsnelheid.

00:04:45.945 --> 00:04:49.970
Meer data. Meer.

00:04:51.200 --> 00:04:53.174
We hebben nu veel meer data,

00:04:53.174 --> 00:04:57.326
omdat we dingen verzamelen waarover we 
van oudsher informatie verzamelen.

00:04:57.886 --> 00:05:00.542
Maar ook omdat we dingen verzamelen

00:05:00.542 --> 00:05:03.354
die altijd al informatie boden,

00:05:03.354 --> 00:05:05.840
maar die nooit in dataformaat 
werden opgeslagen.

00:05:05.840 --> 00:05:08.259
We maken er nu gegevens van.

00:05:08.259 --> 00:05:11.567
Denk eens aan de locatie.

00:05:11.567 --> 00:05:13.816
Neem bijvoorbeeld Martin Luther.

00:05:13.816 --> 00:05:15.693
Als we in de 16e eeuw wilden weten

00:05:15.693 --> 00:05:18.080
waar Martin Luther zich bevond,

00:05:18.080 --> 00:05:20.172
zouden we hem steeds moeten volgen,

00:05:20.172 --> 00:05:22.309
misschien met inkt en een veer,

00:05:22.309 --> 00:05:23.985
en we zouden dat vastleggen.

00:05:23.985 --> 00:05:26.168
Maar bedenk eens hoe dat er nu uitziet.

00:05:26.168 --> 00:05:28.290
Je weet dat er ergens,

00:05:28.290 --> 00:05:30.736
in een database van een telefoonbedrijf

00:05:30.736 --> 00:05:35.862
een bestand is, of iets in dat bestand,
dat informatie over jou bevat.

00:05:35.862 --> 00:05:37.923
Over waar je ooit hebt uitgehangen.

00:05:37.923 --> 00:05:40.793
Als je een mobieltje hebt met gps,

00:05:40.793 --> 00:05:42.130
maar zelfs zonder,

00:05:42.130 --> 00:05:44.515
dan bewaart het die informatie.

00:05:44.515 --> 00:05:48.599
Hierbij wordt locatie in gegevens omgezet.

00:05:48.599 --> 00:05:53.200
Denk bijvoorbeeld eens aan je houding.

00:05:53.200 --> 00:05:54.995
Hoe je op dit moment zit.

00:05:54.995 --> 00:05:56.515
Hoe jij zit,

00:05:56.515 --> 00:05:59.286
hoe jij zit, hoe jij zit.

00:05:59.286 --> 00:06:00.356
Dat is verschillend

00:06:00.356 --> 00:06:01.746
en hangt af van je beenlengte

00:06:01.746 --> 00:06:03.456
en je rug en de kromming ervan.

00:06:03.456 --> 00:06:05.987
Als ik 100 sensoren zou plaatsen

00:06:05.987 --> 00:06:07.753
in jullie stoelen,

00:06:07.753 --> 00:06:11.353
zou ik een serie getallen krijgen
die uniek voor jou is.

00:06:11.353 --> 00:06:15.762
Een soort vingerafdruk
maar niet van je vinger.

00:06:15.762 --> 00:06:18.731
Wat zouden we er dan mee kunnen doen?

00:06:18.731 --> 00:06:21.128
Onderzoekers in Tokyo gebruiken dit

00:06:21.128 --> 00:06:25.516
als mogelijk anti-autodiefstal-apparaat.

00:06:25.516 --> 00:06:28.440
Het idee is dat de autodief
achter het stuur zit

00:06:28.440 --> 00:06:30.544
en ervandoor gaat, maar de auto ontdekt

00:06:30.544 --> 00:06:32.906
dat iemand stuurt die daar niet hoort.

00:06:32.906 --> 00:06:34.280
De motor stopt dan,

00:06:34.280 --> 00:06:38.247
tenzij je een wachtwoord intypt
op het dashboard

00:06:38.247 --> 00:06:40.607
waarmee je zegt: "Ik heb toestemming."

00:06:40.607 --> 00:06:41.967
Geweldig.

00:06:42.967 --> 00:06:45.328
Als alle auto's in Europa

00:06:45.328 --> 00:06:46.915
deze technologie nou eens hadden?

00:06:46.915 --> 00:06:50.080
Wat zouden we nog meer kunnen doen?

00:06:50.080 --> 00:06:52.320
Als we deze informatie zouden verzamelen

00:06:52.320 --> 00:06:56.134
konden we aanwijzingen signaleren

00:06:56.134 --> 00:07:03.103
die voorspellen dat over 5 seconden 
een auto-ongeluk gaat gebeuren.

00:07:04.736 --> 00:07:07.293
Wat we daarvoor zullen gaan vastleggen,

00:07:07.293 --> 00:07:09.076
is vermoeidheid tijdens het rijden.

00:07:09.076 --> 00:07:11.410
De applicatie in de auto merkt het

00:07:11.410 --> 00:07:14.847
als de persoon wegzakt

00:07:14.847 --> 00:07:18.841
en weet dan automatisch
dat er een wekker moet afgaan

00:07:18.841 --> 00:07:20.866
die het stuurwiel laat trillen, toetert,

00:07:20.866 --> 00:07:22.587
en zegt: "Wakker worden,

00:07:22.587 --> 00:07:24.491
beter opletten op de weg."

00:07:24.491 --> 00:07:26.344
Dit soort dingen kunnen we doen

00:07:26.344 --> 00:07:29.165
als we nog meer van ons leven
vastleggen in gegevens.

00:07:29.165 --> 00:07:32.840
Wat is de waarde van big data?

00:07:32.840 --> 00:07:35.030
Denk eens na.

00:07:35.030 --> 00:07:37.442
Je hebt meer informatie.

00:07:37.442 --> 00:07:40.783
Je kan dingen doen
die je eerst niet kon doen.

00:07:40.783 --> 00:07:42.459
Een van de indrukwekkendste plekken

00:07:42.459 --> 00:07:44.188
waar dit idee wordt uitgevoerd

00:07:44.188 --> 00:07:47.495
is die van machine-leren.

00:07:47.495 --> 00:07:50.572
Machine-leren is een tak
van kunstmatige intelligentie

00:07:50.572 --> 00:07:53.950
die zelf weer onderdeel is
van computerwetenschap.

00:07:53.950 --> 00:07:57.603
Het idee is dat we de computer
niet vertellen wat hij moet doen

00:07:57.610 --> 00:08:00.230
maar dat we er gewoon gegevens in gooien

00:08:00.230 --> 00:08:03.436
en de computer opdragen
het probleem zelf op te lossen.

00:08:03.436 --> 00:08:07.053
Je begrijpt het beter als je ziet
waar het vandaan komt.

00:08:08.765 --> 00:08:10.153
In de vijftiger jaren

00:08:10.153 --> 00:08:14.745
vond computerwetenschapper Arthur Samuel
van IBM, het leuk om te dammen.

00:08:14.745 --> 00:08:16.147
Hij schreef een programma

00:08:16.147 --> 00:08:18.960
zodat hij tegen de computer kon spelen.

00:08:18.960 --> 00:08:21.671
Hij speelde en won.

00:08:21.671 --> 00:08:23.774
Hij speelde en won.

00:08:23.774 --> 00:08:26.789
Hij speelde en won,

00:08:26.789 --> 00:08:28.567
omdat de computer alleen wist

00:08:28.567 --> 00:08:30.794
wat een geldige zet was.

00:08:30.794 --> 00:08:32.881
Arthur Samuel wist nog meer.

00:08:32.881 --> 00:08:36.580
Arthur Samuel kende strategie.

00:08:37.510 --> 00:08:39.906
Hij schreef er een programmaatje bij

00:08:39.906 --> 00:08:41.880
dat op de achtergrond werkte

00:08:41.880 --> 00:08:43.697
en bijhield hoe groot de kans was

00:08:43.697 --> 00:08:46.260
dat een bepaalde spelsituatie leidde

00:08:46.260 --> 00:08:49.170
naar winst of verlies

00:08:49.170 --> 00:08:51.678
na elke zet.

00:08:51.678 --> 00:08:54.828
Hij speelt tegen de computer. Hij wint.

00:08:54.828 --> 00:08:57.336
Hij speelt tegen de computer. Hij wint.

00:08:57.336 --> 00:09:00.007
Hij speelt tegen de computer. Hij wint.

00:09:01.067 --> 00:09:05.564
En dan laat hij het de computer
tegen zichzelf spelen.

00:09:05.571 --> 00:09:09.080
Hij speelt tegen zichzelf
en verzamelt meer gegevens.

00:09:09.080 --> 00:09:13.389
Hij verzamelt meer gegevens
en wordt preciezer in zijn voorspelling.

00:09:13.389 --> 00:09:15.493
Dan gaat Samuel terug naar de computer,

00:09:15.493 --> 00:09:17.811
speelt tegen hem en verliest.

00:09:17.811 --> 00:09:19.880
En speelt nogmaals en verliest.

00:09:19.880 --> 00:09:21.927
En speelt weer en verliest.

00:09:21.927 --> 00:09:24.526
Arthur Samuel heeft een machine gemaakt

00:09:24.526 --> 00:09:30.814
die beter is dan Arthur, in een taak 
die Arthur hem aangeleerd heeft.

00:09:30.814 --> 00:09:33.312
Dit idee van machine-leren

00:09:33.312 --> 00:09:37.239
heeft allerlei gevolgen.

00:09:37.239 --> 00:09:40.388
Hoe denk je dat we
zelfrijdende auto's krijgen?

00:09:40.388 --> 00:09:42.525
Zijn we beter af als maatschappij

00:09:42.525 --> 00:09:45.810
door alle regels van de weg
in software te stoppen?

00:09:45.810 --> 00:09:48.408
Nee. Geheugen is goedkoper. Nee.

00:09:48.408 --> 00:09:52.402
Algoritmes zijn sneller. Nee.
Processors zijn beter. Nee.

00:09:52.402 --> 00:09:55.174
Die dingen doen ertoe,
maar dat is niet de reden.

00:09:55.174 --> 00:09:58.315
Het komt omdat we de aard 
van het probleem veranderd hebben.

00:09:58.315 --> 00:09:59.845
Vroeger probeerden we

00:09:59.845 --> 00:10:02.090
aan de computer uit te leggen

00:10:02.090 --> 00:10:04.671
hoe hij moet rijden.

00:10:04.671 --> 00:10:05.987
Nu zeggen we:

00:10:05.987 --> 00:10:09.243
"Hier zijn veel gegevens over dit voertuig.
Zoek het maar uit.

00:10:09.396 --> 00:10:11.263
Vind maar uit
dat het een verkeerslicht is,

00:10:11.263 --> 00:10:13.344
dat het rood is en niet groen,

00:10:13.344 --> 00:10:15.358
dat je dan moet stoppen

00:10:15.358 --> 00:10:18.441
en niet meer vooruit moet gaan."

00:10:18.441 --> 00:10:19.959
Machine-leren is de basis

00:10:19.959 --> 00:10:21.950
van veel dingen die we online doen:

00:10:21.950 --> 00:10:23.807
zoekmachines,

00:10:23.807 --> 00:10:27.608
het personaliseer-algoritme van Amazon,

00:10:27.608 --> 00:10:29.820
computervertalingen,

00:10:29.820 --> 00:10:32.340
systemen voor stemherkenning.

00:10:34.110 --> 00:10:36.945
Onderzoekers hebben onlangs gekeken

00:10:36.945 --> 00:10:40.140
naar de kwestie van biopsies,

00:10:40.140 --> 00:10:42.907
kankerbiopsies.

00:10:42.907 --> 00:10:45.222
Ze vroegen de computer te kijken

00:10:45.222 --> 00:10:47.693
naar de gegevens 
en overlevingsstatistieken

00:10:47.693 --> 00:10:53.660
om te bepalen of het kankercellen zijn

00:10:54.904 --> 00:10:56.682
Als je de gegevens erin gooit

00:10:56.682 --> 00:10:58.729
en een machine-leer-algoritme gebruikt,

00:10:58.729 --> 00:11:01.886
bleek dat de machine
12 verklikkers kon bepalen

00:11:01.886 --> 00:11:03.268
die het beste voorspellen

00:11:03.268 --> 00:11:06.167
of een biopsie van kankercellen

00:11:06.167 --> 00:11:09.385
inderdaad kanker is.

00:11:09.385 --> 00:11:11.883
Het probleem: de medische literatuur

00:11:11.883 --> 00:11:14.672
kende er maar negen.

00:11:14.672 --> 00:11:16.472
Naar drie kenmerken

00:11:16.472 --> 00:11:19.447
hoefde de mens niet te kijken,

00:11:19.447 --> 00:11:22.478
maar de machine zag ze wel.

00:11:24.978 --> 00:11:30.643
Er zit ook een zwarte kant aan big data.

00:11:30.643 --> 00:11:32.977
Het verbetert ons leven,
maar er zijn problemen

00:11:32.977 --> 00:11:35.617
waar we ons van bewust moeten zijn.

00:11:35.617 --> 00:11:38.240
De eerste is het idee

00:11:38.240 --> 00:11:40.926
dat we gestraft kunnen worden
voor onze voorspellingen

00:11:40.926 --> 00:11:44.796
en dat de politie ook big data gebruikt.

00:11:44.796 --> 00:11:47.147
Een beetje als in de film 'Minory Report'.

00:11:47.147 --> 00:11:49.898
Het heet 'predictive policing'
(voorspellend politiewerk),

00:11:49.898 --> 00:11:51.951
of algoritme-criminologie.

00:11:51.951 --> 00:11:53.987
We nemen daarbij een hoop gegevens

00:11:53.987 --> 00:11:56.146
bijvoorbeeld waar criminaliteit voorkwam,

00:11:56.146 --> 00:11:58.689
om te weten we waar agenten
hun ronde moeten doen.

00:11:58.689 --> 00:12:00.804
Dat lijkt slim maar het probleem

00:12:00.804 --> 00:12:05.348
is dat het niet zal blijven
bij gegevens over de locatie,

00:12:05.348 --> 00:12:08.307
maar dat tot op 
het individuele niveau zal gaan.

00:12:08.307 --> 00:12:10.297
Waarom gebruiken we geen gegevens

00:12:10.297 --> 00:12:12.785
over iemands middelbareschoolverleden?

00:12:12.785 --> 00:12:15.036
Of ze werkloos zijn of niet,

00:12:15.036 --> 00:12:16.374
hun kredietwaardigheid,

00:12:16.374 --> 00:12:17.926
hun websurfgedrag,

00:12:17.926 --> 00:12:19.804
of ze laat naar bed gaan.

00:12:19.804 --> 00:12:22.965
Als hun gps-horloge
biologische dingen kan meten,

00:12:22.965 --> 00:12:25.641
zal het merken
of hij agressieve gedachten heeft.

00:12:27.201 --> 00:12:29.422
We zullen algoritmes krijgen
die voorspellen

00:12:29.422 --> 00:12:31.055
wat we van plan zijn te doen

00:12:31.055 --> 00:12:34.889
en zouden kunnen worden aangesproken
voordat we gehandeld hebben.

00:12:34.889 --> 00:12:36.621
Privacy was de grote uitdaging

00:12:36.621 --> 00:12:39.501
bij weinig gegevens.

00:12:39.501 --> 00:12:41.650
In het big data-tijdperk

00:12:41.650 --> 00:12:46.173
wordt de uitdaging het waarborgen 
van de vrije wil,

00:12:46.173 --> 00:12:49.952
morele keuzevrijheid, menselijke wil,

00:12:49.952 --> 00:12:53.020
menselijk handelen.

00:12:54.540 --> 00:12:56.765
Er is nog een probleem.

00:12:56.765 --> 00:13:00.321
Big data zal banen gaan kosten.

00:13:00.321 --> 00:13:03.833
Big data en algoritmes zullen het opnemen

00:13:03.833 --> 00:13:06.894
tegen de kantoormensen, kenniswerk,

00:13:06.894 --> 00:13:08.547
in de 21ste eeuw.

00:13:08.547 --> 00:13:10.981
Net zoals fabrieksautomatisering

00:13:10.981 --> 00:13:13.170
en lopende banden

00:13:13.170 --> 00:13:16.196
het opnamen tegen de fabrieksaarbeiders
in de 20ste eeuw.

00:13:16.196 --> 00:13:18.288
Denk eens aan een laborant

00:13:18.288 --> 00:13:19.697
die in een microscoop kijkt

00:13:19.697 --> 00:13:21.321
naar een kankerbiopsie

00:13:21.321 --> 00:13:23.958
om te kijken of het kanker is of niet.

00:13:23.958 --> 00:13:25.930
Deze persoon is afgestudeerd,

00:13:25.930 --> 00:13:27.360
koopt een huis,

00:13:27.360 --> 00:13:29.101
hij of zij gaat naar de stembus,

00:13:29.101 --> 00:13:32.767
en neemt deel aan de maatschappij.

00:13:32.767 --> 00:13:37.321
Die persoon en nog een hele rij
soortgelijke professionals

00:13:37.739 --> 00:13:40.889
zullen merken dat hun baan
heel erg verandert

00:13:40.889 --> 00:13:43.246
of helemaal verdwijnt.

00:13:43.246 --> 00:13:44.530
We willen graag geloven

00:13:44.530 --> 00:13:47.717
dat techniek mettertijd
voor banen zorgt,

00:13:47.717 --> 00:13:51.182
na een periode van ontwrichting.

00:13:51.182 --> 00:13:53.123
Dat klopt voor het referentiekader

00:13:53.123 --> 00:13:55.265
waarin we leven, de industriÃ«le revolutie.

00:13:55.265 --> 00:13:57.593
Want dat is precies wat er is gebeurd.

00:13:57.593 --> 00:13:59.926
Maar we hebben iets vergeten
in die analyse.

00:13:59.926 --> 00:14:01.756
Er zijn een paar soorten banen

00:14:01.756 --> 00:14:05.176
die gewoon verdwijnen
en nooit meer terugkomen.

00:14:05.176 --> 00:14:07.180
De industriÃ«le revolutie was niet best

00:14:07.180 --> 00:14:11.182
als je een paard was.

00:14:11.182 --> 00:14:13.237
We moeten dus erg zorgvuldig zijn,

00:14:13.237 --> 00:14:16.751
en big data aanpassen aan onze behoeftes,

00:14:16.751 --> 00:14:19.936
onze zeer menselijke behoeftes.

00:14:19.936 --> 00:14:21.890
We moeten de technologie de baas zijn.

00:14:21.890 --> 00:14:23.546
niet omgekeerd.

00:14:23.546 --> 00:14:26.504
We staan aan het begin
van het big data-tijdperk,

00:14:26.504 --> 00:14:29.654
en eerlijk gezegd
zijn we nog niet zo goed

00:14:29.654 --> 00:14:33.861
in het omgaan met de big data
die we verzamelen.

00:14:33.861 --> 00:14:37.191
Het is niet alleen een probleem
voor de NSA.

00:14:37.191 --> 00:14:40.229
Bedrijven verzamelen veel data
en misbruiken die ook.

00:14:40.229 --> 00:14:43.896
We moeten er beter in worden
en dat kost tijd.

00:14:43.896 --> 00:14:45.718
Het lijkt op de uitdaging

00:14:45.718 --> 00:14:48.125
die de mens ooit had met vuur.

00:14:48.125 --> 00:14:50.010
Het is een gereedschap,

00:14:50.010 --> 00:14:53.569
maar als je niet uitkijkt, verbrand je.

00:14:56.008 --> 00:14:59.128
Big data gaat ons leven veranderen.

00:14:59.128 --> 00:15:01.929
Hoe we leven, hoe we werken
en hoe we denken.

00:15:01.929 --> 00:15:03.818
Het gaat ons helpen bij onze carriÃ¨re

00:15:03.818 --> 00:15:07.452
en ons een tevreden
en hoopvol leven laten leiden

00:15:07.452 --> 00:15:10.444
in blijdschap en gezondheid.

00:15:10.444 --> 00:15:13.750
Maar vroeger keken we vaak 
naar informatietechnologie

00:15:13.750 --> 00:15:15.958
en zagen we alleen de T,

00:15:15.958 --> 00:15:17.644
Technologie, de spullen,

00:15:17.644 --> 00:15:19.906
omdat dat fysiek was.

00:15:19.906 --> 00:15:22.830
Maar nu moeten we onze blik aanpassen
om de I te zien,

00:15:22.830 --> 00:15:24.210
de Informatie,

00:15:24.210 --> 00:15:25.583
die minder zichtbaar is

00:15:25.583 --> 00:15:29.692
maar in zekere zin belangrijker.

00:15:29.692 --> 00:15:33.157
De mensheid kan eindelijk leren
van informatie

00:15:33.157 --> 00:15:35.575
die ze verzamelt

00:15:35.575 --> 00:15:37.690
als onderdeel van onze eeuwige zoektocht

00:15:37.690 --> 00:15:40.849
om de wereld en onze plek erin
beter te begrijpen.

00:15:40.849 --> 00:15:46.480
Daarom is big data van groot belang.

00:15:46.480 --> 00:15:50.048
(Applaus)

