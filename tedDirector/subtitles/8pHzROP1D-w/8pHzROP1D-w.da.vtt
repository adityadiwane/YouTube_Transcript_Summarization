WEBVTT
Kind: captions
Language: da

00:00:00.000 --> 00:00:07.000
Translator: Simon Bugge Jensen
Reviewer: Anders Finn Jørgensen

00:00:12.787 --> 00:00:16.632
USAs yndlingstærte er?

00:00:16.632 --> 00:00:20.138
Publikum: Æble
Kenneth Cukier: Æble. Selvfølgelig er det det.

00:00:20.138 --> 00:00:21.369
Hvordan ved vi det?

00:00:21.369 --> 00:00:24.122
På grund af data.

00:00:24.122 --> 00:00:26.188
Man kigger på supermarkedssalget.

00:00:26.188 --> 00:00:29.054
Man kigger på salget af frosne 30-centimeter tærter

00:00:29.054 --> 00:00:33.129
og her vinder æble-tærter, uden konkurrence.

00:00:33.129 --> 00:00:36.279
Størstedelen af salget er æble.

00:00:38.309 --> 00:00:41.273
Men så startede supermarkederne med at sælge

00:00:41.273 --> 00:00:43.856
mindre 11-centimeter tærter,

00:00:43.856 --> 00:00:48.030
og pludselig faldt æbletærter til 4. eller 5. pladsen.

00:00:48.030 --> 00:00:50.905
Hvorfor? Hvad skete der?

00:00:50.905 --> 00:00:53.723
Ok, tænk jer om.

00:00:53.723 --> 00:00:57.571
Når man køber en en 30-centimeter tærte,

00:00:57.571 --> 00:00:59.832
så er hele familien nødt til at enes,

00:00:59.832 --> 00:01:03.623
og æble er alles anden-favorit.

00:01:03.623 --> 00:01:05.558
(Latter)

00:01:05.558 --> 00:01:09.173
Men når man køber en 11-centimeter 
tærte til sig selv,

00:01:09.173 --> 00:01:12.918
så kan man købe den, man helst vil have.

00:01:12.918 --> 00:01:16.933
Man kan få sit førstevalg.

00:01:16.933 --> 00:01:18.574
Man har mere data.

00:01:18.574 --> 00:01:20.128
Man kan se noget,

00:01:20.128 --> 00:01:21.260
som man ikke kunne se,

00:01:21.260 --> 00:01:25.213
da man havde mindre mængder af det.

00:01:25.213 --> 00:01:27.688
Pointen er her, at mere data,

00:01:27.688 --> 00:01:29.971
ikke bare lader os se mere,

00:01:29.971 --> 00:01:31.825
mere af det samme, som vi kiggede på.

00:01:31.825 --> 00:01:35.438
Mere data tillader os at se noget nyt.

00:01:35.438 --> 00:01:38.532
Det tillader os at se bedre.

00:01:38.532 --> 00:01:42.188
Det tillader os at se anderledes.

00:01:42.188 --> 00:01:45.361
I dette tilfælde tillader det os at se,

00:01:45.361 --> 00:01:48.274
hvad USAs yndlingstærte er:

00:01:48.274 --> 00:01:50.816
ikke æble.

00:01:50.816 --> 00:01:54.430
I har formentlig alle hørt om begrebet "big data".

00:01:54.430 --> 00:01:56.487
I er formentlig endda allerede trætte af 
at høre om begrebet

00:01:56.487 --> 00:01:58.117
"big data".

00:01:58.117 --> 00:02:01.447
Det er sandt, at der er en masse hype
omkring begrebet,

00:02:01.447 --> 00:02:03.779
hvilket er meget uheldigt,

00:02:03.779 --> 00:02:06.825
fordi "big data" er et ekstremt vigtigt redskab

00:02:06.825 --> 00:02:10.559
til at udvikle samfundet.

00:02:10.559 --> 00:02:14.120
Indtil nu har vi analyseret på 
mindre mængde data

00:02:14.120 --> 00:02:15.824
og tænk på, hvad det har betydet

00:02:15.824 --> 00:02:17.320
for at prøve at forstå verdenen,

00:02:17.320 --> 00:02:19.311
og nu har vi meget mere af det,

00:02:19.311 --> 00:02:22.033
kan vi forstå mere end nogensinde før.

00:02:22.033 --> 00:02:23.910
Det vi opnår, når vi har

00:02:23.910 --> 00:02:26.634
en stor mængde data er, 
at vi grundlæggende kan gøre ting,

00:02:26.634 --> 00:02:29.910
som vi ikke kunne, da vi havde
mindre mængder data.

00:02:29.910 --> 00:02:32.551
"Big data" er vigtigt og "big data" er nyt,

00:02:32.551 --> 00:02:34.328
og når man tænker over det,

00:02:34.328 --> 00:02:36.544
så er den eneste måde 
denne planet kan håndtere

00:02:36.544 --> 00:02:38.333
med dens globale udfordringer -

00:02:38.333 --> 00:02:41.870
at give folk mad, give dem lægebehandling,

00:02:41.870 --> 00:02:44.680
levere energi, strøm

00:02:44.680 --> 00:02:46.469
og sikre sig, at de ikke bliver forbrændte

00:02:46.469 --> 00:02:47.707
pga. global opvarmning -

00:02:47.707 --> 00:02:51.902
er pga. den effektive udnyttelse af data.

00:02:51.902 --> 00:02:55.772
Så hvad er det det nye ved "big data"? 
Hvad handler det om?

00:02:55.772 --> 00:02:58.289
For at besvare dette spørgsmål, 
så lad os huske på,

00:02:58.289 --> 00:03:00.185
hvordan information så ud,

00:03:00.185 --> 00:03:03.219
fysisk så ud i fortiden.

00:03:03.219 --> 00:03:06.830
I 1908 på øen Kreta

00:03:06.830 --> 00:03:11.565
opdagede arkæologer en skive ler.

00:03:11.565 --> 00:03:15.624
De daterede den til 2000 år f.kr., 
så den er 4000 år gammel.

00:03:15.624 --> 00:03:17.628
Der er inskriptioner på denne skive,

00:03:17.628 --> 00:03:18.955
men vi aner faktisk ikke, hvad de betyder.

00:03:18.955 --> 00:03:21.053
Det er et komplet mysterie, men pointen er,

00:03:21.053 --> 00:03:22.981
at det var sådan information så ud

00:03:22.981 --> 00:03:25.070
for 4000 år siden.

00:03:25.070 --> 00:03:27.618
Det var sådan samfundet opbevarede

00:03:27.618 --> 00:03:31.142
og overførte information.

00:03:31.142 --> 00:03:35.302
Samfundet har egentlig ikke ændret sig så meget.

00:03:35.302 --> 00:03:38.776
Vi gemmer stadig information på skiver,

00:03:38.776 --> 00:03:41.960
men nu kan vi gemme meget mere information,

00:03:41.960 --> 00:03:43.220
mere end nogensinde.

00:03:43.220 --> 00:03:46.313
At søge i det er nemmere. 
At kopiere det er nemmere.

00:03:46.313 --> 00:03:49.813
At dele det er nemmere. 
At bearbejde det er nemmere.

00:03:49.813 --> 00:03:52.579
Og det vi kan gøre er, 
at vi kan genbruge denne information

00:03:52.579 --> 00:03:54.413
til ting vi aldrig havde forestillet os,

00:03:54.413 --> 00:03:57.608
da vi først indsamlede de data.

00:03:57.608 --> 00:03:59.860
I den henseende er data gået

00:03:59.860 --> 00:04:03.392
fra at være fast til at være flydende,

00:04:03.392 --> 00:04:07.330
fra noget der er stationært og statisk

00:04:07.330 --> 00:04:10.939
til noget der er flydende og dynamisk.

00:04:10.939 --> 00:04:14.962
Der er, om man vil, 
en likviditet af information.

00:04:14.962 --> 00:04:18.436
Den disk, der blev opdaget på Kreta,

00:04:18.436 --> 00:04:22.200
der er 4000 år gammel, er tung,

00:04:22.200 --> 00:04:24.162
den kan ikke opbevare meget information,

00:04:24.162 --> 00:04:27.278
og informationen kan ikke ændres.

00:04:27.278 --> 00:04:31.289
Omvendt, så kan alle de filer

00:04:31.289 --> 00:04:33.150
som Edward Snowden tog

00:04:33.150 --> 00:04:35.771
fra NSA i USA

00:04:35.771 --> 00:04:38.190
være på et USB-stik

00:04:38.190 --> 00:04:41.200
på størrelse med en fingernegl,

00:04:41.200 --> 00:04:45.945
og de kan blive delt med lysets hastighed.

00:04:45.945 --> 00:04:49.070
Mere data. Mere.

00:04:50.940 --> 00:04:53.174
En af grundene til, at vi har så 
meget data i verden i dag er,

00:04:53.174 --> 00:04:54.606
at vi indsamler ting,

00:04:54.606 --> 00:04:57.886
som vi altid har indsamlet information om,

00:04:57.886 --> 00:05:00.542
men en anden grund hvorfor er, at vi tager ting,

00:05:00.542 --> 00:05:03.354
der altid har været information,

00:05:03.354 --> 00:05:05.840
men som aldrig har eksisteret som data

00:05:05.840 --> 00:05:08.259
og vi omsætter det til data.

00:05:08.259 --> 00:05:11.567
Tænke f.eks. på spørgsmålet om lokation.

00:05:11.567 --> 00:05:13.816
Tag f.eks. Martin Luther.

00:05:13.816 --> 00:05:15.413
Hvis vi ønskede at vide i 1500-tallet,

00:05:15.413 --> 00:05:18.080
hvor Martin Luther var,

00:05:18.080 --> 00:05:20.172
ville vi være nødt til at følge ham konstant,

00:05:20.172 --> 00:05:22.309
eventuelt med en fjer og et blækhus

00:05:22.309 --> 00:05:23.985
og nedfælde det,

00:05:23.985 --> 00:05:26.168
men tænk på hvordan det foregår i dag.

00:05:26.168 --> 00:05:28.290
Man ved at et eller andet sted,

00:05:28.290 --> 00:05:30.736
formentlig i en telekommunikations-
virksomheds database,

00:05:30.736 --> 00:05:33.772
er der et dataark eller i det mindste
en databaseindgang,

00:05:33.772 --> 00:05:35.860
der optager ens information,

00:05:35.860 --> 00:05:37.923
om hvor man har opholdt sig til hver en tid.

00:05:37.923 --> 00:05:39.283
Hvis man har en mobiltelefon

00:05:39.283 --> 00:05:42.130
og den telefon har GPS, 
og selvom det ikke har GPS,

00:05:42.130 --> 00:05:44.515
kan den optage den information.

00:05:44.515 --> 00:05:48.599
I den henseende, så er ens lokation 
blevet omsat til data.

00:05:48.599 --> 00:05:53.200
Tænk f.eks. på emnet kropsholdning,

00:05:53.200 --> 00:05:54.485
den måde I alle sidder på lige nu,

00:05:54.485 --> 00:05:56.515
den måde du sidder på,

00:05:56.515 --> 00:05:59.286
den måde du sidder på, 
den måde du sidder på,

00:05:59.286 --> 00:06:01.363
de er alle forskellige og er en 
funktion af jeres benlængde,

00:06:01.363 --> 00:06:03.456
jeres ryg og konturerne af jeres ryg

00:06:03.456 --> 00:06:05.987
og hvis jeg skulle sætte, måske 100 censorer

00:06:05.987 --> 00:06:07.753
på alle jeres stole lige nu,

00:06:07.753 --> 00:06:11.353
så kunne jeg skabe et indeks, 
der er ganske unikt for jer,

00:06:11.353 --> 00:06:15.762
på en måde som et fingeraftryk, 
men det det er ikke jeres finger.

00:06:15.762 --> 00:06:18.731
Så hvad kan vi bruge dette til?

00:06:18.731 --> 00:06:21.128
Forskere i Tokyo bruger det

00:06:21.128 --> 00:06:25.516
som en potentiel tyverialarm i biler

00:06:25.516 --> 00:06:28.440
Ideen er at biltyven sidder bag rattet

00:06:28.440 --> 00:06:30.544
og forsøger at komme væk, 
men bilen genkender,

00:06:30.544 --> 00:06:32.906
at en ikke-godkendt chauffør sidder bag rattet

00:06:32.906 --> 00:06:35.070
og måske stopper motoren medmindre

00:06:35.070 --> 00:06:38.247
man indtaster et password i kontrolpanelet

00:06:38.247 --> 00:06:42.905
for at sige: "Hej, jeg har godkendelse til at køre." 
Fantastisk.

00:06:42.905 --> 00:06:45.458
Hvad hvis hver eneste bil i Europa

00:06:45.458 --> 00:06:46.915
havde denne teknologi indbygget?

00:06:46.915 --> 00:06:50.080
Hvad kunne vi så gøre?

00:06:50.080 --> 00:06:52.320
Måske, hvis vi aggregerede data,

00:06:52.320 --> 00:06:56.134
kunne vi identificere afslørende tegn,

00:06:56.134 --> 00:06:58.843
der bedst kan forudsige, at en ulykke

00:06:58.843 --> 00:07:04.736
vil ske indenfor de næste fem sekunder.

00:07:04.736 --> 00:07:07.293
Og så er det, som vi har omsat til data

00:07:07.293 --> 00:07:09.076
chauffør-træthed

00:07:09.076 --> 00:07:11.410
og servicen vil så være, 
at når bilen registrerer,

00:07:11.410 --> 00:07:14.847
at personen falder sammen i den postitur

00:07:14.847 --> 00:07:18.841
vil den automatisk vide det og 
sætte en intern alarm i gang,

00:07:18.841 --> 00:07:20.866
der ville få rattet til at vibrere, 
indvendigt dytte hornet

00:07:20.866 --> 00:07:22.587
for at sige, "Hallo, vågn op,

00:07:22.587 --> 00:07:24.491
være mere opmærksom på vejen."

00:07:24.491 --> 00:07:26.344
Det er den slags ting, som vi kan gøre,

00:07:26.344 --> 00:07:29.165
når vi får data på flere aspekter af vores liv.

00:07:29.165 --> 00:07:32.840
Så hvad er værdien af "big data"?

00:07:32.840 --> 00:07:35.030
Tænk over det.

00:07:35.030 --> 00:07:37.442
Man har mere information.

00:07:37.442 --> 00:07:40.783
Man kan gøre ting, man ikke kunne gøre før.

00:07:40.783 --> 00:07:42.459
Et af de mest imponerende områder,

00:07:42.459 --> 00:07:44.188
hvor dette koncept forekommer

00:07:44.188 --> 00:07:47.495
er indenfor området for maskinindlæring.

00:07:47.495 --> 00:07:50.572
Maskine-indlæring er en kategori 
indenfor kunstig intelligens,

00:07:50.572 --> 00:07:53.950
der i sig selv er en kategori 
indenfor computervidenskab.

00:07:53.950 --> 00:07:55.493
Den generelle ide er, at i stedet for

00:07:55.493 --> 00:07:57.610
at instruere en computer i, 
hvad den skal gøre,

00:07:57.610 --> 00:08:00.230
vil vil ganske enkelt smide data efter problemet

00:08:00.230 --> 00:08:03.436
og fortælle computeren, 
at den selv skal finde ud af det.

00:08:03.436 --> 00:08:05.213
Og den vil hjælpe en med at forstå det

00:08:05.213 --> 00:08:08.765
ved at se dets oprindelse.

00:08:08.765 --> 00:08:11.153
I 1950'erne var der er en datamatiker hos IBM,

00:08:11.153 --> 00:08:14.745
der hed Arthur Samuel, 
som kunne lide at spille dam,

00:08:14.745 --> 00:08:16.147
så han skrev et computer program,

00:08:16.147 --> 00:08:18.960
så han kunne spille mod computeren.

00:08:18.960 --> 00:08:21.671
Han spillede. Han vandt.

00:08:21.671 --> 00:08:23.774
Han spillede. Han vandt.

00:08:23.774 --> 00:08:26.789
Han spillede. Han vandt,

00:08:26.789 --> 00:08:28.567
fordi computeren vidste kun,

00:08:28.567 --> 00:08:30.794
hvad der var et lovligt træk.

00:08:30.794 --> 00:08:32.881
Arthur Samuel vidste mere end det.

00:08:32.881 --> 00:08:37.510
Arthur Samuel kendte til strategi.

00:08:37.510 --> 00:08:39.906
Så han skrev et mindre 
under-program ved siden af,

00:08:39.906 --> 00:08:41.880
der kørte i baggrunden og alt det gjorde,

00:08:41.880 --> 00:08:43.697
var at udregne sandsynligheden for,

00:08:43.697 --> 00:08:46.260
at en given stilling på 
pladen formentlig ville føre

00:08:46.260 --> 00:08:49.170
til et vindende spil i forhold
til et tabende spil

00:08:49.170 --> 00:08:51.678
for hvert træk.

00:08:51.678 --> 00:08:54.828
Han spiller mod computeren. Han vinder.

00:08:54.828 --> 00:08:57.336
Han spiller mod computeren. Han vinder.

00:08:57.336 --> 00:09:01.067
Han spiller mod computeren. Han vinder.

00:09:01.067 --> 00:09:03.344
Og så lader Arthur Samuel computeren

00:09:03.344 --> 00:09:05.571
spille mod sig selv.

00:09:05.571 --> 00:09:09.080
Den spiller mod sig selv. 
Den indsamler mere data.

00:09:09.080 --> 00:09:13.389
Den indsamler mere data. 
Den øger nøjagtigheden af sine forudsigelser.

00:09:13.389 --> 00:09:15.493
Og så går Arthur Samuel tilbage til computeren

00:09:15.493 --> 00:09:17.811
og han spiller mod den, og han taber,

00:09:17.811 --> 00:09:19.880
og han spiller mod den, og han taber,

00:09:19.880 --> 00:09:21.927
og han spiller mod den, og han taber.

00:09:21.927 --> 00:09:24.526
Så Arthur Samuel har skabt en maskine,

00:09:24.526 --> 00:09:30.814
der overgår hans evner for en opgave, 
som han har lært den.

00:09:30.814 --> 00:09:33.312
Og denne ide om maskine-indlæring

00:09:33.312 --> 00:09:37.239
forekommer overalt.

00:09:37.239 --> 00:09:40.388
Hvordan tror I vi har selv-kørende biler?

00:09:40.388 --> 00:09:42.525
Er vi bedre stillet som samfund,

00:09:42.525 --> 00:09:45.810
ved at programmere alle trafikregler
ind i noget software?

00:09:45.810 --> 00:09:48.408
Nej. Hukommelse er billigere. Nej.

00:09:48.408 --> 00:09:52.402
Algoritmer er hurtigere. Nej.
Processorer er bedre. Nej

00:09:52.402 --> 00:09:55.174
Alle disse ting betyder noget, 
men det er ikke derfor.

00:09:55.174 --> 00:09:58.315
Det er fordi vi har ændret på 
karakteren af problemet.

00:09:58.315 --> 00:09:59.845
Vi ændrede problemets karakter fra et,

00:09:59.845 --> 00:10:02.090
hvor vi tydeligt og eksplicit

00:10:02.090 --> 00:10:04.671
forklarer computeren, hvordan man kører,

00:10:04.671 --> 00:10:05.987
til et hvor vi siger:

00:10:05.987 --> 00:10:07.863
Her er en masse data om køretøjet.

00:10:07.863 --> 00:10:09.396
Regn det selv ud.

00:10:09.396 --> 00:10:11.263
Regn selv ud, at det er et trafiklys,

00:10:11.263 --> 00:10:13.344
at det trafiklys er rødt og ikke grønt,

00:10:13.344 --> 00:10:15.358
at det betyder, at man er nødt til at stoppe

00:10:15.358 --> 00:10:18.441
og ikke fortsætte fremad."

00:10:18.441 --> 00:10:19.959
Maskinindlæring er grundlaget

00:10:19.959 --> 00:10:21.950
for mange af de ting vi foretager os online:

00:10:21.950 --> 00:10:23.807
søgemaskiner,

00:10:23.807 --> 00:10:27.608
Amazons personaliserings-algoritme

00:10:27.608 --> 00:10:29.820
computer-oversættelser

00:10:29.820 --> 00:10:34.110
stemmegenkendelse-programmer

00:10:34.110 --> 00:10:36.945
Forskere har for nyligt set på

00:10:36.945 --> 00:10:40.140
spørgsmålet vedrørende biopsier,

00:10:40.140 --> 00:10:42.907
kræft-biopsier,

00:10:42.907 --> 00:10:45.222
og de har bedt en computer 
om at identificere

00:10:45.222 --> 00:10:47.693
ved at kigge på data og overlevelsesrater

00:10:47.693 --> 00:10:52.360
for at afgøre, om celler rent faktisk er

00:10:52.360 --> 00:10:54.904
kræft eller ej,

00:10:54.904 --> 00:10:56.682
og ganske rigtigt, når man smider data efter det,

00:10:56.682 --> 00:10:58.729
gennem en maskinlært algoritme,

00:10:58.729 --> 00:11:00.606
var maskinen i stand til at identificere

00:11:00.606 --> 00:11:02.868
de 12 indikatorer, der bedst kan forudsige

00:11:02.868 --> 00:11:06.167
om denne biopsi af brystkræftceller

00:11:06.167 --> 00:11:09.385
rent faktisk er kræft

00:11:09.385 --> 00:11:11.883
Problemet: Den medicinske litteratur

00:11:11.883 --> 00:11:14.672
kendte kun ni af dem.

00:11:14.672 --> 00:11:16.472
Tre af disse træk var nogle,

00:11:16.472 --> 00:11:19.447
som folk ikke behøvede at kigge efter,

00:11:19.447 --> 00:11:24.978
men som maskinen identificerede.

00:11:24.978 --> 00:11:30.903
Der er dog også skyggesider ved "big data".

00:11:30.903 --> 00:11:32.977
Det vil forbedre vores liv, 
men der er problemer,

00:11:32.977 --> 00:11:35.617
som vi er nødt til at være bevidste omkring,

00:11:35.617 --> 00:11:38.240
og den første er den ide,

00:11:38.240 --> 00:11:40.926
at vi muligvis bliver straffet for forudsigelser,

00:11:40.926 --> 00:11:44.796
at politiet måske vil benytte 
"big data" til deres formål,

00:11:44.796 --> 00:11:47.147
lidt som i "Minority Report".

00:11:47.147 --> 00:11:49.588
Det er et begreb der kaldes 
prædiktivt politiarbejde,

00:11:49.588 --> 00:11:51.951
eller algoritmisk kriminalarbejde,

00:11:51.951 --> 00:11:53.987
og ideen er, 
at hvis vi tager en masse data,

00:11:53.987 --> 00:11:56.146
f.eks. hvor tidligere forbrydelser 
har fundet sted,

00:11:56.146 --> 00:11:58.689
så ved vi, hvor vi skal sende patruljer hen.

00:11:58.689 --> 00:12:00.804
Det giver mening, 
men problemet er selvfølgelig,

00:12:00.804 --> 00:12:05.348
at det ikke stopper ved data for lokation,

00:12:05.348 --> 00:12:08.307
det vil komme helt ned på individ-niveau.

00:12:08.307 --> 00:12:10.557
Hvorfor benytter vi ikke data om en persons

00:12:10.557 --> 00:12:12.785
gymnasie-papirer?

00:12:12.785 --> 00:12:14.346
Måske skulle vi benytte det faktum,

00:12:14.346 --> 00:12:16.374
om de er arbejdsløse eller ej, 
deres kreditværdighed

00:12:16.374 --> 00:12:17.926
deres internet-adfærd,

00:12:17.926 --> 00:12:19.804
om de er oppe sent om aftenen.

00:12:19.804 --> 00:12:22.965
Deres Fitbit, når det er i stand til 
at identificere biokemi,

00:12:22.965 --> 00:12:27.201
vil afsløre, når de har aggressive tanker.

00:12:27.201 --> 00:12:29.422
Vi vil muligvis have algoritmer, 
der sandsynligt kan forudsige,

00:12:29.422 --> 00:12:31.055
hvad vi skal til at foretage os,

00:12:31.055 --> 00:12:32.299
og vi vil måske blive holdt ansvarlige,

00:12:32.299 --> 00:12:34.889
før vi overhovedet handlede.

00:12:34.889 --> 00:12:36.621
Privatlivet var en central udfordring

00:12:36.621 --> 00:12:39.501
i æraen for "small data"

00:12:39.501 --> 00:12:41.650
I "big data"-tidsalderen

00:12:41.650 --> 00:12:46.173
vil udfordringen være at beskytte den frie vilje

00:12:46.173 --> 00:12:49.952
moralske valg, menneskelig vilje,

00:12:49.952 --> 00:12:53.020
menneskets evne til at tage beslutninger.

00:12:54.540 --> 00:12:56.765
Der er et andet problem:

00:12:56.765 --> 00:13:00.321
"Big data" vil komme til at stjæle vores jobs.

00:13:00.321 --> 00:13:03.833
"Big data" og algoritmer vil udfordre

00:13:03.833 --> 00:13:06.894
administrativt arbejde, 
professionelt vidensarbejde

00:13:06.894 --> 00:13:08.547
i det 21. århundrede

00:13:08.547 --> 00:13:10.981
på samme måde som 
automatisering af fabrikker

00:13:10.981 --> 00:13:13.170
og samlebåndsteknikken

00:13:13.170 --> 00:13:16.196
udfordrede det fysiske 
arbejde i det 20. århundrede.

00:13:16.196 --> 00:13:18.288
Tænk på en laborant,

00:13:18.288 --> 00:13:19.697
der kigger i et mikroskop

00:13:19.697 --> 00:13:21.321
på en kræft-biopsi

00:13:21.321 --> 00:13:23.958
og skal afgøre om det er kræft eller ej.

00:13:23.958 --> 00:13:25.930
Den person gik på universitetet.

00:13:25.930 --> 00:13:27.360
Den person køber ejendom.

00:13:27.360 --> 00:13:29.101
Han eller hun stemmer.

00:13:29.101 --> 00:13:32.767
Han eller hun er en interessent i samfundet.

00:13:32.767 --> 00:13:34.161
Og den persons arbejde,

00:13:34.161 --> 00:13:35.770
så vel som en lang række andre

00:13:35.770 --> 00:13:37.739
beskæftigede som den person,

00:13:37.739 --> 00:13:40.889
vil opdage, at deres jobs vil ændre sig radikalt

00:13:40.889 --> 00:13:43.246
eller simpelthen forsvinde.

00:13:43.246 --> 00:13:44.530
Vi kan godt lide at tænke på,

00:13:44.530 --> 00:13:47.717
at teknologi skaber jobs over tid

00:13:47.717 --> 00:13:51.182
efter en kort midlertidig periode med uro,

00:13:51.182 --> 00:13:53.123
og det skete også for reference-
rammen som vi alle

00:13:53.123 --> 00:13:55.265
har, den industrielle revolution,

00:13:55.265 --> 00:13:57.593
fordi det er præcis det, der skete.

00:13:57.593 --> 00:13:59.926
Men vi glemte noget i den analyse:

00:13:59.926 --> 00:14:01.756
Der er nogen kategorier af jobs

00:14:01.756 --> 00:14:05.176
der simpelthen forsvinder og 
aldrig kommer tilbage.

00:14:05.176 --> 00:14:07.180
Den industrielle revolution var ikke særlig god,

00:14:07.180 --> 00:14:11.182
hvis man var en hest.

00:14:11.182 --> 00:14:13.237
Så vi er nødt til at være meget forsigtige

00:14:13.237 --> 00:14:16.751
og tage "big data" og justere det til vores behov,

00:14:16.751 --> 00:14:19.936
vores meget menneskelige behov.

00:14:19.936 --> 00:14:21.890
Vi er nødt til at være herre over denne teknologi

00:14:21.890 --> 00:14:23.546
ikke dens tjener.

00:14:23.546 --> 00:14:26.504
Vi står lige på tærsklen til "big data"-æraen

00:14:26.504 --> 00:14:29.654
og helt ærligt, så er vi ikke særligt gode til

00:14:29.654 --> 00:14:33.861
at behandle alle disse data, 
som vi nu kan indsamle.

00:14:33.861 --> 00:14:37.191
Det er ikke kun et problem for NSA.

00:14:37.191 --> 00:14:40.229
Forretningsverdenen indsamler 
mange data og de bruger det også dårligt

00:14:40.229 --> 00:14:43.896
og vi er nødt til at blive bedre til dette 
og det vil tage tid.

00:14:43.896 --> 00:14:45.718
Det er lidt ligesom udfordringen som

00:14:45.718 --> 00:14:48.125
stenaldermanden havde med ild.

00:14:48.125 --> 00:14:50.010
Det er et værktøj, men det er et værktøj der,

00:14:50.010 --> 00:14:53.569
medmindre vi er forsigtige, vil brænde os.

00:14:56.008 --> 00:14:59.128
"Big data" vil forandre, hvordan vi bor,

00:14:59.128 --> 00:15:01.929
hvordan vi arbejder og hvordan vi tænker

00:15:01.929 --> 00:15:03.818
Det vil hjælpe os med at styre vores karriere

00:15:03.818 --> 00:15:07.452
og leve et liv med tilfredsstillelse, håb

00:15:07.452 --> 00:15:10.444
glæde og sundhed

00:15:10.444 --> 00:15:13.750
men tidligere har vi ofte set på
informationsteknologi

00:15:13.750 --> 00:15:15.958
og vores øjne har kun set T'et

00:15:15.958 --> 00:15:17.644
teknologien, hardwaren,

00:15:17.644 --> 00:15:19.906
fordi den var fysisk.

00:15:19.906 --> 00:15:22.830
Vi er nu nødt til at ændre vores syn på I'et

00:15:22.830 --> 00:15:24.210
informationen,

00:15:24.210 --> 00:15:25.583
der er mindre åbenlys,

00:15:25.583 --> 00:15:29.692
men på nogle områder meget vigtigere.

00:15:29.692 --> 00:15:33.157
Menneskeheden kan endelig 
lære fra den information,

00:15:33.157 --> 00:15:35.575
som den indsamler,

00:15:35.575 --> 00:15:37.690
som del af en tidløs stræben efter

00:15:37.690 --> 00:15:40.849
at forstå verden og vores rolle i den,

00:15:40.849 --> 00:15:46.480
og det er derfor, at "big data" betyder så meget.

00:15:46.480 --> 00:15:50.048
(Klapsalver)

