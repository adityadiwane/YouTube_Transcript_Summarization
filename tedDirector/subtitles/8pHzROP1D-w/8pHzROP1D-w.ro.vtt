WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Teodora Rogozea
Corector: Adrian Dobroiu

00:00:12.927 --> 00:00:16.732
Plăcinta preferată a Americii. Care este?

00:00:16.732 --> 00:00:20.218
Public: De mere! 
Kenneth Cukier: De mere, sigur că da.

00:00:20.218 --> 00:00:21.659
De unde știm?

00:00:21.659 --> 00:00:24.742
Datorită datelor.

00:00:24.742 --> 00:00:30.378
Ne uităm la vânzările supermarketurilor,
vânzările plăcintelor congelate de 30 cm.

00:00:30.378 --> 00:00:32.919
Iar plăcinta de mere câștigă.
Detașat.

00:00:32.919 --> 00:00:36.939
Majoritatea vânzărilor
sunt la plăcinta de mere.

00:00:38.919 --> 00:00:43.863
Dar apoi supermarketurile au început
să vândă plăcinte mai mici, de 11 cm,

00:00:43.863 --> 00:00:48.110
și dintr-o dată plăcinta de mere
a căzut pe locul 4 sau 5.

00:00:48.110 --> 00:00:50.905
De ce? Ce s-a întâmplat?

00:00:50.905 --> 00:00:53.833
Ia să ne gândim.

00:00:53.833 --> 00:00:57.571
Când cumpărăm o plăcintă de 30 cm

00:00:57.571 --> 00:00:59.962
toată familia trebuie să fie de acord,

00:00:59.962 --> 00:01:03.873
iar plăcinta de mere 
e a doua preferință a tuturor.

00:01:03.873 --> 00:01:05.558
(Râsete)

00:01:05.558 --> 00:01:09.383
Dar când iei o plăcintă
personală, de 11 cm,

00:01:09.383 --> 00:01:13.048
poți s-o iei pe cea pe care ți-o dorești.

00:01:13.048 --> 00:01:16.933
Poți să-ți alegi prima preferință.

00:01:16.933 --> 00:01:18.864
Avem mai multe date.

00:01:18.864 --> 00:01:24.258
Vedem ceva ce nu puteam vedea
când aveam cantități mai mici de date.

00:01:25.248 --> 00:01:27.778
Dar ideea e că datele mai multe

00:01:27.778 --> 00:01:32.081
nu ne permit doar să vedem mai mult,
mai mult din același lucru.

00:01:32.081 --> 00:01:35.438
Datele mai multe ne permit
să vedem ceva nou.

00:01:35.438 --> 00:01:38.532
Ne permit să vedem mai bine.

00:01:38.532 --> 00:01:42.188
Ne permit să vedem altfel.

00:01:42.188 --> 00:01:45.361
În cazul de faţă ne permit să vedem

00:01:45.361 --> 00:01:48.274
care e plăcinta preferată a Americii:

00:01:48.274 --> 00:01:50.816
nu cea de mere.

00:01:50.816 --> 00:01:54.310
Probabil toată lumea a auzit
termenul „date masive”.

00:01:54.310 --> 00:01:58.137
De fapt probabil vi s-a făcut acru
tot auzind „date masive”.

00:01:58.137 --> 00:02:03.897
E adevărat că se face mult tam-tam
pe seama termenului și e mare păcat,

00:02:03.897 --> 00:02:06.955
pentru că datele masive sunt 
o unealtă foarte importantă

00:02:06.955 --> 00:02:10.729
prin care va avansa societatea.

00:02:10.729 --> 00:02:14.120
În trecut ne uitam la date puține

00:02:14.120 --> 00:02:17.374
și ne întrebam cum am putea
încerca să înțelegem lumea,

00:02:17.374 --> 00:02:22.621
iar acum avem mult mai multe,
mai multe decât era posibil înainte.

00:02:22.621 --> 00:02:26.990
Constatăm că având o colecție mare de date
putem face lucruri

00:02:26.990 --> 00:02:29.910
imposibil de realizat cu date puține.

00:02:29.910 --> 00:02:32.601
Datele masive sunt importante și sunt noi.

00:02:32.601 --> 00:02:34.428
Dacă ne gândim bine,

00:02:34.428 --> 00:02:38.354
singurul mod în care planeta
va face față problemelor globale

00:02:38.354 --> 00:02:41.870
— hrănirea populației,
furnizarea serviciilor medicale,

00:02:41.870 --> 00:02:44.680
alimentarea cu energie, electricitate,

00:02:44.680 --> 00:02:48.039
și cum facem să nu ne rumenim
cu încălzirea globală —

00:02:48.039 --> 00:02:51.902
e prin folosirea eficientă a datelor.

00:02:51.902 --> 00:02:56.342
Dar ce e nou în datele masive?
Care e marea scofală?

00:02:56.342 --> 00:03:03.259
Pentru a răspunde, să ne amintim
cum arătau informațiile efectiv în trecut.

00:03:04.239 --> 00:03:07.050
În 1908, pe insula Creta,

00:03:07.050 --> 00:03:11.855
arheologii au descoperit un disc de lut.

00:03:11.855 --> 00:03:16.124
L-au datat în 2000 î.Hr.,
deci e vechi de 4000 ani.

00:03:16.124 --> 00:03:20.168
Discul are inscripții, dar nu știm
ce înseamnă, e un mister complet.

00:03:20.168 --> 00:03:25.240
Dar ideea e că așa arătau informațiile
acum 4000 ani.

00:03:25.240 --> 00:03:31.368
Așa proceda societatea pentru a păstra
și transmite informațiile.

00:03:31.368 --> 00:03:35.612
Dar societatea nu a avansat așa de mult.

00:03:35.612 --> 00:03:38.876
Încă mai păstrăm informații pe discuri,

00:03:38.876 --> 00:03:43.370
dar acum putem stoca
mult mai multe informații decât oricând.

00:03:43.370 --> 00:03:46.433
Căutarea e mai ușoară. 
Copierea e mai ușoară.

00:03:46.433 --> 00:03:49.953
Distribuirea e mai ușoară.
Prelucrarea e mai ușoară.

00:03:49.953 --> 00:03:52.829
Și putem refolosi aceste informații

00:03:52.829 --> 00:03:57.623
în moduri pe care nu ni le-am închipuit
când am colectat datele.

00:03:57.623 --> 00:04:03.470
În această privință datele au trecut
de la a fi păstrate la a fi circulate,

00:04:03.470 --> 00:04:07.330
de la ceva staționar și static

00:04:07.330 --> 00:04:10.839
la ceva fluid și dinamic.

00:04:10.839 --> 00:04:15.572
Ca să zic așa,
informațiile au o lichiditate.

00:04:15.572 --> 00:04:20.180
Discul descoperit în Creta
și vechi de 4000 ani

00:04:20.180 --> 00:04:24.162
e greu, nu stochează multe informații.

00:04:24.162 --> 00:04:27.278
Iar acele informații nu pot fi schimbate.

00:04:27.278 --> 00:04:31.429
Pe de altă parte, toate documentele

00:04:31.429 --> 00:04:35.940
pe care le-a luat Edward Snowden de la
Agenția de Securitate Națională din SUA

00:04:35.940 --> 00:04:40.970
încap pe un stick de memorie
de mărimea unei unghii,

00:04:40.970 --> 00:04:44.975
și se pot transmite cu viteza luminii.

00:04:46.425 --> 00:04:49.730
Mai multe date. Mai multe.

00:04:51.200 --> 00:04:54.714
Un motiv pentru care azi lumea are
atâtea date e că adunăm lucruri

00:04:54.714 --> 00:04:58.116
despre care dintotdeauna
am adunat informații.

00:04:58.116 --> 00:05:03.382
Dar un alt motiv e că luăm lucruri
care au fost mereu informaționale,

00:05:03.382 --> 00:05:08.310
dar n-au mai fost puse sub formă de date,
și le transformăm în date.

00:05:08.310 --> 00:05:11.887
Gândiți-vă de exemplu
la problema localizării.

00:05:11.887 --> 00:05:13.816
Să-l luăm pe Martin Luther.

00:05:13.816 --> 00:05:18.123
Dacă voiam să știm, în anii 1500,
unde se află Martin Luther,

00:05:18.123 --> 00:05:24.012
trebuia să-l urmăm peste tot,
poate cu pană și cerneală, ca să notăm.

00:05:24.012 --> 00:05:26.218
Dar acum gândiți-vă cum e azi.

00:05:26.218 --> 00:05:30.930
Știți că undeva, printr-o bază de date
a unui furnizor de telecomunicații,

00:05:30.930 --> 00:05:33.952
e un tabel sau cel puțin o înscriere

00:05:33.952 --> 00:05:37.920
care înregistrează informații despre noi,
unde am fost în fiecare moment.

00:05:37.920 --> 00:05:42.293
Dacă aveți un telefon mobil cu GPS,
dar chiar dacă nu are GPS,

00:05:42.293 --> 00:05:44.515
vă poate memora informațiile.

00:05:44.515 --> 00:05:48.599
În această privință
localizarea a fost „datificată”.

00:05:48.599 --> 00:05:53.200
Acum gândiți-vă de exemplu
la problema posturii,

00:05:53.200 --> 00:05:55.345
cum stați așezați,

00:05:55.345 --> 00:05:56.745
cum stați dv.

00:05:56.745 --> 00:05:59.206
sau cum stați dv. sau dv.

00:05:59.206 --> 00:06:03.983
Diferă în funcție de lungimea piciorului,
de spate și de conturul spatelui.

00:06:03.983 --> 00:06:07.777
Dacă aș pune sensori, să zicem
100 de sensori, în scaunele tuturor,

00:06:07.777 --> 00:06:11.403
aș putea crea un index
unic pentru fiecare.

00:06:11.403 --> 00:06:15.762
Ca o amprentă, dar nu a degetului.

00:06:15.762 --> 00:06:18.731
Și la ce am putea s-o folosim?

00:06:18.731 --> 00:06:25.548
Unii cercetători din Tokio o folosesc
ca posibil sistem antifurt pentru mașini.

00:06:25.548 --> 00:06:29.460
Ideea e că hoțul stă la volan,
încearcă să pornească,

00:06:29.460 --> 00:06:32.934
dar mașina recunoaște
că la volan e un șofer neautorizat

00:06:32.934 --> 00:06:38.340
și atunci de exemplu se oprește motorul
dacă nu tastezi o parolă în sistem

00:06:38.340 --> 00:06:40.972
ca să-i spui:
„Hei, sunt autorizat să conduc.”

00:06:40.972 --> 00:06:42.754
Grozav.

00:06:43.084 --> 00:06:47.148
Ce-ar fi dacă toate mașinile din Europa
ar folosi această tehnologie?

00:06:47.148 --> 00:06:50.080
Ce am putea face atunci?

00:06:50.080 --> 00:06:54.430
Dacă punem datele cap la cap
poate reușim să identificăm

00:06:54.430 --> 00:06:58.134
semnele distinctive care să prezică optim

00:06:58.134 --> 00:07:01.163
că se va produce un accident de mașină

00:07:01.163 --> 00:07:05.106
în următoarele cinci secunde.

00:07:05.106 --> 00:07:09.123
Astfel s-ar datifica oboseala șoferului.

00:07:09.123 --> 00:07:15.260
Iar utilitatea apare când mașina simte
că persoana cade în poziția aceea

00:07:15.260 --> 00:07:18.841
și știe automat să pornească
o alarmă internă,

00:07:18.841 --> 00:07:21.916
să vibreze volanul
sau să claxoneze înăuntru, să spună:

00:07:21.916 --> 00:07:24.757
„Trezește-te, fii mai atent la drum!”

00:07:24.757 --> 00:07:29.704
Astfel de lucruri putem face 
datificând mai multe aspecte ale vieții.

00:07:29.704 --> 00:07:33.010
Deci ce valoare au datele masive?

00:07:34.140 --> 00:07:37.450
Ia gândiți-vă.
Avem mai multe informații.

00:07:37.450 --> 00:07:40.783
Putem face lucruri pe care
nu le puteam face înainte.

00:07:40.783 --> 00:07:44.599
Una din aplicațiile impresionante
ale acestei noțiuni

00:07:44.599 --> 00:07:47.565
e în domeniul învățării automate.

00:07:47.565 --> 00:07:51.032
Învățarea automată e o ramură 
a inteligenței artificiale

00:07:51.032 --> 00:07:53.950
care ea însăși e o ramură a informaticii.

00:07:53.950 --> 00:07:57.633
Pe scurt, în loc să instruim 
un calculator ce să facă,

00:07:57.633 --> 00:08:00.230
bombardăm problema cu informații

00:08:00.230 --> 00:08:03.436
și-i cerem calculatorului
să descopere singur.

00:08:03.436 --> 00:08:08.783
Veți înțelege mai bine
dacă veți vedea începuturile.

00:08:08.783 --> 00:08:13.053
În anii 1950, un informatician de la IBM
pe nume Arthur Samuel,

00:08:13.053 --> 00:08:14.965
căruia îi plăcea să joace dame,

00:08:14.965 --> 00:08:18.997
a scris un program pentru a putea juca
împotriva calculatorului.

00:08:18.997 --> 00:08:21.421
A jucat. A câștigat.

00:08:21.671 --> 00:08:23.514
A jucat. A câștigat.

00:08:23.774 --> 00:08:25.869
A jucat. A câștigat.

00:08:26.849 --> 00:08:30.827
Pentru că tot ce știa calculatorul
erau mutările permise.

00:08:30.827 --> 00:08:32.951
Arthur Samuel mai știa altceva.

00:08:32.951 --> 00:08:35.749
Arthur Samuel mai știa

00:08:35.749 --> 00:08:37.587
și strategie.

00:08:37.587 --> 00:08:41.276
Atunci a adăugat un mic sub-program
care să opereze în fundal.

00:08:41.276 --> 00:08:45.670
Tot ce făcea era să calculeze
probabilitatea ca o configurație dată

00:08:45.670 --> 00:08:49.280
să conducă la o tablă de joc
câștigătoare sau necâștigătoare

00:08:49.280 --> 00:08:51.188
după fiecare mutare.

00:08:51.678 --> 00:08:54.588
Joacă cu calculatorul. Câștigă.

00:08:54.828 --> 00:08:57.076
Joacă cu calculatorul. Câștigă.

00:08:57.336 --> 00:09:00.107
Joacă cu calculatorul. Câștigă.

00:09:01.067 --> 00:09:06.024
Atunci Arthur Samuel
lasă calculatorul să joace singur.

00:09:06.024 --> 00:09:09.080
Joacă singur, adună mai multe date.

00:09:09.080 --> 00:09:13.389
Adună mai multe date,
îi crește precizia predicției.

00:09:13.389 --> 00:09:17.903
Atunci Arthur Samuel se întoarce
la calculator și joacă cu el, și pierde.

00:09:17.903 --> 00:09:19.770
Și joacă, și pierde.

00:09:20.020 --> 00:09:21.737
Și joacă, și pierde.

00:09:21.977 --> 00:09:24.526
Și Arthur Samuel a creat o mașină

00:09:24.526 --> 00:09:29.834
care îl depășește la o sarcină
în care el a inițiat-o.

00:09:30.814 --> 00:09:36.282
Această idee de învățare automată
se răspândește peste tot.

00:09:37.269 --> 00:09:40.698
Cum credeți că avem mașini 
care se conduc singure?

00:09:40.698 --> 00:09:45.835
E societatea mai capabilă să pună
toate regulile rutiere într-un software?

00:09:45.835 --> 00:09:46.807
Nu.

00:09:46.807 --> 00:09:48.477
E mai ieftină memoria? Nu.

00:09:48.477 --> 00:09:50.069
Sunt mai rapizi algoritmii? Nu.

00:09:50.069 --> 00:09:52.541
Sunt mai bune procesoarele? Nu.

00:09:52.541 --> 00:09:55.174
Toate astea contează, 
dar nu sunt ele motivul.

00:09:55.174 --> 00:09:58.315
Motivul e că am schimbat natura problemei.

00:09:58.315 --> 00:10:04.615
Am trecut de la a-i spune deschis
și explicit calculatorului cum să conducă

00:10:04.615 --> 00:10:06.037
la a-i spune:

00:10:06.037 --> 00:10:09.423
„Iată o mulțime de date despre vehicul.
Descurcă-te.

00:10:09.423 --> 00:10:13.293
Prinde-te singur că ăla e un semafor,
că semaforul e roșu și nu verde,

00:10:13.293 --> 00:10:18.458
că asta înseamnă să te oprești
și nu să continui”.

00:10:18.458 --> 00:10:21.949
Învățarea automată e la baza
multor lucruri pe care le facem online:

00:10:21.950 --> 00:10:23.807
motoare de căutare,

00:10:23.807 --> 00:10:27.608
algoritmul de personalizare de la Amazon,

00:10:27.608 --> 00:10:29.880
traduceri computerizate,

00:10:29.880 --> 00:10:34.110
sisteme de recunoaștere a vocii.

00:10:34.110 --> 00:10:40.145
Cercetătorii s-au interesat recent
de problema biopsiilor,

00:10:40.145 --> 00:10:42.907
a biopsiilor de cancer.

00:10:42.907 --> 00:10:45.222
Au cerut calculatorului să identifice,

00:10:45.222 --> 00:10:48.413
analizând datele
și procentajul de supraviețuire,

00:10:48.413 --> 00:10:52.910
să determine dacă într-adevăr celulele

00:10:52.910 --> 00:10:54.904
sunt canceroase sau nu.

00:10:54.904 --> 00:10:58.592
Și bineînțeles, folosind date
și un algoritm de învățare automată,

00:10:58.592 --> 00:11:03.096
mașina a reușit să identifice
cele 12 semne tipice care prezic optim

00:11:03.096 --> 00:11:09.407
că biopsia unor celule canceroase
de sân e într-adevăr canceroasă.

00:11:09.407 --> 00:11:11.193
Problema?

00:11:11.193 --> 00:11:14.672
Literatura medicală cunoștea
numai nouă dintre ele.

00:11:14.672 --> 00:11:19.422
Trei caracteristici nu erau
între cele care trebuiau verificate,

00:11:19.422 --> 00:11:22.918
dar mașina le-a detectat.

00:11:26.118 --> 00:11:30.903
Datele masive au și părți negative.

00:11:30.903 --> 00:11:35.647
Ne vor îmbunătăți viața, dar sunt probleme
de care trebuie să fim conștienți.

00:11:35.647 --> 00:11:38.120
Prima e ideea

00:11:38.120 --> 00:11:40.926
că s-ar putea să fim
pedepsiți pentru predicții,

00:11:40.926 --> 00:11:45.146
că poliția ar putea folosi datele masive
pentru propriile scopuri,

00:11:45.146 --> 00:11:47.617
ca în filmul „Raport Special”.

00:11:47.617 --> 00:11:51.978
Se numește „poliție preventivă”
sau „criminologie algoritmică”,

00:11:51.978 --> 00:11:56.247
iar ideea e că folosind multe date,
de exemplu locul crimelor trecute,

00:11:56.247 --> 00:11:58.689
știm unde să trimitem patrulele.

00:11:58.689 --> 00:12:05.374
Are logică, dar desigur problema
e că nu se va limita la localizare,

00:12:05.374 --> 00:12:08.307
ci va ajunge la nivelul individului.

00:12:08.307 --> 00:12:12.807
De ce să nu folosim date 
din foaia matricolă de liceu?

00:12:12.807 --> 00:12:16.396
Poate ar trebui să ținem cont
dacă sunt șomeri, ce risc de credit au,

00:12:16.396 --> 00:12:19.816
ce comportament au pe internet,
dacă se culcă noaptea târziu.

00:12:19.816 --> 00:12:27.125
Fitbitul lor, când va decela biochimia,
va arăta că au gânduri agresive.

00:12:27.125 --> 00:12:31.072
Poate vom avea algoritmi care să prezică
ce avem de gând să facem

00:12:31.072 --> 00:12:34.909
și poate vom fi trași la răspundere
înainte de a face ceva.

00:12:34.909 --> 00:12:39.531
Intimitatea era problema centrală
în epoca datelor puține.

00:12:39.531 --> 00:12:43.740
În epoca datelor masive problema va fi

00:12:43.740 --> 00:12:46.373
de a proteja liberul arbitru,

00:12:46.373 --> 00:12:48.275
alegerea morală,

00:12:48.275 --> 00:12:49.947
voința umană,

00:12:49.947 --> 00:12:52.660
factorul uman.

00:12:54.600 --> 00:12:57.005
Mai e o problemă.

00:12:57.005 --> 00:13:00.321
Datele masive ne vor fura
locurile de muncă.

00:13:00.321 --> 00:13:04.053
Datele masive și algoritmii
vor pune la încercare

00:13:04.053 --> 00:13:08.404
munca funcționarilor
și a profesioniștilor în secolul XXI

00:13:08.404 --> 00:13:13.201
așa cum automatizarea fabricilor
și linia de asamblare

00:13:13.201 --> 00:13:16.196
au pus la încercare
muncitorimea în secolul XX.

00:13:16.196 --> 00:13:18.288
Să luăm un laborant

00:13:18.288 --> 00:13:21.337
care se uită cu microscopul
la o biopsie de cancer

00:13:21.337 --> 00:13:23.958
să vadă dacă e canceroasă sau nu.

00:13:23.958 --> 00:13:26.030
Omul a fost la facultate.

00:13:26.030 --> 00:13:27.560
Cumpără proprietate.

00:13:27.560 --> 00:13:29.271
Votează.

00:13:29.271 --> 00:13:32.767
E acționar în societate.

00:13:32.767 --> 00:13:37.751
Omul acesta și o întreagă armată
de profesioniști ca el

00:13:37.751 --> 00:13:43.379
își vor găsi slujbele schimbate radical
sau chiar complet eliminate.

00:13:43.379 --> 00:13:47.730
Ne place să credem că tehnologia
creează slujbe pentru o vreme

00:13:47.730 --> 00:13:51.332
după o perioadă scurtă de dislocare.

00:13:51.332 --> 00:13:55.263
E adevărat în sistemul de referință
cu care trăim: revoluția industrială.

00:13:55.263 --> 00:13:57.593
Pentru că exact așa s-a întâmplat.

00:13:57.593 --> 00:14:00.346
Dar uităm ceva în analiza aceasta:

00:14:00.346 --> 00:14:05.196
anumite categorii de locuri de muncă
sunt eliminate total și nu se mai întorc.

00:14:05.196 --> 00:14:10.230
Revoluția industrială
nu prea a fost bună dacă erai un cal.

00:14:11.210 --> 00:14:13.697
Deci va trebui să avem grijă,

00:14:13.697 --> 00:14:16.951
să luăm datele masive 
și să le adaptăm la nevoile noastre,

00:14:16.951 --> 00:14:19.866
la nevoile noastre foarte omenești.

00:14:19.866 --> 00:14:23.520
Trebuie să fim stăpânul tehnologiei,
nu servitorul ei.

00:14:23.520 --> 00:14:26.504
Era datelor masive abia acum începe

00:14:26.504 --> 00:14:33.884
și, sincer, nu prea ne descurcăm
cu datele pe care le putem colecta acum.

00:14:33.884 --> 00:14:37.261
Nu e doar o problemă pentru
Agenția de Securitate Națională.

00:14:37.261 --> 00:14:40.229
Firmele adună o mulțime de date
și mai abuzează de ele.

00:14:40.229 --> 00:14:43.896
Trebuie să avansăm, iar asta durează.

00:14:43.896 --> 00:14:48.138
E cam ca problema pe care o avea
omul primitiv cu focul.

00:14:48.138 --> 00:14:53.930
E o unealtă, dar e o unealtă care,
dacă nu suntem atenți, ne va arde.

00:14:56.008 --> 00:15:01.958
Datele masive ne vor transforma
viața, munca și gândirea.

00:15:01.958 --> 00:15:06.288
Ne vor ajuta să ne ocupăm de cariere
și să trăim o viață plină de satisfacții,

00:15:06.288 --> 00:15:10.482
de speranță, de fericire și de sănătate.

00:15:10.482 --> 00:15:13.750
Dar în trecut ne-am uitat adesea
la tehnologia informației

00:15:13.750 --> 00:15:17.618
și ochii noștri au văzut doar T-ul,
tehnologia, hardware-ul,

00:15:17.618 --> 00:15:19.906
pentru că asta era partea fizică.

00:15:19.906 --> 00:15:25.590
Acum trebuie să ne aruncăm privirea pe I,
informația, care e mai puțin vizibilă,

00:15:25.590 --> 00:15:29.692
dar în unele privințe mult mai importantă.

00:15:29.692 --> 00:15:35.597
Omenirea poate în sfârșit învăța 
din informațiile pe care le poate colecta,

00:15:35.597 --> 00:15:40.960
în încercarea noastră dintotdeauna
de a înțelege lumea și locul nostru în ea.

00:15:40.960 --> 00:15:46.480
De aceea datele masive
sunt mare scofală.

00:15:46.480 --> 00:15:50.048
(Aplauze)

