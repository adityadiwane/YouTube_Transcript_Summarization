WEBVTT
Kind: captions
Language: en

00:00:12.787 --> 00:00:16.632
America's favorite pie is?

00:00:16.632 --> 00:00:20.138
Audience: Apple.
Kenneth Cukier: Apple. Of course it is.

00:00:20.138 --> 00:00:21.369
How do we know it?

00:00:21.369 --> 00:00:24.122
Because of data.

00:00:24.122 --> 00:00:26.188
You look at supermarket sales.

00:00:26.188 --> 00:00:29.054
You look at supermarket
sales of 30-centimeter pies

00:00:29.054 --> 00:00:33.129
that are frozen, and apple wins, no contest.

00:00:33.129 --> 00:00:38.309
The majority of the sales are apple.

00:00:38.309 --> 00:00:41.273
But then supermarkets started selling

00:00:41.273 --> 00:00:43.856
smaller, 11-centimeter pies,

00:00:43.856 --> 00:00:48.030
and suddenly, apple fell to fourth or fifth place.

00:00:48.030 --> 00:00:50.905
Why? What happened?

00:00:50.905 --> 00:00:53.723
Okay, think about it.

00:00:53.723 --> 00:00:57.571
When you buy a 30-centimeter pie,

00:00:57.571 --> 00:00:59.832
the whole family has to agree,

00:00:59.832 --> 00:01:03.623
and apple is everyone's second favorite.

00:01:03.623 --> 00:01:05.558
(Laughter)

00:01:05.558 --> 00:01:09.173
But when you buy an individual 11-centimeter pie,

00:01:09.173 --> 00:01:12.918
you can buy the one that you want.

00:01:12.918 --> 00:01:16.933
You can get your first choice.

00:01:16.933 --> 00:01:18.574
You have more data.

00:01:18.574 --> 00:01:20.128
You can see something

00:01:20.128 --> 00:01:21.260
that you couldn't see

00:01:21.260 --> 00:01:25.213
when you only had smaller amounts of it.

00:01:25.213 --> 00:01:27.688
Now, the point here is that more data

00:01:27.688 --> 00:01:29.971
doesn't just let us see more,

00:01:29.971 --> 00:01:31.825
more of the same thing we were looking at.

00:01:31.825 --> 00:01:35.438
More data allows us to see new.

00:01:35.438 --> 00:01:38.532
It allows us to see better.

00:01:38.532 --> 00:01:42.188
It allows us to see different.

00:01:42.188 --> 00:01:45.361
In this case, it allows us to see

00:01:45.361 --> 00:01:48.274
what America's favorite pie is:

00:01:48.274 --> 00:01:50.816
not apple.

00:01:50.816 --> 00:01:54.430
Now, you probably all have heard the term big data.

00:01:54.430 --> 00:01:56.487
In fact, you're probably sick of hearing the term

00:01:56.487 --> 00:01:58.117
big data.

00:01:58.117 --> 00:02:01.447
It is true that there is a lot of hype around the term,

00:02:01.447 --> 00:02:03.779
and that is very unfortunate,

00:02:03.779 --> 00:02:06.825
because big data is an extremely important tool

00:02:06.825 --> 00:02:10.559
by which society is going to advance.

00:02:10.559 --> 00:02:14.120
In the past, we used to look at small data

00:02:14.120 --> 00:02:15.824
and think about what it would mean

00:02:15.824 --> 00:02:17.320
to try to understand the world,

00:02:17.320 --> 00:02:19.311
and now we have a lot more of it,

00:02:19.311 --> 00:02:22.033
more than we ever could before.

00:02:22.033 --> 00:02:23.910
What we find is that when we have

00:02:23.910 --> 00:02:26.634
a large body of data, we can fundamentally do things

00:02:26.634 --> 00:02:29.910
that we couldn't do when we
only had smaller amounts.

00:02:29.910 --> 00:02:32.551
Big data is important, and big data is new,

00:02:32.551 --> 00:02:34.328
and when you think about it,

00:02:34.328 --> 00:02:36.544
the only way this planet is going to deal

00:02:36.544 --> 00:02:38.333
with its global challenges —

00:02:38.333 --> 00:02:41.870
to feed people, supply them with medical care,

00:02:41.870 --> 00:02:44.680
supply them with energy, electricity,

00:02:44.680 --> 00:02:46.469
and to make sure they're not burnt to a crisp

00:02:46.469 --> 00:02:47.707
because of global warming —

00:02:47.707 --> 00:02:51.902
is because of the effective use of data.

00:02:51.902 --> 00:02:55.772
So what is new about big 
data? What is the big deal?

00:02:55.772 --> 00:02:58.289
Well, to answer that question, let's think about

00:02:58.289 --> 00:03:00.185
what information looked like,

00:03:00.185 --> 00:03:03.219
physically looked like in the past.

00:03:03.219 --> 00:03:06.830
In 1908, on the island of Crete,

00:03:06.830 --> 00:03:11.565
archaeologists discovered a clay disc.

00:03:11.565 --> 00:03:15.624
They dated it from 2000 B.C., so it's 4,000 years old.

00:03:15.624 --> 00:03:17.628
Now, there's inscriptions on this disc,

00:03:17.628 --> 00:03:18.955
but we actually don't know what it means.

00:03:18.955 --> 00:03:21.053
It's a complete mystery, but the point is that

00:03:21.053 --> 00:03:22.981
this is what information used to look like

00:03:22.981 --> 00:03:25.070
4,000 years ago.

00:03:25.070 --> 00:03:27.618
This is how society stored

00:03:27.618 --> 00:03:31.142
and transmitted information.

00:03:31.142 --> 00:03:35.302
Now, society hasn't advanced all that much.

00:03:35.302 --> 00:03:38.776
We still store information on discs,

00:03:38.776 --> 00:03:41.960
but now we can store a lot more information,

00:03:41.960 --> 00:03:43.220
more than ever before.

00:03:43.220 --> 00:03:46.313
Searching it is easier. Copying it easier.

00:03:46.313 --> 00:03:49.813
Sharing it is easier. Processing it is easier.

00:03:49.813 --> 00:03:52.579
And what we can do is we can reuse this information

00:03:52.579 --> 00:03:54.413
for uses that we never even imagined

00:03:54.413 --> 00:03:57.608
when we first collected the data.

00:03:57.608 --> 00:03:59.860
In this respect, the data has gone

00:03:59.860 --> 00:04:03.392
from a stock to a flow,

00:04:03.392 --> 00:04:07.330
from something that is stationary and static

00:04:07.330 --> 00:04:10.939
to something that is fluid and dynamic.

00:04:10.939 --> 00:04:14.962
There is, if you will, a liquidity to information.

00:04:14.962 --> 00:04:18.436
The disc that was discovered off of Crete

00:04:18.436 --> 00:04:22.200
that's 4,000 years old, is heavy,

00:04:22.200 --> 00:04:24.162
it doesn't store a lot of information,

00:04:24.162 --> 00:04:27.278
and that information is unchangeable.

00:04:27.278 --> 00:04:31.289
By contrast, all of the files

00:04:31.289 --> 00:04:33.150
that Edward Snowden took

00:04:33.150 --> 00:04:35.771
from the National Security
Agency in the United States

00:04:35.771 --> 00:04:38.190
fits on a memory stick

00:04:38.190 --> 00:04:41.200
the size of a fingernail,

00:04:41.200 --> 00:04:45.945
and it can be shared at the speed of light.

00:04:45.945 --> 00:04:51.200
More data. More.

00:04:51.200 --> 00:04:53.174
Now, one reason why we have
so much data in the world today

00:04:53.174 --> 00:04:54.606
is we are collecting things

00:04:54.606 --> 00:04:57.886
that we've always collected information on,

00:04:57.886 --> 00:05:00.542
but another reason why is we're taking things

00:05:00.542 --> 00:05:03.354
that have always been informational

00:05:03.354 --> 00:05:05.840
but have never been rendered into a data format

00:05:05.840 --> 00:05:08.259
and we are putting it into data.

00:05:08.259 --> 00:05:11.567
Think, for example, the question of location.

00:05:11.567 --> 00:05:13.816
Take, for example, Martin Luther.

00:05:13.816 --> 00:05:15.413
If we wanted to know in the 1500s

00:05:15.413 --> 00:05:18.080
where Martin Luther was,

00:05:18.080 --> 00:05:20.172
we would have to follow him at all times,

00:05:20.172 --> 00:05:22.309
maybe with a feathery quill and an inkwell,

00:05:22.309 --> 00:05:23.985
and record it,

00:05:23.985 --> 00:05:26.168
but now think about what it looks like today.

00:05:26.168 --> 00:05:28.290
You know that somewhere,

00:05:28.290 --> 00:05:30.736
probably in a telecommunications carrier's database,

00:05:30.736 --> 00:05:33.772
there is a spreadsheet or at least a database entry

00:05:33.772 --> 00:05:35.860
that records your information

00:05:35.860 --> 00:05:37.923
of where you've been at all times.

00:05:37.923 --> 00:05:39.283
If you have a cell phone,

00:05:39.283 --> 00:05:42.130
and that cell phone has GPS,
but even if it doesn't have GPS,

00:05:42.130 --> 00:05:44.515
it can record your information.

00:05:44.515 --> 00:05:48.599
In this respect, location has been datafied.

00:05:48.599 --> 00:05:53.200
Now think, for example, of the issue of posture,

00:05:53.200 --> 00:05:54.485
the way that you are all sitting right now,

00:05:54.485 --> 00:05:56.515
the way that you sit,

00:05:56.515 --> 00:05:59.286
the way that you sit, the way that you sit.

00:05:59.286 --> 00:06:01.363
It's all different, and it's a function of your leg length

00:06:01.363 --> 00:06:03.456
and your back and the contours of your back,

00:06:03.456 --> 00:06:05.987
and if I were to put sensors, 
maybe 100 sensors

00:06:05.987 --> 00:06:07.753
into all of your chairs right now,

00:06:07.753 --> 00:06:11.353
I could create an index that's fairly unique to you,

00:06:11.353 --> 00:06:15.762
sort of like a fingerprint, but it's not your finger.

00:06:15.762 --> 00:06:18.731
So what could we do with this?

00:06:18.731 --> 00:06:21.128
Researchers in Tokyo are using it

00:06:21.128 --> 00:06:25.516
as a potential anti-theft device in cars.

00:06:25.516 --> 00:06:28.440
The idea is that the carjacker sits behind the wheel,

00:06:28.440 --> 00:06:30.544
tries to stream off, but the car recognizes

00:06:30.544 --> 00:06:32.906
that a non-approved driver is behind the wheel,

00:06:32.906 --> 00:06:35.070
and maybe the engine just stops, unless you

00:06:35.070 --> 00:06:38.247
type in a password into the dashboard

00:06:38.247 --> 00:06:42.905
to say, "Hey, I have authorization to drive." Great.

00:06:42.905 --> 00:06:45.458
What if every single car in Europe

00:06:45.458 --> 00:06:46.915
had this technology in it?

00:06:46.915 --> 00:06:50.080
What could we do then?

00:06:50.080 --> 00:06:52.320
Maybe, if we aggregated the data,

00:06:52.320 --> 00:06:56.134
maybe we could identify telltale signs

00:06:56.134 --> 00:06:58.843
that best predict that a car accident

00:06:58.843 --> 00:07:04.736
is going to take place in the next five seconds.

00:07:04.736 --> 00:07:07.293
And then what we will have datafied

00:07:07.293 --> 00:07:09.076
is driver fatigue,

00:07:09.076 --> 00:07:11.410
and the service would be when the car senses

00:07:11.410 --> 00:07:14.847
that the person slumps into that position,

00:07:14.847 --> 00:07:18.841
automatically knows, hey, set an internal alarm

00:07:18.841 --> 00:07:20.866
that would vibrate the steering wheel, honk inside

00:07:20.866 --> 00:07:22.587
to say, "Hey, wake up,

00:07:22.587 --> 00:07:24.491
pay more attention to the road."

00:07:24.491 --> 00:07:26.344
These are the sorts of things we can do

00:07:26.344 --> 00:07:29.165
when we datafy more aspects of our lives.

00:07:29.165 --> 00:07:32.840
So what is the value of big data?

00:07:32.840 --> 00:07:35.030
Well, think about it.

00:07:35.030 --> 00:07:37.442
You have more information.

00:07:37.442 --> 00:07:40.783
You can do things that you couldn't do before.

00:07:40.783 --> 00:07:42.459
One of the most impressive areas

00:07:42.459 --> 00:07:44.188
where this concept is taking place

00:07:44.188 --> 00:07:47.495
is in the area of machine learning.

00:07:47.495 --> 00:07:50.572
Machine learning is a branch of artificial intelligence,

00:07:50.572 --> 00:07:53.950
which itself is a branch of computer science.

00:07:53.950 --> 00:07:55.493
The general idea is that instead of

00:07:55.493 --> 00:07:57.610
instructing a computer what do do,

00:07:57.610 --> 00:08:00.230
we are going to simply throw data at the problem

00:08:00.230 --> 00:08:03.436
and tell the computer to figure it out for itself.

00:08:03.436 --> 00:08:05.213
And it will help you understand it

00:08:05.213 --> 00:08:08.765
by seeing its origins.

00:08:08.765 --> 00:08:11.153
In the 1950s, a computer scientist

00:08:11.153 --> 00:08:14.745
at IBM named Arthur Samuel liked to play checkers,

00:08:14.745 --> 00:08:16.147
so he wrote a computer program

00:08:16.147 --> 00:08:18.960
so he could play against the computer.

00:08:18.960 --> 00:08:21.671
He played. He won.

00:08:21.671 --> 00:08:23.774
He played. He won.

00:08:23.774 --> 00:08:26.789
He played. He won,

00:08:26.789 --> 00:08:28.567
because the computer only knew

00:08:28.567 --> 00:08:30.794
what a legal move was.

00:08:30.794 --> 00:08:32.881
Arthur Samuel knew something else.

00:08:32.881 --> 00:08:37.510
Arthur Samuel knew strategy.

00:08:37.510 --> 00:08:39.906
So he wrote a small sub-program alongside it

00:08:39.906 --> 00:08:41.880
operating in the background, and all it did

00:08:41.880 --> 00:08:43.697
was score the probability

00:08:43.697 --> 00:08:46.260
that a given board configuration would likely lead

00:08:46.260 --> 00:08:49.170
to a winning board versus a losing board

00:08:49.170 --> 00:08:51.678
after every move.

00:08:51.678 --> 00:08:54.828
He plays the computer. He wins.

00:08:54.828 --> 00:08:57.336
He plays the computer. He wins.

00:08:57.336 --> 00:09:01.067
He plays the computer. He wins.

00:09:01.067 --> 00:09:03.344
And then Arthur Samuel leaves the computer

00:09:03.344 --> 00:09:05.571
to play itself.

00:09:05.571 --> 00:09:09.080
It plays itself. It collects more data.

00:09:09.080 --> 00:09:13.389
It collects more data. It increases
the accuracy of its prediction.

00:09:13.389 --> 00:09:15.493
And then Arthur Samuel goes back to the computer

00:09:15.493 --> 00:09:17.811
and he plays it, and he loses,

00:09:17.811 --> 00:09:19.880
and he plays it, and he loses,

00:09:19.880 --> 00:09:21.927
and he plays it, and he loses,

00:09:21.927 --> 00:09:24.526
and Arthur Samuel has created a machine

00:09:24.526 --> 00:09:30.814
that surpasses his ability in a task that he taught it.

00:09:30.814 --> 00:09:33.312
And this idea of machine learning

00:09:33.312 --> 00:09:37.239
is going everywhere.

00:09:37.239 --> 00:09:40.388
How do you think we have self-driving cars?

00:09:40.388 --> 00:09:42.525
Are we any better off as a society

00:09:42.525 --> 00:09:45.810
enshrining all the rules of the road into software?

00:09:45.810 --> 00:09:48.408
No. Memory is cheaper. No.

00:09:48.408 --> 00:09:52.402
Algorithms are faster. No. Processors are better. No.

00:09:52.402 --> 00:09:55.174
All of those things matter, but that's not why.

00:09:55.174 --> 00:09:58.315
It's because we changed the nature of the problem.

00:09:58.315 --> 00:09:59.845
We changed the nature of the problem from one

00:09:59.845 --> 00:10:02.090
in which we tried to overtly and explicitly

00:10:02.090 --> 00:10:04.671
explain to the computer how to drive

00:10:04.671 --> 00:10:05.987
to one in which we say,

00:10:05.987 --> 00:10:07.863
"Here's a lot of data around the vehicle.

00:10:07.863 --> 00:10:09.396
You figure it out.

00:10:09.396 --> 00:10:11.263
You figure it out that that is a traffic light,

00:10:11.263 --> 00:10:13.344
that that traffic light is red and not green,

00:10:13.344 --> 00:10:15.358
that that means that you need to stop

00:10:15.358 --> 00:10:18.441
and not go forward."

00:10:18.441 --> 00:10:19.959
Machine learning is at the basis

00:10:19.959 --> 00:10:21.950
of many of the things that we do online:

00:10:21.950 --> 00:10:23.807
search engines,

00:10:23.807 --> 00:10:27.608
Amazon's personalization algorithm,

00:10:27.608 --> 00:10:29.820
computer translation,

00:10:29.820 --> 00:10:34.110
voice recognition systems.

00:10:34.110 --> 00:10:36.945
Researchers recently have looked at

00:10:36.945 --> 00:10:40.140
the question of biopsies,

00:10:40.140 --> 00:10:42.907
cancerous biopsies,

00:10:42.907 --> 00:10:45.222
and they've asked the computer to identify

00:10:45.222 --> 00:10:47.693
by looking at the data and survival rates

00:10:47.693 --> 00:10:52.360
to determine whether cells are actually

00:10:52.360 --> 00:10:54.904
cancerous or not,

00:10:54.904 --> 00:10:56.682
and sure enough, when you throw the data at it,

00:10:56.682 --> 00:10:58.729
through a machine-learning algorithm,

00:10:58.729 --> 00:11:00.606
the machine was able to identify

00:11:00.606 --> 00:11:02.868
the 12 telltale signs that best predict

00:11:02.868 --> 00:11:06.167
that this biopsy of the breast cancer cells

00:11:06.167 --> 00:11:09.385
are indeed cancerous.

00:11:09.385 --> 00:11:11.883
The problem: The medical literature

00:11:11.883 --> 00:11:14.672
only knew nine of them.

00:11:14.672 --> 00:11:16.472
Three of the traits were ones

00:11:16.472 --> 00:11:19.447
that people didn't need to look for,

00:11:19.447 --> 00:11:24.978
but that the machine spotted.

00:11:24.978 --> 00:11:30.903
Now, there are dark sides to big data as well.

00:11:30.903 --> 00:11:32.977
It will improve our lives, but there are problems

00:11:32.977 --> 00:11:35.617
that we need to be conscious of,

00:11:35.617 --> 00:11:38.240
and the first one is the idea

00:11:38.240 --> 00:11:40.926
that we may be punished for predictions,

00:11:40.926 --> 00:11:44.796
that the police may use big data for their purposes,

00:11:44.796 --> 00:11:47.147
a little bit like "Minority Report."

00:11:47.147 --> 00:11:49.588
Now, it's a term called predictive policing,

00:11:49.588 --> 00:11:51.951
or algorithmic criminology,

00:11:51.951 --> 00:11:53.987
and the idea is that if we take a lot of data,

00:11:53.987 --> 00:11:56.146
for example where past crimes have been,

00:11:56.146 --> 00:11:58.689
we know where to send the patrols.

00:11:58.689 --> 00:12:00.804
That makes sense, but the problem, of course,

00:12:00.804 --> 00:12:05.348
is that it's not simply going to stop on location data,

00:12:05.348 --> 00:12:08.307
it's going to go down to the level of the individual.

00:12:08.307 --> 00:12:10.557
Why don't we use data about the person's

00:12:10.557 --> 00:12:12.785
high school transcript?

00:12:12.785 --> 00:12:14.346
Maybe we should use the fact that

00:12:14.346 --> 00:12:16.374
they're unemployed or not, their credit score,

00:12:16.374 --> 00:12:17.926
their web-surfing behavior,

00:12:17.926 --> 00:12:19.804
whether they're up late at night.

00:12:19.804 --> 00:12:22.965
Their Fitbit, when it's able
to identify biochemistries,

00:12:22.965 --> 00:12:27.201
will show that they have aggressive thoughts.

00:12:27.201 --> 00:12:29.422
We may have algorithms that are likely to predict

00:12:29.422 --> 00:12:31.055
what we are about to do,

00:12:31.055 --> 00:12:32.299
and we may be held accountable

00:12:32.299 --> 00:12:34.889
before we've actually acted.

00:12:34.889 --> 00:12:36.621
Privacy was the central challenge

00:12:36.621 --> 00:12:39.501
in a small data era.

00:12:39.501 --> 00:12:41.650
In the big data age,

00:12:41.650 --> 00:12:46.173
the challenge will be safeguarding free will,

00:12:46.173 --> 00:12:49.952
moral choice, human volition,

00:12:49.952 --> 00:12:53.020
human agency.

00:12:54.540 --> 00:12:56.765
There is another problem:

00:12:56.765 --> 00:13:00.321
Big data is going to steal our jobs.

00:13:00.321 --> 00:13:03.833
Big data and algorithms are going to challenge

00:13:03.833 --> 00:13:06.894
white collar, professional knowledge work

00:13:06.894 --> 00:13:08.547
in the 21st century

00:13:08.547 --> 00:13:10.981
in the same way that factory automation

00:13:10.981 --> 00:13:13.170
and the assembly line

00:13:13.170 --> 00:13:16.196
challenged blue collar labor in the 20th century.

00:13:16.196 --> 00:13:18.288
Think about a lab technician

00:13:18.288 --> 00:13:19.697
who is looking through a microscope

00:13:19.697 --> 00:13:21.321
at a cancer biopsy

00:13:21.321 --> 00:13:23.958
and determining whether it's cancerous or not.

00:13:23.958 --> 00:13:25.930
The person went to university.

00:13:25.930 --> 00:13:27.360
The person buys property.

00:13:27.360 --> 00:13:29.101
He or she votes.

00:13:29.101 --> 00:13:32.767
He or she is a stakeholder in society.

00:13:32.767 --> 00:13:34.161
And that person's job,

00:13:34.161 --> 00:13:35.770
as well as an entire fleet

00:13:35.770 --> 00:13:37.739
of professionals like that person,

00:13:37.739 --> 00:13:40.889
is going to find that their jobs are radically changed

00:13:40.889 --> 00:13:43.246
or actually completely eliminated.

00:13:43.246 --> 00:13:44.530
Now, we like to think

00:13:44.530 --> 00:13:47.717
that technology creates jobs over a period of time

00:13:47.717 --> 00:13:51.182
after a short, temporary period of dislocation,

00:13:51.182 --> 00:13:53.123
and that is true for the frame of reference

00:13:53.123 --> 00:13:55.265
with which we all live, the Industrial Revolution,

00:13:55.265 --> 00:13:57.593
because that's precisely what happened.

00:13:57.593 --> 00:13:59.926
But we forget something in that analysis:

00:13:59.926 --> 00:14:01.756
There are some categories of jobs

00:14:01.756 --> 00:14:05.176
that simply get eliminated and never come back.

00:14:05.176 --> 00:14:07.180
The Industrial Revolution wasn't very good

00:14:07.180 --> 00:14:11.182
if you were a horse.

00:14:11.182 --> 00:14:13.237
So we're going to need to be careful

00:14:13.237 --> 00:14:16.751
and take big data and adjust it for our needs,

00:14:16.751 --> 00:14:19.936
our very human needs.

00:14:19.936 --> 00:14:21.890
We have to be the master of this technology,

00:14:21.890 --> 00:14:23.546
not its servant.

00:14:23.546 --> 00:14:26.504
We are just at the outset of the big data era,

00:14:26.504 --> 00:14:29.654
and honestly, we are not very good

00:14:29.654 --> 00:14:33.861
at handling all the data that we can now collect.

00:14:33.861 --> 00:14:37.191
It's not just a problem for
the National Security Agency.

00:14:37.191 --> 00:14:40.229
Businesses collect lots of
data, and they misuse it too,

00:14:40.229 --> 00:14:43.896
and we need to get better at
this, and this will take time.

00:14:43.896 --> 00:14:45.718
It's a little bit like the challenge that was faced

00:14:45.718 --> 00:14:48.125
by primitive man and fire.

00:14:48.125 --> 00:14:50.010
This is a tool, but this is a tool that,

00:14:50.010 --> 00:14:53.569
unless we're careful, will burn us.

00:14:56.008 --> 00:14:59.128
Big data is going to transform how we live,

00:14:59.128 --> 00:15:01.929
how we work and how we think.

00:15:01.929 --> 00:15:03.818
It is going to help us manage our careers

00:15:03.818 --> 00:15:07.452
and lead lives of satisfaction and hope

00:15:07.452 --> 00:15:10.444
and happiness and health,

00:15:10.444 --> 00:15:13.750
but in the past, we've often
looked at information technology

00:15:13.750 --> 00:15:15.958
and our eyes have only seen the T,

00:15:15.958 --> 00:15:17.644
the technology, the hardware,

00:15:17.644 --> 00:15:19.906
because that's what was physical.

00:15:19.906 --> 00:15:22.830
We now need to recast our gaze at the I,

00:15:22.830 --> 00:15:24.210
the information,

00:15:24.210 --> 00:15:25.583
which is less apparent,

00:15:25.583 --> 00:15:29.692
but in some ways a lot more important.

00:15:29.692 --> 00:15:33.157
Humanity can finally learn from the information

00:15:33.157 --> 00:15:35.575
that it can collect,

00:15:35.575 --> 00:15:37.690
as part of our timeless quest

00:15:37.690 --> 00:15:40.849
to understand the world and our place in it,

00:15:40.849 --> 00:15:46.480
and that's why big data is a big deal.

00:15:46.480 --> 00:15:50.048
(Applause)

