WEBVTT
Kind: captions
Language: ar

00:00:00.000 --> 00:00:07.000
المترجم: Eman Shahen
المدقّق: Amr Samy

00:00:12.780 --> 00:00:15.756
تبدأ هذه القصة عام 1985،

00:00:15.780 --> 00:00:17.756
في سن 22 عامًا،

00:00:17.780 --> 00:00:20.156
أصبحت بطل العالم في لعبة الشطرنج

00:00:20.180 --> 00:00:23.380
بعد التغلب على أناطولي كاربوف.

00:00:24.300 --> 00:00:25.556
في مطلع تلك السنة،

00:00:25.580 --> 00:00:29.196
لعبت ما يدعى بالاستعراض الفوري

00:00:29.220 --> 00:00:33.516
ضد 32 من أفضل 
الآلات اللاعبة للشطرنج في العالم.

00:00:33.540 --> 00:00:34.900
بمدينة هامبورغ، ألمانيا.

00:00:35.980 --> 00:00:37.180
فزت بجميع المباريات،

00:00:38.380 --> 00:00:41.556
عندها لم تعتبرهذه مفاجأة بحد كبير

00:00:41.580 --> 00:00:45.620
كوني استطعت هزيمة 32
حاسوبًا في نفس الوقت.

00:00:46.300 --> 00:00:48.876
بالنسبة لي، كان ذلك العصر الذهبي.

00:00:48.900 --> 00:00:50.996
(ضحك)

00:00:51.020 --> 00:00:52.540
كانت الآلات ضعيفة،

00:00:53.500 --> 00:00:54.836
وكان شعري قويًا.

00:00:54.860 --> 00:00:57.060
(ضحك)

00:00:58.540 --> 00:01:00.596
بعدها بــ 12 عامًا فقط،

00:01:00.620 --> 00:01:05.236
كنت أصارع من أجل حياتي ضد حاسوب واحد فقط

00:01:05.260 --> 00:01:06.460
في مباراة

00:01:07.180 --> 00:01:09.236
سميت في غلاف "نيوزويك"

00:01:09.260 --> 00:01:11.036
"الصمود الأخير للعقل."

00:01:11.060 --> 00:01:12.276
بلا حرج.

00:01:12.300 --> 00:01:13.820
(ضحك)

00:01:14.860 --> 00:01:17.436
من علم الأساطير إلى الخيال العلمي،

00:01:17.460 --> 00:01:20.196
صراع الإنسان ضد الآلة

00:01:20.220 --> 00:01:22.980
وصف غالبًا بأنه مسألة حياة أو موت.

00:01:23.780 --> 00:01:25.356
جون هنري،

00:01:25.380 --> 00:01:27.076
المسمى برجل المثقاب الفولاذي

00:01:27.100 --> 00:01:30.876
في القرن التاسع عشر هو
أسطورة شعبية من أصل إفريقي-أمريكي،

00:01:30.900 --> 00:01:32.276
اشترك في سباق

00:01:32.300 --> 00:01:35.036
ضد مطرقة تعمل بالبخار

00:01:35.060 --> 00:01:37.420
حيث شق نفق عبر جبل صخري.

00:01:38.620 --> 00:01:42.820
أسطورة جون هنري هي جزء من سرد تاريخي طويل

00:01:43.500 --> 00:01:46.580
لتباري الإنسانية ضد التكنولوجيا.

00:01:48.020 --> 00:01:50.900
وهذا الخطاب التنافسي هو المعيار الآن.

00:01:51.380 --> 00:01:53.340
نحن في سباق ضد الآلات،

00:01:54.180 --> 00:01:56.260
في معركة أو حتى في حرب.

00:01:57.700 --> 00:01:59.316
تم تدمير جميع الوظائف.

00:01:59.340 --> 00:02:02.900
تستبدل الناس كأنها اختفت
من على وجه الأرض.

00:02:04.060 --> 00:02:07.556
و يكفي الاعتقاد أن الأفلام
كفيلم "ذا تريمناتور" أو "ذا ماتريكس"

00:02:07.580 --> 00:02:08.780
ليست خيالية.

00:02:11.460 --> 00:02:15.780
هناك أمثلة قليلة جدًا في ميدان

00:02:17.180 --> 00:02:21.436
حيث العقل والجسم البشري
بإمكانه على قدم المساواة منافسة

00:02:21.459 --> 00:02:23.300
حاسوب أو إنسان آلي.

00:02:24.100 --> 00:02:25.958
في الحقيقة، أتمنى لو كان هناك المزيد.

00:02:27.580 --> 00:02:28.780
في حين،

00:02:29.660 --> 00:02:34.316
بفضل بركتي وسحري

00:02:34.340 --> 00:02:37.036
غدوت مثالًا وقدوة

00:02:37.060 --> 00:02:40.156
في نزال الرجل ضد الآلة

00:02:40.180 --> 00:02:42.060
التي يتحدث عنها الجميع.

00:02:44.940 --> 00:02:49.956
في أشهر نزال للإنسان ضد الآلة
منذ نزال جون هنري،

00:02:49.980 --> 00:02:52.556
خُضت مباراتين

00:02:52.580 --> 00:02:56.020
ضد الحاسوب الخارق
لشركة آي بي إم المسمى ديب بلو.

00:02:58.860 --> 00:03:01.036
لا أحد يتذكر أني ربحت المباراة الأولى --

00:03:01.060 --> 00:03:03.396
(ضحك)

00:03:03.420 --> 00:03:06.820
(تصفيق)

00:03:07.740 --> 00:03:12.716
في فيلادلفيا، قبل خسارة المباراة الثانية
السنة التالية في نيويورك.

00:03:12.740 --> 00:03:14.500
لكن أظن أن هذا عدل.

00:03:16.140 --> 00:03:21.236
ليس هناك يوم في التاريخ،
مدخل خاص في التقويم

00:03:21.260 --> 00:03:24.756
لكل من فشلوا في تسلق قمة جبل إيفرست

00:03:24.780 --> 00:03:27.516
قبل أن يقوم السير إدموند هيلاري
و تينزين نورغاي

00:03:27.540 --> 00:03:28.740
ببلوغ القمة.

00:03:29.780 --> 00:03:33.540
في 1997، كنت ما أزال بطل العالم

00:03:36.340 --> 00:03:40.540
عندما أصبحت حواسيب الشطرنج
تتربع على العرش.

00:03:41.340 --> 00:03:43.316
كنت كجبل إيفرست،

00:03:43.340 --> 00:03:44.940
وبلغ الحاسوب ديب بلو القمة.

00:03:46.420 --> 00:03:50.476
علي أن أقول بالطبع،
أنه ليس الحاسوب من تغلب علي،

00:03:50.500 --> 00:03:52.636
بل صانعيه البشر --

00:03:52.660 --> 00:03:55.996
آنانثارمان، وكامبل، وهون، وسو.

00:03:56.020 --> 00:03:57.220
تحية لهم.

00:03:58.660 --> 00:04:03.076
لطالما كان انتصار الآلة 
هو انتصارًا للإنسان،

00:04:03.100 --> 00:04:07.860
شيء نميل لنسيانه عندما
تفوقت إبدعاتنا علي صنعنا.

00:04:10.180 --> 00:04:11.620
كان ديب بلو منتصرًا،

00:04:13.220 --> 00:04:14.420
لكن هل كان ذكيا؟

00:04:15.180 --> 00:04:16.940
لا، لم يكن كذلك،

00:04:18.020 --> 00:04:23.076
على الأقل ليس بالطريقة التي كان آلان
تورينغ والمؤسسين الآخرين لعلم الحاسوب

00:04:23.100 --> 00:04:24.300
يأملونها.

00:04:25.060 --> 00:04:29.836
تبين أن الشطرنج
يمكن أن يُحطم بقوة غاشمة،

00:04:29.860 --> 00:04:34.116
بمجرد تسريع المعدات بدرجة كافية

00:04:34.140 --> 00:04:37.100
وكون الحلول الحسابية ذكية كفاية.

00:04:38.580 --> 00:04:42.276
بالرغم من تعريف الناتج،

00:04:42.300 --> 00:04:45.516
مستوى سادة الشطرنج،

00:04:45.540 --> 00:04:46.820
كان ديب بلو ذكيًا.

00:04:49.140 --> 00:04:51.540
لكن حتى مع السرعة المذهلة،

00:04:52.380 --> 00:04:55.580
200 مليون موضع في الثانية،

00:04:57.180 --> 00:04:58.380
قدمت طريقة ديب بلو

00:04:59.180 --> 00:05:05.780
قليلًا من البصيرة 
المرجوة للغز الذكاء البشري.

00:05:08.780 --> 00:05:10.596
قريبًا،

00:05:10.620 --> 00:05:13.196
ستقود الآلات سيارات الأجرة

00:05:13.220 --> 00:05:15.636
وتكون أطباء، وأساتذة،

00:05:15.660 --> 00:05:18.260
لكن هل سيكونون "أذكياء"؟

00:05:19.660 --> 00:05:22.156
من الأفضل ترك هذه التعاريف

00:05:22.180 --> 00:05:25.740
للفلاسفة وللقاموس.

00:05:27.260 --> 00:05:31.140
ما يهم حقًا هو كيف نشعر نحن البشر

00:05:32.140 --> 00:05:35.740
حيال العيش والعمل مع هذه الآلات.

00:05:37.980 --> 00:05:43.236
عندما قابلت ديب بلو لأول مرة
في فبراير عام 1996،

00:05:43.260 --> 00:05:45.860
كنت بطل العالم حينها لأكثر من 10 سنين،

00:05:47.900 --> 00:05:51.916
وقد لعبت 182 مباراة في بطولة العالم

00:05:51.940 --> 00:05:57.036
ومئات المباريات ضد كبار
اللاعبين في منافسات أخرى.

00:05:57.060 --> 00:06:02.116
عرفت المتوقع من خصومي

00:06:02.140 --> 00:06:03.820
والمتوقع من نفسي.

00:06:04.500 --> 00:06:09.676
اعتدت على تقدير حركاتهم

00:06:09.700 --> 00:06:13.316
وتقدير حالاتهم العاطفية

00:06:13.340 --> 00:06:17.180
بمشاهدة لغة أجسادهم والنظر في أعينهم.

00:06:17.700 --> 00:06:21.700
ومن ثم جلست في الجانب الآخر لرقعة 
الشطرنج في مواجهة ديب بلو.

00:06:24.780 --> 00:06:27.636
أحسست على الفور بشيء جديد.

00:06:27.660 --> 00:06:28.980
شيء مقلق.

00:06:31.260 --> 00:06:34.060
قد تكونوا جربتم إحساسًا مماثلًا

00:06:35.140 --> 00:06:37.676
في أول مرة تركبون فيها سيارة بدون سائق

00:06:37.700 --> 00:06:42.540
أو أول مرة يصدر فيها متحكم
حاسوبي جديد أمرًا في العمل.

00:06:45.620 --> 00:06:48.740
لكن عندما جلست في تلك المبارة الأولى،

00:06:49.900 --> 00:06:52.036
لم يكن باستطاعتي التأكد

00:06:52.060 --> 00:06:55.740
مما هو قادرعليه.

00:06:56.740 --> 00:06:59.900
بإمكان التكنولوجيا التطور بسرعة،
وقد استثمرت آي بي أم بشكل كبير.

00:07:00.500 --> 00:07:01.700
خسرت تلك المبارة.

00:07:04.140 --> 00:07:05.916
ولم أستطع التوقف عن التساؤل،

00:07:05.940 --> 00:07:07.500
هل هو لا يقهر؟

00:07:08.420 --> 00:07:10.780
هل انتهت لعبة الشطرنج المحببة لدي؟

00:07:12.620 --> 00:07:16.756
كانت هناك شكوك ومخاوف بشرية

00:07:16.780 --> 00:07:18.460
والشيء الوحيد الذي تأكدت منه

00:07:19.220 --> 00:07:22.116
هو أن غريمي ديب بلو لم يكن
لديه مثل هذه الشكوك إطلاقًا.

00:07:22.140 --> 00:07:23.900
(ضحك)

00:07:25.740 --> 00:07:27.140
وصارعت مرة أخرى

00:07:28.220 --> 00:07:29.900
بعد تلك الضربة المدمرة

00:07:30.820 --> 00:07:32.020
لكسب المبارة الأولى،

00:07:32.780 --> 00:07:34.420
لكن كان هذا واضحًا.

00:07:36.220 --> 00:07:38.356
وفي النهاية خسرت لصالح الآلة

00:07:38.380 --> 00:07:41.436
لكنيّ لم أواجه مصير جون هنري

00:07:41.460 --> 00:07:44.500
الذي فاز لكنه مات ومطرقته بيده.

00:07:49.540 --> 00:07:52.076
اتضح أن عالم الشطرنج

00:07:52.100 --> 00:07:55.340
ما زال بحاجة إلى بطل بشري للشطرنج.

00:07:56.740 --> 00:07:58.420
وحتى اليوم،

00:07:59.900 --> 00:08:03.356
عندما يكون تطبيق مجاني للشطرنج
على أحدث الهواتف المحمولة

00:08:03.380 --> 00:08:05.396
أقوى من ديب بلو

00:08:05.420 --> 00:08:06.900
لا يزال الناس يلعبون الشطرنج،

00:08:08.500 --> 00:08:10.740
وحتى أكثر من ذي قبل.

00:08:11.620 --> 00:08:14.836
تنبأ المتشائمون بأن أحداً لن يلمس اللعبة

00:08:14.860 --> 00:08:17.116
التي بإمكان الآلة هزيمتها،

00:08:17.140 --> 00:08:19.356
وقد كانوا مخطئين، خطأ مثبت،

00:08:19.380 --> 00:08:22.836
لكن دائمًا يكون التشاؤم تسلية شعبية

00:08:22.860 --> 00:08:24.220
عندما يخص الأمر التكنولوجيا.

00:08:26.180 --> 00:08:28.916
ما تعلمته من تجربتي الشخصية

00:08:28.940 --> 00:08:33.596
هو أنه يجب علينا مواجهة مخاوفنا

00:08:33.620 --> 00:08:37.340
إذا كنا نريد الحصول على
المزيد من التكنولوجيا خاصتنا.

00:08:38.180 --> 00:08:40.556
ويجب علينا التغلب على هذه المخاوف

00:08:40.580 --> 00:08:45.820
إذا كنا نريد أن نخرج
أفضل ما في الإنسانية.

00:08:47.940 --> 00:08:49.715
خلال فترة التعافي من هزيمتي،

00:08:49.739 --> 00:08:51.700
جاءني الكثير من الإلهام

00:08:52.900 --> 00:08:55.595
من معاركي ضد ديب بلو.

00:08:55.619 --> 00:08:58.740
وكما يقول المثل الروسي، إذا
لم تستطع هزيمتهم، فانضم إليهم.

00:09:00.700 --> 00:09:02.076
ومن ثم فكرت،

00:09:02.100 --> 00:09:04.436
ماذا لو أستطعت اللعب مع حاسوب --

00:09:04.460 --> 00:09:07.620
معًا، مع حاسوب إلى جانبي، ودمج قوتنا،

00:09:08.980 --> 00:09:12.756
الحدس البشري بالإضافة 
إلى القدرة الحسابية للجهاز،

00:09:12.780 --> 00:09:15.476
واستراتيجية البشر، وتكتيكات الجهاز،

00:09:15.500 --> 00:09:17.916
وخبرة البشر، وذاكرة الجهاز.

00:09:17.940 --> 00:09:20.140
هل يمكن أن تكون أفضل
مبارة تلعب على الإطلاق؟

00:09:21.820 --> 00:09:23.500
تحققت فكرتي

00:09:24.740 --> 00:09:28.116
في عام 1998 باسم أدفانسد تشس

00:09:28.140 --> 00:09:33.820
عندما خضت هذه المنافسة المشتركة
بين الإنسان والآلة ضد أحد أفضل اللاعبين.

00:09:35.100 --> 00:09:36.996
لكن في هذه التجربة الأولى،

00:09:37.020 --> 00:09:43.380
فشلنا نحن الإثنان في دمج
المهارات البشرية والآلية بكفاءة.

00:09:46.740 --> 00:09:48.980
وجدت أدفانسد تشس مكانًا على الإنترنت،

00:09:49.980 --> 00:09:54.836
وفي 2005، أوجدت ما يسمى
ببطولة الشطرنج الحرة

00:09:54.860 --> 00:09:56.220
الإلهام.

00:09:59.060 --> 00:10:02.596
شارك فريق من سادة الشطرنج وأفضل الآلات،

00:10:02.620 --> 00:10:05.356
لكن لم يكن الفائزون هم سادة الشطرنج،

00:10:05.380 --> 00:10:06.740
ولم يكن كذلك للحاسوب الخارق.

00:10:07.500 --> 00:10:11.836
كان الفائزون هما لاعبان
أمريكيان من هواة الشطرنج

00:10:11.860 --> 00:10:15.020
يشغّلان ثلاثة حواسيب عادية في ذات الوقت.

00:10:17.380 --> 00:10:20.396
ساوت مهاراتهم في قيادة آلاتهم

00:10:20.420 --> 00:10:26.196
كفاءة المعرفة الفائقة بالشطرنج

00:10:26.220 --> 00:10:27.796
التي لدى خصومهم من سادة الشطرنج

00:10:27.820 --> 00:10:31.980
وكانت أعظم من القوة الحاسوبية للآخرين.

00:10:33.420 --> 00:10:35.380
وقد توصلت لهذه المعادلة.

00:10:36.380 --> 00:10:39.756
أن لاعباً بشرياً ضعيف بالإضافة إلي آلة

00:10:39.780 --> 00:10:43.036
بالإضافة الي عملية أفضل هو أقوى

00:10:43.060 --> 00:10:45.476
من آلة عملاقة وحدها،

00:10:45.500 --> 00:10:49.396
لكن الأهم، أنها تكون أقوى
من لاعب بشري قوي

00:10:49.420 --> 00:10:51.380
بالاضافة الي آلة

00:10:52.940 --> 00:10:55.340
وعملية أضعف.

00:10:58.180 --> 00:11:00.300
أقنعني هذا أننا نحتاج إلى

00:11:01.820 --> 00:11:05.500
وسائط أفضل لمساعدتنا في قيادة آلاتنا

00:11:06.340 --> 00:11:08.060
نحو ذكاء أكثر إفادة.

00:11:10.140 --> 00:11:13.436
البشر بالإضافة الي الآلة ليسوا المستقبل،

00:11:13.460 --> 00:11:14.676
لكنهم الحاضر.

00:11:14.700 --> 00:11:18.836
كل أحد يستخدم ترجمة الإنترنت

00:11:18.860 --> 00:11:23.156
للحصول على فحوى مقالات 
إخبارية من صحف أجنبية،

00:11:23.180 --> 00:11:24.820
يعرف أنها ليست متقنة.

00:11:25.500 --> 00:11:27.596
لذا نستخدم خبرتنا البشرية

00:11:27.620 --> 00:11:29.716
لفهم ذلك،

00:11:29.740 --> 00:11:32.516
ثم بعدها تتعلم الآلة من تصحيحاتنا.

00:11:32.540 --> 00:11:37.500
وينتشر هذا النموذج ويستثمر في
التشخيص الطبي، والتحليل الأمني.

00:11:38.260 --> 00:11:40.380
تستقي الآلة البيانات،

00:11:41.140 --> 00:11:42.876
وتحسب الاحتمالات،

00:11:42.900 --> 00:11:46.556
وتحصل على %80 من الطريقة، أو %90،

00:11:46.580 --> 00:11:50.956
جاعلة إياها أسهل للتحليل

00:11:50.980 --> 00:11:53.580
واتخاذ القرارت للشريك البشري.

00:11:54.100 --> 00:11:58.940
ولكنّا لن نرسل أطفالنا

00:11:59.820 --> 00:12:03.380
للمدرسة في سيارة ذاتية
القيادة متقنة بنسبة %90

00:12:04.420 --> 00:12:06.020
أو حتي بنسبة %99.

00:12:07.380 --> 00:12:10.236
لذا فنحن نحتاج إلى قفزة للأمام

00:12:10.260 --> 00:12:16.420
لإضافة المزيد من المقامات العشرية المهمة.

00:12:18.980 --> 00:12:23.020
بعد عشرين سنة من مباراتي مع ديب بلو،

00:12:24.020 --> 00:12:25.636
المبارة الثانية،

00:12:25.660 --> 00:12:31.956
هذا العنوان العظيم "الصمود الأخير للعقل"

00:12:31.980 --> 00:12:33.556
قد أصبح مألوفًا

00:12:33.580 --> 00:12:36.116
وكما أن الآلات الذكية

00:12:36.140 --> 00:12:37.340
تتقدم

00:12:38.380 --> 00:12:40.580
في كل المجالات، كل يوم على ما يبدو.

00:12:41.980 --> 00:12:45.076
على خلاف الماضي،

00:12:45.100 --> 00:12:46.740
عندما حلّت الآلات محل

00:12:48.300 --> 00:12:50.676
حيوانات المزرعة، والعمالة اليدوية،

00:12:50.700 --> 00:12:53.196
والآن يسعون خلف الناس
أصحاب الشهادات الجامعية

00:12:53.220 --> 00:12:54.500
وأصحاب النفوذ السياسي.

00:12:55.940 --> 00:12:58.036
وكشخص حارب ضد الآلة وخسر،

00:12:58.060 --> 00:13:00.700
أنا هنا لأخبركم أن هذه أخبار رائعة جدًا.

00:13:02.820 --> 00:13:05.036
في النهاية، كل مهنة

00:13:05.060 --> 00:13:07.156
سوف تعتريها هذه الضغوطات

00:13:07.180 --> 00:13:12.780
أو بمعنى آخر أن الإنسانية قد توقف تقدمها.

00:13:14.580 --> 00:13:15.780
نحن لا

00:13:17.260 --> 00:13:18.980
نختار

00:13:20.300 --> 00:13:23.020
متى ولا أين يتوقف التقدم التكنولوجي.

00:13:24.980 --> 00:13:26.340
لا نستطيع

00:13:27.780 --> 00:13:29.276
أن نبطئ.

00:13:29.300 --> 00:13:31.116
في الحقيقة،

00:13:31.140 --> 00:13:33.060
يجب علينا الإسراع.

00:13:36.420 --> 00:13:39.060
تمتاز الكتنولوجيا الخاصة بنا بإزالة

00:13:41.020 --> 00:13:44.380
الصعاب والشكوك من حياتنا،

00:13:46.820 --> 00:13:49.636
ولذا يجب علينا البحث عن

00:13:49.660 --> 00:13:51.516
تحديات أكثر صعوبة،

00:13:51.540 --> 00:13:55.620
وذات شكوك أكثر.

00:14:00.020 --> 00:14:01.220
لدى الآلات

00:14:02.976 --> 00:14:05.516
العمليات الحسابية.

00:14:06.007 --> 00:14:07.116
لدينا الفهم.

00:14:07.140 --> 00:14:09.071
لدى الآلات التوجيهات.

00:14:09.854 --> 00:14:12.516
لدينا الغرض.

00:14:12.540 --> 00:14:14.820
لدى الآلات

00:14:16.900 --> 00:14:18.116
الموضوعية.

00:14:18.140 --> 00:14:19.340
لدينا العاطفة.

00:14:20.420 --> 00:14:26.396
لا يجدر بنا القلق تجاه 
ما تفعله آلاتنا حاليًا.

00:14:26.420 --> 00:14:30.996
بدلًا عن ذلك، لابد أن نقلق
حيال ما لا يمكنهم فعله اليوم.

00:14:31.020 --> 00:14:36.516
لأننا سنحتاج مساعدة الآلات الجديدة الذكية

00:14:36.540 --> 00:14:40.620
لتحويل أعظم أحلامنا إلى حقيقة.

00:14:41.820 --> 00:14:43.140
وإذا فشلنا،

00:14:44.060 --> 00:14:48.716
إذا فشلنا، هذا ليس لأن آلاتنا ذكية للغاية،

00:14:48.740 --> 00:14:50.140
أو ليست ذكية كفايةً.

00:14:51.020 --> 00:14:54.100
إذا فشلنا، هذا لأننا قد رضينا

00:14:55.500 --> 00:14:57.060
وتقلصت طموحتنا.

00:14:58.340 --> 00:15:01.380
إنسانيتنا ليست محددة بأي مهارة،

00:15:03.100 --> 00:15:05.780
كأرجحة مطرقة
أو حتى لعب الشطرنج.

00:15:06.380 --> 00:15:09.396
هناك شيء واحد
وحده الإنسان قادر على القيام به

00:15:09.420 --> 00:15:10.620
انه الحلم.

00:15:11.940 --> 00:15:14.476
فدعونا نحلم أحلامًا كبيرة

00:15:14.500 --> 00:15:15.716
شكرًا لكم.

00:15:15.740 --> 00:15:19.627
(تصفيق)

