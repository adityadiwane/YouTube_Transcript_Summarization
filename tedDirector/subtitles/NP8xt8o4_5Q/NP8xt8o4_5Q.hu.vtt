WEBVTT
Kind: captions
Language: hu

00:00:00.000 --> 00:00:07.000
Fordító: Péter Pallós
Lektor: Zsuzsanna Lőrincz

00:00:12.780 --> 00:00:15.756
A történet 1985-ben kezdődik,

00:00:15.780 --> 00:00:17.756
22 éves koromban,

00:00:17.780 --> 00:00:20.156
amikor sakkvilágbajnok lettem

00:00:20.180 --> 00:00:23.380
Anatolij Karpov legyőzésével.

00:00:24.050 --> 00:00:25.556
Abban az évben korábban

00:00:25.580 --> 00:00:29.196
szimultán mérkőzést játszottam

00:00:29.220 --> 00:00:33.516
a világ 32 legjobb sakkozógépe ellen

00:00:33.540 --> 00:00:34.900
a németországi Hamburgban.

00:00:35.980 --> 00:00:37.330
Minden játszmát megnyertem,

00:00:38.380 --> 00:00:41.556
és nem számított meglepőnek,

00:00:41.580 --> 00:00:45.620
hogy egyidejűleg meg tudtam verni
32 számítógépet.

00:00:46.300 --> 00:00:48.876
Az volt az én aranykorom.

00:00:48.900 --> 00:00:50.996
(Nevetés)

00:00:51.020 --> 00:00:52.540
A gépek gyengék voltak,

00:00:53.500 --> 00:00:54.836
a hajam pedig dús.

00:00:54.860 --> 00:00:57.060
(Nevetés)

00:00:58.540 --> 00:01:00.596
De 12 évvel később

00:01:00.620 --> 00:01:05.236
élet-halál küzdelmet vívtam
egyetlen számítógép ellen

00:01:05.260 --> 00:01:06.460
olyan mérkőzésen,

00:01:07.180 --> 00:01:09.236
amelyet a Newsweek címoldala

00:01:09.260 --> 00:01:11.036
"Az agy utolsó védvonalá"-nak hívott.

00:01:11.060 --> 00:01:12.276
Spongyát rá!

00:01:12.300 --> 00:01:13.820
(Nevetés)

00:01:14.860 --> 00:01:17.436
A mitológiától kezdve a sci-fiig

00:01:17.460 --> 00:01:20.196
az ember gép elleni küzdelmét

00:01:20.220 --> 00:01:22.980
gyakran élet-halál harcként ábrázolják.

00:01:23.780 --> 00:01:25.356
John Henry,

00:01:25.380 --> 00:01:27.076
az acélkalapácsos ember,

00:01:27.100 --> 00:01:30.876
a 19. századi afroamerikai
népi legenda hőse,

00:01:30.900 --> 00:01:32.276
gőzkalapács ellen

00:01:32.300 --> 00:01:35.036
folytatott küzdelmet,

00:01:35.060 --> 00:01:37.420
amikor alagutat tört a sziklás hegyen át.

00:01:38.620 --> 00:01:42.820
John Henry legendája része
annak a régi gondolkodási sémának,

00:01:43.500 --> 00:01:46.580
amely az embert és a technológiát
szembeállítja egymással.

00:01:48.020 --> 00:01:50.900
A versenyzés retorikája 
manapság is uralkodó.

00:01:51.380 --> 00:01:53.340
Versenyben vagyunk a gépekkel,

00:01:54.180 --> 00:01:56.260
küzdelemben, sőt háborúban.

00:01:57.700 --> 00:01:59.316
Munkahelyek szűnnek meg.

00:01:59.340 --> 00:02:02.900
Gépek lépnek emberek helyébe,
mintha soha nem léteztek volna a Földön.

00:02:04.060 --> 00:02:07.556
Elég arra gondolni, 
hogy a Terminátor vagy a Mátrix c. film

00:02:07.580 --> 00:02:08.780
valósággá váltak.

00:02:11.460 --> 00:02:15.780
Kevés terület maradt,

00:02:17.180 --> 00:02:21.436
ahol az emberi test és ész
egyenlő feltételekkel versenyezhet

00:02:21.459 --> 00:02:23.300
számítógépekkel vagy robotokkal.

00:02:24.100 --> 00:02:25.958
Szeretném, ha sokkal több lenne.

00:02:27.580 --> 00:02:28.780
Ehelyett

00:02:29.660 --> 00:02:34.316
egyszerre voltam megáldva és megátkozva,

00:02:34.340 --> 00:02:37.036
hogy szó szerint példaalakja lettem

00:02:37.060 --> 00:02:40.156
az ember és a gép versenyének,

00:02:40.180 --> 00:02:42.230
akire állandóan hivatkoznak.

00:02:44.940 --> 00:02:49.956
A John Henry óta lezajlott leghíresebb 
ember–gép versenyben

00:02:49.980 --> 00:02:52.556
két mérkőzést játszottam

00:02:52.580 --> 00:02:56.020
az IBM Deep Blue nevű
csúcsszámítógépe ellen.

00:02:58.860 --> 00:03:01.296
Senki sem emlékszik rá,
hogy az elsőt megnyertem...

00:03:01.296 --> 00:03:03.396
(Nevetés)

00:03:03.420 --> 00:03:06.820
(Taps)

00:03:07.740 --> 00:03:12.716
...Philadelphiában, mielőtt elvesztettem
a visszavágót egy év múlva New Yorkban.

00:03:12.740 --> 00:03:14.500
De ez rendjén való.

00:03:16.140 --> 00:03:21.236
Nem tartják számon a naptárban azokat,

00:03:21.260 --> 00:03:24.756
akiknek nem sikerült
megmászniuk a Mount Everestet,

00:03:24.780 --> 00:03:27.516
mielőtt Sir Edmund Hillary
és Tenzing Norgay

00:03:27.540 --> 00:03:28.830
föl nem jutott a csúcsára.

00:03:29.780 --> 00:03:33.540
1997-ben még sakkvilágbajnok voltam,

00:03:36.340 --> 00:03:40.540
mikor a sakkszámítógépek végül beértek.

00:03:41.340 --> 00:03:43.316
Én voltam a Mount Everest,

00:03:43.340 --> 00:03:44.940
és a Deep Blue elérte a csúcsot.

00:03:46.420 --> 00:03:50.476
Persze, nem a Deep Blue tette,

00:03:50.500 --> 00:03:52.636
hanem a létrehozói

00:03:52.660 --> 00:03:55.996
Anantharaman, Campbell, Hoane, Hsu.

00:03:56.020 --> 00:03:57.220
Le a kalappal előttük!

00:03:58.660 --> 00:04:03.076
Mint mindig, a gép győzelme
az ember győzelme,

00:04:03.100 --> 00:04:07.860
ezt hajlunk elfeledni, amikor teremtményei
túltesznek létrehozójukon.

00:04:10.180 --> 00:04:11.620
A Deep Blue győzedelmeskedett,

00:04:13.220 --> 00:04:14.420
de intelligens volt-e?

00:04:15.180 --> 00:04:17.170
Nem volt, legalábbis abban az értelemben,

00:04:18.020 --> 00:04:23.076
ahogy Alan Turing s az informatika
tudományának megalapítói

00:04:23.100 --> 00:04:24.300
remélték.

00:04:25.060 --> 00:04:29.836
Kiderült, hogy a sakkjátékban
a nyers erő is dönthet,

00:04:29.860 --> 00:04:34.116
ha a hardver elég gyors

00:04:34.140 --> 00:04:37.100
és az algoritmus elég okos.

00:04:38.580 --> 00:04:42.276
Bár az eredmény szempontjából

00:04:42.300 --> 00:04:45.516
– hogy ti. nagymesteri fokon játsszék –

00:04:45.540 --> 00:04:46.820
a Deep Blue okos volt.

00:04:49.140 --> 00:04:51.540
De a hihetetlen sebességű

00:04:52.380 --> 00:04:55.580
– 200 millió állás másodpercenként –

00:04:57.180 --> 00:04:59.080
Deep Blue módszer
nem sokat tett hozzá,

00:04:59.180 --> 00:05:05.780
hogy belelássunk
az emberi intelligencia rejtelmébe.

00:05:08.780 --> 00:05:10.596
Nemsokára

00:05:10.620 --> 00:05:13.196
gépek lesznek a taxisok,

00:05:13.220 --> 00:05:15.636
orvosok, egyetemi tanárok,

00:05:15.660 --> 00:05:18.260
de vajon intelligensek lesznek-e?

00:05:19.660 --> 00:05:23.866
Ezeket a meghatározásokat
inkább meghagyom

00:05:23.866 --> 00:05:25.740
filozófusoknak és szótáraknak.

00:05:27.260 --> 00:05:31.140
Igazából az számít, hogy mi, emberek,

00:05:32.140 --> 00:05:35.740
hogyan érezzük magunkat e gépek
között élve és velük dolgozva.

00:05:37.980 --> 00:05:43.236
Amikor 1996 februárjában 
először találkoztam a Deep Blue-val,

00:05:43.260 --> 00:05:45.860
már több mint 10 éve világbajnok voltam,

00:05:47.900 --> 00:05:51.916
és 182 világbajnoki játszmán voltam túl,

00:05:51.940 --> 00:05:57.036
meg más kiváló sakkozók
ellen vívott több száz játszmán.

00:05:57.060 --> 00:06:02.116
Tudtam, mire számítsak ellenfeleimtől,

00:06:02.140 --> 00:06:03.820
és tudtam, mit várhatok magamtól.

00:06:04.500 --> 00:06:09.676
Megszoktam, hogy mérlegeljem a lépéseiket,

00:06:09.700 --> 00:06:13.316
és fölbecsüljem érzelmi állapotukat

00:06:13.340 --> 00:06:17.180
testbeszédük alapján és a szemükbe nézve.

00:06:17.700 --> 00:06:21.700
Amikor a Deep Blue sakktáblájához ültem,

00:06:24.780 --> 00:06:27.636
rögtön valami újdonságot éreztem,

00:06:27.660 --> 00:06:28.980
valami nyugtalanítót.

00:06:31.260 --> 00:06:34.060
Amilyent akkor éreznek,

00:06:35.140 --> 00:06:37.676
mikor először ülnek
vezető nélküli kocsiba,

00:06:37.700 --> 00:06:42.540
vagy amikor az új IT-főnöktől
először kapnak utasítást.

00:06:45.620 --> 00:06:48.740
De az első játszmánál még

00:06:49.900 --> 00:06:52.036
nem lehettem benne biztos,

00:06:52.060 --> 00:06:55.740
mire képes ez a micsoda.

00:06:56.740 --> 00:06:59.980
A technológia ugrásszerűen fejlődik,
és az IBM sokat fektetett bele.

00:07:00.500 --> 00:07:01.880
Azt a játszmát elvesztettem.

00:07:04.140 --> 00:07:05.916
Csak tűnődtem:

00:07:05.940 --> 00:07:07.500
lehet, hogy legyőzhetetlen?

00:07:08.420 --> 00:07:10.780
Talán befellegzett imádott sakkomnak?

00:07:12.620 --> 00:07:16.756
Ezek emberi kétségek, 
emberi félelmek voltak.

00:07:16.780 --> 00:07:18.460
Egyben biztos voltam:

00:07:19.220 --> 00:07:22.116
Deep Blue nevű ellenfelemnek
nincsenek ilyen kétségei.

00:07:22.140 --> 00:07:23.900
(Nevetés)

00:07:25.740 --> 00:07:27.140
A megsemmisítő csapás után

00:07:28.220 --> 00:07:29.900
visszavágtam,

00:07:30.450 --> 00:07:32.020
és megnyertem az első mérkőzést,

00:07:32.530 --> 00:07:34.420
de a baljós előjelek már jelentkeztek.

00:07:36.220 --> 00:07:38.356
Végül is vesztettem a géppel szemben,

00:07:38.380 --> 00:07:41.436
de legalább nem jutottam 
John Henry sorsára,

00:07:41.460 --> 00:07:44.500
aki bár győzött,
kalapácsával a kezében halt meg.

00:07:49.540 --> 00:07:52.076
Kiderült, hogy a sakk világának

00:07:52.100 --> 00:07:55.340
még szüksége van emberi sakkbajnokra.

00:07:56.740 --> 00:07:58.420
Még manapság is, mikor a mobilokon

00:07:59.900 --> 00:08:03.356
az ingyen sakkprogramok

00:08:03.380 --> 00:08:05.396
erősebbek a Deep Blue-nál,

00:08:05.420 --> 00:08:06.900
az emberek mégis sakkoznak,

00:08:08.500 --> 00:08:10.740
többet, mint bármikor.

00:08:11.620 --> 00:08:14.836
A vészmadarak azt jósolták,
hogy senki nem fog sakkozni,

00:08:14.860 --> 00:08:17.116
ha gép is legyőzheti.

00:08:17.140 --> 00:08:19.356
Bebizonyosodott a tévedésük,

00:08:19.380 --> 00:08:22.836
de a vészmadaraknak mindig
kedvenc időtöltésük

00:08:22.860 --> 00:08:24.220
a károgás a technológiáról.

00:08:26.180 --> 00:08:28.916
Saját tapasztalatomból tudom,

00:08:28.940 --> 00:08:33.596
hogy szembe kell néznünk a félelmünkkel,

00:08:33.620 --> 00:08:37.340
ha a legtöbbet akarjuk
kihozni a technológiából,

00:08:38.180 --> 00:08:40.556
és le kell győznünk félelmünket,

00:08:40.580 --> 00:08:45.820
hogy a legjobbat hozzuk
ki emberi mivoltunkból.

00:08:47.940 --> 00:08:49.715
Sebeim nyalogatása közben

00:08:49.739 --> 00:08:51.700
a Deep Blue elleni küzdelemből

00:08:52.900 --> 00:08:55.595
merítettem ihletet.

00:08:55.619 --> 00:08:58.990
A régi orosz mondás szerint: ha nem
tudod megverni, csatlakozz hozzá.

00:09:00.700 --> 00:09:02.076
Akkor arra gondoltam:

00:09:02.100 --> 00:09:04.436
mi lenne, ha összefognék a géppel,

00:09:04.460 --> 00:09:07.620
a számítógép és én együttműködnénk,
egyesítenénk erősségeinket:

00:09:08.980 --> 00:09:12.756
az emberi ösztönt a gépi számolással,

00:09:12.780 --> 00:09:15.476
az emberi stratégiát a gépi taktikával,

00:09:15.500 --> 00:09:17.916
az emberi tapasztalatot 
a gép memóriájával?

00:09:17.940 --> 00:09:20.140
Tán ez lenne az eddigi
legtökéletesebb játszma.

00:09:21.820 --> 00:09:23.500
1998-ban Haladó Sakk néven

00:09:24.740 --> 00:09:28.116
megvalósítottam az elgondolásomat.

00:09:28.140 --> 00:09:33.820
A géppel az oldalamon játszottam
egy másik kiváló sakkozó ellen.

00:09:35.100 --> 00:09:37.256
Az első kísérletben
egyikünknek sem sikerült

00:09:37.256 --> 00:09:43.380
hatékonyan egyesítenie
az ember és a gép erősségét.

00:09:46.740 --> 00:09:48.980
A Haladó Sakk fölkerült az internetre,

00:09:49.980 --> 00:09:54.836
és 2005-ben az ún. kötetlen sakkbajnokság

00:09:54.860 --> 00:09:56.220
meglepetésszámba ment.

00:09:59.060 --> 00:10:02.596
Nagymesterek csapata
s a legjobb sakkgépek vettek benne részt,

00:10:02.620 --> 00:10:05.356
de nem a nagymesterek nyertek,

00:10:05.380 --> 00:10:06.740
és nem a csúcsszámítógép.

00:10:07.500 --> 00:10:11.836
Egy amerikai amatőr sakkpáros nyert,

00:10:11.860 --> 00:10:15.020
amely egyidejűleg három közönséges
személyi számítógépet kezelt.

00:10:17.380 --> 00:10:20.396
Gépeik kezelése révén

00:10:20.420 --> 00:10:26.196
hatékonyan fölülmúlták

00:10:26.220 --> 00:10:28.666
nagymester ellenfeleik
sokkal nagyobb sakktudását

00:10:28.666 --> 00:10:31.980
és a többiek sokkal nagyobb
számítási teljesítményét.

00:10:33.420 --> 00:10:35.380
Kialakítottam e képletet:

00:10:36.380 --> 00:10:39.756
gyenge játékos plusz gép

00:10:39.780 --> 00:10:43.036
plusz jobb kombináció fölülmúlja

00:10:43.060 --> 00:10:45.476
az önálló nagy teljesítményű gépet,

00:10:45.500 --> 00:10:49.396
de még figyelemreméltóbb, hogy fölülmúlja

00:10:49.420 --> 00:10:51.380
az erős játékos plusz gép összeállítást,

00:10:52.940 --> 00:10:55.340
ha csapnivaló a kombináció.

00:10:58.180 --> 00:11:00.830
Ez arról győzött meg,
hogy fejlettebb felületek kellenek

00:11:01.820 --> 00:11:05.500
gépeink összehangolására

00:11:06.340 --> 00:11:08.060
a jobb intelligencia érdekében.

00:11:10.140 --> 00:11:13.436
Az ember + gép nem a jövő,

00:11:13.460 --> 00:11:14.676
hanem a jelen.

00:11:14.700 --> 00:11:18.836
Aki már használt internetes fordítást

00:11:18.860 --> 00:11:23.156
idegen nyelvű újsághír
lényegének megértéséhez,

00:11:23.180 --> 00:11:24.820
tudja, hogy a fordítás gyatra.

00:11:25.500 --> 00:11:27.596
De ha hozzáadjuk az emberi tapasztalatot,

00:11:27.620 --> 00:11:29.716
hogy értelmessé tegyük,

00:11:29.740 --> 00:11:32.516
a gép tanul a kiigazításainkból.

00:11:32.540 --> 00:11:37.500
E modell egyre jobban terjed az orvosi
diagnosztikában, a biztonsági elemzésben.

00:11:38.260 --> 00:11:40.380
A gép feldolgozza az adatokat,

00:11:41.140 --> 00:11:42.876
valószínűségeket számol,

00:11:42.900 --> 00:11:46.556
eléri a 80%-os, majd 90%-os pontosságot,

00:11:46.580 --> 00:11:50.956
az emberi oldalnak elemzésre

00:11:50.980 --> 00:11:53.580
és döntés-előkészítésre
alkalmassá teszi őket.

00:11:54.100 --> 00:11:58.940
De senki sem küldi gyerekét iskolába

00:11:59.820 --> 00:12:03.380
90%-os pontosságú vezető nélküli kocsival,

00:12:04.420 --> 00:12:06.020
de még 99%-ossal sem.

00:12:07.380 --> 00:12:10.236
Nagyot kell még ugranunk előre,

00:12:10.260 --> 00:12:16.420
hogy pár tizedes értékkel javuljunk.

00:12:18.980 --> 00:12:22.990
A Deep Blue-val vívott
második mérkőzésem után

00:12:24.020 --> 00:12:25.636
20 évvel

00:12:25.660 --> 00:12:31.956
a szenzációhajhász szalagcím:
"Az agy utolsó védvonala"

00:12:31.980 --> 00:12:33.556
közhellyé vált,

00:12:33.580 --> 00:12:36.116
ahogy az intelligens gépek

00:12:36.140 --> 00:12:37.340
behatolnak

00:12:38.380 --> 00:12:40.580
minden ágazatba, úgyszólván nap mint nap.

00:12:41.980 --> 00:12:45.076
De a múlttól eltérően,

00:12:45.100 --> 00:12:46.740
amikor a gépek az igavonó állatot

00:12:48.300 --> 00:12:50.676
és a kétkezi munkát helyettesítették,

00:12:50.700 --> 00:12:53.196
most a diplomásokat

00:12:53.220 --> 00:12:54.690
és a politikusokat fenyegetik.

00:12:55.940 --> 00:12:58.036
Mint aki gép ellen küzdött és vesztett,

00:12:58.060 --> 00:13:00.700
azt mondom önöknek, hogy ez kiváló hír.

00:13:02.820 --> 00:13:05.036
Végtére is, minden szakmának

00:13:05.060 --> 00:13:07.156
el kell viselnie ezt a nyomást,

00:13:07.180 --> 00:13:12.780
különben az emberiség
fejlődése megrekedne.

00:13:14.580 --> 00:13:15.780
Nem mi

00:13:17.260 --> 00:13:18.980
választjuk meg,

00:13:20.300 --> 00:13:23.020
mikor és hol áll meg a fejlődés.

00:13:24.980 --> 00:13:26.340
Nincs lehetőségünk

00:13:27.780 --> 00:13:29.276
lelassítani.

00:13:29.300 --> 00:13:31.116
Valójában,

00:13:31.140 --> 00:13:33.060
ideje fölgyorsulnunk.

00:13:36.420 --> 00:13:39.060
Technológiánk pompásan boldogul

00:13:41.020 --> 00:13:44.380
életünk nehézségeinek
s kockázatainak leküzdésével,

00:13:46.820 --> 00:13:49.636
ezért még bonyolultabb,

00:13:49.660 --> 00:13:51.516
még kockázatosabb feladatokat

00:13:51.540 --> 00:13:55.620
kell találnunk magunknak.

00:14:00.020 --> 00:14:01.220
A gépek

00:14:03.700 --> 00:14:05.450
tudnak számolni.

00:14:05.450 --> 00:14:07.216
Nekünk megvan
az értelmi képességünk.

00:14:07.216 --> 00:14:09.180
A gépek utasításokat kapnak.

00:14:10.660 --> 00:14:12.516
Nekünk célunk van.

00:14:12.540 --> 00:14:14.820
A gépek

00:14:16.900 --> 00:14:18.116
objektívak.

00:14:18.140 --> 00:14:19.550
Mi szenvedélyesek vagyunk.

00:14:20.420 --> 00:14:26.396
Ne izguljunk amiatt,
amire gépeink ma képesek.

00:14:26.420 --> 00:14:30.996
Inkább azon izguljunk,
amire ma még nem képesek,

00:14:31.020 --> 00:14:36.516
mert szükségünk lesz új, 
intelligens gépek segítségére

00:14:36.540 --> 00:14:40.620
legmerészebb álmaink valóra váltásához.

00:14:41.820 --> 00:14:43.140
Ha kudarcot vallunk,

00:14:44.060 --> 00:14:48.716
ha mégis kudarcot vallunk, nem azért lesz,
mert gépeink túl intelligensek,

00:14:48.740 --> 00:14:50.140
vagy nem elég intelligensek.

00:14:51.020 --> 00:14:54.100
Ha kudarcot vallunk, annak oka,
hogy önteltté váltunk,

00:14:55.500 --> 00:14:57.060
és fékeztük becsvágyunkat.

00:14:58.340 --> 00:15:01.380
Emberi mivoltunkat nem
készségeink határozzák meg,

00:15:03.100 --> 00:15:05.780
mint pl. a pörölycsapás vagy a sakkozás.

00:15:06.380 --> 00:15:09.396
Egy dologra csak ember képes.

00:15:09.420 --> 00:15:10.620
Ez az álmodozás.

00:15:11.940 --> 00:15:14.476
Álmodjunk nagyot!

00:15:14.500 --> 00:15:15.716
Köszönöm.

00:15:15.740 --> 00:15:19.627
(Taps)

