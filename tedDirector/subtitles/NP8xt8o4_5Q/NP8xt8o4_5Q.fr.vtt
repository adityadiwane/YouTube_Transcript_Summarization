WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: América Aguilera
Relecteur: Lucie Langevin

00:00:12.780 --> 00:00:15.756
Cette histoire commence en 1985

00:00:15.780 --> 00:00:17.756
quand, à l'âge de 22 ans,

00:00:17.780 --> 00:00:20.156
je suis devenu champion du monde d'échecs

00:00:20.180 --> 00:00:23.380
en battant Anatoly Karpov.

00:00:24.300 --> 00:00:25.556
Plus tôt cette même année,

00:00:25.580 --> 00:00:29.196
j'ai participé à ce qu'on appelle
une série de parties simultanées

00:00:29.220 --> 00:00:33.516
contre 32 des machines joueuses d'échecs
les plus performantes

00:00:33.540 --> 00:00:34.900
à Hambourg.

00:00:35.980 --> 00:00:37.180
Je les ai toutes gagnées

00:00:38.380 --> 00:00:41.556
et à l'époque,
ça n'avait rien de surprenant

00:00:41.580 --> 00:00:45.620
que je puisse battre 32 ordinateurs
simultanément.

00:00:46.300 --> 00:00:48.876
Ah, pour moi, c'était l'âge d'or.

00:00:48.900 --> 00:00:50.996
(Rires)

00:00:51.020 --> 00:00:53.000
Les machines avaient
peu de puissance

00:00:53.500 --> 00:00:54.836
et moi, j'avais des cheveux.

00:00:54.860 --> 00:00:57.060
(Rires)

00:00:58.540 --> 00:01:00.596
Douze ans plus tard seulement,

00:01:00.620 --> 00:01:05.236
je me retrouvais à m'échiner contre
un seul ordinateur

00:01:05.260 --> 00:01:06.460
dans une partie,

00:01:07.180 --> 00:01:09.236
surnommée en couverture de Newsweek,

00:01:09.260 --> 00:01:11.036
« le dernier combat du cerveau ».

00:01:11.060 --> 00:01:12.276
Pas de pression, donc.

00:01:12.300 --> 00:01:13.820
(Rires)

00:01:14.860 --> 00:01:17.436
De la mythologie à la science-fiction,

00:01:17.460 --> 00:01:20.196
l'affrontement de l'humain
et de la machine

00:01:20.220 --> 00:01:22.980
a souvent été vu comme
une question de vie ou de mort.

00:01:23.780 --> 00:01:25.356
John Henry,

00:01:25.380 --> 00:01:27.076
qu'on appelle le pousseur d'acier

00:01:27.100 --> 00:01:30.876
dans la légende folklorique
afro-américaine du XIXème siècle,

00:01:30.900 --> 00:01:32.276
s'est mesuré, pour un pari,

00:01:32.300 --> 00:01:35.036
à un marteau à vapeur

00:01:35.060 --> 00:01:37.420
pour creuser
un tunnel dans la roche.

00:01:38.620 --> 00:01:42.820
La légende de John Henry appartient
à un corps plus large de récits

00:01:43.500 --> 00:01:46.580
qui oppose l'humanité à la technologie.

00:01:48.020 --> 00:01:50.900
Cette rhétorique de la compétition
est monnaie courante.

00:01:51.380 --> 00:01:53.340
Nous faisons la course
contre les machines

00:01:54.180 --> 00:01:56.260
ou nous menons un combat
ou même une guerre.

00:01:57.700 --> 00:01:59.316
Des emplois disparaissent.

00:01:59.340 --> 00:02:02.900
Des gens sont remplacés comme
s'ils n'avaient jamais existé.

00:02:04.060 --> 00:02:07.556
Il y a de quoi penser que des films comme
« Terminator » ou « Matrix »

00:02:07.580 --> 00:02:08.780
sont du documentaire.

00:02:11.460 --> 00:02:15.780
Il y a très peu d'exemples de domaines

00:02:17.180 --> 00:02:21.436
où le corps et l'esprit humain
peuvent être à égalité

00:02:21.459 --> 00:02:23.300
avec un ordinateur ou un robot.

00:02:24.100 --> 00:02:25.958
J'aimerais en fait qu'il y en ait plus.

00:02:27.580 --> 00:02:28.780
Au lieu de ça,

00:02:29.660 --> 00:02:34.316
ça a été une bénédiction
et une malédiction pour moi

00:02:34.340 --> 00:02:37.036
de devenir précisément ce fameux homme

00:02:37.060 --> 00:02:40.156
dans cette compétition entre l'homme
et la machine

00:02:40.180 --> 00:02:42.150
dont tout le monde parle encore.

00:02:44.940 --> 00:02:49.956
Lors de l'affrontement homme-machine
le plus célèbre depuis John Henry,

00:02:49.980 --> 00:02:52.556
j'ai joué deux séries de parties

00:02:52.580 --> 00:02:56.020
contre le superordinateur d'IBM Deep Blue.

00:02:58.860 --> 00:03:01.436
On ne se souvient jamais
que j'ai gagné la première...

00:03:01.436 --> 00:03:03.396
(Rires)

00:03:03.420 --> 00:03:06.820
(Applaudissements)

00:03:07.740 --> 00:03:12.716
à Philadelphie, avant de perdre
la revanche en 1997 à New York.

00:03:12.740 --> 00:03:14.680
Mais bon, ce n'est que justice.

00:03:16.140 --> 00:03:21.236
Il n'y a pas de date anniversaire,
de jour spécial au calendrier

00:03:21.260 --> 00:03:24.756
pour tous les gens qui n'ont pas réussi
à escalader l'Everest

00:03:24.780 --> 00:03:27.516
avant que Sir Edmund Hillary
et Tenzing Norgay

00:03:27.540 --> 00:03:29.170
ne parviennent au sommet.

00:03:29.780 --> 00:03:33.540
Et en 1997, j'étais toujours
champion du monde

00:03:36.340 --> 00:03:40.540
quand les ordinateurs d'échecs
sont enfin arrivés à maturité.

00:03:41.340 --> 00:03:43.316
Le mont Everest, c'était moi,

00:03:43.340 --> 00:03:44.940
et Deep Blue a atteint le sommet.

00:03:46.420 --> 00:03:50.476
Bien sûr, je ferais mieux de dire,
non pas que Deep Blue a fait ça,

00:03:50.500 --> 00:03:52.636
mais ses créateurs humains :

00:03:52.660 --> 00:03:55.996
Anantharaman, Campbell, Hoane, Hsu.

00:03:56.020 --> 00:03:57.590
Je leur tire mon chapeau.

00:03:58.660 --> 00:04:03.076
Comme toujours, le triomphe des machines
fut le triomphe des hommes.

00:04:03.100 --> 00:04:07.860
Nous sommes enclins à l'oublier quand les
humains sont surpassés par leur création.

00:04:10.180 --> 00:04:12.150
Deep Blue a remporté la victoire,

00:04:12.960 --> 00:04:14.420
mais était-il intelligent ?

00:04:15.180 --> 00:04:16.940
Non, il ne l'était pas,

00:04:18.020 --> 00:04:23.076
du moins pas de la façon dont Alan Turing
et d'autres fondateurs de l'informatique

00:04:23.100 --> 00:04:24.300
l'avaient espéré.

00:04:25.060 --> 00:04:29.836
Il s'est avéré que les échecs pouvaient
être dominés par de la force brute,

00:04:29.860 --> 00:04:34.116
une fois que le matériel informatique
est devenu assez rapide

00:04:34.140 --> 00:04:37.100
et que les algorithmes sont devenus
assez malins.

00:04:38.580 --> 00:04:42.276
Cependant, si l'on s'en tient
à ce qu'il produisait,

00:04:42.300 --> 00:04:45.516
du jeu d'échecs de niveau grand maître,

00:04:45.540 --> 00:04:47.200
Deep Blue était intelligent.

00:04:49.140 --> 00:04:51.540
Mais même à cette vitesse incroyable

00:04:52.380 --> 00:04:55.580
de 200 millions de positions par seconde,

00:04:57.180 --> 00:04:58.380
la méthode de Deep Blue

00:04:59.180 --> 00:05:05.780
ne permettait pas de percer le mystère de
l'intelligence humaine comme on en rêve.

00:05:08.780 --> 00:05:10.596
Bientôt,

00:05:10.620 --> 00:05:13.196
des machines seront chauffeurs de taxi,

00:05:13.220 --> 00:05:15.636
médecins et professeurs,

00:05:15.660 --> 00:05:18.260
mais seront-elles pour autant
« intelligentes » ?

00:05:19.660 --> 00:05:22.156
Je m'en remettrai pour ces définitions

00:05:22.180 --> 00:05:25.740
aux philosophes et au dictionnaire.

00:05:27.260 --> 00:05:31.140
Ce qui importe vraiment c'est ce que nous,
les humains,

00:05:32.140 --> 00:05:35.740
nous ressentons à vivre et à travailler
avec ces machines.

00:05:37.980 --> 00:05:43.236
Quand j'ai rencontré Deep Blue
pour la première fois en février 1996,

00:05:43.260 --> 00:05:46.260
cela faisait plus de dix ans que j'étais
champion du monde

00:05:47.900 --> 00:05:51.916
et j'avais disputé 182 parties
de championnat du monde

00:05:51.940 --> 00:05:57.036
et des centaines contre des joueurs
de haut niveau dans d'autres compétitions.

00:05:57.060 --> 00:06:02.116
Je savais à quoi m'attendre de la part
de mes adversaires

00:06:02.140 --> 00:06:03.820
et de moi-même.

00:06:04.500 --> 00:06:09.676
J'avais l'habitude de mesurer leurs coups

00:06:09.700 --> 00:06:13.316
et d'évaluer leur état emotionnel

00:06:13.340 --> 00:06:17.180
en observant leur gestuelle et
en les regardant dans les yeux.

00:06:17.700 --> 00:06:21.700
Et puis, me voilà assis de l'autre côté de
l'échiquier, face à Deep Blue.

00:06:24.780 --> 00:06:27.636
J'ai tout de suite ressenti
quelque chose de nouveau,

00:06:27.660 --> 00:06:28.980
de déstabilisant.

00:06:31.260 --> 00:06:34.060
Vous pourriez avoir la même sensation

00:06:35.140 --> 00:06:37.966
la première fois que vous prenez
une voiture sans conducteur

00:06:37.966 --> 00:06:42.540
ou la première fois que votre nouveau
chef-ordinateur vous donne un ordre.

00:06:45.620 --> 00:06:48.740
Mais quand je me suis assis pour jouer
cette première partie,

00:06:49.900 --> 00:06:52.036
je ne pouvais pas être sûr

00:06:52.060 --> 00:06:55.740
de ce dont cette chose était capable.

00:06:56.740 --> 00:06:59.900
La technologie avance à pas de géant et
IBM avait beaucoup investi.

00:07:00.500 --> 00:07:02.160
J'ai perdu cette partie.

00:07:04.140 --> 00:07:05.916
Et je ne pouvais m'empêcher de penser

00:07:05.940 --> 00:07:07.500
« peut-il être invincible ? »

00:07:08.420 --> 00:07:11.000
Était-ce la fin de ce jeu d'échecs
que j'aimais tant ?

00:07:12.620 --> 00:07:16.756
C'étaient là des inquiétudes et des peurs
toutes humaines,

00:07:16.780 --> 00:07:18.460
et la seule chose dont j'étais sûr,

00:07:19.220 --> 00:07:22.116
c'était que Deep Blue
n'avait pas de tels émois.

00:07:22.140 --> 00:07:23.900
(Rires)

00:07:25.740 --> 00:07:27.140
Je me suis battu

00:07:28.220 --> 00:07:29.900
après ce coup dur

00:07:30.820 --> 00:07:32.450
pour gagner la première série

00:07:32.780 --> 00:07:34.420
mais les dés étaient jetés.

00:07:36.220 --> 00:07:38.356
J'ai finalement perdu contre la machine

00:07:38.380 --> 00:07:41.436
mais je n'ai pas souffert le même sort
que John Henry

00:07:41.460 --> 00:07:44.500
qui gagna mais mourut
le marteau à la main.

00:07:49.540 --> 00:07:52.076
En fait, le monde des échecs

00:07:52.100 --> 00:07:55.340
voulait toujours avoir un champion humain.

00:07:56.740 --> 00:07:58.420
Et aujourd'hui encore,

00:07:59.900 --> 00:08:03.356
quand une application gratuite
de jeu d'échecs pour portable dernier cri

00:08:03.380 --> 00:08:05.396
est plus performante que Deep Blue,

00:08:05.420 --> 00:08:07.450
les gens jouent toujours aux échecs,

00:08:08.500 --> 00:08:10.740
et même plus qu'avant.

00:08:11.620 --> 00:08:14.836
Les alarmistes avaient prédit que
tout le monde déserterait ce jeu

00:08:14.860 --> 00:08:17.116
qui pouvait être conquis par les machines,

00:08:17.140 --> 00:08:19.356
et ils ont eu tort,
on le voit bien,

00:08:19.380 --> 00:08:22.836
mais jouer les alarmistes est
un passe-temps populaire

00:08:22.860 --> 00:08:24.520
en matière de technologie.

00:08:26.180 --> 00:08:28.916
Ce que m'a appris
mon expérience personnelle,

00:08:28.940 --> 00:08:33.596
c'est qu'il nous faut affronter nos peurs

00:08:33.620 --> 00:08:37.340
si nous voulons tirer le meilleur parti
de notre technologie,

00:08:38.180 --> 00:08:40.556
et nous devons dépasser ces peurs

00:08:40.580 --> 00:08:45.820
si nous voulons obtenir le meilleur de
ce que l'humanité peut donner.

00:08:47.940 --> 00:08:49.715
Tout en me remettant de ma défaite,

00:08:49.739 --> 00:08:51.700
j'ai été très inspiré

00:08:52.900 --> 00:08:55.595
par mes affrontements avec Deep Blue.

00:08:55.619 --> 00:08:59.240
Comme le dit ce proverbe russe :
si on ne peut les vaincre, rejoignons-les.

00:09:00.700 --> 00:09:02.076
Et puis, je me suis dit,

00:09:02.100 --> 00:09:04.436
et si je pouvais jouer
avec un ordinateur...

00:09:04.460 --> 00:09:07.620
avec un ordinateur à mes côtés,
en combinant nos forces,

00:09:08.980 --> 00:09:12.756
l'intuition humaine et la capacité
de calcul de la machine,

00:09:12.780 --> 00:09:15.476
la stratégie humaine,
la tactique de la machine,

00:09:15.500 --> 00:09:17.916
l'expérience humaine,
la mémoire de la machine.

00:09:17.940 --> 00:09:20.770
Serait-ce la partie la plus parfaite
jamais jouée ?

00:09:21.820 --> 00:09:23.590
Mon idée est devenue réalité

00:09:24.740 --> 00:09:28.116
en 1998, sous le nom d'Advanced Chess,

00:09:28.140 --> 00:09:34.010
quand j'ai disputé cette compétition
humain/machine contre un joueur d'élite.

00:09:35.100 --> 00:09:36.996
Mais lors de ce premier essai,

00:09:37.020 --> 00:09:43.380
nous avons tous les deux échoué à associer
efficacement nos savoir-faire propres.

00:09:46.740 --> 00:09:48.980
L'Advanced Chess a trouvé
sa place sur internet

00:09:49.980 --> 00:09:54.836
et en 2005, un tournoi d'échecs
« freestyle »

00:09:54.860 --> 00:09:56.220
a été une révélation.

00:09:59.060 --> 00:10:02.596
Une équipe de grands maîtres et
de machines de haut niveau participèrent,

00:10:02.620 --> 00:10:05.356
mais les gagnants ne furent
ni les grands maîtres,

00:10:05.380 --> 00:10:06.740
ni un superordinateur.

00:10:07.500 --> 00:10:11.836
Les gagnants furent un duo
de joueurs amateurs américains

00:10:11.860 --> 00:10:15.020
qui contrôlaient trois PC ordinaires
à la fois.

00:10:17.380 --> 00:10:20.396
Leur talent à accompagner leurs machines

00:10:20.420 --> 00:10:26.196
a de fait contrecarré le savoir supérieur
du jeu d'échecs

00:10:26.220 --> 00:10:27.796
des grands maîtres face à eux

00:10:27.820 --> 00:10:31.980
et le pouvoir informatique bien plus grand
d'autres personnes.

00:10:33.420 --> 00:10:35.380
Et j'en suis venu à cette idée :

00:10:36.380 --> 00:10:39.756
un humain de faible niveau
auquel s'ajoute une machine

00:10:39.780 --> 00:10:43.036
et une meilleure méthode est supérieur

00:10:43.060 --> 00:10:45.476
à une machine très puissante seule,

00:10:45.500 --> 00:10:49.396
mais plus remarquable encore,
il est supérieur à un joueur humain fort

00:10:49.420 --> 00:10:51.380
auquel s'ajoute une machine

00:10:52.940 --> 00:10:55.340
et une méthode inférieure.

00:10:58.180 --> 00:11:00.300
Cela m'a convaincu qu'on aurait besoin

00:11:01.820 --> 00:11:05.500
de meilleures interfaces pour aider
à l'accompagnement des machines

00:11:06.340 --> 00:11:08.260
et rendre cette intelligence plus utile.

00:11:10.140 --> 00:11:13.436
L'humain plus la machine,
ce n'est pas l'avenir,

00:11:13.460 --> 00:11:14.676
c'est notre présent.

00:11:14.700 --> 00:11:18.836
Tout le monde a déjà utilisé
des outils de traduction en ligne

00:11:18.860 --> 00:11:23.156
pour comprendre les grandes lignes
d'un article de presse étrangère

00:11:23.180 --> 00:11:24.820
malgré leurs imperfections.

00:11:25.500 --> 00:11:27.596
Nous utilisons après notre
expérience humaine

00:11:27.620 --> 00:11:29.716
pour faire sens de tout ça,

00:11:29.740 --> 00:11:32.516
et puis la machine apprend
de nos rectifications.

00:11:32.540 --> 00:11:38.030
Ce modèle se développe en diagnostic
médical et en analyse de sécurité.

00:11:38.260 --> 00:11:40.380
La machine analyse des données,

00:11:41.140 --> 00:11:42.876
calcule des probabilités,

00:11:42.900 --> 00:11:46.556
fait 80 ou 90% du chemin,

00:11:46.580 --> 00:11:50.956
ce qui facilite l'analyse

00:11:50.980 --> 00:11:53.580
et la prise de décision humaines.

00:11:54.100 --> 00:11:58.940
Mais vous n'allez pas
envoyer vos enfants

00:11:59.820 --> 00:12:03.380
à l'école dans une voiture sans conducteur
fiable à 90%

00:12:04.420 --> 00:12:06.020
ou même à 99%.

00:12:07.380 --> 00:12:10.236
Nous avons donc besoin
d'une grande avancée

00:12:10.260 --> 00:12:16.420
pour gagner encore
quelques décimales cruciales.

00:12:18.980 --> 00:12:23.020
Vingt ans après ma série de parties
contre Deep Blue,

00:12:24.020 --> 00:12:25.636
la deuxième,

00:12:25.660 --> 00:12:31.956
ce gros titre sensationnaliste,
« le dernier combat du cerveau »,

00:12:31.980 --> 00:12:33.556
est omniprésent

00:12:33.580 --> 00:12:36.116
à l'heure où les machines intelligentes

00:12:36.140 --> 00:12:37.340
s'invitent

00:12:38.380 --> 00:12:40.830
dans tous les secteurs d'activité
tous les jours.

00:12:41.980 --> 00:12:45.076
Mais là où par le passé

00:12:45.100 --> 00:12:46.740
les machines ont remplacé

00:12:48.300 --> 00:12:50.676
le bétail, le travail manuel,

00:12:50.700 --> 00:12:53.196
de nos jours, elles s'attaquent
à des diplômés

00:12:53.220 --> 00:12:55.840
ou des personnes politiquement influentes.

00:12:55.840 --> 00:12:58.326
En tant que personne
qui les a combattues et a perdu,

00:12:58.326 --> 00:13:00.930
je suis là pour dire que
c'est une excellente nouvelle.

00:13:02.820 --> 00:13:05.036
Un jour, toutes les professions

00:13:05.060 --> 00:13:07.156
devront faire face à cette pression

00:13:07.180 --> 00:13:12.780
ou bien cela voudra dire que l'humanité
a cessé de progresser.

00:13:14.580 --> 00:13:15.850
Ce n'est pas à nous

00:13:17.260 --> 00:13:18.980
de choisir

00:13:20.300 --> 00:13:23.020
où et quand le progrès technologique
s'arrêtera.

00:13:24.980 --> 00:13:26.340
On ne peut pas

00:13:27.780 --> 00:13:29.276
ralentir.

00:13:29.300 --> 00:13:31.116
À vrai dire,

00:13:31.140 --> 00:13:33.060
nous devons accélérer.

00:13:36.420 --> 00:13:39.060
Notre technologie excelle
lorsqu'il s'agit d'effacer

00:13:41.020 --> 00:13:44.380
de nos vies difficultés et incertitudes,

00:13:46.820 --> 00:13:49.636
et nous devons donc partir à la recherche

00:13:49.660 --> 00:13:51.516
de défis plus grands,

00:13:51.540 --> 00:13:55.620
plus incertains encore.

00:14:00.020 --> 00:14:01.220
Les machines

00:14:03.700 --> 00:14:05.516
font des calculs.

00:14:05.540 --> 00:14:07.116
Nous comprenons les choses.

00:14:07.140 --> 00:14:09.180
Les machines reçoivent des instructions.

00:14:10.660 --> 00:14:12.516
Nous avons des buts.

00:14:12.540 --> 00:14:14.820
Les machines ont pour elles

00:14:16.900 --> 00:14:18.116
l'objectivité.

00:14:18.140 --> 00:14:19.340
Nous avons la passion.

00:14:20.420 --> 00:14:26.396
Nous ne devrions pas avoir peur de ce que
nos machines peuvent faire aujourd'hui.

00:14:26.420 --> 00:14:30.996
Nous devrions plutôt nous inquiéter de ce
qu'elles ne peuvent toujours pas faire

00:14:31.020 --> 00:14:36.516
car nous aurons besoin de l'aide
de ces nouvelles machines intelligentes

00:14:36.540 --> 00:14:40.620
pour faire de nos rêves les plus fous
une réalité.

00:14:41.820 --> 00:14:43.140
Et si nous échouons,

00:14:44.060 --> 00:14:48.716
si nous échouons, ce n'est pas parce que
nos machines sont trop intelligentes

00:14:48.740 --> 00:14:50.140
ou pas assez.

00:14:51.020 --> 00:14:54.100
Si nous échouons, c'est parce que
nous nous sommes laissés aller

00:14:55.500 --> 00:14:57.480
et avons rogné sur nos ambitions.

00:14:58.340 --> 00:15:01.380
Notre humanité n'est pas définie
par un savoir-faire quelconque,

00:15:03.100 --> 00:15:05.780
comme manier le marteau
ou même jouer aux échecs.

00:15:06.380 --> 00:15:09.396
L'humanité ne peut faire qu'une chose.

00:15:09.420 --> 00:15:10.620
Rêver.

00:15:11.940 --> 00:15:14.476
Alors faisons de grands rêves.

00:15:14.500 --> 00:15:15.716
Merci.

00:15:15.740 --> 00:15:19.627
(Applaudissements)

