WEBVTT
Kind: captions
Language: fa

00:00:00.000 --> 00:00:07.000
Translator: Maryam Manzoori
Reviewer: soheila Jafari

00:00:12.780 --> 00:00:15.756
این داستان در سال ۱۹۸۵ آغاز می شود،

00:00:15.780 --> 00:00:17.756
وقتی که در ۲۲ سالگی،

00:00:17.780 --> 00:00:20.156
قهرمان شطرنج جهان شدم،

00:00:20.180 --> 00:00:23.380
بعد از این که آناتولی کارپوو را شکست دادم.

00:00:24.300 --> 00:00:25.556
پیشتر در همان سال،

00:00:25.580 --> 00:00:29.196
یک تنه در مسابقه دسته جمعی همزمان 

00:00:29.220 --> 00:00:33.516
در مقابل ۳۲ تا از پیچیده ترین کامپیوترهای
شطرنج باز جهان بازی کردم

00:00:33.540 --> 00:00:34.900
در هامبورگ، آلمان،

00:00:35.980 --> 00:00:37.180
و همه آنها را بردم،

00:00:38.380 --> 00:00:41.556
ولی آن زمان کسی تعجب نکرد از این که

00:00:41.580 --> 00:00:45.620
من توانستم همزمان ۳۲ کامپیوتر را ببرم.

00:00:46.300 --> 00:00:48.876
برای من، آن زمان عصر عطلایی بود.

00:00:48.900 --> 00:00:50.996
(خنده حاضران)

00:00:51.020 --> 00:00:52.540
کامیپوترها ضعیف بودند،

00:00:53.500 --> 00:00:54.836
و موهای من پرپشت بود.

00:00:54.860 --> 00:00:57.060
(خنده حاضران)

00:00:58.540 --> 00:01:00.596
فقط ۱۲ سال بعد،

00:01:00.620 --> 00:01:05.236
در مقابل تنها یک کامپیوتر
برای زندگی ام مبارزه می کردم

00:01:05.260 --> 00:01:06.460
در یک مسابقه

00:01:07.180 --> 00:01:09.236
که مجله نیوزویک اسمش را گذاشت

00:01:09.260 --> 00:01:11.036
«آخرین مقاومت مغز.»

00:01:11.060 --> 00:01:12.276
بدون هیچ فشاری.

00:01:12.300 --> 00:01:13.820
(خنده حاضران)

00:01:14.860 --> 00:01:17.436
از اسطوره شناسی تا داستان های علمی تخیلی،

00:01:17.460 --> 00:01:20.196
انسان در مقابل ماشین

00:01:20.220 --> 00:01:22.980
اغلب به عنوان مسئله مرگ و زندگی 
تصویر شده است.

00:01:23.780 --> 00:01:25.356
جان هنری،

00:01:25.380 --> 00:01:27.076
موسوم به مرد کوه کن

00:01:27.100 --> 00:01:30.876
در افسانه فولک آفریقایی-آمریکایی قرن ۱۹

00:01:30.900 --> 00:01:32.276
در یک مسابقه شرکت داده شد

00:01:32.300 --> 00:01:35.036
در مقابل یک چکش که
با نیروی بخار کار می کرد

00:01:35.060 --> 00:01:37.420
تا تونلی در یک کوه صخره ای بکنند.

00:01:38.620 --> 00:01:42.820
افسانه جان هنری 
بخشی از یک روایت تاریخی طولانی است

00:01:43.500 --> 00:01:46.580
که بشریت و تکنولوژی را به مصاف می کشد.

00:01:48.020 --> 00:01:50.900
و این اندیشه حریف طلب اکنون استاندارد است.

00:01:51.380 --> 00:01:53.340
ما در مسابقه در مقابل
ماشین آلات به سر می بریم.

00:01:54.180 --> 00:01:56.260
در نبرد یا حتی در جنگ.

00:01:57.700 --> 00:01:59.316
مشاغل را از بین می برند.

00:01:59.340 --> 00:02:02.900
افراد با ماشین جایگزین می شوند
گویی که از روی کره زمین غیب شده اند.

00:02:04.060 --> 00:02:07.556
کافی است که فکر کنیم فیلم هایی چون 
«ترمیناتور» یا «متریکس»

00:02:07.580 --> 00:02:08.780
تخیلی نیستند.

00:02:11.460 --> 00:02:15.780
در چندین مورد انگشت شمار

00:02:17.180 --> 00:02:21.436
بدن انسان و مغز در موقعیتی برابر 
می تواند رقابت کند 

00:02:21.459 --> 00:02:23.300
با یک کامپیوتر یا ربات.

00:02:24.100 --> 00:02:25.958
در واقع، ای کاش موارد
بیشتری از این دست وجود داشت.

00:02:27.580 --> 00:02:28.780
در عوض،

00:02:29.660 --> 00:02:34.316
این از خوشبختی و یا بدشانسی من است

00:02:34.340 --> 00:02:37.036
که به معنای واقعی به ضرب المثلی تبدیل شوم

00:02:37.060 --> 00:02:40.156
که مصداق رقابت انسان و ماشین است

00:02:40.180 --> 00:02:42.060
که هنوز که هنوز است 
همه درباره اش حرف می زنند.

00:02:44.940 --> 00:02:49.956
در مشهورترین هماورد انسان-ماشین
از زمان جان هنری به بعد،

00:02:49.980 --> 00:02:52.556
من در دو مسابقه شرکت کردم

00:02:52.580 --> 00:02:56.020
در مقابل ابرکامپیوتر آی.بی.ام ،
به نام دیپ بلو.

00:02:58.860 --> 00:03:01.036
کسی یادش نیست که مسابقه اول را من بردم --

00:03:01.060 --> 00:03:03.396
(خنده حاضران)

00:03:03.420 --> 00:03:06.820
(تشویق حاضران)

00:03:07.740 --> 00:03:12.716
در فیلادلفیا، قبل از آن که سال بعد 
در بازی برگشت در نیویورک به کامپیوتر ببازم.

00:03:12.740 --> 00:03:14.500
اما گمان می کنم منصفانه باشد.

00:03:16.140 --> 00:03:21.236
در تاریخ هیچ روزی در تقویم
به نام کسانی نشده که

00:03:21.260 --> 00:03:24.756
تلاش کردند اورست را فتح کنند و نتوانستند

00:03:24.780 --> 00:03:27.516
تا این که سر ادموند هیلاری و تنزینگ نورگای

00:03:27.540 --> 00:03:28.740
فتحش کردند.

00:03:29.780 --> 00:03:33.540
و در ۱۹۹۷، من همچنان قهرمان بودم

00:03:36.340 --> 00:03:40.540
تا وقتی که کامپیوترهای
شطرنج بالاخره پیشرفته شدند.

00:03:41.340 --> 00:03:43.316
من کوه اورست بودم.

00:03:43.340 --> 00:03:44.940
و دیپ بلو به آن قله رسید.

00:03:46.420 --> 00:03:50.476
البته باید بگویم که این کار دیپ بلو نبود،

00:03:50.500 --> 00:03:52.636
بلکه کار خالقان آن بود --

00:03:52.660 --> 00:03:55.996
آنانتارامان، کمپبل، هوآن، سو.

00:03:56.020 --> 00:03:57.220
به احترامشان کلاه از سر برمیدارم.

00:03:58.660 --> 00:04:03.076
مانند همیشه، پیروزی ماشین
پیروزی انسان بود،

00:04:03.100 --> 00:04:07.860
همان چیزی که وقتی انسان توسط مخلوقات
خودش مغلوب می شوداغلب یادمان می رود.

00:04:10.180 --> 00:04:11.620
دیپ بلو فاتح بود،

00:04:13.220 --> 00:04:14.420
اما آیا هوشمند هم بود؟

00:04:15.180 --> 00:04:16.940
نه، نبود.

00:04:18.020 --> 00:04:23.076
دستکم نه به آن اندازه که الن تورینگ 
و دیگر خالقان علوم کامپیوتر 

00:04:23.100 --> 00:04:24.300
امیدش را داشتند.

00:04:25.060 --> 00:04:29.836
معلوم شد که شطرنج می تواند توسط 
یک نیروی فاقد شعور درهم شکسته شود،

00:04:29.860 --> 00:04:34.116
وقتی که سخت افزار به اندازه کافی سریع

00:04:34.140 --> 00:04:37.100
و الگوریتم ها هوشمند شدند.

00:04:38.580 --> 00:04:42.276
هرچند از نظر تعریف محصول،

00:04:42.300 --> 00:04:45.516
شطرنج در سطح قهرمانی،

00:04:45.540 --> 00:04:46.820
دیپ بلو هوشمند بود.

00:04:49.140 --> 00:04:51.540
اما در آن سرعت مافوق تصور،

00:04:52.380 --> 00:04:55.580
۲۰۰ میلیون پوزیشن در ثانیه،

00:04:57.180 --> 00:04:58.380
روش دیپ بلو

00:04:59.180 --> 00:05:05.780
نقش اندکی در روشنگری مطلوب 
از اسرار هوش انسان ارائه داد.

00:05:08.780 --> 00:05:10.596
به زودی،

00:05:10.620 --> 00:05:13.196
ماشین ها تاکسی می رانند

00:05:13.220 --> 00:05:15.636
و دکتر و پرفسور خواهند شد،

00:05:15.660 --> 00:05:18.260
اما آیا «هوشمند» هم خواهند بود؟

00:05:19.660 --> 00:05:22.156
ترجیح می دهم این تعاریف را واگذار کنم

00:05:22.180 --> 00:05:25.740
برعهده فیلسوف ها و فرهنگ لغات.

00:05:27.260 --> 00:05:31.140
آنچه مهم است این است که ما انسان ها

00:05:32.140 --> 00:05:35.740
چه احساسی داریم درباره
زندگی و کار با این کامپیوترها.

00:05:37.980 --> 00:05:43.236
اولین بار که در سال ۱۹۹۶ دیپ بلو را دیدم ،

00:05:43.260 --> 00:05:45.860
برای ده سال بود که قهرمان جهان بودم،

00:05:47.900 --> 00:05:51.916
و در ۱۸۲ مسابقه قهرمانی جهان 
بازی کرده بودم

00:05:51.940 --> 00:05:57.036
و در صدها مسابقه در مقابل دیگر شطرنج بازان 
در رقابت های دیگر داشتم.

00:05:57.060 --> 00:06:02.116
می دانستم که از حریفانم
چه انتظاری باید داشته باشم

00:06:02.140 --> 00:06:03.820
و از خودم چه انتظاری داشته باشم.

00:06:04.500 --> 00:06:09.676
حرکات آنان را می سنجیدم

00:06:09.700 --> 00:06:13.316
و وضع روحی شان را محک می زدم

00:06:13.340 --> 00:06:17.180
ااز طریق نگاه کردن به 
زبان بدن و زل زدن به چشمانشان.

00:06:17.700 --> 00:06:21.700
بعد در مقابل صفحه شطرنج دیپ بلو نشستم.

00:06:24.780 --> 00:06:27.636
فورا چیزی جدید را حس کردم،

00:06:27.660 --> 00:06:28.980
چیزی که در جای خودش نبود.

00:06:31.260 --> 00:06:34.060
ممکن است همین حس به سراغتان بیاید

00:06:35.140 --> 00:06:37.676
در اولین باری که در
یک اتومبیل بدون راننده هستید

00:06:37.700 --> 00:06:42.540
یا اولین باری که مدیر کامپیوتری شما
در سر کار به شما دستور می دهد.

00:06:45.620 --> 00:06:48.740
ولی وقتی که سر اولین مسابقه نشستم،

00:06:49.900 --> 00:06:52.036
نمی دانستم

00:06:52.060 --> 00:06:55.740
که این ماشین چه قابلیتی دارد.

00:06:56.740 --> 00:06:59.900
تکنولوژی می تواند به سرعت پیشرفت کند، 
و آی.بی.ام در این راه سرمایه گذاری هنگفتی کرده بود.

00:07:00.500 --> 00:07:01.700
مسابقه را باختم.

00:07:04.140 --> 00:07:05.916
و از این فکر در نمی آمدم که 

00:07:05.940 --> 00:07:07.500
که آیا این ماشین شکست ناپذیر است؟

00:07:08.420 --> 00:07:10.780
آیا بازی محبوب من شطرنج،
به پایان رسیده است؟

00:07:12.620 --> 00:07:16.756
اینها همه شک های انسانی
و ترس های انسانی بود،

00:07:16.780 --> 00:07:18.460
و تنها چیزی که درباره اش اطمینان داشتم

00:07:19.220 --> 00:07:22.116
این بود که حریفم دیپ بلو اصلا و ابدا
چنین نگرانی هایی نداشت.

00:07:22.140 --> 00:07:23.900
(خنده حاضران)

00:07:25.740 --> 00:07:27.140
به مبارزه ادامه دادم

00:07:28.220 --> 00:07:29.900
بعد از این شکست ویران کننده

00:07:30.820 --> 00:07:32.020
و اولین دور مسابقه را ببرم،

00:07:32.780 --> 00:07:34.420
اما تقدیر از قبل تعیین شده بود.

00:07:36.220 --> 00:07:38.356
نهایتا مسابقه را به کامپیوتر باختم

00:07:38.380 --> 00:07:41.436
اما از سرنوشتی مشابه آنچه که برای
جان هنری رخ داد رنج نکشیدم

00:07:41.460 --> 00:07:44.500
که برد اما با چکشش در دست
جان باخت.

00:07:49.540 --> 00:07:52.076
اینطور از آب در آمد که 
جهان شطرنج

00:07:52.100 --> 00:07:55.340
هنوز می خواست قهرمان انسانی داشته باشد.

00:07:56.740 --> 00:07:58.420
و حتی امروز،

00:07:59.900 --> 00:08:03.356
که اپ مجانی شطرنج روی موبایل های مدل جدید

00:08:03.380 --> 00:08:05.396
از دیپ بلو قوی تر است،

00:08:05.420 --> 00:08:06.900
مردم کماکان شطرنج بازی می کنند،

00:08:08.500 --> 00:08:10.740
حتی بیشتر از قبل.

00:08:11.620 --> 00:08:14.836
بدبین ها پیش بینی کرده بودند که 
دیگر هیچکس دست به شطرنج نخواهد زد

00:08:14.860 --> 00:08:17.116
و این که کامپیوتر شطرنج را فتح خواهد کرد،

00:08:17.140 --> 00:08:19.356
اشتباه می کردند، ثابت شد
که اشتبا می کردند،

00:08:19.380 --> 00:08:22.836
اما بدبینی همواره سرگرمی محبوبی بوده

00:08:22.860 --> 00:08:24.220
وقتی که پای تکنولوژی در میان است.

00:08:26.180 --> 00:08:28.916
آنچه که از تجربه ام آموختم 

00:08:28.940 --> 00:08:33.596
این است که باید با ترس هایمان مواجه شویم

00:08:33.620 --> 00:08:37.340
اگر که می خواهیم بیشترین استفاده را 
از تکنولوژی ببریم،

00:08:38.180 --> 00:08:40.556
و باید بر آن ترس ها غلبه کنیم

00:08:40.580 --> 00:08:45.820
اگر که می خواهیم از انسان بودنمان 
بیشترین استفاده را بکنیم.

00:08:47.940 --> 00:08:49.715
همانطور که زخم هایم را التیام می دادم،

00:08:49.739 --> 00:08:51.700
الهام های فراوانی به ذهنم خطور کرد

00:08:52.900 --> 00:08:55.595
از مبارزه هایم در مقابل دیپ بلو.

00:08:55.619 --> 00:08:58.740
یک ضرب المثل قدیمی روسی می گوید، 
اگر نمی توانی شکستشان دهی، به آنها بپیوند.

00:09:00.700 --> 00:09:02.076
بعد فکر کردم،

00:09:02.100 --> 00:09:04.436
چطور می شود که با یک کامپیوتر بازی کنم --

00:09:04.460 --> 00:09:07.620
و یک کامپیوتر هم بغل دست خودم باشد، 
تا زورمان را روی هم بگذاریم،

00:09:08.980 --> 00:09:12.756
دریافت انسانی، به علاوه قدرت محاسبه کامپوتر،

00:09:12.780 --> 00:09:15.476
استراتژی انسانی، تاکتیک کامپوتری،

00:09:15.500 --> 00:09:17.916
تجربه انسانی، حافظه کامپیوتری.

00:09:17.940 --> 00:09:20.140
آیا این می تواند بهترین مسابقه ای باشد
که تابه حال انجام شده؟

00:09:21.820 --> 00:09:23.500
ایده من محقق شد

00:09:24.740 --> 00:09:28.116
در ۱۹۹۸ تحت عنوان «شطرنج پیشرفته»

00:09:28.140 --> 00:09:33.820
وقتی که در یک مسابقه انسان به علاوه کامپیوتر
در مقابل یک شطرنج باز قهار بازی کردم.

00:09:35.100 --> 00:09:36.996
اما در این اولین تجربه،

00:09:37.020 --> 00:09:43.380
هر دوی ما از مخلوط کردن موثر 
مهارت های انسانی و کامپیوتری درماندیم.

00:09:46.740 --> 00:09:48.980
شطرنج پیشرفته جای خودش را 
روی اینترنت پیدا کرد،

00:09:49.980 --> 00:09:54.836
و در ۲۰۰۵ یک تورنمنت شطرنج آزاد

00:09:54.860 --> 00:09:56.220
پرده برداری کرد.

00:09:59.060 --> 00:10:02.596
تیمی متشکل از قهرمان های شطرنج 
و کامپیوترهای پیشرفته در مسابقه شرکت کردند،

00:10:02.620 --> 00:10:05.356
اما برنده نه استادان شطرنج بودند،

00:10:05.380 --> 00:10:06.740
و نه ابرکامپیوترها.

00:10:07.500 --> 00:10:11.836
برندگان یک جفت شطرنج باز
آماتور آمریکایی بودند

00:10:11.860 --> 00:10:15.020
که سه کامپیوتر عادی 
را توأمان اداره می کردند.

00:10:17.380 --> 00:10:20.396
مهارت آنها در کار با ماشین ها

00:10:20.420 --> 00:10:26.196
به شکل موثری در تضاد با دانش برتر شطرنج

00:10:26.220 --> 00:10:27.796
در قهرمانان حریفشان بود

00:10:27.820 --> 00:10:31.980
و بسیار بزرگتر بود از 
توان محاسبه دیگران.

00:10:33.420 --> 00:10:35.380
و به این فرمول رسیدم.

00:10:36.380 --> 00:10:39.756
یک شطرنج باز ضعیف به علاوه کامپیوتر

00:10:39.780 --> 00:10:43.036
به علاوه یک فرایند بهتر برتری دارد

00:10:43.060 --> 00:10:45.476
به یک ماشین بسیار قوی به تنهایی،

00:10:45.500 --> 00:10:49.396
اما مهمتر این است که 
برتری دارد به یک شطرنج باز قوی

00:10:49.420 --> 00:10:51.380
به علاوه کامپیوتر

00:10:52.940 --> 00:10:55.340
و فرایند ضعیف.

00:10:58.180 --> 00:11:00.300
این من را متقاعد کرد که ما نیاز داریم

00:11:01.820 --> 00:11:05.500
به حدفاصلی که به ما کمک کند 
کامپیوترهایمان را هدایت کنیم 

00:11:06.340 --> 00:11:08.060
به سوی هوشمندی مفیدتر.

00:11:10.140 --> 00:11:13.436
انسان به علاوه کامپیوتر آینده نیست،

00:11:13.460 --> 00:11:14.676
حال حاضر است.

00:11:14.700 --> 00:11:18.836
همه می دانند که با ترجمه آنلاین

00:11:18.860 --> 00:11:23.156
می توانند لب کلام را از
یک روزنامه خارجی دریابند،

00:11:23.180 --> 00:11:24.820
که زبانش را خوب بلد نیستند.

00:11:25.500 --> 00:11:27.596
بعد ما از تجربه انسانی خود بهره می بریم

00:11:27.620 --> 00:11:29.716
تا به ترجمه کامپیوتری منطق ببخشیم،

00:11:29.740 --> 00:11:32.516
و بعد ماشین از اصلاحات ما یاد می گیرد.

00:11:32.540 --> 00:11:37.500
این مدل در حال گسترش و سرمایه گذاری در بخش 
تشخیص پزشکی و همچنین تحلیل های امنیتی است.

00:11:38.260 --> 00:11:40.380
کامپیوتر داده های اطلاعاتی را بررسی میکند،

00:11:41.140 --> 00:11:42.876
احتمالات را محاسبه می کند،

00:11:42.900 --> 00:11:46.556
۸۰ تا ۹۰ درصد راه را می رود،

00:11:46.580 --> 00:11:50.956
کار را برای تحلیلگران

00:11:50.980 --> 00:11:53.580
و برای بخش تصمیم گیرنده انسانی،
راحت تر می کند.

00:11:54.100 --> 00:11:58.940
اما هیچکس بچه هایش را

00:11:59.820 --> 00:12:03.380
با ماشین های خودرانی که ۹۰ درصد دقیق هستند، 
به مدرسه نمی فرستد.

00:12:04.420 --> 00:12:06.020
حتی با دقت ۹۹ درصد.

00:12:07.380 --> 00:12:10.236
بنابراین ما به جهشی رو به جلو نیاز داریم

00:12:10.260 --> 00:12:16.420
تا این چند درصد باقیمانده 
در دقت را نیز اضافه کنیم.

00:12:18.980 --> 00:12:23.020
بیست سال بعد از 
مسابقه من با دیپ بلو،

00:12:24.020 --> 00:12:25.636
مسابقه دوم،

00:12:25.660 --> 00:12:31.956
این تیتر شورانگیز 
«آخرین سنگر مغز»

00:12:31.980 --> 00:12:33.556
مبتذل و تکراری شده

00:12:33.580 --> 00:12:36.116
چرا که کامپیوترهای هوشمند

00:12:36.140 --> 00:12:37.340
حرکت می کنند

00:12:38.380 --> 00:12:40.580
در هر ثانیه و هر روزه.

00:12:41.980 --> 00:12:45.076
اما برخلاف گذشته،

00:12:45.100 --> 00:12:46.740
حالا که ماشین آلات

00:12:48.300 --> 00:12:50.676
جای حیوانات مزرعه
و نیروی کار را گرفته اند،

00:12:50.700 --> 00:12:53.196
حالا دنبال افراد دارای مدرک دانشگاهی

00:12:53.220 --> 00:12:54.500
و دارای نفوذ سیاسی راه افتاده اند.

00:12:55.940 --> 00:12:58.036
و به عنوان کسی که با
کامپیوتر مبارزه کرد و باخت،

00:12:58.060 --> 00:13:00.700
اینجا هستم تا به شما بگویم 
این یک خبر فوق العاده عالی است.

00:13:02.820 --> 00:13:05.036
در نهایت، هر حرفه ای

00:13:05.060 --> 00:13:07.156
این فشارها را حس خواهد کرد

00:13:07.180 --> 00:13:12.780
و در غیر این صورت به این معنی است که
بشریت از پیشرفت بازماند.

00:13:14.580 --> 00:13:15.780
با ما نیست

00:13:17.260 --> 00:13:18.980
تا انتخاب کنیم

00:13:20.300 --> 00:13:23.020
کی و کجا پیشرفت تکنولوژیک متوقف می شود.

00:13:24.980 --> 00:13:26.340
نمی توانیم

00:13:27.780 --> 00:13:29.276
سرعت را آهسته کنیم.

00:13:29.300 --> 00:13:31.116
در واقع ،

00:13:31.140 --> 00:13:33.060
باید سرعت را بالا ببریم.

00:13:36.420 --> 00:13:39.060
تکنولوژی ما عالی عمل می کند در از بین بردن

00:13:41.020 --> 00:13:44.380
مشکلات و تردیدها از زندگی مان،

00:13:46.820 --> 00:13:49.636
بنابراین باید

00:13:49.660 --> 00:13:51.516
دنبال گرفتاری های بیشتر بگردیم،

00:13:51.540 --> 00:13:55.620
و دنبال چالش های دشوارتر بگردیم.

00:14:00.020 --> 00:14:01.220
کامپیوتر

00:14:03.700 --> 00:14:05.516
قدرت محاسبه دارد.

00:14:05.540 --> 00:14:07.116
ما شعور داریم.

00:14:07.140 --> 00:14:09.180
کاپیوتر برنامه ریزی می شود.

00:14:10.660 --> 00:14:12.516
ما هدف داریم.

00:14:12.540 --> 00:14:14.820
کامپیوتر

00:14:16.900 --> 00:14:18.116
بی طرف است.

00:14:18.140 --> 00:14:19.340
ما شور و شوق داریم.

00:14:20.420 --> 00:14:26.396
نباید نگران توانایی های امروز کامپیوترها باشیم.

00:14:26.420 --> 00:14:30.996
در عوض، باید نگران این باشیم که 
هنوز از عهده چه کارهایی برنمی آیند،

00:14:31.020 --> 00:14:36.516
چرا که به کمک کامپیوترهای جدید و هوشمند 
نیاز خواهیم داشت

00:14:36.540 --> 00:14:40.620
تا بزرگترین آرزوهایمان
را به واقعیت بدل کنیم.

00:14:41.820 --> 00:14:43.140
و اگر شکست بخوریم،

00:14:44.060 --> 00:14:48.716
اگر شکست بخوریم، دلیلش این نیست که 
کامپیوترهایمان زیادی هوشمندند،

00:14:48.740 --> 00:14:50.140
یا به اندازه کافی هوشمند نیستند.

00:14:51.020 --> 00:14:54.100
اگر شکست بخوریم، از این روست که
به خودمان غره شده ایم

00:14:55.500 --> 00:14:57.060
و جاه طلبی مان را محدود کرده ایم.

00:14:58.340 --> 00:15:01.380
انسانیت ما با هیچ مهارتی
توضیح داده نمی شود،

00:15:03.100 --> 00:15:05.780
مهارتی مثل پرتاب چکش یا حتی شطرنج بازی.

00:15:06.380 --> 00:15:09.396
تنها یک چیز وجود دارد 
که بشر قادر به انجامش است.

00:15:09.420 --> 00:15:10.620
و آن رویا و خیال است.

00:15:11.940 --> 00:15:14.476
پس بیایید رویاهای بزرگ ببینیم.

00:15:14.500 --> 00:15:15.716
تشکر می کنم.

00:15:15.740 --> 00:15:19.627
(تشویق حاضران)

