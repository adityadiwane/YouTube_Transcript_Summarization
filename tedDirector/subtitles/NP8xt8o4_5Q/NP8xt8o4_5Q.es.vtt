WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Sebastian Betti
Revisor: Lidia Cámara de la Fuente

00:00:12.780 --> 00:00:15.756
Esta historia empieza en 1985,

00:00:15.780 --> 00:00:17.756
cuando a mis 22 años,

00:00:17.780 --> 00:00:20.156
gané el Campeonato Mundial de Ajedrez

00:00:20.180 --> 00:00:23.380
tras vencer a Anatoli Kárpov.

00:00:24.300 --> 00:00:25.556
A principios de ese año,

00:00:25.580 --> 00:00:29.196
jugué lo que se llama 
partidas simultáneas

00:00:29.220 --> 00:00:33.516
contra 32 de las mejores 
máquinas de ajedrez en el mundo

00:00:33.540 --> 00:00:34.900
en Hamburgo, Alemania.

00:00:35.980 --> 00:00:37.180
Gané todas,

00:00:38.380 --> 00:00:41.556
y no se consideró una gran sorpresa

00:00:41.580 --> 00:00:45.620
que pudiera ganarle a 32 computadoras
al mismo tiempo.

00:00:46.300 --> 00:00:48.876
Para mí, esa fue la edad de oro.

00:00:48.900 --> 00:00:50.996
(Risas)

00:00:51.020 --> 00:00:52.540
Las máquinas eran débiles,

00:00:53.500 --> 00:00:54.836
y mi cabello era fuerte.

00:00:54.860 --> 00:00:57.060
(Risas)

00:00:58.540 --> 00:01:00.596
Doce años después,

00:01:00.620 --> 00:01:05.236
luchaba a muerte contra una computadora

00:01:05.260 --> 00:01:06.460
en una partida

00:01:07.180 --> 00:01:09.236
llamada en la portada de "Newsweek"

00:01:09.260 --> 00:01:11.036
"El último combate del cerebro".

00:01:11.060 --> 00:01:12.276
Sin presión.

00:01:12.300 --> 00:01:13.820
(Risas)

00:01:14.860 --> 00:01:17.436
De la mitología a la ciencia ficción,

00:01:17.460 --> 00:01:20.196
el humano contra la máquina

00:01:20.220 --> 00:01:23.180
se ha retratado a menudo como
una cuestión de vida o muerte.

00:01:23.780 --> 00:01:25.356
John Henry,

00:01:25.380 --> 00:01:27.076
llamado el "martillo de acero"

00:01:27.100 --> 00:01:30.876
en la leyenda popular de EE.UU.
del siglo XIX,

00:01:30.900 --> 00:01:32.276
se enfrentó en una carrera

00:01:32.300 --> 00:01:35.036
contra un "martillo de vapor"

00:01:35.060 --> 00:01:37.750
perforando un túnel a través 
de la roca en la montaña.

00:01:38.620 --> 00:01:42.820
La leyenda de John Henry es parte
de una larga narrativa histórica

00:01:43.500 --> 00:01:46.580
que enfrenta a la humanidad
contra la tecnología.

00:01:48.020 --> 00:01:50.900
Y esa retórica competitiva
ahora es algo común.

00:01:51.380 --> 00:01:53.690
Estamos en una carrera 
contra las máquinas,

00:01:54.180 --> 00:01:56.260
en una lucha o incluso en una guerra.

00:01:57.700 --> 00:01:59.316
Los trabajos se están acabando.

00:01:59.340 --> 00:02:02.900
Se reemplaza a la gente como si 
hubieran desaparecido de la Tierra.

00:02:04.060 --> 00:02:07.556
Basta pensar que las películas
como "Terminador" o "Matrix",

00:02:07.580 --> 00:02:08.780
ya no son ficción.

00:02:11.460 --> 00:02:15.780
Hay muy pocas áreas

00:02:17.180 --> 00:02:21.436
en las que el cuerpo humano y la mente 
puedan competir de igual a igual

00:02:21.459 --> 00:02:23.300
con una computadora o un robot.

00:02:24.100 --> 00:02:26.768
En realidad, me gustaría 
que hubiera unas cuantas más.

00:02:27.580 --> 00:02:28.780
En cambio,

00:02:29.660 --> 00:02:34.316
fue tanto mi bendición 
como mi maldición

00:02:34.340 --> 00:02:37.036
literalmente convertirme 
en el hombre proverbial,

00:02:37.060 --> 00:02:40.156
en la lucha del hombre contra la máquina,

00:02:40.180 --> 00:02:42.570
de la que todavía hoy se sigue hablando.

00:02:44.940 --> 00:02:49.956
En el combate hombre-máquina 
más famoso desde la época de John Henry,

00:02:49.980 --> 00:02:52.556
jugué dos partidas

00:02:52.580 --> 00:02:56.020
contra Deep Blue, 
la supercomputadora de IBM.

00:02:58.860 --> 00:03:01.246
Nadie recuerda que yo gané 
la primer partida...

00:03:01.246 --> 00:03:03.396
(Risas)

00:03:03.420 --> 00:03:06.820
(Aplausos)

00:03:07.740 --> 00:03:12.716
en Filadelfia, antes de perder la revancha
al año siguiente, en Nueva York.

00:03:12.740 --> 00:03:14.500
Pero supongo que eso es justo.

00:03:16.140 --> 00:03:21.236
No hay día en la historia,
un día especial en el calendario,

00:03:21.260 --> 00:03:24.756
para cada persona que no llegó 
a la cima del Everest

00:03:24.780 --> 00:03:26.476
antes de que llegaran

00:03:26.477 --> 00:03:28.740
Sir Edmund Hillary y Tenzing Norgay.

00:03:29.780 --> 00:03:33.540
Y en 1997, yo todavía 
era el campeón del mundo

00:03:36.340 --> 00:03:40.540
cuando las computadoras de ajedrez 
llegaron finalmente a la mayoría de edad.

00:03:41.340 --> 00:03:43.316
Yo era el Everest,

00:03:43.340 --> 00:03:44.940
y Deep Blue llegó a la cima.

00:03:46.420 --> 00:03:50.476
Debo decir, por supuesto,
que no lo hizo Deep Blue,

00:03:50.500 --> 00:03:52.636
sino sus creadores humanos...

00:03:52.660 --> 00:03:55.996
Anantharaman, Campbell, Hoane, Hsu.

00:03:56.020 --> 00:03:57.690
Me quito el sombrero ante ellos.

00:03:58.660 --> 00:04:03.076
Como siempre, el triunfo de la máquina
fue un triunfo humano,

00:04:03.100 --> 00:04:07.860
algo que solemos olvidar si las máquinas 
superan a los humanos.

00:04:10.180 --> 00:04:11.620
Deep Blue tuvo la victoria,

00:04:13.220 --> 00:04:14.420
pero ¿era inteligente?

00:04:15.180 --> 00:04:16.940
No, no lo era,

00:04:18.020 --> 00:04:23.076
al menos no como esperaban 
Alan Turing y otros fundadores

00:04:23.100 --> 00:04:24.300
de la informática.

00:04:25.060 --> 00:04:29.836
Resultó que al ajedrez 
se le podía ganar por fuerza bruta,

00:04:29.860 --> 00:04:34.116
con un hardware suficientemente rápido

00:04:34.140 --> 00:04:37.100
y algoritmos suficientemente inteligentes.

00:04:38.580 --> 00:04:42.276
Aunque al ver el resultado que produjo,

00:04:42.300 --> 00:04:45.516
un ajedrez de nivel de gran maestro,

00:04:45.540 --> 00:04:46.820
Deep Blue era inteligente.

00:04:49.140 --> 00:04:51.540
Pero incluso con esa velocidad increíble,

00:04:52.380 --> 00:04:55.580
200 millones de posiciones por segundo,

00:04:57.180 --> 00:04:58.380
el método de Deep Blue

00:04:59.180 --> 00:05:05.780
no permitió penetrar el misterio de
la inteligencia humana como soñamos.

00:05:08.780 --> 00:05:10.596
Pronto,

00:05:10.620 --> 00:05:13.196
las máquinas serán taxistas,

00:05:13.220 --> 00:05:15.636
médicos y profesores,

00:05:15.660 --> 00:05:18.260
pero ¿serán "inteligentes"?

00:05:19.660 --> 00:05:22.156
Dejaría estas definiciones

00:05:22.180 --> 00:05:25.740
a los filósofos y al diccionario.

00:05:27.260 --> 00:05:31.140
Lo que realmente importa 
es cómo, como humanos,

00:05:32.140 --> 00:05:35.740
nos sentimos al vivir y trabajar 
con estas máquinas.

00:05:37.980 --> 00:05:43.236
Cuando conocí a Deep Blue 
en febrero de 1996,

00:05:43.260 --> 00:05:45.860
ya había sido campeón mundial 
durante más de 10 años,

00:05:47.900 --> 00:05:51.916
y había jugado 182 partidas
de campeonatos del mundo

00:05:51.940 --> 00:05:57.036
y cientos de partidas contra otros 
jugadores de alto nivel en otros torneos.

00:05:57.060 --> 00:06:02.116
Sabía qué esperar de mis oponentes

00:06:02.140 --> 00:06:03.820
y qué esperar de mí mismo.

00:06:04.500 --> 00:06:09.676
Estaba acostumbrado 
a medir sus movimientos

00:06:09.700 --> 00:06:13.316
y su estado emocional,

00:06:13.340 --> 00:06:17.180
a ver su lenguaje corporal
y a mirarlos a los ojos.

00:06:17.700 --> 00:06:21.700
Y luego me senté frente al tablero
de ajedrez de Deep Blue.

00:06:24.780 --> 00:06:27.636
De inmediato sentí algo nuevo,

00:06:27.660 --> 00:06:28.980
algo inquietante.

00:06:31.260 --> 00:06:34.060
Puede que sientan algo similar

00:06:35.140 --> 00:06:37.676
la primera vez que suban
a un auto sin conductor,

00:06:37.700 --> 00:06:42.540
o la primera vez que un gerente de TI
emita una orden en el trabajo.

00:06:45.620 --> 00:06:48.740
Pero en esa primera partida,

00:06:49.900 --> 00:06:52.036
no podía estar seguro

00:06:52.060 --> 00:06:55.740
de qué era capaz esta cosa.

00:06:56.740 --> 00:06:59.900
La tecnología avanza de a saltos,
e IBM había invertido mucho.

00:07:00.500 --> 00:07:01.700
Perdí esa partida.

00:07:04.140 --> 00:07:05.916
Y no pude evitar preguntarme,

00:07:05.940 --> 00:07:07.500
¿será invencible?

00:07:08.420 --> 00:07:10.780
¿Mi amado ajedrez llegó a su fin?

00:07:12.620 --> 00:07:16.756
Estas eran dudas humanas, temores humanos,

00:07:16.780 --> 00:07:18.460
y lo único que sabía con certeza

00:07:19.220 --> 00:07:22.116
era que mi oponente Deep Blue 
no tenía esas preocupaciones.

00:07:22.140 --> 00:07:23.900
(Risas)

00:07:25.740 --> 00:07:27.140
Batallé

00:07:28.220 --> 00:07:29.900
tras ese golpe devastador

00:07:30.820 --> 00:07:32.440
para ganar la primera partida,

00:07:32.780 --> 00:07:34.420
pero la suerte estaba echada.

00:07:36.220 --> 00:07:38.356
Al final perdí contra la máquina

00:07:38.380 --> 00:07:41.436
pero no corrí la suerte de John Henry

00:07:41.460 --> 00:07:44.500
que ganó, pero murió 
con el martillo en la mano.

00:07:49.540 --> 00:07:52.076
Resultó que el mundo del ajedrez

00:07:52.100 --> 00:07:55.340
todavía quería tener un campeón humano.

00:07:56.740 --> 00:07:58.420
E incluso hoy,

00:07:59.900 --> 00:08:03.356
cuando una aplicación gratuita 
de ajedrez en el último móvil

00:08:03.380 --> 00:08:05.396
es más potente que Deep Blue,

00:08:05.420 --> 00:08:07.310
las personas siguen jugando ajedrez,

00:08:08.500 --> 00:08:10.740
incluso más que antes.

00:08:11.620 --> 00:08:14.836
Los alarmistas predijeron que
todos abandonarían el juego,

00:08:14.860 --> 00:08:17.116
que podría ser conquistado 
por las máquinas,

00:08:17.140 --> 00:08:19.356
y estaban equivocados,
se puede ver claramente,

00:08:19.380 --> 00:08:22.836
pero el alarmismo siempre ha sido
un pasatiempo popular

00:08:22.860 --> 00:08:24.220
en materia de tecnología.

00:08:26.180 --> 00:08:28.916
De mi experiencia personal aprendí

00:08:28.940 --> 00:08:33.596
que debemos enfrentar los temores

00:08:33.620 --> 00:08:37.340
si queremos aprovechar al máximo
nuestra tecnología,

00:08:38.180 --> 00:08:40.556
y debemos superar esos temores

00:08:40.580 --> 00:08:45.820
si queremos obtener lo mejor 
que pueda dar nuestra humanidad.

00:08:47.940 --> 00:08:49.715
Mientras asimilaba la derrota,

00:08:49.739 --> 00:08:51.700
me inspiré mucho

00:08:52.900 --> 00:08:55.595
en las batallas contra Deep Blue.

00:08:55.619 --> 00:08:59.110
Como dice el viejo refrán ruso,
si no puedes vencerlos, únete a ellos.

00:09:00.700 --> 00:09:02.076
Entonces pensé,

00:09:02.100 --> 00:09:04.436
y si pudiera jugar con una computadora,

00:09:04.460 --> 00:09:07.620
con una computadora a mi lado,
y combinar nuestras fortalezas,

00:09:08.980 --> 00:09:12.756
la intuición humana 
más el cálculo de la máquina,

00:09:12.780 --> 00:09:15.476
la estrategia humana, 
la táctica de la máquina,

00:09:15.500 --> 00:09:17.916
la experiencia humana,
la memoria de la máquina.

00:09:17.940 --> 00:09:20.800
¿Sería esa la partida 
más perfecta de la historia?

00:09:21.820 --> 00:09:23.500
Mi idea se hizo realidad

00:09:24.740 --> 00:09:28.116
en 1998, bajo el nombre 
de "ajedrez avanzado",

00:09:28.140 --> 00:09:33.820
cuando jugué esta partida humano y máquina
contra otro jugador de élite.

00:09:35.100 --> 00:09:36.996
Pero en este primer experimento,

00:09:37.020 --> 00:09:43.380
ambos fracasamos en la combinación
efectiva de elementos humano y máquina.

00:09:46.740 --> 00:09:49.260
El ajedrez avanzado encontró 
su hogar en Internet.

00:09:49.980 --> 00:09:54.836
Y en 2005, un estilo llamado
torneo de ajedrez libre

00:09:54.860 --> 00:09:56.220
produjo una revelación.

00:09:59.060 --> 00:10:02.596
Participaron un equipo de maestros 
y máquinas de alto nivel,

00:10:02.620 --> 00:10:05.356
pero los ganadores no fueron
ni grandes maestros,

00:10:05.380 --> 00:10:06.740
ni supercomputadoras.

00:10:07.500 --> 00:10:11.836
Ganó un dúo de aficionados estadounidenses

00:10:11.860 --> 00:10:15.020
al mando de tres PC comunes en simultáneo.

00:10:17.380 --> 00:10:20.396
El talento para acompañar a sus máquinas

00:10:20.420 --> 00:10:25.660
contrarrestó con eficacia 
el conocimiento superior de ajedrez

00:10:25.660 --> 00:10:28.026
de sus oponentes 
que eran grandes maestros

00:10:28.026 --> 00:10:31.980
y tenían mayor poder computacional.

00:10:33.420 --> 00:10:35.380
Y llegué a esta formulación.

00:10:36.380 --> 00:10:39.756
Un jugador humano débil más una máquina

00:10:39.780 --> 00:10:43.036
más un mejor proceso, es superior

00:10:43.060 --> 00:10:45.476
a una máquina muy potente sola,

00:10:45.500 --> 00:10:49.396
pero aún más notable, es superior 
a un jugador humano fuerte

00:10:49.420 --> 00:10:51.380
más una máquina

00:10:52.940 --> 00:10:55.340
y un proceso inferior.

00:10:58.180 --> 00:11:00.300
Esto me convenció de que necesitaríamos

00:11:01.820 --> 00:11:05.500
mejores interfaces para 
entrenar a nuestras máquinas

00:11:06.340 --> 00:11:08.060
hacia una inteligencia más útil.

00:11:10.140 --> 00:11:13.436
El humano más la máquina no es el futuro,

00:11:13.460 --> 00:11:14.676
es el presente.

00:11:14.700 --> 00:11:18.836
Todos hemos usado herramientas 
de traducción en línea

00:11:18.860 --> 00:11:23.156
para entender la idea de 
un artículo de la prensa extranjera,

00:11:23.180 --> 00:11:24.820
a pesar de sus imperfecciones.

00:11:25.500 --> 00:11:27.596
Después usamos la experiencia humana

00:11:27.620 --> 00:11:29.716
para darle sentido a eso,

00:11:29.740 --> 00:11:32.516
y luego la máquina aprende 
de nuestras correcciones.

00:11:32.540 --> 00:11:37.500
Este modelo se desarrolla en diagnóstico
médico y análisis de seguridad.

00:11:38.260 --> 00:11:40.380
La máquina analiza los datos,

00:11:41.140 --> 00:11:42.876
calcula las probabilidades,

00:11:42.900 --> 00:11:46.556
hace 80 % o 90 % del camino,

00:11:46.580 --> 00:11:50.956
lo que facilita el análisis

00:11:50.980 --> 00:11:53.580
y la toma de decisión humana.

00:11:54.100 --> 00:11:58.940
Pero uno no enviaría a sus hijos

00:11:59.820 --> 00:12:03.380
a la escuela en un auto sin conductor
que tuviera un 90 % de exactitud,

00:12:04.420 --> 00:12:06.020
ni uno con un 99 %.

00:12:07.380 --> 00:12:10.236
Por eso necesitamos un gran avance

00:12:10.260 --> 00:12:16.420
para ganar algunos decimales cruciales.

00:12:18.980 --> 00:12:23.020
Veinte años después de 
mi partida con Deep Blue,

00:12:24.020 --> 00:12:25.636
la segunda partida,

00:12:25.660 --> 00:12:31.956
la del titular sensacionalista,
"El último combate del cerebro",

00:12:31.980 --> 00:12:33.556
se ha vuelto algo común

00:12:33.580 --> 00:12:36.116
conforme las máquinas inteligentes

00:12:36.140 --> 00:12:37.340
incursionan

00:12:38.380 --> 00:12:40.580
en todos los sectores, 
aparentemente a diario.

00:12:41.980 --> 00:12:45.076
Pero a diferencia del pasado,

00:12:45.100 --> 00:12:46.740
cuando las máquinas reemplazaban

00:12:48.300 --> 00:12:50.676
a los animales de granja, 
al trabajo manual,

00:12:50.700 --> 00:12:53.196
ahora vienen a reemplazar 
a personas con diplomas,

00:12:53.220 --> 00:12:55.060
o personas con influencia política.

00:12:55.390 --> 00:12:58.036
Como alguien que luchó 
contra la máquina y perdió,

00:12:58.060 --> 00:13:00.700
vine a decirles que 
es una noticia excelente.

00:13:02.820 --> 00:13:05.036
Un día, todas las profesiones

00:13:05.060 --> 00:13:07.156
deberán enfrentar esta presión,

00:13:07.180 --> 00:13:12.780
de lo contrario, la humanidad
habrá dejado de progresar.

00:13:14.580 --> 00:13:15.780
No seremos nosotros

00:13:17.260 --> 00:13:18.980
quienes elijan,

00:13:20.300 --> 00:13:23.020
cuándo y dónde se detendrá 
el progreso tecnológico.

00:13:24.980 --> 00:13:26.340
No podemos

00:13:27.780 --> 00:13:29.276
desacelerar.

00:13:29.300 --> 00:13:31.116
De hecho,

00:13:31.140 --> 00:13:33.060
tenemos que acelerar.

00:13:36.420 --> 00:13:39.060
Nuestra tecnología se destaca por quitar

00:13:41.020 --> 00:13:44.380
dificultades e incertidumbres
de nuestras vidas,

00:13:46.820 --> 00:13:49.636
así que tenemos que ir en busca

00:13:49.660 --> 00:13:51.516
de mayores desafíos,

00:13:51.540 --> 00:13:55.620
aún más inciertos.

00:14:00.020 --> 00:14:01.220
Las máquinas

00:14:03.700 --> 00:14:05.516
hacen cálculos.

00:14:05.540 --> 00:14:07.116
Nosotros comprendemos las cosas.

00:14:07.140 --> 00:14:09.180
Las máquinas reciben instrucciones.

00:14:10.660 --> 00:14:12.516
Nosotros tenemos propósito.

00:14:12.540 --> 00:14:14.820
Las máquinas tienen

00:14:16.900 --> 00:14:18.116
objetividad.

00:14:18.140 --> 00:14:19.340
Nosotros tenemos pasión.

00:14:20.420 --> 00:14:26.396
No deberíamos temer a lo que
pueden hacer las máquinas hoy.

00:14:26.420 --> 00:14:30.996
En cambio, deberíamos preocuparnos 
por lo que todavía no pueden hacer,

00:14:31.020 --> 00:14:36.516
porque vamos a necesitar la ayuda
de nuevas máquinas inteligentes

00:14:36.540 --> 00:14:40.620
para hacer realidad nuestros 
más grandes sueños.

00:14:41.820 --> 00:14:43.140
Y si fracasamos,

00:14:44.060 --> 00:14:48.716
si fallamos, no será porque nuestras 
máquinas sean muy inteligentes,

00:14:48.740 --> 00:14:50.140
o no lo suficientemente inteligentes.

00:14:51.020 --> 00:14:54.100
Si no lo logramos, será porque
nos dejamos llevar

00:14:55.500 --> 00:14:57.060
y limitamos nuestras ambiciones.

00:14:58.340 --> 00:15:01.380
Ninguna habilidad 
define nuestra humanidad,

00:15:03.100 --> 00:15:05.780
ni martillar, ni siquiera 
jugar al ajedrez.

00:15:06.380 --> 00:15:09.396
La humanidad solo puede hacer una cosa.

00:15:09.420 --> 00:15:10.620
Soñar.

00:15:11.940 --> 00:15:14.476
Soñemos en grande.

00:15:14.500 --> 00:15:15.716
Gracias.

00:15:15.740 --> 00:15:19.627
(Aplausos)

