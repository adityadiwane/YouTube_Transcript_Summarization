WEBVTT
Kind: captions
Language: uk

00:00:00.000 --> 00:00:07.000
Перекладач: Khrystyna Romashko
Утверджено: Hanna Leliv

00:00:12.780 --> 00:00:15.756
Ця історія починається у 1985,

00:00:15.780 --> 00:00:17.756
коли у 22 роки

00:00:17.780 --> 00:00:20.156
я став чемпіоном світу з шахів,

00:00:20.180 --> 00:00:23.380
побивши Анатолія Карпова.

00:00:24.300 --> 00:00:25.556
Раніше того року

00:00:25.580 --> 00:00:29.196
я зіграв одночасно

00:00:29.220 --> 00:00:33.516
проти 32-ох найкращих у світі
шахових комп'ютерів

00:00:33.540 --> 00:00:34.900
у Гамбурзі, що в Німеччині.

00:00:35.980 --> 00:00:37.180
Я виграв усі партії,

00:00:38.380 --> 00:00:41.556
і тоді це не виглядало несподіванкою,

00:00:41.580 --> 00:00:45.620
що я зміг виграти одночасно
у 32-ох комп'ютерів.

00:00:46.300 --> 00:00:48.876
Для мене то був Золотий вік.

00:00:48.900 --> 00:00:50.996
(Сміх)

00:00:51.020 --> 00:00:52.540
Комп'ютери були слабкими,

00:00:53.500 --> 00:00:54.836
а моє волосся міцним.

00:00:54.860 --> 00:00:57.060
(Сміх)

00:00:58.540 --> 00:01:00.596
Минуло лише 12 років,

00:01:00.620 --> 00:01:05.236
і я боровся з комп'ютером
за своє життя,

00:01:05.260 --> 00:01:06.460
у партії,

00:01:07.180 --> 00:01:09.236
яку видання "Newsweek" назвало

00:01:09.260 --> 00:01:11.036
"Останньою лінією оборони мозку" .

00:01:11.060 --> 00:01:12.276
Жодного тиску.

00:01:12.300 --> 00:01:13.820
(Сміх)

00:01:14.860 --> 00:01:17.436
Від міфології до наукової фантастики

00:01:17.460 --> 00:01:20.196
протистояння людини і машини

00:01:20.220 --> 00:01:22.980
часто змальовувалось
як справа життя і смерті.

00:01:23.780 --> 00:01:25.356
Джон Генрі,

00:01:25.380 --> 00:01:27.076
якого називали людиною зі сталі

00:01:27.100 --> 00:01:30.876
в північно-африканській народній легенді
19-го століття,

00:01:30.900 --> 00:01:32.276
загнав себе в могилу 
під час змагання

00:01:32.300 --> 00:01:35.036
з паровим молотом,

00:01:35.060 --> 00:01:37.420
буруючи тунель крізь скелі в горах.

00:01:38.620 --> 00:01:42.820
Легенда про Джона Генрі
є частиною довгої історії

00:01:43.500 --> 00:01:46.580
боротьби людства з технологіями.

00:01:48.020 --> 00:01:50.900
Ця змагальницька риторика
нині є стандартом.

00:01:51.380 --> 00:01:53.340
Ми змагаємося з машинами

00:01:54.180 --> 00:01:56.260
в битвах чи, навіть, у війні.

00:01:57.700 --> 00:01:59.316
Робочі місця знищуються.

00:01:59.340 --> 00:02:02.900
Людей заміняють, наче вони
зникли з лиця Землі.

00:02:04.060 --> 00:02:07.556
Досить того, що фільми
типу "Термінатора" або "Матриці" -

00:02:07.580 --> 00:02:08.780
це не фантастика.

00:02:11.460 --> 00:02:15.780
Існує дуже мало галузей,

00:02:17.180 --> 00:02:21.436
де людське тіло та розум
можуть змагатися на рівних

00:02:21.459 --> 00:02:23.300
з комп'ютером чи роботом.

00:02:24.100 --> 00:02:25.958
Власне, мені б хотілося,
щоб цих моментів було трохи більше.

00:02:27.580 --> 00:02:28.780
Натомість,

00:02:29.660 --> 00:02:34.316
моїм благословенням і моїм прокляттям

00:02:34.340 --> 00:02:37.036
було стати в прямому сенсі
людиною-легендою

00:02:37.060 --> 00:02:40.156
у змаганні людини проти машини,

00:02:40.180 --> 00:02:42.060
про яке всі досі говорять.

00:02:44.940 --> 00:02:49.956
У найвідомішому протистоянні
людина-машина з часів Джона Генрі

00:02:49.980 --> 00:02:52.556
я зіграв дві партії

00:02:52.580 --> 00:02:56.020
проти суперкомп'ютера IBM, Deep Blue.

00:02:58.860 --> 00:03:01.036
Ніхто не пам'ятає, 
що я виграв першу партію -

00:03:01.060 --> 00:03:03.396
(Сміх)

00:03:03.420 --> 00:03:06.820
(Оплески)

00:03:07.740 --> 00:03:12.716
У Філадельфії, перед тим, як я програв
реванш наступного року у Нью-Йорку.

00:03:12.740 --> 00:03:14.500
Та, гадаю, це справедливо.

00:03:16.140 --> 00:03:21.236
В історії немає дня,
спеціального дня в календарі,

00:03:21.260 --> 00:03:24.756
для всіх тих, хто не зміг піднятись
на гору Еверест

00:03:24.780 --> 00:03:27.516
до сера Едмунда Гілларі
та Тензінга Норґея,

00:03:27.540 --> 00:03:28.740
які змогли дістатись вершини.

00:03:29.780 --> 00:03:33.540
У 1997 році я все ще 
був чемпіоном світу,

00:03:36.340 --> 00:03:40.540
коли шахові комп'ютери нарешті
вдосконалили.

00:03:41.340 --> 00:03:43.316
Я був горою Еверест,

00:03:43.340 --> 00:03:44.940
і Deep Blue дійшов до вершини.

00:03:46.420 --> 00:03:50.476
Звісно, я мав би сказати, що це
зробив не Deep Blue,

00:03:50.500 --> 00:03:52.636
а його творці-люди -

00:03:52.660 --> 00:03:55.996
Анантараман, Кемпбелл, Гоан, Гсу.

00:03:56.020 --> 00:03:57.220
Схиляю голову перед ними.

00:03:58.660 --> 00:04:03.076
Як завжди, тріумф машини
був тріумфом людини:

00:04:03.100 --> 00:04:07.860
ми забуваємо про це, коли людей 
випереджають їх власні творіння.

00:04:10.180 --> 00:04:11.620
Deep Blue був переможцем,

00:04:13.220 --> 00:04:14.420
але що було розумним?

00:04:15.180 --> 00:04:16.940
Ні, не він,

00:04:18.020 --> 00:04:23.076
Принаймні, не так, як сподівався
Алан Тюрінг та інші творці

00:04:23.100 --> 00:04:24.300
комп'ютерної науки.

00:04:25.060 --> 00:04:29.836
Виявилося, що шахову тактику
можна розгризти брутальною силою,

00:04:29.860 --> 00:04:34.116
як тільки обладнання стає 
досить швидкісним,

00:04:34.140 --> 00:04:37.100
а алгоритми достатньо розумними.

00:04:38.580 --> 00:04:42.276
Тим не менше, за визначенням
результату гри

00:04:42.300 --> 00:04:45.516
гросмейстерського рівня,

00:04:45.540 --> 00:04:46.820
Deep Blue був розумним.

00:04:49.140 --> 00:04:51.540
Та навіть при неймовірній швидкості,

00:04:52.380 --> 00:04:55.580
200 мільйонів позицій за секунду,

00:04:57.180 --> 00:04:58.380
метод Deep Blue

00:04:59.180 --> 00:05:05.780
зробив лиш маленький крок до омріяного 
осягнення таємниць людського розуму.

00:05:08.780 --> 00:05:10.596
Незабаром

00:05:10.620 --> 00:05:13.196
машини стануть водіями таксі,

00:05:13.220 --> 00:05:15.636
лікарями та професорами,

00:05:15.660 --> 00:05:18.260
та чи будуть вони "розумними"?

00:05:19.660 --> 00:05:22.156
Я радше залишу ці визначення

00:05:22.180 --> 00:05:25.740
філософам та словнику.

00:05:27.260 --> 00:05:31.140
Насправді, важливо те, 
як ми, люди,

00:05:32.140 --> 00:05:35.740
почуваємося, живучи та працюючи
поруч з цими машинами.

00:05:37.980 --> 00:05:43.236
Коли я вперше побачив Deep Blue
у лютому 1996-го,

00:05:43.260 --> 00:05:45.860
я був чемпіоном світу
понад 10 років

00:05:47.900 --> 00:05:51.916
і зіграв 182 чемпіонські партії

00:05:51.940 --> 00:05:57.036
та сотні ігор проти найкращих
гравців на інших змаганнях.

00:05:57.060 --> 00:06:02.116
Я знав, чого очікувати 
від своїх суперників

00:06:02.140 --> 00:06:03.820
та чого очікувати від себе самого.

00:06:04.500 --> 00:06:09.676
Я звик прораховувати їхні ходи

00:06:09.700 --> 00:06:13.316
та вимірювати їхній емоційний стан,

00:06:13.340 --> 00:06:17.180
спостерігаючи за їхньою мовою тіла,
дивлячись їм в очі.

00:06:17.700 --> 00:06:21.700
А тоді я сів за дошку
з Deep Blue.

00:06:24.780 --> 00:06:27.636
І одразу відчув щось нове,

00:06:27.660 --> 00:06:28.980
щось, що вибивало з колії.

00:06:31.260 --> 00:06:34.060
Мабуть, подібне відчуття 
з'являється тоді,

00:06:35.140 --> 00:06:37.676
коли вперше їдеш машиною
без водія,

00:06:37.700 --> 00:06:42.540
чи тоді, коли твій новий 
керівник-комп'ютер видає наказ на роботі.

00:06:45.620 --> 00:06:48.740
Та коли я вперше сів за ту гру,

00:06:49.900 --> 00:06:52.036
я не міг знати,

00:06:52.060 --> 00:06:55.740
на що здатна ця річ.

00:06:56.740 --> 00:06:59.900
Технології можуть різко прогресувати, 
і IBM вклало дуже багато коштів.

00:07:00.500 --> 00:07:01.700
Я програв партію.

00:07:04.140 --> 00:07:05.916
Мені довго не давала спокою думка:

00:07:05.940 --> 00:07:07.500
чи могла та машина 
бути непереможною?

00:07:08.420 --> 00:07:10.780
Чи то був кінець моєї улюбленої
гри в шахи?

00:07:12.620 --> 00:07:16.756
То були людські сумніви, людські страхи.

00:07:16.780 --> 00:07:18.460
Єдине, що я знав напевно,

00:07:19.220 --> 00:07:22.116
що мій суперник цим всім 
абсолютно не переймався.

00:07:22.140 --> 00:07:23.900
(Сміх)

00:07:25.740 --> 00:07:27.140
Після цієї розгромної партії

00:07:28.220 --> 00:07:29.900
я зіграв знову,

00:07:30.820 --> 00:07:32.020
щоб виграти першу партію,

00:07:32.780 --> 00:07:34.420
але факт залишився фактом.

00:07:36.220 --> 00:07:38.356
Так чи інакше, я програв машині,

00:07:38.380 --> 00:07:41.436
але мене не спіткала доля
Джона Генрі,

00:07:41.460 --> 00:07:44.500
який виграв, але помер
зі своїм молотом в руці.

00:07:49.540 --> 00:07:52.076
Виявилося, що світ шахів

00:07:52.100 --> 00:07:55.340
все ще хотів мати чемпіона світу
людину.

00:07:56.740 --> 00:07:58.420
І навіть сьогодні,

00:07:59.900 --> 00:08:03.356
коли безкоштовні додатки для гри в шахи
на найновішому мобільному телефоні

00:08:03.380 --> 00:08:05.396
сильніші за Deep Blue,

00:08:05.420 --> 00:08:06.900
люди досі грають в шахи,

00:08:08.500 --> 00:08:10.740
навіть більше, ніж раніше.

00:08:11.620 --> 00:08:14.836
Песимісти передбачали, що ніхто
не сяде за гру,

00:08:14.860 --> 00:08:17.116
яку може виграти машина,

00:08:17.140 --> 00:08:19.356
та вони помилялися, як було доведено.

00:08:19.380 --> 00:08:22.836
Песимізм, зрештою, завжди був
популярним заняттям,

00:08:22.860 --> 00:08:24.220
коли йшлося про технології.

00:08:26.180 --> 00:08:28.916
З власного досвіду я усвідомив,

00:08:28.940 --> 00:08:33.596
що ми мусимо протистояти своїм страхам,

00:08:33.620 --> 00:08:37.340
якщо хочемо отримати максимум
від наших технологій,

00:08:38.180 --> 00:08:40.556
і мусимо побороти ці страхи,

00:08:40.580 --> 00:08:45.820
якщо хочемо взяти найкраще 
від нашої людяності.

00:08:47.940 --> 00:08:49.715
Зализуючи рани після поразки

00:08:49.739 --> 00:08:51.700
я отримав багато натхнення

00:08:52.900 --> 00:08:55.595
від моїх партій з Deep Blue.

00:08:55.619 --> 00:08:58.740
Як каже старе російське прислів'я:
"Якщо не можеш побороти їх, приєднайся до них".

00:09:00.700 --> 00:09:02.076
Тоді я подумав,

00:09:02.100 --> 00:09:04.436
а що, якби я зіграв з комп'ютером -

00:09:04.460 --> 00:09:07.620
разом з іншим комп'ютером на моєму боці,
поєднавши наші переваги,

00:09:08.980 --> 00:09:12.756
людську інтуїцію та машинний розрахунок,

00:09:12.780 --> 00:09:15.476
людську стратегію, машинну тактику,

00:09:15.500 --> 00:09:17.916
людський досвід, машинну пам'ять.

00:09:17.940 --> 00:09:20.140
Чи могла б така гра стати 
ідеальною грою всіх часів?

00:09:21.820 --> 00:09:23.500
Моя ідея втілилася

00:09:24.740 --> 00:09:28.116
у 1998 році під назвою "Прогресивні шахи",

00:09:28.140 --> 00:09:33.820
коли я зіграв таку партію людина-плюс-машина
проти іншого елітного гравця.

00:09:35.100 --> 00:09:36.996
Та в тому першому експерименті

00:09:37.020 --> 00:09:43.380
нам обом не вдалося поєднати
людські та машинні здібності ефективно.

00:09:46.740 --> 00:09:48.980
"Прогресивні шахи" знайшли
своє місце в інтернеті,

00:09:49.980 --> 00:09:54.836
і в 2005 році так званий 
шаховий турнір вільного стилю

00:09:54.860 --> 00:09:56.220
став відкриттям.

00:09:59.060 --> 00:10:02.596
Участь взяли команда гросмейстерів
та найкращі комп'ютери,

00:10:02.620 --> 00:10:05.356
та переможцями не стали
ні гросмейстери,

00:10:05.380 --> 00:10:06.740
ні суперкомп'ютери.

00:10:07.500 --> 00:10:11.836
Ними стали пара аматорів,
американських гравців у шахи,

00:10:11.860 --> 00:10:15.020
які користувалися одночасно
трьома звичайними ПК.

00:10:17.380 --> 00:10:20.396
Їхнє вміння оперувати
своїми комп'ютерами

00:10:20.420 --> 00:10:26.196
ефективно дало відсіч глибоким
знанням із шахів

00:10:26.220 --> 00:10:27.796
їхніх суперників-гросмейстрів

00:10:27.820 --> 00:10:31.980
та набагато кращій здатності 
суперкомп'ютерів прораховувати ходи.

00:10:33.420 --> 00:10:35.380
І я дійшов до наступного формулювання.

00:10:36.380 --> 00:10:39.756
Слабкий гравець-людина плюс комп'ютер

00:10:39.780 --> 00:10:43.036
плюс кращий процесор є сильнішими

00:10:43.060 --> 00:10:45.476
за сам лише дуже потужний комп'ютер,

00:10:45.500 --> 00:10:49.396
та, що цікавіше, це також сильніше 
за сильного гравця-людину

00:10:49.420 --> 00:10:51.380
плюс комп'ютер

00:10:52.940 --> 00:10:55.340
зі слабшим процесором.

00:10:58.180 --> 00:11:00.300
Це переконало мене, що нам потрібні будуть

00:11:01.820 --> 00:11:05.500
кращі інтерфейси, які допоможуть
керувати нашими комп'ютерами,

00:11:06.340 --> 00:11:08.060
щоб ефективніше 
використовувати розум.

00:11:10.140 --> 00:11:13.436
Людина плюс машина - 
це не майбутнє,

00:11:13.460 --> 00:11:14.676
це теперішнє.

00:11:14.700 --> 00:11:18.836
Усі, хто користувався онлайн перекладом,

00:11:18.860 --> 00:11:23.156
щоб зрозуміти, про що йдеться
в іноземній газеті,

00:11:23.180 --> 00:11:24.820
знають, що він далеко не досконалий.

00:11:25.500 --> 00:11:27.596
Тоді ми застосовуємо наш людський досвід,

00:11:27.620 --> 00:11:29.716
щоб надати змісту інформації,

00:11:29.740 --> 00:11:32.516
а машина вчиться з наших коригувань.

00:11:32.540 --> 00:11:37.500
Ця модель поширюється та допомагає
робити медичні прогнози, аналізи безпеки.

00:11:38.260 --> 00:11:40.380
Комп'ютер розшифровує дані,

00:11:41.140 --> 00:11:42.876
розраховує імовірності,

00:11:42.900 --> 00:11:46.556
отримує 80-90 відсотків в процесі,

00:11:46.580 --> 00:11:50.956
що полегшує людям аналіз

00:11:50.980 --> 00:11:53.580
та ухвалення рішень.

00:11:54.100 --> 00:11:58.940
Але ви ж не відправите своїх дітей

00:11:59.820 --> 00:12:03.380
до школи в авто без водія
з 90% безпомилковості,

00:12:04.420 --> 00:12:06.020
навіть з 99%.

00:12:07.380 --> 00:12:10.236
Тож нам потрібен стрибок вперед,

00:12:10.260 --> 00:12:16.420
щоб додати ще цих декілька
ключових десяткових чисел.

00:12:18.980 --> 00:12:23.020
Через двадцять років після
моєї гри з Deep Blue

00:12:24.020 --> 00:12:25.636
відбулася друга партія,

00:12:25.660 --> 00:12:31.956
цей сенсаційний заголовок
"Остання лінія оборони розуму"

00:12:31.980 --> 00:12:33.556
став доречним,

00:12:33.580 --> 00:12:36.116
оскільки розумні машини

00:12:36.140 --> 00:12:37.340
рухаються вперед

00:12:38.380 --> 00:12:40.580
в кожному секторі, чи не кожного дня.

00:12:41.980 --> 00:12:45.076
Та, на відміну від минулого,

00:12:45.100 --> 00:12:46.740
коли машини заступали

00:12:48.300 --> 00:12:50.676
тварин на фермі, ручну роботу,

00:12:50.700 --> 00:12:53.196
тепер вони починають заступати
людей з університетськими ступенями

00:12:53.220 --> 00:12:54.500
та політичним впливом.

00:12:55.940 --> 00:12:58.036
Як той, хто грав проти машини 
і програв,

00:12:58.060 --> 00:13:00.700
я тут, щоб сказати вам, що
це чудові, прекрасні новини.

00:13:02.820 --> 00:13:05.036
Власне, кожна професія

00:13:05.060 --> 00:13:07.156
буде змушена відчути цей тиск,

00:13:07.180 --> 00:13:12.780
інакше це означатиме, що людство
перестало прогресувати.

00:13:14.580 --> 00:13:15.780
Ми

00:13:17.260 --> 00:13:18.980
не обираємо,

00:13:20.300 --> 00:13:23.020
коли й де зупиниться
технологічний прогрес.

00:13:24.980 --> 00:13:26.340
Ми не можемо

00:13:27.780 --> 00:13:29.276
сповільнитися.

00:13:29.300 --> 00:13:31.116
Насправді,

00:13:31.140 --> 00:13:33.060
нам слід прискоритися.

00:13:36.420 --> 00:13:39.060
Наші технології блискуче справляються

00:13:41.020 --> 00:13:44.380
з усуванням труднощів та непевностей
з нашого життя,

00:13:46.820 --> 00:13:49.636
і нам треба шукати

00:13:49.660 --> 00:13:51.516
ще складніші,

00:13:51.540 --> 00:13:55.620
ще непевніші проблеми.

00:14:00.020 --> 00:14:01.220
Машини мають

00:14:03.700 --> 00:14:05.516
розрахунки.

00:14:05.540 --> 00:14:07.116
Ми маємо розуміння.

00:14:07.140 --> 00:14:09.180
Машини мають інструкції.

00:14:10.660 --> 00:14:12.516
Ми маємо мету.

00:14:12.540 --> 00:14:14.820
Машини мають

00:14:16.900 --> 00:14:18.116
об'єктивність.

00:14:18.140 --> 00:14:19.340
Ми маємо пристрасть.

00:14:20.420 --> 00:14:26.396
Нам не треба хвилюватися через те,
що наші машини вміють робити сьогодні.

00:14:26.420 --> 00:14:30.996
Натомість, варто хвилюватися через те,
чого вони все ще не вміють робити сьогодні,

00:14:31.020 --> 00:14:36.516
бо ми потребуватимемо допомоги
нових, розумних машин,

00:14:36.540 --> 00:14:40.620
щоб перетворити наші найбільші мрії
в реальність.

00:14:41.820 --> 00:14:43.140
А якщо нам не вдасться,

00:14:44.060 --> 00:14:48.716
якщо не вдасться, то не через те, 
що наші машини надто розумні,

00:14:48.740 --> 00:14:50.140
чи недостатньо розумні.

00:14:51.020 --> 00:14:54.100
Якщо нам не вдасться, то через те,
що ми розслабилися на лаврах

00:14:55.500 --> 00:14:57.060
і обмежили власні амбіції.

00:14:58.340 --> 00:15:01.380
Наше людство не визначається
якимось вмінням,

00:15:03.100 --> 00:15:05.780
як-от гупати молотом
чи грати в шахи.

00:15:06.380 --> 00:15:09.396
Існує лише одна річ, яку може робити
тільки людина.

00:15:09.420 --> 00:15:10.620
Мріяти.

00:15:11.940 --> 00:15:14.476
Закликаю вас мріяти по-великому.

00:15:14.500 --> 00:15:15.716
Дякую.

00:15:15.740 --> 00:15:19.627
(Оплески)

