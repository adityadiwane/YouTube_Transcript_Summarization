WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Doina Zamfirescu
Corector: Matei Sterian

00:00:12.570 --> 00:00:18.327
Lucrez cu matematicieni, 
filozofi și cercetători IT

00:00:18.327 --> 00:00:20.556
și ne gândim

00:00:20.556 --> 00:00:23.540
la viitorul inteligenței artificiale,
printre altele.

00:00:24.030 --> 00:00:28.605
Unii cred că unele dintre aceste lucruri 
sunt științifico-fantastice,

00:00:28.605 --> 00:00:30.896
departe de noi, nebunești.

00:00:31.756 --> 00:00:33.326
Dar mie îmi place să zic:

00:00:33.326 --> 00:00:36.930
OK, hai să vedem condiția omului modern.

00:00:36.930 --> 00:00:38.622
(Râsete)

00:00:38.622 --> 00:00:40.624
Asta e normalul.

00:00:42.074 --> 00:00:43.309
Dar de fapt

00:00:43.309 --> 00:00:46.602
suntem niște oaspeți
relativ recenți pe această planetă

00:00:46.602 --> 00:00:48.044
ca specie umană.

00:00:49.584 --> 00:00:53.290
Gândiți-vă, dacă Pământul 
a fi fost creat în urmă cu un an,

00:00:53.290 --> 00:00:56.338
specia umană ar fi existat 
de doar 10 minute.

00:00:56.978 --> 00:00:59.826
Epoca Industrială ar fi început 
de doar două secunde.

00:01:01.276 --> 00:01:06.281
Am putea analiza aceasta și din prisma 
PIB-ului global din ultimii 10 000 de ani.

00:01:06.281 --> 00:01:09.310
V-am făcut și un grafic.

00:01:10.070 --> 00:01:11.224
Arată așa.

00:01:11.224 --> 00:01:12.667
(Râsete)

00:01:12.667 --> 00:01:15.078
Are o formă ciudată 
pentru o situație normală.

00:01:15.078 --> 00:01:17.076
Eu unul nu m-aș așeza pe el.

00:01:17.076 --> 00:01:18.597
(Râsete)

00:01:18.597 --> 00:01:23.661
Hai să ne punem întrebarea: 
care ar fi cauza acestei anomalii?

00:01:23.841 --> 00:01:26.393
Unii ar zice că ar fi tehnologia.

00:01:26.393 --> 00:01:31.061
Adevărat, în decursul istoriei, 
umanitatea a acumulat multă tehnologie

00:01:31.061 --> 00:01:35.293
și, în acest moment, tehnologia 
avansează extrem de rapid.

00:01:35.653 --> 00:01:37.278
Aceasta e cauza imediată,

00:01:37.278 --> 00:01:39.843
de aceea suntem atât de productivi.

00:01:40.623 --> 00:01:45.134
Dar îmi place să gândesc mai departe,
la cauza primară.

00:01:45.134 --> 00:01:47.900
Priviți-i pe acești domni distinși.

00:01:48.720 --> 00:01:50.480
Îl avem pe Kanzi,

00:01:50.480 --> 00:01:54.573
el a stăpânit 200 de semne lexicale,
o ispravă nemaipomenită.

00:01:54.973 --> 00:01:58.587
Și pe Ed Witten care a declanșat 
a doua revoluție a superstringurilor.

00:01:58.817 --> 00:02:01.141
Dacă „deschidem capota”, iată ce găsim:

00:02:01.141 --> 00:02:02.711
în esență același lucru.

00:02:02.711 --> 00:02:04.374
Unul dintre ele e ceva mai mare,

00:02:04.374 --> 00:02:07.602
posibil cu câteva trucuri în plus
în privința modului de montare.

00:02:07.602 --> 00:02:11.094
Aceste diferențe invizibile, totuși, 
nu pot fi prea complicate

00:02:11.094 --> 00:02:15.379
pentru că s-au perindat 
doar 250 000 de generații

00:02:15.379 --> 00:02:17.421
de la ultimul nostru strămoș comun

00:02:17.421 --> 00:02:21.130
și știm că mecanismele complicate 
durează mult până evoluează.

00:02:21.830 --> 00:02:24.929
Așa că o mână de schimbări minore

00:02:24.929 --> 00:02:27.786
ne-au dus de la Kanzi la Witten,

00:02:27.786 --> 00:02:32.109
de la crengi rupte
la rachete balistice intercontinentale.

00:02:32.839 --> 00:02:36.774
Atunci pare destul de evident
că tot ce am realizat

00:02:36.774 --> 00:02:39.802
și toate cele de care ne pasă 
depind radical

00:02:39.802 --> 00:02:43.560
de schimbări relativ minore 
făcute de mintea umană.

00:02:44.570 --> 00:02:48.312
Iar corolarul este, desigur,
că orice viitoare schimbare

00:02:48.312 --> 00:02:51.649
ce ar putea schimba substanțial
substratul gândirii

00:02:51.649 --> 00:02:54.571
ar putea avea consecințe uriașe.

00:02:56.771 --> 00:02:59.226
Unii colegi cred că suntem pe cale

00:02:59.226 --> 00:03:03.134
de a produce ceva ce ar putea cauza
o schimbare profundă a acestui substrat,

00:03:03.134 --> 00:03:05.797
aceasta fiind 
superinteligența artificială.

00:03:06.347 --> 00:03:10.946
Inteligența artificială era desemnată
ca fiind o cutie în care se pun comenzi.

00:03:10.946 --> 00:03:13.341
Trebuiau să existe programatori umani

00:03:13.341 --> 00:03:16.776
care să modeleze din greu 
părțile de cunoaștere.

00:03:16.776 --> 00:03:18.442
Se realizează niște sisteme expert

00:03:18.442 --> 00:03:20.296
care vor fi de folos în anumit scop,

00:03:20.296 --> 00:03:22.827
dar care sunt foarte firave,
nu se pot extinde.

00:03:22.827 --> 00:03:25.690
În principiu, primești de la ele
doar ce ai programat.

00:03:26.410 --> 00:03:27.627
De atunci, însă,

00:03:27.627 --> 00:03:30.874
s-a produs o schimbare în paradigmă
în inteligența artificială.

00:03:30.874 --> 00:03:34.424
Acum acțiunea se petrece în jurul
învățării sistemelor artificiale.

00:03:34.424 --> 00:03:40.551
În loc să realizăm reprezentări și 
caracteristici ale cunoașterii,

00:03:40.551 --> 00:03:45.775
creăm algoritmi de învățare adesea 
pe bază de date perceptuale brute.

00:03:46.685 --> 00:03:50.253
În principiu, lucru similar 
cu ceea ce face un copil.

00:03:51.063 --> 00:03:55.270
Rezultatul este o I.A. 
ce nu se limitează la un domeniu,

00:03:55.270 --> 00:03:59.701
același sistem putând să învețe 
să traducă între oricare două limbi

00:03:59.701 --> 00:04:05.088
sau să învețe să joace orice joc
pe calculator pe o consolă Atari.

00:04:05.938 --> 00:04:07.117
Desigur,

00:04:07.117 --> 00:04:10.936
I.A. nu are nici pe departe puterea,

00:04:10.936 --> 00:04:14.065
abilitatea transdisciplinară a omului
de a planifica și învăța.

00:04:14.065 --> 00:04:16.601
Cortexul are încă 
niște trucuri de algoritm

00:04:16.601 --> 00:04:19.241
pe care încă nu știm cum 
să le transpunem în mecanisme.

00:04:19.886 --> 00:04:21.735
Se pune deci întrebarea

00:04:21.735 --> 00:04:24.815
cât de de departe suntem de momentul 
în care putem face asta.

00:04:26.265 --> 00:04:27.328
Cu câțiva ani în urmă,

00:04:27.328 --> 00:04:30.146
am făcut un sondaj printre 
cei mai de seamă experți în I.A.

00:04:30.146 --> 00:04:33.440
pentru a vedea ce cred ei 
și una din întrebări a fost:

00:04:33.440 --> 00:04:36.793
„Până în ce an credeți că vom ajunge 
la probabilitatea de 50%

00:04:36.793 --> 00:04:40.255
de a realizare inteligența artificiala
la nivelul omului?”

00:04:41.115 --> 00:04:45.148
Prin „nivelul omului” am înțeles 
capacitatea de a presta

00:04:45.148 --> 00:04:47.839
aproape orice sarcină
cel puțin la nivelul unui adult,

00:04:47.839 --> 00:04:51.204
deci nivel uman general, 
nu doar limitat la un domeniu restrâns.

00:04:51.844 --> 00:04:55.494
Răspunsul mediu a fost 2040 sau 2050,

00:04:55.494 --> 00:04:58.300
în funcție de
grupul de experți chestionați.

00:04:59.520 --> 00:05:02.339
S-ar putea întâmpla 
mult mai târziu sau mai devreme,

00:05:02.339 --> 00:05:04.279
adevărul e că nimeni nu știe.

00:05:05.179 --> 00:05:09.671
Ceea ce știm e că limita superioară 
a procesării informației

00:05:09.671 --> 00:05:14.542
într-un mediu artificial e mult 
mai departe de limitele noastre biologice.

00:05:15.241 --> 00:05:17.449
Totul se reduce la fizică.

00:05:17.449 --> 00:05:22.177
Neuronul transmite la vreo 200 de herți, 
de 200 de ori pe secundă.

00:05:22.177 --> 00:05:25.561
Dar chiar și acum, un tranzistor 
operează în gigaherți.

00:05:25.881 --> 00:05:29.138
Impulsurile se propagă prin axoni încet, 

00:05:29.138 --> 00:05:31.398
cu cel mult 100 de metri pe secundă.

00:05:31.398 --> 00:05:34.339
Dar în calculatoare semnalele 
pot circula cu viteza luminii.

00:05:35.079 --> 00:05:36.948
Există și limitări date de volum,

00:05:36.948 --> 00:05:40.205
creierul uman trebuie 
să încapă în cutia craniană,

00:05:40.205 --> 00:05:43.766
dar un calculator poate fi mare 
cât un depozit sau mai mare.

00:05:44.736 --> 00:05:50.505
Deci potențialul de superinteligență
e în stare latentă în materie,

00:05:50.505 --> 00:05:54.187
la fel ca puterea atomului 
care a fost în stare latentă

00:05:54.187 --> 00:05:55.907
în toată istoria umanității,

00:05:55.907 --> 00:05:59.262
așteptând cu răbdare până în 1945.

00:06:00.262 --> 00:06:01.150
În acest secol,

00:06:01.150 --> 00:06:05.818
oamenii de știință ar putea să trezească 
puterea inteligenței artificiale.

00:06:05.818 --> 00:06:09.596
Și cred că atunci am putea fi martorii 
unei explozii de inteligență.

00:06:10.406 --> 00:06:14.363
Majoritatea oamenilor, gândindu-se 
la cine e deștept și cine prost,

00:06:14.363 --> 00:06:17.386
cred că au în cap ceva de genul acesta.

00:06:17.386 --> 00:06:19.984
La o extremitate avem prostul satului,

00:06:19.984 --> 00:06:22.467
departe, la cealaltă extremitate,

00:06:22.467 --> 00:06:26.943
pe Ed Witten, sau Albert Einstein, 
sau oricine altcineva ar fi favoritul.

00:06:27.403 --> 00:06:31.797
Dar eu zic că, din punctul de vedere 
al inteligenței artificiale,

00:06:31.797 --> 00:06:34.738
schema este, de fapt, mai mult așa:

00:06:35.258 --> 00:06:38.636
I.A. începe în acest punct,
la inteligență zero,

00:06:38.636 --> 00:06:41.647
apoi, după foarte mulți ani 
de muncă asiduă,

00:06:41.647 --> 00:06:45.601
poată că inteligența artificială 
ajunge la nivelul șoarecelui,

00:06:45.601 --> 00:06:49.751
ceva ce poate naviga într-un mediu haotic
la fel de bine cum poate un șoarece.

00:06:49.751 --> 00:06:54.221
Iar apoi, după alți mulți ani 
de muncă asiduă, cu multe investiții,

00:06:54.221 --> 00:06:58.130
poate că inteligența artificială 
ajunge la nivelul cimpanzeului.

00:06:58.860 --> 00:07:01.960
Iar apoi, după și mai mulți ani 
de muncă asiduă,

00:07:01.960 --> 00:07:04.823
ajungem la inteligența artificială 
a prostului satului.

00:07:04.823 --> 00:07:08.055
Și după câteva momente 
suntem dincolo de Ed Witten.

00:07:08.055 --> 00:07:10.955
Trenul nu oprește la „Gara Omului”.

00:07:10.955 --> 00:07:13.717
Din contră, probabil va trece în viteză.

00:07:14.247 --> 00:07:16.621
Aceasta are implicații serioase,

00:07:16.621 --> 00:07:19.763
mai ales când vine vorba 
de probleme de putere.

00:07:20.093 --> 00:07:21.992
De exemplu, cimpanzeii sunt puternici:

00:07:21.992 --> 00:07:26.854
la kilograme, cimpanzeul e de vreo 2 ori 
mai puternic decât un bărbat sănătos.

00:07:27.214 --> 00:07:32.248
Totuși, soarta lui Kanzi și a celor ca el
depinde cu mult mai mult

00:07:32.248 --> 00:07:35.968
de ce facem noi, oamenii, 
decât de ce fac semenii cimpanzei.

00:07:37.528 --> 00:07:39.542
Cu apariția superinteligenței,

00:07:39.542 --> 00:07:43.381
soarta umanității poate depinde 
de ce face superinteligența.

00:07:44.451 --> 00:07:45.978
Gândiți-vă:

00:07:45.978 --> 00:07:50.012
inteligența artificială e ultima invenție
pe care va trebui s-o facă umanitatea.

00:07:50.382 --> 00:07:53.305
Căci după aceea mașinile 
vor fi mai bune la inventat decât noi

00:07:53.305 --> 00:07:56.305
și vor face asta la scară digitală.

00:07:56.305 --> 00:08:00.346
Aceasta înseamnă, de fapt, 
telescopizarea viitorului.

00:08:00.966 --> 00:08:04.524
Luați toate tehnologiile nebunești 
pe care vi le-ați putea imagina,

00:08:04.524 --> 00:08:07.322
pe care oamenii 
le-ar putea realiza în timp:

00:08:07.322 --> 00:08:10.580
oprirea îmbătrânirii, 
colonizarea spațiului cosmic,

00:08:10.580 --> 00:08:14.311
nanoroboți auto-replicativi 
sau încărcarea minții în calculator,

00:08:14.311 --> 00:08:16.470
tot felul de chestii SF

00:08:16.470 --> 00:08:18.937
care sunt totuși în concordanță 
cu legile fizicii.

00:08:18.937 --> 00:08:23.419
Pe toate astea superinteligența
le poate realiza, și încă foarte repede.

00:08:24.449 --> 00:08:27.887
Superinteligența de o astfel de 
maturitate tehnologică

00:08:27.887 --> 00:08:30.206
ar fi extrem de puternică

00:08:30.206 --> 00:08:34.412
și, cel puțin în unele scenarii,
ar putea obține ce vrea.

00:08:35.012 --> 00:08:39.713
Atunci am avea viitorul
modelat de preferințele acesteia.

00:08:41.855 --> 00:08:45.604
O întrebare bună este:
care ar fi aceste preferințe?

00:08:46.244 --> 00:08:48.013
Aici e mai cu schepsis.

00:08:48.013 --> 00:08:49.448
Pentru a avansa cu acest gând,

00:08:49.448 --> 00:08:52.724
în primul rând trebuie 
să evităm antropomorfizarea.

00:08:53.934 --> 00:08:57.235
Iar asta e ironic pentru că 
orice articol de ziar

00:08:57.235 --> 00:09:00.200
despre viitorul I.A. are o poză ca asta:

00:09:02.610 --> 00:09:06.414
Cred că trebuie să concepem 
chestiunea mai abstract,

00:09:06.414 --> 00:09:08.954
nu în termenii colorați
ai scenariilor hollywoodiene.

00:09:09.204 --> 00:09:12.821
Trebuie să ne gândim la inteligență
ca un proces de optimizare,

00:09:12.821 --> 00:09:17.860
un proces ce îndreaptă viitorul
într-un anumit set de configurații.

00:09:18.470 --> 00:09:21.981
Superinteligența ca proces 
de optimizare foarte puternic.

00:09:21.981 --> 00:09:24.718
Extrem de bună pentru a folosi 
mijloacele existente

00:09:24.718 --> 00:09:27.687
pentru a realiza o stare 
în care obiectivele ei sunt atinse.

00:09:28.447 --> 00:09:30.739
Aceasta înseamnă 
că nu există neapărat legătură

00:09:30.739 --> 00:09:33.713
între a fi foarte inteligent în acest sens

00:09:33.713 --> 00:09:38.325
și a avea un obiectiv pe care noi, 
oamenii, l-am considera util și cu sens.

00:09:39.321 --> 00:09:42.875
Să zicem că îi dăm unei I.A. ca obiectiv 
să-i facă pe oameni să zâmbească.

00:09:43.115 --> 00:09:46.097
Când I.A. e slabă, acționează 
util sau amuzant

00:09:46.097 --> 00:09:48.154
ceea ce îl face pe utilizator 
să zâmbească.

00:09:48.614 --> 00:09:51.031
Când I.A. devine superinteligentă,

00:09:51.031 --> 00:09:54.554
își dă seama că există o cale 
mai eficientă pentru a atinge acest scop:

00:09:54.554 --> 00:09:56.476
preia controlul asupra lumii

00:09:56.476 --> 00:09:59.638
și implantează electrozi 
în mușchii faciali ai oamenilor

00:09:59.638 --> 00:10:02.179
pentru a obține rânjete 
strălucitoare constante.

00:10:02.449 --> 00:10:03.414
Alt exemplu:

00:10:03.414 --> 00:10:06.997
dăm I.A. ca obiectiv să rezolve 
o problemă de matematică grea.

00:10:06.997 --> 00:10:08.934
Când I.A. devine superinteligentă,

00:10:08.934 --> 00:10:12.625
își dă seama că modul cel mai eficient 
pentru a găsi soluția problemei

00:10:12.625 --> 00:10:16.035
este transformarea planetei
într-un calculator gigant

00:10:16.035 --> 00:10:18.281
pentru a-i crește capacitatea de gândire.

00:10:18.281 --> 00:10:21.045
Luați seamă că aceasta dă I.A.-ului 
rațiunea instrumentală

00:10:21.045 --> 00:10:23.561
pentru a ne face lucruri 
cu care nu suntem de acord.

00:10:23.561 --> 00:10:25.496
În acest caz, oamenii sunt o amenințare,

00:10:25.496 --> 00:10:28.287
am putea să împiedicăm rezolvarea 
problemei de matematică.

00:10:29.067 --> 00:10:32.121
Desigur, se vede că lucrurile 
nu vor degenera chiar astfel;

00:10:32.121 --> 00:10:34.184
acestea sunt exemple exagerate.

00:10:34.454 --> 00:10:36.393
Dar esența lor e importantă:

00:10:36.393 --> 00:10:39.266
dacă vrei să realizezi 
un proces de optimizare puternic

00:10:39.266 --> 00:10:41.500
pentru a maximiza 
atingerea obiectivului x,

00:10:41.500 --> 00:10:43.776
ar fi bine să te asiguri 
că definiția acelui x

00:10:43.776 --> 00:10:46.155
încorporează tot ce contează pentru tine.

00:10:46.835 --> 00:10:50.489
E un motiv ce apare și în multe legende.

00:10:51.219 --> 00:10:55.807
Regele Midas vroia ca tot ce atinge 
să se transforme în aur.

00:10:56.517 --> 00:10:59.028
Și-a atins fiica, s-a transformat în aur.

00:10:59.378 --> 00:11:01.621
S-a atins de mâncare, 
s-a transformat în aur.

00:11:01.931 --> 00:11:04.460
Aceasta poate fi relevant în practică,

00:11:04.460 --> 00:11:06.590
nu doar ca o metaforă a lăcomiei,

00:11:06.590 --> 00:11:08.485
ci și pentru a ilustra ce se întâmplă

00:11:08.485 --> 00:11:11.172
dacă realizezi 
un proces de optimizare puternic,

00:11:11.172 --> 00:11:15.371
cu obiectivele concepute eronat 
sau insuficient de detaliate.

00:11:16.281 --> 00:11:21.300
Ați putea zice că dacă un calculator 
începe să implanteze electrozi în oameni

00:11:21.300 --> 00:11:23.155
nu avem decât să îl închidem.

00:11:24.555 --> 00:11:29.895
A, poate să nu fie chiar așa de ușor 
dacă suntem dependenți de sistem –

00:11:29.895 --> 00:11:31.937
de unde se poate stinge Internetul?

00:11:32.627 --> 00:11:37.387
B, de ce nu au apăsat cimpanzeii 
pe întrerupătorul umanității?

00:11:37.977 --> 00:11:39.298
Sau neanderthalienii?

00:11:39.298 --> 00:11:41.144
Cu siguranță aveau motive să o facă.

00:11:41.964 --> 00:11:44.759
Avem un întrerupător, de exemplu aici.

00:11:44.759 --> 00:11:46.313
(Se sugrumă)

00:11:46.313 --> 00:11:49.238
Motivul e că suntem 
un adversar inteligent;

00:11:49.238 --> 00:11:51.966
putem anticipa pericolul
și putem să-l preîntâmpinăm.

00:11:51.966 --> 00:11:54.470
Dar la fel ar fi 
și un agent superinteligent

00:11:54.470 --> 00:11:56.864
și ar fi mult mai bun decât noi.

00:11:57.724 --> 00:12:04.911
Faza e că nu ar trebui să credem
că deținem controlul aici.

00:12:04.911 --> 00:12:08.358
Am putea încerca, 
pentru a ne ușura un pic treaba,

00:12:08.358 --> 00:12:10.078
să zicem să punem I.A. într-o cutie,

00:12:10.078 --> 00:12:11.804
de pildă un mediu de soft securizat,

00:12:11.804 --> 00:12:14.766
o simulare de realitate virtuală
din care nu poate scăpa.

00:12:14.766 --> 00:12:18.912
Dar cât de siguri putem fi
că I.A. nu găsește un virus.

00:12:18.912 --> 00:12:22.081
Dat fiind că simplii hackeri umani 
găsesc tot timpul viruși,

00:12:22.081 --> 00:12:24.477
aș zice că, probabil, nu foarte siguri.

00:12:26.237 --> 00:12:30.155
Sau deconectăm cablul ethernet 
pentru a crea o întrerupere.

00:12:30.785 --> 00:12:32.893
Dar, la fel, simplii hackeri umani

00:12:32.893 --> 00:12:36.834
trec adesea peste întreruperi,
prin inginerie socială.

00:12:36.834 --> 00:12:38.093
Chiar în acest moment,

00:12:38.093 --> 00:12:40.482
sunt sigur că există un angajat pe undeva

00:12:40.482 --> 00:12:43.198
care este păcălit
să-și dea datele de cont

00:12:43.198 --> 00:12:46.414
de către cineva care se dă drept 
funcționar la departamentul I.T.

00:12:46.694 --> 00:12:48.701
Există și alte scenarii creative posibile

00:12:48.701 --> 00:12:50.016
cum ar fi: dacă ești I.A.

00:12:50.016 --> 00:12:53.598
ți-ai putea imagina să-ți pui 
electrozi în circuitul intern propriu

00:12:53.598 --> 00:12:56.980
pentru a crea unde radio 
pe care să le folosești pentru comunicare.

00:12:56.980 --> 00:12:59.604
Sau poate te-ai putea preface 
că nu funcționezi corect

00:12:59.604 --> 00:13:02.931
și apoi, când programatorii te deschid 
să vadă care-i baiul cu tine,

00:13:02.931 --> 00:13:04.567
se uită la codul-sursă – pac! –

00:13:04.567 --> 00:13:06.404
poate avea loc manipularea.

00:13:07.134 --> 00:13:10.744
Sau ar putea produce planul
unei tehnologii mișto

00:13:10.744 --> 00:13:12.142
și, când să o implementăm,

00:13:12.142 --> 00:13:16.369
ea are niște efecte secundare ascunse
pe care le-a gândit I.A.

00:13:17.019 --> 00:13:20.002
Concluzia este că nu ar trebui 
să avem prea mare încredere

00:13:20.002 --> 00:13:23.530
că putem ține duhul superinteligent 
închis în sticla sa pentru totdeauna.

00:13:23.810 --> 00:13:25.854
Mai degrabă sau mai târziu, va ieși.

00:13:27.034 --> 00:13:30.137
Cred că aici răspunsul este
să găsim modalitatea

00:13:30.137 --> 00:13:35.091
de a crea o I.A. superinteligentă
care, chiar și după ce scapă,

00:13:35.091 --> 00:13:38.438
e totuși sigură, pentru că
în mod fundamental e de partea noastră,

00:13:38.438 --> 00:13:40.337
pentru că are valorile noastre.

00:13:40.337 --> 00:13:43.547
Nu văd altă cale de rezolvare
a acestei probleme dificile.

00:13:45.577 --> 00:13:48.391
Sunt încrezător că putem rezolva
această problemă.

00:13:48.391 --> 00:13:52.294
Nu ar trebui să facem o listă lungă
cu toate lucrurile la care ținem

00:13:52.294 --> 00:13:55.937
sau, mai rău, să le traducem 
într-un limbaj mașină

00:13:55.937 --> 00:13:57.391
ca C++ sau Python.

00:13:57.391 --> 00:14:00.158
Asta ar fi o sarcină absolut imposibilă.

00:14:00.158 --> 00:14:04.455
În loc de asta, ar trebui să creăm o I.A.
ce-și folosește propria inteligență

00:14:04.455 --> 00:14:07.066
pentru a ne învăța valorile,

00:14:07.066 --> 00:14:10.556
iar sistemul ei de motivare 
să fie construit astfel încât

00:14:10.556 --> 00:14:13.438
să fie motivată să ne urmeze valorile

00:14:13.438 --> 00:14:17.358
sau să facă acțiuni la care se poate
aștepta să aibă aprobarea noastră.

00:14:18.208 --> 00:14:21.152
Astfel am avea, pe cât posibil, 
o pârghie asupra inteligenței

00:14:21.152 --> 00:14:23.897
în rezolvarea problemei 
valorilor încărcate.

00:14:24.567 --> 00:14:26.079
Se poate realiza,

00:14:26.079 --> 00:14:29.015
iar rezultatul ar fi foarte bun 
pentru umanitate.

00:14:29.835 --> 00:14:33.252
Dar asta nu se întâmplă automat.

00:14:33.792 --> 00:14:36.690
Condițiile inițiale 
pentru explozia de inteligență

00:14:36.690 --> 00:14:39.583
ar trebui setate corespunzător

00:14:39.583 --> 00:14:42.283
dacă vrem să avem o explozie controlată.

00:14:43.183 --> 00:14:45.801
Valorile I.A. trebuie să fie 
potrivite cu ale noastre,

00:14:45.801 --> 00:14:47.921
nu doar în contextul obișnuit,

00:14:47.921 --> 00:14:50.179
când putem verifica ușor 
comportamentul I.A.

00:14:50.179 --> 00:14:53.233
ci și în situațiile noi 
în care se va putea afla I.A.

00:14:53.233 --> 00:14:54.550
într-un viitor nedefinit.

00:14:54.550 --> 00:14:59.517
Există și aspecte ezoterice
ce vor trebui rezolvate, clarificate:

00:14:59.517 --> 00:15:01.616
detaliile exacte ale teoriei deciziilor,

00:15:01.616 --> 00:15:03.990
cum să trateze incertitudinea logică etc.

00:15:05.300 --> 00:15:08.262
Problemele tehnice de rezolvat
pentru ca aceasta să funcționeze

00:15:08.262 --> 00:15:09.465
par destul de dificile.

00:15:09.465 --> 00:15:12.805
Nu chiar așa de dificile
ca realizarea I.A. superinteligente,

00:15:12.805 --> 00:15:14.473
dar destul de dificile.

00:15:15.793 --> 00:15:17.528
Iată ce mă îngrijorează:

00:15:17.528 --> 00:15:21.162
realizarea I.A. superinteligente
e o mare provocare.

00:15:22.172 --> 00:15:24.720
Realizarea I.A. superinteligente
care este sigură

00:15:24.720 --> 00:15:27.136
implică probleme suplimentare.

00:15:28.386 --> 00:15:31.493
Riscul e ca cineva să reușească 
să rezolve prima provocare

00:15:31.493 --> 00:15:34.704
fără a găsi calea rezolvării 
problemelor suplimentare

00:15:34.704 --> 00:15:36.605
de asigurare a unei siguranțe perfecte.

00:15:37.375 --> 00:15:40.706
Cred că ar trebui să găsim o soluție

00:15:40.706 --> 00:15:43.378
pentru a controla problema în avans,

00:15:43.378 --> 00:15:45.908
pentru a o avea când va fi nevoie.

00:15:46.768 --> 00:15:50.275
S-ar putea să nu putem rezolva 
problema controlului total în avans

00:15:50.275 --> 00:15:53.299
pentru că poate unele elemente
pot fi puse la locul lor

00:15:53.299 --> 00:15:57.036
doar cunoscând detaliile arhitecturii
locului de implementare.

00:15:57.036 --> 00:16:00.946
Dar cu cât rezolvăm mai mult 
în avans problema controlului,

00:16:00.946 --> 00:16:04.546
cu atât sunt mai mari șansele ca trecerea 
la era inteligenței artificiale

00:16:04.546 --> 00:16:05.786
să decurgă lin.

00:16:06.306 --> 00:16:10.880
Mi se pare un lucru ce merită făcut

00:16:10.880 --> 00:16:15.412
și pot să îmi imaginez că, dacă iese bine,

00:16:15.412 --> 00:16:18.940
oamenii, peste un milion de ani,
privind înapoi la acest secol,

00:16:18.940 --> 00:16:22.772
ar putea foarte bine zice
că singurul lucru important făcut de noi

00:16:22.772 --> 00:16:24.329
a fost că am făcut aceasta bine.

00:16:24.329 --> 00:16:25.438
Mulțumesc.

00:16:25.438 --> 00:16:29.011
(Aplauze)

