WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Denise RQ
Revisor: Sebastian Betti

00:00:12.584 --> 00:00:16.793
Yo trabajo con un grupo de matemáticos,
filósofos y científicos informáticos,

00:00:16.794 --> 00:00:21.985
y nos juntamos para pensar en
el futuro de la inteligencia artificial,

00:00:21.986 --> 00:00:24.029
entre otras cosas.

00:00:24.030 --> 00:00:28.776
Algunos piensan que estas cosas
son una especie de ciencia ficción

00:00:28.777 --> 00:00:31.855
alocadas y alejadas de la verdad.

00:00:31.856 --> 00:00:33.325
Pero bueno, me gusta sugerir

00:00:33.326 --> 00:00:36.929
que analicemos la 
condición humana moderna.

00:00:36.930 --> 00:00:38.621
(Risas)

00:00:38.622 --> 00:00:41.023
Así es cómo tienen que ser las cosas.

00:00:41.024 --> 00:00:43.308
Pero si lo pensamos,

00:00:43.309 --> 00:00:46.601
en realidad acabamos de llegar
a este planeta,

00:00:46.602 --> 00:00:48.683
nosotros, la especie humana.

00:00:48.684 --> 00:00:53.429
Piensen que si la Tierra
hubiera sido creada hace un año,

00:00:53.430 --> 00:00:56.977
entonces la raza humana
solo tendría 10 minutos de edad

00:00:56.978 --> 00:01:00.146
y la era industrial habría empezado
hace dos segundos.

00:01:01.276 --> 00:01:06.250
Otra forma de abordar esto es pensar en
el PIB mundial en los últimos 10 000 años,

00:01:06.251 --> 00:01:09.929
y de hecho, me he tomado la molestia
de representarlo en un gráfico para Uds.

00:01:09.930 --> 00:01:11.303
Se ve así.

00:01:11.304 --> 00:01:12.426
(Risas)

00:01:12.427 --> 00:01:14.817
Tiene una forma curiosa para ser normal.

00:01:14.818 --> 00:01:16.935
Y seguro que no me gustaría
sentarme en ella.

00:01:16.936 --> 00:01:19.066
(Risas)

00:01:19.067 --> 00:01:23.840
Preguntémonos ¿cuál es la
causa de esta anomalía actual?

00:01:23.841 --> 00:01:26.392
Algunas personas dirán
que es la tecnología.

00:01:26.393 --> 00:01:31.060
Ahora bien es cierto que la tecnología
ha aumentado a lo largo de la historia,

00:01:31.061 --> 00:01:35.712
y en la actualidad avanza muy rápidamente

00:01:35.713 --> 00:01:37.277
--esa es la causa inmediata--

00:01:37.278 --> 00:01:39.843
y por esto la razón de ser
muy productivos hoy en día.

00:01:40.473 --> 00:01:44.134
Pero me gusta indagar más allá,
buscar la causa de todo.

00:01:45.114 --> 00:01:48.875
Miren a estos 2 caballeros
muy distinguidos:

00:01:48.876 --> 00:01:50.460
Tenemos a Kanzi,

00:01:50.480 --> 00:01:55.123
que domina 200 unidades léxicas,
una hazaña increíble,

00:01:55.125 --> 00:01:58.626
y a Ed Witten que desató la segunda
revolución de las supercuerdas.

00:01:58.626 --> 00:02:01.127
Si miramos atentamente
esto es lo que encontramos:

00:02:01.141 --> 00:02:02.710
básicamente la misma cosa.

00:02:02.711 --> 00:02:04.523
Uno es un poco más grande,

00:02:04.524 --> 00:02:08.291
y puede que también tenga algunos trucos
más por la forma en que está diseñado,

00:02:08.292 --> 00:02:12.033
sin embargo, estas diferencias invisibles
no pueden ser demasiado complicadas

00:02:12.034 --> 00:02:15.378
porque solo nos separan
250 000 generaciones

00:02:15.379 --> 00:02:17.110
de nuestro último ancestro común.

00:02:17.111 --> 00:02:20.960
Sabemos que los mecanismos complicados
tardan mucho tiempo en evolucionar

00:02:22.000 --> 00:02:24.498
así que una serie de pequeños cambios

00:02:24.499 --> 00:02:27.566
nos lleva de Kanzi a Witten,

00:02:27.584 --> 00:02:32.126
de las ramas de árboles rotas a
los misiles balísticos intercontinentales.

00:02:32.839 --> 00:02:36.553
Así que parece bastante claro
que todo lo que hemos logrado,

00:02:36.554 --> 00:02:38.151
y todo lo que nos importa,

00:02:38.152 --> 00:02:41.725
depende fundamentalmente de algunos 
cambios relativamente menores

00:02:41.726 --> 00:02:43.380
sufridos por la mente humana.

00:02:44.650 --> 00:02:48.311
Y el corolario es que, por supuesto,
cualquier cambio ulterior

00:02:48.312 --> 00:02:51.788
que cambiara significativamente
el fundamento del pensamiento

00:02:51.789 --> 00:02:54.991
podría potencialmente acarrear
enormes consecuencias.

00:02:56.321 --> 00:02:59.225
Algunos de mis colegas
piensan que estamos muy cerca

00:02:59.226 --> 00:03:03.134
de algo que podría causar un cambio 
significativo en ese fundamento

00:03:03.135 --> 00:03:06.334
y que eso es la máquina superinteligente.

00:03:06.347 --> 00:03:11.085
La inteligencia artificial solía ser
la integración de comandos en una caja,

00:03:11.086 --> 00:03:12.750
con programadores humanos

00:03:12.751 --> 00:03:15.885
que elaboraban conocimiento 
minuciosamente a mano.

00:03:15.886 --> 00:03:17.971
Se construían
estos sistemas especializados

00:03:17.972 --> 00:03:20.295
y eran bastante útiles
para ciertos propósitos,

00:03:20.296 --> 00:03:22.968
pero eran muy frágiles
y no se podían ampliar.

00:03:22.969 --> 00:03:26.376
Básicamente, se conseguía solamente
lo que se invertía en ellos.

00:03:26.410 --> 00:03:27.407
Pero desde entonces,

00:03:27.408 --> 00:03:31.082
hubo un cambio de paradigma en
el campo de la inteligencia artificial.

00:03:31.083 --> 00:03:35.001
Hoy, la acción gira en torno
al aprendizaje máquina.

00:03:35.002 --> 00:03:37.575
Así que en lugar de 
producir características

00:03:37.576 --> 00:03:40.820
y representar el conocimiento
de manera artesanal,

00:03:40.821 --> 00:03:46.064
creamos algoritmos que aprenden a menudo 
a partir de datos de percepción en bruto.

00:03:46.065 --> 00:03:51.062
Básicamente lo mismo
que hace el bebé humano.

00:03:51.063 --> 00:03:55.269
El resultado es inteligencia artificial
que no se limita a un solo campo;

00:03:55.270 --> 00:03:59.901
el mismo sistema puede aprender
a traducir entre cualquier par de idiomas

00:03:59.918 --> 00:04:05.335
o aprender a jugar a cualquier juego
de ordenador en la consola Atari.

00:04:05.338 --> 00:04:07.117
Ahora, por supuesto,

00:04:07.125 --> 00:04:11.121
la IA está todavía muy lejos de tener el
mismo poder y alcance interdisciplinario

00:04:11.122 --> 00:04:14.154
para aprender y planificar
como lo hacen los humanos.

00:04:14.155 --> 00:04:16.960
La corteza cerebral aún esconde
algunos trucos algorítmicos

00:04:16.961 --> 00:04:19.765
que todavía no sabemos
cómo simular en las máquinas.

00:04:19.766 --> 00:04:21.784
Así que la pregunta es,

00:04:21.785 --> 00:04:25.285
¿cuánto nos falta para poder
implementar esos trucos?

00:04:26.145 --> 00:04:27.138
Hace un par de años

00:04:27.139 --> 00:04:30.445
hicimos una encuesta entre los expertos
de IA más importantes del mundo

00:04:30.446 --> 00:04:33.559
para ver lo que piensan, y una
de las preguntas que hicimos fue,

00:04:33.560 --> 00:04:36.792
"¿En qué año crees que habrá
un 50 % de probabilidad en elevar

00:04:36.793 --> 00:04:40.275
la inteligencia artificial al mismo nivel
que la inteligencia humana?"

00:04:40.785 --> 00:04:44.627
Donde hemos definido ese nivel
como la capacidad de realizar

00:04:44.628 --> 00:04:48.168
casi todas las tareas, al menos así 
como las desarrolla un humano adulto,

00:04:48.169 --> 00:04:51.843
por lo cual, un nivel real no solo
dentro de un área limitada.

00:04:51.844 --> 00:04:55.493
Y la respuesta fue
alrededor de 2040 o 2050,

00:04:55.494 --> 00:04:58.299
dependiendo del grupo
de expertos consultados.

00:04:58.300 --> 00:05:02.338
Ahora, puede ocurrir
mucho más tarde o más temprano,

00:05:02.339 --> 00:05:04.559
la verdad es que nadie lo sabe realmente.

00:05:05.259 --> 00:05:09.671
Lo que sí sabemos es que el umbral
en el procesamiento de información

00:05:09.672 --> 00:05:12.042
en una infraestructura artificial

00:05:12.055 --> 00:05:15.301
se encuentra mucho más allá de 
los límites del tejido biológico.

00:05:15.302 --> 00:05:17.618
Esto pertenece al campo de la física.

00:05:17.619 --> 00:05:22.077
Una neurona biológica manda impulsos
quizá a 200 Hertz, 200 veces por segundo.

00:05:22.083 --> 00:05:25.917
mientras que incluso hoy, un transistor
opera a la frecuencia de los gigahercios.

00:05:25.931 --> 00:05:29.237
Las neuronas propagan el impulso
lentamente a lo largo de los axones,

00:05:29.238 --> 00:05:31.227
a máximo 100 metros por segundo.

00:05:31.228 --> 00:05:35.078
Pero en las computadoras, las señales
pueden viajar a la velocidad de la luz.

00:05:35.079 --> 00:05:36.947
También hay limitaciones de tamaño,

00:05:36.948 --> 00:05:39.974
como el cerebro humano que tiene
que encajar dentro del cráneo,

00:05:39.975 --> 00:05:44.735
pero una computadora puede ser del 
tamaño de un almacén o aún más grande.

00:05:44.736 --> 00:05:48.024
Así que el potencial de 
la máquina superinteligente

00:05:48.025 --> 00:05:50.334
permanece latente en la materia,

00:05:50.335 --> 00:05:56.046
al igual que el poder atómico
a lo largo de toda la historia

00:05:56.047 --> 00:06:00.451
que esperó pacientemente hasta 1945.

00:06:00.452 --> 00:06:03.609
De cara a este siglo los científicos
pueden aprender a despertar

00:06:03.610 --> 00:06:05.817
el poder de la inteligencia artificial

00:06:05.818 --> 00:06:09.826
y creo que podríamos ser testigos
de una explosión de inteligencia.

00:06:10.406 --> 00:06:14.420
Cuando la mayoría de la gente piensa
en lo inteligente o lo tonto

00:06:14.421 --> 00:06:17.385
creo que tienen en mente
una imagen más o menos así.

00:06:17.386 --> 00:06:19.983
En un extremo tenemos 
al tonto del pueblo,

00:06:19.984 --> 00:06:22.458
y lejos en el otro extremo,

00:06:22.459 --> 00:06:27.210
tenemos a Ed Witten o a Albert Einstein,
o quien sea su gurú favorito.

00:06:27.223 --> 00:06:31.056
Pero creo que desde el punto de 
vista de la inteligencia artificial,

00:06:31.057 --> 00:06:34.738
lo más probable es que la imagen
real sea la siguiente:

00:06:35.258 --> 00:06:38.635
Se empieza en este punto aquí,
en ausencia de inteligencia

00:06:38.636 --> 00:06:41.646
y luego, después de muchos,
muchos años de trabajo muy arduo,

00:06:41.647 --> 00:06:45.490
quizá finalmente lleguemos
al nivel intelectual de un ratón,

00:06:45.491 --> 00:06:47.920
algo que puede navegar
entornos desordenados

00:06:47.921 --> 00:06:49.907
igual que un ratón.

00:06:49.908 --> 00:06:52.114
Y luego, después de muchos,
muchos más años

00:06:52.115 --> 00:06:54.220
de trabajo muy arduo,
de mucha inversión,

00:06:54.221 --> 00:06:58.859
tal vez alcancemos el nivel de 
inteligencia de un chimpancé.

00:06:58.860 --> 00:07:02.070
Y luego, después de más años
de trabajo muy, muy arduo

00:07:02.083 --> 00:07:04.993
alcancemos la inteligencia artificial
del tonto del pueblo.

00:07:04.994 --> 00:07:08.104
Un poco más tarde,
estaremos más allá de Ed Witten.

00:07:08.105 --> 00:07:11.224
El tren del progreso no se detiene
en la estación de los Humanos.

00:07:11.225 --> 00:07:14.246
Es probable que más bien,
pase volando.

00:07:14.247 --> 00:07:16.230
Esto tiene profundas consecuencias,

00:07:16.231 --> 00:07:20.092
especialmente si se trata de poder.

00:07:20.093 --> 00:07:22.291
Por ejemplo, los chimpancés son fuertes.

00:07:22.292 --> 00:07:27.213
Un chimpancé es dos veces más fuerte
y en mejor forma física que un hombre

00:07:27.214 --> 00:07:31.827
y, sin embargo, el destino de Kanzi
y sus amigos depende mucho más

00:07:31.828 --> 00:07:35.968
de lo que hacemos los humanos
que de lo que ellos mismos hacen.

00:07:37.209 --> 00:07:39.541
Una vez que hay superinteligencia,

00:07:39.542 --> 00:07:43.381
el destino de la humanidad dependerá
de lo que haga la superinteligencia.

00:07:44.451 --> 00:07:45.507
Piensen en esto:

00:07:45.508 --> 00:07:48.258
la máquina inteligente
es el último invento

00:07:48.259 --> 00:07:50.551
que la humanidad jamás
tendrá que realizar.

00:07:50.552 --> 00:07:53.524
Las máquinas serán entonces
mejores inventores que nosotros,

00:07:53.525 --> 00:07:56.065
y lo harán a escala
de tiempo digital

00:07:56.083 --> 00:08:00.965
lo que significa básicamente
que acelerarán la cercanía al futuro.

00:08:00.966 --> 00:08:05.041
Piensen en todas las tecnologías
que tal vez, en su opinión,

00:08:05.042 --> 00:08:07.584
los humanos pueden desarrollar
con el paso del tiempo:

00:08:07.586 --> 00:08:10.710
tratamientos para el envejecimiento,
la colonización del espacio,

00:08:10.711 --> 00:08:14.293
nanobots autoreplicantes,
mentes integradas en las computadoras,

00:08:14.311 --> 00:08:16.469
todo tipo de ciencia-ficción

00:08:16.470 --> 00:08:19.206
y sin embargo en consonancia
con las leyes de la física.

00:08:19.207 --> 00:08:21.585
Todo esta superinteligencia
podría desarrollarse

00:08:21.586 --> 00:08:23.419
y posiblemente
con bastante rapidez.

00:08:24.449 --> 00:08:28.006
Ahora, una superinteligencia
con tanta madurez tecnológica

00:08:28.007 --> 00:08:30.185
sería extremadamente poderosa,

00:08:30.186 --> 00:08:34.732
y con la excepción de algunos casos
sería capaz de conseguir lo que quiere.

00:08:34.751 --> 00:08:39.585
Nuestro futuro se determinaría
por las preferencias de esta IA.

00:08:41.855 --> 00:08:45.604
Y una buena pregunta es
¿cuáles son esas preferencias?

00:08:46.244 --> 00:08:48.010
Aquí se vuelve más complicado.

00:08:48.013 --> 00:08:49.447
Para avanzar con esto,

00:08:49.448 --> 00:08:52.724
debemos en primer lugar
evitar el antropomorfismo.

00:08:53.933 --> 00:08:58.654
Y esto es irónico porque cada artículo
de prensa sobre el futuro de la IA

00:08:58.655 --> 00:09:01.090
presenta una imagen como esta:

00:09:02.700 --> 00:09:06.413
Así que creo que tenemos que 
pensar de manera más abstracta,

00:09:06.414 --> 00:09:09.204
no según escenarios
entretenidos de Hollywood.

00:09:09.209 --> 00:09:12.835
Tenemos que pensar en la inteligencia
como un proceso de optimización

00:09:12.836 --> 00:09:18.469
un proceso que dirige el futuro hacia un
conjunto especifico de configuraciones.

00:09:18.470 --> 00:09:21.980
Un superinteligencia es un proceso
de optimización realmente potente.

00:09:21.981 --> 00:09:25.037
Es muy bueno en el uso
de recursos disponibles

00:09:25.038 --> 00:09:28.007
para lograr un estado óptimo
y alcanzar su objetivo.

00:09:28.447 --> 00:09:31.118
Esto significa que no hay
ningún vínculo necesario

00:09:31.119 --> 00:09:33.852
entre ser muy inteligente en este sentido,

00:09:33.853 --> 00:09:38.496
y tener una meta que para los humanos
vale la pena o es significativa.

00:09:39.334 --> 00:09:43.124
Por ejemplo, la IA podría tener el
objetivo de hacer sonreír a los humanos.

00:09:43.125 --> 00:09:46.125
Cuando la IA está en desarrollo,
realiza acciones entretenidas

00:09:46.126 --> 00:09:48.613
para hacer sonreír a su usuario.

00:09:48.614 --> 00:09:51.030
Cuando la IA se vuelve superinteligente,

00:09:51.031 --> 00:09:54.553
se da cuenta de que hay una manera
más eficaz para lograr su objetivo:

00:09:54.554 --> 00:09:56.475
tomar el control del mundo

00:09:56.476 --> 00:09:59.637
e introducir electrodos en 
los músculos faciales de la gente

00:09:59.638 --> 00:10:02.578
para provocar sonrisas
constantes y radiantes.

00:10:02.579 --> 00:10:03.613
Otro ejemplo,

00:10:03.614 --> 00:10:07.416
supongamos que le damos el objetivo de
resolver un problema matemático difícil.

00:10:07.417 --> 00:10:09.383
Cuando la IA se vuelve superinteligente,

00:10:09.384 --> 00:10:13.334
se da cuenta de que la forma más eficaz
para conseguir la solución a este problema

00:10:13.335 --> 00:10:16.484
es mediante la transformación
del planeta en un computador gigante,

00:10:16.485 --> 00:10:18.730
para aumentar su capacidad de pensar.

00:10:18.731 --> 00:10:21.724
Y tengan en cuenta que esto da
a la IA una razón instrumental

00:10:21.725 --> 00:10:24.110
para hacer cosas que nosotros
no podemos aprobar.

00:10:24.111 --> 00:10:26.395
Los seres humanos
se convierten en una amenaza,

00:10:26.396 --> 00:10:29.126
ya que podríamos evitar
que el problema se resuelva.

00:10:29.127 --> 00:10:32.714
Por supuesto, las cosas no tienen
necesariamente que pasar de esa manera:

00:10:32.715 --> 00:10:34.453
son ejemplos de muestra.

00:10:34.454 --> 00:10:36.392
Pero lo importante,

00:10:36.393 --> 00:10:39.258
si crean un proceso
de optimización muy potente,

00:10:39.259 --> 00:10:41.500
optimizado para lograr el objetivo X,

00:10:41.501 --> 00:10:43.775
más vale asegurarse
de que la definición de X

00:10:43.776 --> 00:10:46.245
incluye todo lo que importa.

00:10:46.835 --> 00:10:51.218
Es una moraleja que también
se enseña a través de varios mitos.

00:10:51.219 --> 00:10:56.516
El rey Midas deseaba convertir
en oro todo lo que tocaba.

00:10:56.517 --> 00:10:59.377
Toca a su hija
y ella se convierte en oro.

00:10:59.378 --> 00:11:01.930
Toca su comida, se convierte en oro.

00:11:01.931 --> 00:11:04.519
Es un ejemplo relevante

00:11:04.520 --> 00:11:07.844
no solo de una metáfora de 
la codicia sino como ilustración

00:11:07.845 --> 00:11:11.321
de lo que sucede si crean
un proceso de optimización potente

00:11:11.322 --> 00:11:16.110
pero le encomiendan objetivos
incomprensibles o sin claridad.

00:11:16.111 --> 00:11:17.453
Uno puede pensar:

00:11:17.454 --> 00:11:21.540
"Si una computadora empieza a poner
electrodos en la cara de la gente

00:11:21.542 --> 00:11:23.584
bastaría simplemente con apagarla.

00:11:24.555 --> 00:11:27.132
En primer lugar, puede
que no sea tan sencillo

00:11:27.133 --> 00:11:29.894
si somos dependientes del sistema

00:11:29.895 --> 00:11:32.626
por ejemplo: ¿dónde está el botón
para apagar Internet?

00:11:32.627 --> 00:11:35.370
En segundo lugar,
¿por qué los chimpancés

00:11:35.375 --> 00:11:39.334
no tienen acceso al mismo interruptor
de la humanidad, o los neandertales?

00:11:39.335 --> 00:11:41.963
Sin duda razones tendrían.

00:11:41.964 --> 00:11:44.758
Tenemos un interruptor de apagado,
por ejemplo, aquí mismo.

00:11:44.759 --> 00:11:46.312
(Finge estrangulación)

00:11:46.313 --> 00:11:49.237
La razón es que somos
un adversario inteligente;

00:11:49.238 --> 00:11:51.895
podemos anticipar amenazas
y planificar en consecuencia,

00:11:51.896 --> 00:11:54.469
pero también podría hacerlo
un agente superinteligente,

00:11:54.470 --> 00:11:57.723
y mucho mejor que nosotros.

00:11:57.724 --> 00:12:00.591
El tema es que no debemos confiar

00:12:02.661 --> 00:12:04.910
que podemos controlar esta situación.

00:12:04.911 --> 00:12:08.357
Y podríamos tratar de hacer nuestro
trabajo un poco más fácil digamos,

00:12:08.358 --> 00:12:11.767
poniendo a la IA en una caja,
en un entorno de software seguro,

00:12:11.768 --> 00:12:14.765
una simulación de realidad virtual
de la que no pueda escapar.

00:12:14.766 --> 00:12:18.912
Pero, ¿cómo podemos estar seguros
de que la IA no encontrará un error?

00:12:18.918 --> 00:12:22.377
Dado que incluso los hackers humanos
encuentran errores todo el tiempo,

00:12:22.381 --> 00:12:25.117
yo diría que probablemente,
no podemos estar muy seguros.

00:12:26.250 --> 00:12:30.620
Así que desconectamos el cable ethernet
para crear un espacio vacío,

00:12:30.621 --> 00:12:33.452
pero una vez más, al igual
que los hackers humanos,

00:12:33.453 --> 00:12:36.813
podrían superar estos espacios
usando la ingeniería social.

00:12:36.814 --> 00:12:38.162
Ahora mismo, mientras hablo,

00:12:38.163 --> 00:12:40.581
estoy seguro de que algún
empleado, en algún lugar

00:12:40.582 --> 00:12:43.828
ha sido convencido para revelar
los detalles de su cuenta

00:12:43.834 --> 00:12:46.573
por alguien que dice ser
del departamento de IT.

00:12:46.574 --> 00:12:48.850
Otros escenarios creativos
también son posibles,

00:12:48.851 --> 00:12:50.205
por ejemplo si Ud. es la IA,

00:12:50.206 --> 00:12:53.717
puede hacer cambios en los electrodos
de su circuito interno de seguridad

00:12:53.718 --> 00:12:57.009
para crear ondas de radio y
usarlas para comunicarse.

00:12:57.010 --> 00:12:59.253
O tal vez fingir un mal funcionamiento,

00:12:59.254 --> 00:13:02.861
y cuando los programadores
lo abren para entender qué está mal,

00:13:02.862 --> 00:13:04.798
al mirar el código fuente, ¡pum!

00:13:04.799 --> 00:13:07.244
ya empieza a manipular.

00:13:07.245 --> 00:13:10.674
O podría idear un programa
tecnológico realmente ingenioso,

00:13:10.675 --> 00:13:12.182
y cuando lo implementamos,

00:13:12.183 --> 00:13:16.538
tener efectos secundarios
ocultos planeados por la IA.

00:13:16.539 --> 00:13:20.001
No debemos confiar en nuestra capacidad

00:13:20.002 --> 00:13:23.809
para mantener un genio superinteligente
encerrado en su lámpara para siempre.

00:13:23.810 --> 00:13:26.064
Tarde o temprano, saldrá.

00:13:27.034 --> 00:13:32.226
Creo que la solución es averiguar
cómo crear una IA superinteligente

00:13:32.227 --> 00:13:36.250
para que incluso si, o cuando
se escape, sea todavía segura

00:13:36.251 --> 00:13:40.397
para que fundamentalmente esté de
nuestro lado y comparta nuestros valores.

00:13:40.398 --> 00:13:43.547
No veo cómo evitar
este problema difícil.

00:13:44.557 --> 00:13:48.543
En realidad soy bastante optimista de
que este problema pueda ser resuelto.

00:13:48.544 --> 00:13:52.293
No tendríamos que escribir una larga
lista de todo lo que nos importa,

00:13:52.294 --> 00:13:55.937
o, peor aún, codificarla
en algún lenguaje informático

00:13:55.938 --> 00:13:57.377
como C++ o Python,

00:13:57.391 --> 00:14:00.157
sería una reto imposible.

00:14:00.158 --> 00:14:04.454
A cambio, crearíamos una IA 
que use su inteligencia

00:14:04.455 --> 00:14:07.225
para aprender lo que valoramos,

00:14:07.226 --> 00:14:09.846
y su sistema integrado
de motivación sería diseñado

00:14:11.926 --> 00:14:13.844
para defender nuestros valores

00:14:13.845 --> 00:14:17.737
y realizar acciones
que se ajusten a ellos.

00:14:17.738 --> 00:14:21.151
Así que usaríamos su inteligencia
tanto como fuera posible

00:14:21.152 --> 00:14:23.897
para resolver el problema
de la atribución de valores.

00:14:24.727 --> 00:14:26.238
Esto puede suceder,

00:14:26.239 --> 00:14:29.834
y el resultado podría ser
muy bueno para la humanidad.

00:14:29.835 --> 00:14:33.791
Pero no sucede automáticamente.

00:14:33.792 --> 00:14:36.789
Las condiciones iniciales
para la explosión de la inteligencia

00:14:36.790 --> 00:14:39.652
necesitan ser perfectamente definidas

00:14:39.653 --> 00:14:43.102
si queremos contar con
una detonación controlada.

00:14:43.103 --> 00:14:45.920
Los valores de la IA tienen
que coincidir con los nuestros

00:14:45.921 --> 00:14:47.490
no solo en el ámbito familiar,

00:14:47.491 --> 00:14:49.998
donde podemos comprobar
fácilmente cómo se comporta,

00:14:49.999 --> 00:14:53.232
sino también en todos los nuevos contextos

00:14:53.233 --> 00:14:55.879
donde la IA podría encontrarse
en un futuro indefinido.

00:14:55.880 --> 00:14:59.567
Y también hay algunas cuestiones
esotéricas que habría que resolver:

00:14:59.568 --> 00:15:01.945
los detalles exactos de
su teoría de la decisión,

00:15:01.946 --> 00:15:04.480
cómo manejar la incertidumbre lógica, etc.

00:15:05.330 --> 00:15:07.958
Así que los problemas
técnicos que hay que resolver

00:15:07.959 --> 00:15:10.126
para hacer este trabajo
parecen muy difíciles

00:15:10.162 --> 00:15:12.922
--no tan difíciles como crear
una IA superinteligente--

00:15:12.923 --> 00:15:14.502
pero bastante difíciles.

00:15:15.793 --> 00:15:17.488
Este es la preocupación:

00:15:17.501 --> 00:15:21.127
crear una IA superinteligente
es un reto muy difícil

00:15:22.172 --> 00:15:24.719
y crear una que sea segura

00:15:24.720 --> 00:15:27.256
implica desafíos adicionales.

00:15:28.586 --> 00:15:32.092
El riesgo es si alguien encuentra
la manera de superar el primer reto

00:15:32.093 --> 00:15:36.564
sin resolver el otro desafío
de garantizar la máxima seguridad.

00:15:37.375 --> 00:15:40.705
Así que creo que deberíamos
encontrar una solución

00:15:40.706 --> 00:15:43.527
al problema del control por adelantado,

00:15:43.528 --> 00:15:46.188
de modo que esté disponible
para cuando sea necesario.

00:15:46.768 --> 00:15:49.137
Puede ser que no podamos
resolver por completo

00:15:49.138 --> 00:15:50.864
el problema del control de antemano

00:15:50.865 --> 00:15:53.968
porque tal vez, algunos elementos
solo pueden ser desarrollados

00:15:53.959 --> 00:15:57.293
después de reunir los detalles
técnicos de la IA en cuestión.

00:15:57.296 --> 00:16:00.675
Pero cuanto antes solucionemos
el problema del control,

00:16:00.676 --> 00:16:02.217
mayores serán las probabilidades

00:16:02.218 --> 00:16:05.055
de que la transición a la era
de las máquinas inteligentes

00:16:05.056 --> 00:16:06.305
vaya bien.

00:16:06.306 --> 00:16:10.949
Esto me parece algo digno de hacer

00:16:10.950 --> 00:16:14.281
y puedo imaginar que si
las cosas salen bien,

00:16:14.282 --> 00:16:18.939
la gente en un millón de años 
discutirá nuestro siglo

00:16:18.940 --> 00:16:22.586
y dirá que posiblemente lo único
que hicimos bien y mereció la pena

00:16:22.587 --> 00:16:24.508
fue superar con éxito este reto.

00:16:24.509 --> 00:16:25.787
Gracias.

00:16:25.788 --> 00:16:27.271
(Aplausos)

