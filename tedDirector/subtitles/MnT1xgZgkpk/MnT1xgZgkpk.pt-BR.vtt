WEBVTT
Kind: captions
Language: pt-BR

00:00:00.000 --> 00:00:12.000
Tradutor: Ruy Lopes Pereira
Revisor: Gustavo Rocha

00:00:12.570 --> 00:00:17.007
Eu trabalho com um grupo de matemáticos,
filósofos e cientistas da computação,

00:00:17.007 --> 00:00:21.986
e trocamos ideias sobre o futuro
da inteligência das máquinas,

00:00:21.986 --> 00:00:24.030
entre outras coisas.

00:00:24.030 --> 00:00:28.755
Alguns consideram essas coisas
como ficção científica,

00:00:28.755 --> 00:00:31.856
muito irreais, malucas.

00:00:31.856 --> 00:00:33.326
Mas eu gosto de dizer:

00:00:33.326 --> 00:00:36.930
certo, vamos olhar
a condição humana moderna.

00:00:36.930 --> 00:00:38.622
(Risos)

00:00:38.622 --> 00:00:41.024
Este é o modo normal das coisas.

00:00:41.024 --> 00:00:43.309
Mas se pensarmos bem,

00:00:43.309 --> 00:00:46.492
somos hóspedes
muito recentes deste planeta.

00:00:46.492 --> 00:00:48.684
Nós, a espécie humana.

00:00:48.684 --> 00:00:53.430
Imaginem que a Terra
tenha sido criada há um ano,

00:00:53.430 --> 00:00:56.698
então a espécie humana
existiria apenas há 10 minutos.

00:00:56.698 --> 00:01:00.146
A era industrial teria começado
dois segundos atrás.

00:01:00.866 --> 00:01:06.281
Outro modo de encarar isto é pensar
no PIB global dos últimos 10 mil anos.

00:01:06.281 --> 00:01:09.530
Eu me dei ao trabalho de colocar
isso num gráfico para vocês.

00:01:09.530 --> 00:01:10.900
Ele tem este aspecto.

00:01:10.900 --> 00:01:12.277
(Risos)

00:01:12.277 --> 00:01:14.818
É uma forma curiosa
para uma condição normal.

00:01:14.818 --> 00:01:16.516
Não gostaria de me sentar nele.

00:01:16.516 --> 00:01:18.607
(Risos)

00:01:19.067 --> 00:01:23.841
Perguntemo-nos:
qual é a causa da anomalia atual?

00:01:23.841 --> 00:01:26.393
Alguns diriam que é a tecnologia.

00:01:26.393 --> 00:01:28.061
É verdade,

00:01:28.061 --> 00:01:31.061
a tecnologia tem se acumulado
através da história

00:01:31.061 --> 00:01:35.313
e atualmente, ela avança
com extrema rapidez...

00:01:35.313 --> 00:01:37.278
esta é a causa mais imediata,

00:01:37.278 --> 00:01:39.843
e a razão de sermos
muito produtivos hoje em dia.

00:01:40.473 --> 00:01:44.134
Mas gosto de buscar no passado distante
a causa fundamental de tudo.

00:01:45.114 --> 00:01:48.660
Observem estes dois distintos senhores:

00:01:48.690 --> 00:01:50.480
Temos o Kanzi...

00:01:50.480 --> 00:01:55.123
ele domina 200 símbolos
de léxicos, um feito incrível.

00:01:55.123 --> 00:01:58.817
E Ed Witten, que desencadeou
a segunda revolução da supercorda.

00:01:58.817 --> 00:02:00.881
Dentro do crânio,
eis o que descobriremos:

00:02:00.881 --> 00:02:02.711
essencialmente a mesma coisa.

00:02:02.711 --> 00:02:04.524
Um deles é um pouco maior,

00:02:04.524 --> 00:02:07.592
pode ter alguns truques a mais,
devido à sua arquitetura.

00:02:07.592 --> 00:02:11.094
Contudo, essas diferenças invisíveis,
não podem ser muito complicadas,

00:02:11.094 --> 00:02:15.379
porque foram apenas 250 mil gerações

00:02:15.379 --> 00:02:17.111
desde o último ancestral comum.

00:02:17.111 --> 00:02:20.960
Sabemos que mecanismos complicados
levam muito tempo para evoluir.

00:02:21.790 --> 00:02:24.499
Então um conjunto de pequenas mudanças

00:02:24.499 --> 00:02:27.566
nos levam do Kanzi ao Witten,

00:02:27.566 --> 00:02:32.109
de galhos de árvores quebrados
a mísseis balísticos intercontinentais.

00:02:32.619 --> 00:02:36.774
Parece bastante óbvio
que tudo que realizamos,

00:02:36.774 --> 00:02:39.720
e tudo o que prezamos
depende de modo crucial

00:02:39.720 --> 00:02:44.650
de mudanças relativamente pequenas
que fizeram a mente humana.

00:02:44.650 --> 00:02:48.312
E tem como consequência, é claro,
que quaisquer mudanças posteriores

00:02:48.312 --> 00:02:51.789
que possam alterar significativamente
o substrato do pensamento

00:02:51.789 --> 00:02:54.991
poderiam ter enormes consequências.

00:02:56.321 --> 00:02:59.226
Alguns colegas acham
que estamos muito próximos

00:02:59.226 --> 00:03:03.134
de algo que poderia causar
uma profunda mudança no substrato,

00:03:03.134 --> 00:03:06.347
que é a máquina superinteligente.

00:03:06.347 --> 00:03:11.086
A inteligência artificial costumava ser
colocar comandos em uma caixa.

00:03:11.086 --> 00:03:15.931
Programadores humanos elaborariam
penosamente itens de conhecimento.

00:03:16.491 --> 00:03:18.422
Construímos tais sistemas inteligentes

00:03:18.422 --> 00:03:20.426
e eles eram úteis
para algumas finalidades,

00:03:20.426 --> 00:03:22.937
mas eram muito frágeis,
não podiam ser ampliados.

00:03:22.937 --> 00:03:26.090
Essencialmente, obtinha-se deles
o que havia sido colocado neles.

00:03:26.090 --> 00:03:27.407
Desde então,

00:03:27.407 --> 00:03:30.874
houve uma mudança de paradigma
no campo da inteligência artificial.

00:03:30.874 --> 00:03:33.644
Hoje, o esforço é voltado
à aprendizagem das máquinas.

00:03:34.394 --> 00:03:39.781
Em vez de construirmos representações
do conhecimento e recursos,

00:03:40.511 --> 00:03:43.065
criamos algoritmos que aprendem,

00:03:43.065 --> 00:03:46.065
quase sempre a partir
de dados não tratados de percepção.

00:03:46.065 --> 00:03:51.063
Basicamente a mesma coisa
que o bebê humano faz.

00:03:51.063 --> 00:03:55.270
O resultado é IA que não se limita
a um único domínio,

00:03:55.270 --> 00:03:59.901
o mesmo sistema pode aprender
a traduzir qualquer par de idiomas,

00:03:59.901 --> 00:04:05.338
ou aprender a jogar qualquer game
de computador num console Atari.

00:04:05.338 --> 00:04:06.947
Agora, é claro,

00:04:06.947 --> 00:04:11.116
a IA ainda não está nada perto
de ter a mesma poderosa habilidade

00:04:11.116 --> 00:04:14.225
de aprender e planejar em várias áreas,
como o ser humano.

00:04:14.225 --> 00:04:16.461
O córtex ainda guarda
segredos de algoritmos

00:04:16.461 --> 00:04:19.806
que ainda não sabemos
como reproduzir nas máquinas.

00:04:19.806 --> 00:04:21.645
Então a questão é:

00:04:21.645 --> 00:04:25.595
"Estamos muito longe de podermos
reproduzir essas proezas?"

00:04:26.065 --> 00:04:30.918
Há alguns anos, pesquisamos o que pensavam
os maiores especialistas em IA do mundo.

00:04:30.918 --> 00:04:33.440
E uma das perguntas que fizemos foi:

00:04:33.440 --> 00:04:36.793
“Em qual ano você acha que haverá
50% de probabilidade

00:04:36.793 --> 00:04:40.275
de termos conseguido a inteligência
de máquinas com nível humano?"

00:04:40.785 --> 00:04:44.968
Definimos o nível humano
como a habilidade de realizar

00:04:44.968 --> 00:04:47.839
quase toda tarefa pelo menos
tão bem quanto um adulto humano.

00:04:47.839 --> 00:04:51.624
Então, nível humano real,
não apenas em alguma área limitada.

00:04:51.624 --> 00:04:55.294
E a resposta foi em média 2040 ou 2050,

00:04:55.294 --> 00:04:58.300
dependendo do grupo
de especialistas consultado.

00:04:58.750 --> 00:05:02.339
Poderá acontecer muito mais tarde
ou mais cedo,

00:05:02.339 --> 00:05:04.279
a verdade é que ninguém sabe.

00:05:05.169 --> 00:05:09.671
O que sabemos é que o último limite
do processamento da informação

00:05:09.671 --> 00:05:14.542
em um substrato de máquina situa-se
bem além dos limites do tecido biológico.

00:05:15.241 --> 00:05:17.329
Isto pertence ao domínio da física.

00:05:17.329 --> 00:05:22.337
Um neurônio dispara, talvez,
a 200 hertz, 200 vezes por segundo.

00:05:22.337 --> 00:05:25.931
Até mesmo os transistores atuais operam
à frequência de gigahertz.

00:05:25.931 --> 00:05:28.598
Os neurônios se propagam
lentamente nos axônios,

00:05:28.598 --> 00:05:31.228
no máximo a 100 metros por segundo.

00:05:31.228 --> 00:05:34.339
Mas nos computadores,
os sinais viajam à velocidade da luz.

00:05:34.789 --> 00:05:36.758
Há também limitações de tamanho,

00:05:36.758 --> 00:05:39.715
como a do cérebro humano
ter que caber no crânio,

00:05:39.715 --> 00:05:44.036
mas um computador pode ser do tamanho
de um armazém ou maior ainda.

00:05:44.036 --> 00:05:50.335
Então o potencial para a superinteligência
de certa forma está latente na matéria,

00:05:50.335 --> 00:05:56.047
do mesmo modo que o poder do átomo
permaneceu latente durante a história,

00:05:56.047 --> 00:06:00.452
esperando pacientemente até 1945.

00:06:00.452 --> 00:06:02.830
Neste século, cientistas podem descobrir

00:06:02.830 --> 00:06:05.818
como despertar
o poder da inteligência artificial.

00:06:05.818 --> 00:06:09.826
Eu penso que poderemos presenciar
uma explosão de inteligência.

00:06:10.406 --> 00:06:14.163
Quando a maioria das pessoas pensa
sobre o que é inteligente ou estúpido,

00:06:14.163 --> 00:06:17.386
acho que elas têm em mente
uma imagem como esta.

00:06:17.386 --> 00:06:19.984
Num extremo tem-se um idiota

00:06:19.984 --> 00:06:22.467
e lá longe, no outro extremo,

00:06:22.467 --> 00:06:27.223
temos o Ed Witten, ou Albert Einstein,
ou o seu guru favorito.

00:06:27.223 --> 00:06:31.057
Mas penso que do ponto de vista
da inteligência artificial,

00:06:31.057 --> 00:06:34.738
é mais provável
que o quadro real seja assim:

00:06:35.258 --> 00:06:38.636
a IA começa neste ponto,
na ausência de inteligência,

00:06:38.636 --> 00:06:41.647
e então, após muitos anos
de trabalho bastante duro,

00:06:41.647 --> 00:06:45.491
talvez cheguemos ao nível
de inteligência de um rato,

00:06:45.491 --> 00:06:47.921
algo capaz de se mover
em ambientes desorganizados

00:06:47.921 --> 00:06:49.908
tão bem quanto um rato.

00:06:49.908 --> 00:06:54.221
E a seguir, após muitos anos
de trabalho duro, de muito investimento,

00:06:54.221 --> 00:06:58.860
talvez cheguemos ao nível
da inteligência de um chimpanzé.

00:06:58.860 --> 00:07:02.070
E depois de ainda muito mais anos
de trabalho realmente árduo,

00:07:02.070 --> 00:07:04.983
atinjamos a inteligência artificial
de um idiota.

00:07:04.983 --> 00:07:08.255
Alguns momentos mais tarde,
estamos além de Ed Witten.

00:07:08.255 --> 00:07:11.225
O trem não para
na Estação Cidade da Humanidade.

00:07:11.225 --> 00:07:14.247
É provável que passe zunindo, sem parar.

00:07:14.247 --> 00:07:16.231
Isso tem implicações profundas,

00:07:16.231 --> 00:07:20.093
particularmente no que se refere
a questões de poder.

00:07:20.093 --> 00:07:22.972
Por exemplo, um chimpanzé é
duas vezes mais forte

00:07:22.972 --> 00:07:27.314
do que um humano do sexo masculino
e em boa forma física.

00:07:27.314 --> 00:07:31.828
Apesar disso, o destino de Kanzi
e seus amigos depende muito mais

00:07:31.828 --> 00:07:35.478
do que fazem os humanos
e não do que fazem os chimpanzés.

00:07:37.228 --> 00:07:39.542
Quando houver a superinteligência,

00:07:39.542 --> 00:07:43.941
o destino da humanidade pode depender
do que a superinteligência fizer.

00:07:44.311 --> 00:07:45.508
Pensem nisso.

00:07:45.508 --> 00:07:50.192
Máquina inteligente é a última invenção
que a humanidade precisará fazer.

00:07:50.192 --> 00:07:53.525
As máquinas então serão
melhores inventoras do que nós

00:07:53.525 --> 00:07:56.065
e elas o farão
numa escala de tempo digital.

00:07:56.065 --> 00:08:00.966
Basicamente significa fazer
o futuro ficar mais próximo.

00:08:00.966 --> 00:08:04.244
Imaginem todas as possíveis
tecnologias malucas

00:08:04.244 --> 00:08:07.442
que os humanos poderiam ter desenvolvido
num longo espaço de tempo:

00:08:07.442 --> 00:08:10.580
curas para o envelhecimento,
a colonização do espaço,

00:08:10.580 --> 00:08:14.090
robôs autorreplicantes, ou fazer o upload
de mentes em computadores,

00:08:14.090 --> 00:08:16.350
tudo coisas do repertório
da ficção científica

00:08:16.350 --> 00:08:18.957
embora consistentes com as leis da física.

00:08:18.957 --> 00:08:21.449
Tudo isso a superinteligência
pode desenvolver

00:08:21.449 --> 00:08:24.129
e talvez bem rapidamente.

00:08:24.129 --> 00:08:30.017
Uma inteligência assim tão desenvolvida
seria extremamente poderosa

00:08:30.017 --> 00:08:34.732
e pelo menos em certas situações,
seria capaz de obter o que desejasse.

00:08:34.732 --> 00:08:40.393
O nosso futuro seria determinado
pelas preferências da IA.

00:08:41.645 --> 00:08:45.604
Qual seriam essas preferências?
É uma boa pergunta.

00:08:46.244 --> 00:08:48.013
É aqui que a coisa se complica.

00:08:48.013 --> 00:08:49.448
Para prosseguirmos com isto,

00:08:49.448 --> 00:08:52.724
primeiro devemos evitar
a antropomorfização.

00:08:53.934 --> 00:08:57.235
E é irônico, pois toda matéria de revista

00:08:57.235 --> 00:09:01.090
sobre o futuro da IA
publica um fotografia assim.

00:09:02.280 --> 00:09:06.414
Eu acho que precisamos considerar
a questão mais abstratamente,

00:09:06.414 --> 00:09:09.204
não em termos hollywoodianos.

00:09:09.204 --> 00:09:12.821
Precisamos pensar na inteligência
como um processo de otimização

00:09:12.821 --> 00:09:15.470
que direciona o futuro

00:09:15.470 --> 00:09:18.470
para um conjunto específco
de configurações.

00:09:18.470 --> 00:09:21.981
Uma superinteligência é
um poderoso processo de otimização.

00:09:21.981 --> 00:09:25.018
É extremamente eficiente
em usar os recursos disponíveis

00:09:25.018 --> 00:09:28.007
para atingir seu objetivo.

00:09:28.267 --> 00:09:31.119
Quer dizer que não há necessária ligação

00:09:31.119 --> 00:09:33.853
entre ser muito inteligente neste sentido,

00:09:33.853 --> 00:09:38.515
e ter um objetivo que os humanos
julgariam valer a pena ou ser importante.

00:09:38.891 --> 00:09:43.115
Suponham que déssemos a uma IA
o objetivo de fazer as pessoas sorrirem.

00:09:43.115 --> 00:09:46.097
Quando a IA é fraca, ela realiza
ações úteis ou engraçadas

00:09:46.097 --> 00:09:48.614
que fazem o usuário sorrir.

00:09:48.614 --> 00:09:51.031
Quando a IA se torna superinteligente,

00:09:51.031 --> 00:09:54.554
ela percebe que há um modo
mais eficiente de atingir o objetivo:

00:09:54.554 --> 00:09:56.476
assume o controle do mundo

00:09:56.476 --> 00:09:59.638
e introduz eletrodos nos músculos
das faces das pessoas

00:09:59.638 --> 00:10:02.149
provocando sorrisos
constantes e radiantes.

00:10:02.149 --> 00:10:04.694
Outro exemplo:
suponham que atribuamos à IA

00:10:04.694 --> 00:10:07.067
a meta de resolver
um problema matemático difícil.

00:10:07.067 --> 00:10:08.934
Quando a IA se torna superinteligente,

00:10:08.934 --> 00:10:13.105
ela percebe que o modo mais eficiente
de obter a solução do problema

00:10:13.105 --> 00:10:16.035
é transformar o planeta
em um computador gigantesco,

00:10:16.035 --> 00:10:18.281
para aumentar sua capacidade de pensar.

00:10:18.281 --> 00:10:21.895
E notem que isso dá às IAs
uma razão instrumental para fazerem coisas

00:10:21.895 --> 00:10:23.781
com as quais talvez não concordássemos.

00:10:23.781 --> 00:10:25.896
Neste modelo, os humanos são ameaças

00:10:25.896 --> 00:10:28.427
que poderiam impedir a solução
do problema matemático.

00:10:28.427 --> 00:10:32.431
É evidente que não haverá
problemas desta natureza;

00:10:32.431 --> 00:10:34.454
estes são exemplos de desenho animado.

00:10:34.454 --> 00:10:36.393
Mas a questão mais geral é importante:

00:10:36.393 --> 00:10:39.266
se criarmos um processo de otimização
realmente poderoso,

00:10:39.266 --> 00:10:41.500
otimizado para o objetivo x,

00:10:41.500 --> 00:10:43.776
é bom ter certeza
de que a sua definição de x

00:10:43.776 --> 00:10:46.245
incorpora tudo o que lhe interessa.

00:10:46.835 --> 00:10:51.219
Esta lição também é ensinada
como um mito.

00:10:51.219 --> 00:10:56.517
O rei Midas deseja que tudo que ele tocar
transforme-se em ouro.

00:10:56.517 --> 00:10:59.378
Ele toca sua filha
e ela se transforma em ouro.

00:10:59.378 --> 00:11:01.931
Ele toca sua comida e ela vira ouro.

00:11:01.931 --> 00:11:04.520
Isto poderia tornar-se relevante
em termos práticos,

00:11:04.520 --> 00:11:08.180
não apenas uma metáfora para a ganância,
mas uma ilustração do que acontece

00:11:08.180 --> 00:11:11.232
quando se cria um processo
poderoso de otimização

00:11:11.232 --> 00:11:16.011
e se fornecem objetivos incompreensíveis
ou especificados sem clareza.

00:11:16.011 --> 00:11:19.780
Poderíamos dizer que,
se um computador puser eletrodos

00:11:19.780 --> 00:11:23.300
nas faces das pessoas,
bastaria desligá-lo.

00:11:23.935 --> 00:11:27.365
A: isso não é necessariamente
fácil de fazer

00:11:27.365 --> 00:11:29.895
se nos tormanos dependentes do sistema,

00:11:29.895 --> 00:11:32.627
por exemplo: onde fica o botão
para desligar a Internet?

00:11:32.627 --> 00:11:36.097
B: por que os chimpanzés ou os neandertais

00:11:36.097 --> 00:11:39.198
não interroperam voluntariamente
sua evolução para a humanidade?

00:11:39.198 --> 00:11:41.964
Eles certamente tiveram motivos para isso.

00:11:41.964 --> 00:11:44.759
Por exemplo, não temos
uma chave para desligar aqui.

00:11:44.759 --> 00:11:46.463
(Engasgando)

00:11:46.463 --> 00:11:49.078
É que somos um adversário inteligente;

00:11:49.078 --> 00:11:51.966
podemos antecipar as ameaças
e planejar levando-as em conta.

00:11:51.966 --> 00:11:54.600
Mas um agente superinteligente
também poderia fazê-lo

00:11:54.600 --> 00:11:57.724
e muito melhor do que nós.

00:11:57.724 --> 00:12:00.961
Não deveríamos confiar

00:12:02.581 --> 00:12:04.911
que temos tudo sob o nosso controle.

00:12:04.911 --> 00:12:08.078
Poderíamos tornar nossa tarefa
um pouco mais fácil, digamos,

00:12:08.078 --> 00:12:11.758
protegendo a IA num ambiente
de software seguro,

00:12:11.758 --> 00:12:14.856
uma simulação de realidade virtual
da qual ela não possa escapar.

00:12:14.856 --> 00:12:18.912
Mas como termos certeza
de que a IA não descobriria uma brecha?

00:12:18.912 --> 00:12:21.851
Visto que os hackers
encontram falhas a toda hora,

00:12:21.851 --> 00:12:25.117
eu diria que não temos muita certeza.

00:12:26.127 --> 00:12:30.355
Então desconectaríamos o cabo Ethernet
para criar um “air gap",

00:12:30.355 --> 00:12:34.553
mas de novo, os hackers
transgridem rotineiramebte os air gaps

00:12:35.203 --> 00:12:36.834
usando a engenharia social.

00:12:36.834 --> 00:12:40.412
Enquanto eu falo,
tenho certeza de que algum funcionário

00:12:40.412 --> 00:12:43.458
foi convencido a revelar
os detalhes de sua conta

00:12:43.458 --> 00:12:46.394
para alguém que dizia ser
do departamento de TI.

00:12:46.394 --> 00:12:48.666
Situações mais criativas
também são possíveis,

00:12:48.666 --> 00:12:52.048
como se você for a IA,
pode imaginar colocar muitos eletrodos

00:12:52.048 --> 00:12:53.880
no circuito de segurança interna

00:12:53.880 --> 00:12:56.874
para criar ondas de rádio
que podem ser usadas para comunicação.

00:12:56.874 --> 00:13:01.541
Ou talvez pudesse fingir um defeito
e quando os programadores lhe abrissem

00:13:01.541 --> 00:13:04.642
para investigar o que está errado
eles veriam o código-fonte, bum!

00:13:04.642 --> 00:13:07.314
A manipulação pode acontecer.

00:13:07.314 --> 00:13:10.744
Ou poderia imprimir um projeto
de tecnologia muito elegante,

00:13:10.744 --> 00:13:12.142
e quando o implementássemos,

00:13:12.142 --> 00:13:16.539
ele teria efeitos colaterais ocultos
que a IA houvera planejado.

00:13:16.539 --> 00:13:20.002
A questão é que não deveríamos
confiar na nossa capacidade

00:13:20.002 --> 00:13:23.670
de manter um gênio superinteligente
preso para sempre em uma garrafa.

00:13:23.670 --> 00:13:26.064
Mais cedo ou mais tarde ele escapará.

00:13:26.664 --> 00:13:31.647
Acredito que a solução é descobrir
como criar uma IA superinteligente

00:13:31.647 --> 00:13:35.751
que mesmo se, ou quando, ela escapar,
ainda seja segura,

00:13:35.751 --> 00:13:40.328
porque no fundo está do nosso lado,
pois compartilha nossos valores.

00:13:40.337 --> 00:13:43.547
Não vejo como evitar
este problema difícil.

00:13:45.547 --> 00:13:48.651
Estou razoavelmente otimista
que este problema pode ser resolvido.

00:13:48.651 --> 00:13:52.294
Não teríamos que fazer uma lista grande
de todas as coisas relevantes

00:13:52.294 --> 00:13:55.937
ou pior ainda, escrevê-las
em alguma linguagem de computador

00:13:55.937 --> 00:13:59.998
como C++ ou Python,
que seria uma tarefa muito irritante.

00:13:59.998 --> 00:14:04.455
Em vez disso, criaríamos
uma IA que usa sua inteligência

00:14:04.455 --> 00:14:07.226
para aprender o que valorizamos.

00:14:07.226 --> 00:14:09.506
E seu sistema de motivação
seria construído

00:14:09.506 --> 00:14:12.326
de modo que ela fosse incentivada

00:14:12.326 --> 00:14:14.738
a obedecer aos nossos valores
ou realizar ações

00:14:14.738 --> 00:14:17.738
que ela previsse
que teriam nossa aprovação.

00:14:17.738 --> 00:14:21.152
Assim, aumentaríamos sua inteligência
o mais que pudéssemos

00:14:21.152 --> 00:14:23.897
para resolver o problema
de passar-lhe os nossos valores.

00:14:24.527 --> 00:14:26.239
Isso pode acontecer

00:14:26.239 --> 00:14:29.835
e o resultado pode ser
muito bom para a humanidade.

00:14:29.835 --> 00:14:33.382
Mas não acontece automaticamente.

00:14:33.382 --> 00:14:36.790
As condições inicias
para a explosão da inteligência

00:14:36.790 --> 00:14:39.373
podem precisar sofrer um ajuste
no modo correto

00:14:39.373 --> 00:14:42.653
se quisermos uma detonação controlada.

00:14:42.653 --> 00:14:45.511
Os valores da IA devem
coincidir com os nossos,

00:14:45.511 --> 00:14:47.641
não apenas no contexto conhecido,

00:14:47.641 --> 00:14:50.409
no qual podemos facilmente verificar
como a IA se comporta,

00:14:50.409 --> 00:14:53.383
mas também em todos os novos contextos
que a IA pode encontrar

00:14:53.383 --> 00:14:54.680
no futuro indefinido.

00:14:54.680 --> 00:14:56.967
E há também questões esotéricas

00:14:56.967 --> 00:15:01.506
que precisariam ser resolvidas:
detalhes exatos de sua teoria de decisão,

00:15:01.506 --> 00:15:04.480
como lidar com a incerteza lógica
e assim por diante.

00:15:04.830 --> 00:15:07.340
Então, os problemas técnicos
que devem ser resolvidos

00:15:07.340 --> 00:15:09.495
para que isso funcione
parecem muito difíceis,

00:15:09.495 --> 00:15:12.385
não tão difíceis quanto construir
uma IA superinteligente,

00:15:12.385 --> 00:15:14.583
mas razoavelmente difíceis.

00:15:15.513 --> 00:15:17.488
Eis a preocupação:

00:15:17.488 --> 00:15:21.582
construir IA superinteligente
é um desafio muito grande.

00:15:21.582 --> 00:15:24.580
Construir IA superinteligente segura

00:15:24.580 --> 00:15:27.136
envolve desafio adicional.

00:15:28.216 --> 00:15:31.703
O risco é de alguém descobrir
como vencer o primeiro desafio

00:15:31.703 --> 00:15:34.704
sem que também tenha vencido
o desafio adicional

00:15:34.704 --> 00:15:36.605
de garantir uma segurança perfeita.

00:15:37.375 --> 00:15:39.396
Eu acredito que deveríamos

00:15:39.396 --> 00:15:43.168
procurar uma solução antecipada
para o problema do controle,

00:15:43.168 --> 00:15:46.188
para que esteja à mão
quando precisarmos dela.

00:15:46.565 --> 00:15:48.809
Pode ser que não consigamos resolver

00:15:48.809 --> 00:15:51.876
o problema do controle antecipado
talvez porque alguns elementos

00:15:51.876 --> 00:15:55.586
só possam ser colocados quando conhecermos
os detalhes da arquitetura

00:15:55.586 --> 00:15:57.136
onde será implementado.

00:15:57.136 --> 00:16:00.676
Quanto mais antecipadamente resolvermos
o problema do controle,

00:16:00.676 --> 00:16:02.946
maiores serão as chances
de que a transição

00:16:02.946 --> 00:16:05.456
para a era da máquina inteligente
será bem-sucedida.

00:16:06.406 --> 00:16:10.950
Para mim, parece algo
que vale a pena ser feito

00:16:10.950 --> 00:16:14.282
e posso imaginar
que se as coisas correrem bem,

00:16:14.282 --> 00:16:18.870
e as pessoas daqui a 1 milhão de anos
se lembrarem deste século,

00:16:18.870 --> 00:16:22.732
pode ser que elas digam que a única coisa
que fizemos e que realmente valeu a pena

00:16:22.732 --> 00:16:24.259
foi fazer isso do jeito correto.

00:16:24.259 --> 00:16:25.558
Obrigado.

00:16:25.558 --> 00:16:29.011
(Aplausos)

