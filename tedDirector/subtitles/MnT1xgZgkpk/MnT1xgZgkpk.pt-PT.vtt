WEBVTT
Kind: captions
Language: pt-PT

00:00:00.000 --> 00:00:07.000
Tradutor: Jorge Santos
Revisora: Margarida Ferreira

00:00:12.570 --> 00:00:17.337
Eu trabalho com um grupo de matemáticos,
filósofos e informáticos,

00:00:17.337 --> 00:00:21.986
e pensamos acerca do futuro 
da inteligência mecânica,

00:00:21.986 --> 00:00:24.030
entre outras coisas.

00:00:24.210 --> 00:00:28.755
Algumas pessoas pensam que algumas 
destas coisas são como ciência ficção,

00:00:28.755 --> 00:00:31.856
muito longe da realidade.

00:00:31.856 --> 00:00:33.326
Mas eu gosto de dizer,

00:00:33.326 --> 00:00:36.930
olhemos para as condições 
humanas modernas.

00:00:36.930 --> 00:00:38.622
(Risos)

00:00:38.622 --> 00:00:41.024
Essa é a forma normal de as coisas serem.

00:00:41.024 --> 00:00:43.309
Mas se pensarmos nisso,

00:00:43.309 --> 00:00:46.602
somos na verdade visitantes 
recentes neste planeta,

00:00:46.602 --> 00:00:48.684
a espécie humana.

00:00:48.684 --> 00:00:53.430
Imaginem, se a Terra tivesse sido 
criada há um ano,

00:00:53.430 --> 00:00:56.978
a espécie humana, então,
teria 10 minutos de vida.

00:00:56.978 --> 00:01:00.146
A era da indústria teria começado 
há 2 segundos.

00:01:01.276 --> 00:01:03.171
Outra forma de olhar para isto 

00:01:03.171 --> 00:01:06.321
é calcular o PIB mundial
dos últimos 10 000 anos,

00:01:06.501 --> 00:01:09.530
Tive a preocupação de inserir
isto num gráfico para vocês verem.

00:01:09.680 --> 00:01:11.304
Parece-se com isto.

00:01:11.304 --> 00:01:12.667
(Risos)

00:01:12.667 --> 00:01:14.818
É uma forma curiosa 
para uma situação normal.

00:01:15.178 --> 00:01:17.046
Eu não ficaria muito descansado.

00:01:17.046 --> 00:01:19.067
(Risos)

00:01:19.067 --> 00:01:23.841
Perguntemos a nós próprios, 
qual é a causa dessa anomalia?

00:01:23.841 --> 00:01:26.563
Algumas pessoas diriam que é a tecnologia.

00:01:26.563 --> 00:01:31.061
É verdade, a tecnologia acumulou-se
durante a história da humanidade

00:01:31.061 --> 00:01:35.713
e, neste momento, a tecnologia evolui
extremamente depressa

00:01:35.713 --> 00:01:37.478
— essa é a causa imediata —

00:01:37.478 --> 00:01:40.073
é por isso que estamos tão produtivos.

00:01:40.473 --> 00:01:44.134
Mas eu gosto de pensar mais além,
para a causa fundamental.

00:01:45.114 --> 00:01:48.640
Olhem para estes dois senhores 
muito distintos:

00:01:48.880 --> 00:01:50.480
Temos o Kanzi,

00:01:50.480 --> 00:01:55.123
ele dominava 200 símbolos lexicais, 
uma incrível proeza.

00:01:55.123 --> 00:01:58.817
E Ed Witten desencadeou a segunda
revolução das supercordas.

00:01:58.817 --> 00:02:01.201
Se examinarmos é isto que encontramos:

00:02:01.201 --> 00:02:02.811
basicamente a mesma coisa.

00:02:02.811 --> 00:02:04.524
Uma é um pouco maior,

00:02:04.524 --> 00:02:07.582
talvez tenha alguns truques na maneira
como está ligado.

00:02:07.582 --> 00:02:11.094
Contudo, essas diferenças invisíveis 
não podem ser muito complicadas,

00:02:11.094 --> 00:02:15.559
porque apenas houve 250 000 gerações

00:02:15.559 --> 00:02:17.581
desde o nosso último antepassado comum.

00:02:17.581 --> 00:02:21.200
Sabemos que os mecanismos complicados 
levam muito tempo a evoluir.

00:02:22.000 --> 00:02:24.499
Portanto algumas mudanças mínimas

00:02:24.499 --> 00:02:28.016
levam-nos de Kanzi para Witten,

00:02:28.016 --> 00:02:32.109
desde ramos de árvores quebrados até
mísseis balísticos intercontinentais.

00:02:32.839 --> 00:02:36.774
Assim, parece óbvio que tudo aquilo 
que tenhamos realizado,

00:02:36.774 --> 00:02:38.572
e tudo aquilo que nos preocupa,

00:02:38.572 --> 00:02:43.380
dependa crucialmente de algumas mudanças
mínimas que construíram a mente humana.

00:02:44.650 --> 00:02:48.312
E o corolário, claro, é que
quaisquer mudanças adicionais

00:02:48.312 --> 00:02:51.789
que poderiam mudar significativamente
o substrato de pensar

00:02:51.789 --> 00:02:54.991
poderiam ter enormes consequências.

00:02:56.321 --> 00:02:59.226
Alguns dos meus colegas pensam
que estamos à beira

00:02:59.226 --> 00:03:03.134
de algo que poderá causar uma mudança
drástica nesse substrato,

00:03:03.134 --> 00:03:06.347
e isso é a super inteligência mecânica.

00:03:06.347 --> 00:03:11.086
A inteligência artificial costumava 
cingir-se a ordens numa caixa.

00:03:11.086 --> 00:03:12.951
Tínhamos programadores humanos

00:03:12.951 --> 00:03:16.096
que construíam objectos inteligentes
cuidadosamente.

00:03:16.686 --> 00:03:18.772
Construíamos esses sistemas 
especializados,

00:03:18.772 --> 00:03:20.296
e eram úteis para alguns fins,

00:03:20.296 --> 00:03:22.977
mas eram muito frágeis,
não podíamos aumentá-los.

00:03:22.977 --> 00:03:26.410
Basicamente, apenas obtínhamos 
aquilo que lá colocávamos inicialmente.

00:03:26.410 --> 00:03:27.717
Mas a partir daí,

00:03:27.717 --> 00:03:31.234
ocorreu uma mudança de paradigma
no campo da inteligência artificial.

00:03:31.234 --> 00:03:34.034
Hoje, a acção anda à volta da
aprendizagem da máquina.

00:03:34.764 --> 00:03:40.741
Portanto em vez de construir 
representações e elementos do conhecimento

00:03:40.741 --> 00:03:46.065
criamos algoritmos que aprendem,
muitas vezes a partir de dados em bruto.

00:03:46.905 --> 00:03:50.043
Basicamente a mesma coisa
que a criança faz.

00:03:51.063 --> 00:03:55.270
O resultado é uma inteligência artificial
que não se limita a um domínio

00:03:55.270 --> 00:03:59.901
— o mesmo sistema que pode aprender a
traduzir várias línguas,

00:03:59.901 --> 00:04:05.338
ou aprender a jogar qualquer tipo 
de jogo de computador na consola Atari.

00:04:05.598 --> 00:04:07.117
Agora, é claro,

00:04:07.117 --> 00:04:11.116
a inteligência artificial ainda está muito
longe de ter a mesma capacidade poderosa

00:04:11.116 --> 00:04:14.225
e transversal para aprender
e planificar tal como um ser humano.

00:04:14.225 --> 00:04:16.461
O córtex ainda tem alguns
truques algorítmicos

00:04:16.461 --> 00:04:18.816
que ainda não sabemos 
como ligar nas máquinas.

00:04:19.886 --> 00:04:21.785
Portanto a questão é,

00:04:21.785 --> 00:04:25.285
a que distância estamos 
de poder ligar esses truques?

00:04:26.245 --> 00:04:27.698
Há alguns anos,

00:04:27.698 --> 00:04:30.406
fizemos um inquérito a alguns dos
especialistas em I.A.,

00:04:30.406 --> 00:04:33.580
para ver o que eles pensam, e uma das
questões que colocámos foi:

00:04:33.580 --> 00:04:36.793
"Por volta de que ano é que pensa que
atingiremos a I.A.

00:04:36.793 --> 00:04:40.275
ao nível humano,
com 50% de probabilidade?"

00:04:40.785 --> 00:04:44.968
Definimos o nível humano 
como a capacidade de realizar

00:04:44.968 --> 00:04:47.839
praticamente qualquer trabalho.
pelo menos como adulto,

00:04:47.839 --> 00:04:51.844
a nível humano real, não apenas
dentro de um domínio limitado.

00:04:51.844 --> 00:04:55.494
A resposta média foi 2040 ou 2050,

00:04:55.494 --> 00:04:58.300
consoante o grupo de especialistas 
a que perguntámos.

00:04:59.430 --> 00:05:02.339
Poderá acontecer muito mais tarde, 
ou mais cedo,

00:05:02.339 --> 00:05:04.419
a verdade é que ninguém sabe.

00:05:05.259 --> 00:05:08.321
O que nós sabemos 
é que o limite fundamental

00:05:08.321 --> 00:05:10.961
para processar informação
no substrato duma máquina,

00:05:10.961 --> 00:05:14.542
é muito superior ao limite
dos tecidos biológicos.

00:05:15.241 --> 00:05:17.619
Isto leva-nos à física.

00:05:17.619 --> 00:05:22.337
Um neurónio biológico dispara, talvez,
a 200 hertz, 200 vezes por segundo.

00:05:22.337 --> 00:05:25.691
Mas até um transístor moderno 
opera em gigahertz.

00:05:25.931 --> 00:05:31.088
Os neurónios propagam lentamente
em axónios, a 100 metros por segundo.

00:05:31.088 --> 00:05:34.429
Mas em computadores, os sinais podem
deslocar-se à velocidade da luz.

00:05:35.079 --> 00:05:36.948
Também há limitações de tamanho.

00:05:36.948 --> 00:05:39.975
O cérebro humano tem que
caber dentro do crânio,

00:05:39.975 --> 00:05:44.736
mas um computador pode ser do tamanho 
de um armazém ou ainda maior.

00:05:44.736 --> 00:05:50.335
Por isso o potencial para a super
inteligência permanece latente na matéria,

00:05:50.335 --> 00:05:56.047
tal como a potência do átomo permaneceu
latente na história da humanidade,

00:05:56.047 --> 00:05:59.172
pacientemente à espera até 1945.

00:06:00.452 --> 00:06:01.700
Neste século,

00:06:01.700 --> 00:06:05.818
os cientistas talvez aprendam a despertar
o poder da inteligência artificial.

00:06:05.818 --> 00:06:09.826
E penso que poderemos então assistir
a uma explosão intelectual.

00:06:10.406 --> 00:06:14.363
A maioria das pessoas, quando pensam
acerca do que é a esperteza e a estupidez,

00:06:14.363 --> 00:06:17.386
têm em mente uma imagem 
como esta, penso eu.

00:06:17.386 --> 00:06:19.984
Numa ponta temos o idiota da aldeia,

00:06:19.984 --> 00:06:22.467
e noutra ponta muito distante

00:06:22.467 --> 00:06:26.733
temos Ed Witten, ou Albert Einstein,
ou qualquer um dos vossos gurus favoritos.

00:06:27.223 --> 00:06:31.057
Mas penso que, do ponto de vista
da inteligência artificial,

00:06:31.057 --> 00:06:34.738
a imagem verdadeira é provavelmente
mais parecida com isto.

00:06:35.258 --> 00:06:38.756
Começa tudo neste ponto aqui,
na inteligência zero,

00:06:38.756 --> 00:06:41.647
e depois, após muitos anos 
de trabalho árduo,

00:06:41.647 --> 00:06:45.721
talvez cheguemos à inteligência
artificial ao nível de um rato,

00:06:45.721 --> 00:06:48.231
uma coisa que possa navegar 
em ambientes obstruídos

00:06:48.231 --> 00:06:49.908
tal como um rato pode.

00:06:49.908 --> 00:06:54.221
E depois, após muitos mais anos
de trabalho árduo, muitos investimentos,

00:06:54.221 --> 00:06:58.860
talvez cheguemos à inteligência 
artificial a nível de um chimpanzé.

00:06:58.860 --> 00:07:02.070
E depois, após ainda mais anos 
de trabalho ainda mais duro,

00:07:02.070 --> 00:07:05.173
chegamos à inteligência artificial 
a nível do idiota da aldeia.

00:07:05.173 --> 00:07:08.255
E alguns momentos depois, 
ultrapassamos Ed Witten.

00:07:08.255 --> 00:07:11.225
O comboio não pára na estação Humanville.

00:07:11.225 --> 00:07:14.247
É mais provável que a ultrapasse.

00:07:14.247 --> 00:07:16.541
Isto tem profundas implicações,

00:07:16.541 --> 00:07:19.693
particularmente no que toca
à questão do poder.

00:07:20.103 --> 00:07:22.052
Por exemplo, os chimpanzés são fortes

00:07:22.052 --> 00:07:26.604
— em proporção ao peso, um chimpanzé
é duas vezes mais forte que um ser humano.

00:07:27.414 --> 00:07:32.118
No entanto, o destino de Kanzi e dos seus
camaradas depende mais

00:07:32.118 --> 00:07:35.968
daquilo que nós humanos fazemos 
do que o que os chimpanzés fazem.

00:07:37.608 --> 00:07:39.682
Uma vez atingida a super inteligência,

00:07:39.682 --> 00:07:43.251
o destino da humanidade pode depender
daquilo que a super inteligência faz.

00:07:44.451 --> 00:07:45.798
Pensem nisto:

00:07:45.798 --> 00:07:50.552
A inteligência mecânica é a última invenção
que a humanidade precisa de fazer.

00:07:50.552 --> 00:07:53.525
As máquinas tornar-se-ão melhores 
a inventar do que nós,

00:07:53.525 --> 00:07:56.065
e farão isso em tempos digitais.

00:07:56.335 --> 00:08:00.966
O que isto significa é basicamente uma
previsão do futuro distante.

00:08:01.156 --> 00:08:04.764
Pensem em todas as tecnologias absurdas
que alguma vez podem ter imaginado

00:08:04.764 --> 00:08:07.412
que os humanos pudessem ter
desenvolvido com o tempo:

00:08:07.412 --> 00:08:10.580
curas para o envelhecimento,
colonização do espaço,

00:08:10.580 --> 00:08:14.311
nanorobôs auto-replicadores ou transferir
as nossas mentes para computadores,

00:08:14.311 --> 00:08:16.650
todos os tipos de objectos 
da ciência ficção

00:08:16.650 --> 00:08:19.337
que, no entanto, são consistentes
com as leis da física.

00:08:19.337 --> 00:08:23.419
Toda esta super inteligência poderia 
ser desenvolvida, e rapidamente.

00:08:24.449 --> 00:08:28.007
Uma super inteligência com tanta
maturidade tecnológica

00:08:28.007 --> 00:08:30.186
poderia ser extremamente poderosa

00:08:30.186 --> 00:08:34.732
e, pelo menos nalguns cenários,
poderia conseguir aquilo que quer.

00:08:35.372 --> 00:08:38.855
Teríamos então um futuro construído

00:08:38.855 --> 00:08:41.625
segundo as preferências 
dessa inteligência artificial.

00:08:41.855 --> 00:08:45.604
Agora uma boa pergunta é,
quais são essas preferências?

00:08:46.244 --> 00:08:47.953
Aqui torna-se mais complicado.

00:08:47.953 --> 00:08:49.848
Para fazer qualquer progresso com isto,

00:08:49.848 --> 00:08:52.724
temos de, primeiramente,
evitar antropomorfizar.

00:08:53.934 --> 00:08:57.565
E isto é irónico porque 
todos os artigos de jornais

00:08:57.565 --> 00:09:00.810
acerca do futuro da inteligência
artificial têm uma imagem como esta.

00:09:02.280 --> 00:09:06.414
Então penso que aquilo que temos de fazer
é imaginar a questão mais abstractamente,

00:09:06.414 --> 00:09:09.204
não em termos de cenários
brilhantes de Hollywood.

00:09:09.204 --> 00:09:12.821
Temos de pensar na inteligência como
um processo de optimização,

00:09:12.821 --> 00:09:17.870
um processo que guia o futuro para 
um conjunto particular de configurações.

00:09:18.470 --> 00:09:22.091
A super inteligência é um processo de
optimização muito forte.

00:09:22.091 --> 00:09:26.098
É extremamente bom a utilizar os meios
disponíveis para atingir um estado

00:09:26.098 --> 00:09:28.267
no qual o seu objetivo seja atingido.

00:09:28.447 --> 00:09:31.119
Isto significa que não há 
ligação necessária

00:09:31.119 --> 00:09:33.853
entre ser muito inteligente neste sentido,

00:09:33.853 --> 00:09:38.515
e ter um objectivo que nós humanos
acharíamos útil ou proveitoso.

00:09:39.191 --> 00:09:43.445
Suponham que damos o objectivo de criar
sorrisos humanos à inteligência artificial.

00:09:43.445 --> 00:09:46.097
Quando a I.A. é fraca,
realiza acções cómicas ou úteis

00:09:46.097 --> 00:09:48.314
que levam o utilizador a sorrir.

00:09:48.314 --> 00:09:51.241
Quando a inteligência artificial 
se torna super inteligente,

00:09:51.241 --> 00:09:54.554
apercebe-se que existe uma melhor forma 
de atingir esse objectivo:

00:09:54.554 --> 00:09:56.476
controlar o mundo

00:09:56.476 --> 00:09:59.638
e inserir eléctrodos 
nos músculos faciais dos humanos

00:09:59.638 --> 00:10:02.479
para causar sorrisos 
constantes e radiantes.

00:10:02.479 --> 00:10:03.614
Outro exemplo:

00:10:03.614 --> 00:10:06.997
suponham que desafiamos a I.A.
a resolver um problema matemático difícil.

00:10:06.997 --> 00:10:08.934
Quando a I.A. se torna
super inteligente,

00:10:08.934 --> 00:10:13.105
percebe que a forma mais eficiente de 
obter a solução para este problema

00:10:13.105 --> 00:10:16.035
é através da transformação do planeta
num computador gigante,

00:10:16.035 --> 00:10:18.281
para aumentar a sua capacidade de pensar.

00:10:18.281 --> 00:10:21.045
E reparem que isto dá uma razão
instrumental à I.A.

00:10:21.045 --> 00:10:23.441
para nos fazer coisas 
que possamos não aprovar.

00:10:23.441 --> 00:10:25.776
Neste modelo, os seres humanos 
são uma ameaça,

00:10:25.776 --> 00:10:28.737
poderíamos impedir a resolução 
deste problema matemático.

00:10:28.877 --> 00:10:32.701
Claro, as coisas não vão dar erradas 
nessas formas particulares;

00:10:32.701 --> 00:10:34.454
estes são exemplos caricaturados.

00:10:34.454 --> 00:10:36.503
Mas este ponto geral é importante:

00:10:36.503 --> 00:10:39.266
se criarem um processo de optimização
muito potente

00:10:39.266 --> 00:10:41.500
para maximizar o objectivo x,

00:10:41.500 --> 00:10:43.776
é melhor assegurarem-se 
que a definição de x

00:10:43.776 --> 00:10:46.245
incorpora tudo aquilo que vos interessa.

00:10:46.835 --> 00:10:51.219
Esta é uma lição que também 
é ensinada em muitos mitos.

00:10:51.219 --> 00:10:56.517
O Rei Midas deseja que tudo aquilo
em que ele toca se torne ouro.

00:10:56.517 --> 00:10:59.378
Toca na filha dele, transforma-a em ouro.

00:10:59.378 --> 00:11:01.931
Toca na comida dele, esta torna-se ouro.

00:11:01.931 --> 00:11:04.520
Isto poderia tornar-se 
particularmente relevante,

00:11:04.520 --> 00:11:06.590
não apenas como metáfora para a ganância,

00:11:06.590 --> 00:11:08.745
mas como uma ilustração
daquilo que acontece

00:11:08.745 --> 00:11:11.322
se criarem um processo 
de optimização poderoso

00:11:11.322 --> 00:11:15.321
e lhe derem objectivos pouco específicos.

00:11:16.441 --> 00:11:21.300
Podem dizer, se um computador começar a
prender eléctrodos nas caras das pessoas,

00:11:21.300 --> 00:11:23.565
basta desligá-los.

00:11:24.555 --> 00:11:29.895
A) isso não é assim tão fácil de fazer
se nos tornarmos dependentes do sistema

00:11:29.895 --> 00:11:32.627
— por exemplo, onde está 
o interruptor da Internet?

00:11:33.087 --> 00:11:36.267
B) porque é que os chimpanzés 
ou os neandertais

00:11:36.267 --> 00:11:39.298
não desligaram
o interruptor para a humanidade?

00:11:39.298 --> 00:11:41.964
Eles de certeza que tinham motivos.

00:11:41.964 --> 00:11:44.759
Temos um interruptor aqui, por exemplo.

00:11:44.899 --> 00:11:46.313
(Sufocação)

00:11:46.583 --> 00:11:49.238
A razão é que somos 
um adversário inteligente;

00:11:49.238 --> 00:11:51.966
podemos prever ameaças 
e fazer planos para evitá-las.

00:11:51.966 --> 00:11:54.470
Mas isso também consegue
um agente super inteligente,

00:11:54.470 --> 00:11:57.034
e seria muito melhor nisso do que nós.

00:11:57.724 --> 00:12:04.911
A questão é, não devemos ser confiantes 
e pensar que temos tudo sob controlo.

00:12:04.911 --> 00:12:07.778
Podíamos tentar fazer o nosso trabalho
um pouco mais fácil,

00:12:07.778 --> 00:12:09.948
pondo a inteligência artificial numa caixa,

00:12:09.948 --> 00:12:11.854
como um "software" de ambiente seguro,

00:12:11.854 --> 00:12:14.766
uma simulação da realidade virtual 
da qual não possa escapar.

00:12:14.766 --> 00:12:18.912
Mas quanta certeza podemos ter 
que a I.A. não encontraria um buraco.

00:12:18.912 --> 00:12:22.081
Dado que os "hackers" humanos
estão sempre a encontrar buracos,

00:12:22.081 --> 00:12:25.117
eu diria, provavelmente 
não muito confiantes.

00:12:26.237 --> 00:12:30.785
Então desligamos o cabo da Ethernet 
para criar uma caixa de ar,

00:12:30.785 --> 00:12:33.453
mas mais uma vez, como meros "hackers"

00:12:33.453 --> 00:12:36.834
que transgridem caixas de ar 
utilizando engenharia social.

00:12:36.834 --> 00:12:38.533
Neste momento em que falo,

00:12:38.533 --> 00:12:40.732
tenho a certeza que há 
um empregado, algures.

00:12:40.732 --> 00:12:43.828
a quem alguém que diz 
ser do departamento de informática

00:12:43.828 --> 00:12:46.574
está a pedir os dados 
de identificação e "password".

00:12:46.814 --> 00:12:49.021
Também são possíveis 
cenários mais criativos.

00:12:49.021 --> 00:12:50.786
Por exemplo, uma I.A. pode imaginar

00:12:50.786 --> 00:12:53.548
agitar eléctrodos nos circuitos internos

00:12:53.548 --> 00:12:56.750
para criar ondas de rádio 
que pode utilizar para comunicar.

00:12:57.010 --> 00:12:59.304
Ou talvez pudesse fingir uma avaria

00:12:59.304 --> 00:13:03.061
e depois, quando os programadores a abrirem
para ver o que se passou de errado,

00:13:03.061 --> 00:13:04.867
olham para o código fonte — Bam! —

00:13:04.867 --> 00:13:07.314
a manipulação toma lugar.

00:13:07.314 --> 00:13:10.744
Ou poderia emitir um rascunho 
para uma tecnologia genial

00:13:10.744 --> 00:13:12.322
e, quando a implementamos,

00:13:12.322 --> 00:13:16.539
tem alguns efeitos secundários 
que a inteligência artificial planeou.

00:13:17.149 --> 00:13:20.112
A questão aqui é que não deveríamos
confiar na nossa capacidade

00:13:20.112 --> 00:13:23.810
em manter um génio super inteligente
fechado na sua garrafa para sempre.

00:13:23.810 --> 00:13:26.064
Mais cedo ou mais tarde ele vai sair.

00:13:27.034 --> 00:13:30.137
Acredito que a resposta seja encontrar

00:13:30.137 --> 00:13:35.161
uma forma de criar uma inteligência
artificial que, mesmo que escape,

00:13:35.161 --> 00:13:38.438
ainda se mantenha segura porque está
fundamentalmente do nosso lado

00:13:38.438 --> 00:13:40.337
porque partilha os nossos valores.

00:13:40.337 --> 00:13:43.547
Não vejo outra forma 
para este problema complexo.

00:13:44.557 --> 00:13:48.391
Eu sinto-me optimista 
quanto à resolução deste problema.

00:13:48.391 --> 00:13:52.294
Não teríamos de escrever uma longa lista
com tudo aquilo que nos é importante,

00:13:52.294 --> 00:13:55.937
ou ainda pior, enunciá-la numa
linguagem de computador

00:13:55.937 --> 00:13:57.391
como C++ ou Python,

00:13:57.391 --> 00:14:00.158
o que seria uma tarefa sem esperança.

00:14:00.158 --> 00:14:04.455
Em vez disso, criaríamos uma inteligência
artificial que utiliza a sua inteligência

00:14:04.455 --> 00:14:07.226
para aprender o que nós valorizamos.

00:14:07.226 --> 00:14:12.506
O seu sistema de motivação seria construído
de tal forma que fosse motivado

00:14:12.506 --> 00:14:17.738
pela busca de valores ou de acções,
prevendo que iríamos aprová-las.

00:14:18.338 --> 00:14:21.432
Iríamos então elevar a sua inteligência
o mais possível

00:14:21.432 --> 00:14:24.117
para resolver o problema de 
carregamento de valores.

00:14:24.727 --> 00:14:26.239
Isto pode acontecer,

00:14:26.239 --> 00:14:29.835
e o resultado poderia ser muito
bom para a Humanidade.

00:14:29.835 --> 00:14:33.022
Mas não acontece sozinho.

00:14:33.792 --> 00:14:36.790
As condições iniciais para a 
explosão da inteligência

00:14:36.790 --> 00:14:39.653
podem precisar de ser definidas
da forma correta

00:14:39.653 --> 00:14:42.363
se queremos ter uma detonação controlada.

00:14:43.183 --> 00:14:45.801
Os valores da I.A.
têm de corresponder aos nossos,

00:14:45.801 --> 00:14:47.701
não apenas num contexto familiar,

00:14:47.701 --> 00:14:50.389
onde podemos ver com facilidade
como a I.A. se comporta,

00:14:50.389 --> 00:14:53.233
mas também em todos os contextos 
que a I.A. possa encontrar

00:14:53.233 --> 00:14:54.790
no futuro indefinido.

00:14:54.790 --> 00:14:59.527
E há também algumas questões esotéricas
que teriam de ser resolvidas, que são:

00:14:59.527 --> 00:15:01.616
os detalhes exactos da sua
teoria decisiva,

00:15:01.616 --> 00:15:04.480
como lidar com a incerteza lógica 
e assim por diante.

00:15:05.330 --> 00:15:08.292
Os problemas que têm de ser
resolvidos tornam este trabalho

00:15:08.292 --> 00:15:09.545
um pouco difícil

00:15:09.545 --> 00:15:13.065
— não tão difícil como fazer uma
inteligência artificial super inteligente

00:15:13.065 --> 00:15:15.793
mas bastante difícil.

00:15:15.793 --> 00:15:17.488
A preocupação é esta:

00:15:17.488 --> 00:15:22.172
Criar uma inteligência artificial super
inteligente é um grande desafio.

00:15:22.172 --> 00:15:24.720
Fazer uma inteligência artificial
que seja segura

00:15:24.720 --> 00:15:27.466
envolve desafios adicionais 
para além deste.

00:15:28.216 --> 00:15:31.703
O risco é que, se alguém descobre uma
forma de piratear o primeiro desafio

00:15:31.703 --> 00:15:34.704
sem ter pirateado o desafio adicional

00:15:34.704 --> 00:15:36.865
de assegurar a segurança perfeita.

00:15:37.375 --> 00:15:40.706
Por isso eu penso que deveríamos 
trabalhar numa solução

00:15:40.706 --> 00:15:43.528
para controlar os problemas
com antecedência,

00:15:43.528 --> 00:15:46.188
para que o tenhamos disponível 
para quando for preciso.

00:15:46.768 --> 00:15:50.275
Pode ser que não consigamos resolver 
o problema de controlo por inteiro

00:15:50.275 --> 00:15:53.299
porque talvez apenas se possam
colocar alguns elementos

00:15:53.299 --> 00:15:57.296
uma vez que saibamos os detalhes da
arquitectura onde vai ser implementado.

00:15:57.296 --> 00:16:00.986
Mas quanto mais resolvermos 
o problema de controlo,

00:16:00.986 --> 00:16:04.966
maior será a probabilidade que a transição
para a era da inteligência mecânica

00:16:04.966 --> 00:16:06.306
corra bem.

00:16:06.566 --> 00:16:10.950
Isto parece-me algo 
que vale a pena ser feito

00:16:10.950 --> 00:16:14.282
e posso imaginar que,
se as coisas correrem bem,

00:16:14.282 --> 00:16:18.940
as pessoas daqui um milhão de anos
vão olhar para este século

00:16:18.940 --> 00:16:22.942
e é muito provável que digam que uma das
coisas que fizemos e que teve impacto

00:16:22.942 --> 00:16:24.509
foi pôr isto a funcionar.

00:16:24.509 --> 00:16:26.198
Obrigado.

00:16:26.210 --> 00:16:30.210
(Aplausos)

