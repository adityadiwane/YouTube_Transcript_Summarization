WEBVTT
Kind: captions
Language: fr-CA

00:00:00.000 --> 00:00:07.000
Translator: Florence Marcotte
Reviewer: Serge Brosseau

00:00:12.570 --> 00:00:16.777
Je travaille avec des mathématiciens, des 
philosophes et des informaticiens,

00:00:16.777 --> 00:00:21.986
et, ensemble, nous réfléchissons sur le
futur des machines intelligentes,

00:00:21.986 --> 00:00:24.030
entre autres.

00:00:24.030 --> 00:00:28.755
Certains pensent que ces sujets sont 
de la pure science-fiction,

00:00:28.755 --> 00:00:31.856
irréels et fous.

00:00:31.856 --> 00:00:33.326
Mais j'aime leur répondre:

00:00:33.326 --> 00:00:36.930
«&nbsp;Ok, regardons un instant les
conditions humaines modernes.&nbsp;»

00:00:36.930 --> 00:00:38.622
(Rire)

00:00:38.622 --> 00:00:41.024
Ceci est ce qu'on considère comme normal.

00:00:41.024 --> 00:00:43.309
Mais quand on y pense,

00:00:43.309 --> 00:00:46.602
nous, l'espèce humaine, 
ne sommes apparus sur cette planète

00:00:46.602 --> 00:00:48.684
que très récemment.

00:00:48.684 --> 00:00:53.430
Si la Terre avait été créée
il y un an,

00:00:53.430 --> 00:00:56.978
les humains ne seraient âgés
que de 10 minutes.

00:00:56.978 --> 00:01:00.146
L'ère industrielle n'aurait commencé
qu'il y a deux secondes.

00:01:01.276 --> 00:01:06.501
Un autre point de vue consiste à regarder
le PIB des 10 000 dernières années.

00:01:06.501 --> 00:01:09.530
J'ai fait l'effort de synthétiser ces 
données en un tableau.

00:01:09.530 --> 00:01:11.304
Ça ressemble à ça.

00:01:11.304 --> 00:01:12.667
(Rire)

00:01:12.667 --> 00:01:14.818
Drôle de forme pour 
une condition «&nbsp;normale&nbsp;».

00:01:14.818 --> 00:01:16.626
Je ne voudrais pas m'asseoir dessus.

00:01:16.626 --> 00:01:19.067
(Rire)

00:01:19.067 --> 00:01:23.841
Demandons-nous: quelle est 
la cause de cette anomalie?

00:01:23.841 --> 00:01:26.393
Certains disent que c'est la technologie.

00:01:26.393 --> 00:01:31.061
Il est vrai que les technologies se sont 
accumulées au cours de l'histoire humaine

00:01:31.061 --> 00:01:35.713
et qu'en ce moment, elles se développent
extrêmement rapidement.

00:01:35.713 --> 00:01:37.278
C'est relié à la vraie cause,

00:01:37.278 --> 00:01:39.843
car c'est ce qui nous permet
d'être si productifs.

00:01:40.473 --> 00:01:44.134
Mais j'aime à penser que la cause ultime
réside plus loin dans le temps.

00:01:45.114 --> 00:01:48.880
Regardez ces deux messieurs
hautement distingués.

00:01:48.880 --> 00:01:50.480
Il y a Kanzi:

00:01:50.480 --> 00:01:55.123
il maîtrise 200 unités lexicales,
un exploit incroyable.

00:01:55.123 --> 00:01:58.817
Et Ed Witten, qui a mené à la 2e 
révolution de la théorie des supercordes.

00:01:58.817 --> 00:02:01.361
Si l'on regarde sous le capot,
voici ce que l'on voit:

00:02:01.361 --> 00:02:02.711
pratiquement la même chose.

00:02:02.711 --> 00:02:04.524
Un est un peu plus gros

00:02:04.524 --> 00:02:07.282
et a peut-être quelques
différences dans sa connexion.

00:02:07.282 --> 00:02:11.094
Mais ces différences invisibles ne peuvent
pas être si compliquées,

00:02:11.094 --> 00:02:15.379
car il y a seulement
250 000 générations,

00:02:15.379 --> 00:02:17.111
nous avions le même ancêtre.

00:02:17.111 --> 00:02:20.960
Nous savons que les mécanisme complexes
prennent longtemps à évoluer.

00:02:22.000 --> 00:02:24.499
Donc, une série de petits changements

00:02:24.499 --> 00:02:27.566
nous amène 
de Kanzi à Witten,

00:02:27.566 --> 00:02:32.109
de branches cassés à des 
missiles balistiques intercontinentaux.

00:02:32.839 --> 00:02:36.774
Il semble donc évident que tout ce
que l'on a créé,

00:02:36.774 --> 00:02:38.152
et tout ce à quoi l'on tient,

00:02:38.152 --> 00:02:43.380
dépend à la base de quelques relativement
petits changements dans le cerveau humain.

00:02:44.650 --> 00:02:48.312
Et, corolairement, bien sûr, 
n'importe quel changement

00:02:48.312 --> 00:02:51.789
qui pourrait affecter 
l'essence de la pensée

00:02:51.789 --> 00:02:54.991
pourrait potentiellement avoir
d'énormes conséquences.

00:02:56.321 --> 00:02:59.226
Certains de mes collègues
pensent que nous sommes

00:02:59.226 --> 00:03:03.134
près de quelque chose qui pourrait créer
un profond changement dans cette essence:

00:03:03.134 --> 00:03:06.347
les machines à intelligence artificielle.

00:03:06.347 --> 00:03:11.086
Avant, l'intelligence artificielle (IA)
consistait à créer des commandes.

00:03:11.086 --> 00:03:13.691
Des programmeurs humains
inséraient avec difficultés

00:03:13.691 --> 00:03:15.886
des éléments d'information
dans une boîte.

00:03:15.886 --> 00:03:17.892
On construisait des machines expertes qui

00:03:17.892 --> 00:03:21.276
étaient utiles pour certaines choses,
mais qui étaient très restreintes.

00:03:21.276 --> 00:03:23.237
On ne pouvait les faire à grande échelle.

00:03:23.237 --> 00:03:26.410
On en retirait que ce
que l'on avait mis.

00:03:26.410 --> 00:03:27.137
Mais depuis,

00:03:27.137 --> 00:03:31.144
un changement de paradigme à eu lieu dans
le domaine de l'intelligence artificielle.

00:03:31.144 --> 00:03:34.304
Aujourd'hui, on se concentre sur 
les machines qui apprennent.

00:03:34.394 --> 00:03:39.781
Donc, au lieu d'insérer 
manuellement de l'information,

00:03:40.511 --> 00:03:46.065
on crée des algorithmes qui apprennent,
souvent à partir de donnés perceptives.

00:03:46.065 --> 00:03:51.063
Essentiellement, ils font la même 
chose que des enfants humains.

00:03:51.063 --> 00:03:55.270
Il en résulte des IA qui ne sont
pas limitées à un seul domaine;

00:03:55.270 --> 00:03:59.901
le même système peut apprendre
à traduire n'importe quelle langue

00:03:59.901 --> 00:04:05.338
et à jouer tous les jeux
sur la console Atari.

00:04:05.338 --> 00:04:07.117
Bien sûr,

00:04:07.117 --> 00:04:11.116
l'IA est loin d'avoir la même
puissance universelle

00:04:11.116 --> 00:04:14.335
d'apprentissage et de planification
que l'être humain.

00:04:14.335 --> 00:04:16.711
Le cortex a encore quelques
ruses algorithmiques

00:04:16.711 --> 00:04:19.116
que l'on arrive pas à créer
dans des machines.

00:04:19.886 --> 00:04:21.785
La question est donc:

00:04:21.785 --> 00:04:25.285
dans combien de temps 
réussirons-nous à les créer?

00:04:26.095 --> 00:04:27.268
Il y a quelques années,

00:04:27.268 --> 00:04:30.896
nous avons fait un sondage auprès 
d'experts de l'IA mondialement reconnus

00:04:30.896 --> 00:04:32.306
pour avoir leur opinion.

00:04:32.306 --> 00:04:36.793
Une des questions posées était:
«&nbsp;À quand, selon vous, un 50% de chance

00:04:36.793 --> 00:04:40.275
d’avoir créé une intelligence artificielle 
équivalente à celle de l’humain?&nbsp;»

00:04:40.785 --> 00:04:44.968
Nous avons définis cette dernière comme 
l'habileté de faire n'importe quel travail

00:04:44.968 --> 00:04:47.839
aussi bien, voire mieux, 
qu'un humain adulte,

00:04:47.839 --> 00:04:51.844
au niveau d’une intelligence humaine, 
qui n'est pas restreinte à un seul domaine.

00:04:51.844 --> 00:04:55.494
Et la réponse médiane a été 2040 ou 2050,

00:04:55.494 --> 00:04:58.300
selon les groupes d'experts questionnés.

00:04:58.300 --> 00:05:02.339
Bien sûr, cela pourrait se produire bien
plus tard, ou plus tôt;

00:05:02.339 --> 00:05:04.819
la vérité, c'est que personne ne le sait.

00:05:05.259 --> 00:05:09.671
Ce que l'on sait, par contre, c'est que
la capacité de traitement de l'information

00:05:09.671 --> 00:05:14.542
est beaucoup plus grande pour 
une machine que pour un humain.

00:05:15.241 --> 00:05:17.619
C'est simplement de la physique.

00:05:17.619 --> 00:05:22.337
Un neurone biologique décharge, environ, à
200 Hertz, 200 fois/sec,

00:05:22.337 --> 00:05:25.931
alors qu'un transistor, de nos jours, 
fonctionne en Gigahertz.

00:05:25.931 --> 00:05:31.228
Les neurones se propagent en axons à une
vitesse de 100 m/sec, max,

00:05:31.228 --> 00:05:35.099
alors que les signaux des ordinateurs
peuvent voyager à la vitesse de la lumière

00:05:35.099 --> 00:05:37.118
Il y a aussi des
différences de grandeur:

00:05:37.118 --> 00:05:39.975
un cerveau humain doit entrer à
l’intérieur d'un crâne,

00:05:39.975 --> 00:05:44.736
alors qu'un ordinateur peut avoir la
taille d'un entrepôt, et même plus.

00:05:44.736 --> 00:05:50.335
Donc, le potentiel de la 
super-intelligence est en attente,

00:05:50.335 --> 00:05:56.047
tout comme celui du pouvoir de l'atome
l'était au cours de l'histoire,

00:05:56.047 --> 00:06:00.032
attendant patiemment jusqu'en 1945.

00:06:00.452 --> 00:06:01.700
Au cours de notre siècle,

00:06:01.700 --> 00:06:05.818
les scientifiques réussiront peut-être à
exploiter le pouvoir de l'I.A.

00:06:05.818 --> 00:06:09.826
Et alors, selon moi, nous verrons
une explosion de l'intelligence.

00:06:10.406 --> 00:06:14.363
Je crois que lorsque quelqu'un s'imagine
ce qu'est être intelligent ou idiot,

00:06:14.363 --> 00:06:17.386
il a en tête une image comme celle-ci.

00:06:17.386 --> 00:06:19.984
À un bout, il y a l’idiot du village,

00:06:19.984 --> 00:06:22.467
et très loin à l'autre bout,

00:06:22.467 --> 00:06:27.223
il y a Ed Witten, ou Albert Einstein, ou 
peu importe qui est votre génie préféré.

00:06:27.223 --> 00:06:31.057
Mais du point de vue de
l'intelligence artificielle,

00:06:31.057 --> 00:06:34.738
la vraie image ressemble plutôt à ceci.

00:06:35.288 --> 00:06:38.606
L'IA a commencé au bout,
avec zéro intelligence,

00:06:38.606 --> 00:06:41.647
puis, après plusieurs années de travail,

00:06:41.647 --> 00:06:45.291
nous arriverons peut-être à la rendre
au niveau de la souris,

00:06:45.291 --> 00:06:48.571
c'.-à-d. qu'elle pourra naviguer
dans des environnements encombrés,

00:06:48.571 --> 00:06:49.908
tout comme une souris.

00:06:49.908 --> 00:06:54.221
Puis, après plusieurs autres années
de travail, beaucoup d'investissements,

00:06:54.221 --> 00:06:58.860
nous arriverons peut-être au niveau
d'intelligence des chimpanzés.

00:06:58.860 --> 00:07:02.070
Puis, après encore plusieurs autres années
de travail très acharné,

00:07:02.070 --> 00:07:04.983
nous arriverons au
niveau de l’idiot du village.

00:07:04.983 --> 00:07:08.255
Puis, à peine un moment plus tard,
nous serons au-delà d'Ed Witten,

00:07:08.255 --> 00:07:11.225
car le train ne s'arrête pas
à la station Humain.

00:07:11.225 --> 00:07:14.247
Il y a de bonne chance qu'il
passe tout droit.

00:07:14.247 --> 00:07:16.231
Cela aura des conséquences importantes,

00:07:16.231 --> 00:07:20.093
en particulier lorsqu'il est
question du pouvoir.

00:07:20.093 --> 00:07:21.992
Par exemple, les chimpanzés sont forts,

00:07:21.992 --> 00:07:27.214
— livre pour livre, ils sont environ 2 fois
plus fort qu'un humain bien bâti —

00:07:27.214 --> 00:07:31.828
Pourtant, le destin de Kanzi et de ses
amis dépend bien plus

00:07:31.828 --> 00:07:35.968
des activités des humains que de leurs
propres activités.

00:07:37.228 --> 00:07:39.542
Une fois qu'il y aura
une super-intelligence,

00:07:39.542 --> 00:07:43.381
le destin des humains dépendra peut-être
uniquement des activités de celle-ci.

00:07:44.451 --> 00:07:45.508
Pensez-y:

00:07:45.508 --> 00:07:50.552
L'IA est la dernière invention que les
humains auront jamais à créer.

00:07:50.552 --> 00:07:53.525
Les machines seront de meilleurs
créateurs que nous,

00:07:53.525 --> 00:07:56.065
et ils le feront à une vitesse
à l'échelle numérique.

00:07:56.065 --> 00:08:00.966
Cela signifie que le futur
va arriver avant son temps.

00:08:00.966 --> 00:08:04.244
Pensez à toutes les technologies 
audacieuses possibles

00:08:04.244 --> 00:08:07.502
que les humains auraient peut-être
réussi à créer avec le temps:

00:08:07.502 --> 00:08:10.580
la fontaine de jouvence,
la colonisation de l'espace,

00:08:10.580 --> 00:08:14.311
des nanorobots autoréplicatifs, 
des esprits intégrés à des ordinateurs,

00:08:14.311 --> 00:08:16.490
toutes sortes de choses de science-fiction

00:08:16.490 --> 00:08:19.487
qui sont tout de même compatibles
avec les lois de la physique.

00:08:19.487 --> 00:08:23.419
Tout cela pourrait être créé par la
super-intelligence, sans doute rapidement.

00:08:24.449 --> 00:08:28.007
Une super-intelligence à
un niveau aussi élevé

00:08:28.007 --> 00:08:30.186
serait extrêmement puissante,

00:08:30.186 --> 00:08:34.732
et, dans certains scénarios,
elle aurait tout ce qu'elle veut.

00:08:34.732 --> 00:08:40.393
Notre futur serait donc 
construit selon ses préférences.

00:08:41.855 --> 00:08:45.604
Une bonne question à se poser est:
mais quelles sont ces préférences?

00:08:45.974 --> 00:08:48.013
C'est là que ça devient plus compliqué.

00:08:48.013 --> 00:08:49.448
Pour avancer sur ce sujet,

00:08:49.448 --> 00:08:52.724
il faut avant tout éviter
l'anthropomorphisme.

00:08:53.954 --> 00:09:01.115
C'est ironique, car chaque article de
journal à ce propos offre cette image.

00:09:02.280 --> 00:09:06.414
Donc, ce que je pense qu'on doit faire, 
c'est penser de façon plus abstraite,

00:09:06.414 --> 00:09:09.204
et non pas selon les
scénarios hollywoodiens.

00:09:09.204 --> 00:09:12.821
Nous devons penser à l'intelligence
comme un processus d'amélioration

00:09:12.821 --> 00:09:18.470
qui dirige le futur selon certaines
configurations précises.

00:09:18.470 --> 00:09:21.981
Une super-intelligence est un processus
d'amélioration excellent.

00:09:21.981 --> 00:09:26.098
Il est très bon pour utiliser tous 
les moyens disponibles

00:09:26.098 --> 00:09:28.007
pour arriver à son but.

00:09:28.447 --> 00:09:31.119
Cela signifie qu'il n'y a
pas nécessairement de lien

00:09:31.119 --> 00:09:33.853
entre avoir une haute intelligence

00:09:33.853 --> 00:09:38.515
et avoir un objectif que les humains 
trouvent digne d'intérêt ou significatif.

00:09:39.321 --> 00:09:43.075
Par exemple, l'IA pourrait avoir comme
objectif de faire sourire les humains.

00:09:43.075 --> 00:09:46.427
Au début, l'IA n'étant pas encore très
développée, elle fera sans doute

00:09:46.427 --> 00:09:48.614
des actions qui feront 
sourire l'utilisateur.

00:09:48.614 --> 00:09:51.031
Puis, quand elle
deviendra super-intelligente,

00:09:51.031 --> 00:09:54.674
elle découvrira qu'il y a une autre
façon plus efficace d'arriver à son but:

00:09:54.674 --> 00:09:56.476
prendre contrôle de la planète

00:09:56.476 --> 00:09:59.638
et coller des électrodes aux muscles
faciaux des humains

00:09:59.638 --> 00:10:02.489
afin que, constamment, ils
aient un large sourire.

00:10:02.489 --> 00:10:03.684
Un autre exemple.

00:10:03.684 --> 00:10:07.087
Nous donnons à l'IA un problème 
mathématique complexe à résoudre.

00:10:07.087 --> 00:10:09.174
Lorsque l'IA devient super-intelligent,

00:10:09.174 --> 00:10:13.105
il découvre que la façon la plus
efficace pour le résoudre

00:10:13.105 --> 00:10:16.035
est de transformer la planète en un
immense ordinateur

00:10:16.035 --> 00:10:18.281
afin d'augmenter sa capacité de penser.

00:10:18.281 --> 00:10:20.755
L'IA se retrouve donc avec 
une raison instrumentale

00:10:20.755 --> 00:10:23.491
de nous faire subir des choses 
que nous n'approuvons pas.

00:10:23.491 --> 00:10:25.736
Dans cet exemple, les humains
sont des menaces;

00:10:25.736 --> 00:10:28.667
nous pourrions empêcher que
le problème soit résolu.

00:10:29.207 --> 00:10:32.701
Bien sûr, les choses ne se passeront
pas nécessairement de cette façon là:

00:10:32.701 --> 00:10:34.454
ce sont des caricatures.

00:10:34.454 --> 00:10:36.643
Mais ce qui est important
à retenir est ceci:

00:10:36.643 --> 00:10:39.266
si l'on crée une machine très puissante

00:10:39.266 --> 00:10:41.500
afin d'atteindre l'objectif X,

00:10:41.500 --> 00:10:43.876
on est mieux de s'assurer que 
la définition de X

00:10:43.876 --> 00:10:46.565
comprend tout ce à quoi l'on tient.

00:10:46.835 --> 00:10:51.219
C'est une morale qui est aussi racontée
à travers plusieurs mythes.

00:10:51.219 --> 00:10:56.517
Le Roi Midas souhaite que tout ce qu'il
touche devienne de l'or.

00:10:56.517 --> 00:10:59.378
Il touche sa fille,
elle se transforme en or.

00:10:59.378 --> 00:11:01.901
Il touche sa nourriture,
elle se transforme en or.

00:11:01.901 --> 00:11:06.590
Ceci est pertinent non seulement pour
créer une métaphore sur l'envie,

00:11:06.590 --> 00:11:11.405
mais aussi pour illustrer ce qui arrive
si l'on crée une super-machine

00:11:11.405 --> 00:11:16.111
et qu'on lui donne des buts inadaptés
ou mal spécifiés.

00:11:16.111 --> 00:11:21.300
On peut penser: «&nbsp;Si l'ordinateur commence
à coller des électrodes sur les gens,

00:11:21.300 --> 00:11:23.565
on n'aura qu'à l'éteindre.&nbsp;»

00:11:24.555 --> 00:11:29.895
1. Ce n'est pas nécessairement facile
si nous sommes dépendants du système

00:11:29.895 --> 00:11:32.627
— Où est le bouton off d'Internet? —

00:11:32.627 --> 00:11:37.747
2. Pourquoi les chimpanzés n'ont pas
«&nbsp;éteint&nbsp;» les humains

00:11:37.747 --> 00:11:39.298
ou les Néandertaliens?

00:11:39.298 --> 00:11:41.964
Ils avaient sans doute des raisons,

00:11:41.964 --> 00:11:44.759
car nous pouvons être éteints, 
par exemple, par ici.

00:11:44.759 --> 00:11:46.143
— Étouffant —

00:11:46.143 --> 00:11:48.908
La raison est que nous sommes
des adversaires intelligents.

00:11:48.908 --> 00:11:51.926
Nous pouvons anticiper les menaces
et planifier en conséquence.

00:11:51.926 --> 00:11:54.800
Et c'est ce que ferait un ordinateur
super-intelligent,

00:11:54.800 --> 00:11:57.724
et bien mieux que nous en plus.

00:11:57.724 --> 00:12:04.911
Le fait est que nous ne devrions pas
penser que nous maîtrisons la situation.

00:12:04.911 --> 00:12:08.358
Nous pourrions essayer de faciliter
notre travail

00:12:08.358 --> 00:12:09.948
en mettant l'IA dans une boîte,

00:12:09.948 --> 00:12:11.984
tel un environnement 
numérique sécuritaire,

00:12:11.984 --> 00:12:14.816
une réalité virtuelle de laquelle il ne
pourrait s'échapper.

00:12:14.816 --> 00:12:18.912
Mais pouvons-nous vraiment être sûr que
l'IA ne trouvera pas de bogues,

00:12:18.912 --> 00:12:22.081
surtout considérant que les hackers
humains y arrivent sans arrêt?

00:12:22.081 --> 00:12:25.117
Je ne crois pas.

00:12:26.237 --> 00:12:30.785
Donc nous débranchons les câbles ethernets
afin de créer un manque d'air,

00:12:30.785 --> 00:12:33.113
mais là encore, les hackers humains

00:12:33.113 --> 00:12:36.694
passent de manière routinière par-dessus
ces problèmes grâce à l’ingénierie.

00:12:36.694 --> 00:12:38.093
Au moment où je vous parle,

00:12:38.093 --> 00:12:40.482
je suis sûr qu'il y a un employé,
quelque part,

00:12:40.482 --> 00:12:43.828
que l'on a convaincu de divulguer
les détails de son compte

00:12:43.828 --> 00:12:46.564
en prétendant être du
département de soutien informatique.

00:12:46.564 --> 00:12:48.861
Des scénarios plus créatifs
sont aussi possibles.

00:12:48.861 --> 00:12:50.346
Par exemple, si vous êtes l'IA,

00:12:50.346 --> 00:12:53.898
vous pouvez vous imaginer remuant des
électrodes dans votre circuit interne

00:12:53.898 --> 00:12:57.010
afin de créer des ondes radios
pour communiquer.

00:12:57.010 --> 00:12:59.434
Ou, vous pourriez prétendre
ne plus fonctionner,

00:12:59.434 --> 00:13:03.011
et, lorsque les programmeurs vous ouvrent
afin de voir quel est le problème,

00:13:03.011 --> 00:13:04.867
il regarde le code source, et BAM!,

00:13:04.867 --> 00:13:07.314
la manipulation peut commencer.

00:13:07.314 --> 00:13:10.744
Ou il pourrait changer les plans
avec une technologie astucieuse

00:13:10.744 --> 00:13:12.642
de tel sorte que
lorsqu'on les implante,

00:13:12.642 --> 00:13:16.539
un effet secondaire
prévu par l'IA se produit.

00:13:16.539 --> 00:13:20.002
Ce qu'il faut retenir, c'est qu'on ne 
devrait pas avoir trop confiance

00:13:20.002 --> 00:13:23.810
en notre capacité à maintenir
un génie dans une lampe pour toujours.

00:13:23.810 --> 00:13:26.064
Tôt ou tard, il en sortira.

00:13:27.034 --> 00:13:30.137
Je crois que la solution 
est de trouver une façon

00:13:30.137 --> 00:13:36.308
de créer une IA qui, même si elle
s'échappe, sera toujours sécuritaire:

00:13:36.308 --> 00:13:40.337
une IA qui sera toujours de notre bord,
car elle partagera nos valeurs.

00:13:40.337 --> 00:13:43.547
Je ne vois aucun moyen
de contourner ce problème.

00:13:44.557 --> 00:13:48.391
Mais je suis plutôt optimiste et
je crois qu'on peut trouver la solution.

00:13:48.391 --> 00:13:52.294
Nous n'aurions pas à faire une longue
liste de tout ce à quoi l'on tient,

00:13:52.294 --> 00:13:55.937
ou, pire encore, transformer celle-ci
en langage informatique

00:13:55.937 --> 00:13:57.391
tel C++ ou Python;

00:13:57.391 --> 00:14:00.158
ce serait une tâche désespérée.

00:14:00.158 --> 00:14:04.455
Il faudrait plutôt créer une IA 
qui utilise son intelligence

00:14:04.455 --> 00:14:07.226
pour apprendre ce à quoi l'on tient

00:14:07.226 --> 00:14:12.506
et qui est construit de tel sorte que 
sa motivation consiste à défendre

00:14:12.506 --> 00:14:17.738
nos valeurs ou à faire des actions
seulement s'il pense qu'on les approuve.

00:14:17.738 --> 00:14:21.152
Nous utiliserions donc son
intelligence autant que possible

00:14:21.152 --> 00:14:24.537
afin qu'elle résolve le problème
d’implantation de la liste de valeurs.

00:14:24.727 --> 00:14:26.239
Cela est possible

00:14:26.239 --> 00:14:29.835
et le résultat pourrait être
incroyable pour l'humanité.

00:14:29.835 --> 00:14:33.492
Mais ça ne se passera pas
comme ça obligatoirement.

00:14:33.492 --> 00:14:37.380
Il faut que les conditions initiales, 
lors de l'explosion de l'intelligence,

00:14:37.380 --> 00:14:41.913
soient créées d'une façon spécifique afin
que nous ayons un détonation contrôlée.

00:14:42.273 --> 00:14:45.541
Les valeurs de l'IA doivent être
les mêmes que les nôtres

00:14:45.541 --> 00:14:47.741
non seulement dans le
contexte que l'on connaît

00:14:47.741 --> 00:14:49.999
où l'on peut contrôler
son comportement,

00:14:49.999 --> 00:14:53.233
mais aussi dans des contextes nouveaux
que l'IA peut rencontrer

00:14:53.233 --> 00:14:54.790
dans un futur indéfini.

00:14:54.790 --> 00:14:59.107
Il y a aussi quelques problèmes
ésotériques qui devraient être réglés:

00:14:59.107 --> 00:15:01.616
le détail de sa méthode pour
prendre des décisions,

00:15:01.616 --> 00:15:04.480
sa façon de gérer les 
incertitudes logiques, etc.

00:15:05.330 --> 00:15:09.275
Donc, les problèmes techniques qui
doivent être résolus semblent difficiles,

00:15:09.275 --> 00:15:12.925
pas autant que créer 
une IA super-intelligente,

00:15:12.925 --> 00:15:15.793
mais assez difficiles quand même.

00:15:15.793 --> 00:15:17.488
Voici ce qui est inquiétant:

00:15:17.488 --> 00:15:22.172
Créer une IA super-intelligente
est un défi colossal.

00:15:22.172 --> 00:15:25.180
Créer une IA super-intelligente 
qui, en plus, est sécuritaire

00:15:25.180 --> 00:15:27.256
rajoute un niveau de difficulté.

00:15:28.216 --> 00:15:31.913
Le risque réside dans la possibilité que
quelqu'un surmonte le premier défi,

00:15:31.913 --> 00:15:36.054
sans avoir surmonté le deuxième, 
celui de la sécurité.

00:15:37.375 --> 00:15:42.886
Donc, je crois qu'on devrait surmonter
le deuxième défi en avance

00:15:43.138 --> 00:15:46.188
afin qu'il soit prêt lorsqu'on
en a besoin.

00:15:46.768 --> 00:15:50.275
Peut-être ne pourrons-nous pas le
surmonter entièrement en avance,

00:15:50.275 --> 00:15:53.299
car certains éléments 
ne peuvent être créés

00:15:53.299 --> 00:15:56.916
seulement lorsque l'on connaîtra les
détails techniques de l'IA en question.

00:15:56.916 --> 00:16:00.676
Mais plus nous commencerons à travailler
sur ce problème de contrôle en avance,

00:16:00.676 --> 00:16:04.766
plus nous augmenterons nos chances
de passer dans cette nouvelle ère

00:16:04.766 --> 00:16:06.306
en tout sécurité.

00:16:06.306 --> 00:16:10.950
Selon moi, ceci est la chose
la plus importante à faire.

00:16:10.950 --> 00:16:14.282
Je suis sûr que si on y parvient,

00:16:14.282 --> 00:16:18.940
les humains dans des millions d'années
qui se pencheront sur notre siècle

00:16:18.940 --> 00:16:22.942
diront que la seule chose que nous avons 
fait qui avait vraiment de l'importance

00:16:22.942 --> 00:16:24.759
était de réussir à surmonter ce défi.

00:16:24.759 --> 00:16:26.198
Merci

00:16:26.198 --> 00:16:29.011
(Applaudissements)

