WEBVTT
Kind: captions
Language: uk

00:00:00.000 --> 00:00:07.000
Перекладач: Daria Prichantovskaya
Утверджено: Khrystyna Romashko

00:00:12.570 --> 00:00:16.777
Я працював із купою математиків, філософів
та інформатиків,

00:00:16.777 --> 00:00:21.986
і ми сиділи й думали 
про майбутнє машинного інтелекту,

00:00:21.986 --> 00:00:24.030
серед іншого.

00:00:24.030 --> 00:00:28.755
Дехто вважає, що дещо з цього
щось типу наукової фантастики,

00:00:28.755 --> 00:00:31.856
недосяжне, божевільне.

00:00:31.856 --> 00:00:33.326
Але я люблю казати:

00:00:33.326 --> 00:00:36.930
"Добре, подивімося на те, якою є
сучасна людина".

00:00:36.930 --> 00:00:38.622
(Сміх)

00:00:38.622 --> 00:00:41.024
Це звичайний стан речей.

00:00:41.024 --> 00:00:43.309
Але якщо ми замислимося над цим,

00:00:43.309 --> 00:00:46.602
ми, власне, гості на цій планеті,

00:00:46.602 --> 00:00:48.684
людський рід.

00:00:48.684 --> 00:00:53.430
Задумайтесь, що, якби Землю
було створено рік тому,

00:00:53.430 --> 00:00:56.978
людство тоді б було віком лише 10 хвилин.

00:00:56.978 --> 00:01:00.146
Індустріальна ера розпочалася
дві секунди тому.

00:01:01.276 --> 00:01:06.501
Інший кут зору - подумати
про світовий ВВП за останні 10 000 років,

00:01:06.501 --> 00:01:09.530
я взагалі-то подбав про те, щоб
накреслити для вас графік.

00:01:09.530 --> 00:01:11.304
Він виглядає отак.

00:01:11.304 --> 00:01:12.667
(Сміх)

00:01:12.667 --> 00:01:14.818
Це цікава форма для звичайного стану.

00:01:14.818 --> 00:01:16.516
Я, напевне, не хотів би
сидіти на цьому.

00:01:16.516 --> 00:01:19.067
(Сміх)

00:01:19.067 --> 00:01:23.841
Давайте спитаємо себе: "Що спричинило
цю теперішню аномалію?"

00:01:23.841 --> 00:01:26.393
Хтось скаже, що це технології.

00:01:26.393 --> 00:01:31.061
Дійсно, технології накопичувалися
протягом людської історії.

00:01:31.061 --> 00:01:35.713
і просто зараз технології
розвиваються вкрай швидко -

00:01:35.713 --> 00:01:37.278
це безпосередня причина,

00:01:37.278 --> 00:01:39.843
чому ми зараз такі продуктивні.

00:01:40.473 --> 00:01:44.134
Але я волію згадувати про
кінцеву мету.

00:01:45.114 --> 00:01:48.880
Подивіться на цих двох
шляхетних джентльменів:

00:01:48.880 --> 00:01:50.480
Це Канзі --

00:01:50.480 --> 00:01:55.123
він вивчив 200 лексичних символів,
неймовірне досягнення.

00:01:55.123 --> 00:01:58.817
І Ед Віттен, котрий спричинив
другу суперструнну революцію.

00:01:58.817 --> 00:02:01.141
Якщо ми заглянемо "під капот",
ось що з'ясується:

00:02:01.141 --> 00:02:02.711
по суті, те саме.

00:02:02.711 --> 00:02:04.524
Один трошки більший,

00:02:04.524 --> 00:02:07.282
він може мати певні 
особливості в сплетінні.

00:02:07.282 --> 00:02:11.094
Ці невидимі відмінності однак 
не можуть бути надто складними,

00:02:11.094 --> 00:02:15.379
тому що було лише
250 000 поколінь

00:02:15.379 --> 00:02:17.111
від останнього 
спільного предка.

00:02:17.111 --> 00:02:20.960
Ми знаємо, що складний механізм
потребує багато часу, щоб розвинутися.

00:02:22.000 --> 00:02:24.499
Тому купа відносно незначних змін

00:02:24.499 --> 00:02:27.566
привели нас від Канзі до Віттена,

00:02:27.566 --> 00:02:32.109
від відламаних гілок дерева до
міжконтинентальних балістичних ракет.

00:02:32.839 --> 00:02:36.774
Отже тоді виглядає цілком очевидно,
що все, чого ми досягли,

00:02:36.774 --> 00:02:38.152
і все, що нам небайдуже,

00:02:38.152 --> 00:02:43.380
принципово залежить від досить неістотних
змін, яких зазнав людський мозок.

00:02:44.650 --> 00:02:48.312
І як наслідок, звичайно,
усі подальші зміни,

00:02:48.312 --> 00:02:51.789
які можуть докорінно змінити
підґрунтя для мислення,

00:02:51.789 --> 00:02:54.991
матимуть потенційно
величезні наслідки.

00:02:56.321 --> 00:02:59.226
Дехто з моїх колег
вважає, що ми на межі

00:02:59.226 --> 00:03:03.134
чогось, що може призвести до
глибоких змін у цьому підґрунті,

00:03:03.134 --> 00:03:06.347
і це машинний суперінтелект.

00:03:06.347 --> 00:03:11.086
Штучний інтелект був чимось на кшталт
введення команд у коробку.

00:03:11.086 --> 00:03:12.751
У вас мають бути люди-програмісти,

00:03:12.751 --> 00:03:15.886
які скрупульозно вручну
створюватимуть одиниці знань.

00:03:15.886 --> 00:03:17.972
Ви будуєте цю систему 
штучного інтелекту,

00:03:17.972 --> 00:03:20.296
і вона типу корисна для якихось цілей,

00:03:20.296 --> 00:03:22.977
але надто крихка, 
її не можна масштабувати.

00:03:22.977 --> 00:03:26.410
По суті, ви отримуєте лише те,
що самі вклали всередину.

00:03:26.410 --> 00:03:27.407
Але відтоді

00:03:27.407 --> 00:03:30.874
стався зсув парадигми
у галузі штучного інтелекту.

00:03:30.874 --> 00:03:33.644
Сьогодні дія відбувається
довкола машинного навчання.

00:03:34.394 --> 00:03:39.781
Тому, радше, ніж створювати вручну
образи та характеристики знань,

00:03:40.511 --> 00:03:46.065
ми створюємо алгоритми, які вчаться
на "сирих" сприйняттєвих даних.

00:03:46.065 --> 00:03:51.063
Власне, це те саме, що робить
дитина.

00:03:51.063 --> 00:03:55.270
Результатом є штучний інтелект, не 
обмежений однією цариною -

00:03:55.270 --> 00:03:59.901
та ж система спроможна навчитися
перекладати між будь-якими парами мов,

00:03:59.901 --> 00:04:05.338
або навчитися грати у будь-яку 
комп'ютерну гру на консолі Атарі.

00:04:05.338 --> 00:04:07.117
Зараз, звісно,

00:04:07.117 --> 00:04:11.116
штучний інтелект далекий від того,
щоб мати таку могутню міжгалузеву

00:04:11.116 --> 00:04:14.335
здатність вчитися і планувати,
яку має людина.

00:04:14.335 --> 00:04:16.461
Кора головного мозку досі має
деякі хитрощі,

00:04:16.461 --> 00:04:18.816
які ми поки що не знаємо, як
створити у машинах.

00:04:19.886 --> 00:04:21.785
Тому питання:

00:04:21.785 --> 00:04:25.285
як далеко ми від спроможності
розгадати ці хитрощі?

00:04:26.245 --> 00:04:27.328
Пару років тому

00:04:27.328 --> 00:04:30.216
ми провели опитування серед
провідних експертів зі штучного інтелекту,

00:04:30.216 --> 00:04:33.440
щоб побачити, що вони думають,
і одним із питань було:

00:04:33.440 --> 00:04:36.793
"У якому році, на вашу думку, 
існує 50-відсоткова імовірність

00:04:36.793 --> 00:04:40.275
досягнення людського рівня
інтелекту у машині?"

00:04:40.785 --> 00:04:44.968
Тут ми визначили людський рівень
як спроможність виконувати

00:04:44.968 --> 00:04:47.839
майже будь-яку роботу, принаймні
так само, як доросла людина,

00:04:47.839 --> 00:04:51.844
отже справжній людський рівень, 
не лише в межах певної обмеженої галузі.

00:04:51.844 --> 00:04:55.494
І середня відповідь була 2040 або 2050,

00:04:55.494 --> 00:04:58.300
залежно від того, яку групу
експертів ми питали.

00:04:58.300 --> 00:05:02.339
Це може статися набагато пізніше,
або раніше,

00:05:02.339 --> 00:05:04.279
правду кажучи, ніхто 
в дійсності не знає.

00:05:05.259 --> 00:05:09.671
Ми знаємо, що остаточний
ліміт на оброблення інформації

00:05:09.671 --> 00:05:14.542
на машинному підґрунті дуже
перевершує обмеження біологічних тканин.

00:05:15.241 --> 00:05:17.619
Це походить з фізики.

00:05:17.619 --> 00:05:22.337
Біологічний нейрон передає, мабуть,
на 200 герц, 200 разів за секунду.

00:05:22.337 --> 00:05:25.931
Але навіть сьогоднішній транзистор
оперує гігагерцами.

00:05:25.931 --> 00:05:31.228
Нейрони поширюються повільно в аксонах,
100 метрів за секунду найбільше.

00:05:31.228 --> 00:05:34.339
Але в комп'ютерах сигнали можуть ширитися
зі швидкістю світла.

00:05:35.079 --> 00:05:36.948
Тут теж є обмеження за величиною,

00:05:36.948 --> 00:05:39.975
бо людський мозок має
вміщуватися у череп,

00:05:39.975 --> 00:05:44.736
але комп'ютер може бути завбільшки
з цілий склад або й більшим.

00:05:44.736 --> 00:05:50.335
Тому потенціал суперінтелекту
поки що спить у матерії,

00:05:50.335 --> 00:05:56.047
точнісінько як потужність атома
спала протягом людської історії,

00:05:56.047 --> 00:06:00.452
терпляче чекаючи на 1945.

00:06:00.452 --> 00:06:01.700
Цього століття

00:06:01.700 --> 00:06:05.818
науковці можуть навчитися, як розбудити
могутність штучного інтелекту.

00:06:05.818 --> 00:06:09.826
І мені здається, що ми можемо тоді
спостерегти бурхливий розвиток інтелекту.

00:06:10.406 --> 00:06:14.363
Зараз більшість людей, думаючи про те,
що є розумним і що дурним,

00:06:14.363 --> 00:06:17.386
мені здається, тримають у голові
десь схожу на оцю картинку.

00:06:17.386 --> 00:06:19.984
На початку ми маємо сільського дурника,

00:06:19.984 --> 00:06:22.467
і далеко на іншому кінці -

00:06:22.467 --> 00:06:27.223
Еда Віттена, Альберта Ейнштейна, або
хто там ваш улюблений гуру.

00:06:27.223 --> 00:06:31.057
Але мені здається, що з точки зору
штучного інтелекту,

00:06:31.057 --> 00:06:34.738
справжня картинка дійсно
більше схожа на ось таку.

00:06:35.258 --> 00:06:38.636
Все починається в цій точці отут,
на нульовому інтелекті,

00:06:38.636 --> 00:06:41.647
і потім, після багатьох-багатьох
років направду тяжкої праці,

00:06:41.647 --> 00:06:45.491
мабуть, зрештою ми досягнемо
штучного інтелекту на рівні миші,

00:06:45.491 --> 00:06:47.921
який зможе орієнтуватися у
захаращених середовищах

00:06:47.921 --> 00:06:49.908
так само, як це може миша.

00:06:49.908 --> 00:06:54.221
Потім, після ще більшої кількості років
дуже тяжкої праці, інвестицій,

00:06:54.221 --> 00:06:58.860
мабуть, зрештою ми досягнемо рівня
інтелекту на рівні шимпанзе.

00:06:58.860 --> 00:07:02.070
І потім, після ще більшої кількості років
дуже-дуже тяжкої праці,

00:07:02.070 --> 00:07:04.983
ми досягнемо штучного інтелекту
на рівні сільського дурника.

00:07:04.983 --> 00:07:08.255
А кілька митей потому ми вже
вийдемо за межі Еда Віттена.

00:07:08.255 --> 00:07:11.225
Потяг не спиняється
на станції "Людствоград".

00:07:11.225 --> 00:07:14.247
Він, скоріше, мчить повз неї зі свистом.

00:07:14.247 --> 00:07:16.231
Тепер це має глибокі наслідки,

00:07:16.231 --> 00:07:20.093
особливо, коли йдеться про питання влади.

00:07:20.093 --> 00:07:21.992
Приміром, шимпанзе сильні -

00:07:21.992 --> 00:07:27.214
за будь-яких умов шимпанзе принаймні
удвічі сильніший за здорового чоловіка.

00:07:27.214 --> 00:07:31.828
Тим не менше, доля Канзі і його товаришів
набагато більше залежить

00:07:31.828 --> 00:07:35.968
від того, що робимо ми, люди,
ніж від того, що шимпанзе роблять самі.

00:07:37.228 --> 00:07:39.542
Коли з'явиться суперінтелект,

00:07:39.542 --> 00:07:43.381
доля людства може залежати від того,
що робитиме цей інтелект.

00:07:44.451 --> 00:07:45.508
Подумайте про це:

00:07:45.508 --> 00:07:50.552
машинний інтелект - це остання річ,
яку людство має винайти.

00:07:50.552 --> 00:07:53.525
Машини після цього будуть кращими
винахідниками, ніж ми,

00:07:53.525 --> 00:07:56.065
і вони робитимуть це
із цифровою швидкістю.

00:07:56.065 --> 00:08:00.966
Це фактично означає
телескопіювання майбутнього.

00:08:00.966 --> 00:08:04.524
Уявіть лише всі божевільні технології,

00:08:04.524 --> 00:08:07.322
які людство могло б розвинути,
маючи вдосталь часу:

00:08:07.322 --> 00:08:10.580
ліки від старіння, колонізація космосу,

00:08:10.580 --> 00:08:14.311
самовідтворювані наноботи чи
завантаження свідомості у комп'ютер,

00:08:14.311 --> 00:08:16.470
усі ці науково-фантастичні штуки,

00:08:16.470 --> 00:08:19.207
які, тим не менше, сумісні
із законами фізики.

00:08:19.207 --> 00:08:23.419
Усе це суперінтелект може розвинути,
і, можливо, цілком швидко.

00:08:24.449 --> 00:08:28.007
Суперінтелект із такою
технологічною довершеністю

00:08:28.007 --> 00:08:30.186
буде неймовірно могутнім,

00:08:30.186 --> 00:08:34.732
і принаймні за кількох сценаріїв він
досягне того, чого прагне.

00:08:34.732 --> 00:08:40.393
Ми тоді матимемо майбутнє,
окреслене цінностями цього штучного інтелекту.

00:08:41.855 --> 00:08:45.604
Тепер хороше питання: які це цінності?

00:08:46.244 --> 00:08:48.013
Тут все стає складнішим.

00:08:48.013 --> 00:08:49.448
Щоб просунутися із цим уперед,

00:08:49.448 --> 00:08:52.724
ми маємо насамперед
уникати антропоморфічності.

00:08:53.934 --> 00:08:57.235
І в цьому іронія, адже кожна
стаття в газеті

00:08:57.235 --> 00:09:01.090
про майбутнє штучного інтелекту
проілюстрована ось цим.

00:09:02.280 --> 00:09:06.414
Тому я думаю, що ми повинні підійти
до питання абстрактніше,

00:09:06.414 --> 00:09:09.204
не в дусі яскравих
голлівудських сценаріїв.

00:09:09.204 --> 00:09:12.821
Ми маємо подумати про інтелект
як про процес оптимізації,

00:09:12.821 --> 00:09:18.470
процес, що кермує майбутнє у
визначений набір структур.

00:09:18.470 --> 00:09:21.981
Суперінтелект направду є сильним
опитимізаційним процесом.

00:09:21.981 --> 00:09:26.098
Він неймовірний у використанні
доступних зособів

00:09:26.098 --> 00:09:28.007
для досягнення мети.

00:09:28.447 --> 00:09:31.119
Це значить, що немає необхідних
зв'язків між

00:09:31.119 --> 00:09:33.853
бути високорозвиненим у цьому сенсі

00:09:33.853 --> 00:09:38.515
і мати ціль, яку ми, люди,
вважатимемо вартісною і змістовною.

00:09:39.321 --> 00:09:43.115
Припустимо, ми поставили перед Ш. І. мету
викликати у людей посмішку.

00:09:43.115 --> 00:09:46.097
Коли Ш. І. слабкий, він робитиме
потрібні або кумедні речі,

00:09:46.097 --> 00:09:48.614
які змусять його користувача посміхатися.

00:09:48.614 --> 00:09:51.031
Коли Ш. І. стане суперінтелектом,

00:09:51.031 --> 00:09:54.554
він зрозуміє, що є ефективніші
шляхи досягти цієї мети:

00:09:54.554 --> 00:09:56.476
підкорити світ

00:09:56.476 --> 00:09:59.638
і приклеїти електроди до лицевих
м'язів людей,

00:09:59.638 --> 00:10:02.579
щоб викликати постійний променистий вищир.

00:10:02.579 --> 00:10:03.614
Інший приклад:

00:10:03.614 --> 00:10:06.997
скажімо, ми даємо Ш. І. завдання вирішити
складну математичну проблему.

00:10:06.997 --> 00:10:08.934
Коли Ш. І. стане суперінтелектом,

00:10:08.934 --> 00:10:13.105
він зрозуміє, що найефективніший шлях
отримати вирішення цієї проблеми --

00:10:13.105 --> 00:10:16.035
це перетворити планету
на гігантський комп'ютер,

00:10:16.035 --> 00:10:18.281
щоб збільшити свою
спроможність мислити.

00:10:18.281 --> 00:10:21.045
Зауважте, що це дає Ш. І. 
інструментальну причину

00:10:21.045 --> 00:10:23.561
робити якісь речі так,
що ми цього не схвалимо.

00:10:23.561 --> 00:10:25.496
Людські створіння у цій моделі -
це загрози,

00:10:25.496 --> 00:10:28.417
ми можемо перешкодити
вирішенню цієї проблеми.

00:10:29.207 --> 00:10:32.701
Звичайно, відчутно речі не підуть
цим хибним шляхом;

00:10:32.701 --> 00:10:34.454
це гіпертрофовані приклади.

00:10:34.454 --> 00:10:36.393
Але загалом це важливо:

00:10:36.393 --> 00:10:39.266
якщо ви створюєте дійсно потужний
оптимізаційний процес

00:10:39.266 --> 00:10:41.500
для збільшення об'єктивного х,

00:10:41.500 --> 00:10:43.776
краще впевніться, що ваше визначення х

00:10:43.776 --> 00:10:46.245
включає все, що вам небайдуже.

00:10:46.835 --> 00:10:51.219
Це урок, якому нас вчать у багатьох міфах.

00:10:51.219 --> 00:10:56.517
Цар Мідас бажав, щоб усе, до чого
він торкався, оберталося на золото.

00:10:56.517 --> 00:10:59.378
Він торкнувся своєї доньки,
вона перетворилася на золото.

00:10:59.378 --> 00:11:01.931
Він торкнувся їжі -- вона стала золотом.

00:11:01.931 --> 00:11:04.520
Це може стати практично дійсністю,

00:11:04.520 --> 00:11:06.590
не лише як метафора жадібності,

00:11:06.590 --> 00:11:08.485
а й як ілюстрація того, що стається,

00:11:08.485 --> 00:11:11.322
коли ви створюєте потужний
оптимізаційний процес

00:11:11.322 --> 00:11:16.111
і ставите перед ним несформульовані
або погано описані цілі.

00:11:16.111 --> 00:11:21.300
Ви можете зауважити: якщо комп'ютер почне
тицяти електродами людям в обличчя,

00:11:21.300 --> 00:11:23.565
ми просто вимкнемо його.

00:11:24.555 --> 00:11:29.895
А) Це необов'язково просто зробити,
якщо ми виросли залежними від системи --

00:11:29.895 --> 00:11:32.627
типу, як тепер вимкнути інтернет?

00:11:32.627 --> 00:11:37.747
Б) Чому ж шимпанзе не натиснули
на вимикач людства,

00:11:37.747 --> 00:11:39.298
чи неандертальці?

00:11:39.298 --> 00:11:41.964
Вони, напевно, мали причини.

00:11:41.964 --> 00:11:44.759
Ми маємо вимикач, наприклад, прямо тут.

00:11:44.759 --> 00:11:46.313
(Тисне)

00:11:46.313 --> 00:11:49.238
Причина в тому, що ми -
розумний супротивник;

00:11:49.238 --> 00:11:51.966
ми можемо передбачати загрози
і планувати навколо них.

00:11:51.966 --> 00:11:54.470
Але так зможе і суперінтелектелект,

00:11:54.470 --> 00:11:57.724
і він буде набагато вправнішим
в цьому за нас.

00:11:57.724 --> 00:12:04.911
Справа в тому, що ми не можемо бути
впевнені, що у нас усе під контролем.

00:12:04.911 --> 00:12:08.358
І ми можемо спробувати зробити
своє завдання трохи легшим, скажімо,

00:12:08.358 --> 00:12:09.948
поклавши Ш. І. до коробки,

00:12:09.948 --> 00:12:11.744
як у безпечне софтверне середовище,

00:12:11.744 --> 00:12:14.766
у симулятор віртуальної реальності,
з якої він не може втекти.

00:12:14.766 --> 00:12:18.912
Але як ми можемо бути певні, що
Ш. І. не зможе знайти баг?

00:12:18.912 --> 00:12:22.081
Зважаючи, що навіть хакери-люди
постійно знаходять баги,

00:12:22.081 --> 00:12:25.117
я б сказав, імовірно, не дуже впевнено.

00:12:26.237 --> 00:12:30.785
Ми від'єднуємо кабель локальної мережі,
щоб створити повітряний проміжок,

00:12:30.785 --> 00:12:33.453
але знов-таки, навіть хакери-люди

00:12:33.453 --> 00:12:36.834
"перестрибують" повітряні проміжки,
використовуючи соціальну інженерію.

00:12:36.834 --> 00:12:38.093
Зараз, коли я розмовляю,

00:12:38.093 --> 00:12:40.482
впевнений, що є десь якийсь службовець,

00:12:40.482 --> 00:12:43.828
який повідомляє дані свого акаунту

00:12:43.828 --> 00:12:46.574
комусь, хто стверджує, 
що він з ІТ-департаменту.

00:12:46.574 --> 00:12:48.701
Більш оригінальні сценарії теж можливі,

00:12:48.701 --> 00:12:50.016
типу, якщо ви Ш.І.,

00:12:50.016 --> 00:12:53.548
ви можете уявити тремтячі електроди
навколо свого устаткування,

00:12:53.548 --> 00:12:57.010
щоб створити радіохвилі, які можна
використати для комунікації.

00:12:57.010 --> 00:12:59.434
Або ви навіть можете 
удати з себе зламаного,

00:12:59.434 --> 00:13:02.931
і коли програміст відкриє вас,
щоб подивитися, що з вами не так,

00:13:02.931 --> 00:13:04.867
вони дивляться у вихідний код -- Бам! --

00:13:04.867 --> 00:13:07.314
може статися маніпуляція.

00:13:07.314 --> 00:13:10.744
Або він може надрукувати схему
дійсно вартісної технології,

00:13:10.744 --> 00:13:12.142
і коли ми реалізуємо її,

00:13:12.142 --> 00:13:16.539
вона матиме якісь побічні ефекти,
які Ш. І. нишком спланував.

00:13:16.539 --> 00:13:20.002
Справа в тому, що ми не повинні бути
впевнені у нашій можливості

00:13:20.002 --> 00:13:23.810
тримати суперінтелектуального джина
у його пляшці довіку.

00:13:23.810 --> 00:13:26.064
Раніш чи пізніш він визволиться.

00:13:27.034 --> 00:13:30.137
Я вірю, що відповідь тут - це з'ясувати,

00:13:30.137 --> 00:13:35.161
як створити такий супер Ш. І.,
щоб навіть якщо він втече,

00:13:35.161 --> 00:13:38.438
він залишатиметься безпечним,
бо буде принципово на нашому боці,

00:13:38.438 --> 00:13:40.337
бо розділятиме наші цінності.

00:13:40.337 --> 00:13:43.547
Я не бачу виходу з цієї складної проблеми.

00:13:44.557 --> 00:13:48.391
Зараз я досить оптимістичний
щодо її вирішення.

00:13:48.391 --> 00:13:52.294
Ми не повинні писати довгий
список того, до чого ми небайдужі,

00:13:52.294 --> 00:13:55.937
або навіть гірше, промовляти це 
якоюсь комп'ютерною мовою,

00:13:55.937 --> 00:13:57.391
типу С++ або Пітону,

00:13:57.391 --> 00:14:00.158
це буде безнадійне завдання.

00:14:00.158 --> 00:14:04.455
Натомість ми маємо створити Ш. І.,
що використовує свій інтелект,

00:14:04.455 --> 00:14:07.226
щоб дізнатися про наші цінності,

00:14:07.226 --> 00:14:12.506
і його мотиваційна система сконструйована
так, що він мотивований

00:14:12.506 --> 00:14:17.738
розділяти наші цінності або виконувати 
дії, які ми маємо схвалити.

00:14:17.738 --> 00:14:21.152
Тоді ми подіємо на його інтелект 
так сильно, як тільки зможемо,

00:14:21.152 --> 00:14:23.897
щоб вирішити проблему 
"завантаження цінностей".

00:14:24.727 --> 00:14:26.239
Це може статися,

00:14:26.239 --> 00:14:29.835
і результат може виявитись 
дуже вагомим для людства.

00:14:29.835 --> 00:14:33.792
Але це не станеться автоматично.

00:14:33.792 --> 00:14:36.790
Початкові умови інтелектуального вибуху

00:14:36.790 --> 00:14:39.653
потрібно правильно встановити,

00:14:39.653 --> 00:14:43.183
так, ніби ми маємо 
контрольований детонатор.

00:14:43.183 --> 00:14:45.801
Цінності, за якими Ш.І. 
має свівпадати з нами,

00:14:45.801 --> 00:14:47.561
мають бути не лише вже нам знайомими,

00:14:47.561 --> 00:14:49.999
такими, за якими ми легко 
перевіримо поведінку Ш.І.,

00:14:49.999 --> 00:14:53.233
але також і в новітньому контексті, 
який Ш.І. прораховуватиме

00:14:53.233 --> 00:14:54.790
в невизначеному майбутньому.

00:14:54.790 --> 00:14:59.527
Є також певні потаємні проблеми,
які необхідно вирішити, наприклад:

00:14:59.527 --> 00:15:01.616
конкретні деталі теорії прийняття рішень,

00:15:01.616 --> 00:15:04.480
як справлятись з логічними 
невизначенностями і таке інше.

00:15:05.330 --> 00:15:08.432
Тому технічні проблеми, які будемо 
вирішувати, щоб все спрацювало,

00:15:08.432 --> 00:15:09.545
є досить складними --

00:15:09.545 --> 00:15:12.925
не настільки, як власне створення Ш.І.,

00:15:12.925 --> 00:15:15.793
але достатньо складними.

00:15:15.793 --> 00:15:17.488
Мене хвилює наступне:

00:15:17.488 --> 00:15:22.172
створення Ш.І. є, по-справжньому, 
складним випробуванням.

00:15:22.172 --> 00:15:24.720
Створення безпечного Ш.І.

00:15:24.720 --> 00:15:27.136
включає ще додаткову складність.

00:15:28.216 --> 00:15:31.703
Ризик у тому, що хтось зможе 
розгадати перше випробування,

00:15:31.703 --> 00:15:34.704
не розгадуючи додаткове,

00:15:34.704 --> 00:15:36.605
по забезпеченню абсолютної безпеки.

00:15:37.375 --> 00:15:40.706
Тому, я вважаю, що розв'язок 
проблеми контролю

00:15:40.706 --> 00:15:43.528
нам потрібно розробити в першу чергу,

00:15:43.528 --> 00:15:46.188
щоб мати його одразу тоді, 
коли знадобиться.

00:15:46.768 --> 00:15:50.275
Зараз ми, можливо, не можемо розгадати 
всю проблему контролю наперед,

00:15:50.275 --> 00:15:53.299
оскільки деякі елементи можна створити

00:15:53.299 --> 00:15:57.296
лише знаючи деталі загальної архітектури, 
куди їх буде впроваджено.

00:15:57.296 --> 00:16:00.676
Але чим більше ми розробимо наперед,

00:16:00.676 --> 00:16:04.766
тим більша ймовірність того, що 
перехід до ери машинного інтеллекту

00:16:04.766 --> 00:16:06.306
пройде успішно.

00:16:06.306 --> 00:16:10.950
Як на мене, цим дійсно варто займатись,

00:16:10.950 --> 00:16:14.282
і можна уявити, що у випадку, 
якщо все пройде успішно,

00:16:14.282 --> 00:16:18.940
люди через мільйони років, 
споглядаючи в наше століття,

00:16:18.940 --> 00:16:22.942
можливо, вважатимуть, що 
єдина важлива річ, яку ми зробили,

00:16:22.942 --> 00:16:24.509
було створити цю річ правильно.

00:16:24.509 --> 00:16:26.198
Дякую.

00:16:26.198 --> 00:16:29.011
(Оплески)

