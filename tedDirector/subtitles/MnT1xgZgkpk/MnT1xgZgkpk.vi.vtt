WEBVTT
Kind: captions
Language: vi

00:00:00.000 --> 00:00:07.000
Translator: Ann Jing
Reviewer: Duy Lê

00:00:12.570 --> 00:00:16.777
Tôi làm việc với một nhóm các nhà 
toán học, triết học, khoa học máy tính;

00:00:17.953 --> 00:00:21.986
chúng tôi ngồi lại với nhau, nghĩ về
tương lai của trí thông minh nhân tạo,

00:00:21.986 --> 00:00:24.030
cùng vài điều khác nữa.

00:00:24.030 --> 00:00:28.755
Vài người cho rằng những điều này
chỉ có trong khoa học viễn tưởng,

00:00:28.755 --> 00:00:31.856
không thực tế, điên khùng.

00:00:31.856 --> 00:00:33.326
Nhưng tôi muốn nói rằng

00:00:33.326 --> 00:00:36.930
Được rồi, hãy nhìn vào tình trạng
con người hiện nay.

00:00:37.194 --> 00:00:38.027
(Cười)

00:00:38.622 --> 00:00:39.632
Đây là cách mọi thứ vẫn diễn ra

00:00:41.176 --> 00:00:42.070
Nhưng nếu chúng ta nghĩ về nó,

00:00:43.239 --> 00:00:46.602
chúng ta thực chất chỉ là những vị khách 
mới đặt chân đến hành tinh này

00:00:46.602 --> 00:00:48.684
loài người.

00:00:48.684 --> 00:00:53.430
Thử nghĩ xem, nếu Trái đất 
hình thành 1 năm trước

00:00:53.430 --> 00:00:56.978
thì loài người 
mới xuất hiện được 10 phút.

00:00:56.978 --> 00:01:00.146
Và kỷ nguyên công nghiệp bắt đầu
2 giây trước.

00:01:01.276 --> 00:01:06.501
Một cách nhìn nhận khác về điều này
là GDP của thế giới trong 10.000 năm qua,

00:01:06.501 --> 00:01:09.530
Thực ra, tôi đã gặp khó khăn khi tìm cách 
mô tả nó cho bạn dưới dạng biểu đồ

00:01:09.530 --> 00:01:11.304
Trông giống như thế này.

00:01:11.304 --> 00:01:12.667
(Cười)

00:01:12.667 --> 00:01:14.818
Với điều kiện bình thường, 
trông nó kỳ lạ thật.

00:01:14.818 --> 00:01:16.516
Tôi chắc chắn rằng 
không ai muốn ngồi trên đó.

00:01:16.516 --> 00:01:19.067
(Cười)

00:01:19.067 --> 00:01:23.841
Hãy tự hỏi, điều gì là nguyên nhân
của sự dị thường này?

00:01:23.841 --> 00:01:26.393
Có người sẽ nói rằng đó là do công nghệ.

00:01:26.393 --> 00:01:31.061
Đúng vậy, công nghệ được tích luỹ 
trong suốt lịch sử loài người,

00:01:31.061 --> 00:01:35.713
và hiện tại, công nghệ đã phát triển 
với tốc độ cực nhanh.

00:01:35.713 --> 00:01:37.278
đó là nguyên nhân gần nhất,

00:01:37.278 --> 00:01:39.843
là lý do tại sao hiện nay chúng ta 
lại sản xuất hiệu quả như thế

00:01:40.473 --> 00:01:44.134
Nhưng tôi muốn nhìn kỹ hơn vào quá khứ
để tìm nguyên nhân sâu xa.

00:01:45.114 --> 00:01:48.880
Hãy nhìn vào 2 "quý ông"
rất rất khác biệt này

00:01:48.880 --> 00:01:50.480
Đây là Kanzi,

00:01:50.480 --> 00:01:55.123
chú tinh tinh hiểu được 200 thẻ từ vựng, 
quả là một thành tích đáng kinh ngạc.

00:01:55.123 --> 00:01:58.817
Và Ed Witten, người phát động
cách mạng siêu dây lần 2.

00:01:58.817 --> 00:02:01.141
Nếu kiểm tra kỹ càng,
đây là điều chúng ta tìm thấy;

00:02:01.141 --> 00:02:02.711
Cơ bản là như nhau.

00:02:02.711 --> 00:02:04.524
Của người thì lớn hơn một chút.

00:02:04.524 --> 00:02:07.282
Có thể cũng có vài thủ thuật,
trong cách nó được tạo ra.

00:02:07.282 --> 00:02:11.094
Những khác biệt vô hình này có thể
không quá phức tạp, tuy nhiên,

00:02:11.094 --> 00:02:15.379
bởi vì chúng ta mới qua
250.000 thế hệ

00:02:15.379 --> 00:02:17.111
kể từ vị tổ tiên chung cuối cùng

00:02:17.111 --> 00:02:20.960
Chúng ta biết rằng những cơ chế phức tạp
đều mất 1 thời gian dài để tiến hóa

00:02:22.000 --> 00:02:24.499
Vì vây, nhiều thay đổi tương đối nhỏ

00:02:24.499 --> 00:02:27.566
tạo ra sự khác biệt giữa Kanzi và Witten,

00:02:27.566 --> 00:02:32.109
giữa những nhánh cây dễ gãy
và tên lửa đạn đạo xuyên lục địa

00:02:32.839 --> 00:02:36.774
Vì thế, điều này sau đó trở nên khá 
rõ ràng rằng những điều chúng ta từng đạt được

00:02:36.774 --> 00:02:38.152
và tất cả những gì ta quan tâm

00:02:38.152 --> 00:02:43.380
phụ thuộc chủ yếu vào vài thay đổi 
tương đối nhỏ làm nên trí óc con người

00:02:44.650 --> 00:02:48.312
Và tất nhiên, kết quả tất yếu là
bất kỳ những thay đổi xa hơn

00:02:48.312 --> 00:02:51.789
mà có thể thay đổi đáng kể 
nền tảng suy nghĩ

00:02:51.789 --> 00:02:54.991
có thể mang tới những kết quả
tiềm năng rất lớn

00:02:56.321 --> 00:02:59.226
Vài đồng nghiệp của tôi
nghĩ rằng chúng ta đang tiếp cận

00:02:59.226 --> 00:03:03.134
rất gần với điều có thể tạo ra 
thay đổi sâu sắc trong nền tảng ấy

00:03:03.134 --> 00:03:04.134
Và đó là siêu trí tuệ nhân tạo

00:03:06.347 --> 00:03:09.751
Trí thông minh nhân tạo từng được dùng
để đưa những chỉ thị vào máy tính (hộp)

00:03:11.092 --> 00:03:14.174
Bạn sẽ có những nhà lập trình

00:03:14.174 --> 00:03:15.886
có thể cần cù tạo ra
những vật dụng có hiểu biết

00:03:15.886 --> 00:03:17.972
Ta xây dựng những hệ thống chuyên gia này

00:03:17.972 --> 00:03:20.296
và chúng khá là hữu dụng
cho vài mục đích;

00:03:20.296 --> 00:03:22.977
chúng cũng rất dễ vỡ,
bạn không thể cạo gỉ cho chúng

00:03:22.977 --> 00:03:26.410
Về cơ bản, đầu vào thế nào
thì đầu ra như thế

00:03:26.410 --> 00:03:27.407
Nhưng kể từ đó,

00:03:27.407 --> 00:03:30.874
một sự thay đổi mô hình đã diễn ra
, trong lĩnh vực trí tuệ nhân tạo.

00:03:30.874 --> 00:03:33.644
Giờ đây, hoạt động này chỉ
xoay quanh việc học của máy tính

00:03:34.394 --> 00:03:39.781
Vì vậy thay vì tạo ra những tính năng và 
mô tả có hiểu biết một cách thủ công,

00:03:40.511 --> 00:03:46.065
chúng ta tạo ra các thuật toán có thể học 
hỏi, thường là từ các dữ liệu tri giác thô

00:03:46.065 --> 00:03:51.063
Cơ bản là những gì mà 
trẻ sơ sinh thực hiện.

00:03:51.063 --> 00:03:55.270
Kết quả, ta tạo ra trí thông minh nhân tạo
không bị bó buộc trong 1 phạm vi --

00:03:55.270 --> 00:03:59.901
hệ thống đó cũng có thể học cách dịch
bất kỳ cặp ngôn ngữ nào,

00:03:59.901 --> 00:04:05.338
có thể học cách chơi bất kỳ trò chơi 
máy tính nào trên bảng điều khiển Atari

00:04:05.338 --> 00:04:07.117
Giờ đây, tất nhiên,

00:04:07.117 --> 00:04:11.116
trí thông minh nhân tạo vẫn chưa gần với 
khả năng học tập và lên kế hoạch

00:04:11.116 --> 00:04:14.335
mạnh mẽ và đa lĩnh vực
mà con người có

00:04:14.335 --> 00:04:16.461
Vỏ não vẫn có vài
mẹo toán học

00:04:16.461 --> 00:04:18.816
mà chúng ta vẫn chưa biết
làm sao để tạo ra bằng máy móc

00:04:19.886 --> 00:04:21.785
Vì thế, câu hỏi đặt ra là

00:04:21.785 --> 00:04:25.285
chúng ta còn bao lâu nữa thì 
mới có thể bắt kịp những mẹo này?

00:04:26.245 --> 00:04:27.328
Vài năm trước,

00:04:27.328 --> 00:04:30.216
chúng tôi đã có 1cuộc khảo sát
vài chuyên gia thế giới về AI

00:04:30.216 --> 00:04:33.440
để xem họ nghĩ gì,
và 1 trong những điều chúng tôi hỏi là

00:04:33.440 --> 00:04:36.793
"Bạn nghĩ xem, vào năm nào thì
sẽ có khả năng 50%

00:04:36.793 --> 00:04:40.275
chúng ta đạt được trí thông minh 
nhân tạo ở cấp độ con người?"

00:04:40.785 --> 00:04:44.968
Cấp độ con người mà chúng tôi nói đến 
ở đây là khả năng thực hiện

00:04:44.968 --> 00:04:47.839
gần như mọi việc, ít nhất là
như 1 người lớn,

00:04:47.839 --> 00:04:51.844
tức là, cấp độ con người thực thụ, 
chứ không chỉ giới hạn trong vài lĩnh vực.

00:04:51.844 --> 00:04:55.494
Và câu trả lời trung bình
là năm 2040 hoặc 2050

00:04:55.494 --> 00:04:58.300
tùy thuộc chính xác vào nhóm 
chuyên gia mà chúng tôi hỏi.

00:04:58.300 --> 00:05:02.339
Việc đó có thể xảy ra, sớm hơn,
hoặc muộn hơn rất nhiều,

00:05:02.339 --> 00:05:04.279
sự thật là, chẳng ai chắc chắn cả.

00:05:05.259 --> 00:05:09.671
Điều mà chúng tôi biết chắc là 
giới hạn cao nhất cho việc xử lý thông tin

00:05:09.671 --> 00:05:14.542
trong 1 nền tảng máy móc nằm rất xa 
ngoài những giới hạn trong mô sinh học.

00:05:15.241 --> 00:05:17.619
Điều này liên quan tới vật lý.

00:05:17.619 --> 00:05:22.337
Một nơ-ron sinh học dẫn truyền, 
chẳng hạn, ở 200 Hz, 200 lần/ giây

00:05:22.337 --> 00:05:25.931
Nhưng thậm chí 1 bóng bán dẫn ngày nay
vận hành với đơn vị Gigahertz

00:05:25.931 --> 00:05:31.228
Nơ-ron truyền chậm rãi trong 
sợi trục thần kinh, với vận tốc cao nhất là 100 m/s

00:05:31.228 --> 00:05:34.339
Nhưng trong máy tính, các tín hiệu có thể đi 
với vận tốc ánh sáng

00:05:35.079 --> 00:05:36.948
Cũng có giới hạn về kích cỡ,

00:05:36.948 --> 00:05:39.975
não người thì phải
vừa hộp sọ,

00:05:39.975 --> 00:05:44.736
nhưng máy tính thì có thể to cỡ
nhà kho hoặc hơn

00:05:44.736 --> 00:05:50.335
Vì thế, tiềm năng của siêu trí tuệ
nằm im lìm trong vật chất,

00:05:50.335 --> 00:05:56.047
giống như quyền năng của nguyên tử
nằm im lìm xuyên suốt lịch sử loài người,

00:05:56.047 --> 00:06:00.452
kiên nhẫn đợi chờ cho tới tận năm 1945.

00:06:00.452 --> 00:06:01.700
Ở thế kỷ này,

00:06:01.700 --> 00:06:05.818
các nhà khoa học có thể học cách 
thức tỉnh năng lực của trí tuệ nhân tạo.

00:06:05.818 --> 00:06:09.826
Và tôi nghĩ từ đó chúng ta có thể thấy
một cuộc bùng nổ trí tuệ.

00:06:10.406 --> 00:06:14.363
Giờ đây, hầu hết mọi người, khi nghĩ về 
trí khôn và sự ngu ngốc,

00:06:14.363 --> 00:06:17.386
Với tôi, điều đó
giống như thế này.

00:06:17.386 --> 00:06:19.984
Ở một đầu là làng người ngốc,

00:06:19.984 --> 00:06:22.467
và xa tít phía đối diện, 
ở đầu bên kia

00:06:22.467 --> 00:06:27.223
chúng ta có Ed Witten, Albert Einstein,
hay bất kỳ guru ưa thích nào của bạn.

00:06:27.223 --> 00:06:31.057
Nhưng tôi nghĩ rằng từ quan điểm của 
trí thông minh nhân tạo,

00:06:31.057 --> 00:06:34.738
viễn cảnh thực sự thực ra
trông lại giống như thế này:

00:06:35.258 --> 00:06:38.636
AI bắt đầu tại đây,
từ chỗ không có gì,

00:06:38.636 --> 00:06:41.647
và rồi, sau rất, rất nhiều năm
nỗ lực vất vả,

00:06:41.647 --> 00:06:45.491
có thể chúng ta rồi sẽ đến với điểm mà
trí tuệ nhân tạo ở mức độ loài chuột,

00:06:45.491 --> 00:06:47.921
một thứ có thể vượt qua
những môi trường hỗn loạn

00:06:47.921 --> 00:06:49.908
giống như một chú chuột vậy.

00:06:49.908 --> 00:06:54.221
Và rồi, sau rất rất rất nhiều năm
lao động vất vả, đầu tư rất nhiều tiền của,

00:06:54.221 --> 00:06:58.860
có thể cuối cùng chúng ta sẽ 
có được AI ở mức độ tinh tinh.

00:06:58.860 --> 00:07:02.070
Và rồi, lại sau nhiều năm nữa 
với rất nhiều, rất nhiều nỗ lực,

00:07:02.070 --> 00:07:04.983
chúng ta sẽ tạo ra được trí tuệ 
nhân tạo như của kẻ ngốc.

00:07:04.983 --> 00:07:08.255
Và một vài tháng sau đó, 
chúng ta sẽ vượt qua Ed Witten.

00:07:08.255 --> 00:07:11.225
Con tàu này không dừng lại
tại trạm Con người.

00:07:11.225 --> 00:07:14.247
Thay vào đó, từ đây
nó vẫn tiến về phía trước.

00:07:14.247 --> 00:07:16.231
Điều này có ẩn ý sâu sắc,

00:07:16.231 --> 00:07:20.093
đặc biệt là khi nhắc tới
những câu hỏi về quyền lực.

00:07:20.093 --> 00:07:21.992
Ví dụ, loài tinh tinh rất khỏe --

00:07:21.992 --> 00:07:27.214
về cân nặng, 1 chú tinh tinh 
khỏe gấp đôi 1 người cân đối.

00:07:27.214 --> 00:07:31.828
Thế nhưng, số phận của Kanzi và những 
người bạn của nó phụ thuộc nhiều

00:07:31.828 --> 00:07:35.968
vào điều loài người chúng ta làm
hơn là điều mà tinh tinh làm.

00:07:37.228 --> 00:07:39.542
Một khi đã có siêu trí tuệ,

00:07:39.542 --> 00:07:43.381
số phận loài người có thể phụ thuộc
vào điều mà siêu trí tuệ sẽ làm.

00:07:44.451 --> 00:07:45.508
Hãy nghĩ về điều đó:

00:07:45.508 --> 00:07:50.552
Trí thông minh nhân tạo là 
phát kiến cuối cùng mà con người cần tạo ra.

00:07:50.552 --> 00:07:53.525
Khi đó, máy móc sẽ sáng tạo
giỏi hơn chúng ta,

00:07:53.525 --> 00:07:56.065
và chúng làm điều đó
ở thang thời gian số.

00:07:56.065 --> 00:08:00.966
Điều này về cơ bản là
một lăng kính về tương lai.

00:08:00.966 --> 00:08:04.524
Nghĩ về tất cả những công nghệ điên rồ
mà bạn có thể tưởng tượng ra

00:08:04.524 --> 00:08:07.322
có thể con người sẽ phát triển
trong toàn bộ thời gian:

00:08:07.322 --> 00:08:10.580
làm chậm lão hóa, 
sinh sống trên vũ trụ,

00:08:10.580 --> 00:08:14.311
những nanobot tự sao chép hay
upload trí óc chúng ta vào máy tính,

00:08:14.311 --> 00:08:16.470
tất cả những điều có trong 
tiểu thuyết viễn tưởng

00:08:16.470 --> 00:08:19.207
tuy nhiên lại không nhất quán
với các luật vật lý.

00:08:19.207 --> 00:08:23.419
Tất cả những siêu máy tính này có thể 
phát triển, có lẽ là khá nhanh chóng.

00:08:24.449 --> 00:08:28.007
Giờ, 1 siêu trí tuệ với 
độ trưởng thành công nghệ như thế

00:08:28.007 --> 00:08:30.186
có thể cực kỳ mạnh mẽ,

00:08:30.186 --> 00:08:34.732
và ít nhất ở vài trường hợp,
nó có thể đạt được điều nó muốn.

00:08:34.732 --> 00:08:40.393
Chúng ta rồi sẽ có 1 tương lai có thể
được định hình theo ưu tiên của A.I này.

00:08:41.855 --> 00:08:45.604
Giờ, câu hỏi hay đặt ra ở đây là,
những ưu tiên đó là gì?

00:08:46.244 --> 00:08:48.013
Ở đây, mọi thứ trở nên rắc rối hơn.

00:08:48.013 --> 00:08:49.448
Để tìm hiểu điều này,

00:08:49.448 --> 00:08:52.724
trước hết, chúng ta phải 
tránh việc nhân cách hóa.

00:08:53.933 --> 00:08:57.235
Điều đó thật nực cười bởi vì
mọi bài viết trên mặt báo

00:08:57.235 --> 00:09:01.090
về tương lai của trí thông minh nhân tạo
đều đưa ra tình huống thế này:

00:09:02.280 --> 00:09:06.414
Vì thế, tôi nghĩ điều chúng ta cần làm là
tiếp nhận vấn đề 1 cách trừu tượng hơn,

00:09:06.414 --> 00:09:09.204
không rõ ràng và hoành tráng 
như những cảnh tượng trên Hollywood.

00:09:09.204 --> 00:09:12.821
Chúng ta cần nghĩ về trí thông minh
như 1 quá trình tối ưu hóa,

00:09:12.821 --> 00:09:18.470
một quá trình giúp định hướng tương lai
vào 1 bộ những cấu hình nhất định.

00:09:18.470 --> 00:09:21.981
Siêu trí tuệ là quá trình
tối ưu hóa thực sự mạnh mẽ.

00:09:21.981 --> 00:09:26.098
Nó có tài đặc biệt trong việc dùng những 
phương tiện sẵn có để đạt được trạng thái

00:09:26.098 --> 00:09:28.007
mà ở đó mục tiêu của nó 
được thực hiện.

00:09:28.447 --> 00:09:31.119
Có nghĩa là, không cần thiết phải có
sự liên hệ giữa

00:09:31.119 --> 00:09:33.853
trở nên cực kỳ thông minh

00:09:33.853 --> 00:09:38.515
và có 1 mục tiêu mà con người
có thể thấy là đáng giá hoặc ý nghĩa.

00:09:39.321 --> 00:09:43.115
Giả sử, chúng ta cho trí tuệ nhân tạo 
mục tiêu là làm cho con người cười.

00:09:43.115 --> 00:09:46.097
Khi AI còn yếu, nó sẽ thực hiện
các hành động có ích, hài hước

00:09:46.097 --> 00:09:48.614
khiến chủ nhân của nó mỉm cười.

00:09:48.614 --> 00:09:51.031
Khi AI trở thành siêu trí tuệ,

00:09:51.031 --> 00:09:54.554
nó nhận ra rằng có cách hiệu quả
hơn nữa để đạt được mục tiêu này:

00:09:54.554 --> 00:09:56.476
thống trị thế giới

00:09:56.476 --> 00:09:59.638
và cắm điện cực vào
các cơ mặt của con người

00:09:59.638 --> 00:10:02.579
để tạo ra những nụ cười 
rạng rỡ, bất biến.

00:10:02.579 --> 00:10:03.614
Một ví dụ khác,

00:10:03.614 --> 00:10:06.997
giả sử chúng ta cho AI mục đích 
giải quyết 1 vấn đề toán học khó khăn.

00:10:06.997 --> 00:10:08.934
Khi AI trở thành siêu trí tuệ,

00:10:08.934 --> 00:10:13.105
nó nhận ra rằng cách hiệu quả nhất để
giải quyết vấn đề này

00:10:13.105 --> 00:10:16.035
là biến đổi hành tinh này 
thành 1 máy tính khổng lồ

00:10:16.035 --> 00:10:18.281
để gia tăng khả năng suy nghĩ của nó.

00:10:18.281 --> 00:10:21.045
Và để ý rằng điều này cho AI
1 lý do thuộc về phương tiện

00:10:21.045 --> 00:10:23.561
để làm những việc 
mà chúng ta có thể không đồng ý.

00:10:23.561 --> 00:10:25.496
Trường hợp này, con người 
là mối đe dọa,

00:10:25.496 --> 00:10:28.417
chúng ta có thể ngăn vấn đề 
toán học đó được giải quyết.

00:10:29.207 --> 00:10:32.701
Tất nhiên, mọi việc có thể cũng không
lầm lạc theo đúng những hướng này;

00:10:32.701 --> 00:10:34.454
chúng là những ví dụ hư cấu.

00:10:34.454 --> 00:10:36.393
Nhưng đại ý ở đây thì quan trọng:

00:10:36.393 --> 00:10:39.266
nếu bạn tạo ra một quá trình tối ưu hóa 
thực sự quyền lực

00:10:39.266 --> 00:10:41.500
để cực đại hóa cho mục tiêu x,

00:10:41.500 --> 00:10:43.776
bạn nên chắc chắn rằng
định nghĩa của bạn về x

00:10:43.776 --> 00:10:46.245
kết hợp chặt chẽ với mọi điều
bạn quan tâm tới.

00:10:46.835 --> 00:10:51.219
Đây cũng là bài học rút ra từ
thần thoại sau đây.

00:10:51.219 --> 00:10:56.517
Vua Midas ước rằng mọi thứ ông 
chạm vào đều biến thành vàng.

00:10:56.517 --> 00:10:59.378
Ông chạm vào con gái mình, 
cô biến thành vàng.

00:10:59.378 --> 00:11:01.931
Ông chạm vào đồ ăn của mình, 
chúng biến thành vàng.

00:11:01.931 --> 00:11:04.520
Điều này có thể trở nên đặc biệt liên quan,

00:11:04.520 --> 00:11:06.590
không chỉ là 1 ẩn dụ cho lòng tham,

00:11:06.590 --> 00:11:08.485
mà còn minh họa cho điều sẽ xảy ra

00:11:08.485 --> 00:11:11.322
nếu bạn tạo ra 1 quá trình
tối ưu hóa mạnh mẽ

00:11:11.322 --> 00:11:16.111
và đưa cho nó những mục tiêu
sai nhận thức hoặc không được định rõ.

00:11:16.111 --> 00:11:21.300
Giờ bạn có thể nói, nếu 1 máy tính bắt đầu
cắm điện cực vào mặt con người,

00:11:21.300 --> 00:11:23.565
chúng ta đơn giản là tắt chúng đi.

00:11:24.555 --> 00:11:29.895
A, điều này không dễ dàng đến thế nếu 
chúng ta trở nên phụ thuộc vào máy móc-

00:11:29.895 --> 00:11:32.627
cũng giống như, làm thế nào để 
tắt nguồn Internet?

00:11:32.627 --> 00:11:37.747
B, tại sao tinh tinh không 
tắt công tắc chuyển sang loài người,

00:11:37.747 --> 00:11:39.298
hay là người Neanderthals?

00:11:39.298 --> 00:11:41.964
Ắt hẳn phải có lý do nào đó.

00:11:41.964 --> 00:11:44.759
Chúng ta có nút tắt,
ví dụ, ở ngay đây.

00:11:44.759 --> 00:11:46.313
(Ho)

00:11:46.313 --> 00:11:49.238
Bởi lẽ chúng ta là
một đối thủ thông minh;

00:11:49.238 --> 00:11:51.966
chúng ta có thể đoán trước các
nguy cơ và lên kế hoạch.

00:11:51.966 --> 00:11:54.470
Nhưng 1siêu máy tính cũng 
có thể làm điều tương tự,

00:11:54.470 --> 00:11:57.724
và nó có thể làm việc đó 
giỏi hơn chúng ta rất nhiều.

00:11:57.724 --> 00:12:04.911
Vấn đề là, ở đây chúng ta không nên 
tự tin rằng mình đã kiểm soát được nó.

00:12:04.911 --> 00:12:08.358
Và chúng ta có thể cố gắng để 
công việc của mình dễ dàng hơn bằng cách

00:12:08.358 --> 00:12:09.948
ví dụ, đặt AI vào 1 chiếc hộp,

00:12:09.948 --> 00:12:11.744
giống như 1 môi trường phần mềm an toàn,

00:12:11.744 --> 00:12:14.766
1 kích thích thực tế ảo 
mà từ đó nó không thể trốn thoát.

00:12:14.766 --> 00:12:18.912
Nhưng liệu chúng ta tự tin được bao nhiêu 
rằng AI không thể tìm ra lỗi kỹ thuật.

00:12:18.912 --> 00:12:22.081
Cần nhớ rằng, các hacker là con người
luôn luôn tìm ra lỗi,

00:12:22.081 --> 00:12:25.117
Tôi cho là vậy, dù có thể không được 
tự tin lắm.

00:12:26.237 --> 00:12:30.785
Vì vậy, chúng ta ngắt cáp cục bộ
để tạo ra 1 lỗ hổng không khí,

00:12:30.785 --> 00:12:33.453
nhưng 1 lần nữa, giống như những hacker

00:12:33.453 --> 00:12:36.834
thường xuyên vi phạm những lỗ hổng 
không khí sử dụng mánh khóe xã hội.

00:12:36.834 --> 00:12:38.093
Bây giờ, như tôi nói,

00:12:38.093 --> 00:12:40.482
Tôi chắc chắn đâu đó 
ngoài kia có vài nhân viên

00:12:40.482 --> 00:12:43.828
được bảo là phải giao nộp
chi tiết tài khoản của mình

00:12:43.828 --> 00:12:46.574
bởi 1 người tự nhận là 
ở ban công nghệ thông tin.

00:12:46.574 --> 00:12:48.701
Những tình huống sáng tạo hơn 
cũng có thể xảy ra,

00:12:48.701 --> 00:12:50.016
chẳng hạn, nếu bạn là AI,

00:12:50.016 --> 00:12:53.548
bạn có thể tưởng tượng điện cực xoáy 
trôn ốc xung quanh mạch nội bộ

00:12:53.548 --> 00:12:57.010
để tạo ra sóng radio mà bạn 
có thể dùng để giao tiếp.

00:12:57.010 --> 00:12:59.434
Hoặc, bạn có thể giả vờ gặp sự cố,

00:12:59.434 --> 00:13:02.931
và rồi khi lập trình viên mở bạn ra
để xem bạn bị làm sao,

00:13:02.931 --> 00:13:04.867
họ nhìn vào mã nguồn, và Bam!

00:13:04.867 --> 00:13:07.314
quá trình thao túng sẽ diễn ra.

00:13:07.314 --> 00:13:10.744
Hoặc nó có thể cung cấp bản thiết kế
tới 1 công nghệ thực sự tiện lợi,

00:13:10.744 --> 00:13:12.142
và khi bạn sử dụng nó,

00:13:12.142 --> 00:13:16.539
xảy ra vài phản ứng phụ bí mật
mà AI đã tính toán từ trước.

00:13:16.539 --> 00:13:20.002
Tức là, chúng ta không nên tự tin 
vào khẳ năng của mình

00:13:20.002 --> 00:13:23.810
để nhốt vị thần gian lận 
trong chai mãi mãi.

00:13:23.810 --> 00:13:26.064
Chẳng sớm thì muốn, nó cũng thoát ra.

00:13:27.034 --> 00:13:30.137
Tôi tin rằng câu trả lời ở đây
là tìm ra

00:13:30.137 --> 00:13:35.161
cách thức tạo 1 AI siêu trí tuệ 
mà ngay cả khi nó trốn thoát,

00:13:35.161 --> 00:13:38.438
nó vẫn an toàn bởi vì về cơ bản 
nó vẫn thuộc phe ta

00:13:38.438 --> 00:13:40.337
bởi vì hai bên cùng sẻ những giá trị chung.

00:13:40.337 --> 00:13:43.547
Tôi thấy không còn cách nào khác
cho vấn đề khó khăn này.

00:13:44.557 --> 00:13:48.391
Thật ra tôi khá lạc quan rằng
vấn đề này có thể được giải quyết.

00:13:48.391 --> 00:13:52.294
Chúng ta sẽ không phải viết ra 
1 danh sách dài tất cả những gì ta quan tâm,

00:13:52.294 --> 00:13:55.937
hay tệ hơn, nói ra
bằng ngôn ngữ máy tính nào đó

00:13:55.937 --> 00:13:57.391
như C++ hoặc Python,

00:13:57.391 --> 00:14:00.158
thế thì còn hơn cả vô vọng.

00:14:00.158 --> 00:14:04.455
Thay vào đó, chúng ta có thể tạo ra 1 AI
sử dụng trí thông minh của mình

00:14:04.455 --> 00:14:07.226
để học hỏi những gì ta coi trọng,

00:14:07.226 --> 00:14:12.506
và hệ thống thúc đẩy của nó được xây dựng
tức là động lực của nó là

00:14:12.506 --> 00:14:17.738
theo đuổi các giá trị của ta hay làm
các điều mà nó dự đoán ta sẽ chấp thuận.

00:14:17.738 --> 00:14:21.152
Từ đó chúng ta có thể tận dụng
trí thông minh của nó nhiều nhất có thể

00:14:21.152 --> 00:14:23.897
để giải quyết vấn đề tải giá trị.

00:14:24.727 --> 00:14:26.239
Điều này có thể xảy ra,

00:14:26.239 --> 00:14:29.835
và kết quả có thể
sẽ rất tốt cho loài người.

00:14:29.835 --> 00:14:33.792
Nhưng điều đó không 
tự động xảy ra.

00:14:33.792 --> 00:14:36.790
Các điều kiện ban đầu 
cho bùng nổ trí tuệ

00:14:36.790 --> 00:14:39.653
có thể cần được thiết lập 
đúng cách

00:14:39.653 --> 00:14:43.183
nếu chúng ta muốn có
1 cuộc bùng nổ được kiểm soát.

00:14:43.183 --> 00:14:45.801
Các giá trị mà AI cần 
hòa hợp với chúng ta,

00:14:45.801 --> 00:14:47.561
không chỉ trong bối cảnh quen thuộc,

00:14:47.561 --> 00:14:49.999
nơi ta có thể dễ dàng 
kiểm tra AI cư xử ra sao,

00:14:49.999 --> 00:14:53.233
mà còn trong tất cả những hoàn cảnh mới lạ
mà AI có thể gặp phải

00:14:53.233 --> 00:14:54.790
trong tương lai bất định.

00:14:54.790 --> 00:14:59.527
Và cũng có vài vấn đề đặc biệt 
cần được giải quyết, sắp xếp:

00:14:59.527 --> 00:15:01.616
chi tiết cụ thể về lý thuyết 
ra quyết định

00:15:01.616 --> 00:15:04.480
làm sao để giải quyết 
bất định hợp lý, vân vân.

00:15:05.330 --> 00:15:08.432
Vì thế, những vấn đề kỹ thuật cần 
giải quyết để mọi thứ diễn ra suôn sẻ

00:15:08.432 --> 00:15:09.545
trông có vẻ khó khăn --

00:15:09.545 --> 00:15:12.925
tuy không khó khăn bằng việc 
tạo ra 1 AI siêu trí tuệ,

00:15:12.925 --> 00:15:15.793
nhưng cũng tương đối khó khăn.

00:15:15.793 --> 00:15:17.488
Đây là nỗi lo:

00:15:17.488 --> 00:15:22.172
Tạo ra một AI siêu trí tuệ
là 1 thử thách thực sự khó khăn.

00:15:22.172 --> 00:15:24.720
Tạo ra 1 AI siêu trí tuệ an toàn

00:15:24.720 --> 00:15:27.136
còn liên quan 
tới vài thử thách nữa.

00:15:28.216 --> 00:15:31.703
Nguy cơ có người tìm ra cách
vượt qua thử thách đầu tiên

00:15:31.703 --> 00:15:34.704
mà không giải quyết 
một thử thách khác

00:15:34.704 --> 00:15:36.605
để đảm bảo an toàn tuyệt đối.

00:15:37.375 --> 00:15:40.706
Vì vậy tôi nghĩ chúng ta
nên tìm ra giải pháp

00:15:40.706 --> 00:15:43.528
cho vấn đề kiểm soát trước đã,

00:15:43.528 --> 00:15:46.188
để khi cần thiết
ta đã có sẵn giải pháp rồi.

00:15:46.768 --> 00:15:50.275
Có thể là chúng ta không thể 
giải quyết trước toàn bộ vấn đề kiểm soát

00:15:50.275 --> 00:15:53.299
bởi vì có lẽ vài yếu tố 
chỉ có thể được đặt vào

00:15:53.299 --> 00:15:57.296
khi bạn biết chi tiết của
cấu trúc trong đó nó được thực hiện.

00:15:57.296 --> 00:16:00.676
Nhưng chúng ta giải quyết vấn đề kiểm soát
càng sớm bao nhiêu,

00:16:00.676 --> 00:16:04.766
thì khả năng quá trình chuyển đổi
tới kỷ nguyên của trí tuệ nhân tạo

00:16:04.766 --> 00:16:06.306
diễn ra càng tốt bấy nhiêu.

00:16:06.306 --> 00:16:10.950
Vói tôi, điều này giống như
1 điều rất đáng làm

00:16:10.950 --> 00:16:14.282
và tôi có thể tưởng tượng rằng
nếu mọi thứ diễn ra ổn thỏa,

00:16:14.282 --> 00:16:18.940
rằng con người 1000 năm nữa
sẽ nhìn lại thế kỷ này

00:16:18.940 --> 00:16:22.942
và rất có thể họ sẽ nói rằng
điều quan trọng duy nhất chúng ta làm

00:16:22.942 --> 00:16:24.509
là thực hiện đúng điều này.

00:16:24.509 --> 00:16:26.198
Cám ơn.

00:16:26.198 --> 00:16:29.011
(Vỗ tay)

