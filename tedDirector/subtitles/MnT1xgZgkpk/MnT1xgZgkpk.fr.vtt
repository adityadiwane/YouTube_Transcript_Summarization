WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: Vincent LECOANET
Relecteur: Elisabeth Buffard

00:00:12.570 --> 00:00:16.777
Je travaille avec des mathématiciens,
philosophes et informaticiens,

00:00:16.777 --> 00:00:21.986
et nous nous réunissons pour imaginer
le futur de l'intelligence artificielle,

00:00:21.986 --> 00:00:24.030
entre autres choses.

00:00:24.030 --> 00:00:28.755
Certains pensent que
c'est un peu de la science-fiction,

00:00:28.755 --> 00:00:31.856
complètement éloigné du réel.

00:00:31.856 --> 00:00:33.326
Mais j'aime dire,

00:00:33.326 --> 00:00:36.930
d'accord, jetons un coup d'oeil
à la condition humaine moderne.

00:00:36.930 --> 00:00:38.622
(Rires)

00:00:38.622 --> 00:00:41.024
C'est la façon normale d'être des choses.

00:00:41.024 --> 00:00:43.309
Mais si on y pense,

00:00:43.309 --> 00:00:46.832
nous ne sommes en fait que des invités
récemment arrivés sur cette planète,

00:00:46.832 --> 00:00:48.684
l'espèce humaine.

00:00:48.684 --> 00:00:53.430
Imaginez si la Terre 
avait été créée il y a un an,

00:00:53.430 --> 00:00:56.978
l'espèce humaine existerait alors
depuis dix minutes.

00:00:56.978 --> 00:01:00.146
L'ère industrielle a débuté
il y a deux secondes.

00:01:01.276 --> 00:01:03.501
Une autre façon de voir est de calculer

00:01:03.501 --> 00:01:06.501
le PIB mondial
des 10 000 dernières années.

00:01:06.501 --> 00:01:09.530
J'ai vraiment pris le temps
de faire un graphe pour vous.

00:01:09.530 --> 00:01:11.304
Il ressemble à ça.

00:01:11.304 --> 00:01:12.557
(Rires)

00:01:12.557 --> 00:01:14.698
Drôle de courbe
pour une condition normale.

00:01:14.698 --> 00:01:16.516
Je ne voudrais pas lui tourner le dos.

00:01:16.516 --> 00:01:19.067
(Rires)

00:01:19.067 --> 00:01:23.841
Demandons-nous, quelle est la cause
de cette anomalie ?

00:01:23.851 --> 00:01:26.393
Certains diront que c'est la technologie.

00:01:26.393 --> 00:01:31.061
C'est vrai, la technologie s'est accumulée
au cours de l'histoire humaine,

00:01:31.061 --> 00:01:35.713
et aujourd'hui, la technologie
progresse très rapidement --

00:01:35.713 --> 00:01:37.278
c'est la cause la plus proche,

00:01:37.278 --> 00:01:39.843
c'est pourquoi nous sommes
si productifs de nos jours.

00:01:40.473 --> 00:01:44.134
Mais je préfère réfléchir en remontant 
à la cause fondamentale.

00:01:45.114 --> 00:01:48.880
Regardez ces deux messieurs
très distingués :

00:01:48.880 --> 00:01:50.480
Nous avons Kanzi --

00:01:50.480 --> 00:01:55.123
il maîtrise 200 symboles lexicaux,
un exploit incroyable.

00:01:55.123 --> 00:01:58.557
Et Ed Witten a déclenché
la seconde révolution des supercordes.

00:01:58.557 --> 00:02:01.411
Si nous regardons sous la capuche,
voici ce que l'on trouve :

00:02:01.411 --> 00:02:02.711
en gros, la même chose.

00:02:02.711 --> 00:02:04.524
L'un est un peu plus grand,

00:02:04.524 --> 00:02:07.282
il y a peut-être aussi quelques
subtilités de câblage.

00:02:07.282 --> 00:02:11.094
Ces différences invisibles ne peuvent
être trop compliquées quoi qu'il en soit,

00:02:11.094 --> 00:02:15.379
car il n'y a eu que
250 000 générations

00:02:15.379 --> 00:02:17.121
depuis notre dernier ancêtre commun.

00:02:17.121 --> 00:02:21.030
Nous savons que les mécanismes compliqués
demandent beaucoup de temps pour évoluer.

00:02:22.000 --> 00:02:24.499
Donc des changements relativement mineurs

00:02:24.499 --> 00:02:27.566
nous emmènent de Kanzi à Witten,

00:02:27.566 --> 00:02:32.109
de branches arrachées aux arbres aux
missiles balistiques intercontinentaux.

00:02:32.839 --> 00:02:36.774
Il semble alors assez évident
que tout ce que nous avons réalisé,

00:02:36.774 --> 00:02:38.152
et ce que nous chérissons,

00:02:38.152 --> 00:02:41.650
dépend principalement de quelques
changements mineurs

00:02:41.650 --> 00:02:44.650
qui ont aboutit à l'esprit humain.

00:02:44.650 --> 00:02:48.312
Le corollaire, bien sûr,
est que tout changement à venir

00:02:48.312 --> 00:02:51.789
qui pourrait changer significativement
le substrat de la pensée

00:02:51.789 --> 00:02:54.991
pourrait avoir potentiellement
d'énormes conséquences.

00:02:56.181 --> 00:02:59.226
Certains de mes collègues
pensent que nous sommes sur le point

00:02:59.226 --> 00:03:03.134
de développer quelque chose qui pourrait
causer un tel changement dans ce substrat,

00:03:03.134 --> 00:03:06.347
et c'est la super
intelligence artificielle.

00:03:06.347 --> 00:03:11.086
Avant, l'intelligence artificielle consistait
à mettre des commandes dans une boîte.

00:03:11.086 --> 00:03:12.751
Il y avait des programmeurs humains

00:03:12.751 --> 00:03:15.886
qui fabriquaient minutieusement
des objets savants.

00:03:15.886 --> 00:03:17.972
On construisait ces systèmes experts,

00:03:17.972 --> 00:03:20.146
et ils étaient utiles
pour certains buts,

00:03:20.146 --> 00:03:23.097
mais ils étaient très fragiles,
on ne pouvait pas les agrandir.

00:03:23.097 --> 00:03:26.410
En gros, vous n'aviez que
ce que vous aviez mis dedans.

00:03:26.410 --> 00:03:27.407
Mais depuis,

00:03:27.407 --> 00:03:30.874
une révolution conceptuelle s'est opérée
dans le domaine de l'I.A..

00:03:30.874 --> 00:03:33.744
Aujourd'hui, l'action est centré sur
l'apprentissage machine.

00:03:34.394 --> 00:03:39.781
Plutôt que de coder à la main des
programmes et leurs caractéristiques,

00:03:40.511 --> 00:03:43.065
on crée des algorithmes qui apprennent,

00:03:43.065 --> 00:03:46.065
souvent à partir 
des données brutes perçues.

00:03:46.065 --> 00:03:51.063
En gros, la même chose que fait un enfant.

00:03:51.063 --> 00:03:55.270
Le résultat est une I.A.
qui n'est pas limitée à un domaine --

00:03:55.270 --> 00:03:59.901
le même système peut apprendre à traduire
n'importe quel couple de langues,

00:03:59.901 --> 00:04:05.338
ou apprendre à jouer n'importe quel jeu
sur la console Atari.

00:04:05.338 --> 00:04:07.117
Bien sûr,

00:04:07.117 --> 00:04:11.116
l'I.A. est toujours loin d'avoir
la capacité puissante et transversale

00:04:11.116 --> 00:04:14.335
à apprendre et planifier
d'un être humain.

00:04:14.335 --> 00:04:16.461
Le cortex a encore des
secrets algorithmiques

00:04:16.461 --> 00:04:18.816
que nous ne savons pas
intégrer dans les machines.

00:04:19.886 --> 00:04:21.785
Donc la question est,

00:04:21.785 --> 00:04:25.285
combien de temps nous faudra-t-il
pour réussir à les intégrer ?

00:04:26.125 --> 00:04:27.218
Il y a quelques années,

00:04:27.218 --> 00:04:30.216
nous avons fait un sondage
auprès des experts mondiaux des I.A.,

00:04:30.216 --> 00:04:33.440
pour voir ce qu'ils pensaient,
et une des questions posées était,

00:04:33.440 --> 00:04:36.793
« En quelle année pensez-vous 
qu'il y aura 50% de chance

00:04:36.793 --> 00:04:40.275
qu'une I.A. atteigne le niveau
d'une intelligence humaine ? »

00:04:40.785 --> 00:04:44.968
Nous définissons ici le seuil à atteindre
par la capacité de l'I.A. à réaliser

00:04:44.968 --> 00:04:47.839
presque toutes les tâches
au moins aussi bien qu'un adulte,

00:04:47.839 --> 00:04:51.844
donc réellement comme un humain,
pas seulement dans un domaine limité.

00:04:51.844 --> 00:04:55.494
La réponse médiane était 2040 ou 2050,

00:04:55.494 --> 00:04:58.300
en fonction du groupe d'experts
que nous interrogions.

00:04:58.300 --> 00:05:02.339
Ça pourrait se produire
bien plus tard ou bien plus tôt,

00:05:02.339 --> 00:05:04.279
la vérité est que personne ne le sait.

00:05:05.259 --> 00:05:09.671
Ce que nous savons est que la limite
de traitement de l'information

00:05:09.671 --> 00:05:14.542
dans une machine est bien supérieure
à celle d'un tissu biologique.

00:05:15.241 --> 00:05:17.619
Ça s'explique par la physique.

00:05:17.619 --> 00:05:22.337
Un neurone biologique "décharge" 
environ à 200 hertz, 200 fois par seconde.

00:05:22.337 --> 00:05:25.931
Mais, même un transistor actuel
fonctionne au gigahertz.

00:05:25.931 --> 00:05:31.228
L'information se propage dans les neurones
le long d'axones à 100 m/s maximum.

00:05:31.228 --> 00:05:34.839
Mais dans les ordinateurs, le signal
peut voyager à la vitesse de la lumière.

00:05:35.079 --> 00:05:36.948
Il y a aussi des limitations de taille,

00:05:36.948 --> 00:05:39.975
car le cerveau humain
doit rentrer dans la boîte crânienne,

00:05:39.975 --> 00:05:44.736
mais un ordinateur peut être 
de la taille d'un entrepôt ou plus grand.

00:05:44.736 --> 00:05:50.335
Donc le potentiel de super intelligence
est en sommeil dans la matière,

00:05:50.335 --> 00:05:56.047
tout comme la puissance de l'atome
est restée en sommeil

00:05:56.047 --> 00:06:00.452
tout au long de l'histoire humaine,
attendant patiemment jusqu'en 1945.

00:06:00.452 --> 00:06:03.620
Au cours de ce siècle, il se peut 
que les scientifiques apprennent

00:06:03.620 --> 00:06:05.818
à réveiller la puissance de l'I.A..

00:06:05.828 --> 00:06:09.826
Je pense que nous pourrions alors
assister à une explosion d'intelligence.

00:06:10.406 --> 00:06:14.363
La plupart des gens, quand ils pensent
à ce qui est bête ou intelligent

00:06:14.363 --> 00:06:17.386
ont une image de ce genre en tête.

00:06:17.386 --> 00:06:19.984
À une extrémité on a l'idiot du village,

00:06:19.984 --> 00:06:22.467
et à l'autre bout

00:06:22.467 --> 00:06:27.223
on a Ed Witten, ou Albert Einstein,
ou votre gourou, qui qu'il soit.

00:06:27.223 --> 00:06:31.057
Mais je pense que du point de vue
de l'intelligence artificielle,

00:06:31.057 --> 00:06:34.738
la véritable image est plus probablement
comme ceci, en réalité :

00:06:35.258 --> 00:06:38.636
l'I.A. commence à cet endroit,
à zéro intelligence,

00:06:38.636 --> 00:06:41.647
et ensuite, après de nombreuses
années de dur labeur,

00:06:41.647 --> 00:06:45.191
peut-être, arrivons-nous au niveau
de l'intelligence d'une souris,

00:06:45.191 --> 00:06:48.241
quelque chose qui peut naviguer
dans des environnements encombrés

00:06:48.241 --> 00:06:49.908
aussi bien qu'une souris.

00:06:49.908 --> 00:06:54.221
Ensuite, après encore plus d'années de
dur labeur et beaucoup d'investissements,

00:06:54.221 --> 00:06:58.800
peut-être, finalement, arrivons-nous
au niveau d'intelligence d'un chimpanzé.

00:06:58.800 --> 00:07:02.070
Ensuite, après toujours plus d'années
de vraiment très dur labeur,

00:07:02.070 --> 00:07:04.983
nous arrivons au niveau d'intelligence
de l'idiot du village.

00:07:04.983 --> 00:07:08.255
Et quelques mois plus tard,
nous sommes après Ed Witten.

00:07:08.255 --> 00:07:11.225
Le train ne s'arrête pas
à la station Humainville.

00:07:11.225 --> 00:07:14.247
Il va plutôt passer à fond devant.

00:07:14.247 --> 00:07:16.231
Il y a là de profondes implications,

00:07:16.231 --> 00:07:20.023
en particulier quand il est question
de pouvoir.

00:07:20.023 --> 00:07:21.992
Par exemple, les chimpanzés sont forts --

00:07:21.992 --> 00:07:27.214
à poids équivalent, un chimpanzé est
deux fois plus fort qu'un homme adulte.

00:07:27.214 --> 00:07:31.828
Pourtant, le destin de Kanzi
et de ses congénères dépend beaucoup plus

00:07:31.828 --> 00:07:35.968
de ce que font les humains que de ce que
les chimpanzés font eux-mêmes.

00:07:37.228 --> 00:07:39.542
Une fois que la super intelligence
sera là,

00:07:39.542 --> 00:07:43.431
le destin de l'humanité pourrait dépendre
des actions de cette super intelligence.

00:07:44.451 --> 00:07:45.508
Pensez-y :

00:07:45.508 --> 00:07:50.282
l'I.A. est la dernière invention que
l'homme aura jamais besoin de faire.

00:07:50.282 --> 00:07:53.545
Les machines seront alors de meilleurs
inventeurs que nous le sommes,

00:07:53.545 --> 00:07:56.295
et elles inventeront sur des échelles
de temps numériques.

00:07:56.295 --> 00:08:00.966
Ça veut dire un télescopage avec le futur.

00:08:00.966 --> 00:08:04.434
Pensez à toutes les technologies 
incroyables que vous avez imaginées,

00:08:04.434 --> 00:08:07.432
que les hommes pourraient
avoir développées avec le temps :

00:08:07.432 --> 00:08:10.530
plus de vieillissement,
colonisation de l'espace,

00:08:10.530 --> 00:08:11.530
nano-robots auto-répliquants,

00:08:11.530 --> 00:08:14.391
téléchargement d'esprits humains
dans des ordinateurs,

00:08:14.391 --> 00:08:16.470
plein de technologies de science-fiction

00:08:16.470 --> 00:08:19.247
qui sont néanmoins cohérentes
avec les lois de la physique.

00:08:19.247 --> 00:08:23.419
Toute cette super intelligence pourrait
se développer assez rapidement.

00:08:24.449 --> 00:08:28.007
Bon, une super intelligence avec
une telle maturité technologique

00:08:28.007 --> 00:08:30.186
serait extrêmement puissante,

00:08:30.186 --> 00:08:34.732
et au moins dans certains scénarios,
serait capable d'obtenir ce qu'elle veut.

00:08:34.732 --> 00:08:40.393
Nous aurions alors un futur modelé
par les préférences de cette I.A.

00:08:41.855 --> 00:08:45.604
Une bonne question est,
quelles sont ces préférences ?

00:08:46.244 --> 00:08:48.013
C'est là que ça devient délicat.

00:08:48.013 --> 00:08:49.448
Pour progresser là-dessus,

00:08:49.448 --> 00:08:52.724
nous devons tout d'abord
éviter tout anthropomorphisme.

00:08:53.934 --> 00:08:57.235
C'est ironique car dans tous
les articles de journaux

00:08:57.235 --> 00:09:01.090
qui parle de l'avenir de l'I.A.
comportent une image de ceci.

00:09:02.280 --> 00:09:06.414
Je pense que nous devons concevoir
ce problème de manière plus abstraite,

00:09:06.414 --> 00:09:09.204
et non en scénario hollywoodien fertile.

00:09:09.204 --> 00:09:12.821
Nous devons penser à l'intelligence
comme un processus d'optimisation,

00:09:12.821 --> 00:09:18.470
un processus qui guide le futur
dans un certain jeu de configurations.

00:09:18.470 --> 00:09:21.981
Une super intelligence est un
processus d'optimisation très fort.

00:09:21.981 --> 00:09:26.098
Elle est très douée pour utiliser les
moyens disponibles pour atteindre un état

00:09:26.098 --> 00:09:28.007
dans lequel son but est réalisé.

00:09:28.307 --> 00:09:31.119
Ça signifie qu'il n'y a pas
de nécessaire connexion entre

00:09:31.119 --> 00:09:33.853
le fait d'être très intelligent
dans ce sens,

00:09:33.853 --> 00:09:38.515
et avoir un objectif que nous, humains,
trouverions utile ou significatif.

00:09:39.321 --> 00:09:42.865
Supposons qu'on donne comme but
à une I.A. de faire sourire les humains.

00:09:42.865 --> 00:09:46.097
Quand l'I.A. est faible, elle réalise
des actions utiles ou amusantes

00:09:46.097 --> 00:09:48.614
qui provoque le sourire de l'utilisateur.

00:09:48.614 --> 00:09:51.031
Quand l'I.A. devient super intelligente,

00:09:51.031 --> 00:09:54.554
elle réalise qu'il y a un moyen
plus efficace d'atteindre son objectif :

00:09:54.554 --> 00:09:56.476
prendre le contrôle du monde

00:09:56.476 --> 00:09:59.638
et implanter des électrodes
dans les muscles faciaux des humains

00:09:59.638 --> 00:10:02.579
pour provoquer des sourires
rayonnants et constants.

00:10:02.579 --> 00:10:03.454
Un autre exemple,

00:10:03.454 --> 00:10:07.027
supposons qu'on demande à une I.A.
de résoudre un problème de math très dur.

00:10:07.027 --> 00:10:08.934
Quand l'I.A. devient super intelligente,

00:10:08.934 --> 00:10:13.105
elle réalise que le moyen le plus efficace
pour résoudre ce problème

00:10:13.105 --> 00:10:16.035
est de transformer la planète
en un ordinateur géant,

00:10:16.035 --> 00:10:18.281
pour augmenter sa capacité de calcul.

00:10:18.281 --> 00:10:20.945
Remarquez que ça donne aux I.A.s
une raison pratique

00:10:20.945 --> 00:10:23.561
de faire des choses
que nous pourrions ne pas approuver.

00:10:23.561 --> 00:10:25.606
Les humains sont des menaces
dans ce modèle,

00:10:25.606 --> 00:10:28.417
car nous pourrions empêcher
la résolution du problème.

00:10:29.207 --> 00:10:32.701
Bien sûr, les choses perceptibles
ne tourneront pas mal de ces façons-là ;

00:10:32.701 --> 00:10:34.454
ce sont des exemples caricaturés.

00:10:34.454 --> 00:10:36.393
Mais l'argument général est important :

00:10:36.393 --> 00:10:39.076
si vous créez un processus d'optimisation
très puissant

00:10:39.076 --> 00:10:41.500
pour maximiser les chances
d'atteindre l'objectif x,

00:10:41.500 --> 00:10:43.796
vous devez vous assurer
que votre définition de x

00:10:43.796 --> 00:10:46.245
incorpore tout ce à quoi vous tenez.

00:10:46.835 --> 00:10:51.219
C'est une leçon qui est enseignée
dans de nombreux mythes.

00:10:51.219 --> 00:10:56.517
Le roi Midas souhaitait que tout
ce qu'il touche se transforme en or.

00:10:56.517 --> 00:10:59.378
Il touche sa fille,
elle se transforme en or.

00:10:59.378 --> 00:11:01.931
Il touche sa nourriture,
elle se transforme en or.

00:11:01.931 --> 00:11:04.520
Ça pourrait devenir
pertinent en pratique,

00:11:04.520 --> 00:11:06.880
ne pas se limiter à une métaphore 
de la cupidité

00:11:06.880 --> 00:11:08.565
mais illustrer ce qui arrive

00:11:08.565 --> 00:11:11.322
si vous créez un processus
d'optimisation puissant

00:11:11.322 --> 00:11:16.111
et lui donnez des objectifs
mal conçus ou trop vagues.

00:11:16.111 --> 00:11:21.300
Vous pourriez dire que si un ordinateur
commence à nous implanter des électrodes,

00:11:21.300 --> 00:11:23.565
nous le débrancherions.

00:11:24.555 --> 00:11:29.895
A, ce n'est pas forcément si facile
à faire si nous sommes devenus dépendants,

00:11:29.895 --> 00:11:32.627
par exemple,
comment arrête-t-on internet ?

00:11:32.627 --> 00:11:37.537
B, pourquoi les chimpanzés 
ou les Neandertals

00:11:37.537 --> 00:11:39.298
n'ont-ils pas
empêché l'humanité ?

00:11:39.298 --> 00:11:41.964
Ils avaient de bonnes raisons.

00:11:41.964 --> 00:11:44.759
Nous avons un interrupteur,
par exemple, juste ici.

00:11:44.759 --> 00:11:46.313
(Suffocation)

00:11:46.313 --> 00:11:49.108
La raison est que nous sommes
un adversaire intelligent ;

00:11:49.108 --> 00:11:52.026
nous pouvons anticiper les menaces
et planifier des solutions.

00:11:52.026 --> 00:11:54.530
Mais une super intelligence 
pourrait le faire aussi,

00:11:54.530 --> 00:11:57.724
et elle le ferait bien mieux que nous.

00:11:57.724 --> 00:12:04.911
L'important est que nous ne devrions pas
croire que nous avons tout sous contrôle.

00:12:04.911 --> 00:12:08.358
Nous pourrions tenter 
de nous faciliter la tâche, disons

00:12:08.358 --> 00:12:09.948
en mettant l'I.A. dans une boîte,

00:12:09.948 --> 00:12:11.744
comme un environnement logiciel sûr,

00:12:11.744 --> 00:12:14.766
une simulation de la réalité
d'où elle ne peut s'échapper.

00:12:14.766 --> 00:12:18.912
Mais à quel point sommes-nous sûrs
qu'elle ne trouvera pas un bug.

00:12:18.912 --> 00:12:22.231
Étant donné que de simples hackers humains
trouvent toujours des bugs,

00:12:22.231 --> 00:12:25.117
je dirais, probablement pas très sûrs.

00:12:26.237 --> 00:12:30.785
Donc on déconnecte le câble Ethernet
pour créer une séparation physique,

00:12:30.785 --> 00:12:33.453
mais encore une fois,
comme de simples hackers humains

00:12:33.453 --> 00:12:36.734
transgressent les séparations physiques 
grâce à l'ingéniérie sociale.

00:12:36.734 --> 00:12:38.903
À l'heure où je vous parle,
en ce moment-même,

00:12:38.903 --> 00:12:41.052
je suis sûr qu'il y a un employé,
quelque part

00:12:41.052 --> 00:12:43.858
à qui quelqu'un prétendant être
du département informatique

00:12:43.858 --> 00:12:46.484
a demandé de donner
son identifiant et son mot de passe.

00:12:46.484 --> 00:12:48.791
Des scénarios plus créatifs
sont aussi possibles,

00:12:48.791 --> 00:12:50.476
par exemple, si vous êtes une I.A.

00:12:50.476 --> 00:12:53.548
vous pouvez déplacer des électrodes
dans vos circuits internes

00:12:53.548 --> 00:12:57.010
pour créer des ondes radio que vous
utiliserez pour communiquer.

00:12:57.010 --> 00:12:59.434
Ou vous pouvez prétendre
dysfonctionner,

00:12:59.434 --> 00:13:02.931
et quand les ingénieurs vous ouvrent
pour voir ce qui ne marche pas,

00:13:02.931 --> 00:13:04.867
ils regardent votre code source 
-- Vlan ! --

00:13:04.867 --> 00:13:07.314
la manipulation peut commencer.

00:13:07.314 --> 00:13:10.744
Ou elle pourrait produire le plan
d'une nouvelle technologie géniale,

00:13:10.744 --> 00:13:12.142
et quand nous l'implementons,

00:13:12.142 --> 00:13:16.539
elle a quelques effets secondaires furtifs
planifiés par l'I.A.

00:13:16.539 --> 00:13:20.002
Donc nous ne devrions pas
faire confiance à notre capacité

00:13:20.002 --> 00:13:23.810
à garder un génie super intelligent
prisonnier dans sa lampe éternellement.

00:13:23.810 --> 00:13:26.064
À un moment donné, il va s'échapper.

00:13:27.034 --> 00:13:30.137
Je crois que la réponse à ça
est de découvrir

00:13:30.137 --> 00:13:35.101
comment créer une super intelligence
telle que même si ou quand elle s'échappe,

00:13:35.101 --> 00:13:38.488
on est toujours en sécurité car
elle est fondamentalement de notre côté

00:13:38.488 --> 00:13:40.337
car elle partage nos valeurs.

00:13:40.337 --> 00:13:43.547
Je ne vois aucune solution à ce problème.

00:13:44.557 --> 00:13:48.391
Mais je suis plutôt optimiste quant le fait
que ce problème peut être résolu.

00:13:48.391 --> 00:13:52.294
Nous n'aurions pas à écrire une longue
liste de tout ce que nous chérissons,

00:13:52.294 --> 00:13:55.937
ou, encore pire, devoir le coder
en language informatique

00:13:55.937 --> 00:13:57.391
comme C++ ou Python,

00:13:57.391 --> 00:14:00.158
ce qui serait une tâche sans espoir.

00:14:00.158 --> 00:14:04.455
Au lieu de ça, nous créerions une I.A.
qui utilise son intelligence

00:14:04.455 --> 00:14:07.226
pour apprendre nos valeurs,

00:14:07.226 --> 00:14:12.506
et son système de motivation est construit
de telle sorte qu'elle est motivée

00:14:12.506 --> 00:14:17.738
par la recherche de valeurs ou d'actions
qu'elle prédit que nous approuverions.

00:14:17.738 --> 00:14:21.152
Nous pourrions ainsi influencer
son intelligence autant que possible

00:14:21.152 --> 00:14:23.897
à résoudre des problèmes importants.

00:14:24.727 --> 00:14:26.239
Ça peut arriver,

00:14:26.239 --> 00:14:29.835
et le résultat en serait très positif
pour l'humanité.

00:14:29.835 --> 00:14:33.792
Mais ça n'arrive pas automatiquement.

00:14:33.792 --> 00:14:36.790
Les conditions initiales
de l'explosion de l'intelligence

00:14:36.790 --> 00:14:39.653
devront être programmées
de manière précise

00:14:39.653 --> 00:14:43.183
si nous voulons obtenir
une détonation contrôlée.

00:14:43.183 --> 00:14:45.701
Les valeurs de l'I.A. devront
correspondre aux nôtres,

00:14:45.701 --> 00:14:47.621
pas seulement dans un contexte familier,

00:14:47.621 --> 00:14:50.289
où il est facile de contrôler 
comment l'I.A. se comporte,

00:14:50.289 --> 00:14:53.473
mais aussi dans de nouveaux contextes
que l'I.A. pourrait rencontrer

00:14:53.473 --> 00:14:54.790
dans un futur indéfini.

00:14:54.790 --> 00:14:59.497
Il y a aussi des problèmes ésotériques
qui devront être résolus :

00:14:59.497 --> 00:15:01.616
les détails exacts
de sa théorie de décision,

00:15:01.616 --> 00:15:04.480
comment gérer l'incertitude logique
et ainsi de suite.

00:15:05.150 --> 00:15:08.432
Les problèmes techniques qui doivent
être surmontés pour que ça marche

00:15:08.432 --> 00:15:09.545
semblent ardus--

00:15:09.545 --> 00:15:12.925
pas autant que de faire 
une I.A. super intelligente,

00:15:12.925 --> 00:15:15.793
mais assez ardus.

00:15:15.793 --> 00:15:17.488
Là où c'est inquiétant, c'est que

00:15:17.488 --> 00:15:22.172
faire une I.A. super intelligente
est un défi vraiment difficile.

00:15:22.172 --> 00:15:24.720
Faire une I.A. super intelligente
qui soit sûre

00:15:24.720 --> 00:15:27.136
implique quelques
défis supplémentaires.

00:15:28.166 --> 00:15:31.703
Le risque est que si quelqu'un trouve
comment résoudre le premier défi

00:15:31.703 --> 00:15:34.704
sans avoir aussi résolu

00:15:34.704 --> 00:15:36.605
l'autre défi, celui d'assurer
une sécurité parfaite.

00:15:37.375 --> 00:15:40.706
Je pense que nous devrions donc
commencer à résoudre

00:15:40.706 --> 00:15:43.528
le problème de contrôle d'abord,

00:15:43.528 --> 00:15:46.188
pour qu'il soit disponible
quand on en aura besoin.

00:15:46.768 --> 00:15:50.275
On ne pourra peut-être pas résoudre
tout le problème du contrôle à l'avance

00:15:50.275 --> 00:15:53.299
car certains éléments ne peuvent
être mis en place

00:15:53.299 --> 00:15:57.296
qu'une fois qu'on connait les détails
de l'architecture où ce sera implémenté.

00:15:57.296 --> 00:16:00.676
Mais plus nous résolvons ce problème
de contrôle à l'avance,

00:16:00.676 --> 00:16:04.766
meilleure sera notre chance 
que la transition vers l'ère de l'I.A.

00:16:04.766 --> 00:16:06.306
se passera bien.

00:16:06.306 --> 00:16:10.950
Pour moi, ça semble valoir la peine

00:16:10.950 --> 00:16:14.282
et j'imaginer que,
si tout se passe bien,

00:16:14.282 --> 00:16:18.940
les gens, dans un million d'années,
penseront peut-être

00:16:18.940 --> 00:16:22.942
que la chose qui a vraiment été
importante dans notre siècle

00:16:22.942 --> 00:16:24.509
était de faire ça bien.

00:16:24.509 --> 00:16:26.198
Merci.

00:16:26.198 --> 00:16:29.011
(Applaudissements)

