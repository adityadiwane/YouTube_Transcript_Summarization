WEBVTT
Kind: captions
Language: ru

00:00:00.000 --> 00:00:07.000
Переводчик: Marina Vereschagina
Редактор: Myo Aung

00:00:12.570 --> 00:00:16.777
Я работаю с математиками,
философами и информатиками.

00:00:16.777 --> 00:00:21.986
Среди всего прочего,
мы собираемся и думаем

00:00:21.986 --> 00:00:24.030
о будущем машинного интеллекта.

00:00:24.030 --> 00:00:28.755
Некоторые люди полагают,
что это вроде научной фантастики,

00:00:28.755 --> 00:00:31.856
далеко отсюда, безумие какое-то.

00:00:31.856 --> 00:00:33.326
Но я люблю говорить

00:00:33.326 --> 00:00:36.930
хорошо, давайте глянем
на современное состояние человечества.

00:00:36.930 --> 00:00:38.622
(Смех)

00:00:38.622 --> 00:00:41.024
Всё как обычно.

00:00:41.024 --> 00:00:43.309
Но если задуматься над этим,

00:00:43.309 --> 00:00:46.602
на самом деле мы гости, появившиеся
совсем недавно на этой планете,

00:00:46.602 --> 00:00:48.684
человеческий род.

00:00:48.684 --> 00:00:53.430
Задумайтесь, если бы Земля
была создана год назад,

00:00:53.430 --> 00:00:56.978
человеческому роду было бы
всего 10 минут от роду.

00:00:56.978 --> 00:01:00.146
Индустриальная эра началась
две секунды назад.

00:01:01.276 --> 00:01:06.501
Другой способ взглянуть на это — подумать
о мировом ВВП за последние 10000 лет.

00:01:06.501 --> 00:01:09.530
Я построил для вас график.

00:01:09.530 --> 00:01:11.304
Это выглядит вот так.

00:01:11.304 --> 00:01:12.667
(Смех)

00:01:12.667 --> 00:01:14.818
Это любопытная форма
для обычного состояния.

00:01:14.818 --> 00:01:16.516
Я бы не хотел сидеть на этом.

00:01:16.516 --> 00:01:19.067
(Смех)

00:01:19.067 --> 00:01:23.841
Давайте спросим себя, что же является
причиной нынешней аномалии?

00:01:23.841 --> 00:01:26.393
Кто-то скажет, что это технологии.

00:01:26.393 --> 00:01:31.061
Да, это правда, технологии накопились
за всё время существования человека,

00:01:31.061 --> 00:01:35.713
и сейчас технологии
развиваются чрезвычайно быстро —

00:01:35.713 --> 00:01:37.278
это непосредственная причина,

00:01:37.278 --> 00:01:39.843
вот почему мы в последнее время
очень продуктивны.

00:01:40.473 --> 00:01:44.134
Но мне хочется думать дальше,
об окончательной цели.

00:01:45.114 --> 00:01:48.880
Взгляните на этих двух
выдающихся джентльменов:

00:01:48.880 --> 00:01:50.480
У нас есть Канзи,

00:01:50.480 --> 00:01:55.123
он освоил 200 лексем,
невероятный подвиг.

00:01:55.123 --> 00:01:58.817
И Эд Уиттен, развязавший
вторую революцию в теории струн.

00:01:58.817 --> 00:02:01.141
Если мы посмотрим вглубь,
вот что мы найдём:

00:02:01.141 --> 00:02:02.711
в основном одно и то же.

00:02:02.711 --> 00:02:04.524
Один чуть крупнее,

00:02:04.524 --> 00:02:07.282
может быть, хитрее устроен изнутри.

00:02:07.282 --> 00:02:11.094
Как бы там ни было, невидимые различия
не могут быть очень сложными,

00:02:11.094 --> 00:02:15.379
потому что появилось
всего 250 000 поколений

00:02:15.379 --> 00:02:17.111
после нашего последнего общего предка.

00:02:17.111 --> 00:02:20.960
Мы знаем, что сложным механизмам
для эволюции требуется много времени.

00:02:22.000 --> 00:02:24.499
Куча относительно незначительных изменений

00:02:24.499 --> 00:02:27.566
привела нас от Канзи к Уиттену,

00:02:27.566 --> 00:02:32.109
от палок-копалок к межконтинентальным
баллистическим ракетам.

00:02:32.839 --> 00:02:36.774
Поэтому становится довольно очевидным,
что всё достигнутое,

00:02:36.774 --> 00:02:38.152
и всё важное для нас

00:02:38.152 --> 00:02:43.380
кардинально зависит от незначительных
изменений, создавших человеческий разум.

00:02:44.650 --> 00:02:48.312
И следствием, конечно же, является,
то, что какие-либо дальнейшие изменения,

00:02:48.312 --> 00:02:51.789
которые могли бы существенно
изменить основание мышления,

00:02:51.789 --> 00:02:54.991
могут иметь потенциально
огромные последствия.

00:02:56.321 --> 00:02:59.226
Некоторые из моих коллег думают,
что мы на грани

00:02:59.226 --> 00:03:03.134
чего-то, что может создать
глубокое изменение в том основании

00:03:03.134 --> 00:03:06.347
и это машинный суперинтеллект.

00:03:06.347 --> 00:03:11.086
Искусственным интеллектом ранее считался
ввод команд в ящик.

00:03:11.086 --> 00:03:12.751
У вас есть программисты-люди,

00:03:12.751 --> 00:03:15.886
которые кропотливо вручную
создавали крупицы знаний.

00:03:15.886 --> 00:03:17.972
Вы строите экспертные системы,

00:03:17.972 --> 00:03:20.296
и они были в какой-то степени полезны
для некоторых целей,

00:03:20.296 --> 00:03:22.977
но они были очень хрупкими,
они не масштабировались.

00:03:22.977 --> 00:03:26.410
В основном мы получали
только то, что вводили.

00:03:26.410 --> 00:03:27.407
Но с тех пор

00:03:27.407 --> 00:03:30.874
в области искусственного интеллекта
произошла смена парадигмы.

00:03:30.874 --> 00:03:33.644
Сегодня вся активность сосредоточена
вокруг машинного обучения.

00:03:34.394 --> 00:03:39.781
Вместо создания знания вручную
мы создаём алгоритмы,

00:03:40.511 --> 00:03:46.065
которые обучаются, зачастую
из необработанных сигналов сенсоров.

00:03:46.065 --> 00:03:51.063
Почти то же, что делает младенец.

00:03:51.063 --> 00:03:55.270
В результате ИИ не ограничен
одной областью знаний.

00:03:55.270 --> 00:03:59.901
Одна и та же система может научиться переводить
между несколькими парами языков,

00:03:59.901 --> 00:04:05.338
или научиться играть в компьютерные игры
на игровой приставке Atari.

00:04:05.338 --> 00:04:07.117
Конечно,

00:04:07.117 --> 00:04:11.116
ИИ до сих пор далёк
от мощной междисциплинарной способности

00:04:11.116 --> 00:04:14.335
обучаться и планировать,
как это делает человек.

00:04:14.335 --> 00:04:16.461
У коры мозга всё ещё есть
некоторые алгоритмические приёмы,

00:04:16.461 --> 00:04:18.816
которые мы ещё не знаем,
как реализовать в машинах.

00:04:19.886 --> 00:04:21.785
Вопрос в том,

00:04:21.785 --> 00:04:25.285
как мы далеки от возможности
реализовать эти приёмы?

00:04:26.245 --> 00:04:27.328
Пару лет назад

00:04:27.328 --> 00:04:30.216
мы опросили
ведущих мировых экспертов по ИИ.

00:04:30.216 --> 00:04:33.440
Одним из наших вопросов был:

00:04:33.440 --> 00:04:36.793
«К какому году будет 50% вероятности,

00:04:36.793 --> 00:04:40.275
что мы достигнем машинного интеллекта
человеческого уровня?»

00:04:40.785 --> 00:04:44.968
Мы определили человеческий уровень
как способность выполнять

00:04:44.968 --> 00:04:47.839
практически любую работу также хорошо,
как взрослый человек.

00:04:47.839 --> 00:04:51.844
Обычный человеческий уровень, не только
в пределах какой-то ограниченной области.

00:04:51.844 --> 00:04:55.494
И средний ответ был 2040 или 2050,

00:04:55.494 --> 00:04:58.300
в зависимости от группы экспертов,
которую мы опрашивали.

00:04:58.300 --> 00:05:02.339
Это может произойти намного-намного
позднее или же раньше,

00:05:02.339 --> 00:05:04.279
по правде говоря, никто точно не знает.

00:05:05.259 --> 00:05:09.671
Но мы точно знаем, что предел скорости
обработки информации машинами

00:05:09.671 --> 00:05:14.542
лежит далеко за пределами
возможностей биологической ткани.

00:05:15.241 --> 00:05:17.619
Всё сводится к физике.

00:05:17.619 --> 00:05:22.337
Биологический нейрон срабатывает
примерно 200 раз в секунду, 200 герц.

00:05:22.337 --> 00:05:25.931
Но даже современный транзистор
работает на гигагерцах.

00:05:25.931 --> 00:05:31.228
Нейроны медленно двигаются в аксонах,
максимум 100 метров в секунду.

00:05:31.228 --> 00:05:34.339
А в компьютерах сигналы могут
путешествовать со скоростью света.

00:05:35.079 --> 00:05:36.948
Есть также ограничения по размеру.

00:05:36.948 --> 00:05:39.975
Человеческий мозг
обязан умещаться внутри черепа,

00:05:39.975 --> 00:05:44.736
а компьютер может быть
размером со склад или даже больше.

00:05:44.736 --> 00:05:50.335
Потенциал для интеллекта
дремлет в материи,

00:05:50.335 --> 00:05:56.047
так же как энергия атома дремала
на протяжении всей человеческой истории,

00:05:56.047 --> 00:06:00.452
терпеливо ожидая 1945 года.

00:06:00.452 --> 00:06:01.700
В этом столетии

00:06:01.700 --> 00:06:05.818
учёные могут узнать, как пробудить
энергию искусственного интеллекта.

00:06:05.818 --> 00:06:09.826
И я думаю, что тогда мы могли бы
увидеть взрыв интеллекта.

00:06:10.406 --> 00:06:14.363
Сейчас большинство людей, когда они думают
о том, что умно, а что глупо,

00:06:14.363 --> 00:06:17.386
думаю у них в голове
примерно такая картинка.

00:06:17.386 --> 00:06:19.984
На одном конце у нас есть
деревенский идиот,

00:06:19.984 --> 00:06:22.467
а далеко на другой стороне

00:06:22.467 --> 00:06:27.223
у нас есть Эд Уиттен или Альберт Эйнштейн,
или кто-либо из ваших любимых гуру.

00:06:27.223 --> 00:06:31.057
Но я думаю, что с точки зрения
искусственного интеллекта

00:06:31.057 --> 00:06:34.738
настоящая картинка выглядит
примерно вот так.

00:06:35.258 --> 00:06:38.636
ИИ начинается отсюда,
в нулевом интеллекте

00:06:38.636 --> 00:06:41.647
и затем, после многих, многих лет
очень тяжёлой работы,

00:06:41.647 --> 00:06:45.491
может быть, в итоге, мы получим
искусственный интеллект уровня мыши.

00:06:45.491 --> 00:06:47.921
Что-то, что сможет перемещаться
по беспорядочным средам,

00:06:47.921 --> 00:06:49.908
также как может мышь.

00:06:49.908 --> 00:06:54.221
Затем, после многих, многих лет
тяжёлой работы, множества инвестиций,

00:06:54.221 --> 00:06:58.860
может быть, в итоге, мы получим
искусственный интеллект уровня шимпанзе.

00:06:58.860 --> 00:07:02.070
Затем, после многих, многих лет
очень, очень тяжёлой работы,

00:07:02.070 --> 00:07:04.983
мы придём к искусственному интеллекту
деревенского дурачка.

00:07:04.983 --> 00:07:08.255
И несколько мгновений спустя
окажемся дальше Эда Уиттена.

00:07:08.255 --> 00:07:11.225
Поезд не останавливается
на станции «Человечество».

00:07:11.225 --> 00:07:14.247
Скорее он со свистом пронесётся мимо.

00:07:14.247 --> 00:07:16.231
У этого далеко идущие последствия,

00:07:16.231 --> 00:07:20.093
особенно когда это касается
вопросов энергии.

00:07:20.093 --> 00:07:21.992
Например, шимпанзе сильные

00:07:21.992 --> 00:07:27.214
во всех отношениях, шимпанзе примерно
в два раза сильнее мужчины в форме.

00:07:27.214 --> 00:07:31.828
И ещё — судьба Канзи и его товарищей
гораздо больше зависит

00:07:31.828 --> 00:07:35.968
от людей, чем от самих шимпанзе.

00:07:37.228 --> 00:07:39.542
Как только появится суперинтеллект,

00:07:39.542 --> 00:07:43.381
судьба человечества может зависеть
от того, что будет делать суперинтеллект.

00:07:44.451 --> 00:07:45.508
Подумайте об этом:

00:07:45.508 --> 00:07:50.552
машинный интеллект —
последнее изобретение человечества.

00:07:50.552 --> 00:07:53.525
Тогда машины будут лучше
в изобретениях, чем мы,

00:07:53.525 --> 00:07:56.065
и они будут это делать
с цифровой скоростью.

00:07:56.065 --> 00:08:00.966
Это означает
телескопичность будущего.

00:08:00.966 --> 00:08:04.524
Подумайте обо всех
сумасшедших технологиях,

00:08:04.524 --> 00:08:07.322
которые люди могли бы открыть,
имея время в избытке:

00:08:07.322 --> 00:08:10.580
лекарства от старения,
колонизация космоса,

00:08:10.580 --> 00:08:14.311
самовоспроизводящиеся нанороботы
или загрузка мозгов в компьютеры,

00:08:14.311 --> 00:08:16.470
все виды вещей из научной фантастики,

00:08:16.470 --> 00:08:19.207
в рамках законов физики, конечно.

00:08:19.207 --> 00:08:23.419
Всё это мог бы открыть суперинтеллект
и, возможно, довольно таки быстро.

00:08:24.449 --> 00:08:28.007
Суперинтеллект
с такой технологической зрелостью

00:08:28.007 --> 00:08:30.186
был бы чрезвычайно влиятельным,

00:08:30.186 --> 00:08:34.732
и, по крайней мере по некоторым сценариям,
он сможет получить всё, что захочет.

00:08:34.732 --> 00:08:40.393
Мы бы тогда имели будущее,
сформированное предпочтениями этого ИИ.

00:08:41.855 --> 00:08:45.604
Теперь интересный вопрос в том,
каковы эти предпочтения?

00:08:46.244 --> 00:08:48.013
Тут всё хитрее.

00:08:48.013 --> 00:08:49.448
Чтобы как-то сдвинуться,

00:08:49.448 --> 00:08:52.724
прежде всего мы обязаны
избегать очеловечивания.

00:08:53.934 --> 00:08:57.235
И это иронично, потому что
в каждой газетной статье

00:08:57.235 --> 00:09:01.090
о будущем ИИ есть такая картинка.

00:09:02.280 --> 00:09:06.414
Я думаю, что нам необходимо
представить проблему более абстрактно,

00:09:06.414 --> 00:09:09.204
без ярких голливудских сценариев.

00:09:09.204 --> 00:09:12.821
Нам нужно подумать об интеллекте,
как о процессе оптимизации,

00:09:12.821 --> 00:09:18.470
процессе, регулирующем будущее
в определённый набор конфигураций.

00:09:18.470 --> 00:09:21.981
Суперинтеллект это очень сильный
процесс оптимизации.

00:09:21.981 --> 00:09:26.098
Он чрезвычайно хорош
в использовании доступных средств

00:09:26.098 --> 00:09:28.007
для достижения цели.

00:09:28.447 --> 00:09:31.119
Это значит, что нет
обязательной связи между

00:09:31.119 --> 00:09:33.853
«быть очень интеллектуальным»
в этом смысле

00:09:33.853 --> 00:09:38.515
и «иметь цель, которую мы люди
нашли бы стоящей и значимой».

00:09:39.321 --> 00:09:43.115
Предположим, что мы дали ИИ цель —
«улыбнуть» людей.

00:09:43.115 --> 00:09:46.097
Когда ИИ слаб, он выполняет
полезные и забавные действия,

00:09:46.097 --> 00:09:48.614
которые вызывают улыбку у пользователя.

00:09:48.614 --> 00:09:51.031
Когда ИИ становится суперумным,

00:09:51.031 --> 00:09:54.554
он понимает, что существует более
эффективный способ достичь эту цель:

00:09:54.554 --> 00:09:56.476
взять мир под контроль

00:09:56.476 --> 00:09:59.638
и вживлять электроды
в лицевые мышцы людей,

00:09:59.638 --> 00:10:02.579
вызывая постоянные сияющие улыбки.

00:10:02.579 --> 00:10:03.614
Другой пример.

00:10:03.614 --> 00:10:06.997
Предположим, мы даём ИИ цель —
решить трудную математическую проблему.

00:10:06.997 --> 00:10:08.934
Когда ИИ становится суперумным,

00:10:08.934 --> 00:10:13.105
он понимает, что самый эффективный способ
решить проблему —

00:10:13.105 --> 00:10:16.035
преобразовать планету
в гигантский компьютер,

00:10:16.035 --> 00:10:18.281
чтобы улучшить
свою мыслительную способность.

00:10:18.281 --> 00:10:21.045
И заметьте, что это даёт ИИ
инструментальное обоснование

00:10:21.045 --> 00:10:23.561
делать для нас вещи,
которые мы можем не одобрить.

00:10:23.561 --> 00:10:25.496
Люди в этой модели являются угрозами —

00:10:25.496 --> 00:10:28.417
мы могли препятствовать решению
математической проблемы.

00:10:29.207 --> 00:10:32.701
Конечно, вещи не выйдут из-под контроля
именно такими способами,

00:10:32.701 --> 00:10:34.454
это надуманные примеры.

00:10:34.454 --> 00:10:36.393
Но главная суть здесь важна:

00:10:36.393 --> 00:10:39.266
если вы создаёте
очень мощный процесс оптимизации

00:10:39.266 --> 00:10:41.500
для максимизации цели «икс»,

00:10:41.500 --> 00:10:43.776
вам лучше убедиться,
что ваше определение «икс»

00:10:43.776 --> 00:10:46.245
включает всё, что вас волнует.

00:10:46.835 --> 00:10:51.219
Это урок, который также
давался во многих мифах.

00:10:51.219 --> 00:10:56.517
Король Мидас желает, чтобы всё,
чего он касается, превращалось в золото.

00:10:56.517 --> 00:10:59.378
Он трогает свою дочь,
она превращается в золото.

00:10:59.378 --> 00:11:01.931
Он трогает свою еду,
она превращается в золото.

00:11:01.931 --> 00:11:04.520
Это могло стать актуальным на практике,

00:11:04.520 --> 00:11:06.590
не только как метафора для жадности,

00:11:06.590 --> 00:11:08.485
но как иллюстрация возможности,

00:11:08.485 --> 00:11:11.322
что будет, если вы создадите
мощный процесс оптимизации

00:11:11.322 --> 00:11:16.111
и дадите ему неправильное представление
или плохо определённые цели.

00:11:16.111 --> 00:11:21.300
Вы можете сказать, что если компьютер
начнёт вживлять электроды в лица людей,

00:11:21.300 --> 00:11:23.565
мы просто отключим его.

00:11:24.555 --> 00:11:29.895
А) это не обязательно легко сделать,
если мы стали зависимыми от системы.

00:11:29.895 --> 00:11:32.627
Например, где кнопка отключения интернета?

00:11:32.627 --> 00:11:37.747
Б) почему шимпанзе не отключили
кнопку человечества

00:11:37.747 --> 00:11:39.298
или неандертальцы?

00:11:39.298 --> 00:11:41.964
У них определённо были причины.

00:11:41.964 --> 00:11:44.759
У нас есть кнопка выключения,
например, прямо здесь.

00:11:44.759 --> 00:11:46.313
(Душит)

00:11:46.313 --> 00:11:49.238
Причина в том, что мы
интеллектуальные соперники:

00:11:49.238 --> 00:11:51.966
мы можем предвидеть угрозы
и планировать обходные пути.

00:11:51.966 --> 00:11:54.470
Но это может и суперумный агент,

00:11:54.470 --> 00:11:57.724
и он будет намного лучше в этом, чем мы.

00:11:57.724 --> 00:12:04.911
Суть в том, что мы не должны быть уверены,
что у нас это под контролем.

00:12:04.911 --> 00:12:08.358
И мы могли бы попытаться сделать
нашу работу проще, скажем,

00:12:08.358 --> 00:12:09.948
запихнув ИИ в коробку,

00:12:09.948 --> 00:12:11.744
в безопасную программную среду,

00:12:11.744 --> 00:12:14.766
виртуальную имитацию реальности
из которой он не сможет сбежать.

00:12:14.766 --> 00:12:18.912
Но насколько мы можем быть уверены,
что ИИ не сможет найти такую ошибку.

00:12:18.912 --> 00:12:22.081
Учитывая, что даже человеческие хакеры
находят ошибки всё время,

00:12:22.081 --> 00:12:25.117
я бы сказал, возможно, не очень уверены.

00:12:26.237 --> 00:12:30.785
Мы отсоединили сетевой кабель,
чтобы создать воздушный зазор.

00:12:30.785 --> 00:12:33.453
Но опять же, человеческие хакеры

00:12:33.453 --> 00:12:36.834
регулярно нарушают воздушные зазоры,
используя социальную инженерию.

00:12:36.834 --> 00:12:38.093
В то время как я говорю,

00:12:38.093 --> 00:12:40.482
я уверен, где-то там
есть некий работник,

00:12:40.482 --> 00:12:43.828
которого убедил раскрыть свой пароль

00:12:43.828 --> 00:12:46.574
кто-то, утверждающий,
что он из отдела ИТ.

00:12:46.574 --> 00:12:48.701
Возможно, будут
ещё более творческие сценарии,

00:12:48.701 --> 00:12:50.016
как если бы ИИ

00:12:50.016 --> 00:12:53.548
представлялся вам шевелящимися
электродами вокруг вашей внутренней схемы,

00:12:53.548 --> 00:12:57.010
создающим радиоволны, которые
вы можете использовать для общения.

00:12:57.010 --> 00:12:59.434
Или, может, вы могли бы
симулировать сбои,

00:12:59.434 --> 00:13:02.931
и затем, когда программисты вскроют вас,
что же с вами пошло не так,

00:13:02.931 --> 00:13:04.867
они посмотрят на исходный код — Бам!

00:13:04.867 --> 00:13:07.314
Манипуляция имеет место быть.

00:13:07.314 --> 00:13:10.744
Или он может напечатать схему
действительно отличной технологии,

00:13:10.744 --> 00:13:12.142
и когда мы реализуем её,

00:13:12.142 --> 00:13:16.539
будут некоторые тайные побочные эффекты,
которые ИИ уже спланировал.

00:13:16.539 --> 00:13:20.002
Суть здесь в том, что мы не должны
быть уверены в нашей способности

00:13:20.002 --> 00:13:23.810
вечно держать сверхразумного
джина взаперти в бутылке.

00:13:23.810 --> 00:13:26.064
Рано или поздно он выйдет наружу.

00:13:27.034 --> 00:13:30.137
Я верю, что ответ заключается в том,
чтобы выяснить,

00:13:30.137 --> 00:13:35.161
как создать сверхразумный ИИ с учётом, что если он сбежит,

00:13:35.161 --> 00:13:38.438
он всё равно будет безопасен, потому что
он по существу на нашей стороне

00:13:38.438 --> 00:13:40.337
и разделяет наши ценности.

00:13:40.337 --> 00:13:43.547
Я не вижу путей обхода
этой сложной проблемы.

00:13:44.557 --> 00:13:48.391
Вообще я довольно оптимистичен,
что эту проблему можно решить.

00:13:48.391 --> 00:13:52.294
Не нужно писать длинный список
всего что нас волнует,

00:13:52.294 --> 00:13:55.937
или ещё хуже, расшифровывать
это на каком-нибудь компьютерном языке,

00:13:55.937 --> 00:13:57.391
как C++ или Python.

00:13:57.391 --> 00:14:00.158
Это было бы безнадёжной задачей.

00:14:00.158 --> 00:14:04.455
Вместо этого мы бы создали ИИ,
который использует свой интеллект

00:14:04.455 --> 00:14:07.226
для познания того, чем мы дорожим.

00:14:07.226 --> 00:14:12.506
ИИ, который был бы мотивирован
преследовать наши ценности

00:14:12.506 --> 00:14:17.738
или выполнять действия,
наше одобрение на которые он предсказал.

00:14:17.738 --> 00:14:21.152
Следовательно, мы бы использовали
его интеллект как можно больше,

00:14:21.152 --> 00:14:23.897
чтобы решить проблему наполнения ценностями.

00:14:24.727 --> 00:14:26.239
Это может произойти,

00:14:26.239 --> 00:14:29.835
и результат может быть
очень полезен для человечества.

00:14:29.835 --> 00:14:33.792
Но это не произойдёт автоматически.

00:14:33.792 --> 00:14:36.790
Начальные условия
для взрыва интеллекта

00:14:36.790 --> 00:14:39.653
нуждаются в правильной установке,

00:14:39.653 --> 00:14:43.183
если мы хотим иметь
контролируемый взрыв.

00:14:43.183 --> 00:14:45.801
Ценности ИИ должны
согласовываться с нашими,

00:14:45.801 --> 00:14:47.561
не просто в знакомых контекстах,

00:14:47.561 --> 00:14:49.999
где мы можем легко проверить,
как ИИ себя ведёт,

00:14:49.999 --> 00:14:53.233
но также во всех новых контекстах,
с которыми ИИ может столкнуться

00:14:53.233 --> 00:14:54.790
в неопределённом будущем.

00:14:54.790 --> 00:14:59.527
Также, есть несколько необычных проблем,
которые нам необходимо решить:

00:14:59.527 --> 00:15:01.616
точные детали его теории принятия решений,

00:15:01.616 --> 00:15:04.480
как обращаться с логической
неуверенностью и так далее.

00:15:05.330 --> 00:15:08.432
Технические проблемы,
нужные для завершения этой работы,

00:15:08.432 --> 00:15:09.545
выглядят весьма трудно,

00:15:09.545 --> 00:15:12.925
не так трудно,
как создание сверхразумного ИИ,

00:15:12.925 --> 00:15:15.793
но довольно трудно.

00:15:15.793 --> 00:15:17.488
Вот что нас волнует:

00:15:17.488 --> 00:15:22.172
создание сверхразумного ИИ —
действительно сложная задача.

00:15:22.172 --> 00:15:24.720
Создание сверхразумного и безопасного ИИ

00:15:24.720 --> 00:15:27.136
включает в себя ещё некоторые
дополнительные проблемы.

00:15:28.216 --> 00:15:31.703
Риск в том, что кто-то
сможет решить первую задачу

00:15:31.703 --> 00:15:34.704
без решения второй задачи,

00:15:34.704 --> 00:15:36.605
без обеспечения безопасности.

00:15:37.375 --> 00:15:40.706
Я думаю, мы должны заранее найти

00:15:40.706 --> 00:15:43.528
решение проблемы контроля,

00:15:43.528 --> 00:15:46.188
чтобы оно было доступно,
когда понадобится.

00:15:46.768 --> 00:15:50.275
Возможно, мы не сможем решить
проблему контроля целиком и заранее,

00:15:50.275 --> 00:15:53.299
потому что, возможно, некоторые
элементы могут быть разработаны

00:15:53.299 --> 00:15:57.296
только со знанием деталей архитектуры
места реализации.

00:15:57.296 --> 00:16:00.676
Но чем большую часть проблемы контроля
мы решим заранее,

00:16:00.676 --> 00:16:04.766
тем больше наши шансы
на благополучный переход

00:16:04.766 --> 00:16:06.306
к эре машинного интеллекта.

00:16:06.306 --> 00:16:10.950
Для меня это выглядит
проблемой, достойной решения,

00:16:10.950 --> 00:16:14.282
и я могу представить,
что если всё пойдёт хорошо,

00:16:14.282 --> 00:16:18.940
через миллион лет люди взглянут назад
на этот век, и, вполне возможно,

00:16:18.940 --> 00:16:22.942
они скажут,
что единственной важной вещью

00:16:22.942 --> 00:16:24.509
была именно эта.

00:16:24.509 --> 00:16:26.198
Спасибо.

00:16:26.198 --> 00:16:29.011
(Аплодисменты)

