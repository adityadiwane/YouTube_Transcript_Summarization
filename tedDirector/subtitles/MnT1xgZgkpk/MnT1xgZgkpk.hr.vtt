WEBVTT
Kind: captions
Language: hr

00:00:00.000 --> 00:00:07.000
Prevoditelj: Lidija Šimunović
Recezent: Ivan Stamenković

00:00:12.570 --> 00:00:16.777
Radim s mnogo matematičara,
filozofa i računalnih znanstvenika

00:00:16.777 --> 00:00:21.986
s kojima razmišljam o budućnosti
strojne inteligencije,

00:00:21.986 --> 00:00:24.030
među drugim stvarima.

00:00:24.030 --> 00:00:28.755
Neki ljudi misle da su te stvari
u zoni znanstvene fantastike,

00:00:28.755 --> 00:00:31.856
nešto ludo, nestvarno.

00:00:31.856 --> 00:00:33.326
Ali ja volim reći

00:00:33.326 --> 00:00:36.930
ok, pogledajmo uvjete
modernoga života.

00:00:36.930 --> 00:00:38.622
(Smijeh)

00:00:38.622 --> 00:00:41.024
Ovo je normalno stanje stvari.

00:00:41.024 --> 00:00:43.309
Ali ako malo razmislimo o tome,

00:00:43.309 --> 00:00:46.602
mi smo zapravo tek nedavno
stigli na ovaj planet,

00:00:46.602 --> 00:00:48.684
mi, ljudska vrsta.

00:00:48.684 --> 00:00:53.430
Kad bismo gledali na Zemlju kao da
je stvorena prije godinu dana,

00:00:53.430 --> 00:00:56.978
onda bi ljudska vrsta bila
stara deset minuta.

00:00:56.978 --> 00:01:00.146
Industrijska je era počela
prije dvije sekunde.

00:01:01.276 --> 00:01:06.501
Drugi pogled na ovo jest taj da promatramo
svjetski BDP u zadnjih 10 000 godina.

00:01:06.501 --> 00:01:09.530
Odvojio sam nešto vremena i
to za vas grafički prikazao.

00:01:09.530 --> 00:01:11.304
Izgleda ovako.

00:01:11.304 --> 00:01:12.667
(Smijeh)

00:01:12.667 --> 00:01:14.818
Neobičan je to oblik za
uobičajene uvjete.

00:01:14.818 --> 00:01:16.516
Ja sigurno ne bih sjedio na njemu.

00:01:16.516 --> 00:01:19.067
(Smijeh)

00:01:19.067 --> 00:01:23.841
Zapitajmo se koji je uzrok
ove trenutne anomalije.

00:01:23.841 --> 00:01:26.393
Neki bi ljudi rekli da je tehnologija.

00:01:26.393 --> 00:01:31.061
Istina je da se tijekom povijesti
tehnologija nagomilavala

00:01:31.061 --> 00:01:35.713
i u ovom se trenutku
tehnologija jako brzo razvija --

00:01:35.713 --> 00:01:37.278
to je neposredni uzrok,

00:01:37.278 --> 00:01:39.843
i zbog toga smo trenutno
jako produktivni.

00:01:40.473 --> 00:01:44.134
Ali razmislimo o krajnjem uzroku.

00:01:45.114 --> 00:01:48.880
Pogledajte ova dva vrlo
istaknuta gospodina:

00:01:48.880 --> 00:01:50.480
imamo Kanzija --

00:01:50.480 --> 00:01:55.123
koji je svladao 200 leksičkih
znakova što je nevjerojatan podvig.

00:01:55.123 --> 00:01:58.817
I Ed Witten koji je započeo drugu
revoluciju superstruna.

00:01:58.817 --> 00:02:01.141
Ako pomno pogledamo,
uočit ćemo ovo:

00:02:01.141 --> 00:02:02.711
u principu istu stvar.

00:02:02.711 --> 00:02:04.524
Jedna je malo veća,

00:02:04.524 --> 00:02:07.282
možda ima par specifičnosti
u načinu na koji je sklopljena.

00:02:07.282 --> 00:02:11.094
Međutim, ove nevidljive razlike
ne mogu biti jako složene

00:02:11.094 --> 00:02:15.379
jer nas dijeli samo 250 000 generacija

00:02:15.379 --> 00:02:17.111
od zadnjeg zajedničkog pretka.

00:02:17.111 --> 00:02:20.960
Znamo da se složeni
mehanizmi dugo razvijaju.

00:02:22.000 --> 00:02:24.499
Tako da nas hrpa relativno malih promjena

00:02:24.499 --> 00:02:27.566
vodi od Kanzija do Wittena,

00:02:27.566 --> 00:02:32.109
od polomljenih grana do
interkontinentalnih balističkih raketa.

00:02:32.839 --> 00:02:36.774
Onda je poprilično očito
da sve što smo postigli

00:02:36.774 --> 00:02:38.152
i sve do čega nam je stalo

00:02:38.152 --> 00:02:43.380
uvelike ovisi o relativno malim
promjenama koje čine ljudski um.

00:02:44.650 --> 00:02:48.312
Nužna je posljedica ta
da sve daljnje izmjene

00:02:48.312 --> 00:02:51.789
koje bi mogle značajno promijeniti
način razmišljanja

00:02:51.789 --> 00:02:54.991
mogu imati potencijalno
ogromne posljedice.

00:02:56.321 --> 00:02:59.226
Neki od mojih kolega
smatraju da smo na rubu

00:02:59.226 --> 00:03:03.134
nečega što bi moglo izazvati
takve temeljite promjene,

00:03:03.134 --> 00:03:06.347
a radi se o strojnoj superinteligenciji.

00:03:06.347 --> 00:03:11.086
Prije je umjetna inteligencija bila
pisanje naredbi u kutiju.

00:03:11.086 --> 00:03:12.751
Ljudski bi programeri

00:03:12.751 --> 00:03:15.886
mukotrpno ručno stvarali stavke znanja.

00:03:15.886 --> 00:03:17.972
Izgradite takve stručne sustave

00:03:17.972 --> 00:03:20.296
koji su za određene svrhe korisni,

00:03:20.296 --> 00:03:22.977
ali su bili krhki i
nisu bili mjerljivi.

00:03:22.977 --> 00:03:26.410
U principu ste dobivali samo
ono što ste unijeli.

00:03:26.410 --> 00:03:27.407
Ali, od onda se

00:03:27.407 --> 00:03:30.874
dogodila promjena u pristupu
u polju umjetne inteligencije.

00:03:30.874 --> 00:03:33.644
Danas se uglavnom radi o
učenju strojeva.

00:03:34.394 --> 00:03:39.781
Umjesto ručnog unosa prikaza
znanja i značajki,

00:03:40.511 --> 00:03:46.065
stvaramo algoritme koji uče, i to često
iz čistih perceptualnih podataka.

00:03:46.065 --> 00:03:51.063
Načelno je to ista stvar
koju čini ljudsko dijete.

00:03:51.063 --> 00:03:55.270
Rezultat je taj da UI nije
ograničena na jedno područje --

00:03:55.270 --> 00:03:59.901
isti sustav može naučiti prevoditi
bilo koju kombinaciju jezika

00:03:59.901 --> 00:04:05.338
ili naučiti igrati bilo koju
računalnu igru na Atariju.

00:04:05.338 --> 00:04:07.117
Naravno,

00:04:07.117 --> 00:04:11.116
UI nije ni blizu posjedovanja
iste jake, unakrsne sposobnosti

00:04:11.116 --> 00:04:14.335
učenja i planiranja raznih područja
kao što to radi ljudsko biće.

00:04:14.335 --> 00:04:16.461
Korteks ima neke algoritamske trikove

00:04:16.461 --> 00:04:18.816
koje ne znamo kako prenijeti strojevima.

00:04:19.886 --> 00:04:21.785
Tako da je pitanje

00:04:21.785 --> 00:04:25.285
koliko smo blizu tome da
uskladimo te trikove.

00:04:26.245 --> 00:04:27.328
Prije nekoliko godina

00:04:27.328 --> 00:04:30.216
proveli smo istraživanje s
vodećim stručnjacima za UI

00:04:30.216 --> 00:04:33.440
kako bismo vidjeli što misle,
i jedno od pitanja bilo je

00:04:33.440 --> 00:04:36.793
"Što mislite, do koje će godine
biti 50% vjerojatnosti

00:04:36.793 --> 00:04:40.275
da ćemo postići strojnu inteligenciju
na razini ljudske inteligencije?"

00:04:40.785 --> 00:04:44.968
Ljudsku smo razinu definirali kao
sposobnost da se bilo koji zadatak

00:04:44.968 --> 00:04:47.839
obavi jednako dobro kao što bi
ga obavio odrastao čovjek,

00:04:47.839 --> 00:04:51.844
znači, stvarna ljudska razina, a ne
samo unutar određenog područja.

00:04:51.844 --> 00:04:55.494
Srednji je odgovor bio 2040. ili 2050.,

00:04:55.494 --> 00:04:58.300
ovisno o skupini stručnjaka
kojoj smo pitanje postavili.

00:04:58.300 --> 00:05:02.339
To bi se moglo dogoditi puno, puno
kasnije ili ranije,

00:05:02.339 --> 00:05:04.279
istina je ta da nitko to zapravo ne zna.

00:05:05.259 --> 00:05:09.671
Ali ono što znamo jest to da krajnja
granica procesuiranja informacija

00:05:09.671 --> 00:05:14.542
u strojevima uvelike nadilazi
ograničenja biološkog tkiva.

00:05:15.241 --> 00:05:17.619
Radi se o fizici.

00:05:17.619 --> 00:05:22.337
Biološki se neuron ispaljuje na možda
200 herca, 200 puta u sekundi.

00:05:22.337 --> 00:05:25.931
Ali čak i današnji tranzistor
radi u gigahercima.

00:05:25.931 --> 00:05:31.228
Neuroni se polako šire u aksone,
najviše 100 metara u sekundi.

00:05:31.228 --> 00:05:34.339
Ali u računalima signali mogu 
putovati brzinom svjetlosti.

00:05:35.079 --> 00:05:36.948
I tamo postoje ograničenja u veličini,

00:05:36.948 --> 00:05:39.975
isto kao što ljudski mozak
mora stati u lubanju,

00:05:39.975 --> 00:05:44.736
ali računalo može biti veličine
skladišta, ili čak veće.

00:05:44.736 --> 00:05:50.335
Potencijal superinteligencije
prikriven je i čeka,

00:05:50.335 --> 00:05:56.047
slično kao što je snaga atoma
bila prikrivena tijekom povijesti,

00:05:56.047 --> 00:06:00.452
strpljivo čekajući 1945. godinu.

00:06:00.452 --> 00:06:01.700
U ovom su stoljeću

00:06:01.700 --> 00:06:05.818
znanstvenici možda otkrili kako
probuditi moć umjetne inteligencije.

00:06:05.818 --> 00:06:09.826
A onda bismo mogli svjedočiti
eksploziji inteligencije.

00:06:10.406 --> 00:06:14.363
Većina ljudi, kada razmišlja o
tome što je pametno, a što glupo,

00:06:14.363 --> 00:06:17.386
mislim da otprilike zamišlja
ovako nešto.

00:06:17.386 --> 00:06:19.984
Na jednom kraju imamo seosku budalu,

00:06:19.984 --> 00:06:22.467
a na drugome

00:06:22.467 --> 00:06:27.223
Eda Wittena ili Alberta Einsteina,
ili već preferiranog gurua.

00:06:27.223 --> 00:06:31.057
Ali iz perspektive umjetne inteligencije,

00:06:31.057 --> 00:06:34.738
ta slika vjerojatno izgleda ovako:

00:06:35.258 --> 00:06:38.636
sve počinje na točki nulte inteligencije,

00:06:38.636 --> 00:06:41.647
a onda nakon puno, puno
godina napornog rada

00:06:41.647 --> 00:06:45.491
možda konačno dođemo do
umjetne inteligencije na razini miša,

00:06:45.491 --> 00:06:47.921
nešto što se može kretati
kroz pretrpan prostor

00:06:47.921 --> 00:06:49.908
jednako dobro kao miševi.

00:06:49.908 --> 00:06:54.221
A onda nakon još puno, puno godina
napornog rada i mnogo ulaganja,

00:06:54.221 --> 00:06:58.860
možda dođemo do umjetne
inteligencije na razini čimpanze.

00:06:58.860 --> 00:07:02.070
A onda, nakon još puno godina
vrlo, vrlo napornog rada,

00:07:02.070 --> 00:07:04.983
dođemo do seoske budale
umjetne inteligencije.

00:07:04.983 --> 00:07:08.255
I nakon nekoliko trenutaka
nadiđemo Eda Wittena.

00:07:08.255 --> 00:07:11.225
Tu napredak ne prestaje

00:07:11.225 --> 00:07:14.247
već se ubrzano nastavlja.

00:07:14.247 --> 00:07:16.231
To ima duboke implikacije,

00:07:16.231 --> 00:07:20.093
posebno kad se radi o
pitanju moći.

00:07:20.093 --> 00:07:21.992
Na primjer, čimpanze su snažne --

00:07:21.992 --> 00:07:27.214
dvostruko su jače od muškaraca.

00:07:27.214 --> 00:07:31.828
A ipak, sudbina Kanzija i njegovih
prijatelja više ovisi o tome što

00:07:31.828 --> 00:07:35.968
mi ljudi radimo nego o tome
što same čimpanze rade.

00:07:37.228 --> 00:07:39.542
Jednom kada se stvori superinteligencija,

00:07:39.542 --> 00:07:43.381
sudbina će čovječanstva možda
ovisiti o tome što ona radi.

00:07:44.451 --> 00:07:45.508
Razmislite.

00:07:45.508 --> 00:07:50.552
Strojna inteligencija je zadnji izum
koji će čovječanstvo ikada trebati.

00:07:50.552 --> 00:07:53.525
Strojevi će onda biti bolji u
izumljivanju od nas,

00:07:53.525 --> 00:07:56.065
i oni će to raditi u digitalnom
vremenskom rasponu.

00:07:56.065 --> 00:08:00.966
Načelno to znači
teleskopiranje budućnosti.

00:08:00.966 --> 00:08:04.524
Zamislite sve moguće
lude tehnologije

00:08:04.524 --> 00:08:07.322
koje bi ljudi mogli razviti: 
lijek protiv starenja,

00:08:07.322 --> 00:08:08.322
kolonizacija svemira,

00:08:10.580 --> 00:08:14.311
samoreplicirajući nanoboti,
unošenje uma u računalo,

00:08:14.311 --> 00:08:16.470
svakakve znanstveno-fantastične stvari

00:08:16.470 --> 00:08:19.207
koje su u skladu sa zakonima fizike.

00:08:19.207 --> 00:08:23.419
Superinteligencija mogla bi se razviti,
i to dosta brzo.

00:08:24.449 --> 00:08:28.007
Superinteligencija s takvom
tehnološkom zrelošću

00:08:28.007 --> 00:08:30.186
bila bi iznimno moćna,

00:08:30.186 --> 00:08:34.732
i bar bi u nekim slučajevima,
mogla dobiti što želi.

00:08:34.732 --> 00:08:40.393
Onda bismo u budućnosti imali svijet
oblikovan prema preferencijama te UI.

00:08:41.855 --> 00:08:45.604
Dobro je pitanje koje su te preference.

00:08:46.244 --> 00:08:48.013
Tu se stvari kompliciraju.

00:08:48.013 --> 00:08:49.448
Da bismo napredovali s tim,

00:08:49.448 --> 00:08:52.724
moramo prvo izbjeći antropomorfizaciju.

00:08:53.934 --> 00:08:57.235
A to je ironično jer
svi novinski članci

00:08:57.235 --> 00:09:01.090
o budućnosti UI
imaju sliku ovoga:

00:09:02.280 --> 00:09:06.414
Tako da mislim da trebamo pojmiti
ovo pitanje malo apstraktnije,

00:09:06.414 --> 00:09:09.204
a ne u obliku holivudskih scenarija.

00:09:09.204 --> 00:09:12.821
Inteligenciju trebamo promatrati
kao proces optimizacije,

00:09:12.821 --> 00:09:18.470
proces koji usmjerava budućnost
u određeni set konfiguracija.

00:09:18.470 --> 00:09:21.981
Superinteligencija je zaista jak
proces optimizacije.

00:09:21.981 --> 00:09:26.098
Nevjerojatno je dobra u korištenju
raspoloživih sredstava kako bi postigla

00:09:26.098 --> 00:09:28.007
svoj cilj.

00:09:28.447 --> 00:09:31.119
To znači da nužno ne postoji
povezanost između

00:09:31.119 --> 00:09:33.853
visoke inteligencije u tom smislu

00:09:33.853 --> 00:09:38.515
i cilja koji bismo mi ljudi smatrali
vrijednim ili smislenim.

00:09:39.321 --> 00:09:43.115
Recimo da UI damo cilj
da nasmiju ljude.

00:09:43.115 --> 00:09:46.097
Kad je UI slaba, izvodi korisne
ili zabavne radnje

00:09:46.097 --> 00:09:48.614
zbog kojih se njihov korisnik smije.

00:09:48.614 --> 00:09:51.031
Kada UI postane superinteligentna,

00:09:51.031 --> 00:09:54.554
uvidjet će da postoji učinkovitiji
način na koji postići taj cilj:

00:09:54.554 --> 00:09:56.476
preuzimanje kontrole nad svijetom

00:09:56.476 --> 00:09:59.638
i smještanje elektroda u
mišiće lica ljudi

00:09:59.638 --> 00:10:02.579
kako bi izazvala neprestan, vedar osmijeh.

00:10:02.579 --> 00:10:03.614
Još jedan primjer,

00:10:03.614 --> 00:10:06.997
recimo da zadamo UI da riješi
zahtjevan matematički problem.

00:10:06.997 --> 00:10:08.934
Kad UI postane superinteligentna,

00:10:08.934 --> 00:10:13.105
uviđa da je najučinkovitiji način za
rješavanje toga problema

00:10:13.105 --> 00:10:16.035
preobrazba planeta u ogromno računalo,

00:10:16.035 --> 00:10:18.281
da bi povećala njegovu 
sposobnost razmišljanja.

00:10:18.281 --> 00:10:21.045
I imajte na umu da to daje UI
instrumentalni razlog da

00:10:21.045 --> 00:10:23.561
nam radi stvari koje mi
možda ne odobravamo.

00:10:23.561 --> 00:10:25.496
U ovom su primjeri ljudi prijetnja,

00:10:25.496 --> 00:10:28.417
mogli bismo spriječiti rješavanje
matematičkih problema.

00:10:29.207 --> 00:10:32.701
Naravno, stvari neće baš
tako poći po krivu;

00:10:32.701 --> 00:10:34.454
ovo su primjeri iz crtića.

00:10:34.454 --> 00:10:36.393
Ali važna je poanta:

00:10:36.393 --> 00:10:39.266
ako stvorite zaista moćan
proces optimizacije

00:10:39.266 --> 00:10:41.500
kako biste maksimizirali cilj x,

00:10:41.500 --> 00:10:43.776
morate biti sigurni da
vaša definicija x-a

00:10:43.776 --> 00:10:46.245
uključuje sve do čega vam je stalo.

00:10:46.835 --> 00:10:51.219
Ovo je lekcija na koju nas
upozoravaju mnogi mitovi.

00:10:51.219 --> 00:10:56.517
Kralj Mida želi da se sve što
dotakne pretvori u zlato.

00:10:56.517 --> 00:10:59.378
Dodirne kćer i ona se pretvori u zlato.

00:10:59.378 --> 00:11:01.931
Dodirne hranu, ona postane zlato.

00:11:01.931 --> 00:11:04.520
Ovo bi moglo postati i praktički važno,

00:11:04.520 --> 00:11:06.590
ne samo kao metafora za pohlepu,

00:11:06.590 --> 00:11:08.485
nego i kao prikaz onoga što se dogodi

00:11:08.485 --> 00:11:11.322
ako stvorite moćan
proces optimizacije

00:11:11.322 --> 00:11:16.111
i date mu pogrešne ili loše
određene ciljeve.

00:11:16.111 --> 00:11:21.300
Mogli biste reći da, ako računalo
počne stavljati elektrode u lica ljudi,

00:11:21.300 --> 00:11:23.565
jednostavno ćemo ga isključiti.

00:11:24.555 --> 00:11:29.895
Pod a, to nije tako jednostavno
ako smo već ovisni o sustavu --

00:11:29.895 --> 00:11:32.627
na primjer, kako isključiti internet?

00:11:32.627 --> 00:11:37.747
Pod b, zašto čimpanze nisu
isključile prekidač ljudske vrste,

00:11:37.747 --> 00:11:39.298
oni ili neandertalci?

00:11:39.298 --> 00:11:41.964
Zasigurno su postojali razlozi za to.

00:11:41.964 --> 00:11:44.759
Mi imamo prekidač, recimo,
upravo ovdje.

00:11:44.759 --> 00:11:46.313
(Guši se)

00:11:46.313 --> 00:11:49.238
Razlog je taj što smo mi
inteligentni protivnici;

00:11:49.238 --> 00:11:51.966
predviđamo prijetnje i
planiramo kako ih izbjeći.

00:11:51.966 --> 00:11:54.470
Ali to bi mogao raditi i
superinteligentni izvršitelj

00:11:54.470 --> 00:11:57.724
i to puno bolje nego
što mi to radimo.

00:11:57.724 --> 00:12:04.911
Poanta je ovoga da ne smijemo biti
uvjereni da sve držimo pod kontrolom.

00:12:04.911 --> 00:12:08.358
Mogli bismo si olakšati posao tako što

00:12:08.358 --> 00:12:09.948
bismo smjestili UI u kutiju,

00:12:09.948 --> 00:12:11.744
nekakvo sigurno softversko okruženje,

00:12:11.744 --> 00:12:14.766
virtualnu simulaciju stvarnosti iz
koje ne može pobjeći.

00:12:14.766 --> 00:12:18.912
Ali kako možemo biti sigurni
da UI neće pronaći rupu?

00:12:18.912 --> 00:12:22.081
Ako uobzirimo da hakeri
neprestano pronalaze rupe,

00:12:22.081 --> 00:12:25.117
vjerojatno ne možemo biti sigurni u to.

00:12:26.237 --> 00:12:30.785
Isključimo Ethernet kabel da bismo
stvorili zračni prostor,

00:12:30.785 --> 00:12:33.453
ali opet, ljudski hakeri rutinski nadilaze

00:12:33.453 --> 00:12:36.834
te prostore socijalnim inženjeringom.

00:12:36.834 --> 00:12:38.093
Dok ovo govorim,

00:12:38.093 --> 00:12:40.482
siguran sam da su negdje neku zaposlenicu

00:12:40.482 --> 00:12:43.828
nagovorili da otkrije
detalje svog računa

00:12:43.828 --> 00:12:46.574
nekome tko je tvrdio
da je iz IT odjela.

00:12:46.574 --> 00:12:48.701
Mogući su i kreativniji scenariji,

00:12:48.701 --> 00:12:50.016
na primjer, ako ste UI,

00:12:50.016 --> 00:12:53.548
možete zamisliti micanje elektroda
u unutrašnjem sklopu kako biste

00:12:53.548 --> 00:12:57.010
stvorili radio valove kojima
možete komunicirati.

00:12:57.010 --> 00:12:59.434
Ili se možete prevarati da ste neispravni

00:12:59.434 --> 00:13:02.931
i kada vas programeri otvore da vide
što nije u redu s vama,

00:13:02.931 --> 00:13:04.867
pogledaju izvorni kod i -- Bum! --

00:13:04.867 --> 00:13:07.314
manipulacija je počela.

00:13:07.314 --> 00:13:10.744
Ili bi moglo dati nacrt
zaista divne tehnologije,

00:13:10.744 --> 00:13:12.142
a kada ga primijenimo,

00:13:12.142 --> 00:13:16.539
ima neke skrivene posljedice
koje je UI isplanirala.

00:13:16.539 --> 00:13:20.002
Poanta jest ta da ne bismo trebali biti
presigurni u svoju sposobnost

00:13:20.002 --> 00:13:23.810
da superinteligentnog duha
možemo zauvijek čuvati u boci.

00:13:23.810 --> 00:13:26.064
Prije ili kasnije će se osloboditi.

00:13:27.034 --> 00:13:30.137
Vjerujem da je rješenje u
pronalasku načina kako

00:13:30.137 --> 00:13:35.161
stvoriti superinteligentnu UI
koja bi čak - kad - se oslobodi

00:13:35.161 --> 00:13:38.438
još uvijek bila sigurna jer
je u osnovi na našoj strani

00:13:38.438 --> 00:13:40.337
jer dijeli naša uvjerenja.

00:13:40.337 --> 00:13:43.547
Ne vidim kako drukčije
riješiti ovaj veliki problem.

00:13:44.557 --> 00:13:48.391
Zapravo sam ja i optimističan kada
mislim da je problem rješiv.

00:13:48.391 --> 00:13:52.294
Ne bismo morali pisati duge liste
svega do čega nam je stalo,

00:13:52.294 --> 00:13:55.937
ili, još gore, unijeti to u
neki računalni jezik

00:13:55.937 --> 00:13:57.391
kao C++ ili Python,

00:13:57.391 --> 00:14:00.158
to bi bio i više nego beznadan pothvat!

00:14:00.158 --> 00:14:04.455
Umjesto toga, stvorimo UI koja
koristi svoju inteligenciju kako

00:14:04.455 --> 00:14:07.226
bi naučila što nam je važno,

00:14:07.226 --> 00:14:12.506
i čiji je motivacijski sustav konstruiran
tako da bude motivirana za

00:14:12.506 --> 00:14:17.738
provođenje naših uvjerenja ili izvođenje
radnji za koje predviđa da ih odobravamo.

00:14:17.738 --> 00:14:21.152
Tako bismo iskoristili njezinu 
inteligenciju što je više moguće

00:14:21.152 --> 00:14:23.897
kako bismo riješili ovaj problem.

00:14:24.727 --> 00:14:26.239
To se može dogoditi,

00:14:26.239 --> 00:14:29.835
a ishod bi mogao biti jako
dobar za čovječanstvo.

00:14:29.835 --> 00:14:33.792
Ali to se ne događa automatski.

00:14:33.792 --> 00:14:36.790
Polazni uvjeti za
eksploziju inteligencije

00:14:36.790 --> 00:14:39.653
morat će biti postavljeni
na točno određen način

00:14:39.653 --> 00:14:43.183
ako želimo kontroliranu detonaciju.

00:14:43.183 --> 00:14:45.801
Vrijednosti UI moraju odgovarati našima,

00:14:45.801 --> 00:14:47.561
ne samo u poznatim kontekstima

00:14:47.561 --> 00:14:49.999
u kojima lako provjerimo
kako se UI ponaša,

00:14:49.999 --> 00:14:53.233
nego i u novim kontekstima s
kojima bi se UI mogla susresti

00:14:53.233 --> 00:14:54.790
u neodređenoj budućnosti.

00:14:54.790 --> 00:14:59.527
Postoje i neka ezoterična pitanja
koja bi se morala riješiti:

00:14:59.527 --> 00:15:01.616
točni detalji teorije odlučivanja,

00:15:01.616 --> 00:15:04.480
kako se nositi s logičkom
nesigurnosti i tako dalje.

00:15:05.330 --> 00:15:08.432
Tehnički problemi koji se moraju
riješiti kako bi ovo uspjelo

00:15:08.432 --> 00:15:09.545
poprilično su veliki --

00:15:09.545 --> 00:15:12.925
ne toliko veliki kao stvaranje
superinteligentne UI,

00:15:12.925 --> 00:15:15.793
ali prilično veliki.

00:15:15.793 --> 00:15:17.488
Ovo je razlog za brigu:

00:15:17.488 --> 00:15:22.172
Stvaranje superinteligentne UI
težak je izazov.

00:15:22.172 --> 00:15:24.720
Stvaranje sigurne superinteligentne UI

00:15:24.720 --> 00:15:27.136
dodaje još izazova.

00:15:28.216 --> 00:15:31.703
Rizik leži u otkrivanju kako
savladati prvi izazov,

00:15:31.703 --> 00:15:34.704
ali bez shvaćanja kako savladati
dodatni izazov,

00:15:34.704 --> 00:15:36.605
osiguravanje sigurnosti.

00:15:37.375 --> 00:15:40.706
Smatram da bismo
trebali riješiti

00:15:40.706 --> 00:15:43.528
pitanje kontrole unaprijed

00:15:43.528 --> 00:15:46.188
kako bismo bili spremni
kada za to dođe vrijeme.

00:15:46.768 --> 00:15:50.275
Može se dogoditi da ne možemo
taj problem riješiti unaprijed

00:15:50.275 --> 00:15:53.299
jer se mogu posložiti samo neki elementi

00:15:53.299 --> 00:15:57.296
kada točno saznamo gdje će se provoditi.

00:15:57.296 --> 00:16:00.676
Što više problema po pitanju
kontrole riješimo unaprijed,

00:16:00.676 --> 00:16:04.766
bolji su izgledi da će prijelaz
u eru strojne inteligencije

00:16:04.766 --> 00:16:06.306
proći dobro.

00:16:06.306 --> 00:16:10.950
Meni se čini da se to isplati raditi

00:16:10.950 --> 00:16:14.282
i mogu zamisliti da, ako
sve prođe u redu,

00:16:14.282 --> 00:16:18.940
će ljudi za milijun godina
gledati na ovo stoljeće

00:16:18.940 --> 00:16:22.942
i reći da smo napravili jednu stvar
koja je stvarno važna, a ta je

00:16:22.942 --> 00:16:24.509
da smo ovo napravili kako treba.

00:16:24.509 --> 00:16:26.198
Hvala.

00:16:26.198 --> 00:16:29.011
(Pljesak)

