WEBVTT
Kind: captions
Language: hu

00:00:00.000 --> 00:00:07.000
Fordító: Gabriella Zsoter
Lektor: Péter Pallós

00:00:12.570 --> 00:00:16.777
Több matematikussal, filozófussal 
és számítógépes szakemberrel dolgozom,

00:00:16.777 --> 00:00:21.986
akikkel együtt gondolkodunk 
a gépi intelligencia, értelem jövőjéről

00:00:24.030 --> 00:00:26.655
Néhányan azt gondolják, 
egyes kérdéseink

00:00:26.655 --> 00:00:31.206
sci-fibe illő, elvont őrültségek.

00:00:31.206 --> 00:00:33.326
Rendben, szoktam mondani, 
de nézzük meg,

00:00:33.326 --> 00:00:37.290
milyen ma az ember helyzete.

00:00:37.300 --> 00:00:38.622
(Nevetés)

00:00:38.622 --> 00:00:41.024
Ez a szokásos állapot, 
ahogy annak lennie kell.

00:00:41.024 --> 00:00:43.309
Ám ha utánagondolunk, mi, emberek

00:00:43.309 --> 00:00:45.922
csak nemrég érkezett vendégek vagyunk

00:00:45.922 --> 00:00:48.104
ezen a bolygón.

00:00:48.104 --> 00:00:53.430
Képzeljük el, hogy a Föld 
csak egy éve jött lére,

00:00:53.430 --> 00:00:56.978
így az emberi faj tíz perce létezne.

00:00:56.978 --> 00:01:00.146
Az ipari korszak csak 
két másodperce kezdődött.

00:01:01.276 --> 00:01:06.501
Máshonnan nézve a kérdést, gondoljunk 
a világ elmúlt 10 000 évi GDP-jére.

00:01:06.501 --> 00:01:09.770
Vettem magamnak a fáradságot,

00:01:09.770 --> 00:01:11.944
és készítettem önöknek egy grafikont. Íme!

00:01:11.944 --> 00:01:12.667
(Nevetés)

00:01:12.667 --> 00:01:15.548
Egy normál állapothoz képest 
elég furcsa görbe.

00:01:15.548 --> 00:01:17.326
Hát, én biztos nem szeretnék ráülni.

00:01:17.326 --> 00:01:19.067
(Nevetés)

00:01:19.067 --> 00:01:23.841
Tegyük fel magunknak a kérdést, 
mi az oka ennek a szabálytalanságnak?

00:01:23.841 --> 00:01:26.393
Néhányan a technológiát neveznék meg.

00:01:26.393 --> 00:01:31.061
Valóban, a technológiai megoldások 
egyre tökéletesedtek a történelem során,

00:01:31.061 --> 00:01:35.103
és éppen most a technológiai fejlődés

00:01:35.103 --> 00:01:37.278
hihetetlenül felgyorsult, 
ami közvetlen oka

00:01:37.278 --> 00:01:39.843
jelenlegi magas termelékenységünknek.

00:01:40.473 --> 00:01:44.134
De szeretnék jobban 
visszamenni a tényleges okig.

00:01:45.114 --> 00:01:48.880
Nézzük csak ezt a két kiváló urat!

00:01:48.880 --> 00:01:50.480
Itt van Kanzi,

00:01:50.480 --> 00:01:55.123
aki 200 nyelvi szimbólumot tanult meg, 
ami hihetetlen teljesítmény,

00:01:55.123 --> 00:01:58.817
és Ed Witten, aki elindította 
a második szuperhúr forradalmat.

00:01:58.817 --> 00:02:01.141
Ha benézünk a burkolat alá,

00:02:01.141 --> 00:02:02.711
ott alapvetően ugyanazt találjuk.

00:02:02.711 --> 00:02:04.524
Az egyikük kicsit nagyobb, s esetleg

00:02:04.524 --> 00:02:07.282
a kapcsolatokban is van 
egy-két trükkös megoldás.

00:02:07.282 --> 00:02:11.094
De ezek a láthatatlan különbségek 
nem lehetnek nagyon bonyolultak,

00:02:11.094 --> 00:02:15.379
mivel mi csupán 
250 000 nemzedéknyire vagyunk

00:02:15.379 --> 00:02:17.371
utolsó közös ősünktől.

00:02:17.371 --> 00:02:21.610
Tudjuk, hogy az összetett mechanizmusok 
kifejlődéséhez hosszú időre van szükség.

00:02:22.000 --> 00:02:24.499
Tehát jó néhány viszonylag kisebb változás

00:02:24.499 --> 00:02:27.566
elvezet Kanzitól Wittenig,

00:02:27.566 --> 00:02:32.109
a letört faágaktól az interkontinentális 
ballisztikus rakétákig.

00:02:32.839 --> 00:02:35.444
Ezért eléggé nyilvánvaló, hogy minden,

00:02:35.444 --> 00:02:38.772
amit elértünk, ami fontos számunkra,

00:02:38.772 --> 00:02:44.290
alapvetően pár kisebb változás eredménye,
melyek kialakították az emberi elmét.

00:02:44.650 --> 00:02:48.312
Következésképpen, 
minden további változásnak,

00:02:48.312 --> 00:02:50.599
ami jelentősen módosíthatja

00:02:50.599 --> 00:02:55.391
a gondolkodás alapjait, 
óriási kihatása lehet.

00:02:56.321 --> 00:02:59.226
Néhány kollégám szerint 
közel járunk valamihez,

00:02:59.226 --> 00:03:03.134
ami gyökeresen megváltoztathatja 
gondolkodásunk alapjait:

00:03:03.134 --> 00:03:06.347
ez pedig a gépi szuperértelem.

00:03:06.347 --> 00:03:09.906
A mesterséges intelligencia 
eddig azt jelentette,

00:03:09.906 --> 00:03:12.751
hogy parancsokat írunk egy dobozba.
A programozók egyesével,

00:03:12.751 --> 00:03:15.886
aprólékosan pötyögték be a tudnivalókat.

00:03:15.886 --> 00:03:17.972
Felépítettük a szakértői rendszereket,

00:03:17.972 --> 00:03:20.296
amelyek megfeleltek néhány célra,

00:03:20.296 --> 00:03:22.977
de nagyon merevek 
és skálázhatatlanok voltak.

00:03:22.977 --> 00:03:26.410
Alapvetően csak az jött ki, 
amit beletettünk.

00:03:26.410 --> 00:03:27.887
De azóta

00:03:27.887 --> 00:03:30.874
paradigmaváltás történt 
a mesterséges intelligencia területén.

00:03:30.874 --> 00:03:33.644
Ma már a gépi tanulásról 
szól a történet.

00:03:34.394 --> 00:03:39.961
Ismeretek manuális bütykölése helyett

00:03:40.511 --> 00:03:46.065
tanuló algoritmusokat alkotunk, 
gyakorta közvetlenül az észlelt adatokból.

00:03:46.065 --> 00:03:51.063
Tulajdonképpen úgy, 
ahogy a kisgyerekek csinálják.

00:03:51.063 --> 00:03:55.270
Az eredmény a mesterséges intelligencia 
(MI), mely nem korlátozódik egy területre:

00:03:55.270 --> 00:03:59.901
ugyanaz a rendszer megtanulhat 
bármely két nyelv között fordítani,

00:03:59.901 --> 00:04:04.588
vagy bármilyen számítógépes játékot
játszani egy Atari konzolon.

00:04:04.588 --> 00:04:07.347
Azért persze az MI-nek
még távolról sincs meg

00:04:07.347 --> 00:04:11.116
az a figyelemre méltó, 
több területet átfogó képessége,

00:04:11.116 --> 00:04:14.335
hogy ember módjára tanuljon és tervezzen.

00:04:14.335 --> 00:04:17.031
Az agykéregnek van 
néhány algoritmikus trükkje,

00:04:17.031 --> 00:04:19.726
melyet még nem tudunk gépekkel utánozni.

00:04:19.886 --> 00:04:21.785
Szóval az a kérdés,

00:04:21.785 --> 00:04:25.285
milyen messze vagyunk attól, 
hogy lemásoljuk ezeket a trükköket?

00:04:25.915 --> 00:04:27.678
Néhány éve felmérést végeztünk

00:04:27.688 --> 00:04:30.216
a világ néhány vezető 
MI szakértőjének bevonásával,

00:04:30.216 --> 00:04:33.440
hogy lássuk, mit gondolnak a jövőről. 
Egyik kérdésünk így szólt:

00:04:33.440 --> 00:04:36.793
''Mikorra gondolja, 
hogy 50%-os valószínűséggel meglesz

00:04:36.793 --> 00:04:40.275
az emberi szinvonalú gépi értelem?''

00:04:40.785 --> 00:04:44.968
Az emberi szintet úgy határoztuk meg, 
mint olyan képességet,

00:04:44.968 --> 00:04:47.839
amellyel egy felnőtt csaknem 
bármely tevékenységet

00:04:47.839 --> 00:04:51.844
egyformán jól elvégezhet,
nem csak egyszerű feladatokat.

00:04:51.844 --> 00:04:55.494
A válaszok mediánja, azaz középértéke 
2040 vagy 2050 volt,

00:04:55.494 --> 00:04:58.300
attól függően, melyik 
szakértői csoportot kérdeztük meg.

00:04:58.300 --> 00:05:02.339
Ez az esemény sokkal később 
vagy hamarabb is bekövetkezhet,

00:05:02.339 --> 00:05:04.279
igazság szerint senki sem tudja.

00:05:05.259 --> 00:05:09.791
Azt viszont tudjuk,
hogy a gépi információfeldolgozás

00:05:09.791 --> 00:05:14.872
végső lehetőségei jóval meghaladják 
az élő agyszövet korlátait.

00:05:15.241 --> 00:05:17.619
Ez fizikai alapokra vezethető vissza.

00:05:17.619 --> 00:05:22.337
Egy élő neuron legfeljebb 200 hertzcel 
sül ki, azaz egy másodperc alatt 200-szor.

00:05:22.337 --> 00:05:25.931
Ezzel szemben ma már egy tranzisztor 
is gigahertzes tartományban üzemel.

00:05:25.931 --> 00:05:31.228
A neuronok axonjai lassan, 
legföljebb 100 m/s sebességgel működnek.

00:05:31.228 --> 00:05:34.339
De a számítógépekben a jelek 
fénysebességgel terjedhetnek.

00:05:35.079 --> 00:05:36.948
És ott vannak a méret adta korlátok:

00:05:36.948 --> 00:05:39.975
az emberi agynak 
bele kell férnie a koponyába,

00:05:39.975 --> 00:05:44.736
de egy számítógép raktárméretű 
vagy még nagyobb is lehet.

00:05:44.736 --> 00:05:50.335
A szuperértelem lehetősége 
ott szunnyad az anyagban,

00:05:50.335 --> 00:05:56.047
akár az atomerő, amely a történelem során

00:05:56.047 --> 00:06:00.452
türelmesen várt ébredésére 1945-ig.

00:06:00.452 --> 00:06:01.700
Ebben az évszázadban

00:06:01.700 --> 00:06:05.818
a kutatók rájöhetnek, 
hogyan kell életre hívni az MI erejét.

00:06:05.818 --> 00:06:09.826
Úgy gondolom, intelligencia-robbanást 
láthatunk majd.

00:06:10.406 --> 00:06:14.363
A legtöbbünk, amikor arra gondol, 
mi az okosság és a butaság,

00:06:14.363 --> 00:06:17.386
szerintem nagyjából 
egy ilyen képet fest maga elé.

00:06:17.386 --> 00:06:19.984
A skála egyik végén ott a falu bolondja

00:06:19.984 --> 00:06:22.467
és valahol, jó messze a másik végén

00:06:22.467 --> 00:06:27.223
ott van Ed Witten vagy Albert Einstein, 
vagy bárki a kedvenc guruink közül.

00:06:27.223 --> 00:06:31.057
Szerintem a mesterséges 
intelligenciát illetően

00:06:31.057 --> 00:06:34.738
a valódi helyzet valószínűleg 
inkább így áll:

00:06:35.258 --> 00:06:38.636
Az MI itt kezdődik, 
a nulla intelligenciánál,

00:06:38.636 --> 00:06:41.647
aztán nagyon-nagyon sok év 
szorgalmas munkájával,

00:06:41.647 --> 00:06:45.491
talán eljutunk egy egér szintjének 
megfelelő mesterséges intelligenciához.

00:06:45.491 --> 00:06:47.921
Olyasmihez, ami eligazodik 
zsúfolt környezetben,

00:06:47.921 --> 00:06:49.908
úgy, mint azt egy egér teszi.

00:06:49.908 --> 00:06:54.221
Aztán még sokkal több év szívós
munkája, rengeteg befektetés árán

00:06:54.221 --> 00:06:58.860
talán elérjük 
egy csimpánz szintjének megfelelő MI-t.

00:06:58.860 --> 00:07:02.070
Majd még több évnyi 
nagyon-nagyon kitartó munkával

00:07:02.070 --> 00:07:04.983
elérjük a falu bolondjának MI szintjét.

00:07:04.983 --> 00:07:08.255
Csak egy pillanattal később 
már lekörözzük Ed Wittent.

00:07:08.255 --> 00:07:11.225
A vonat nem áll meg 
az Emberfalva állomáson,

00:07:11.225 --> 00:07:14.247
hanem valószínűleg átrobog rajta.

00:07:14.247 --> 00:07:16.231
Ennek pedig lényeges kihatásai vannak,

00:07:16.231 --> 00:07:19.573
főleg, ha már erőviszonyokról lesz szó.

00:07:19.573 --> 00:07:23.492
A csimpánzok például erősek.

00:07:23.492 --> 00:07:27.214
Súlyához képest a csimpánz kétszer 
olyan erős, mint egy jó erőben lévő férfi.

00:07:27.214 --> 00:07:31.828
Mégis, Kanzi és társai sorsa 
sokkal inkább attól függ,

00:07:31.828 --> 00:07:35.968
hogy mi, emberek mit teszünk, 
mint attól, hogy ők mit tesznek.

00:07:36.738 --> 00:07:39.542
Ha egyszer eljön a szuperértelem kora,

00:07:39.542 --> 00:07:43.381
az emberiség sorsa attól függhet, 
amit ez a szuperértelem művel.

00:07:43.511 --> 00:07:46.028
Gondoljunk csak bele! 
A gépi intelligencia lesz

00:07:46.028 --> 00:07:50.552
az utolsó találmány, amit 
nekünk kell kigondolnunk.

00:07:50.552 --> 00:07:53.525
A gépek jobb feltalálók lesznek, 
mint mi vagyunk,

00:07:53.525 --> 00:07:56.065
ráadásul digitális időkeretben működnek.

00:07:56.065 --> 00:08:00.376
Alapvetően ez a jövő 
felgyorsulását jelenti.

00:08:00.406 --> 00:08:04.444
Gondoljunk az összes elképzelhető, 
eszement technológiára,

00:08:04.454 --> 00:08:07.892
amelyeket ha elég időnk lenne, 
talán kifejleszthetnénk:

00:08:10.410 --> 00:08:14.581
önmagukat reprodukáló nanobotok, 
az emberi elme gépre történő feltöltése

00:08:16.470 --> 00:08:19.207
amelyek azért a fizikai 
törvényeknek nem mondanak ellent.

00:08:19.207 --> 00:08:24.309
Egy szuperértelem mindezt talán 
elég gyorsan ki tudná fejleszteni.

00:08:24.449 --> 00:08:28.007
Egy ilyen kifinomult technológiájú 
szuperértelemnek

00:08:28.007 --> 00:08:30.186
rendkívüli hatalma lenne, mellyel legalább

00:08:30.186 --> 00:08:34.732
néhány esetben el tudná érni, amit akar.

00:08:34.732 --> 00:08:40.393
A jövőnket ekkor ennek az MI-nek 
a szempontjai alakítanák.

00:08:41.855 --> 00:08:45.604
Jó kérdés, melyek is ezek a szempontok?

00:08:46.244 --> 00:08:48.013
Itt kezd rázóssá válni a dolog.

00:08:48.013 --> 00:08:49.448
Hogy valahová is eljussunk,

00:08:49.448 --> 00:08:52.724
először is el kell kerülnünk 
az antropomorfizálást.

00:08:53.934 --> 00:08:58.055
Ez azért ironikus, 
mert az MI jövőjéről szóló

00:08:58.055 --> 00:09:01.090
minden újságcikkben ilyen kép szerepel.

00:09:02.280 --> 00:09:06.414
A kérdéshez egy kicsit elvonatkoztatva 
kellene közelítenünk,

00:09:06.414 --> 00:09:09.204
nem a látványos hollywoodi 
forgatókönyvek alapján.

00:09:09.204 --> 00:09:12.821
Az értelmet optimalizálási 
eljárásként kell felfognunk,

00:09:12.821 --> 00:09:18.470
amely a jövőt bizonyos lehetséges 
kimenetek felé tereli.

00:09:18.470 --> 00:09:21.981
A szuperértelem tényleg 
nagyon jó optimalizációs eljárás,

00:09:21.981 --> 00:09:26.098
amely elképesztően ügyesen használja 
az elérhető eszközöket, hogy létrejöjjön

00:09:26.098 --> 00:09:28.007
a céljának megfelelő állapot.

00:09:28.447 --> 00:09:31.119
Ez azt jelenti, 
hogy nem szükségképpen kötődik

00:09:31.119 --> 00:09:33.853
az ebben az értelemben vett 
magas intelligenciához

00:09:33.853 --> 00:09:38.515
egy számunkra értékes 
vagy értelmes cél követése.

00:09:39.321 --> 00:09:43.115
Adjuk azt a feladatot egy MI-nek, 
hogy késztesse mosolyra az embereket!

00:09:43.115 --> 00:09:46.097
Amíg az MI még gyenge, 
hasznos vagy mulatságos dolgokat tesz,

00:09:46.097 --> 00:09:48.614
mosolyra fakasztva a felhasználót.

00:09:48.614 --> 00:09:51.031
Mire az MI szuperértelmes lesz, rájön,

00:09:51.031 --> 00:09:54.554
hogy sokkal hatékonyabban is 
elérheti célját:

00:09:54.554 --> 00:09:56.476
átveszi a világ fölötti uralmat,

00:09:56.476 --> 00:09:59.638
és elektródákat ültet be 
az emberek arcizmaiba,

00:09:59.638 --> 00:10:02.579
amelyek állandó vigyorra kényszerítenek.

00:10:02.579 --> 00:10:03.614
Egy másik példa:

00:10:03.614 --> 00:10:07.157
tegyük fel, egy bonyolult matematikai 
problémát kell megoldania az MI-nek.

00:10:07.157 --> 00:10:08.934
Amikor az MI szuperértelmes lesz,

00:10:08.934 --> 00:10:13.105
rájön, hogy a probléma 
leghatékonyabb megoldása

00:10:13.105 --> 00:10:16.035
a bolygó átalakítása 
egy hatalmas számítógéppé,

00:10:16.035 --> 00:10:18.281
hogy kiterjeszthesse 
gondolkodási képességét.

00:10:18.281 --> 00:10:21.045
Vegyük észre, 
hogy ez további jó ok az MI-nek,

00:10:21.045 --> 00:10:23.561
hogy olyat műveljen, 
amellyel mi nem értenénk egyet.

00:10:23.561 --> 00:10:25.786
Mi fenyegetjük őt ebben a modellben,

00:10:25.786 --> 00:10:28.997
mert akadályozhatjuk 
a matematikai probléma megoldását.

00:10:28.997 --> 00:10:32.701
Az események persze nem pont 
így mehetnek rossz irányba,

00:10:32.701 --> 00:10:34.454
ezek csak képregényszintű példák.

00:10:34.454 --> 00:10:36.393
Fontos viszont az általános tanulság:

00:10:36.393 --> 00:10:39.266
ha egy valóban jó 
optimalizálási eljárást alkotunk,

00:10:39.266 --> 00:10:41.500
amely x cél szerint maximalizál,

00:10:41.500 --> 00:10:43.776
akkor gondoskodjunk róla, 
hogy az x célkitűzés

00:10:43.776 --> 00:10:46.635
tartalmazza mindazt, ami fontos számunkra.

00:10:46.835 --> 00:10:51.219
Erről sokat mond Midász király mondája,

00:10:51.219 --> 00:10:56.517
aki azt kívánta, hogy amihez 
csak hozzáér, váljék arannyá.

00:10:56.517 --> 00:10:59.378
Megérinti a lányát, aki arannyá változik.

00:10:59.378 --> 00:11:01.801
Arannyá válik az étele is, 
amihez hozzányúl.

00:11:01.801 --> 00:11:03.210
A rege nem csak

00:11:03.210 --> 00:11:06.590
a mohóság metaforájaként értelmezhető,

00:11:06.590 --> 00:11:08.485
de annak bemutatásaként is,
mi történik,

00:11:08.485 --> 00:11:11.322
ha túl jól sikerül 
optimalizálnunk egy folyamatot,

00:11:11.322 --> 00:11:16.111
amelyhez rosszul felfogott
vagy homályos célokat rendeltünk.

00:11:16.111 --> 00:11:21.300
Mondhatnák persze, hogy ha egy gép
elektródákat akar a képünkbe dugdosni,

00:11:21.300 --> 00:11:23.565
majd egyszerűen kikapcsoljuk.

00:11:24.555 --> 00:11:29.895
De ezt nem olyan könnyű megtenni, 
ha már függővé váltunk a rendszertől.

00:11:29.895 --> 00:11:32.627
Ugyan már, hol az internet kikapcsolója?

00:11:32.627 --> 00:11:37.747
Miért nem kapcsolták ki 
a csimpánzok az emberiséget

00:11:37.747 --> 00:11:39.298
vagy a neandervölgyieket?

00:11:39.298 --> 00:11:41.964
Alapos okuk volt rá.

00:11:41.964 --> 00:11:44.759
Van nekünk is egy kikapcsolónk, 
például itt.

00:11:44.759 --> 00:11:46.313
(Fojtogatja magát)

00:11:46.313 --> 00:11:49.238
Az ok azonban az, hogy mi olyan
okos ellenfél vagyunk,

00:11:49.238 --> 00:11:51.966
amelyik előre látja a veszélyeket, 
és felkészül rájuk.

00:11:51.966 --> 00:11:54.470
De egy szuperértelmes szereplő is 
ezt tenné,

00:11:54.470 --> 00:11:57.724
csak nálunk sokkal ügyesebben,

00:11:57.724 --> 00:12:04.911
Nem kellene abban bíznunk, 
hogy urai vagyunk helyzetnek.

00:12:04.911 --> 00:12:08.358
De azért megpróbálhatnánk 
megkönnyíteni a dolgunkat,

00:12:08.358 --> 00:12:09.948
pl. hogy az MI-t bedobozoljuk

00:12:09.948 --> 00:12:11.744
egy biztos szoftveres környezetbe,

00:12:11.744 --> 00:12:14.766
olyan virtuális valóságba, 
amelyből nem szabadulhat ki.

00:12:14.766 --> 00:12:18.912
Mennyire bízhatunk azonban abban, 
hogy az MI nem találna-e programhibát?

00:12:18.912 --> 00:12:22.251
Tekintve, hogy hackerek is 
mindig találnak hibákat,

00:12:22.251 --> 00:12:26.007
azt mondanám, hogy ebben 
nem nagyon bízhatunk.

00:12:26.237 --> 00:12:30.785
Akkor húzzuk ki az ethernet kábelt, 
egy légrést teremtve,

00:12:30.785 --> 00:12:33.453
de még az egyszerű hackerek is simán

00:12:33.453 --> 00:12:36.834
veszik ezt az akadályt, 
pszichológiai manipulációt használva.

00:12:36.834 --> 00:12:38.093
Éppen most, amíg beszélek,

00:12:38.093 --> 00:12:40.482
valahol egy alkalmazottat biztosan

00:12:40.482 --> 00:12:43.828
éppen rádumáltak, 
hogy árulja el fiókja adatait valakinek,

00:12:43.828 --> 00:12:46.574
aki állítása szerint a cég informatikusa.

00:12:46.574 --> 00:12:48.701
Sokkal kreatívabb cselek is lehetségesek:

00:12:48.701 --> 00:12:50.136
mondjuk,

00:12:50.136 --> 00:12:53.548
egy MI elektródákat köthet 
az áramköreinkre,

00:12:53.548 --> 00:12:57.010
hogy az így kibocsátott 
rádióhullámok útján kommunikálhasson.

00:12:57.010 --> 00:12:59.434
Esetleg üzemzavart mímelhetne,

00:12:59.434 --> 00:13:02.931
és amikor a programozók kinyitják, 
hogy megkeressék, mi a baj,

00:13:02.931 --> 00:13:04.867
megnézik a forráskódot is, és hoppá,

00:13:04.867 --> 00:13:07.314
már sor is kerülhet a manipulációra.

00:13:07.314 --> 00:13:10.744
Egy MI tervezhetne valami 
nagyon pöpec technológiát,

00:13:10.744 --> 00:13:12.902
amelynek alkalmazásakor

00:13:12.902 --> 00:13:16.539
az MI által tervezett néhány alattomos
mellékhatás is előjön.

00:13:16.539 --> 00:13:20.002
Kulcsfontosságú, hogy nem szabad
bíznunk benne,

00:13:20.002 --> 00:13:23.810
hogy egy szuperértelmes szellemet
örökre palackba zárva tarthatunk,

00:13:23.810 --> 00:13:26.064
mert előbb-utóbb úgyis kiszabadul.

00:13:26.864 --> 00:13:30.137
Azt hiszem, a megoldás inkább az, 
ha kitaláljuk, hogyan alkothatunk

00:13:30.137 --> 00:13:35.161
olyan szuperértelmet, 
mely ha netán elszabadul,

00:13:35.161 --> 00:13:38.438
még mindig megbízható, 
mert alapvetően a mi oldalunkon áll,

00:13:38.438 --> 00:13:40.337
mivel értékeink közösek.

00:13:40.337 --> 00:13:43.547
Ez a fogas kérdés megkerülhetetlen.

00:13:44.557 --> 00:13:48.391
A kérdés megoldhatóságát illetően 
eléggé optimista vagyok.

00:13:48.391 --> 00:13:52.294
Írhatnánk egy hosszú listát mindarról, 
amit fontosnak tartunk,

00:13:52.294 --> 00:13:55.937
vagy ami még rosszabb: 
valamilyen programnyelven írnánk meg,

00:13:55.937 --> 00:13:57.391
pl. C++-ban vagy Pythonban,

00:13:57.391 --> 00:14:00.158
ami reménytelen feladat lenne.

00:14:00.158 --> 00:14:04.455
Ehelyett egy olyan MI-t csinálhatnánk, 
amely értelmét arra használja,

00:14:04.455 --> 00:14:07.226
hogy megtanulja, mik az értékeink,

00:14:07.226 --> 00:14:12.506
s az MI ösztönzőrendszerét
a mi értékeink követésére,

00:14:12.506 --> 00:14:17.738
vagy az általunk vélhetően 
engedélyezett akciókra terveznénk.

00:14:17.738 --> 00:14:21.152
Az MI értelmét tehát feljavítanánk,
amennyire lehet,

00:14:21.152 --> 00:14:23.897
hogy megoldjuk az értékkövetés kérdését.

00:14:24.487 --> 00:14:26.399
Ez a lehetséges kimenetel

00:14:26.399 --> 00:14:29.835
nagyon jó lenne az emberiségnek.

00:14:29.835 --> 00:14:33.792
De ez nem történik meg magától.

00:14:33.792 --> 00:14:36.790
Az intelligencia-robbanás 
kezdeti feltételeit

00:14:36.790 --> 00:14:39.653
már most jól elő kellene készíteni,

00:14:39.653 --> 00:14:43.183
ha irányított robbanást akarunk.

00:14:43.183 --> 00:14:45.801
Az MI értékeinek illeszkedniük 
kell a mieinkhez,

00:14:45.801 --> 00:14:47.561
az olyan ismerős helyzeteken túl is,

00:14:47.561 --> 00:14:49.999
amikor könnyen ellenőrizhető 
az MI viselkedése,

00:14:49.999 --> 00:14:53.493
de olyan új helyzetekben is, 
amelyekkel az MI szembekerülhet,

00:14:53.493 --> 00:14:55.600
a bizonytalan jövőben.

00:14:55.600 --> 00:14:59.527
Van még néhány megoldandó 
ezoterikus kérdés,

00:14:59.527 --> 00:15:01.616
mint a döntéselméleti kérdések részletei,

00:15:01.616 --> 00:15:04.480
a logikai bizonytalanság 
és egyebek kezelése.

00:15:04.670 --> 00:15:07.842
A megoldandó technikai 
nehézségek miatt a feladat

00:15:07.842 --> 00:15:09.425
eléggé bonyolultnak látszik.

00:15:09.435 --> 00:15:12.925
Nem annyira, mint 
egy szuperértelmes MI létrehozása,

00:15:12.925 --> 00:15:15.793
de még így is meglehetősen komplikált.

00:15:15.793 --> 00:15:17.488
Azért aggódhatunk,

00:15:17.488 --> 00:15:22.172
hogy egy értelmes MI létrehozása 
tényleg kemény dió,

00:15:22.172 --> 00:15:25.380
de a biztonságos, szuperértelmes 
MI megalkotása

00:15:25.380 --> 00:15:27.956
ezt még néhány további feladattal tetézi.

00:15:28.216 --> 00:15:31.703
Abban rejlik a kockázat, 
ha megoldjuk az első feladatot anélkül,

00:15:31.703 --> 00:15:34.704
hogy megoldottuk volna a másodikat is,

00:15:34.704 --> 00:15:37.055
amely szavatolná a teljes biztonságot.

00:15:37.375 --> 00:15:40.706
Ezért olyan megoldást kell kidolgoznunk,

00:15:40.706 --> 00:15:43.528
amely előbb oldja meg 
az ellenőrizhetőség kérdését,

00:15:43.528 --> 00:15:46.428
hogy mire szükségünk lesz rá, 
már kéznél legyen.

00:15:46.768 --> 00:15:50.275
Talán nem tudjuk az ellenőrzés 
kérdését előre és teljesen megoldani,

00:15:50.275 --> 00:15:53.299
mert néhány elem csak 
akkor kerülhet a helyére,

00:15:53.299 --> 00:15:57.296
ha részleteiben ismerjük 
a fogadó architektúrát.

00:15:57.296 --> 00:16:00.676
De minél többet megoldunk előre 
az ellenőrzés kérdéséből,

00:16:00.676 --> 00:16:04.766
annál jobbak az esélyeink, 
hogy a gépi értelem korszakába

00:16:04.766 --> 00:16:06.306
zökkenőmentes lesz az átmenet.

00:16:06.306 --> 00:16:10.950
Szerintem ezt nagyon megéri 
rendesen megcsinálni,

00:16:10.950 --> 00:16:14.282
és azt is el tudom képzelni, 
ha minden jól megy,

00:16:14.282 --> 00:16:18.940
amikor az emberek egymillió év múlva 
visszatekintenek erre az évszázadra,

00:16:18.940 --> 00:16:22.522
elmondhatják: az egyetlen lényeges dolgot

00:16:22.522 --> 00:16:24.119
elődeik akkor jól rendezték el.

00:16:24.119 --> 00:16:25.108
Köszönöm.

00:16:25.108 --> 00:16:30.210
(Taps)

