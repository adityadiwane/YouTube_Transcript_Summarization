WEBVTT
Kind: captions
Language: cs

00:00:00.000 --> 00:00:07.000
Překladatel: Marek Vanžura
Korektor: Soňa Baštincová

00:00:12.570 --> 00:00:16.777
Spolupracuji s matematiky, 
filozofy a informatiky,

00:00:16.777 --> 00:00:21.986
se kterými přemýšlíme nad
budoucností strojové inteligence

00:00:21.986 --> 00:00:24.030
a dalšími otázkami.

00:00:24.030 --> 00:00:28.755
Někteří lidé si myslí, že jde o věci 
patřící do science-fiction,

00:00:28.755 --> 00:00:31.856
tedy vzdálené a bláznivé.

00:00:31.856 --> 00:00:33.326
Na to jim ale rád odpovídám,

00:00:33.326 --> 00:00:36.930
fajn, tak se podívejte 
na moderního člověka.

00:00:36.930 --> 00:00:38.622
(Smích)

00:00:38.622 --> 00:00:41.024
Tohle je dnes běžný stav věcí.

00:00:41.024 --> 00:00:43.309
Když se nad tím ale zamyslíme,

00:00:43.309 --> 00:00:46.602
jako lidský druh 
jsme ve skutečnosti teprve

00:00:46.602 --> 00:00:48.684
nedávnými hosty na této planetě.

00:00:48.684 --> 00:00:53.430
Představíme-li si, 
že Země vznikla před rokem,

00:00:53.430 --> 00:00:56.978
bude lidský druh starý pouhých 10 minut.

00:00:56.978 --> 00:01:00.146
Průmyslová éra začala 
před dvěma sekundami.

00:01:01.276 --> 00:01:06.501
Anebo se podívejme na vývoj 
světového HDP za posledních 10 tisíc let.

00:01:06.501 --> 00:01:09.530
Dal jsem si takovou práci, 
že jsem vám jej zpracoval do grafu.

00:01:09.530 --> 00:01:11.304
Vypadá takhle.

00:01:11.304 --> 00:01:12.667
(Smích)

00:01:12.667 --> 00:01:14.818
Jde o podivný tvar pro běžné podmínky.

00:01:14.818 --> 00:01:16.516
Nechtěl bych na něm sedět.

00:01:16.516 --> 00:01:19.067
(Smích)

00:01:19.067 --> 00:01:23.841
Zeptejme se sami sebe, 
co je příčinou tohoto výkyvu?

00:01:23.841 --> 00:01:26.393
Někteří lidé by odpověděli, že technika.

00:01:26.393 --> 00:01:31.061
To je pravda, technika se během 
lidských dějin nahromadila

00:01:31.061 --> 00:01:35.713
a v současnosti se vyvíjí extrémně rychle.

00:01:35.713 --> 00:01:37.278
Je v tom příčinná souvislost.

00:01:37.278 --> 00:01:39.843
Proto jsme nyní tak produktivní.

00:01:40.473 --> 00:01:44.134
Já bych se ale rád vrátil
k pravé příčině zpět do minulosti.

00:01:45.114 --> 00:01:48.880
Podívejme se na tyto 
mimořádně ctihodné gentlemany:

00:01:48.880 --> 00:01:50.480
tohle je Kanzi –

00:01:50.480 --> 00:01:55.123
ovládl 200 různých znaků, 
fantastický výkon.

00:01:55.123 --> 00:01:58.817
A Ed Witten spustil druhou 
superstrunovou revoluci.

00:01:58.817 --> 00:02:01.141
Podíváme-li se pod pokličku, 
nalezneme tohle:

00:02:01.141 --> 00:02:02.711
v podstatě jednu a tutéž věc.

00:02:02.711 --> 00:02:04.524
Jedna je jen trochu větší

00:02:04.524 --> 00:02:07.282
a možná má pár vylepšení 
ve svých zapojeních.

00:02:07.282 --> 00:02:11.094
Ale tyto neviditelné rozdíly 
nemohou být příliš komplikované,

00:02:11.094 --> 00:02:15.379
protože od doby našeho 
nejbližšího společného předka

00:02:15.379 --> 00:02:17.111
uplynulo pouze 250 tisíc generací.

00:02:17.111 --> 00:02:20.960
Víme, že složitější mechanismy potřebují 
ke svému vývoji delší dobu.

00:02:22.000 --> 00:02:24.499
Takže skupina relativně malých změn

00:02:24.499 --> 00:02:27.566
nás od Kanziho přenesla k Wittenovi,

00:02:27.566 --> 00:02:32.109
od prolézání větvovím stromů 
k mezikontinentálním balistickým střelám.

00:02:32.839 --> 00:02:36.774
Takže se zdá být zřejmé, 
že vše, čeho jsme dosáhli,

00:02:36.774 --> 00:02:38.152
a vše, co nás zajímá,

00:02:38.152 --> 00:02:43.380
zásadně závisí na relativně malých 
změnách, které vytvořily lidskou mysl.

00:02:44.650 --> 00:02:48.312
Důsledkem toho je samozřejmě to, 
že jakékoli další změny,

00:02:48.312 --> 00:02:51.789
které výrazně změní 
substrát našeho myšlení,

00:02:51.789 --> 00:02:54.991
mohou mít potenciálně mimořádné důsledky.

00:02:56.321 --> 00:02:59.226
Někteří z mých kolegů si myslí, 
že jsme na okraji něčeho,

00:02:59.226 --> 00:03:03.134
co může přivodit podstatnou 
změnu tohoto substrátu.

00:03:03.134 --> 00:03:06.347
Jde o strojovou superinteligenci.

00:03:06.347 --> 00:03:11.086
Umělá inteligence bývala 
o zadávání příkazů do krabičky.

00:03:11.086 --> 00:03:12.751
Museli jste mít
lidské programátory,

00:03:12.751 --> 00:03:15.886
kteří ručně vytvářeli databáze znalostí.

00:03:15.886 --> 00:03:17.972
Získali jste tím expertní systémy,

00:03:17.972 --> 00:03:20.296
které byly užitečné pro určité úkoly,

00:03:20.296 --> 00:03:22.977
ale byly dost nevhodné 
pro nějaké výraznější rozšíření.

00:03:22.977 --> 00:03:26.410
V podstatě jste z nich dostali jen to, 
co jste do nich vložili.

00:03:26.410 --> 00:03:27.407
Ale od té doby

00:03:27.407 --> 00:03:30.874
došlo na poli umělé inteligence 
ke změně paradigmatu.

00:03:30.874 --> 00:03:33.644
Dnes se vše děje kolem strojového učení.

00:03:34.394 --> 00:03:39.781
Takže namísto ručního vytváření 
databází znalostí,

00:03:40.511 --> 00:03:46.065
vytváříme algoritmy, které se samy učí, 
často z velmi hrubých a neurčitých dat.

00:03:46.065 --> 00:03:51.063
V podstatě dělají stejnou věc 
jako lidské miminko.

00:03:51.063 --> 00:03:55.270
Výsledkem je umělá inteligence, 
která není omezena jednou oblastí:

00:03:55.270 --> 00:03:59.901
tentýž systém se může naučit 
překládat z jednoho jazyka do druhého

00:03:59.901 --> 00:04:05.338
nebo se může naučit hrát 
jakoukoli hru na konzoli Atari.

00:04:05.338 --> 00:04:07.117
Samozřejmě

00:04:07.117 --> 00:04:11.116
umělá inteligence nedosahuje stejných 
výsledků co se týče schopností učit se

00:04:11.116 --> 00:04:14.335
napříč různými oblastmi a plánovat, 
jako dokáže člověk.

00:04:14.335 --> 00:04:16.461
Mozková kůra má pořád v rukávu 
pár algoritmických

00:04:16.461 --> 00:04:18.816
triků, které zatím neumíme
u strojů vytvořit.

00:04:19.886 --> 00:04:21.785
Otázkou je,

00:04:21.785 --> 00:04:25.285
jak daleko jsme od toho, 
kdy se nám je vytvořit podaří?

00:04:26.245 --> 00:04:27.328
Před pár lety

00:04:27.328 --> 00:04:30.216
jsme udělali průzkum mezi 
experty na umělou inteligenci,

00:04:30.216 --> 00:04:33.440
abychom věděli, co si oni myslí, 
a jedna z položených otázek zněla:

00:04:33.440 --> 00:04:36.793
„V jakém roce si myslíte, 
že bude 50% pravděpodobnost,

00:04:36.793 --> 00:04:40.275
že u strojů dosáhneme inteligence
srovnatelné s lidskou?"

00:04:40.785 --> 00:04:44.968
Lidskou inteligenci jsme definovali 
jako schopnost provádět téměř jakoukoli

00:04:44.968 --> 00:04:47.839
práci přinejmenším takovým způsobem
jako dospělý člověk,

00:04:47.839 --> 00:04:51.844
takže jsme nevytvářeli nějaká omezení.

00:04:51.844 --> 00:04:55.494
Nejčastější odpověď byla 2040 a 2050,

00:04:55.494 --> 00:04:58.300
v závislosti na tom, 
jaké skupiny jsme se zeptali.

00:04:58.300 --> 00:05:02.339
Může k tomu dojít mnohem později 
nebo mnohem dříve,

00:05:02.339 --> 00:05:04.279
pravdou je, že to nikdo doopravdy neví.

00:05:05.259 --> 00:05:09.671
Co ale víme, je, že nejzazší hranice 
pro zpracování informací leží

00:05:09.671 --> 00:05:14.542
u strojových substrátů daleko 
za hranicemi biologických tkání.

00:05:15.241 --> 00:05:17.619
Vysvětlení nám dává fyzika.

00:05:17.619 --> 00:05:22.337
Biologický neuron má frekvenci okolo 
200 Hz, je aktivní 200krát za sekundu.

00:05:22.337 --> 00:05:25.931
Ale už dnešní tranzistory pracují 
na gigahertzových frekvencích.

00:05:25.931 --> 00:05:31.228
Signál se v axonu neuronů šíří pomalu, 
maximálně 100 metrů za sekundu.

00:05:31.228 --> 00:05:34.339
V počítačích může ale signál 
cestovat rychlostí světla.

00:05:35.079 --> 00:05:36.948
A existují i prostorová omezení,

00:05:36.948 --> 00:05:39.975
lidský mozek se musí vejít do lebky,

00:05:39.975 --> 00:05:44.736
ale počítač může být velký jako skladiště 
nebo i větší.

00:05:44.736 --> 00:05:50.335
Takže potenciál pro superinteligenci 
zatím tiše spočívá v hmotě,

00:05:50.335 --> 00:05:56.047
podobně jako tam spočívala síla atomu

00:05:56.047 --> 00:06:00.452
až do roku 1945.

00:06:00.452 --> 00:06:01.700
V tomto století

00:06:01.700 --> 00:06:05.818
se mohou vědci naučit, 
jak probudit sílu umělé inteligence.

00:06:05.818 --> 00:06:09.826
A myslím, 
že pak uvidíme explozi inteligence.

00:06:10.406 --> 00:06:14.363
Dnes většina lidí, když přemýšlí o tom, 
co je chytré a co hloupé,

00:06:14.363 --> 00:06:17.386
má na mysli situaci jako je tato.

00:06:17.386 --> 00:06:19.984
Takže na jedné straně 
máme vesnického idiota,

00:06:19.984 --> 00:06:22.467
a na opačném konci

00:06:22.467 --> 00:06:27.223
máme Eda Wittena nebo Alberta Einsteina 
nebo si doplňte svého oblíbence.

00:06:27.223 --> 00:06:31.057
Myslím ale, 
že z pohledu umělé inteligence

00:06:31.057 --> 00:06:34.738
vypadá skutečná situace spíše jako toto:

00:06:35.258 --> 00:06:38.636
umělá inteligence začíná 
v tomto bodě na nule,

00:06:38.636 --> 00:06:41.647
a pak po mnoha a mnoha letech tvrdé dřiny

00:06:41.647 --> 00:06:45.491
se dostáváme téměř 
na úroveň inteligence myši,

00:06:45.491 --> 00:06:47.921
něčeho, co se dokáže orientovat 
ve složitém prostředí,

00:06:47.921 --> 00:06:49.908
jako to dokáže myš.

00:06:49.908 --> 00:06:54.221
A pak po mnoha a mnoha letech 
další tvrdé dřiny, mnoha investicí,

00:06:54.221 --> 00:06:58.860
možná dospějeme 
na úroveň inteligence šimpanze.

00:06:58.860 --> 00:07:02.070
A pak po ještě dalších letech tvrdé práce

00:07:02.070 --> 00:07:04.983
se dostaneme na úroveň vesnického idiota.

00:07:04.983 --> 00:07:08.255
Ale pak po pár okamžicích 
jsme za úrovní Eda Wittena.

00:07:08.255 --> 00:07:11.225
Vlak nezastavuje na Zastávce lidstvo.

00:07:11.225 --> 00:07:14.247
Je pravděpodobnější, že jí prosviští.

00:07:14.247 --> 00:07:16.231
Tohle má závažné implikace,

00:07:16.231 --> 00:07:20.093
obzvláště dojde-li na otázky moci.

00:07:20.093 --> 00:07:21.992
Kupříkladu šimpanzi jsou silní –

00:07:21.992 --> 00:07:27.214
v poměru ke své hmotnosti jsou zhruba 
dvojnásobně silnější než dospělý muž.

00:07:27.214 --> 00:07:31.828
Přesto osud Kanziho a jeho druhů 
závisí mnohem více na tom,

00:07:31.828 --> 00:07:35.968
co po nich chceme my, 
a ne co chtějí sami šimpanzi.

00:07:37.228 --> 00:07:39.542
Jakmile tu bude superinteligence,

00:07:39.542 --> 00:07:43.381
osud lidstva může záviset na tom, 
co bude chtít superinteligence.

00:07:44.451 --> 00:07:45.508
Zamyslete se nad tím.

00:07:45.508 --> 00:07:50.552
Strojová inteligence je posledním 
vynálezem, který je kdy třeba učinit.

00:07:50.552 --> 00:07:53.525
Stroje poté budou 
ve vynalézání lepší než my

00:07:53.525 --> 00:07:56.065
a také budou pracovat digitální rychlostí.

00:07:56.065 --> 00:08:00.966
To znamená, že nás přímo 
katapultují do budoucnosti.

00:08:00.966 --> 00:08:04.524
Uvažte ty nejšílenější technologie, 
které si jen dokážete představit,

00:08:04.524 --> 00:08:07.322
a které by snad lidstvo 
s dostatkem času někdy mohlo vytvořit:

00:08:07.322 --> 00:08:10.580
kúra proti stárnutí, obydlení vesmíru,

00:08:10.580 --> 00:08:14.311
samoreplikující se nanoroboti, 
nahrávání mysli do počítače,

00:08:14.311 --> 00:08:16.470
všechny tyto věci ze science-fiction,

00:08:16.470 --> 00:08:19.207
které nejsou v rozporu se zákony fyziky.

00:08:19.207 --> 00:08:23.419
Všechno toto by mohla superinteligence 
vytvořit, zřejmě dost rychle.

00:08:24.449 --> 00:08:28.007
Superinteligence s takovou 
technologickou vyspělostí

00:08:28.007 --> 00:08:30.186
by byla extrémně mocná.

00:08:30.186 --> 00:08:34.732
A v některých případech by dostala, 
co by si zamanula.

00:08:34.732 --> 00:08:40.393
Naše budoucnost by tak byla utvářena 
preferencemi této umělé inteligence.

00:08:41.855 --> 00:08:45.604
Dobrou otázkou proto je, 
jaké jsou tyto preference?

00:08:46.244 --> 00:08:48.013
To je komplikovaná otázka.

00:08:48.013 --> 00:08:49.448
Abychom mohli odpovědět,

00:08:49.448 --> 00:08:52.724
musíme se vyvarovat antropomorfizaci.

00:08:53.934 --> 00:08:57.235
A to je legrační, 
protože každý článek v novinách

00:08:57.235 --> 00:09:01.090
o budoucnosti umělé inteligence 
má obrázek jako je tento.

00:09:02.280 --> 00:09:06.414
Takže myslím, že musíme 
téma uchopit abstraktněji,

00:09:06.414 --> 00:09:09.204
a ne v pojmech hollywoodských scénářů.

00:09:09.204 --> 00:09:12.821
Musíme o inteligenci uvažovat 
jako o optimalizačním procesu,

00:09:12.821 --> 00:09:18.470
procesu, který řídí budoucnost 
do mezí určitého nastavení.

00:09:18.470 --> 00:09:21.981
Superinteligence je velice 
výkonný optimalizační proces.

00:09:21.981 --> 00:09:26.098
Je velice dobrá ve využívání 
dostupných prostředků

00:09:26.098 --> 00:09:28.007
k dosažení vytčeného cíle.

00:09:28.447 --> 00:09:31.119
To znamená, že neexistuje nutné spojení

00:09:31.119 --> 00:09:33.853
mezi vysokou inteligencí

00:09:33.853 --> 00:09:38.515
a cílem, který bychom my lidé považovali 
za hodnotný nebo smysluplný.

00:09:39.321 --> 00:09:43.115
Představte si, že dáme umělé inteligenci 
úkol rozesmát lidi.

00:09:43.115 --> 00:09:46.097
Když bude slabá, provede užitečné 
nebo úsměvné úkony,

00:09:46.097 --> 00:09:48.614
aby své uživatele rozesmála.

00:09:48.614 --> 00:09:51.031
Když se stane superinteligentní,

00:09:51.031 --> 00:09:54.554
uvědomí si, že existuje efektivnější 
způsob, jak toho dosáhnout:

00:09:54.554 --> 00:09:56.476
převezme vládu nad světem

00:09:56.476 --> 00:09:59.638
a strčí lidem 
do obličejových svalů elektrody,

00:09:59.638 --> 00:10:02.579
čímž vytvoří neustálý úsměv na tváři.

00:10:02.579 --> 00:10:03.614
Jiný příklad,

00:10:03.614 --> 00:10:06.997
předpokládejme, že umělá inteligence 
bude řešit složitý matematický problém.

00:10:06.997 --> 00:10:08.934
Když se stane superinteligentní,

00:10:08.934 --> 00:10:13.105
uvědomí si, že nejefektivnější způsob, 
jak se dopracovat výsledku,

00:10:13.105 --> 00:10:16.035
je přebudovat tuto planetu 
do obrovského počítače,

00:10:16.035 --> 00:10:18.281
aby zvýšila výpočetní kapacitu.

00:10:18.281 --> 00:10:21.045
Všimne si, že toto jí dává pomocný důvod,

00:10:21.045 --> 00:10:23.561
aby dělala věci, 
které bychom jí běžně nedovolili.

00:10:23.561 --> 00:10:25.496
Lidské bytosti jsou v této situaci hrozbou,

00:10:25.496 --> 00:10:28.417
která by jí mohla zabránit 
ve vyřešení matematického problému.

00:10:29.207 --> 00:10:32.701
Samozřejmě by se věci zřejmě 
nevyvíjely tímto způsobem,

00:10:32.701 --> 00:10:34.454
jde o karikované příklady.

00:10:34.454 --> 00:10:36.393
Ale obecné poučení je důležité:

00:10:36.393 --> 00:10:39.266
pokud vytvoříte skutečně
výkonný optimalizační proces,

00:10:39.266 --> 00:10:41.500
abyste co nejlépe vyřešili úkol X,

00:10:41.500 --> 00:10:43.776
ujistěte se, že definice tohoto X

00:10:43.776 --> 00:10:46.245
zahrnuje všechno, o co máte zájem.

00:10:46.835 --> 00:10:51.219
Je to lekce, kterou dávají i mnohé mýty.

00:10:51.219 --> 00:10:56.517
Král Midas si přál, aby se všechno, 
čeho se dotkne, proměnilo ve zlato.

00:10:56.517 --> 00:10:59.378
Dotkl se své dcery, 
a ta se proměnila ve zlato.

00:10:59.378 --> 00:11:01.931
Dotkl se jídla, to se proměnilo ve zlato.

00:11:01.931 --> 00:11:04.520
Tohle může být relevantní

00:11:04.520 --> 00:11:06.590
nikoli jen jako metafora chamtivosti,

00:11:06.590 --> 00:11:08.485
ale také jako ilustrace toho,

00:11:08.485 --> 00:11:11.322
co se stane, když vytvoříte 
výkonný optimalizační proces

00:11:11.322 --> 00:11:16.111
a dáte mu zavádějící 
nebo špatně definované cíle.

00:11:16.111 --> 00:11:21.300
Můžete si říct, že pokud počítač 
začne lidem strkat do tváře elektrody,

00:11:21.300 --> 00:11:23.565
prostě jej vypnete.

00:11:24.555 --> 00:11:29.895
Za A, to nemusí být nutně tak jednoduše
proveditelné, pokud na něm budeme závislí.

00:11:29.895 --> 00:11:32.627
Kde je třeba tlačítko
na vypnutí internetu?

00:11:32.627 --> 00:11:37.747
Za B, proč šimpanzi nebo neandrtálci 
nezmáčkli vypínač

00:11:37.747 --> 00:11:39.298
bránící vzniku lidstva?

00:11:39.298 --> 00:11:41.964
Zcela jistě pro to byl důvod.

00:11:41.964 --> 00:11:44.759
Máme vypínač například zrovna tady.

00:11:44.759 --> 00:11:46.313
(Dusí se)

00:11:46.313 --> 00:11:49.238
Důvodem je, 
že jsme inteligentní protivníci,

00:11:49.238 --> 00:11:51.966
dokážeme předvídat hrozby 
a vyhýbat se jim.

00:11:51.966 --> 00:11:54.470
To by ale dokázal i 
superinteligentní hráč,

00:11:54.470 --> 00:11:57.724
a byl by v tom mnohem lepší než my.

00:11:57.724 --> 00:12:04.911
Pointa je v tom, že bychom si neměli 
být tak jistí, že máme vše pod kontrolou.

00:12:04.911 --> 00:12:08.358
Mohli bychom si zkusit 
usnadnit práci třeba tím,

00:12:08.358 --> 00:12:09.948
že by se U. I. 
zavřela do skříňky,

00:12:09.948 --> 00:12:11.744
do zabezpečeného prostředí,

00:12:11.744 --> 00:12:14.766
simulované virtuální reality, 
ze které by nemohla uprchnout.

00:12:14.766 --> 00:12:18.912
Ale jak moc si můžeme být jistí, 
že nenajde nějakou díru?

00:12:18.912 --> 00:12:22.081
Vzhledem k tomu, že lidští hackeři 
nalézají díry v jednom kuse,

00:12:22.081 --> 00:12:25.117
bychom moc jistí být neměli.

00:12:26.237 --> 00:12:30.785
Takže vypojíme síťový kabel, 
abychom přerušili kontakt,

00:12:30.785 --> 00:12:33.453
ale je to tu zas, lidští hackeři

00:12:33.453 --> 00:12:36.834
běžně tuto překážku překonávají 
sociálním inženýrstvím.

00:12:36.834 --> 00:12:38.093
Jak teď zrovna hovořím,

00:12:38.093 --> 00:12:40.482
zcela jistě je venku nějaký zaměstnanec,

00:12:40.482 --> 00:12:43.828
který byl požádán, 
aby nadiktoval údaje svého účtu

00:12:43.828 --> 00:12:46.574
někomu, kdo tvrdí, 
že je z technické podpory.

00:12:46.574 --> 00:12:48.701
Možné jsou i nápaditější scénáře,

00:12:48.701 --> 00:12:50.016
kdy v roli U. I.

00:12:50.016 --> 00:12:53.548
rozmístíte elektrody kolem svého obvodu,

00:12:53.548 --> 00:12:57.010
abyste vytvořili rádiové vlny, 
kterými budete komunikovat.

00:12:57.010 --> 00:12:59.434
Anebo můžete předstírat poruchu

00:12:59.434 --> 00:13:02.931
a když se objeví programátor, 
aby se podíval, co se porouchalo,

00:13:02.931 --> 00:13:04.867
aby se podíval na zdrojový kód 
– Bum! –

00:13:04.867 --> 00:13:07.314
poradíte si s ním.

00:13:07.314 --> 00:13:10.744
Anebo může vytvořit plán 
pro velmi mazanou technologii,

00:13:10.744 --> 00:13:12.142
kterou když sestrojíme,

00:13:12.142 --> 00:13:16.539
bude mít na nás neblahé vedlejší účinky.

00:13:16.539 --> 00:13:20.002
Zkrátka bychom neměli příliš 
věřit ve svou schopnost

00:13:20.002 --> 00:13:23.810
udržet superinteligentního 
džina v láhvi navždy.

00:13:23.810 --> 00:13:26.064
Dříve nebo později se dostane ven.

00:13:27.034 --> 00:13:30.137
Myslím, že řešením je přijít na to,

00:13:30.137 --> 00:13:35.161
jak vytvořit superinteligenci tak, 
že i kdyby utekla,

00:13:35.161 --> 00:13:38.438
byla by stále neškodná, 
protože by byla na naší straně,

00:13:38.438 --> 00:13:40.337
protože by měla stejné hodnoty jako my.

00:13:40.337 --> 00:13:43.547
Nevidím jinou možnost.

00:13:44.557 --> 00:13:48.391
Jsem velice optimistický co se týče 
vyřešení tohoto problému.

00:13:48.391 --> 00:13:52.294
Nemuseli bychom sepsat dlouhý 
seznam všeho, na čem nám záleží,

00:13:52.294 --> 00:13:55.937
nebo jej snad
vytvořit v programovacím jazyce

00:13:55.937 --> 00:13:57.391
jako je C++ nebo Python,

00:13:57.391 --> 00:14:00.158
což by byl beznadějný úkol.

00:14:00.158 --> 00:14:04.455
Namísto toho bychom měli sestrojit 
systém, který svoji inteligenci využije

00:14:04.455 --> 00:14:07.226
k tomu, aby se naučil, jaké hodnoty máme,

00:14:07.226 --> 00:14:12.506
a aby jeho motivační systém 
byl naladěn tak,

00:14:12.506 --> 00:14:17.738
aby sledoval tyto hodnoty a konal činy, 
které bychom schválili.

00:14:17.738 --> 00:14:21.152
Mohli bychom ovlivnit jeho inteligenci 
jak jen by to bylo možné,

00:14:21.152 --> 00:14:23.897
abychom vyřešili problém načítání hodnot.

00:14:24.727 --> 00:14:26.239
Může k tomu dojít

00:14:26.239 --> 00:14:29.835
a výsledek by byl pro lidstvo příznivý.

00:14:29.835 --> 00:14:33.792
Nedojde k tomu ale automaticky.

00:14:33.792 --> 00:14:36.790
Výchozí podmínky pro explozi inteligence

00:14:36.790 --> 00:14:39.653
mohou vyžadovat to správné nastavení,

00:14:39.653 --> 00:14:43.183
abychom dosáhli řízené detonace.

00:14:43.183 --> 00:14:45.801
Hodnoty umělé inteligence 
musí být shodné s našimi,

00:14:45.801 --> 00:14:47.561
a to nejen v běžných situacích,

00:14:47.561 --> 00:14:49.999
kdy můžeme snadno zkontrolovat, 
jak se chová,

00:14:49.999 --> 00:14:53.233
ale také v nových situacích, 
se kterými se může setkat

00:14:53.233 --> 00:14:54.790
v neurčité budoucnosti.

00:14:54.790 --> 00:14:59.527
Je tu také pár esoterických otázek, 
které by měly být vyřešeny:

00:14:59.527 --> 00:15:01.616
přesné detaily její rozhodovací teorie,

00:15:01.616 --> 00:15:04.480
jak bude nakládat s logickou neurčitostí 
a tak dále.

00:15:05.330 --> 00:15:08.432
Takže technické problémy, 
které je třeba vyřešit,

00:15:08.432 --> 00:15:09.545
vypadají složitě –

00:15:09.545 --> 00:15:12.925
i když ne tak složitě 
jako vytvoření superinteligence,

00:15:12.925 --> 00:15:15.793
každopádně hodně složitě.

00:15:15.793 --> 00:15:17.488
Existuje jisté znepokojení.

00:15:17.488 --> 00:15:22.172
Vytvoření superinteligence 
je skutečně velká výzva.

00:15:22.172 --> 00:15:24.720
Vytvoření superinteligence, 
která bude bezpečná,

00:15:24.720 --> 00:15:27.136
zahrnuje navíc několik dalších výzev.

00:15:28.216 --> 00:15:31.703
Riziko spočívá v tom, když někdo 
přijde na to, jak vyřešit první výzvu,

00:15:31.703 --> 00:15:34.704
aniž by zároveň vyřešil připojené výzvy

00:15:34.704 --> 00:15:36.605
spojené se zachováním bezpečnosti.

00:15:37.375 --> 00:15:40.706
Takže myslím, že bychom měli najít řešení,

00:15:40.706 --> 00:15:43.528
jak to druhé vyřešit v předstihu,

00:15:43.528 --> 00:15:46.188
abychom byli připravení, až dospěje čas.

00:15:46.768 --> 00:15:50.275
Může se stát, že nevyřešíme problém včas,

00:15:50.275 --> 00:15:53.299
protože některé části bude možné doplnit

00:15:53.299 --> 00:15:57.296
až tehdy, kdy budeme znát 
podrobnosti výpočetní architektury.

00:15:57.296 --> 00:16:00.676
Ale čím více v rámci 
tohoto problému vyřešíme,

00:16:00.676 --> 00:16:04.766
tím větší je šance, že přechod 
do éry inteligentních strojů

00:16:04.766 --> 00:16:06.306
proběhne dobře.

00:16:06.306 --> 00:16:10.950
Toto na mě působí jako věc, 
kterou má smysl dělat,

00:16:10.950 --> 00:16:14.282
a dovedu si představit, 
že pokud se věci vyvinou dobře,

00:16:14.282 --> 00:16:18.940
lidé se za milion let 
podívají zpět na toto století

00:16:18.940 --> 00:16:22.942
a řeknou si, že věc, kterou 
jsme udělali skutečně správně,

00:16:22.942 --> 00:16:24.509
bylo vypořádání se s tímto problémem.

00:16:24.509 --> 00:16:26.198
Děkuji.

00:16:26.198 --> 00:16:29.011
(Potlesk)

