WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: Claire Ghyselen
Relecteur: Lison Hasse

00:00:12.974 --> 00:00:17.889
La plupart d'entre nous associe
le mouvement au visuel.

00:00:17.889 --> 00:00:22.977
Si je traverse cette scène
ou bouge mes mains alors que je parle,

00:00:22.977 --> 00:00:26.255
ce mouvement est quelque chose 
que vous pouvez observer.

00:00:26.255 --> 00:00:31.737
Mais il y a un monde de gestes importants
qui sont imperceptibles à l’œil humain,

00:00:31.737 --> 00:00:33.778
et au cours de ces dernières années,

00:00:33.778 --> 00:00:35.775
on s'est rendu compte que les cameras

00:00:35.775 --> 00:00:39.425
peuvent détecter ces mouvements 
même quand l’être humain en est incapable.

00:00:40.163 --> 00:00:41.837
Laissez-moi donc vous montrer.

00:00:42.717 --> 00:00:46.339
Sur la gauche, vous voyez la vidéo
du poignet d'une personne,

00:00:46.339 --> 00:00:49.486
et à droite, vous voyez la vidéo
d'un bébé endormi.

00:00:49.486 --> 00:00:52.632
Mais si je ne vous avais pas dit
qu'il s'agissait de vidéos,

00:00:52.632 --> 00:00:56.393
vous auriez pu penser que vous regardiez
deux images tout à fait normales.

00:00:56.393 --> 00:00:58.065
Car dans les deux cas,

00:00:58.065 --> 00:01:02.175
ces vidéos semblent
presque complètement immobiles.

00:01:02.175 --> 00:01:06.060
Mais il y a en fait beaucoup
de mouvement imperceptibles.

00:01:06.060 --> 00:01:08.452
Et si vous touchiez
le poignet sur la gauche,

00:01:08.452 --> 00:01:10.448
vous sentiriez un pouls

00:01:10.448 --> 00:01:12.763
et si vous teniez 
le bébé sur l'image de droite,

00:01:12.763 --> 00:01:15.304
vous sentiriez la montée
et la descente de sa poitrine

00:01:15.304 --> 00:01:17.232
à chacune de ses respirations.

00:01:17.762 --> 00:01:21.338
Et ces mouvements sont lourds de sens

00:01:21.338 --> 00:01:24.681
mais ils sont souvent 
trop subtils pour que nous les voyions.

00:01:24.681 --> 00:01:26.957
Donc à la place, nous devons les observer

00:01:26.957 --> 00:01:30.997
au travers d'un contact direct, 
au travers du toucher.

00:01:30.997 --> 00:01:32.552
Il y a quelques années,

00:01:32.552 --> 00:01:36.667
mes collègues du MIT ont développé
un microscope amplificateur de mouvement.

00:01:36.667 --> 00:01:41.051
C'est en fait un logiciel qui repère
ces mouvements imperceptibles en vidéo

00:01:41.051 --> 00:01:45.416
et les amplifie de manière à les grossir
suffisamment pour qu'on puisse les voir.

00:01:45.416 --> 00:01:48.899
Si bien que, si l'on utilise ce logiciel
sur la vidéo de gauche,

00:01:48.899 --> 00:01:52.149
ça nous permet de voir le pouls 
à l’intérieur du poignet.

00:01:52.149 --> 00:01:53.844
Si nous devions compter ce pouls,

00:01:53.844 --> 00:01:57.095
nous pourrions même obtenir
le rythme cardiaque de la personne.

00:01:57.095 --> 00:02:00.160
Si nous utilisons le même logiciel
sur la vidéo de droite,

00:02:00.160 --> 00:02:03.387
nous pouvons voir chacune 
des respirations de ce bébé,

00:02:03.387 --> 00:02:07.524
et l'utiliser comme un moyen sans contact 
pour surveiller sa respiration.

00:02:08.884 --> 00:02:11.232
Et donc cette technologie
est réellement puissante

00:02:11.232 --> 00:02:13.652
puisqu'elle repère ces phénomènes

00:02:13.652 --> 00:02:16.599
que nous ne pouvons 
sentir qu'avec le toucher,

00:02:16.599 --> 00:02:19.914
et elle les enregistre
visuellement de façon non invasive.

00:02:21.104 --> 00:02:25.515
Il y a deux ans, j'ai rejoint l'équipe 
qui a créé ce logiciel

00:02:25.515 --> 00:02:28.242
et nous avons décidé de poursuivre 
une idée folle.

00:02:28.882 --> 00:02:31.575
On s'est dit, c'est génial
d'utiliser un logiciel

00:02:31.575 --> 00:02:34.710
pour visualiser ainsi
de tout petits mouvements

00:02:34.710 --> 00:02:38.378
et on peut presque le voir comme un 
moyen d’améliorer notre sens du toucher.

00:02:39.168 --> 00:02:43.227
Mais qu'en serait-il si on pouvait en 
faire de même avec notre audition?

00:02:44.508 --> 00:02:49.173
Et si on pouvait utiliser la vidéo
pour capturer les vibrations sonores,

00:02:49.173 --> 00:02:52.000
un autre type de mouvements en fait,

00:02:52.000 --> 00:02:55.346
et faire passer ce que l'on voit 
dans un microphone?

00:02:56.236 --> 00:02:58.207
C'est une idée un peu étrange.

00:02:58.207 --> 00:03:01.760
Laissez-moi donc mettre cela
en perspective pour vous.

00:03:01.760 --> 00:03:05.011
Un microphone traditionnel fonctionne
en convertissant le mouvement

00:03:05.011 --> 00:03:08.610
d'un diaphragme interne
en un signal électrique,

00:03:08.610 --> 00:03:12.928
et ce diaphragme est conçu
pour bouger facilement avec le son,

00:03:12.928 --> 00:03:17.735
pour que ce mouvement puisse être 
enregistré et interprété comme de l'audio.

00:03:17.735 --> 00:03:21.403
Mais le son fait vibrer tous les objets !

00:03:21.403 --> 00:03:26.883
Ces vibrations sont trop subtiles,
trop rapides pour qu'on puisse les voir.

00:03:26.883 --> 00:03:30.621
Et si on les enregistrait 
avec une caméra haute vitesse,

00:03:30.621 --> 00:03:34.197
on pourrait utiliser un logiciel
pour extraire les tout petits mouvements

00:03:34.197 --> 00:03:36.287
de notre vidéo en ralenti,

00:03:36.287 --> 00:03:41.129
et analyser ces mouvements 
pour comprendre quel son les a créés.

00:03:41.859 --> 00:03:44.930
On pourrait alors transformer 
les objets visibles

00:03:44.930 --> 00:03:48.140
en microphones visuels à distance.

00:03:49.080 --> 00:03:51.263
On a donc essayé,

00:03:51.263 --> 00:03:53.190
et voici une de nos expériences.

00:03:53.190 --> 00:03:56.139
Ici nous avons pris cette plante
que vous voyez sur la droite,

00:03:56.139 --> 00:03:58.577
et l'avons filmée 
avec une caméra haute vitesse,

00:03:58.577 --> 00:04:02.106
pendant qu'un caisson de basse
jouait ce son à côté.

00:04:02.106 --> 00:04:10.799
(Musique: « Mary had a little lamb »)

00:04:11.820 --> 00:04:14.644
Et voilà la vidéo 
que nous avons enregistrée.

00:04:14.644 --> 00:04:18.568
Nous l'avons enregistrée 
à des milliers d'images par seconde.

00:04:18.568 --> 00:04:20.890
Même si vous y regardez de très près,

00:04:20.890 --> 00:04:22.841
vous ne pouvez voir que des feuilles

00:04:22.841 --> 00:04:25.906
qui ne bougent presque pas.

00:04:25.906 --> 00:04:30.712
Car en effet, notre son a fait bouger
ces feuilles d’à peine un micromètre.

00:04:31.455 --> 00:04:35.379
C'est un dix-millième de centimètre,

00:04:35.379 --> 00:04:39.535
ce qui place cela quelque part entre
un centième et un millième

00:04:39.535 --> 00:04:42.423
de pixel dans cette image.

00:04:42.423 --> 00:04:44.768
Donc vous pouvez loucher 
autant que vous voulez,

00:04:44.768 --> 00:04:48.597
un mouvement si petit 
est quasiment invisible.

00:04:49.667 --> 00:04:53.824
Mais en fait, un mouvement
invisible à l'oeil

00:04:53.824 --> 00:04:56.633
peut avoir du sens numériquement parlant.

00:04:56.633 --> 00:04:58.635
Parce qu'avec les bons algorithmes,

00:04:58.635 --> 00:05:02.322
on peut utiliser cette vidéo
silencieuse et apparemment immobile

00:05:02.322 --> 00:05:04.690
pour en extraire le son.

00:05:04.690 --> 00:05:12.074
(Musique: «Mary had a little lamb.»

00:05:12.074 --> 00:05:16.572
(Applaudissements)

00:05:22.058 --> 00:05:23.997
Comment est-ce possible ?

00:05:23.997 --> 00:05:28.341
Comment retirons-nous tant d'informations
à partir de mouvements si infimes ?

00:05:28.341 --> 00:05:33.702
Disons que ces feuilles bougent
d'un seul micromètre,

00:05:33.702 --> 00:05:38.245
et que ça modifie notre image
d'un millième de pixel.

00:05:39.495 --> 00:05:41.841
Ça peut paraître peu,

00:05:41.841 --> 00:05:43.837
mais un seul plan dans une vidéo

00:05:43.837 --> 00:05:47.094
contient des centaines 
de milliers de pixels.

00:05:47.094 --> 00:05:50.548
En combinant tous ces infimes mouvements

00:05:50.548 --> 00:05:52.846
sur une image entière,

00:05:52.846 --> 00:05:55.469
un millième de pixel

00:05:55.469 --> 00:05:59.185
finit par former 
quelque chose d'important.

00:05:59.185 --> 00:06:02.505
Sur le plan personnel, réaliser ça
nous a tous bouleversés !

00:06:02.505 --> 00:06:04.825
(Rires)

00:06:04.825 --> 00:06:08.078
Mais même avec le bon algorithme,

00:06:08.078 --> 00:06:10.945
il nous manquait 
une pièce importante du puzzle.

00:06:11.695 --> 00:06:14.959
Vous voyez, il y a beaucoup de facteurs
qui influencent comment

00:06:14.959 --> 00:06:17.296
et quand cette technique fonctionne.

00:06:17.296 --> 00:06:20.500
L'objet lui-même et la distance,

00:06:20.500 --> 00:06:22.894
la caméra, et l'objectif 
que vous utilisez,

00:06:22.894 --> 00:06:26.985
la lumière sur l'objet 
et le volume du son.

00:06:27.945 --> 00:06:31.320
Même avec le bon algorithme,

00:06:31.320 --> 00:06:34.540
il nous a fallu être prudents
dans nos premières expériences

00:06:34.540 --> 00:06:37.352
parce qu'il était impossible
de dire ce qui n'allait pas,

00:06:37.352 --> 00:06:39.470
si un seul de ces facteurs était biaisé.

00:06:39.470 --> 00:06:42.117
Le résultat était du bruit.

00:06:42.117 --> 00:06:45.437
Beaucoup de nos premières expériences
ressemblent à ceci.

00:06:45.437 --> 00:06:47.643
Me voilà,

00:06:47.643 --> 00:06:51.403
et en bas à gauche, on devine
la caméra haute vitesse,

00:06:51.403 --> 00:06:53.866
qui cadre un paquet de chips.

00:06:53.866 --> 00:06:56.815
Deux spots illuminent toute la scène.

00:06:56.815 --> 00:07:01.180
Nous devions donc être très prudents
durant ces premières expériences.

00:07:01.180 --> 00:07:03.688
Voici leur déroulement :

00:07:03.688 --> 00:07:07.449
(Vidéo) Abe Davis: un, deux, trois, go !

00:07:07.449 --> 00:07:12.836
Mary had a little lamb !
Little lamb ! Little lamb !

00:07:12.836 --> 00:07:17.336
(Rires)

00:07:17.336 --> 00:07:20.156
AD : Ça a l'air complètement ridicule !

00:07:20.156 --> 00:07:21.938
(Rires)

00:07:21.938 --> 00:07:24.863
Après tout, je suis en train de crier 
sur un paquet de chips.

00:07:24.863 --> 00:07:25.834
(Rires)

00:07:25.834 --> 00:07:27.951
Et il y a tant de spots

00:07:27.951 --> 00:07:32.181
que les premiers sachets ont 
littéralement fondu sous la chaleur.

00:07:32.181 --> 00:07:35.799
Mais aussi ridicule 
que ça puisse avoir l'air,

00:07:35.799 --> 00:07:37.587
c'était très important.

00:07:37.587 --> 00:07:40.513
Parce que nous avons pu récupérer le son.

00:07:40.513 --> 00:07:45.225
(Audio) Mary had a little lamb !
Little lamb ! Little lamb !

00:07:45.225 --> 00:07:49.313
(Applaudissements)

00:07:49.313 --> 00:07:51.194
AD : Ce fut une expérience-clef,

00:07:51.194 --> 00:07:55.052
parce que ce fut la première restitution
d'un discours intelligible,

00:07:55.052 --> 00:07:57.765
à partir d'une vidéo muette d'un objet.

00:07:57.765 --> 00:08:00.156
Ça nous a permis de créer une référence.

00:08:00.156 --> 00:08:03.778
On a pu progressivement 
modifier les paramètres :

00:08:03.778 --> 00:08:07.911
utiliser des objets différents,
les éloigner,

00:08:07.911 --> 00:08:11.510
utiliser des éclairages moins puissants,
ou réduire le volume du son.

00:08:11.510 --> 00:08:14.761
On a analysé toutes ces expériences,

00:08:14.761 --> 00:08:18.383
jusqu'à ce que nous ayons compris
les limites de notre technologie.

00:08:18.383 --> 00:08:20.333
Parce qu'une fois
ses limites déterminées,

00:08:20.333 --> 00:08:22.679
on a pu trouver des moyens
de les repousser.

00:08:22.679 --> 00:08:25.860
Par exemple, à travers cette expérience,

00:08:25.860 --> 00:08:28.599
où je vais encore parler 
au paquet de chips.

00:08:28.599 --> 00:08:33.429
Mais cette fois, la caméra est à 5 mètres,

00:08:33.429 --> 00:08:36.262
à l'extérieur, 
derrière une fenêtre insonorisée,

00:08:36.262 --> 00:08:40.371
avec la seule lumière naturelle.

00:08:40.371 --> 00:08:43.160
Voilà la vidéo.

00:08:44.450 --> 00:08:49.009
Voilà la bande-son à l'intérieur,
à côté du paquet de chips.

00:08:49.009 --> 00:08:54.047
(Audio) Marie avait un petit agneau,
à la laine blanche comme de la neige,

00:08:54.047 --> 00:08:59.666
partout où Marie se rendait, 
l'agneau sûrement l'accompagnait.

00:08:59.666 --> 00:09:03.683
AD : Et voici ce que nous avons récupéré
de notre vidéo muette,

00:09:03.683 --> 00:09:06.028
prise à travers cette fenêtre.

00:09:06.028 --> 00:09:10.463
(Audio) Marie avait un petit agneau,
à la laine blanche comme de la neige,

00:09:10.463 --> 00:09:15.920
partout où Marie se rendait, 
l'agneau sûrement l'accompagnait.

00:09:15.920 --> 00:09:20.141
(Applaudissements)

00:09:22.421 --> 00:09:25.963
AD : Nous pouvons repousser les frontières
d'autres manières.

00:09:25.963 --> 00:09:27.761
Voici une expérience plus calme.

00:09:27.761 --> 00:09:31.871
On a filmé des écouteurs
connectés à un portable.

00:09:31.871 --> 00:09:35.981
Ici, notre objectif est de récupérer
la musique de l'ordinateur,

00:09:35.981 --> 00:09:38.280
à partir de la vidéo muette

00:09:38.280 --> 00:09:40.787
de ces deux petits écouteurs en plastique.

00:09:40.787 --> 00:09:42.970
Les résultats furent si concluants,

00:09:42.970 --> 00:09:45.431
qu'on a même pu les vérifier sur Shazam.

00:09:45.431 --> 00:09:47.337
(Rires)

00:09:49.657 --> 00:09:59.225
(Musique: « Under Pressure », Queen)

00:10:01.615 --> 00:10:06.584
(Rires) (Applaudissements)

00:10:06.584 --> 00:10:11.135
On peut aussi repousser les limites
en changeant de matériel.

00:10:11.135 --> 00:10:13.596
Toutes ces expériences ont été réalisées

00:10:13.596 --> 00:10:15.918
avec une caméra haute vitesse,

00:10:15.918 --> 00:10:18.797
qui enregistre 100 fois plus d'images

00:10:18.797 --> 00:10:20.724
qu'un smartphone normal.

00:10:20.724 --> 00:10:23.533
On a donc aussi développé une technique

00:10:23.533 --> 00:10:25.763
qui permet d'utiliser 
des caméras normales.

00:10:25.763 --> 00:10:29.832
On y arrive en utilisant
l'obturateur automatique.

00:10:29.832 --> 00:10:34.630
En fait, la plupart des caméras
enregistrent les images de haut en bas.

00:10:34.630 --> 00:10:40.332
Si l'objet bouge pendant l'enregistrement
d'une seule image,

00:10:40.344 --> 00:10:43.061
il y a un léger délai
entre chaque ligne d'enregistrement.

00:10:43.061 --> 00:10:46.218
Ça provoque d'imperceptibles artéfacts

00:10:46.218 --> 00:10:49.701
qui sont encodés 
dans chaque plan de la vidéo.

00:10:49.701 --> 00:10:53.507
En analysant ces artéfacts,

00:10:53.507 --> 00:10:58.122
on peut récupérer le son en utilisant
une version modifiée de notre algorithme.

00:10:58.122 --> 00:11:00.034
Voici une autre expérience.

00:11:00.034 --> 00:11:01.939
Nous avons filmé un sachet de bonbons,

00:11:01.939 --> 00:11:04.000
à côté d'un ampli
qui joue la même chanson :

00:11:04.000 --> 00:11:06.442
« Mary Had a Little Lamb »

00:11:06.442 --> 00:11:10.645
Mais cette fois-ci, nous avons utilisé
une caméra ordinaire.

00:11:10.645 --> 00:11:13.819
Je vais vous laisser écouter le son
que nous avons récupéré.

00:11:13.819 --> 00:11:15.869
Le son sera un peu distordu,

00:11:15.869 --> 00:11:19.514
mais essayez quand même de voir 
si vous pouvez reconnaître la musique.

00:11:19.514 --> 00:11:25.946
(Audio: « Mary Had a Little Lamb »)

00:11:37.718 --> 00:11:40.992
Certes, le son est déformé.

00:11:40.992 --> 00:11:45.378
Mais ce qui est extraordinaire,
c'est que nous avons pu réaliser cela

00:11:45.378 --> 00:11:48.004
avec un appareil disponible
en grande surface

00:11:48.004 --> 00:11:50.222
et utiliser facilement.

00:11:51.122 --> 00:11:52.485
À ce stade,

00:11:52.485 --> 00:11:54.459
les gens qui découvrent notre travail,

00:11:54.459 --> 00:11:57.872
pensent souvent à la surveillance.

00:11:57.872 --> 00:12:01.197
En étant honnête,
ce n'est pas difficile d'imaginer

00:12:01.197 --> 00:12:04.420
comment utiliser cette technologie 
pour espionner autrui.

00:12:04.420 --> 00:12:07.927
Mais il y a déjà sur le marché
beaucoup de technologies matures

00:12:07.927 --> 00:12:09.946
dans le domaine de la surveillance.

00:12:09.946 --> 00:12:12.036
On utilise des lasers

00:12:12.036 --> 00:12:15.749
pour intercepter des conversations
via des objets, depuis des décennies.

00:12:15.749 --> 00:12:18.003
Ce qui est fondamentalement nouveau ici,

00:12:18.003 --> 00:12:19.853
et qui distingue notre technologie,

00:12:19.853 --> 00:12:23.738
c'est notre capacité à percevoir
les vibrations des objets.

00:12:23.738 --> 00:12:27.151
Ça nous donne un nouvel objectif
pour observer le monde.

00:12:27.151 --> 00:12:28.661
Et on peut l'utiliser

00:12:28.661 --> 00:12:33.560
pour étudier les forces comme le son
qui causent des vibrations sur un objet,

00:12:33.560 --> 00:12:36.671
mais on peut aussi 
étudier l'objet lui-même.

00:12:36.671 --> 00:12:38.668
Je vais prendre un peu de recul

00:12:38.668 --> 00:12:42.917
pour réfléchir en quoi ça peut modifier
les manières dont nous utilisons la vidéo.

00:12:42.917 --> 00:12:46.470
En général, on utilise la vidéo
pour regarder des choses.

00:12:46.470 --> 00:12:48.792
Mais je viens de vous montrer 
comment l'utiliser

00:12:48.792 --> 00:12:50.649
pour écouter des choses.

00:12:50.649 --> 00:12:54.620
Il y a une autre manière importante
d'étudier le monde :

00:12:54.620 --> 00:12:56.895
en interagissant avec lui.

00:12:56.895 --> 00:13:00.006
On appuie, on tire, 
ou donne des petits coups sur les objets.

00:13:00.006 --> 00:13:03.187
On peut les secouer 
et voir ce qui se passe.

00:13:03.187 --> 00:13:07.460
La vidéo ne nous permet pas encore
de faire tout ça.

00:13:07.460 --> 00:13:09.596
En tout cas, de manière traditionnelle.

00:13:09.596 --> 00:13:11.396
Je vous montre mes nouveaux travaux.

00:13:11.396 --> 00:13:14.252
Ils reposent sur une idée que j'ai eue
il y a quelques mois.

00:13:14.252 --> 00:13:17.513
C'est la première fois
que je les dévoile en public.

00:13:17.513 --> 00:13:22.877
L'idée de base est d'utiliser 
les vibrations dans la vidéo

00:13:22.877 --> 00:13:27.358
pour saisir des objets
de manière à interagir avec eux,

00:13:27.358 --> 00:13:30.290
et voir comment ils réagissent.

00:13:31.120 --> 00:13:32.884
Voilà un objet.

00:13:32.884 --> 00:13:36.716
C'est une statue en fil de fer,
qui a la forme d'un humain.

00:13:36.716 --> 00:13:39.804
On va la filmer avec une caméra normale.

00:13:39.804 --> 00:13:41.928
La caméra n'a rien de spécial.

00:13:41.928 --> 00:13:44.889
J'ai même essayé avec la caméra
de mon smartphone.

00:13:44.889 --> 00:13:47.141
Nous voulons observer
les vibrations de l'objet.

00:13:47.141 --> 00:13:48.274
Et pour cela,

00:13:48.274 --> 00:13:51.620
on va donner des petits coups 
sur la surface où elle est déposée,

00:13:51.620 --> 00:13:53.758
pendant l'enregistrement.

00:13:59.398 --> 00:14:03.069
C'est tout. 5 secondes de vidéo normale,

00:14:03.069 --> 00:14:05.205
on donne des coups sur le plan,

00:14:05.205 --> 00:14:08.718
et on va utiliser les vibrations 
enregistrées par la vidéo

00:14:08.718 --> 00:14:13.262
pour étudier les propriétés 
structurelles et matérielles de l'objet.

00:14:13.262 --> 00:14:18.096
On va ensuite les utiliser pour créer
quelque chose de neuf et interactif.

00:14:25.073 --> 00:14:27.519
En voici le résultat.

00:14:27.519 --> 00:14:29.748
On dirait une image normale.

00:14:29.748 --> 00:14:32.859
Mais ce n'est pas le cas.
Ce n'est pas non plus une vidéo,

00:14:32.859 --> 00:14:35.227
parce que maintenant,
je peux prendre ma souris,

00:14:35.227 --> 00:14:38.086
et interagir avec l'objet.

00:14:44.936 --> 00:14:46.489
Ce que vous voyez ici,

00:14:46.489 --> 00:14:49.615
c'est une simulation 
des réactions de cet objet

00:14:49.615 --> 00:14:54.073
lorsqu'il subit des forces
qu'on n'a pas encore vues.

00:14:54.073 --> 00:14:58.345
Nous avons créé cela
à partir d'une vidéo de 5 secondes.

00:14:58.345 --> 00:15:03.964
(Applaudissements)

00:15:09.421 --> 00:15:12.558
C'est un moyen puissant 
d'observer le monde,

00:15:12.558 --> 00:15:15.620
parce qu'il nous permet de prédire
comment les objets vont réagir

00:15:15.620 --> 00:15:17.443
dans des situations nouvelles.

00:15:17.443 --> 00:15:20.916
On pourrait imaginer, par exemple,
regarder un vieux pont,

00:15:20.916 --> 00:15:24.443
en se demandant ce qui va se passer,
quand je vais le traverser en voiture.

00:15:24.443 --> 00:15:27.276
Le pont va-t-il supporter ce poids ?

00:15:27.276 --> 00:15:30.050
Et vous vous poseriez cette question,
sans doute,

00:15:30.050 --> 00:15:33.988
avant de devoir traverser 
un tel vieux pont.

00:15:33.988 --> 00:15:37.260
Bien entendu, 
la technologie a ses limites,

00:15:37.260 --> 00:15:39.722
tout comme celle 
avec le microphone visuel.

00:15:39.722 --> 00:15:42.903
Mais nous avons constaté
que ça fonctionne dans beaucoup de cas,

00:15:42.903 --> 00:15:44.778
même des cas inattendus,

00:15:44.778 --> 00:15:47.546
surtout si on utilise 
des vidéos plus longues.

00:15:47.546 --> 00:15:50.054
Par exemple,
voici une de mes vidéos.

00:15:50.054 --> 00:15:52.353
C'est un arbuste 
à côté de mon appartement.

00:15:52.353 --> 00:15:55.441
Je n'ai pas touché à l'arbuste.

00:15:55.441 --> 00:15:58.146
J'ai pris une vidéo d'une minute.

00:15:58.146 --> 00:16:01.524
Un vent léger a provoqué 
suffisamment de vibrations

00:16:01.524 --> 00:16:05.519
pour nous permettre 
de développer cette simulation.

00:16:07.909 --> 00:16:13.412
(Applaudissements)

00:16:13.412 --> 00:16:16.384
On pourrait aussi imaginer 
qu'un réalisateur

00:16:16.384 --> 00:16:19.093
utilise cette technique pour contrôler,
par exemple,

00:16:19.093 --> 00:16:23.025
la force ou la direction du vent
après avoir tourné la scène.

00:16:24.810 --> 00:16:29.345
Dans ce cas-ci, 
on a filmé une tenture.

00:16:29.345 --> 00:16:33.474
Il n'y a aucun mouvement perceptible 
dans cette vidéo.

00:16:33.474 --> 00:16:36.399
Mais un enregistrement de deux minutes,

00:16:36.399 --> 00:16:39.317
a permis d'analyser suffisamment
de mouvements imperceptibles

00:16:39.317 --> 00:16:43.249
causés par des courants d'air 
naturels dans la pièce

00:16:43.249 --> 00:16:46.244
pour créer cette simulation.

00:16:48.705 --> 00:16:50.609
Paradoxalement,

00:16:50.609 --> 00:16:53.697
on est habitué à ce genre d'interactions

00:16:53.697 --> 00:16:56.344
avec des objets virtuels,

00:16:56.344 --> 00:16:59.641
dans les jeux vidéo ou les modèles 3D.

00:16:59.641 --> 00:17:04.045
Mais pouvoir capter des informations
sur des objets réels, dans le monde réel

00:17:04.045 --> 00:17:06.862
en utilisant une vidéo normale,

00:17:06.862 --> 00:17:10.664
est quelque chose de tout à fait innovant,
avec un grand potentiel.

00:17:10.664 --> 00:17:14.801
Voici les membres formidables
qui ont contribué à ces projets.

00:17:16.057 --> 00:17:21.653
(Applaudissements)

00:17:24.486 --> 00:17:27.876
Ce que je vous ai montré aujourd'hui
n'est que le début.

00:17:27.876 --> 00:17:29.989
On vient juste de commencer

00:17:29.989 --> 00:17:33.261
à découvrir ce qui est possible 
de réaliser avec ce genre d'images.

00:17:33.261 --> 00:17:35.597
Ça nous donne de nouvelles méthodes

00:17:35.597 --> 00:17:40.066
pour filmer notre environnement
avec des technologies accessibles.

00:17:40.066 --> 00:17:41.995
À l'avenir,

00:17:41.995 --> 00:17:44.032
ces technologies pourront nous enseigner

00:17:44.032 --> 00:17:46.683
des choses fascinantes sur le monde.

00:17:46.683 --> 00:17:48.424
Merci.

00:17:48.424 --> 00:17:54.531
(Applaudissements)

