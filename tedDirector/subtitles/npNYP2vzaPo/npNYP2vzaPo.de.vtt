WEBVTT
Kind: captions
Language: de

00:00:00.000 --> 00:00:07.000
Übersetzung: Lesley-Ann Mathis
Lektorat: Jo Pi

00:00:13.373 --> 00:00:17.192
Die meisten halten Bewegung 
für etwas Visuelles.

00:00:17.889 --> 00:00:19.977
Wenn ich über diese Bühne laufe

00:00:19.977 --> 00:00:22.977
oder beim Sprechen 
Gesten mit den Händen mache,

00:00:22.977 --> 00:00:25.788
ist das eine Bewegung, 
die Sie sehen können.

00:00:26.255 --> 00:00:31.737
Aber es gibt wichtige Bewegungen,
die das menschliche Auge nicht sieht.

00:00:31.737 --> 00:00:34.935
In den letzten paar Jahren
haben wir herausgefunden,

00:00:34.935 --> 00:00:37.715
dass Kameras diese 
Bewegungen sehen können,

00:00:37.715 --> 00:00:40.305
auch wenn es die Menschen nicht können.

00:00:40.305 --> 00:00:42.496
Ich möchte Ihnen zeigen, 
was ich meine.

00:00:42.717 --> 00:00:46.339
Links sehen Sie 
das Video eines Handgelenks

00:00:46.339 --> 00:00:49.486
und rechts das Video 
eines schlafenden Kleinkinds,

00:00:49.486 --> 00:00:52.632
aber wenn ich Ihnen nicht gesagt hätte,
dass das Videos sind,

00:00:52.632 --> 00:00:56.393
hätten Sie vielleicht angenommen, 
Sie würden zwei normale Bilder anschauen,

00:00:56.393 --> 00:00:58.065
denn in beiden Fällen

00:00:58.065 --> 00:01:01.592
scheinen diese Videos 
völlig still zu stehen.

00:01:02.175 --> 00:01:05.960
Aber in Wirklichkeit ist hier jede Menge 
subtile Bewegung im Gange

00:01:05.960 --> 00:01:08.622
und wenn Sie das Handgelenk 
links berühren könnten,

00:01:08.622 --> 00:01:10.448
dann würden Sie den Pulsschlag spüren,

00:01:10.448 --> 00:01:12.933
und wenn Sie das Kleinkind 
rechts halten würden,

00:01:12.953 --> 00:01:15.482
dann würden Sie das Heben
seiner Brust spüren,

00:01:15.482 --> 00:01:17.014
wenn es atmet.

00:01:17.772 --> 00:01:21.339
Diese Bewegungen sind
von großer Bedeutung,

00:01:21.339 --> 00:01:24.681
aber normalerweise
für uns nicht sichtbar.

00:01:24.681 --> 00:01:26.474
Also müssen wir sie

00:01:26.474 --> 00:01:30.207
durch direkten Kontakt, 
durch Berührung, feststellen.

00:01:30.998 --> 00:01:32.262
Aber vor ein paar Jahren

00:01:32.262 --> 00:01:34.036
haben meine Kollegen am MIT

00:01:34.036 --> 00:01:37.036
ein sogenanntes 
Bewegungs-Mikroskop entwickelt,

00:01:37.036 --> 00:01:41.044
eine Software, die diese subtilen 
Bewegungen in einem Video finden

00:01:41.054 --> 00:01:44.966
und verstärken kann, sodass sie groß genug
für das menschliche Auge sind.

00:01:44.966 --> 00:01:48.891
Wenn wir also diese Software 
auf das Video links anwenden,

00:01:48.901 --> 00:01:52.146
können wir den Pulsschlag
am Handgelenk erkennen

00:01:52.146 --> 00:01:53.873
und wenn wir den Puls zählen würden,

00:01:53.873 --> 00:01:57.059
könnten wir sogar die Herzfrequenz 
dieser Person herausfinden.

00:01:57.109 --> 00:02:00.160
Wenn wir die Software 
auf das Video rechts anwenden würden,

00:02:00.161 --> 00:02:03.385
können wir jeden Atemzug erkennen, 
den das Kleinkind macht,

00:02:03.385 --> 00:02:07.744
und wir könnten ohne Berührung 
seine Atmung überwachen.

00:02:08.884 --> 00:02:13.842
Diese Technologie ist sehr beeindruckend, 
da wir diese Phänomene,

00:02:13.842 --> 00:02:16.599
die wir bisher durch 
Berührung erfahren mussten,

00:02:16.603 --> 00:02:20.076
nun visuell non-invasiv erfassen können.

00:02:21.104 --> 00:02:25.525
Vor ein paar Jahren begann ich, mit 
den Erfindern der Software zu arbeiten

00:02:25.525 --> 00:02:28.882
und wir beschlossen, 
eine verrückte Idee zu verfolgen.

00:02:28.882 --> 00:02:31.575
Wir fanden es cool, 
mit Hilfe einer Software

00:02:31.575 --> 00:02:34.710
winzige Bewegungen wie diese
sichtbar zu machen

00:02:34.710 --> 00:02:39.168
und es beinahe als eine Erweiterung 
unseres Tastsinnes zu sehen.

00:02:39.168 --> 00:02:43.867
Aber könnten wir auch das Gleiche 
mit unserem Hörvermögen machen?

00:02:44.508 --> 00:02:49.173
Was, wenn wir mit einem Video 
Schallschwingungen aufzeichnen könnten,

00:02:49.173 --> 00:02:52.000
die einfach eine andere Form 
von Bewegung sind,

00:02:52.000 --> 00:02:55.736
und alles was wir sehen, 
in ein Mikrofon verwandeln?

00:02:56.236 --> 00:02:58.207
Das mag eine seltsame Idee sein,

00:02:58.207 --> 00:03:00.793
also möchte ich 
den Zusammenhang erklären.

00:03:01.523 --> 00:03:05.011
Klassische Mikrofone konvertieren Bewegung

00:03:05.011 --> 00:03:08.610
einer inneren Membran
in ein elektrisches Signal.

00:03:08.610 --> 00:03:12.928
Diese Membran 
bewegt sich bei jedem Laut,

00:03:12.928 --> 00:03:17.735
sodass seine Bewegung 
als Ton aufgezeichnet werden kann.

00:03:17.735 --> 00:03:21.403
Aber Schall regt alle Gegenstände 
zur Vibration an.

00:03:21.403 --> 00:03:26.883
Diese Vibrationen sind gewöhnlich zu 
subtil und schnell für unser Auge.

00:03:26.883 --> 00:03:30.621
Was aber, wenn wir sie mit einer 
Hochgeschwindigkeitskamera aufzeichnen

00:03:30.621 --> 00:03:34.197
und eine Software benutzen,
um winzige Bewegungen

00:03:34.197 --> 00:03:36.287
aus unserem Video zu entnehmen

00:03:36.287 --> 00:03:41.081
und diese Bewegungen zu analysieren, 
um den auslösenden Ton zu entdecken?

00:03:41.859 --> 00:03:47.738
So könnten wir sichtbare Gegenstände
in visuelle Mikrofone umwandeln.

00:03:49.080 --> 00:03:51.263
Also wir haben wir das ausprobiert

00:03:51.263 --> 00:03:53.190
und das war eines unserer Experimente.

00:03:53.190 --> 00:03:56.139
Wir filmten eine Topfpflanze,
die Sie hier rechts sehen,

00:03:56.139 --> 00:03:58.577
mit einer Hochgeschwindigkeitskamera,

00:03:58.577 --> 00:04:02.106
während aus einem Lautsprecher 
das folgende Lied spielte:

00:04:02.275 --> 00:04:10.465
(Musik: "Mary Had a Little Lamb")

00:04:11.820 --> 00:04:14.644
Das ist das Video, 
das wir aufgezeichnet haben.

00:04:14.644 --> 00:04:18.568
Wir haben es mit 1 000 Bildern
pro Sekunde aufgezeichnet,

00:04:18.568 --> 00:04:20.890
aber selbst wenn Sie
sehr genau hinschauen,

00:04:20.890 --> 00:04:23.221
sehen sie nur ein paar Blätter,

00:04:23.221 --> 00:04:25.906
die einfach dort sind und nichts tun,

00:04:25.906 --> 00:04:30.712
weil unser Schall diese Blätter 
gerade mal einen Mikrometer bewegt hat.

00:04:31.103 --> 00:04:35.379
Das ist ein Zehntausendstel 
eines Zentimeters,

00:04:35.379 --> 00:04:39.945
das umfasst etwas zwischen einem 
Hundertstel und einem Tausendstel Pixel

00:04:39.945 --> 00:04:41.834
in diesem Bild.

00:04:41.881 --> 00:04:44.768
Sie können also so viel blinzeln 
wie Sie wollen,

00:04:44.768 --> 00:04:48.803
aber diese kleine Bewegung 
ist so gut wie unsichtbar.

00:04:49.667 --> 00:04:53.824
Aber in Wahrheit kann etwas unsichtbar

00:04:53.824 --> 00:04:56.633
und dennoch numerisch bedeutend sein,

00:04:56.633 --> 00:04:58.635
denn mit den richtigen Algorithmen

00:04:58.635 --> 00:05:02.322
können wir bei diesem stummen, 
scheinbar bewegungslosen Video

00:05:02.322 --> 00:05:04.389
den Ton wiederherstellen.

00:05:04.690 --> 00:05:12.074
(Musik: "Mary Had a Little Lamb")

00:05:12.074 --> 00:05:17.902
(Applaus)

00:05:22.058 --> 00:05:23.997
Wie ist das möglich?

00:05:23.997 --> 00:05:28.341
Wie können wir so viele Informationen
aus so wenig Bewegung herausbekommen?

00:05:28.341 --> 00:05:33.702
Nehmen wir an, dass diese Blätter sich 
nur einen einzigen Mikrometer bewegen

00:05:33.702 --> 00:05:38.620
und dass das unser Bild nur 
um ein tausendstel Pixel bewegt.

00:05:39.269 --> 00:05:41.841
Das mag nicht viel erscheinen,

00:05:41.841 --> 00:05:43.837
doch ein einziges Bild eines Videos

00:05:43.837 --> 00:05:47.094
besteht aus hunderttausenden Pixeln

00:05:47.094 --> 00:05:50.548
und wenn wir all diese 
winzigen Bewegungen

00:05:50.548 --> 00:05:52.846
aus dem ganzen Bild kombinieren,

00:05:52.846 --> 00:05:55.469
kann sich ein tausendstel Pixel auf einmal

00:05:55.469 --> 00:05:58.484
zu etwas Bedeutendem aufaddieren.

00:05:58.870 --> 00:06:02.875
Ehrlich gesagt waren wir bei 
dieser Entdeckung völlig aus dem Häuschen.

00:06:02.875 --> 00:06:04.825
(Gelächter)

00:06:04.825 --> 00:06:08.078
Aber sogar mit dem richtigen Algorithmus

00:06:08.078 --> 00:06:11.695
fehlte uns immer noch 
ein sehr wichtiges Puzzlestück.

00:06:11.695 --> 00:06:15.309
Es gibt sehr viele Parameter, 
die einen Einfluss darauf haben,

00:06:15.309 --> 00:06:17.496
wie gut diese Technik funktioniert.

00:06:17.496 --> 00:06:20.500
Es hängt von dem Gegenstand 
und seiner Entfernung ab,

00:06:20.500 --> 00:06:22.894
von der Kamera und der benutzten Linse,

00:06:22.894 --> 00:06:27.275
wie viel Licht auf den Gegenstand fällt 
und wie laut der Ton ist.

00:06:27.945 --> 00:06:31.320
Und sogar mit dem richtigen Algorithmus

00:06:31.320 --> 00:06:34.710
mussten wir sehr vorsichtig
in unseren ersten Experimenten sein,

00:06:34.710 --> 00:06:37.132
denn bei nur einem falsch
eingestellten Parameter

00:06:37.132 --> 00:06:39.940
gibt es keine Möglichkeit, 
die Fehlerquelle zu finden.

00:06:39.940 --> 00:06:42.217
Wir hätten nur Rauschen gehört.

00:06:42.217 --> 00:06:45.437
Viele unserer ersten
Experimente sahen so aus.

00:06:45.437 --> 00:06:47.643
Hier bin ich

00:06:47.643 --> 00:06:51.683
und unten links können Sie unsere
Hochgeschwindigkeitskamera sehen,

00:06:51.683 --> 00:06:53.866
die auf eine Tüte Chips zeigt

00:06:53.866 --> 00:06:56.815
und das Ganze wird 
mit hellen Lampen beleuchtet.

00:06:56.815 --> 00:07:01.180
Wie bereits gesagt, mussten wir 
zu Beginn sehr vorsichtig sein,

00:07:01.180 --> 00:07:03.688
und so ging es dann weiter:

00:07:03.688 --> 00:07:07.449
(Video) Abe Davis: 3, 2, 1, los.

00:07:07.449 --> 00:07:12.836
Mary had a little lamb!
Little lamb! Little lamb!

00:07:12.836 --> 00:07:16.126
(Gelächter)

00:07:17.336 --> 00:07:20.370
Dieses Experiment
sieht völlig lächerlich aus.

00:07:20.370 --> 00:07:21.938
(Gelächter)

00:07:21.938 --> 00:07:24.283
Also, ich schreie eine Tüte Chips an --

00:07:24.283 --> 00:07:25.834
(Gelächter)

00:07:25.834 --> 00:07:27.951
und wir strahlen sie mit so viel Licht an,

00:07:27.951 --> 00:07:32.430
dass wir die erste Tüte buchstäblich
geschmolzen haben.

00:07:32.525 --> 00:07:35.799
Aber so lächerlich das Experiment scheint,

00:07:35.799 --> 00:07:37.587
es war tatsächlich sehr wichtig,

00:07:37.587 --> 00:07:40.513
denn wir waren in der Lage,
diese Laute wiederherzustellen.

00:07:40.513 --> 00:07:45.225
(Ton) Mary had a little lamb!
Little lamb! Little lamb!

00:07:45.225 --> 00:07:49.313
(Applaus)

00:07:49.313 --> 00:07:51.194
Das war sehr bedeutend,

00:07:51.194 --> 00:07:55.313
weil wir zum ersten Mal 
eine verständliche menschliche Sprache

00:07:55.314 --> 00:07:58.815
aus einem stummen Video eines Gegenstandes
wiederherstellen konnten.

00:07:58.815 --> 00:08:00.456
Das gab uns einen Anhaltspunkt

00:08:00.456 --> 00:08:04.027
und wir konnten das Experiment 
schrittweise verändern,

00:08:04.106 --> 00:08:07.911
indem wir andere Gegenstände benutzten 
oder sie weiter weg bewegten

00:08:07.911 --> 00:08:11.271
und weniger Licht 
oder leisere Töne benutzten.

00:08:11.887 --> 00:08:14.761
Wir analysierten alle diese Experimente,

00:08:14.761 --> 00:08:18.503
bis wir die Grenzen 
unserer Technik begriffen,

00:08:18.503 --> 00:08:22.679
denn dann wussten wir,
wie wir sie überschreiten konnten.

00:08:22.679 --> 00:08:25.860
Das führte zu folgendem Experiment,

00:08:25.860 --> 00:08:28.599
bei dem ich wieder
zu einer Tüte Chips spreche,

00:08:28.599 --> 00:08:33.429
aber dieses Mal haben wir die Kamera 
etwa 5 Meter wegbewegt,

00:08:33.429 --> 00:08:36.262
nach draußen hinter 
eine schalldichte Scheibe

00:08:36.262 --> 00:08:39.775
und das Ganze wird nur
von Sonnenlicht beleuchtet.

00:08:40.529 --> 00:08:43.004
Hier das Video,
das wir aufgezeichnet haben.

00:08:44.450 --> 00:08:49.009
So hat es sich in der Nähe 
der Tüte Chips angehört:

00:08:49.009 --> 00:08:54.047
(Ton) Mary had a little lamb
whose fleece was white as snow,

00:08:54.047 --> 00:08:59.666
and everywhere that Mary went,
that lamb was sure to go.

00:08:59.666 --> 00:09:03.683
AD: Das haben wir aus dem 
stummen Video wiedergewonnen,

00:09:03.683 --> 00:09:06.118
das wir außerhalb des Fensters
aufgezeichnet hatten.

00:09:06.118 --> 00:09:10.463
(Ton) Mary had a little lamb
whose fleece was white as snow,

00:09:10.463 --> 00:09:15.920
and everywhere that Mary went,
that lamb was sure to go.

00:09:15.920 --> 00:09:20.141
(Applaus)

00:09:22.421 --> 00:09:25.963
AD: Es gibt noch andere Möglichkeiten, 
die Grenzen zu erweitern.

00:09:25.963 --> 00:09:27.761
Das ist ein ruhigeres Experiment,

00:09:27.761 --> 00:09:29.901
bei dem wir Kopfhörer filmten,

00:09:29.901 --> 00:09:31.871
die in einen Laptop eingesteckt waren,

00:09:31.871 --> 00:09:35.981
mit dem Ziel, die Musik wieder
herzustellen, die auf dem Laptop lief,

00:09:35.981 --> 00:09:38.280
nur von diesem stummen Video

00:09:38.280 --> 00:09:40.787
dieser zwei Mini-Kopfhörer.

00:09:40.787 --> 00:09:42.970
Auch das gelang uns so gut,

00:09:42.970 --> 00:09:45.931
dass das Ergebnis sogar von 
einer Musiksoftware erkannt wurde.

00:09:45.931 --> 00:09:47.842
(Gelächter)

00:09:49.191 --> 00:09:59.225
(Musik: "Under Pressure" von Queen)

00:10:01.615 --> 00:10:06.584
(Applaus)

00:10:06.584 --> 00:10:11.135
Wir können die Dinge vorantreiben, 
in dem wir die Hardware ändern.

00:10:11.135 --> 00:10:13.706
Denn die bisher gezeigten Experimente

00:10:13.706 --> 00:10:16.458
waren mit einer 
Hochgeschwindigkeitskamera aufgezeichnet,

00:10:16.458 --> 00:10:18.797
die ein Video 100-mal schneller 
aufzeichnen kann

00:10:18.797 --> 00:10:20.724
als die meisten Handys,

00:10:20.724 --> 00:10:22.903
aber wir haben auch einen Weg gefunden,

00:10:22.903 --> 00:10:25.763
diese Technik mit 
normaleren Kameras zu nutzen.

00:10:25.763 --> 00:10:29.832
Wir nutzen den sogenannten 
Rolling-Shutter-Effekt aus.

00:10:29.832 --> 00:10:34.630
Die meisten Kameras zeichnen 
Bilder zeilenweise auf

00:10:34.630 --> 00:10:40.332
und wenn sich ein Objekt 
gleichzeitig bewegt,

00:10:40.344 --> 00:10:43.261
gibt es eine kurze Verzögerung 
zwischen den einzelnen Zeilen,

00:10:43.261 --> 00:10:46.228
was leichte Bildstörungen verursacht,

00:10:46.228 --> 00:10:49.701
die in den Einzelbildern 
eines Videos kodiert werden.

00:10:49.701 --> 00:10:53.507
Wir fanden heraus, dass wir beim 
Analysieren der Bildstörungen

00:10:53.507 --> 00:10:58.122
den Ton mit einem angepassten Algorithmus 
wiederherstellen können.

00:10:58.122 --> 00:11:00.022
Das ist unser Experiment,

00:11:00.032 --> 00:11:02.334
bei dem wir eine Tüte 
Süßigkeiten gefilmt haben,

00:11:02.334 --> 00:11:03.939
während ein Lautsprecher das Lied

00:11:03.939 --> 00:11:06.430
"Mary Had a Little Lamb" spielte.

00:11:06.430 --> 00:11:10.652
Aber dieses Mal benutzen wir 
nur eine alltägliche Kamera

00:11:10.652 --> 00:11:14.185
und ich werde Ihnen den Klang vorspielen,
den wir wiederherstellen konnten.

00:11:14.185 --> 00:11:15.939
Es wird dieses Mal verzerrt klingen,

00:11:15.939 --> 00:11:20.209
aber vielleicht können Sie 
das Lied noch erkennen.

00:11:20.209 --> 00:11:25.065
(Ton: "Mary Had a Little Lamb")

00:11:37.507 --> 00:11:40.947
Zugegeben, es klingt verzerrt,

00:11:40.977 --> 00:11:43.762
aber das Beeindruckende hier ist,

00:11:43.762 --> 00:11:46.548
dass wir das mit Geräten gemacht haben,

00:11:46.548 --> 00:11:51.074
die Sie ganz normal in einem 
Elektronik-Fachgeschäft kaufen können.

00:11:51.108 --> 00:11:52.482
An dieser Stelle

00:11:52.482 --> 00:11:54.455
sehen viele Leute diese Arbeit

00:11:54.455 --> 00:11:57.879
und denken sofort an Überwachung.

00:11:57.879 --> 00:12:00.972
Und um ehrlich zu sein,
ist es leicht vorstellbar,

00:12:00.972 --> 00:12:04.437
wie man diese Technik 
zum Ausspionieren nutzen könnte.

00:12:04.437 --> 00:12:06.630
Aber Sie sollten bedenken,

00:12:06.630 --> 00:12:10.227
dass es bereits sehr gute 
Überwachungstechniken gibt.

00:12:10.227 --> 00:12:13.246
Tatsächlich benutzt man 
schon seit Jahrzehnten Laser,

00:12:13.246 --> 00:12:15.686
um Objekte aus Entfernung abzuhören.

00:12:15.686 --> 00:12:19.455
Aber wirklich neu und anders 
an dieser Technik ist,

00:12:19.463 --> 00:12:23.753
dass wir die Vibrationen eines 
Gegenstandes verbildlichen können,

00:12:23.753 --> 00:12:27.148
was uns eine neue Linse gibt, 
durch die wir die Welt betrachten können.

00:12:27.148 --> 00:12:28.791
Mit dieser Linse können wir

00:12:28.791 --> 00:12:33.571
nicht mehr nur über Kräfte wie Schall 
lernen, die Gegenstände vibrieren lassen,

00:12:33.571 --> 00:12:36.970
sondern auch mehr 
über den Gegenstand selbst.

00:12:36.980 --> 00:12:39.195
Deshalb möchte ich 
einen Schritt zurückgehen

00:12:39.195 --> 00:12:40.565
und darüber nachdenken,

00:12:40.565 --> 00:12:43.068
wie das unsere Nutzung von Videos 
verändern könnte.

00:12:43.068 --> 00:12:46.437
Normalerweise verwenden wir Videos,
um Dinge anzuschauen,

00:12:46.437 --> 00:12:48.430
und ich habe Ihnen gerade gezeigt,

00:12:48.430 --> 00:12:50.652
wie wir mit ihnen Dingen zuhören können.

00:12:50.652 --> 00:12:54.619
Aber wir lernen auch viel über die Welt,

00:12:54.619 --> 00:12:56.900
indem wir mit ihr interagieren.

00:12:56.900 --> 00:13:00.015
Wir ziehen, drücken, 
stoßen und stupsen Dinge.

00:13:00.015 --> 00:13:03.186
Wir schütteln Dinge und
warten ab, was passiert.

00:13:03.186 --> 00:13:07.437
Mit einem Video können wir das nicht tun,

00:13:07.451 --> 00:13:09.576
zumindest nicht bisher.

00:13:09.576 --> 00:13:12.095
Deshalb möchte ich Ihnen 
unsere neuste Arbeit zeigen,

00:13:12.095 --> 00:13:15.006
die auf einer Idee basiert, die
ich vor wenigen Monaten hatte

00:13:15.006 --> 00:13:17.846
und hier zum ersten Mal
in der Öffentlichkeit zeige.

00:13:17.846 --> 00:13:22.374
Die Grundidee ist, dass wir die 
Vibrationen in einem Video nutzen,

00:13:22.374 --> 00:13:27.394
um Objekte so aufzuzeichnen,
dass wir mit ihnen interagieren können

00:13:27.394 --> 00:13:31.043
und sehen, wie sie auf uns reagieren.

00:13:31.043 --> 00:13:32.492
Das hier ist ein Gegenstand,

00:13:32.492 --> 00:13:36.809
in diesem Fall eine 
menschenförmige Drahtfigur,

00:13:36.809 --> 00:13:39.796
und wir zeichnen den Gegenstand 
mit einer normalen Kamera auf.

00:13:39.796 --> 00:13:41.384
Die Kamera ist nichts Besonderes.

00:13:41.384 --> 00:13:44.894
Um ehrlich zu sein, habe ich das zuvor
mit meiner Handykamera gemacht.

00:13:44.894 --> 00:13:47.149
Aber wir wollen den Gegenstand 
schwingen sehen,

00:13:47.149 --> 00:13:51.624
deshalb schlagen wir einfach leicht 
auf die Oberfläche, auf der er steht,

00:13:51.624 --> 00:13:54.090
während wir das Video aufzeichnen.

00:13:59.390 --> 00:14:03.078
Das ist alles: fünf Sekunden 
eines normalen Videos,

00:14:03.078 --> 00:14:05.209
während wir auf die Oberfläche schlagen

00:14:05.209 --> 00:14:08.725
und wir nutzen
die Schwingungen im Video,

00:14:08.725 --> 00:14:13.248
um etwas über die Eigenschaften 
unseres Gegenstandes zu lernen,

00:14:13.248 --> 00:14:19.262
und mit diesen Informationen schaffen wir
etwas Neues und Interaktives.

00:14:24.862 --> 00:14:27.516
Das ist dabei herausgekommen.

00:14:27.516 --> 00:14:29.429
Es sieht wie ein gewöhnliches Bild aus,

00:14:29.429 --> 00:14:32.808
aber es ist weder ein Bild noch ein Video,

00:14:32.808 --> 00:14:35.229
denn ich kann jetzt meine Maus nehmen

00:14:35.229 --> 00:14:38.727
und anfangen, mit dem Gegenstand
zu interagieren.

00:14:44.953 --> 00:14:48.472
Hier sehen Sie eine Simulation,

00:14:48.472 --> 00:14:51.689
wie dieses Objekt auf 
neue Kräfte reagieren würde,

00:14:51.689 --> 00:14:54.135
auf die es noch nie getroffen ist,

00:14:54.135 --> 00:14:58.203
und all das haben wir nur aus 
diesem 5-Sekunden-Video geschaffen.

00:14:59.043 --> 00:15:03.896
(Applaus)

00:15:09.393 --> 00:15:12.611
Dieser Blick auf die Welt
gibt uns viele Möglichkeiten,

00:15:12.611 --> 00:15:14.518
denn er erlaubt uns vorherzusagen,

00:15:14.518 --> 00:15:17.460
wie Gegenstände auf 
neue Situationen reagieren werden.

00:15:17.460 --> 00:15:20.913
Es ist vorstellbar, dass man sich
bei einer alten Brücke fragt,

00:15:20.913 --> 00:15:24.446
was passieren würde,
wie sie standhalten würde,

00:15:24.446 --> 00:15:26.773
wenn ich mit meinem Auto darüber fahre.

00:15:26.773 --> 00:15:30.216
Auf diese Frage wüssten Sie 
vermutlich gerne die Antwort,

00:15:30.216 --> 00:15:34.100
bevor Sie über die Brücke fahren.

00:15:34.100 --> 00:15:37.260
Natürlich wird diese Technik
ihre Grenzen haben,

00:15:37.260 --> 00:15:39.720
genauso wie bei dem visuellen Mikrofon,

00:15:39.720 --> 00:15:42.952
aber wir fanden heraus, dass es 
in vielen Situationen funktioniert,

00:15:42.952 --> 00:15:44.813
in denen man es nicht erwarten würde,

00:15:44.813 --> 00:15:47.548
besonders wenn man längere Videos benutzt.

00:15:47.548 --> 00:15:49.616
Das ist zum Beispiel ein Video,

00:15:49.616 --> 00:15:52.354
das ich von einem Busch vor 
meiner Wohnung gefilmt habe,

00:15:52.354 --> 00:15:55.423
und ich habe nichts mit dem Busch gemacht,

00:15:55.423 --> 00:15:58.301
außer dass ich ein einminütiges Video 
aufgezeichnet habe.

00:15:58.301 --> 00:16:01.516
Ein leichtes Lüftchen hat genug 
Schwingungen verursacht,

00:16:01.516 --> 00:16:05.864
dass wir genug Informationen hatten,
um diese Simulation zu erstellen.

00:16:07.503 --> 00:16:11.020
(Applaus)

00:16:13.150 --> 00:16:16.092
Man könnte nun das Video
einem Filmregisseur geben,

00:16:16.092 --> 00:16:20.364
damit er die Stärke und 
Richtung des Windes

00:16:20.364 --> 00:16:23.373
nach einer Aufnahme steuern kann.

00:16:24.810 --> 00:16:29.420
Oder in diesem Fall hier richteten 
wir unsere Kamera auf einen Vorhang

00:16:29.420 --> 00:16:33.465
und man kann überhaupt
keine Bewegung im Video erkennen,

00:16:33.465 --> 00:16:36.404
aber während des zweiminütigen Videos

00:16:36.404 --> 00:16:40.189
sorgte normale Luftzirkulation
für ausreichend subtile,

00:16:40.189 --> 00:16:43.377
nicht wahrnehmbare
Bewegungen und Schwingungen,

00:16:43.377 --> 00:16:46.779
dass wir genug Informationen hatten, 
um diese Simulation zu kreieren.

00:16:48.208 --> 00:16:50.613
Und ironischerweise

00:16:50.613 --> 00:16:53.689
sind wir es gewöhnt, 
diese Art der Interaktion

00:16:53.689 --> 00:16:56.337
bei virtuellen Gegenständen zu erleben,

00:16:56.337 --> 00:16:59.614
zum Beispiel in Videospielen
und 3D-Modellen,

00:16:59.614 --> 00:17:04.081
aber diese Informationen von einem 
Gegenstand in der wirklichen Welt

00:17:04.081 --> 00:17:06.805
mit einem gewöhnlichen Video
aufzuzeichnen,

00:17:06.825 --> 00:17:10.022
ist etwas Neues mit viel Potential.

00:17:10.987 --> 00:17:13.580
Das hier sind die beeindruckenden Leute,

00:17:13.580 --> 00:17:17.040
die mit mir an diesen Projekten
gearbeitet haben.

00:17:17.040 --> 00:17:18.854
(Applaus)

00:17:24.943 --> 00:17:27.869
Was ich Ihnen heute gezeigt habe,
ist nur der Anfang.

00:17:27.869 --> 00:17:30.896
Wir haben gerade begonnen, 
an der Oberfläche dessen zu kratzen,

00:17:30.896 --> 00:17:33.559
was man mit dieser Art der 
Bildverarbeitung machen kann,

00:17:33.559 --> 00:17:35.606
da sie uns eine neue Möglichkeit bietet,

00:17:35.606 --> 00:17:39.472
unsere Umgebung mit 
gewöhnlicher Technik aufzuzeichnen.

00:17:40.082 --> 00:17:42.006
Mit Blick auf die Zukunft

00:17:42.006 --> 00:17:44.025
wird es sehr aufregend sein zu entdecken,

00:17:44.025 --> 00:17:46.332
was uns das über die Welt sagen kann.

00:17:46.335 --> 00:17:47.611
Danke.

00:17:48.131 --> 00:17:51.415
(Applaus)

