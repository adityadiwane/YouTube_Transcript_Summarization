WEBVTT
Kind: captions
Language: pt-BR

00:00:00.000 --> 00:00:12.000
Tradutor: Guilherme Dias
Revisor: Leonardo Silva

00:00:12.974 --> 00:00:17.889
Nós pensamos em movimento
como algo visual.

00:00:17.889 --> 00:00:22.817
Se eu andar pelo palco
ou gesticular enquanto falo,

00:00:22.817 --> 00:00:26.255
esse movimento é algo que vocês podem ver.

00:00:26.255 --> 00:00:31.737
Mas há um mundo de movimentos importantes
que é muito sutil para o olho humano,

00:00:31.737 --> 00:00:33.678
e nos últimos anos,

00:00:33.678 --> 00:00:35.635
começamos a descobrir que câmeras

00:00:35.635 --> 00:00:39.615
podem ver esse movimento,
mesmo quando humanos não podem.

00:00:40.163 --> 00:00:41.837
Deixe-me mostrar o que quero dizer.

00:00:42.437 --> 00:00:46.339
Na esquerda, vocês veem o vídeo
do pulso de uma pessoa

00:00:46.339 --> 00:00:49.486
e na direita, vocês veem o vídeo
de um bebê dormindo,

00:00:49.486 --> 00:00:52.632
mas se eu não tivesse dito
que são vídeos,

00:00:52.632 --> 00:00:56.143
vocês poderiam achar que estavam vendo
duas imagens comuns,

00:00:56.143 --> 00:00:57.835
porque em ambos os casos,

00:00:57.835 --> 00:01:02.175
os vídeos parecem estar
completamente imóveis.

00:01:02.175 --> 00:01:05.910
Mas, na verdade, há muitos
movimentos sutis acontecendo aqui,

00:01:05.910 --> 00:01:08.452
e se vocês tocassem o pulso da esquerda,

00:01:08.452 --> 00:01:10.448
sentiriam a pulsação,

00:01:10.448 --> 00:01:12.933
e se vocês segurassem o bebê da direita,

00:01:12.933 --> 00:01:15.324
sentiriam seu tórax subir e descer

00:01:15.324 --> 00:01:17.762
a cada vez que respira.

00:01:17.762 --> 00:01:21.338
E esses movimentos carregam
muito significado,

00:01:21.338 --> 00:01:24.681
mas geralmente são
muito sutis para serem vistos,

00:01:24.681 --> 00:01:26.957
então, em vez disso, temos que observá-los

00:01:26.957 --> 00:01:30.997
através do contato direto,
através do toque.

00:01:30.997 --> 00:01:32.262
Mas alguns anos atrás,

00:01:32.262 --> 00:01:36.667
meus colegas no MIT desenvolveram o que
eles chamam de microscópio do movimento,

00:01:36.667 --> 00:01:41.051
que é um software que encontra
esses movimentos sutis em vídeos

00:01:41.051 --> 00:01:45.416
e os amplifica para que se tornem
grandes o suficiente para podermos ver.

00:01:45.416 --> 00:01:48.899
Então, se usarmos o software
no vídeo da esquerda,

00:01:48.899 --> 00:01:52.149
podemos ver a pulsação,

00:01:52.149 --> 00:01:53.844
e se contássemos esta pulsação,

00:01:53.844 --> 00:01:57.095
nós poderíamos descobrir
os batimentos cardíacos dessa pessoa.

00:01:57.095 --> 00:02:00.160
E se usássemos o mesmo software
no vídeo da direita,

00:02:00.160 --> 00:02:03.387
ele nos deixa ver cada
vez que este bebê respira,

00:02:03.387 --> 00:02:07.524
e podemos usá-lo como uma maneira
de monitorar sua respiração sem tocar.

00:02:08.884 --> 00:02:13.662
E essa tecnologia é realmente poderosa,
pois pega esses fenômenos

00:02:13.662 --> 00:02:16.489
que normalmente temos
que experimentar pelo toque

00:02:16.489 --> 00:02:19.914
e nos deixa capturá-los visualmente
e não invasivamente.

00:02:21.014 --> 00:02:25.345
Alguns anos atrás, eu comecei a trabalhar
com as pessoas que criaram esse software,

00:02:25.345 --> 00:02:28.732
e decidimos ir atrás de uma ideia louca.

00:02:28.732 --> 00:02:31.575
Pensamos, é legal
podermos usar esse software

00:02:31.575 --> 00:02:34.380
para visualizar movimentos pequenos assim,

00:02:34.380 --> 00:02:39.168
e poder pensar nisso como uma maneira
de estender nosso senso de toque.

00:02:39.168 --> 00:02:43.607
Mas e se pudéssemos fazer a mesma coisa
com a nossa capacidade de ouvir?

00:02:44.328 --> 00:02:49.173
E se pudéssemos usar o vídeo
para capturar as vibrações de som,

00:02:49.173 --> 00:02:52.000
que são apenas outro tipo de movimento,

00:02:52.000 --> 00:02:55.596
e transformássemos tudo
o que vemos em um microfone?

00:02:56.136 --> 00:02:58.207
Bom, essa é uma ideia um pouco estranha,

00:02:58.207 --> 00:03:01.620
então me deixe colocá-la
em perspectiva para vocês.

00:03:01.620 --> 00:03:05.011
Microfones tradicionais funcionam
convertendo o movimento

00:03:05.011 --> 00:03:08.610
de um diafragma interno em sinal elétrico,

00:03:08.610 --> 00:03:12.928
e o diafragma é feito
para mover prontamente com som

00:03:12.928 --> 00:03:17.645
para que seus movimentos possam
ser gravados e interpretados como áudio.

00:03:17.645 --> 00:03:21.403
Mas o som faz todos os objetos vibrarem.

00:03:21.403 --> 00:03:26.883
Essas vibrações são normalmente
sutis e rápidas demais para nós vermos.

00:03:26.883 --> 00:03:30.621
E se as gravarmos
com uma câmera de alta velocidade

00:03:30.621 --> 00:03:34.197
e depois usarmos o software
para extrair pequenos movimentos

00:03:34.197 --> 00:03:36.287
do nosso vídeo de alta velocidade,

00:03:36.287 --> 00:03:41.129
e analisarmos esses movimentos
para descobrir quais sons os criaram?

00:03:41.749 --> 00:03:47.638
Isto nos permitiria transformar objetos
visíveis em microfones à distância.

00:03:49.080 --> 00:03:51.113
E então nós tentamos,

00:03:51.113 --> 00:03:52.970
e aqui está uma de nossas experiências,

00:03:52.970 --> 00:03:56.139
em que nós pegamos esta planta
que vocês veem na direita

00:03:56.139 --> 00:03:58.567
e a filmamos com uma câmera
de alta velocidade

00:03:58.567 --> 00:04:02.106
enquanto um alto-falante
tocava esta música.

00:04:02.106 --> 00:04:11.039
(Música: "Mary Had a Little Lamb")

00:04:11.820 --> 00:04:14.644
E aqui está o vídeo que gravamos,

00:04:14.644 --> 00:04:18.498
e o gravamos a milhares
de quadros por segundo,

00:04:18.498 --> 00:04:20.820
mas mesmo se vocês olharem de perto,

00:04:20.820 --> 00:04:22.841
só verão algumas folhas

00:04:22.841 --> 00:04:25.906
que estão basicamente
paradas ali, sem fazer nada,

00:04:25.906 --> 00:04:30.882
porque nosso som só moveu aquelas folhas
por volta de um micrômetro.

00:04:31.455 --> 00:04:35.379
Isso é um décimo de milésimo
de centímetro,

00:04:35.379 --> 00:04:39.425
que fica entre um centésimo e um milésimo

00:04:39.425 --> 00:04:42.043
de um pixel nesta imagem.

00:04:42.043 --> 00:04:44.588
Vocês podem olhar o quanto quiserem,

00:04:44.588 --> 00:04:48.597
mas o movimento pequeno assim é
basicamente imperceptível.

00:04:49.557 --> 00:04:53.684
Mas verifica-se que algo
pode ser imperceptível

00:04:53.684 --> 00:04:56.503
e ainda ser numericamente significante,

00:04:56.503 --> 00:04:58.535
pois com os algoritmos certos,

00:04:58.535 --> 00:05:02.152
podemos pegar este vídeo silencioso
e aparentemente parado

00:05:02.152 --> 00:05:04.630
e podemos recuperar este som.

00:05:04.630 --> 00:05:11.834
(Música: "Mary Had a Little Lamb")

00:05:11.834 --> 00:05:17.902
(Aplausos)

00:05:21.958 --> 00:05:23.837
Como isso é possível?

00:05:23.837 --> 00:05:28.211
Como podemos obter tanta informação
de tão pouco movimento?

00:05:28.211 --> 00:05:33.722
Bom, vamos supor que aquelas folhas
se movem a apenas um micrômetro,

00:05:33.722 --> 00:05:39.345
e vamos dizer que isso muda a nossa imagem
a apenas um milésimo de um pixel.

00:05:39.345 --> 00:05:41.571
Pode não parecer muito,

00:05:41.571 --> 00:05:43.607
mas um simples quadro de vídeo

00:05:43.607 --> 00:05:46.894
pode ter centenas de milhares de pixels,

00:05:46.894 --> 00:05:50.548
e se combinarmos todos
os pequenos movimentos que vemos

00:05:50.548 --> 00:05:52.846
em toda essa imagem,

00:05:52.846 --> 00:05:55.469
então um milésimo de pixel

00:05:55.469 --> 00:05:59.185
pode começar a virar
algo bem significante.

00:05:59.185 --> 00:06:02.215
Pessoalmente, ficamos muito empolgados
quando descobrimos isso.

00:06:02.215 --> 00:06:04.615
(Risadas)

00:06:04.615 --> 00:06:07.808
Mas mesmo com o algoritmo certo,

00:06:07.808 --> 00:06:11.695
nós ainda estávamos perdendo alguns
pedaços importantes do quebra-cabeças.

00:06:11.695 --> 00:06:15.299
Vejam, há muitos fatores
que afetam quando e quão bem

00:06:15.299 --> 00:06:17.166
essa técnica vai funcionar.

00:06:17.166 --> 00:06:20.270
Tem o objeto e o quão distante ele está,

00:06:20.270 --> 00:06:22.784
tem a câmera e as lentes usadas,

00:06:22.784 --> 00:06:26.985
quanta luz está iluminando o objeto
e o quão alto o som está.

00:06:27.775 --> 00:06:31.210
E mesmo com o algoritmo certo,

00:06:31.210 --> 00:06:34.380
tivemos que ser cuidadosos
com nossas primeiras experiências,

00:06:34.380 --> 00:06:36.992
porque se errássemos
qualquer um desses fatores,

00:06:36.992 --> 00:06:39.390
não haveria como saber
qual era o problema.

00:06:39.390 --> 00:06:41.947
Nós receberíamos apenas barulho de volta.

00:06:41.947 --> 00:06:45.397
Muitas das nossas primeiras
experiências pareciam com isso.

00:06:45.397 --> 00:06:47.583
E aqui estou eu,

00:06:47.583 --> 00:06:51.473
e abaixo, na esquerda, vocês podem
ver a nossa câmera de alta velocidade,

00:06:51.473 --> 00:06:53.666
que está apontada para um pacote de batata

00:06:53.666 --> 00:06:56.715
e está tudo iluminado
por essas lâmpadas.

00:06:56.715 --> 00:07:01.100
E, como eu disse, nós tivemos que
ser cuidadosos nas primeiras experiências,

00:07:01.100 --> 00:07:03.618
então foi assim que aconteceu.

00:07:03.618 --> 00:07:07.289
(Vídeo) Abe Davis: três, dois, um, vai.

00:07:07.289 --> 00:07:12.676
Mary had a little lamb!
Little lamb! Little lamb!

00:07:12.676 --> 00:07:17.186
(Risadas)

00:07:17.186 --> 00:07:20.000
AD: Então essa experiência
parece completamente ridícula.

00:07:20.000 --> 00:07:21.738
(Risadas)

00:07:21.738 --> 00:07:24.103
Bom, eu estou gritando
com um pacote de batata

00:07:24.103 --> 00:07:25.834
(Risadas)

00:07:25.834 --> 00:07:27.811
e estamos a irradiando com tanta luz,

00:07:27.811 --> 00:07:32.461
que nós literalmente derretemos o primeiro
pacote que nós testamos. (Risadas)

00:07:32.471 --> 00:07:35.679
Mas por mais ridícula
que essa experiência pareça,

00:07:35.679 --> 00:07:37.447
foi, na verdade, muito importante,

00:07:37.447 --> 00:07:40.343
porque pudemos recuperar este som.

00:07:40.343 --> 00:07:45.115
(Áudio) Mary had a little lamb!
Little lamb! Little lamb!

00:07:45.115 --> 00:07:49.153
(Aplausos)

00:07:49.153 --> 00:07:51.084
AD: Isso foi realmente significativo,

00:07:51.084 --> 00:07:55.502
porque foi a primeira vez que nós
recuperamos discurso humano intelegível

00:07:55.502 --> 00:07:57.765
do vídeo silencioso de um objeto.

00:07:57.765 --> 00:08:00.156
Isso nos deu este ponto de referência,

00:08:00.156 --> 00:08:03.948
e pudemos começar a gradualmente
mudar a experiência,

00:08:03.948 --> 00:08:07.761
usando objetos diferentes
ou afastando mais o objeto

00:08:07.761 --> 00:08:11.510
usando menos luz ou sons mais baixos.

00:08:11.510 --> 00:08:14.761
Nós analisamos todos essas experiências

00:08:14.761 --> 00:08:18.383
até realmente entendermos
os limites da nossa técnica,

00:08:18.383 --> 00:08:20.333
pois uma vez entendidos,

00:08:20.333 --> 00:08:22.679
poderíamos descobrir como ultrapassá-los.

00:08:22.679 --> 00:08:25.860
E isso nos levou a experiências como esta,

00:08:25.860 --> 00:08:28.599
em que vou, novamente, falar
com um pacote de batatas,

00:08:28.599 --> 00:08:33.319
mas dessa vez afastamos
a câmera a uns 4,5 metros,

00:08:33.319 --> 00:08:36.262
do lado de fora, atrás
de uma janela à prova de som,

00:08:36.262 --> 00:08:40.371
e tudo está iluminado
apenas por luz natural.

00:08:40.371 --> 00:08:43.160
E aqui está o vídeo que filmamos.

00:08:44.450 --> 00:08:49.009
E foi assim que as coisas soaram
de dentro, próximo ao pacote de batatas.

00:08:49.009 --> 00:08:54.007
(Áudio) "Mary had a little lamb
whose fleece was white as snow,

00:08:54.007 --> 00:08:59.546
and everywhere that Mary went,
that lamb was sure to go."

00:08:59.546 --> 00:09:03.173
AD: E aqui está o que conseguimos
recuperar do nosso vídeo silencioso

00:09:03.173 --> 00:09:05.858
capturado do lado de fora,
atrás da janela.

00:09:05.858 --> 00:09:10.373
(Áudio) "Mary had a little lamb
whose fleece was white as snow,

00:09:10.373 --> 00:09:15.730
and everywhere that Mary went,
that lamb was sure to go."

00:09:15.730 --> 00:09:21.981
(Aplausos)

00:09:21.981 --> 00:09:25.963
AD: E há outras maneiras
de ultrapassar esses limites também.

00:09:25.963 --> 00:09:27.761
Em uma experiência mais silenciosa,

00:09:27.761 --> 00:09:31.871
nós filmamos alguns fones de ouvido
plugados em um laptop,

00:09:31.871 --> 00:09:35.981
e nesse caso, nosso objetivo era recuperar
a música que estava tocando no laptop

00:09:35.981 --> 00:09:38.280
do vídeo silencioso

00:09:38.280 --> 00:09:40.747
desses dois fones de ouvido de plástico,

00:09:40.747 --> 00:09:42.970
e conseguimos fazer isso tão bem

00:09:42.970 --> 00:09:45.431
que eu pude até pôr
os resultados no Shazam.

00:09:45.431 --> 00:09:47.543
(Risadas)

00:09:49.077 --> 00:09:55.168
(Música: Under Pressure - Queen)

00:10:01.265 --> 00:10:06.584
(Aplausos)

00:10:06.584 --> 00:10:11.135
E também podemos dar um empurrãozinho
mudando o hardware que usamos.

00:10:11.135 --> 00:10:13.476
Porque as experiências
que mostrei até agora

00:10:13.476 --> 00:10:15.918
foram feitas com uma câmera,
de alta velocidade,

00:10:15.918 --> 00:10:18.797
que pode gravar vídeos
até 100 vezes mais rápido

00:10:18.797 --> 00:10:20.724
que a maioria dos celulares,

00:10:20.724 --> 00:10:23.533
mas também encontramos um modo
de usar essa técnica

00:10:23.533 --> 00:10:25.763
com câmeras mais comuns,

00:10:25.763 --> 00:10:29.832
e nós fazemos isso tirando vantagem
do que é chamado de persiana.

00:10:29.832 --> 00:10:34.630
Vejam, a maioria das câmeras
gravam imagens um rolo por vez,

00:10:34.630 --> 00:10:40.144
e se um objeto se mover
durante a gravação de apenas uma imagem,

00:10:40.144 --> 00:10:43.061
há um pequeno atraso entre cada rolo,

00:10:43.061 --> 00:10:46.218
e isso causa pequenos artefatos

00:10:46.218 --> 00:10:49.701
que são codificados
entre cada quadro de um vídeo.

00:10:49.701 --> 00:10:53.507
Então descobrimos
que, analisando esses artefatos,

00:10:53.507 --> 00:10:58.122
podemos recuperar o som usando
uma versão modificada do nosso algoritmo.

00:10:58.122 --> 00:11:00.034
Aqui está uma experiência que fizemos

00:11:00.034 --> 00:11:01.729
em que filmamos um pacote de doces

00:11:01.729 --> 00:11:03.470
enquanto um alto-falante tocava

00:11:03.470 --> 00:11:06.442
a mesma música de antes,
"Mary Had a Little Lamb",

00:11:06.442 --> 00:11:10.645
mas dessa vez, usamos apenas
uma câmera comum de loja,

00:11:10.645 --> 00:11:13.719
e em um segundo, vou tocar pra vocês
o som que recuperamos,

00:11:13.719 --> 00:11:15.749
e vai parecer distorcido dessa vez,

00:11:15.749 --> 00:11:19.514
mas escutem e vejam se vocês ainda
reconhecem a música.

00:11:19.514 --> 00:11:26.096
(Áudio: "Mary Had a Little Lamb")

00:11:37.578 --> 00:11:40.992
E, de novo, parece distorcido,

00:11:40.992 --> 00:11:45.378
mas o que é realmente incrível aqui
é que conseguimos fazer isso

00:11:45.378 --> 00:11:48.004
com algo que você pode literalmente sair

00:11:48.004 --> 00:11:50.222
e comprar no Best Buy.

00:11:51.122 --> 00:11:52.455
Nesse momento,

00:11:52.455 --> 00:11:54.409
muitas pessoas veem esse trabalho,

00:11:54.409 --> 00:11:57.832
e imediatamente pensam em vigilância.

00:11:57.832 --> 00:12:00.227
E, pra ser justo,

00:12:00.227 --> 00:12:04.120
não é difícil imaginar que pode-se usar
essa tecnologia para espiar alguém.

00:12:04.120 --> 00:12:08.367
Mas tenha em mente que já
existem muitas tecnologias maduras

00:12:08.367 --> 00:12:09.946
para vigilância.

00:12:09.946 --> 00:12:12.036
De fato, as pessoas têm usado lêiseres

00:12:12.036 --> 00:12:15.749
para bisbilhotar objetos
à distância por décadas.

00:12:15.749 --> 00:12:17.753
Mas o que é realmente novo aqui,

00:12:17.753 --> 00:12:19.443
o que é realmente diferente,

00:12:19.443 --> 00:12:23.738
é que agora temos uma maneira
de imaginar as vibrações de um objeto,

00:12:23.738 --> 00:12:26.911
o que nos dá uma nova lente
através da qual podemos ver o mundo,

00:12:26.911 --> 00:12:28.661
e podemos usar essa lente

00:12:28.661 --> 00:12:33.560
para aprender não apenas sobre forças
como o som, que faz um objeto a vibrar,

00:12:33.560 --> 00:12:36.671
mas também sobre o próprio objeto.

00:12:36.671 --> 00:12:38.668
Eu quero dar um passo atrás

00:12:38.668 --> 00:12:42.917
e pensar em como isso pode mudar
as maneiras como usamos vídeo,

00:12:42.917 --> 00:12:46.470
porque costumamos usar vídeo
para ver as coisas,

00:12:46.470 --> 00:12:48.792
e eu só mostrei como podemos usá-lo

00:12:48.792 --> 00:12:50.619
para ouvir as coisas.

00:12:50.619 --> 00:12:54.030
Mas tem outra maneira importante
de aprendermos sobre o mundo:

00:12:54.030 --> 00:12:56.475
interagindo com ele.

00:12:56.475 --> 00:12:59.936
Nós empurramos, puxamos,
cutucamos e estimulamos coisas.

00:12:59.936 --> 00:13:03.187
Nós mexemos nas coisas
pra ver o que acontece.

00:13:03.187 --> 00:13:07.380
E isso é algo que o vídeo ainda
não nos deixa fazer,

00:13:07.380 --> 00:13:09.596
pelo menos não tradicionalmente.

00:13:09.596 --> 00:13:11.546
Quero mostrar alguns novos trabalhos,

00:13:11.546 --> 00:13:14.212
e isso é baseado em um ideia
que tive alguns meses atrás.

00:13:14.212 --> 00:13:17.513
Esta é a primeira em que mostro isso
para um público, na verdade.

00:13:17.513 --> 00:13:22.877
E a ideia básica é a de que vamos
usar as vibrações em um vídeo

00:13:22.877 --> 00:13:27.358
para capturar objetos de modo
a nos deixar interagir com eles

00:13:27.358 --> 00:13:30.290
e ver como eles reagem a nós.

00:13:31.120 --> 00:13:32.884
Aqui está um objeto,

00:13:32.884 --> 00:13:36.716
e nesse caso, é uma figura em fios
no formato de um humano,

00:13:36.716 --> 00:13:39.804
e vamos filmar esse objeto
com uma câmera comum.

00:13:39.804 --> 00:13:41.928
Não tem nada de especial nessa câmera.

00:13:41.928 --> 00:13:44.889
Na verdade, eu fiz isso
com o meu celular antes.

00:13:44.889 --> 00:13:46.921
Mas queremos ver o objeto vibrar

00:13:46.921 --> 00:13:48.274
e, para isso acontecer,

00:13:48.274 --> 00:13:51.620
nós vamos bater um pouco
na superfície onde ele está parado

00:13:51.620 --> 00:13:53.758
enquanto gravamos este vídeo.

00:13:58.918 --> 00:14:03.009
Então é isso: apenas cinco segundos
de vídeo comum,

00:14:03.009 --> 00:14:05.205
enquanto batemos nessa superfície.

00:14:05.205 --> 00:14:08.718
Vamos usar as vibrações nesse vídeo

00:14:08.718 --> 00:14:13.182
para aprender sobre as propriedades
estruturais e materiais do nosso objeto,

00:14:13.182 --> 00:14:18.096
e vamos usar essa informação
para criar algo novo e interativo.

00:14:25.073 --> 00:14:27.519
Aqui está o que nós criamos.

00:14:27.519 --> 00:14:29.748
E parece uma imagem comum,

00:14:29.748 --> 00:14:32.859
mas isso não é uma imagem,
nem é um video,

00:14:32.859 --> 00:14:35.227
porque agora eu posso pegar o mouse

00:14:35.227 --> 00:14:38.086
e eu posso começar a interagir
com o objeto.

00:14:44.936 --> 00:14:47.229
E o que você vê aqui

00:14:47.229 --> 00:14:49.615
é a simulação de como esse objeto

00:14:49.615 --> 00:14:54.073
responderia a novas forças
que nunca vimos antes,

00:14:54.073 --> 00:14:58.345
e nós criamos isso a partir de cinco
segundos de um vídeo comum.

00:14:58.345 --> 00:15:03.964
(Aplausos)

00:15:09.291 --> 00:15:12.598
Essa é uma maneira muito
poderosa de ver o mundo,

00:15:12.598 --> 00:15:15.620
porque ela nos deixa prever
como os objetos vão responder

00:15:15.620 --> 00:15:17.443
a novas situações,

00:15:17.443 --> 00:15:20.916
e você pode imaginar, por exemplo,
olhar para uma ponte velha

00:15:20.916 --> 00:15:24.443
e se perguntar o que aconteceria,
como a ponte aguentaria

00:15:24.443 --> 00:15:27.276
se eu dirigisse meu carro nela.

00:15:27.276 --> 00:15:30.050
E essa é uma questão que você
provavelmente quer responder

00:15:30.050 --> 00:15:33.988
antes de começar a dirigir naquela ponte.

00:15:33.988 --> 00:15:36.950
E haverá limitações a essa técnica,

00:15:36.950 --> 00:15:39.232
assim como houve com o microfone visual,

00:15:39.232 --> 00:15:42.553
mas descobrimos que ela funciona
em muitas situações

00:15:42.553 --> 00:15:44.778
que você pode não imaginar,

00:15:44.778 --> 00:15:47.156
principalmente com vídeos maiores.

00:15:47.156 --> 00:15:49.964
Por exemplo, aqui tem um vídeo que filmei

00:15:49.964 --> 00:15:52.353
de um arbusto fora do me apartamento,

00:15:52.353 --> 00:15:55.321
e não fiz nada a esse arbusto,

00:15:55.321 --> 00:15:58.056
mas filmando um vídeo de um minuto,

00:15:58.056 --> 00:16:01.524
uma brisa causou vibrações suficientes

00:16:01.524 --> 00:16:05.519
e, assim, pudemos aprender o suficiente
sobre o arbusto para criar essa simulação.

00:16:07.699 --> 00:16:13.412
(Aplausos)

00:16:13.412 --> 00:16:16.024
E você pode imaginar dar isso
a um diretor de cinema,

00:16:16.024 --> 00:16:18.103
e deixá-lo controlar

00:16:18.103 --> 00:16:23.025
a força e a direção do vento
numa filmagem depois que ela foi gravada.

00:16:24.740 --> 00:16:29.345
Ou, nesse caso, nós apontamos nossa câmera
para uma cortina pendurada

00:16:29.345 --> 00:16:33.204
e você não pode ver nenhum
movimento nesse vídeo,

00:16:33.204 --> 00:16:35.999
mas gravando um vídeo de dois minutos,

00:16:35.999 --> 00:16:38.837
as correntes de ar natural nesse quarto

00:16:38.837 --> 00:16:43.249
criaram movimentos e vibrações
sutis e imperceptíveis

00:16:43.249 --> 00:16:46.644
e, assim, pudemos aprender o suficiente
para criar essa simulação.

00:16:48.705 --> 00:16:50.609
Ironicamente,

00:16:50.609 --> 00:16:53.697
nós estamos acostumados a ter
esse tipo de interatividade

00:16:53.697 --> 00:16:56.344
quando se trata de objetos virtuais,

00:16:56.344 --> 00:16:59.641
videogames e modelos 3D,

00:16:59.641 --> 00:17:04.045
mas ser capaz de capturar essa informação
de objetos reais, no mundo real,

00:17:04.045 --> 00:17:06.862
usando apenas um vídeo simples, comum,

00:17:06.862 --> 00:17:10.664
é algo novo que tem muito potencial.

00:17:10.664 --> 00:17:14.801
Aqui estão as pessoas incríveis
que trabalharam comigo nesses projetos.

00:17:16.057 --> 00:17:21.653
(Aplausos)

00:17:24.356 --> 00:17:27.846
E o que mostrei hoje
é apenas o início.

00:17:27.846 --> 00:17:29.879
Nós só começamos a sondar a superfície

00:17:29.879 --> 00:17:32.771
do que pode ser feito
com esse tipo de imagem,

00:17:32.771 --> 00:17:35.207
porque ela nos dá um novo modo

00:17:35.207 --> 00:17:39.966
de notar o que está a nossa volta
com uma tecnologia comum e acessível.

00:17:39.966 --> 00:17:42.055
E olhando para o futuro,

00:17:42.055 --> 00:17:44.032
vai ser realmente animador explorar

00:17:44.032 --> 00:17:46.263
o que isso pode nos dizer sobre o mundo.

00:17:46.263 --> 00:17:47.614
Obrigado.

00:17:47.614 --> 00:17:53.460
(Aplausos)

