WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Lidia Cámara de la Fuente
Revisor: Sebastian Betti

00:00:12.974 --> 00:00:17.889
La mayoría pensamos en el movimiento 
como algo muy visual.

00:00:17.889 --> 00:00:22.977
Si camino por este escenario o gesticulo 
con las manos, mientras hablo,

00:00:22.977 --> 00:00:26.255
ese movimiento se puede ver.

00:00:26.255 --> 00:00:31.737
Existe un mundo de movimiento importante 
demasiado sutil para el ojo humano,

00:00:31.737 --> 00:00:33.778
y en los últimos años,

00:00:33.778 --> 00:00:35.775
hemos averiguado que a menudo las cámaras

00:00:35.775 --> 00:00:39.185
pueden ver este movimiento, 
incluso cuando los humanos no pueden.

00:00:40.163 --> 00:00:41.837
Les mostraré lo que quiero decir.

00:00:42.717 --> 00:00:46.339
A la izquierda, se ve un video 
de la muñeca de una persona,

00:00:46.339 --> 00:00:49.486
y a la derecha, el video 
de un bebé dormido,

00:00:49.486 --> 00:00:52.632
pero si yo no dijera que 
se trataba de videos,

00:00:52.632 --> 00:00:56.393
se puede suponer que uno mira 
imágenes normales,

00:00:56.393 --> 00:00:58.065
porque en ambos casos,

00:00:58.065 --> 00:01:02.175
estos videos parecen casi 
completamente inmóviles.

00:01:02.175 --> 00:01:06.060
Pero en realidad existe mucho 
movimiento sutil aquí,

00:01:06.060 --> 00:01:08.452
y si tocaran la muñeca de la izquierda,

00:01:08.452 --> 00:01:10.448
sentirían un pulso,

00:01:10.448 --> 00:01:12.933
y si se fueran al bebé de la derecha,

00:01:12.933 --> 00:01:15.324
sentirían el ascenso y 
el descenso de su pecho

00:01:15.324 --> 00:01:17.762
mientras respira.

00:01:17.762 --> 00:01:21.338
Y estos movimientos 
tienen mucho significado,

00:01:21.338 --> 00:01:24.681
pero son generalmente demasiado 
sutiles para que los notemos,

00:01:24.681 --> 00:01:26.957
así que en su lugar,
tenemos que observarlos

00:01:26.957 --> 00:01:30.997
mediante contacto directo, 
a través del tacto.

00:01:30.997 --> 00:01:32.262
Pero hace unos años,

00:01:32.262 --> 00:01:36.667
mis colegas del MIT desarrollaron lo que 
llaman un microscopio de movimiento,

00:01:36.667 --> 00:01:41.051
que es un software que capta 
estos movimientos sutiles en video

00:01:41.051 --> 00:01:45.416
y los amplía para que sean lo 
suficientemente grandes para verlos.

00:01:45.416 --> 00:01:48.899
Y así, si usamos ese software 
en el video de la izquierda,

00:01:48.899 --> 00:01:52.149
vemos el pulso de esta muñeca,

00:01:52.149 --> 00:01:53.844
y si contáramos ese pulso,

00:01:53.844 --> 00:01:57.095
podríamos incluso averiguar 
la frecuencia cardíaca de esta persona.

00:01:57.095 --> 00:02:00.160
Y si usamos el mismo software 
en el video de la derecha,

00:02:00.160 --> 00:02:03.387
vemos cada respiración de este bebé,

00:02:03.387 --> 00:02:07.524
y podemos usarlo monitorear 
su respiración sin que haya contacto.

00:02:08.884 --> 00:02:14.232
Y esta tecnología es realmente 
poderosa porque capta estos fenómenos

00:02:14.232 --> 00:02:16.599
que normalmente experimentamos 
a través del tacto

00:02:16.599 --> 00:02:19.914
permitiéndonos captarlos visualmente 
y de forma no invasiva.

00:02:21.104 --> 00:02:25.515
Hace un par de años, empecé a trabajar 
con la gente que creó ese software,

00:02:25.515 --> 00:02:28.882
y decidimos seguir una idea descabellada.

00:02:28.882 --> 00:02:31.575
Pensamos que sería genial 
usar el software

00:02:31.575 --> 00:02:34.710
para visualizar pequeños 
movimientos como este,

00:02:34.710 --> 00:02:39.168
y podemos pensarlo como una forma 
de ampliar el sentido del tacto.

00:02:39.168 --> 00:02:43.227
Pero ¿y si pudiéramos hacer lo mismo 
con nuestra capacidad de escuchar?

00:02:44.508 --> 00:02:49.173
¿Y si pudiéramos usar el video para 
captar las vibraciones de sonido,

00:02:49.173 --> 00:02:52.000
que no son más que 
otro tipo de movimiento,

00:02:52.000 --> 00:02:55.346
y convertir todo lo que vemos 
en un micrófono?

00:02:56.236 --> 00:02:58.207
Esto es una idea un poco extraña,

00:02:58.207 --> 00:03:01.760
así que trataré de ponerlo 
en perspectiva.

00:03:01.760 --> 00:03:05.011
Los micrófonos tradicionales 
funcionan convirtiendo el movimiento

00:03:05.011 --> 00:03:08.610
de un diafragma interno 
en una señal eléctrica,

00:03:08.610 --> 00:03:12.928
y el diafragma está diseñado 
para moverse fácilmente con sonido

00:03:12.928 --> 00:03:17.735
de manera que su movimiento se puede 
grabar e interpretar como sonido.

00:03:17.735 --> 00:03:21.403
Pero el sonido hace que 
todos los objetos vibren.

00:03:21.403 --> 00:03:26.883
Esas vibraciones son por norma demasiado 
sutiles y rápidas para que se vean.

00:03:26.883 --> 00:03:30.621
¿Y si grabamos con una 
cámara de alta velocidad

00:03:30.621 --> 00:03:34.197
y luego usamos el software para 
extraer pequeños movimientos

00:03:34.197 --> 00:03:36.287
de nuestro video de alta velocidad,

00:03:36.287 --> 00:03:41.129
y analizamos los movimientos para 
averiguar qué sonidos se han creado?

00:03:41.859 --> 00:03:47.608
Nos permitiría convertir objetos visibles 
en micrófonos visuales a la distancia.

00:03:49.080 --> 00:03:51.263
Así que lo intentamos,

00:03:51.263 --> 00:03:53.190
y aquí está uno de nuestros experimentos,

00:03:53.190 --> 00:03:56.139
donde tomamos esta planta 
en maceta de la derecha

00:03:56.139 --> 00:03:58.577
y filmamos con una 
cámara de alta velocidad

00:03:58.577 --> 00:04:02.106
mientras que un altavoz cercano 
reproducía este sonido.

00:04:02.106 --> 00:04:10.799
♪ ♫ María tenía un corderito ♪ ♫

00:04:11.820 --> 00:04:14.644
Aquí el video que grabamos,

00:04:14.644 --> 00:04:18.568
que grabamos en miles de 
fotogramas por segundo,

00:04:18.568 --> 00:04:20.890
pero incluso mirándolo muy de cerca,

00:04:20.890 --> 00:04:22.841
solo se ven algunas hojas

00:04:22.841 --> 00:04:25.906
que están más o menos 
allí sin hacer nada,

00:04:25.906 --> 00:04:31.041
porque nuestro sonido solo movió 
esas hojas cerca de un micrómetro.

00:04:31.454 --> 00:04:35.379
Esa es una diezmilésima de centímetro,

00:04:35.379 --> 00:04:39.535
que se extiende en algún lugar 
entre una centésima y una milésima

00:04:39.535 --> 00:04:42.423
de pixel en esta imagen.

00:04:42.423 --> 00:04:44.768
Así que aunque entrecierren 
los ojos lo más posible,

00:04:44.768 --> 00:04:48.597
el movimiento tan pequeño 
es perceptualmente invisible.

00:04:49.667 --> 00:04:53.824
Pero resulta que algo 
perceptualmente invisible

00:04:53.824 --> 00:04:56.633
aún así puede ser 
numéricamente significativo,

00:04:56.633 --> 00:04:58.635
porque con los algoritmos adecuados,

00:04:58.635 --> 00:05:02.322
podemos captar este silencio 
aparentemente silencioso

00:05:02.322 --> 00:05:04.690
y podemos recuperar ese sonido.

00:05:04.690 --> 00:05:12.074
♪ ♫ María tenía un corderito ♪ ♫

00:05:12.074 --> 00:05:17.902
(Aplausos)

00:05:22.058 --> 00:05:23.997
¿Cómo es esto posible?

00:05:23.997 --> 00:05:28.341
¿Cómo podemos conseguir tanta 
información de tan poco movimiento?

00:05:28.341 --> 00:05:33.702
Esas hojas se mueven solo un micrómetro,

00:05:33.702 --> 00:05:39.495
y nuestra imagen cambia 
solo una milésima de píxel.

00:05:39.495 --> 00:05:41.841
Eso puede no parecer mucho,

00:05:41.841 --> 00:05:43.837
pero un solo fotograma de video

00:05:43.837 --> 00:05:47.094
puede contener cientos 
de miles de píxeles,

00:05:47.094 --> 00:05:50.548
y si combinamos todos los minúsculos 
movimientos que vemos

00:05:50.548 --> 00:05:52.846
desde el otro lado de 
esa imagen completa,

00:05:52.846 --> 00:05:55.469
entonces, de repente 
una milésima de un pixel

00:05:55.469 --> 00:05:59.185
puede aportar a algo 
bastante significado.

00:05:59.185 --> 00:06:02.505
A título personal, estábamos muy 
emocionados al darnos cuenta de esto.

00:06:02.505 --> 00:06:04.825
(Risas)

00:06:04.825 --> 00:06:08.078
Pero incluso con el algoritmo correcto,

00:06:08.078 --> 00:06:11.695
todavía faltaba una pieza 
muy importante del rompecabezas.

00:06:11.695 --> 00:06:15.299
Hay muchos factores que afectan
cuánto y cómo de bien

00:06:15.299 --> 00:06:17.296
funcionará esta técnica.

00:06:17.296 --> 00:06:20.500
Ahí está el objeto y lo lejos que está;

00:06:20.500 --> 00:06:22.894
la cámara y la lente que se usa;

00:06:22.894 --> 00:06:26.985
cuánta luz brilla sobre el objeto 
y cuán alto es el sonido.

00:06:27.945 --> 00:06:31.320
E incluso con el algoritmo correcto,

00:06:31.320 --> 00:06:34.710
tuvimos que ser muy cuidadosos 
con nuestros primeros experimentos,

00:06:34.710 --> 00:06:37.102
porque si teníamos alguno 
de estos factores mal,

00:06:37.102 --> 00:06:39.470
no había forma de saber 
cuál era el problema.

00:06:39.470 --> 00:06:42.117
Obtendríamos solo ruido.

00:06:42.117 --> 00:06:45.437
Muchos de nuestros primeros 
experimentos eran así.

00:06:45.437 --> 00:06:47.643
Aquí estoy,

00:06:47.643 --> 00:06:51.683
y abajo a izquierda puede verse
nuestra cámara de alta velocidad

00:06:51.683 --> 00:06:53.866
dirigida a una bolsa de papas,

00:06:53.866 --> 00:06:56.815
y todo está iluminado 
por estos focos brillantes.

00:06:56.815 --> 00:07:01.180
Y como dije, teníamos que ser muy 
cuidados en estos primeros experimentos,

00:07:01.180 --> 00:07:03.688
así es que esta es la forma 
en que fracasó.

00:07:03.688 --> 00:07:07.449
(Video) Abe Davis: Tres, dos, uno.

00:07:07.449 --> 00:07:12.836
♪ ♫ María tenía un corderito,
corderito, corderito ♪ ♫

00:07:12.836 --> 00:07:17.336
(Risas)

00:07:17.336 --> 00:07:20.150
AD: Este experimento parece 
súper ridículo.

00:07:20.150 --> 00:07:21.938
(Risas)

00:07:21.938 --> 00:07:24.283
Quiero decir, estoy gritando 
a una bolsa de papas fritas,

00:07:24.283 --> 00:07:25.834
(Risas)

00:07:25.834 --> 00:07:27.951
y la bombardeamos con tanta luz que,

00:07:27.951 --> 00:07:32.181
literalmente, la bolsa con la que 
lo intentamos, se derritió. (Risas)

00:07:32.181 --> 00:07:35.799
Pero por ridículo que 
se vea este experimento,

00:07:35.799 --> 00:07:37.587
en realidad, era realmente importante,

00:07:37.587 --> 00:07:40.513
porque hemos podido captar este sonido.

00:07:40.513 --> 00:07:45.225
♪ ♫ María tenía un corderito,
corderito, corderito ♪ ♫

00:07:45.225 --> 00:07:49.313
(Aplausos)

00:07:49.313 --> 00:07:51.194
AD: Y esto fue realmente significativo,

00:07:51.194 --> 00:07:55.052
porque era la primera vez que 
capturamos el habla humana inteligible

00:07:55.052 --> 00:07:57.765
a partir de un video 
silencioso de un objeto.

00:07:57.765 --> 00:08:00.156
Así que esto nos dio 
este punto de referencia,

00:08:00.156 --> 00:08:03.778
y poco a poco empezamos 
a modificar el experimento,

00:08:03.778 --> 00:08:07.911
utilizando diferentes objetos 
o alejando el objeto más,

00:08:07.911 --> 00:08:11.510
usando menos luz 
o sonidos más suaves.

00:08:11.510 --> 00:08:14.761
Y analizamos todos estos experimentos

00:08:14.761 --> 00:08:18.383
hasta realmente entender 
los límites de nuestra técnica,

00:08:18.383 --> 00:08:20.333
porque una vez que 
entendimos esos límites,

00:08:20.333 --> 00:08:22.679
podíamos encontrar 
la manera de mejorarlos.

00:08:22.679 --> 00:08:25.860
Y eso llevó a 
experimentos como este,

00:08:25.860 --> 00:08:28.599
donde de nuevo, hablo 
con una bolsa de papas,

00:08:28.599 --> 00:08:33.429
pero esta vez hemos alejado 
la cámara unos 4,5 m,

00:08:33.429 --> 00:08:36.262
tras una ventana insonorizada.

00:08:36.262 --> 00:08:40.371
y todo esto está iluminado 
solo por la luz solar natural.

00:08:40.371 --> 00:08:43.160
Así que aquí está el video 
que hemos capturado.

00:08:44.450 --> 00:08:49.009
Y así se escuchaban las cosas desde 
el interior, junto a la bolsa de papas.

00:08:49.009 --> 00:08:54.047
(Audio) "María tenía un corderito 
con piel blanca como la nieve,

00:08:54.047 --> 00:08:59.666
y a donde iba María, 
ahí iba ese corderito".

00:08:59.666 --> 00:09:03.683
AD: Y esto es lo que hemos podido 
recuperar de nuestro video en silencio

00:09:03.683 --> 00:09:06.028
capturado fuera tras esa ventana.

00:09:06.028 --> 00:09:10.463
(Audio) "María tenía un corderito 
con piel blanca como la nieve,

00:09:10.463 --> 00:09:15.920
y a donde iba María, 
ahí iba ese corderito".

00:09:15.920 --> 00:09:22.421
(Aplausos)

00:09:22.421 --> 00:09:25.963
AD: Y hay otras maneras para 
ir más allá de los límites.

00:09:25.963 --> 00:09:27.761
Así que aquí hay 
un experimento más tranquilo

00:09:27.761 --> 00:09:31.871
donde filmamos los auriculares 
conectados a una portátil,

00:09:31.871 --> 00:09:35.981
y en este caso, teníamos que recuperar 
la música que sonaba en ese portátil

00:09:35.981 --> 00:09:38.280
a partir de ese video 
simplemente en silencio

00:09:38.280 --> 00:09:40.787
a partir de estos dos 
auriculares de plástico,

00:09:40.787 --> 00:09:42.970
y lo hemos hecho tan bien

00:09:42.970 --> 00:09:45.431
que incluso puedo decir Shazam 
por los resultados.

00:09:45.431 --> 00:09:49.657
(Risas)

00:09:49.657 --> 00:09:59.225
(Música: "Under Pressure" de Queen)

00:10:01.615 --> 00:10:06.584
(Aplausos)

00:10:06.584 --> 00:10:11.135
Y también podemos mejorarlo 
cambiando el hardware que usamos.

00:10:11.135 --> 00:10:13.596
Porque los experimentos 
que he mostrado hasta ahora

00:10:13.596 --> 00:10:15.918
se realizaron con una cámara 
de alta velocidad,

00:10:15.918 --> 00:10:18.797
que puede grabar video 
100 veces más rápido

00:10:18.797 --> 00:10:20.724
que la mayoría de 
los teléfonos móviles,

00:10:20.724 --> 00:10:23.533
pero también hemos encontrado 
la manera de usar esta técnica

00:10:23.533 --> 00:10:25.763
con cámaras más convencionales,

00:10:25.763 --> 00:10:29.832
y lo hacemos aprovechando lo que 
se llama el efecto gelatina.

00:10:29.832 --> 00:10:34.630
La mayoría de las cámaras funciona 
con un fotosito por cada píxel,

00:10:34.630 --> 00:10:40.332
y si un objeto se mueve durante 
la grabación de una sola imagen,

00:10:40.344 --> 00:10:43.061
hay una leve demora entre cada fotosito,

00:10:43.061 --> 00:10:46.218
y esto hace que objetos sencillos

00:10:46.218 --> 00:10:49.701
sean codificados en 
cada fotograma de un video.

00:10:49.701 --> 00:10:53.507
Hallamos que mediante 
el análisis de estos objetos,

00:10:53.507 --> 00:10:58.122
se puede recuperar el sonido usando una 
versión modificada de nuestro algoritmo.

00:10:58.122 --> 00:11:00.034
Aquí un experimento que hicimos

00:11:00.034 --> 00:11:01.729
donde filmamos una bolsa de dulces

00:11:01.729 --> 00:11:03.470
mientras que un altavoz reproducía

00:11:03.470 --> 00:11:06.442
el mismo "María tenía un corderito",
la música de antes,

00:11:06.442 --> 00:11:10.645
pero esta vez, usamos una cámara 
comprada en la tienda normal,

00:11:10.645 --> 00:11:13.819
y en un segundo, les reproduciré 
el sonido que hemos recuperado,

00:11:13.819 --> 00:11:15.869
y esta vez sonará distorsionado,

00:11:15.869 --> 00:11:19.514
pero escuchen a ver si aún así todavía 
se puede reconocer la música.

00:11:19.514 --> 00:11:25.946
(Audio: "María tenía un corderito")

00:11:37.718 --> 00:11:40.992
Y así, una vez más, 
esto suena distorsionado,

00:11:40.992 --> 00:11:45.378
pero lo realmente sorprendente 
es que hemos podido hacerlo

00:11:45.378 --> 00:11:48.004
con algo que, literalmente, 
podría estar agotado

00:11:48.004 --> 00:11:50.222
y adquirirse en una tienda de ocasiones.

00:11:51.122 --> 00:11:52.485
Así que en este punto

00:11:52.485 --> 00:11:54.459
mucha gente verá este proyecto,

00:11:54.459 --> 00:11:57.872
y pensará de inmediato en la vigilancia.

00:11:57.872 --> 00:12:00.287
Y para ser justos,

00:12:00.287 --> 00:12:04.420
no es difícil imaginar cómo usar 
esta tecnología para espiar a alguien.

00:12:04.420 --> 00:12:08.367
Pero tengan en cuenta que ya hay 
mucha tecnología muy madura

00:12:08.367 --> 00:12:09.946
para vigilancia.

00:12:09.946 --> 00:12:12.036
De hecho, se ha estado usando láseres

00:12:12.036 --> 00:12:15.749
para espiar objetos 
a distancia durante décadas.

00:12:15.749 --> 00:12:18.003
Pero lo que es realmente nuevo aquí,

00:12:18.003 --> 00:12:19.443
lo que es realmente diferente,

00:12:19.443 --> 00:12:23.738
es que ahora tenemos una forma de 
imaginar las vibraciones de un objeto,

00:12:23.738 --> 00:12:27.151
lo que nos da una nueva lente 
a través de la cual mirar el mundo,

00:12:27.151 --> 00:12:28.661
y podemos usar esa lente,

00:12:28.661 --> 00:12:33.560
aprender no solo de fuerzas como el 
sonido que hacen que un objeto vibre,

00:12:33.560 --> 00:12:36.671
sino también sobre el propio objeto.

00:12:36.671 --> 00:12:38.668
Y por eso quiero dar un paso atrás

00:12:38.668 --> 00:12:42.917
y pensar en cómo podría cambiar 
la manera de usar el video,

00:12:42.917 --> 00:12:46.470
porque normalmente usamos 
el video para mirar las cosas,

00:12:46.470 --> 00:12:48.792
y acabo de mostrar cómo podemos usarlo

00:12:48.792 --> 00:12:50.649
para escuchar las cosas.

00:12:50.649 --> 00:12:54.620
Pero hay otra forma importante 
en que aprendemos del mundo:

00:12:54.620 --> 00:12:56.895
y es interactuando con él.

00:12:56.895 --> 00:13:00.006
Empujamos, estiramos, 
metemos y desplazamos cosas.

00:13:00.006 --> 00:13:03.187
Estrechamos las cosas para ver qué pasa.

00:13:03.187 --> 00:13:07.460
Y eso es algo que el video 
aún no nos deja hacer;

00:13:07.460 --> 00:13:09.596
al menos no el tradicional.

00:13:09.596 --> 00:13:11.546
Así que les mostraré 
un nuevo trabajo,

00:13:11.546 --> 00:13:14.212
y esto se basa en una idea que 
tuve hace apenas unos meses,

00:13:14.212 --> 00:13:17.513
es pues la primera vez que lo muestro 
públicamente a una audiencia.

00:13:17.513 --> 00:13:22.877
Y la idea básica es que usaremos 
las vibraciones en un video

00:13:22.877 --> 00:13:27.358
para capturar objetos de forma que 
nos permitirá interactuar con ellos

00:13:27.358 --> 00:13:30.290
para ver cómo reaccionan con nosotros.

00:13:31.120 --> 00:13:32.884
Aquí hay un objeto,

00:13:32.884 --> 00:13:36.716
y en este caso, es una figura 
de alambre en forma de ser humano,

00:13:36.716 --> 00:13:39.804
y filmaremos ese objeto 
con una cámara normal.

00:13:39.804 --> 00:13:41.928
No hay nada de especial 
en esta cámara.

00:13:41.928 --> 00:13:44.889
En realidad, he hecho esto 
con mi teléfono móvil antes.

00:13:44.889 --> 00:13:47.141
Pero queremos ver cómo vibra el objeto,

00:13:47.141 --> 00:13:48.274
así que para que esto suceda,

00:13:48.274 --> 00:13:51.620
golpearemos un poco 
en la superficie donde yace

00:13:51.620 --> 00:13:53.758
mientras grabamos un video.

00:13:59.398 --> 00:14:03.069
Así que es eso: solo 5 segundos 
de video normal,

00:14:03.069 --> 00:14:05.205
mientras golpeamos en esta superficie,

00:14:05.205 --> 00:14:08.718
y usaremos las vibraciones de ese video

00:14:08.718 --> 00:14:13.262
para aprender algunas propiedades 
estructurales y materiales del objeto,

00:14:13.262 --> 00:14:18.096
y usaremos esa información para 
crear algo nuevo e interactivo.

00:14:25.073 --> 00:14:27.519
Y así, esto es lo que hemos creado.

00:14:27.519 --> 00:14:29.748
Y parece una imagen común,

00:14:29.748 --> 00:14:32.859
pero no es una imagen, 
ni un video,

00:14:32.859 --> 00:14:35.227
porque ahora puedo desplazar mi ratón

00:14:35.227 --> 00:14:38.086
y empezar a interactuar con el objeto.

00:14:44.936 --> 00:14:46.489
Y, cómo se ve aquí,

00:14:46.489 --> 00:14:49.615
es una simulación de cómo este objeto

00:14:49.615 --> 00:14:54.073
respondería a las nuevas fuerzas 
que nunca hemos visto antes,

00:14:54.073 --> 00:14:58.345
y lo creamos a partir de tan solo 
5 segundos de video normal.

00:14:58.345 --> 00:15:03.964
(Aplausos)

00:15:09.421 --> 00:15:12.648
Y esta es una forma muy poderosa 
de mirar el mundo,

00:15:12.648 --> 00:15:15.620
porque nos permite predecir 
cómo responderán los objetos

00:15:15.620 --> 00:15:17.443
a las nuevas situaciones,

00:15:17.443 --> 00:15:20.916
y uno puede imaginar, por ejemplo, 
mirar un viejo puente

00:15:20.916 --> 00:15:24.443
y preguntarse qué ocurriría, 
cómo aguantará ese puente

00:15:24.443 --> 00:15:27.276
si lo atravieso con mi auto.

00:15:27.276 --> 00:15:30.050
Y esa es una pregunta que 
probablemente desee responder

00:15:30.050 --> 00:15:33.988
antes de empezar 
a atravesar ese puente.

00:15:33.988 --> 00:15:37.260
Y, por supuesto, habrá 
limitaciones a esta técnica,

00:15:37.260 --> 00:15:39.722
al igual que había 
con el micrófono visual,

00:15:39.722 --> 00:15:42.903
pero hemos encontrado que 
funciona en muchas situaciones

00:15:42.903 --> 00:15:44.778
que no se podría esperar,

00:15:44.778 --> 00:15:47.546
especialmente con videos más largos.

00:15:47.546 --> 00:15:50.054
Así, por ejemplo, aquí hay 
un video que capturé

00:15:50.054 --> 00:15:52.353
de un arbusto fuera de mi apartamento,

00:15:52.353 --> 00:15:55.441
y no le hice nada a este arbusto,

00:15:55.441 --> 00:15:58.146
solo capturar un video durante un minuto,

00:15:58.146 --> 00:16:01.524
una suave brisa causó 
bastantes vibraciones

00:16:01.524 --> 00:16:05.519
para aprender lo suficiente sobre 
este arbusto y crear esta simulación.

00:16:07.909 --> 00:16:13.412
(Aplausos)

00:16:13.412 --> 00:16:16.384
Y uno podría imaginar 
dárselo a un director de cine,

00:16:16.384 --> 00:16:18.103
y dejarle el control, por ejemplo,

00:16:18.103 --> 00:16:23.025
la fuerza y ​​dirección del viento en 
una toma después de haberla grabado.

00:16:24.810 --> 00:16:29.345
O, en este caso, apuntamos 
la cámara a una cortina,

00:16:29.345 --> 00:16:33.474
y ni siquiera se puede ver 
movimiento en el video,

00:16:33.474 --> 00:16:36.399
sino por la grabación 
de dos minutos de video,

00:16:36.399 --> 00:16:38.837
de corrientes de aire naturales 
en esta sala, creando

00:16:38.837 --> 00:16:43.249
suficientes movimientos y vibraciones
y imperceptibles sutiles

00:16:43.249 --> 00:16:46.244
de las que aprender lo suficiente 
para crear esta simulación.

00:16:48.705 --> 00:16:50.609
E irónicamente,

00:16:50.609 --> 00:16:53.697
estamos muy acostumbrados a tener 
este tipo de interactividad

00:16:53.697 --> 00:16:56.344
con objetos virtuales,

00:16:56.344 --> 00:16:59.641
juegos de video y modelos 3D,

00:16:59.641 --> 00:17:04.045
pero para capturar esta información 
a partir de objetos del mundo real

00:17:04.045 --> 00:17:06.862
el uso de este simple video, normal

00:17:06.862 --> 00:17:10.664
es algo nuevo que tiene mucho potencial.

00:17:10.664 --> 00:17:14.801
Así están las increíbles personas que 
trabajaron conmigo en estos proyectos.

00:17:16.057 --> 00:17:21.653
(Aplausos)

00:17:24.486 --> 00:17:27.876
Y lo que les he mostrado hoy 
es solo el comienzo.

00:17:27.876 --> 00:17:29.989
Acabamos de empezar 
a arañar la superficie

00:17:29.989 --> 00:17:32.961
de lo que se puede hacer 
con este tipo de imágenes,

00:17:32.961 --> 00:17:35.097
porque nos da una nueva forma

00:17:35.097 --> 00:17:40.066
para capturar nuestro entorno 
con tecnología común, accesible.

00:17:40.066 --> 00:17:41.995
Y así, mirar hacia el futuro,

00:17:41.995 --> 00:17:44.032
que será muy emocionante explorar

00:17:44.032 --> 00:17:46.683
lo que esto nos puede 
decir sobre el mundo.

00:17:46.683 --> 00:17:48.424
Gracias.

00:17:48.424 --> 00:17:51.424
(Aplausos)

