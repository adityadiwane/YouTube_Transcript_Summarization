WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Patrizia C Romeo Tomasini
Revisore: Elena Montrasio

00:00:12.974 --> 00:00:17.889
In genere pensiamo al movimento
come un fatto prevalentemente visivo.

00:00:17.889 --> 00:00:22.977
Se io attraverso questo palcoscenico
o faccio dei gesti mentre parlo,

00:00:22.977 --> 00:00:26.255
i miei movimenti
sono qualcosa che si può vedere.

00:00:26.255 --> 00:00:31.737
Ma esiste tutta una serie di movimenti
impercettibili all'occhio umano

00:00:31.737 --> 00:00:33.778
e, nel corso degli ultimi anni,

00:00:33.778 --> 00:00:35.775
abbiamo osservato che le telecamere

00:00:35.775 --> 00:00:39.185
riescono a vedere questi movimenti
che sono invisibili all'occhio umano.

00:00:40.163 --> 00:00:41.837
Passo ora a mostrarvi cosa intendo.

00:00:42.717 --> 00:00:46.339
Sulla sinistra, vedete un video
che riprende il polso di una persona

00:00:46.339 --> 00:00:49.486
mentre, sulla destra, vedete il video
di un bambino che dorme.

00:00:49.486 --> 00:00:52.632
Se non vi avessi detto
che si trattava di filmati,

00:00:52.632 --> 00:00:56.393
si potrebbe supporre che si tratti
di normali fotografie

00:00:56.393 --> 00:00:58.065
perché, in entrambi i casi,

00:00:58.065 --> 00:01:02.175
questi video appaiono
quasi completamente fermi.

00:01:02.175 --> 00:01:06.060
Ma in realtà ci sono tantissimi 
movimenti sottili in atto.

00:01:06.060 --> 00:01:08.452
Infatti, se toccassimo il polso
sulla sinistra,

00:01:08.452 --> 00:01:10.448
potremmo avvertire il battito del polso

00:01:10.448 --> 00:01:12.933
e se prendessimo in braccio
il bambino sulla destra,

00:01:12.933 --> 00:01:15.324
avvertiremmo il suo petto
sollevarsi e abbassarsi

00:01:15.324 --> 00:01:17.762
nei movimenti respiratori.

00:01:17.762 --> 00:01:21.338
Questi movimenti
sono molto significativi,

00:01:21.338 --> 00:01:24.681
ma sono troppo piccoli
per essere visti,

00:01:24.681 --> 00:01:26.957
e per essere in grado di osservarli

00:01:26.957 --> 00:01:30.997
abbiamo bisogno del contatto diretto.

00:01:30.997 --> 00:01:32.262
Alcuni anni fa,

00:01:32.262 --> 00:01:36.667
i miei colleghi del MIT hanno creato
il cosiddetto microscopio da movimento,

00:01:36.667 --> 00:01:41.051
vale a dire un software che individua
i movimenti sottili nei video

00:01:41.051 --> 00:01:45.416
e li amplifica per fare in modo
che siano visibili al nostro occhio.

00:01:45.416 --> 00:01:48.899
Adoperando questo software
sul video di sinistra,

00:01:48.899 --> 00:01:52.149
saremo in grado di vedere
il battito del polso

00:01:52.149 --> 00:01:53.844
e, se cominciamo a contare,

00:01:53.844 --> 00:01:57.095
potremmo anche ricavare
la frequenza cardiaca della persona.

00:01:57.095 --> 00:02:00.160
Con lo stesso software,
sul video di destra

00:02:00.160 --> 00:02:03.387
potremmo vedere
ogni singolo respiro del bambino

00:02:03.387 --> 00:02:07.524
e potremmo usare questo mezzo
per monitorare il respiro senza contatto.

00:02:08.884 --> 00:02:14.232
La grandezza di questa tecnologia
sta nel fatto che questi fenomeni,

00:02:14.232 --> 00:02:16.599
normalmente percepiti
con il contatto fisico,

00:02:16.599 --> 00:02:19.914
possono essere catturati in modo visivo
e non invasivo.

00:02:21.104 --> 00:02:25.515
Un paio di anni fa, iniziai a lavorare
con i creatori del software

00:02:25.515 --> 00:02:28.882
e decidemmo di approfondire un'idea folle.

00:02:28.882 --> 00:02:31.575
Pensavamo che andasse bene
usare il software

00:02:31.575 --> 00:02:34.710
per visualizzare movimenti minuscoli
come questi,

00:02:34.710 --> 00:02:39.168
è come un modo per ampliare
il senso del tatto.

00:02:39.168 --> 00:02:43.227
Ma che accadrebbe se facessimo
la stessa cosa con l'udito?

00:02:44.508 --> 00:02:49.173
Se potessimo usare dei video
per catturare la vibrazione dei suoni,

00:02:49.173 --> 00:02:52.000
che altro non sono
se non un diverso tipo di movimento,

00:02:52.000 --> 00:02:55.346
e trasformare tutto ciò che vediamo
in una sorta di microfono?

00:02:56.236 --> 00:02:58.207
Certo, l'idea può suonare strana,

00:02:58.207 --> 00:03:01.760
perciò permettetemi
di illustrarvela meglio.

00:03:01.760 --> 00:03:05.011
I microfoni tradizionali
funzionano convertendo il movimento

00:03:05.011 --> 00:03:08.610
di un diaframma interno
in un segnale elettrico

00:03:08.610 --> 00:03:12.928
e il diaframma è fatto in modo
da muoversi appena colpito dal suono

00:03:12.928 --> 00:03:17.735
così che il suo movimento possa essere
registrato e interpretato come audio.

00:03:17.735 --> 00:03:21.403
Il suono fa vibrare tutte le cose,

00:03:21.403 --> 00:03:26.883
ma quelle vibrazioni, di solito, 
sono troppo piccole e veloci da vedere.

00:03:26.883 --> 00:03:30.621
E se si potessero registrare
con una video camera ad alta velocità

00:03:30.621 --> 00:03:34.197
e quindi usare il software
per estrarre i movimenti impercettibili

00:03:34.197 --> 00:03:36.287
dal nostro video ad alta velocità,

00:03:36.287 --> 00:03:41.129
analizzando quei movimenti per capire
da quali suoni abbiano avuto origine?

00:03:41.859 --> 00:03:47.308
Si potrebbero trasformare oggetti visibili
in microfoni visivi a distanza.

00:03:49.080 --> 00:03:51.263
Noi abbiamo provato a farlo.

00:03:51.263 --> 00:03:53.190
In uno dei nostri esperimenti,

00:03:53.190 --> 00:03:56.139
abbiamo preso una pianta in vaso,
che vedete sulla destra,

00:03:56.139 --> 00:03:58.577
e l'abbiamo ripresa ad alta velocità

00:03:58.577 --> 00:04:02.106
mentre un altoparlante
emetteva questo suono.

00:04:02.106 --> 00:04:10.799
(Musica: "Mary aveva un agnellino")

00:04:11.820 --> 00:04:14.644
Ecco il video che abbiamo registrato

00:04:14.644 --> 00:04:18.568
e nonostante sia stato registrato
a migliaia di frame al secondo,

00:04:18.568 --> 00:04:20.890
anche se guardate molto da vicino,

00:04:20.890 --> 00:04:22.841
non vedrete altro che delle foglie

00:04:22.841 --> 00:04:25.906
che se ne stanno lì 
senza far nulla

00:04:25.906 --> 00:04:30.712
perché il nostro suono muoveva le foglie
di appena un micrometro,

00:04:31.455 --> 00:04:35.379
vale a dire la decimillesima parte
di un centimetro,

00:04:35.379 --> 00:04:39.535
che va da un centesimo
a un millesimo di un pixel

00:04:39.535 --> 00:04:42.423
in questa immagine.

00:04:42.423 --> 00:04:44.768
Potete strizzare gli occhi quanto volete,

00:04:44.768 --> 00:04:48.597
movimenti così piccoli sono
impossibili da percepire.

00:04:49.667 --> 00:04:53.824
Ma ci sono cose che, 
anche se non percepibili visivamente,

00:04:53.824 --> 00:04:56.633
sono comunque significative
a livello numerico,

00:04:56.633 --> 00:04:58.635
perché con gli algoritmi giusti,

00:04:58.635 --> 00:05:02.322
da un video apparentemente
silenzioso come questo

00:05:02.322 --> 00:05:04.690
è possibile recuperare questo suono.

00:05:04.690 --> 00:05:12.074
(Musica: "Mary aveva un agnellino")

00:05:12.074 --> 00:05:17.902
(Applausi)

00:05:22.058 --> 00:05:23.997
Com'è possibile?

00:05:23.997 --> 00:05:28.341
Come ricavare tante informazioni
da una quantità di moto così piccola?

00:05:28.341 --> 00:05:33.702
Ipotizziamo che quelle foglie
si siano mosse di un solo micrometro

00:05:33.702 --> 00:05:39.495
e che la nostra immagine subisca
uno spostamento di un singolo pixel.

00:05:39.495 --> 00:05:41.841
Potrà sembrare pochissimo,

00:05:41.841 --> 00:05:43.837
ma un unico frame

00:05:43.837 --> 00:05:47.094
può contenere centinaia di migliaia
di pixel

00:05:47.094 --> 00:05:50.548
per cui combinando tutti i movimenti 
microscopici che vediamo

00:05:50.548 --> 00:05:52.846
in tutta l'immagine,

00:05:52.846 --> 00:05:55.469
improvvisamente migliaia di pixel

00:05:55.469 --> 00:05:59.185
cominciano a sommarsi
per formare qualcosa di significativo.

00:05:59.185 --> 00:06:02.505
E vi dirò, la cosa ci esaltò non poco
quando capimmo come funzionava.

00:06:02.505 --> 00:06:04.825
(Risate)

00:06:04.825 --> 00:06:08.078
Ma anche con l'algoritmo giusto,

00:06:08.078 --> 00:06:11.695
mancava ancora un pezzo
piuttosto importante del puzzle.

00:06:11.695 --> 00:06:15.299
Molti sono i fattori che influiscono

00:06:15.299 --> 00:06:17.296
sul funzionamento di questa tecnica.

00:06:17.296 --> 00:06:20.500
Può dipendere dall'oggetto
e dalla sua distanza;

00:06:20.500 --> 00:06:22.894
dalla telecamera usata
e dal tipo di lente;

00:06:22.894 --> 00:06:26.985
dal modo in cui l'oggetto è illuminato
e dal volume del suono.

00:06:27.945 --> 00:06:31.320
E anche disponendo 
dell'algoritmo giusto,

00:06:31.320 --> 00:06:34.710
dovevamo stare molto attenti
nei nostri primi esperimenti

00:06:34.710 --> 00:06:37.102
perché se anche uno solo dei fattori
era sbagliato,

00:06:37.102 --> 00:06:39.470
era assolutamente impossibile
dire quale fosse.

00:06:39.470 --> 00:06:42.117
Avremmo solo ottenuto dei rumori.

00:06:42.117 --> 00:06:45.437
Molti dei nostri esperimenti iniziali
erano più o meno così.

00:06:45.437 --> 00:06:47.643
Qui ci sono io

00:06:47.643 --> 00:06:51.683
e sulla sinistra in basso s'intravvede
la telecamera ad alta velocità

00:06:51.683 --> 00:06:53.866
puntata su una busta di patatine

00:06:53.866 --> 00:06:56.815
e il tutto è illuminato
da una lampada.

00:06:56.815 --> 00:07:01.180
Dovevamo stare molto attenti
con questi primi esperimenti

00:07:01.180 --> 00:07:03.688
ed ecco come andava.

00:07:03.688 --> 00:07:07.449
(Video) Abe Davis: Tre, due, uno, via.

00:07:07.449 --> 00:07:12.836
Mari aveva un agnellino!
Un agnellino! Un agnellino!

00:07:12.836 --> 00:07:17.336
(Risate)

00:07:17.336 --> 00:07:20.150
AD: questo esperimento
è assolutamente ridicolo.

00:07:20.150 --> 00:07:21.938
(Risate)

00:07:21.938 --> 00:07:24.283
Insomma,
io che urlo a una busta di patatine...

00:07:24.283 --> 00:07:25.834
(Risate)

00:07:25.834 --> 00:07:27.951
e la luce
è praticamente sparata a giorno,

00:07:27.951 --> 00:07:32.181
la prima busta si sciolse letteralmente
quando facemmo la prova. (Risate)

00:07:32.181 --> 00:07:35.799
Ma per quanto questo esperimento
possa sembrare ridicolo,

00:07:37.587 --> 00:07:40.513
perché riuscimmo
a recuperare questo suono.

00:07:40.513 --> 00:07:45.225
(Audio) Mary aveva un agnellino!
Un agnellino! Un agnellino!

00:07:45.225 --> 00:07:49.313
(Applausi)

00:07:49.313 --> 00:07:51.194
AD: La cosa era piuttosto significativa:

00:07:51.194 --> 00:07:55.052
per la prima volta recuperavamo
voce umana intelligibile

00:07:55.052 --> 00:07:57.765
dal video muto di un oggetto.

00:07:57.765 --> 00:08:00.156
L'esperimento ci fornì
un punto di riferimento

00:08:00.156 --> 00:08:03.778
e, gradualmente, cominciammo
a modificare il procedimento,

00:08:03.778 --> 00:08:07.911
usando oggetti diversi
oppure spostandoli più lontano,

00:08:07.911 --> 00:08:11.510
diminuendo la luce o usando
suoni più deboli.

00:08:11.510 --> 00:08:14.761
Analizzammo tutti gli esperimenti

00:08:14.761 --> 00:08:18.383
fino a che non ci furono chiari i limiti
della nostra tecnica

00:08:18.383 --> 00:08:20.333
e, una volta compresi i limiti,

00:08:20.333 --> 00:08:22.679
riuscimmo a capire come superarli.

00:08:22.679 --> 00:08:25.860
Ciò condusse 
a esperimenti come questo,

00:08:25.860 --> 00:08:28.599
in cui io parlo di nuovo
a una busta di patatine,

00:08:28.599 --> 00:08:33.429
ma questa volta la telecamera
si trova a circa 4,5 metri di distanza,

00:08:33.429 --> 00:08:36.262
all'esterno, dietro a un vetro antirumore.

00:08:36.262 --> 00:08:40.371
Tutta la scena è illuminata
da luce naturale diurna.

00:08:40.371 --> 00:08:43.160
Questo è il video che abbiamo ripreso.

00:08:44.450 --> 00:08:49.009
Questi sono i suoni udibili dall'interno,
vicino alla busta di patatine.

00:08:49.009 --> 00:08:54.047
(Audio): "Mary aveva un agnellino
con il manto bianco come la neve

00:08:54.047 --> 00:08:59.666
e ovunque Mary andava,
l'agnello la seguiva."

00:08:59.666 --> 00:09:03.683
AD: E questo è quanto abbiamo
recuperato dal video muto

00:09:03.683 --> 00:09:06.028
ripreso all'esterno, fuori della finestra.

00:09:06.028 --> 00:09:10.463
(Audio): "Mary aveva un agnellino
con il manto bianco come la neve

00:09:10.463 --> 00:09:15.920
e ovunque Mary andava,
l'agnello la seguiva."

00:09:15.920 --> 00:09:22.421
(Applauso)

00:09:22.421 --> 00:09:25.963
AD: Ma ci sono altri modi
per superare i limiti.

00:09:25.963 --> 00:09:27.761
Questo è un esperimento
più tranquillo

00:09:27.761 --> 00:09:31.871
in cui abbiamo filmato degli auricolari
connessi a un computer portatile.

00:09:31.871 --> 00:09:35.981
Il nostro scopo era recuperare
la musica suonata dal computer

00:09:35.981 --> 00:09:38.280
dal video muto che riprendeva

00:09:38.280 --> 00:09:40.787
i due auricolari di plastica

00:09:40.787 --> 00:09:42.970
e siamo stati così bravi
che abbiamo potuto

00:09:42.970 --> 00:09:45.431
addirittura usare il risultato con Shazam.

00:09:45.431 --> 00:09:49.657
(Risate)

00:09:49.657 --> 00:09:59.225
(Musica: "Under Pressure" dei Queen)

00:10:01.615 --> 00:10:06.584
(Applauso)

00:10:06.584 --> 00:10:11.135
Possiamo influire sui risultati
anche cambiando tipo di hardware.

00:10:11.135 --> 00:10:13.596
Gli esperimenti
che vi ho mostrato finora

00:10:13.596 --> 00:10:15.918
sono stati fatti
con una telecamera high-speed

00:10:15.918 --> 00:10:18.797
che può registrare video
a una velocità 100 volte superiore

00:10:18.797 --> 00:10:20.724
a quella dei cellulari,

00:10:20.724 --> 00:10:23.533
ma abbiamo trovato il modo
di usare questa tecnica

00:10:23.533 --> 00:10:25.763
con telecamere normali,

00:10:25.763 --> 00:10:29.832
approfittando di un effetto 
comunemente chiamato "rolling shutter".

00:10:29.832 --> 00:10:34.630
La maggior parte delle telecamere
registrano le immagini una riga alla volta

00:10:34.630 --> 00:10:40.332
quindi, se un soggetto si muove
durante la registrazione di un'immagine,

00:10:40.344 --> 00:10:43.061
c'è un leggero ritardo
tra una riga e l'altra,

00:10:43.061 --> 00:10:46.218
questo fa sì che piccoli artefatti

00:10:46.218 --> 00:10:49.701
vengano codificati
in ciascun frame di un video.

00:10:49.701 --> 00:10:53.507
Analizzando questi artefatti,
riusciamo a recuperare suoni

00:10:53.507 --> 00:10:58.122
usando una versione modificata
del nostro algoritmo.

00:10:58.122 --> 00:11:00.034
In questo esperimento

00:11:00.034 --> 00:11:01.729
abbiamo filmato
un pacco di caramelle

00:11:01.729 --> 00:11:03.470
mentre da un altoparlante vicino

00:11:03.470 --> 00:11:06.442
arrivava la musica di prima
"Mary aveva un agnellino",

00:11:06.442 --> 00:11:10.645
ma questa volta abbiamo usato
una normale telecamera commerciale

00:11:10.645 --> 00:11:13.819
e in un attimo riprodurrò per voi
il suono che abbiamo recuperato.

00:11:13.819 --> 00:11:15.869
Questa volta
il suono sarà distorto,

00:11:15.869 --> 00:11:19.514
ma ascoltate e vedete
se riuscite a riconoscere la musica.

00:11:19.514 --> 00:11:25.946
(Audio: "Mary aveva un agnellino")

00:11:37.718 --> 00:11:40.992
Il suono, certo, risulta distorto,

00:11:40.992 --> 00:11:45.378
ma è pur vero che la telecamera
che abbiamo usato

00:11:45.378 --> 00:11:48.004
era una di quelle
che si potevano comprare

00:11:48.004 --> 00:11:50.222
al negozio sotto casa.

00:11:51.122 --> 00:11:52.485
A questo punto,

00:11:52.485 --> 00:11:54.459
molte persone 
che vedono questo lavoro,

00:11:54.459 --> 00:11:57.872
pensano immediatamente
ai servizi di vigilanza.

00:11:57.872 --> 00:12:00.287
E per la verità,

00:12:00.287 --> 00:12:04.420
è molto facile immaginare di usare
questa tecnologia per spiare qualcuno.

00:12:04.420 --> 00:12:08.367
Ma ricordate che esiste già
una tecnologia molto evoluta

00:12:08.367 --> 00:12:09.946
per i sistemi di sorveglianza.

00:12:09.946 --> 00:12:12.036
I laser, ad esempio, sono stati usati

00:12:12.036 --> 00:12:15.749
per decenni per intercettare oggetti
a distanza.

00:12:15.749 --> 00:12:18.003
L'elemento veramente nuovo

00:12:18.003 --> 00:12:19.443
e diverso che si presenta qui

00:12:19.443 --> 00:12:23.738
è un modo nuovo di raffigurare
le vibrazioni di un oggetto

00:12:23.738 --> 00:12:27.151
che ci dà una nuova lente
attraverso la quale guardare il mondo.

00:12:27.151 --> 00:12:28.661
Possiamo usare questa lente

00:12:28.661 --> 00:12:33.560
non solo per imparare che forze
come il suono fanno vibrare un oggetto,

00:12:33.560 --> 00:12:36.671
ma anche per imparare qualcosa
sull'oggetto stesso.

00:12:36.671 --> 00:12:38.668
Ora faccio un passo indietro
per riflettere

00:12:38.668 --> 00:12:42.917
su come ciò potrebbe cambiare
il nostro modo di usare il video.

00:12:42.917 --> 00:12:46.470
Di solito usiamo il video
per guardare degli oggetti,

00:12:46.470 --> 00:12:48.792
ma, come vi ho appena dimostrato,
si può usare anche

00:12:48.792 --> 00:12:50.649
per ascoltare gli oggetti.

00:12:50.649 --> 00:12:54.620
Ma c'è un altro modo fondamentale
per conoscere il mondo

00:12:54.620 --> 00:12:56.895
ed è l'interazione.

00:12:56.895 --> 00:13:00.006
Noi tiriamo, spingiamo
e tocchiamo le cose.

00:13:00.006 --> 00:13:03.187
Le agitiamo e poi
stiamo a guardare cosa succede.

00:13:03.187 --> 00:13:07.460
Ma questo il video
non ci permette di farlo,

00:13:07.460 --> 00:13:09.596
almeno non in modo tradizionale.

00:13:09.596 --> 00:13:11.546
Per cui voglio ora mostrarvi
un lavoro nuovo,

00:13:11.546 --> 00:13:14.212
basato su in'idea
che ho avuto alcuni mesi fa

00:13:14.212 --> 00:13:17.513
ed è la prima volta
che lo faccio vedere in pubblico.

00:13:17.513 --> 00:13:22.877
L'idea di fondo è quella
di usare le vibrazioni in un video

00:13:22.877 --> 00:13:27.358
per riprendere gli oggetti in modo
che sia possibile un'interazione con essi

00:13:27.358 --> 00:13:30.290
e vedere in che modo reagiscono a noi.

00:13:31.120 --> 00:13:32.884
Questo è un oggetto.

00:13:32.884 --> 00:13:36.716
In questo caso, si tratta di una figura
di ferro filato con forma umana.

00:13:36.716 --> 00:13:39.804
Riprenderemo l'oggetto 
con una normale telecamera.

00:13:39.804 --> 00:13:41.928
Non c'è nulla di speciale
in questa telecamera.

00:13:41.928 --> 00:13:44.889
Anzi, altre volte l'ho fatto
con il mio telefono cellulare.

00:13:44.889 --> 00:13:47.141
Noi vogliamo vedere come l'oggetto vibra,

00:13:47.141 --> 00:13:48.274
e perché ciò accada,

00:13:48.274 --> 00:13:51.620
andremo a colpire leggermente
la superficie sulla quale si trova

00:13:51.620 --> 00:13:53.758
mentre giriamo il video.

00:13:59.398 --> 00:14:03.069
E questo è tutto: cinque secondi
di normale ripresa,

00:14:03.069 --> 00:14:05.205
mentre la superficie viene percossa

00:14:05.205 --> 00:14:08.718
e poi useremo le vibrazioni
presenti nel video

00:14:08.718 --> 00:14:13.262
per conoscere le proprietà strutturali
e materiali del nostro oggetto.

00:14:13.262 --> 00:14:18.096
Useremo quelle informazioni per creare
qualcosa di nuovo e interattivo.

00:14:25.073 --> 00:14:27.519
Ed ecco la nostra creazione.

00:14:27.519 --> 00:14:29.748
All'apparenza
è una normalissima immagine

00:14:29.748 --> 00:14:32.859
eppure non è un'immagine
e neanche un video

00:14:32.859 --> 00:14:35.227
perché ora io posso prendere il mouse

00:14:35.227 --> 00:14:38.086
e iniziare a interagire
con l'oggetto.

00:14:44.936 --> 00:14:46.489
Quella che vedete

00:14:46.489 --> 00:14:49.615
è una simulazione di come quest'oggetto

00:14:49.615 --> 00:14:54.073
risponderebbe a forze nuove
e sconosciute,

00:14:54.073 --> 00:14:58.345
una creazione fatta grazie a un normale
video di cinque secondi.

00:14:58.345 --> 00:15:03.964
(Applauso)

00:15:09.421 --> 00:15:12.648
Questa visione del mondo
è davvero efficace

00:15:12.648 --> 00:15:15.620
perché ci consente di prevedere
come gli oggetti risponderanno

00:15:15.620 --> 00:15:17.443
a situazioni nuove.

00:15:17.443 --> 00:15:20.916
Immaginate, ad esempio,
di guardare un vecchio ponte

00:15:20.916 --> 00:15:24.443
chiedendovi cosa succederebbe
e se quel ponte reggerebbe

00:15:24.443 --> 00:15:27.276
passandoci sopra con la macchina.

00:15:27.276 --> 00:15:30.050
Un interrogativo al quale certamente
vorreste rispondere

00:15:30.050 --> 00:15:33.988
prima di cominciare
ad attraversare il ponte.

00:15:33.988 --> 00:15:37.260
Naturalmente ci saranno dei limiti
a questa tecnica,

00:15:37.260 --> 00:15:39.722
esattamente 
come per il microfono visivo,

00:15:39.722 --> 00:15:42.903
ma abbiamo sperimentato che funziona
in molte situazioni

00:15:42.903 --> 00:15:44.778
in cui non ce lo aspetteremmo,

00:15:44.778 --> 00:15:47.546
specie se si fanno video più lunghi.

00:15:47.546 --> 00:15:50.054
Questo, ad esempio,
è il video di un cespuglio

00:15:50.054 --> 00:15:52.353
girato fuori casa mia.

00:15:52.353 --> 00:15:55.441
Nulla è stato fatto a questo cespuglio

00:15:55.441 --> 00:15:58.146
se non girare un video di un minuto.

00:15:58.146 --> 00:16:01.524
Una sottile brezza ha causato
vibrazioni sufficienti

00:16:01.524 --> 00:16:05.519
a farci imparare quanto era necessario
per creare questa simulazione.

00:16:07.909 --> 00:16:13.412
(Applausi)

00:16:13.412 --> 00:16:16.384
Immaginate questa tecnologia
nelle mani di un regista

00:16:16.384 --> 00:16:18.103
per controllare, ad esempio,

00:16:18.103 --> 00:16:23.025
la forza e la direzione del vento
di una scena dopo che è stata girata.

00:16:24.810 --> 00:16:29.345
In questo caso, abbiamo puntato
la telecamera verso una tenda

00:16:29.345 --> 00:16:33.474
e, vedete, non c'è alcun movimento
in questo video.

00:16:33.474 --> 00:16:36.399
Ma girando per due minuti,

00:16:36.399 --> 00:16:38.837
le naturali correnti d'aria nella stanza

00:16:38.837 --> 00:16:43.249
hanno creato impercettibili movimenti
e vibrazioni sufficienti

00:16:43.249 --> 00:16:46.244
da farci imparare quanto basta
per creare questa simulazione.

00:16:48.705 --> 00:16:50.609
E paradossalmente,

00:16:50.609 --> 00:16:53.697
noi siamo abbastanza abituati
a questo tipo di interattività

00:16:53.697 --> 00:16:56.344
quando si tratta di oggetti virtuali,

00:16:56.344 --> 00:16:59.641
video game
e modelli tridimensionali,

00:16:59.641 --> 00:17:04.045
ma riuscire a carpire queste informazioni
da oggetti reali nel mondo reale

00:17:04.045 --> 00:17:06.862
per mezzo di semplici video,

00:17:06.862 --> 00:17:10.414
è un fatto nuovo
con potenzialità enormi.

00:17:10.414 --> 00:17:16.111
Ecco le persone straordinarie che hanno
lavorato con me su questi progetti.

00:17:16.111 --> 00:17:24.466
(Applausi)

00:17:24.466 --> 00:17:27.756
Quello che vi ho mostrato oggi
è solo il principio.

00:17:27.756 --> 00:17:29.989
Abbiamo solo cominciato
a scalfire la superficie

00:17:29.989 --> 00:17:32.961
di ciò che è possibile fare
con questo tipo di imaging

00:17:32.961 --> 00:17:35.097
che ci dà un nuovo modo

00:17:35.097 --> 00:17:40.066
di catturare il mondo circostante
con una tecnologia comune, accessibile.

00:17:40.066 --> 00:17:41.995
Guardando al futuro, credo

00:17:41.995 --> 00:17:44.032
che sarà davvero
interessante esplorare

00:17:44.032 --> 00:17:46.683
ciò che questa tecnologia
saprà dirci del mondo.

00:17:46.683 --> 00:17:48.424
Grazie.

00:17:48.424 --> 00:17:54.531
(Applauso)

