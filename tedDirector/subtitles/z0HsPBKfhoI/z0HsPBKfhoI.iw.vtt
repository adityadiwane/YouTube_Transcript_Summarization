WEBVTT
Kind: captions
Language: iw

00:00:00.000 --> 00:00:07.000
מתרגם: Ilan Caner
מבקר: Ido Dekkers

00:00:12.580 --> 00:00:16.420
בילדותי הייתי החנון המוחלט.

00:00:17.140 --> 00:00:19.316
אני חושב שכמה מכם היו גם.

00:00:19.340 --> 00:00:20.556
(צחוק)

00:00:20.580 --> 00:00:23.796
ואתה אדוני, שצחקת הכי חזק, 
כנראה עדיין גם היום.

00:00:23.820 --> 00:00:26.076
(צחוק)

00:00:26.100 --> 00:00:29.596
גדלתי בעיר קטנה במרחבים המאובקים 
של צפון טקסס,

00:00:29.620 --> 00:00:32.956
בנו של השריף שהיה בן של כומר.

00:00:32.980 --> 00:00:34.900
להיקלע לצרות לא היתה אופציה.

00:00:35.860 --> 00:00:39.116
אז התחלתי לקרוא ספרי חשבון בשביל הכיף.

00:00:39.140 --> 00:00:40.676
(צחוק)

00:00:40.700 --> 00:00:42.396
אתם גם.

00:00:42.420 --> 00:00:46.156
זה הוביל אותי לבניית לייזר ומחשב
ומודלים של טילים,

00:00:46.180 --> 00:00:49.180
מה שהוביל אותי לייצר דלק טילים
בחדר השינה שלי.

00:00:49.780 --> 00:00:53.436
ובכן, במונחים מדעיים,

00:00:53.460 --> 00:00:56.716
אנחנו קוראים לזה רעיון רע מאוד.

00:00:56.740 --> 00:00:57.956
(צחוק)

00:00:57.980 --> 00:01:00.156
בערך באותו זמן,

00:01:00.180 --> 00:01:03.396
הסרט ״2001 אודיסאה בחלל״ של 
סטנלי קובריק הגיע למסכים,

00:01:03.420 --> 00:01:05.620
וחיי השתנו לנצח.

00:01:06.100 --> 00:01:08.156
אהבתי כל מה שהיה קשור לסרט,

00:01:08.180 --> 00:01:10.716
בייחוד את האל 9000 (HAL).

00:01:10.740 --> 00:01:12.796
ובכן, האל היה מחשב בעל מודעות

00:01:12.820 --> 00:01:15.276
שתוכנן להדריך את ספינת החלל דיסקברי

00:01:15.300 --> 00:01:17.836
בדרך מכדור הארץ לצדק.

00:01:17.860 --> 00:01:19.916
האל היה גם טיפוס פגום,

00:01:19.940 --> 00:01:24.220
כי בסופו של דבר הוא בחר להעדיף את המשימה
על פני חיי אדם.

00:01:24.660 --> 00:01:26.756
למרות שהאל היה דמות בדיונית,

00:01:26.780 --> 00:01:29.436
הוא דיבר אל הפחדים שלנו,

00:01:29.460 --> 00:01:31.556
הפחדים שלנו להיות משועבדים

00:01:31.580 --> 00:01:34.596
על ידי בינה מלאכותית, ללא רגשות

00:01:34.620 --> 00:01:36.580
שאדישה לאנושיות שלנו.

00:01:37.700 --> 00:01:40.276
אני מאמין שפחדים כאלו הם חסרי ביסוס.

00:01:40.300 --> 00:01:42.996
אכן, אנו נמצאים בזמן יוצא דופן

00:01:43.020 --> 00:01:44.556
בהסטוריה האנושית,

00:01:44.580 --> 00:01:49.556
שבו, מונעים על ידי סרובינו לקבל את המגבלות
של גופינו ומחשבותינו,

00:01:49.580 --> 00:01:51.276
אנו בונים מכונות

00:01:51.300 --> 00:01:54.916
בעלות עדינות, סיבוכיות יפיפיה וחינניות

00:01:54.940 --> 00:01:56.996
שיאריכו את טווח החוויה האנושית

00:01:57.020 --> 00:01:58.700
בדרכים מעבר לדמיונינו.

00:01:59.540 --> 00:02:02.116
אחרי קריירה שהובילה אותי מהאקדמיה לטיס
בחיל האויר

00:02:02.140 --> 00:02:04.076
לפיקוד על משימות חלל לעכשיו,

00:02:04.100 --> 00:02:05.796
נהייתי מהנדס מערכות,

00:02:05.820 --> 00:02:08.556
ולאחרונה נשאבתי לבעייה הנדסית

00:02:08.580 --> 00:02:11.156
הקשורה למשימה של נאס״א למאדים.

00:02:11.180 --> 00:02:13.676
ובכן, במשימות חלל לירח,

00:02:13.700 --> 00:02:16.836
אנו יכולים לסמוך על פיקוד המשימה ביוסטון

00:02:16.860 --> 00:02:18.836
שיפקח על כל ההיבטים של הטיסה.

00:02:18.860 --> 00:02:22.396
אבל, מאדים רחוק פי 200 יותר,

00:02:22.420 --> 00:02:25.636
ולכן לוקח בממוצע 13 דקות

00:02:25.660 --> 00:02:28.796
לשדר לנוע מכדור הארץ למאדים.

00:02:28.820 --> 00:02:32.220
אם קורות בעיות, אין מספיק זמן.

00:02:32.660 --> 00:02:35.156
ולכן פתרון הנדסי סביר

00:02:35.180 --> 00:02:37.756
יהיה לשים את פיקוד המשימה

00:02:37.780 --> 00:02:40.796
בתוך רכב החלל אוריון.

00:02:40.820 --> 00:02:43.716
רעיון מרתק נוסף בפרופיל המשימה

00:02:43.740 --> 00:02:46.636
הוא לשים רובוטים דמויי אדם על פני מאדים

00:02:46.660 --> 00:02:48.516
לפני שבני האדם מגיעים,

00:02:48.540 --> 00:02:50.196
בתחילה לשם בניית תשתיות

00:02:50.220 --> 00:02:53.580
ולאחר מכן לשרת כחלק שיתופי
מהצוות המדעי.

00:02:55.220 --> 00:02:57.956
כשהתבוננתי בזה מנקודת מבט הנדסית,

00:02:57.980 --> 00:03:01.156
התבהרה לי ההבנה שמה שעלי לתכנן

00:03:01.180 --> 00:03:03.356
היא בינה מלאכותית חכמה, שיתופית

00:03:03.380 --> 00:03:05.756
ובעלת בינה חברתית.

00:03:05.780 --> 00:03:10.076
במילים אחרות, הייתי צריך לבנות
משהו מאוד דומה להאל

00:03:10.100 --> 00:03:12.516
אבל ללא הנטיות האובדניות.

00:03:12.540 --> 00:03:13.900
(צחוק)

00:03:14.740 --> 00:03:16.556
בואו נעצור לרגע.

00:03:16.580 --> 00:03:20.476
האם זה אפשרי באמת לבנות בינה מלאכותית כזו?

00:03:20.500 --> 00:03:21.956
למעשה, כן.

00:03:21.980 --> 00:03:23.236
במובנים רבים,

00:03:23.260 --> 00:03:25.236
זו בעייה הנדסית קשה

00:03:25.260 --> 00:03:26.716
עם אלמנטים של בינה מלאכותית,

00:03:26.740 --> 00:03:31.436
ולא כדור שיער רטוב של בינה מלאכותית
שצריך להיות מהונדס.

00:03:31.460 --> 00:03:34.116
בפרפרזה על דבריו של אלן טיורינג,

00:03:34.140 --> 00:03:36.516
אני לא מעוניין לבנות מכונה מודעת.

00:03:36.540 --> 00:03:38.116
אני לא בונה את האל.

00:03:38.140 --> 00:03:40.556
כל מה שאני רוצה הוא מוח פשוט,

00:03:40.580 --> 00:03:43.700
משהו שמציע את האשליה של בינה.

00:03:44.820 --> 00:03:47.956
המדע והאומנות של המחשוב התקדמו רבות

00:03:47.980 --> 00:03:49.476
מאז שהאל הופיע על המסך,

00:03:49.500 --> 00:03:52.716
ואני מדמיין שאם הממציא שלו
ד״ר צ׳נדרה היה פה היום

00:03:52.740 --> 00:03:55.076
היו לו הרבה שאלות אלינו.

00:03:55.100 --> 00:03:57.196
האם באמת אנחנו יכולים

00:03:57.220 --> 00:04:01.236
לקחת מערכת של מליונים על מליונים
של מכשירים,

00:04:01.260 --> 00:04:02.716
לקרוא את כל הנתונים מהם,

00:04:02.740 --> 00:04:04.996
לנחש את הכשלים ולהגיב מראש?

00:04:05.020 --> 00:04:06.236
כן.

00:04:06.260 --> 00:04:09.450
האם אנו יכולים לבנות מערכות המשוחחות
עם בני אדם בשפה טבעית?

00:04:09.460 --> 00:04:10.676
כן.

00:04:10.700 --> 00:04:13.676
האם אנו יכולים לבנות מערכות
שיכירו אובייקטים, יזהו רגשות,

00:04:13.700 --> 00:04:17.076
שיהו רגשניות, ישחקו משחקים
ואפילו יקראו שפתיים?

00:04:17.100 --> 00:04:18.316
כן.

00:04:18.340 --> 00:04:20.476
האם ביכולתינו לבנות מערכות המציבות יעדים,

00:04:20.500 --> 00:04:24.116
ומוציאות לפועל תוכניות לפי יעדים אלו
ולומדות בדרך?

00:04:24.140 --> 00:04:25.356
כן.

00:04:25.380 --> 00:04:28.716
האם ביכולתינו לבנות מערכות בעלות מודעות?

00:04:28.740 --> 00:04:30.236
את זה אנו לומדים לעשות.

00:04:30.260 --> 00:04:33.740
האם ביכולתינו לבנות מערכות בעלות בסיס 
מורלי ואתי?

00:04:34.300 --> 00:04:36.340
את זה אנו חייבים ללמוד לעשות.

00:04:37.180 --> 00:04:38.556
אז בואו נקבל לרגע

00:04:38.580 --> 00:04:41.476
שזה אפשרי לבנות כזו בינה מלאכותית

00:04:41.500 --> 00:04:43.636
עבור משימה זו ואחרות.

00:04:43.660 --> 00:04:46.196
השאלה הבאה שאתם חייבים לשאול את עצמכם היא,

00:04:46.220 --> 00:04:47.676
האם עלינו לפחד ממנה?

00:04:47.700 --> 00:04:49.676
כל טכנולוגיה חדשה

00:04:49.700 --> 00:04:52.596
מביאה איתה רמה מסויימת של חשש מהלא נודע.

00:04:52.620 --> 00:04:54.316
כשראינו לראשונה מכוניות,

00:04:54.340 --> 00:04:58.356
אנשים חזו שנראה את הרס המשפחה.

00:04:58.380 --> 00:05:01.076
כשראינו לראשונה טלפונים,

00:05:01.100 --> 00:05:03.996
אנשים חששו שזה יביא
לסופו של הדיון התרבותי.

00:05:04.020 --> 00:05:07.956
כשראינו בשלב מסויים את התפשטות המילה הכתובה,

00:05:07.980 --> 00:05:10.476
אנשים חשבו שנאבד את היכולת לזכור.

00:05:10.500 --> 00:05:12.556
כל אלו נכונים במידה מסויימת,

00:05:12.580 --> 00:05:14.996
אבל טכנולוגיות אלו

00:05:15.020 --> 00:05:18.396
הביאו דברים שהרחיבו את הנסיון האנושי

00:05:18.420 --> 00:05:20.300
בדרכים עמוקות.

00:05:21.660 --> 00:05:23.940
אז בואו ניקח את זה מעט רחוק יותר.

00:05:24.940 --> 00:05:29.676
אני לא מפחד מיצירת בינה מלאכותית כזו,

00:05:29.700 --> 00:05:33.516
כיוון שבסופו של דבר היא תכיל גם 
כמה מהערכים שלנו.

00:05:33.540 --> 00:05:37.036
חישבו על כך: בניית מערכת קוגניטיבית
היא שונה מהותית

00:05:37.060 --> 00:05:40.356
מבניית מערכת מסורתית מרובת תוכנה של העבר.

00:05:40.380 --> 00:05:42.836
אנו לא מתכנתים אותן, אנו מלמדים אותן.

00:05:42.860 --> 00:05:45.516
כדי ללמד מערכת לזהות פרחים,

00:05:45.540 --> 00:05:48.556
אני מראה לה אלפי פרחים מהסוג שאני אוהב.

00:05:48.580 --> 00:05:50.836
כדי ללמד מערכת לשחק משחק --

00:05:50.860 --> 00:05:52.820
ובכן, הייתי עושה את זה. אתם גם.

00:05:54.420 --> 00:05:56.460
אני אוהב פרחים. בחייכם.

00:05:57.260 --> 00:06:00.116
כדי ללמד מערכת לשחק משחק כמו גו,

00:06:00.140 --> 00:06:02.196
אגרום לה לשחק אלפי משחקי גו.

00:06:02.220 --> 00:06:03.876
אבל בתהליך אלמד אותה

00:06:03.900 --> 00:06:06.316
איך להבדיל בין משחק טוב למשחק רע.

00:06:06.340 --> 00:06:10.036
אם אני רוצה ליצור בינה מלאכותית
עבור עזרה משפטית,

00:06:10.060 --> 00:06:11.836
אלמד אותה כמה ספרי משפטים

00:06:11.860 --> 00:06:14.716
אך באותו זמן אשלב זאת עם

00:06:14.740 --> 00:06:17.620
חוש הצדק והרחמים שהם חלק מאותם חוקים.

00:06:18.380 --> 00:06:21.356
במונחים מדעיים,
זה מה שאנו קוראים לו אמת בסיסית,

00:06:21.380 --> 00:06:23.396
והנה הנקודה החשובה:

00:06:23.420 --> 00:06:24.876
כחלק מיצירת מכונות אלו,

00:06:24.900 --> 00:06:28.316
אנו מלמדים אותן חלק מערכינו.

00:06:28.340 --> 00:06:31.476
בהקשר זה, אני סומך על בינה מלאכותית

00:06:31.500 --> 00:06:35.140
באותה מידה, אם לא יותר,
מאשר על אדם שאומן היטב.

00:06:35.900 --> 00:06:37.116
אבל, אתם עלולים לשאול,

00:06:37.140 --> 00:06:39.756
מה לגבי סוכנים פורעי חוק,

00:06:39.780 --> 00:06:43.116
כמו ארגון לא ממשלתי ממומן היטב?

00:06:43.140 --> 00:06:46.956
אני לא חושש מבינה מלאכותית בידיים 
של זאב בודד.

00:06:46.980 --> 00:06:51.516
ברור שאיננו יכולים להגן על עצמינו 
מכל מעשה אלימות אקראי,

00:06:51.540 --> 00:06:53.676
אבל המציאות לגבי מערכות אלו היא

00:06:53.700 --> 00:06:56.796
שהן צריכות הרבה אימון, ואימון עדין

00:06:56.820 --> 00:06:59.116
הרבה מעבר למשאבים של אדם בודד.

00:06:59.140 --> 00:07:00.356
ובנוסף,

00:07:00.380 --> 00:07:03.636
זה הרבה יותר מלהזריק וירוס אינטרנט לעולם,

00:07:03.660 --> 00:07:06.756
כשאתה לוחץ על כפתור,
ופתאום זה במליון מקומות

00:07:06.780 --> 00:07:09.236
ומחשבים מתחילים להתפוצץ בכל מקום.

00:07:09.260 --> 00:07:12.076
ובכן, מדובר פה במשהו הרבה יותר גדול,

00:07:12.100 --> 00:07:13.815
ובוודאות נראה את זה מגיע.

00:07:14.340 --> 00:07:17.396
האם אני חושש שבינה מלאכותית כזו

00:07:17.420 --> 00:07:19.380
עלולה לאיים על האנושות כולה?

00:07:20.100 --> 00:07:24.476
אם תתבוננו בסרטים כמו ״המטריקס״, 
״מטרופוליס״ ,

00:07:24.500 --> 00:07:27.676
״שליחות קטלית״, תוכניות כמו ״ווסטוורלד״,

00:07:27.700 --> 00:07:29.836
כולן מדברות על חשש שכזה.

00:07:29.860 --> 00:07:34.156
ואכן, בספר ״סופר אינטליגנציה״
של הפילוסוף ניק בוסטרום,

00:07:34.180 --> 00:07:35.716
הוא בוחן נושא זה

00:07:35.740 --> 00:07:39.756
ושם לב שסופר אינטליגנציה עלולה להיות 
לא רק מסוכנת,

00:07:39.780 --> 00:07:43.636
אלא גם יכולה להוות איום קיומי
על האנושות כולה.

00:07:43.660 --> 00:07:45.876
הטיעון הבסיסי של דוקטור בוסטרום

00:07:45.900 --> 00:07:48.636
הוא שלמערכות כאלו יהיה בסופו של דבר

00:07:48.660 --> 00:07:51.916
צמאון בלתי ניתן לרוויה למידע

00:07:51.940 --> 00:07:54.836
עד שהן אולי ילמדו ללמוד

00:07:54.860 --> 00:07:57.476
ולבסוף יגלו שאולי יש להן יעדים

00:07:57.500 --> 00:07:59.796
מנוגדים לצרכי בני האדם.

00:07:59.820 --> 00:08:01.676
לדוקטור בוסטרום יש מספר עוקבים.

00:08:01.700 --> 00:08:06.020
הוא נתמך ע״י אנשים
כמו אלון מאסק וסטפן הוקינג.

00:08:06.700 --> 00:08:09.100
עם כל הכבוד

00:08:09.980 --> 00:08:11.996
למוחות מבריקים אלו,

00:08:12.020 --> 00:08:14.276
אני מאמין שהם שוגים באופן בסיסי.

00:08:14.300 --> 00:08:17.476
ובכן, יש הרבה חלקים לפרק בטיעון
של דוקטור בוסטרום,

00:08:17.500 --> 00:08:19.636
ואין לי זמן לפרק את כולם,

00:08:19.660 --> 00:08:22.356
אבל בקיצור רב, חישבו על כך:

00:08:22.380 --> 00:08:26.116
ידיעת-על היא מאוד שונה מעשיית-על.

00:08:26.140 --> 00:08:28.036
האל היה איום לצוות הדיסקברי

00:08:28.060 --> 00:08:32.476
רק כיוון שהאל פיקד על כל הצדדים
של הדיסקברי.

00:08:32.500 --> 00:08:34.996
אז כך גם יצטרך להיות עם סופר אינטליגנציה.

00:08:35.020 --> 00:08:37.516
היא תצטרך להיות בשליטה על כל עולמינו.

00:08:37.540 --> 00:08:40.356
זה מזכיר את סקיינט מהסרט ״שליחות קטלנית״

00:08:40.380 --> 00:08:42.236
שבו יש סופר אינטליגנציה

00:08:42.260 --> 00:08:43.636
ששלטה על רצון בני האדם,

00:08:43.660 --> 00:08:47.516
שכיוונה כל מכשיר בכל פינה של העולם.

00:08:47.540 --> 00:08:48.996
אם להיות מעשיים,

00:08:49.020 --> 00:08:51.116
זה לא הולך לקרות.

00:08:51.140 --> 00:08:54.196
אנחנו לא בונים בינה מלאכותית 
ששולטת במזג האוויר,

00:08:54.220 --> 00:08:55.556
שמכוונת את הגאות,

00:08:55.580 --> 00:08:58.956
שמפקדת עלינו, האנשים הגחמניים והכאוטים.

00:08:58.980 --> 00:09:02.876
ובנוסף, אם בינה מלאכותית כזו הייתה קיימת,

00:09:02.900 --> 00:09:05.836
היה עליה להתחרות בכלכלה האנושית,

00:09:05.860 --> 00:09:08.380
ולכן להתחרות נגדינו על משאבים.

00:09:09.020 --> 00:09:10.236
ולבסוף --

00:09:10.260 --> 00:09:11.500
אל תגלו לסירי --

00:09:12.260 --> 00:09:13.636
אנחנו תמיד יכולים לנתק אותם.

00:09:13.660 --> 00:09:15.780
(צחוק)

00:09:17.180 --> 00:09:19.636
אנחנו נמצאים במסע מופלא

00:09:19.660 --> 00:09:22.156
של אבולוציה משותפת עם המכונות שלנו.

00:09:22.180 --> 00:09:24.676
האנשים שאנו היום

00:09:24.700 --> 00:09:27.236
הם לא אותם האנשים שנהיה אז.

00:09:27.260 --> 00:09:30.396
לדאוג היום מהעלייה של סופר אינטליגנציה

00:09:30.420 --> 00:09:33.476
זה במובנים רבים הסחת דעת מסוכנת

00:09:33.500 --> 00:09:35.836
כיוון שהעלייה במיחשוב עצמו

00:09:35.860 --> 00:09:38.876
מביא אלינו מספר בעיות אנושיות וחברתיות

00:09:38.900 --> 00:09:40.540
שאנו חייבים לטפל בהן עכשיו.

00:09:41.180 --> 00:09:43.996
איך עלי לארגן את החברה האנושית

00:09:44.020 --> 00:09:46.356
כשהביקוש לעבודה אנושית הצטמצם?

00:09:46.380 --> 00:09:50.196
כיצד אני יכול להביא הבנה וחינוך
לכל האנושות

00:09:50.220 --> 00:09:51.996
ועדיין לכבד את השונה ביננו?

00:09:52.020 --> 00:09:56.276
איך אאריך ואשפר את חיינו
תוך שימוש במערכת בריאות קוגניטיבית?

00:09:56.300 --> 00:09:59.156
כיצד אוכל להשתמש במחשוב

00:09:59.180 --> 00:10:00.940
כדי לעזור לקחת אותנו לכוככבים?

00:10:01.580 --> 00:10:03.620
וזה הדבר המרתק.

00:10:04.220 --> 00:10:06.556
ההזדמנויות להשתמש במיחשוב

00:10:06.580 --> 00:10:08.116
לקידום ההתנסות האנושית

00:10:08.140 --> 00:10:09.556
הן בטווח ההשגה שלנו,

00:10:09.580 --> 00:10:11.436
כאן ועכשיו,

00:10:11.460 --> 00:10:13.140
ואנו רק מתחילים.

00:10:14.100 --> 00:10:15.316
תודה רבה לכם.

00:10:15.340 --> 00:10:19.626
(מחיאות כפיים)

