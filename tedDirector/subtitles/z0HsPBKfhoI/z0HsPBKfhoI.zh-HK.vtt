WEBVTT
Kind: captions
Language: zh-HK

00:00:00.000 --> 00:00:07.000
Translator: Danly Deng
Reviewer: Alan Watson

00:00:12.440 --> 00:00:16.280
我細個嗰陣係個書蟲

00:00:17.140 --> 00:00:19.316
我估你哋一啲人都係

00:00:19.340 --> 00:00:20.556
（笑聲）

00:00:20.580 --> 00:00:23.796
仲有你呀，阿生
笑得最大聲嗰個，睇嚟宜家都仲係

00:00:23.820 --> 00:00:26.076
（笑聲）

00:00:26.100 --> 00:00:29.596
我喺德州北部平原一個鎮仔大嘅

00:00:29.620 --> 00:00:32.956
我阿爺係牧師，我老豆係警察

00:00:32.980 --> 00:00:35.330
所以自細就係乖乖仔

00:00:35.860 --> 00:00:39.116
睇微積分書當娛樂

00:00:39.140 --> 00:00:40.676
（笑聲）

00:00:40.700 --> 00:00:42.396
你都係咧

00:00:42.420 --> 00:00:46.156
於是我自己整
激光啦、電腦啦、火箭模型啦

00:00:46.180 --> 00:00:49.180
最後仲喺房裏邊整埋火箭燃料

00:00:49.780 --> 00:00:53.436
用我哋宜家科學嘅講法

00:00:53.460 --> 00:00:56.716
係搞搞震無幫襯

00:00:56.740 --> 00:00:57.956
（笑聲）

00:00:57.980 --> 00:00:59.990
就喺嗰陣

00:00:59.990 --> 00:01:03.320
Stanley Kubrick 拍嗰部
《2001太空漫遊》上畫

00:01:03.320 --> 00:01:05.620
我嘅生活從此改寫

00:01:06.100 --> 00:01:08.156
我係部片嘅忠實擁躉

00:01:08.180 --> 00:01:10.716
特別中意哈爾 9000

00:01:10.740 --> 00:01:12.796
哈爾係一部機械人

00:01:12.820 --> 00:01:15.276
專為太空船導航而設計

00:01:15.300 --> 00:01:17.836
指引太空船由地球飛往木星

00:01:17.860 --> 00:01:19.916
但哈爾都有缺點

00:01:19.940 --> 00:01:24.220
佢最後為實現目的而罔顧人類安全

00:01:24.660 --> 00:01:26.756
哈爾雖然係虛構

00:01:26.780 --> 00:01:29.436
但佢反映咗我哋嘅恐懼

00:01:29.460 --> 00:01:36.606
就係怕無感情嘅人工智能
以後會操控人類

00:01:37.700 --> 00:01:40.276
我認為呢種恐懼唔成立

00:01:40.300 --> 00:01:44.316
講真，人類呢一刻嘅歷史
可以話係最輝煌嘅

00:01:44.580 --> 00:01:49.556
我哋冇向身體同大腦限制低頭

00:01:49.580 --> 00:01:54.946
反而製造出精良、複雜又美觀嘅機器

00:01:54.946 --> 00:01:58.956
協助人類逹至超乎想象嘅領域

00:01:59.546 --> 00:02:03.580
我以前喺空軍學校同太空指揮部做嘢嘅

00:02:03.580 --> 00:02:05.796
咁而家，我做咗系統工程師

00:02:05.820 --> 00:02:11.206
最近我著手於美國太空總署嘅
火星任務嘅一個工程問題

00:02:11.206 --> 00:02:13.676
到目前為止，所有上月球嘅太空船

00:02:13.700 --> 00:02:18.856
我哋都可以留喺休斯頓控制中心控制

00:02:18.860 --> 00:02:22.396
不過，火星比月球遠 200 倍

00:02:22.396 --> 00:02:25.812
於是乎由地球傳送到火星嘅訊號

00:02:25.820 --> 00:02:28.820
平均要花 13 分鐘先可以送到

00:02:28.820 --> 00:02:30.510
所以如果中途出咗咩問題

00:02:30.510 --> 00:02:32.660
我哋都唔夠時間解決

00:02:32.660 --> 00:02:35.156
所以解決方法係

00:02:35.180 --> 00:02:40.806
我哋要將任務控制台
裝喺太空船獵戶號嘅墻板裏邊

00:02:40.820 --> 00:02:43.716
另一個方法係

00:02:43.740 --> 00:02:48.536
喺人類登陸之前
喺火星表面放置一個機械人

00:02:48.540 --> 00:02:50.196
機械人前期負責興建設施

00:02:50.220 --> 00:02:53.580
後期就加入科學團隊擔當協助

00:02:55.220 --> 00:02:57.956
而當我企喺工程師嘅角度嚟睇

00:02:57.980 --> 00:03:03.366
我好清楚我要打造嘅
係一個高智能、富團隊精神

00:03:03.386 --> 00:03:05.756
同善於交際嘅人工智能

00:03:05.780 --> 00:03:10.076
換句話嚟講，我要整到好似哈爾咁樣

00:03:10.100 --> 00:03:12.516
不過係唔會當人類
係冚家鏟要消滅嘅機械人

00:03:12.540 --> 00:03:13.900
（笑聲）

00:03:14.740 --> 00:03:16.556
等陣先

00:03:16.580 --> 00:03:20.476
咁係咪真係有可能整個咁嘅機械人先？

00:03:20.500 --> 00:03:21.956
其實，係可以嘅

00:03:21.980 --> 00:03:26.746
好多時，設計人工智能元素係好難嘅

00:03:26.746 --> 00:03:31.436
咁唔係講緊整機械人頭髮

00:03:31.460 --> 00:03:34.116
學 Alan Turning 話齋

00:03:34.140 --> 00:03:36.516
我無興趣整隻有感覺嘅機器

00:03:36.540 --> 00:03:38.116
亦都唔係生產另一個哈爾

00:03:38.140 --> 00:03:40.556
我所追求嘅係一個會簡單思考

00:03:40.580 --> 00:03:44.030
同有少少智慧嘅機械人

00:03:44.820 --> 00:03:47.790
自從哈爾喺電影出現之後

00:03:47.790 --> 00:03:49.476
計算科學已經發展咗好多

00:03:49.500 --> 00:03:52.716
我想像得到，如果發明佢嘅
Chandra 博士今日喺度嘅話

00:03:52.740 --> 00:03:55.076
佢實有好多問題問我哋

00:03:55.100 --> 00:04:01.290
我哋有冇可能
從數以億計嘅設備裡面讀取數據

00:04:01.290 --> 00:04:04.996
同時預測機器犯嘅錯誤
同埋及早更正呢？

00:04:05.020 --> 00:04:06.236
可以

00:04:06.260 --> 00:04:09.436
我哋可唔可以
整隻機械人出嚟識講人話？

00:04:09.460 --> 00:04:10.370
可以

00:04:10.370 --> 00:04:12.780
我哋可唔可以整隻機械人

00:04:12.780 --> 00:04:17.076
識得識別物體、辨別情感
自帶情感、打機，甚至識讀唇語？

00:04:17.100 --> 00:04:18.030
可以

00:04:18.030 --> 00:04:21.266
我哋可唔可以整隻機械人識訂立目標

00:04:21.266 --> 00:04:24.116
實現目標兼且喺過程中自學？

00:04:24.140 --> 00:04:25.230
可以

00:04:25.230 --> 00:04:28.716
我哋可唔可以整隻
有思維邏輯嘅機械人？

00:04:28.740 --> 00:04:30.236
我哋宜家嘗試緊

00:04:30.260 --> 00:04:34.290
我哋可唔可以整隻機械人
明白道德觀念同底線？

00:04:34.300 --> 00:04:36.690
呢個任務我哋責無旁貸

00:04:37.180 --> 00:04:38.556
咁姑且我哋有可能

00:04:38.580 --> 00:04:43.656
為呢個任務或者其他任務
整隻咁樣嘅機械人

00:04:43.660 --> 00:04:45.050
跟住你實會問

00:04:45.050 --> 00:04:47.676
咁嘅人工智能會唔會造成威脅？

00:04:47.700 --> 00:04:52.616
時至今日，每項新科技面世
唔多唔少都會帶嚟不安

00:04:52.620 --> 00:04:54.316
以前啲人第一次見到汽車時

00:04:54.340 --> 00:04:58.356
就驚車禍會造成家破人亡

00:04:58.380 --> 00:05:01.076
以前第一次見到電話時

00:05:01.100 --> 00:05:03.996
啲人就驚人同人之間嘅交流會受到破壞

00:05:04.020 --> 00:05:07.956
曾幾何時啲人見到文字可以傳送

00:05:07.980 --> 00:05:10.476
又驚人類嘅記憶力會喪失

00:05:10.500 --> 00:05:12.556
呢啲不安喺一定程度上嚟講無錯

00:05:12.580 --> 00:05:14.900
但同時呢啲科技

00:05:14.900 --> 00:05:20.440
拓闊咗人類嘅體驗

00:05:21.660 --> 00:05:24.000
我哋不如再講遠啲

00:05:24.940 --> 00:05:29.676
我唔驚呢啲人工智能面世

00:05:29.700 --> 00:05:33.516
因為佢最終會接受人類嘅一啲價值

00:05:33.540 --> 00:05:35.720
試下咁唸：製造感知機械人

00:05:35.720 --> 00:05:38.920
同製造以前傳統嘅軟件密集型機械人

00:05:38.920 --> 00:05:40.380
係有根本性分別

00:05:40.380 --> 00:05:41.660
我哋而家唔係編程機械人

00:05:41.660 --> 00:05:43.120
我哋係教機械人

00:05:43.120 --> 00:05:45.516
為咗教機械人識別花

00:05:45.540 --> 00:05:48.556
我攞幾千種我鍾意嘅花畀佢睇

00:05:48.580 --> 00:05:50.836
為咗教曉機械人點打機——

00:05:50.860 --> 00:05:54.420
我真係教㗎。你都會咁做

00:05:54.430 --> 00:05:56.460
我真係鍾意花呢——

00:05:57.260 --> 00:06:00.116
為咗教識機械人打「殺出重圍」

00:06:00.140 --> 00:06:02.196
我畀佢打幾千局遊戲

00:06:02.220 --> 00:06:06.356
不過呢個過程，我又會教佢
辨別好局同劣局

00:06:06.356 --> 00:06:10.036
如果我想整隻法律助理機械人

00:06:10.060 --> 00:06:12.056
我除咗會教佢法律

00:06:12.056 --> 00:06:17.716
我仲會教佢法律嘅寛容同公義

00:06:18.380 --> 00:06:21.356
套用科學術語
呢啲係我哋所謂嘅參考標準

00:06:21.380 --> 00:06:23.396
而且重要嘅係：

00:06:23.420 --> 00:06:24.876
製造呢啲機械人時

00:06:24.900 --> 00:06:28.316
我哋將自己嘅價值觀灌輸畀佢

00:06:28.340 --> 00:06:31.476
最終，我相信人工智能

00:06:31.500 --> 00:06:35.340
會同一個受過專業訓練嘅人一樣

00:06:35.900 --> 00:06:37.116
不過，你哋可能會問

00:06:37.140 --> 00:06:43.156
如果呢啲人工智能被非法分子利用呢？

00:06:43.156 --> 00:06:46.956
雖然我哋唔可能杜絕所有暴力事件發生

00:06:46.980 --> 00:06:51.516
但我唔擔心人工智能落入一啲壞人手中

00:06:51.540 --> 00:06:56.706
因為人工智能需要持續同細微嘅改進

00:06:56.706 --> 00:06:59.116
單憑個人資源唔使旨意做到

00:06:59.140 --> 00:07:03.686
而且，唔好當成植入網絡病毒咁簡單

00:07:03.686 --> 00:07:06.390
唔好以為隨時隨地㩒個掣

00:07:06.390 --> 00:07:09.236
全世界嘅電腦瞬間就會爆炸

00:07:09.260 --> 00:07:12.076
人工智能係複雜好多嘅嘢

00:07:12.100 --> 00:07:14.335
但我相信遲早有一日人工智能會出現

00:07:14.340 --> 00:07:20.086
我驚唔驚人工智能會威脅全人類？

00:07:20.100 --> 00:07:24.270
電影《黑客帝國》、《大都會》

00:07:24.270 --> 00:07:27.676
《終結者》、電視劇《西部世界》

00:07:27.700 --> 00:07:29.836
呢類影視作品都係刻畫呢種恐懼

00:07:29.860 --> 00:07:35.746
無錯，哲學家 Nick Bostrom 
喺《超人工智能》一書裏邊都認為

00:07:35.746 --> 00:07:39.756
超人工智能唔單止危險

00:07:39.756 --> 00:07:43.356
而且仲危及全人類

00:07:43.660 --> 00:07:45.876
佢嘅基本論點有︰

00:07:45.900 --> 00:07:51.916
咁樣嘅機械人
最終唔會滿足於眼前擁有嘅資訊

00:07:51.940 --> 00:07:54.836
機械人可能會因而自己鑽研學習方法

00:07:54.860 --> 00:07:59.346
以至到最後發現
自己有啲目標同人類需要有矛盾

00:07:59.820 --> 00:08:01.676
有人支持博森博士嘅觀點

00:08:01.700 --> 00:08:06.020
包括 Elon Musk 同霍金

00:08:06.700 --> 00:08:14.280
我想指出其實幾位智者諗錯咗

00:08:14.300 --> 00:08:17.476
Nick Bostrom 嘅理論有好多錯誤

00:08:17.500 --> 00:08:19.636
但我無時間講曬所有

00:08:19.660 --> 00:08:26.136
但簡單嚟講，可以咁理解：
超智能唔代表超萬能

00:08:26.140 --> 00:08:28.396
哈爾對於成個太空探索團隊嘅威脅

00:08:28.396 --> 00:08:32.476
僅限於佢可以對探索任務落命令

00:08:32.500 --> 00:08:34.996
所以任務需要一個超智能機器

00:08:35.020 --> 00:08:37.516
落命令嘅需要有統治世界嘅能力

00:08:37.540 --> 00:08:39.340
電影《未來戰士 2018》
裡面嘅 Skynet

00:08:39.340 --> 00:08:42.660
嗰個可以操控人類意志嘅
超人工智能防禦系統

00:08:42.660 --> 00:08:47.516
控制曬全世界所有嘅機器同裝置

00:08:47.540 --> 00:08:48.996
即係話

00:08:49.020 --> 00:08:51.116
電影情節係唔會發生

00:08:51.140 --> 00:08:55.760
我哋唔係整隻機械人出嚟呼風喚雨

00:08:55.760 --> 00:08:58.956
操控喜怒無常、陷於鬥爭嘅人類

00:08:58.980 --> 00:09:02.876
再者，如果咁樣嘅機械人真係存在

00:09:02.900 --> 00:09:05.836
佢就會同人類嘅經濟鬥過

00:09:05.860 --> 00:09:08.700
甚至同人類爭資源

00:09:09.020 --> 00:09:10.236
最終結果係——

00:09:10.260 --> 00:09:12.250
唔好話俾 Siri 聽——

00:09:12.260 --> 00:09:13.646
我哋可以隨時熄咗佢哋

00:09:13.646 --> 00:09:15.780
（笑聲）

00:09:17.180 --> 00:09:22.046
我哋同機械人係共同進化

00:09:22.046 --> 00:09:27.269
未來嘅人類同今日嘅我哋
唔可以同日而語

00:09:27.269 --> 00:09:30.730
人類擔心人工智能帶嚟威脅

00:09:30.730 --> 00:09:36.110
只會令人類唔去真正關心
科技崛起帶嚟嘅人文同社會問題

00:09:36.110 --> 00:09:40.666
而呢啲問題正正係
我哋需要著手解決嘅

00:09:41.180 --> 00:09:42.420
問題例如有︰

00:09:42.420 --> 00:09:46.376
當我哋唔再需要勞動力嘅時候
我哋要點去調控社會？

00:09:46.380 --> 00:09:52.026
點樣向全世界傳播知識同教育
同時又尊重當地嘅差異？

00:09:52.026 --> 00:09:56.276
點樣通過認知式保健幫人類延年益壽？

00:09:56.300 --> 00:10:01.576
點樣利用電腦幫人類踏足外太空？

00:10:01.580 --> 00:10:03.620
諗下都覺得興奮

00:10:04.220 --> 00:10:11.526
利用計算科學去開拓人類經歷嘅機會
就喺手裏邊

00:10:11.526 --> 00:10:13.816
而我哋只係啱啱捉緊到

00:10:14.116 --> 00:10:15.316
多謝大家

00:10:15.316 --> 00:10:16.852
（掌聲）

