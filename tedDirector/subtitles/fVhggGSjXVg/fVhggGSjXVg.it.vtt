WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Elena Montrasio
Revisore: federica bonaldi

00:00:16.260 --> 00:00:18.260
Fino ad ora, la nostra comunicazione con le macchine

00:00:18.260 --> 00:00:20.260
si è sempre limitata

00:00:20.260 --> 00:00:22.260
a forme coscienti e dirette.

00:00:22.260 --> 00:00:24.260
Che si tratti di un'operazione semplice

00:00:24.260 --> 00:00:26.260
come accendere le luci con un interruttore,

00:00:26.260 --> 00:00:29.260
o complessa come la programmazione robotica,

00:00:29.260 --> 00:00:32.260
abbiamo sempre dovuto dare un comando a una macchina,

00:00:32.260 --> 00:00:34.260
o una serie di comandi,

00:00:34.260 --> 00:00:37.260
in modo che questa facesse qualcosa per noi.

00:00:37.260 --> 00:00:39.260
La comunicazione tra persone, d'altra parte,

00:00:39.260 --> 00:00:42.260
è decisamente più complessa e molto più interessante

00:00:42.260 --> 00:00:44.260
in quanto noi prendiamo in considerazione

00:00:44.260 --> 00:00:47.260
molto più di quanto è espresso esplicitamente.

00:00:47.260 --> 00:00:50.260
Osservando le espressioni del volto, il linguaggio del corpo,

00:00:50.260 --> 00:00:52.260
siamo in grado di intuire sentimenti ed emozioni

00:00:52.260 --> 00:00:55.260
dialogando con un altro essere umano.

00:00:55.260 --> 00:00:57.260
E ciò ha un ruolo molto importante

00:00:57.260 --> 00:00:59.260
nel processo attraverso cui prendiamo le decisioni.

00:00:59.260 --> 00:01:01.260
Ciò che intendiamo fare è introdurre

00:01:01.260 --> 00:01:04.260
questo mondo complesso di interazione umana

00:01:04.260 --> 00:01:06.260
nell'interazione tra essere umano e computer,

00:01:06.260 --> 00:01:08.260
così che i computer possano capire

00:01:08.260 --> 00:01:10.260
non solo ciò per cui ricevono dei comandi

00:01:10.260 --> 00:01:12.260
ma possano anche reagire

00:01:12.260 --> 00:01:14.260
alle espressioni del volto

00:01:14.260 --> 00:01:16.260
e alle esperienze emotive.

00:01:16.260 --> 00:01:18.260
E quale miglior modo per farlo

00:01:18.260 --> 00:01:20.260
dell'interpretare i segnali

00:01:20.260 --> 00:01:22.260
prodotti naturalmente dal nostro cervello,

00:01:22.260 --> 00:01:25.260
il nostro centro di controllo e di esperienza.

00:01:25.260 --> 00:01:27.260
Beh, sembra un'idea piuttosto interessante,

00:01:27.260 --> 00:01:29.260
ma il compito, come ha detto Bruno,

00:01:29.260 --> 00:01:32.260
non è dei più facili, e in particolare per due motivi.

00:01:32.260 --> 00:01:35.260
La prima sono gli algoritmi di rilevamento.

00:01:35.260 --> 00:01:37.260
Il nostro cervello è composto da

00:01:37.260 --> 00:01:39.260
miliardi di neuroni attivi.

00:01:39.260 --> 00:01:42.260
La lunghezza complessiva degli assoni

00:01:42.260 --> 00:01:44.260
ammonta a un totale di circa 170.000 km.

00:01:44.260 --> 00:01:46.260
Quando questi neuroni interagiscono

00:01:46.260 --> 00:01:48.260
la reazione chimica emette un impulso elettrico

00:01:48.260 --> 00:01:50.260
misurabile.

00:01:50.260 --> 00:01:53.260
La maggior parte delle nostre capacità mentali

00:01:53.260 --> 00:01:55.260
è distribuita

00:01:55.260 --> 00:01:57.260
sullo strato superficiale esterno del cervello.

00:01:57.260 --> 00:02:00.260
E per aumentare la superficie a disposizione della capacità mentale

00:02:00.260 --> 00:02:03.260
lo strato superficiale del cervello presenta innumerevoli pieghe.

00:02:03.260 --> 00:02:05.260
Ora, queste pieghe corticali

00:02:05.260 --> 00:02:07.260
rappresentano una sfida complessa

00:02:07.260 --> 00:02:10.260
all'interpretazione degli impulsi elettrici dello strato superficiale.

00:02:10.260 --> 00:02:12.260
La corteccia cerebrale di ogni individuo

00:02:12.260 --> 00:02:14.260
presenta pieghe differenti,

00:02:14.260 --> 00:02:16.260
molto simili a un'impronta digitale.

00:02:16.260 --> 00:02:18.260
Quindi, sebbene un segnale

00:02:18.260 --> 00:02:21.260
possa provenire dalla stessa area di attività del cervello,

00:02:21.260 --> 00:02:23.260
una volta che le pieghe strutturali sono state definite

00:02:23.260 --> 00:02:25.260
la sua ubicazione fisica

00:02:25.260 --> 00:02:27.260
differisce di molto da individuo e individuo,

00:02:27.260 --> 00:02:30.260
persino nei gemelli omozigoti.

00:02:30.260 --> 00:02:32.260
Non c'è più alcuna coerenza

00:02:32.260 --> 00:02:34.260
nei segnali superficiali.

00:02:34.260 --> 00:02:36.260
La nostra innovazione è stata la creazione di un algoritmo

00:02:36.260 --> 00:02:38.260
in grado di districare la corteccia cerebrale,

00:02:38.260 --> 00:02:40.260
così da creare una mappatura dei segnali

00:02:40.260 --> 00:02:42.260
più vicino alla fonte

00:02:42.260 --> 00:02:45.260
in modo da poter funzionare sull'intera popolazione.

00:02:46.260 --> 00:02:48.260
La seconda sfida

00:02:48.260 --> 00:02:51.260
è stato il macchinario con il quale osservare le onde cerebrali.

00:02:51.260 --> 00:02:53.260
Un elettroencefalogramma richiede

00:02:53.260 --> 00:02:56.260
l'uso di una retina con una serie di sensori

00:02:56.260 --> 00:02:59.260
come quella che vedete qui nell'immagine.

00:02:59.260 --> 00:03:01.260
Un tecnico sistema gli elettrodi

00:03:01.260 --> 00:03:03.260
sul cuoio capelluto

00:03:03.260 --> 00:03:05.260
aiutandosi con un conduttore o una pasta

00:03:05.260 --> 00:03:08.260
solitamente dopo una procedura di preparazione del cuoio capelluto

00:03:08.260 --> 00:03:10.260
attraverso una leggera abrasione.

00:03:10.260 --> 00:03:12.260
Tale procedura richiede del tempo

00:03:12.260 --> 00:03:14.260
e non è delle più piacevoli.

00:03:14.260 --> 00:03:16.260
Oltre a tutto ciò, quei sistemi

00:03:16.260 --> 00:03:19.260
costano in realtà decine di migliaia di dollari.

00:03:20.260 --> 00:03:23.260
Ora, detto questo, vorrei invitare sul palco

00:03:23.260 --> 00:03:25.260
Evan Grant, uno degli oratori dello scorso anno,

00:03:25.260 --> 00:03:27.260
il quale ha gentilmente accettato

00:03:27.260 --> 00:03:29.260
di aiutarmi a dimostrare

00:03:29.260 --> 00:03:31.260
ciò che siamo riusciti a sviluppare.

00:03:31.260 --> 00:03:37.260
(Applausi)

00:03:37.260 --> 00:03:39.260
Il dispositivo che vedete

00:03:39.260 --> 00:03:41.260
è un sistema a 14 canali, in alta fedeltà

00:03:41.260 --> 00:03:43.260
per l'acquisizione di un EEG.

00:03:43.260 --> 00:03:46.260
Non richiede alcuna preparazione del cuoio capelluto,

00:03:46.260 --> 00:03:48.260
nessun gel conduttore, nessuna pasta.

00:03:48.260 --> 00:03:51.260
Sono necessari solo pochi minuti per indossarlo

00:03:51.260 --> 00:03:53.260
e perché i segnali si stabilizzino.

00:03:53.260 --> 00:03:55.260
Ed è anche senza fili,

00:03:55.260 --> 00:03:58.260
quindi da' la possibilità di muoversi liberamente.

00:03:58.260 --> 00:04:01.260
E paragonata alle decine di migliaia di dollari

00:04:01.260 --> 00:04:04.260
di un sistema di EEG tradizionale,

00:04:04.260 --> 00:04:06.260
questa cuffia costa solo

00:04:06.260 --> 00:04:08.260
poche centinaia di dollari.

00:04:08.260 --> 00:04:11.260
Passiamo ora agli algoritmi di rilevamento.

00:04:11.260 --> 00:04:13.260
Dunque, le espressioni facciali -

00:04:13.260 --> 00:04:15.260
come ho accennato prima nelle esperienze emotive -

00:04:15.260 --> 00:04:17.260
hanno la funzione di sortire un effetto immediato

00:04:17.260 --> 00:04:19.260
con qualche adattamento alla sensibilità

00:04:19.260 --> 00:04:22.260
disponibile per la personalizzazione.

00:04:22.260 --> 00:04:24.260
Ma con il poco tempo che abbiamo a disposizione

00:04:24.260 --> 00:04:26.260
vorrei mostrarvi la suite cognitiva,

00:04:26.260 --> 00:04:28.260
vale a dire la capacità

00:04:28.260 --> 00:04:31.260
di spostare oggetti virtuali con la mente.

00:04:32.260 --> 00:04:34.260
Ora, per Evan il sistema è nuovo,

00:04:34.260 --> 00:04:36.260
quindi per prima cosa dobbiamo

00:04:36.260 --> 00:04:38.260
creare un nuovo profilo per lui.

00:04:38.260 --> 00:04:41.260
Ovviamente lui non è Joanne - quindi aggiungiamo l'utente.

00:04:41.260 --> 00:04:43.260
Evan. Ok.

00:04:43.260 --> 00:04:46.260
La prima cosa che dobbiamo fare con la suite cognitiva

00:04:46.260 --> 00:04:48.260
è cominciare a familiarizzare

00:04:48.260 --> 00:04:50.260
con un segnale neutro.

00:04:50.260 --> 00:04:52.260
Con il segnale neutro, Evan

00:04:52.260 --> 00:04:54.260
non deve fare niente di particolare.

00:04:54.260 --> 00:04:56.260
Resta qui, si rilassa.

00:04:56.260 --> 00:04:58.260
Il concetto è quello di stabilire una linea di base,

00:04:58.260 --> 00:05:00.260
una condizione di normalità per il suo cervello,

00:05:00.260 --> 00:05:02.260
perché ogni cervello è diverso.

00:05:02.260 --> 00:05:04.260
L'operazione richiede 8 secondi.

00:05:04.260 --> 00:05:06.260
Ora che questo è fatto,

00:05:06.260 --> 00:05:08.260
possiamo scegliere un'azione basata sul movimento.

00:05:08.260 --> 00:05:10.260
Quindi, Evan, scegli qualcosa

00:05:10.260 --> 00:05:12.260
che puoi visualizzare con precisione nella mente.

00:05:12.260 --> 00:05:14.260
Facciamo 'Tira'.

00:05:14.260 --> 00:05:16.260
Ok. Allora scegliamo 'Tira'.

00:05:16.260 --> 00:05:18.260
Il concetto adesso

00:05:18.260 --> 00:05:20.260
è che Evan deve immaginare

00:05:20.260 --> 00:05:22.260
che l'oggetto venga verso di lui

00:05:22.260 --> 00:05:24.260
all'interno dello schermo.

00:05:24.260 --> 00:05:27.260
E la barra che scorre attraverso lo schermo

00:05:27.260 --> 00:05:29.260
misura il progresso di ciò che Evan sta facendo.

00:05:29.260 --> 00:05:31.260
La prima volta non accadrà nulla

00:05:31.260 --> 00:05:34.260
perché il sistema non ha idea di come lui pensi a 'Tirare'.

00:05:34.260 --> 00:05:36.260
Ma mantieni quel pensiero

00:05:36.260 --> 00:05:38.260
per tutta la durata degli 8 secondi.

00:05:38.260 --> 00:05:41.260
Uno, due, tre, via!

00:05:49.260 --> 00:05:51.260
Ok.

00:05:51.260 --> 00:05:53.260
Una volta che accettiamo questo

00:05:53.260 --> 00:05:55.260
il cubo è attivo.

00:05:55.260 --> 00:05:57.260
E ora vediamo se Evan

00:05:57.260 --> 00:06:00.260
può veramente immaginare di tirare.

00:06:00.260 --> 00:06:02.260
Ah, bravissimo!

00:06:02.260 --> 00:06:05.260
(Applausi)

00:06:05.260 --> 00:06:07.260
Davvero incredibile.

00:06:07.260 --> 00:06:11.260
(Applausi)

00:06:11.260 --> 00:06:13.260
Dunque, visto che abbiamo un po' di tempo a disposizione

00:06:13.260 --> 00:06:15.260
chiederò a Evan

00:06:15.260 --> 00:06:17.260
di svolgere un compito molto difficile.

00:06:17.260 --> 00:06:19.260
Ed è davvero difficile

00:06:19.260 --> 00:06:22.260
perché si tratta di essere in grado di visualizzare qualcosa

00:06:22.260 --> 00:06:24.260
che non esiste nel nostro mondo fisico.

00:06:24.260 --> 00:06:26.260
Si tratta di 'Sparire'.

00:06:26.260 --> 00:06:28.260
Quindi ciò che vogliamo - per lo meno con azioni basate sul movimento,

00:06:28.260 --> 00:06:31.260
lo facciamo sempre, quindi lo si può visualizzare.

00:06:31.260 --> 00:06:33.260
Ma con 'sparire' non esistono analogie.

00:06:33.260 --> 00:06:35.260
Allora Evan, quello che devi fare ora

00:06:35.260 --> 00:06:38.260
è immaginare che il cubo lentamente svanisca.

00:06:38.260 --> 00:06:41.260
Stessa procedura. Uno, due, tre, via!

00:06:50.260 --> 00:06:53.260
Ok. Proviamoci.

00:06:53.260 --> 00:06:56.260
Oh, è incredibile. E' troppo bravo!

00:06:57.260 --> 00:06:59.260
Proviamoci di nuovo.

00:07:04.260 --> 00:07:06.260
Sto perdendo la concentrazione.

00:07:06.260 --> 00:07:08.260
(Risate)

00:07:08.260 --> 00:07:10.260
Ma noi vediamo che in realtà funziona,

00:07:10.260 --> 00:07:12.260
anche se riesci a concentrarti solo

00:07:12.260 --> 00:07:14.260
per qualche attimo.

00:07:14.260 --> 00:07:17.260
Come ho detto, è molto difficile

00:07:17.260 --> 00:07:19.260
immaginare una sparizione.

00:07:19.260 --> 00:07:21.260
E la cosa incredibile è che

00:07:21.260 --> 00:07:23.260
abbiamo dato al sofware solo un esempio

00:07:23.260 --> 00:07:26.260
di come Evan pensi a 'sparire'.

00:07:26.260 --> 00:07:29.260
Dato che qui dentro c'è una macchina che apprende gli algoritmi -

00:07:29.260 --> 00:07:33.260
(Applausi)

00:07:33.260 --> 00:07:35.260
Grazie.

00:07:35.260 --> 00:07:38.260
Bravo. Bravo.

00:07:38.260 --> 00:07:40.260
(Applausi)

00:07:40.260 --> 00:07:43.260
Grazie Evan, sei un esempio fantastico,

00:07:43.260 --> 00:07:46.260
una esempio fantastico di questa tecnologia.

00:07:46.260 --> 00:07:48.260
Quindi, come avete visto prima,

00:07:48.260 --> 00:07:51.260
esiste un sistema livellante all'interno di questo software

00:07:51.260 --> 00:07:53.260
in modo che man mano che Evan, o qualsiasi altro fruitore

00:07:53.260 --> 00:07:55.260
familiarizza con il sistema,

00:07:55.260 --> 00:07:58.260
si possono continuare ad aggiungere sempre più rilevamenti

00:07:58.260 --> 00:08:00.260
così che il sistema cominci a differenziare

00:08:00.260 --> 00:08:03.260
tra pensieri distinti con precisione crescente.

00:08:04.260 --> 00:08:06.260
E una volta determinati i rilevamenti

00:08:06.260 --> 00:08:08.260
questi pensieri possono venir assegnati, o mappati

00:08:08.260 --> 00:08:10.260
su qualunque piattaforma, applicazione

00:08:10.260 --> 00:08:12.260
o dispositivo informatico.

00:08:12.260 --> 00:08:14.260
Ora vorrei mostrarvi alcuni esempi,

00:08:14.260 --> 00:08:16.260
perché esistono molte applicazioni possibili

00:08:16.260 --> 00:08:18.260
di questa nuova interfaccia.

00:08:19.260 --> 00:08:21.260
Nei video giochi e nei mondi virtuali, per esempio,

00:08:21.260 --> 00:08:23.260
la vostra espressione facciale

00:08:23.260 --> 00:08:25.260
può venir usata naturalmente e intuitivamente

00:08:25.260 --> 00:08:28.260
per controllare un avatar o un personaggio virtuale.

00:08:29.260 --> 00:08:31.260
Ovviamente, potete provare la magia della simulazione

00:08:31.260 --> 00:08:34.260
e controllare il mondo con la mente.

00:08:36.260 --> 00:08:39.260
Inoltre i colori, le luci,

00:08:39.260 --> 00:08:41.260
il suono e gli effetti

00:08:41.260 --> 00:08:43.260
rispondono in manera dinamica al vostro stato emotivo

00:08:43.260 --> 00:08:46.260
in tempo reale, per intensificare la vostra esperienza.

00:08:47.260 --> 00:08:49.260
Passiamo ora ad alcune applicazioni

00:08:49.260 --> 00:08:52.260
sviluppate da imprenditori e ricercatori di tutto il mondo

00:08:52.260 --> 00:08:55.260
con robot e semplici macchinari. Per esempio -

00:08:55.260 --> 00:08:57.260
in questo caso, si fa volare un elicottero giocattolo

00:08:57.260 --> 00:09:00.260
semplicemente pensando 'solleva' nella propria testa.

00:09:00.260 --> 00:09:02.260
La tecnologia si impiega anche

00:09:02.260 --> 00:09:04.260
ad applicazioni del mondo reale:

00:09:04.260 --> 00:09:06.260
in questo caso, una casa intelligente.

00:09:06.260 --> 00:09:09.260
Vedete, dal sistema di controllo dell'interfaccia dell'utente

00:09:09.260 --> 00:09:11.260
si aprono

00:09:11.260 --> 00:09:14.260
o si chiudono le tende.

00:09:22.260 --> 00:09:25.260
E certamente anche l'illuminazione,

00:09:25.260 --> 00:09:28.260
si accende

00:09:28.260 --> 00:09:30.260
o si spegne.

00:09:30.260 --> 00:09:32.260
Passiamo infine

00:09:32.260 --> 00:09:34.260
a quelle applicazioni che cambiano la vita

00:09:34.260 --> 00:09:37.260
come la possibilità di controllare una sedia a rotelle elettrica.

00:09:37.260 --> 00:09:39.260
In questo caso

00:09:39.260 --> 00:09:42.260
le espressioni facciali vengono collegate ai comandi per il movimento.

00:09:42.260 --> 00:09:45.260
Ora chiudi l'occhio destro per andare a destra.

00:09:50.260 --> 00:09:53.260
Ora il sinistro per girare a sinistra.

00:10:02.260 --> 00:10:05.260
Ora sorridi per andare dritto.

00:10:08.260 --> 00:10:10.260
Noi, veramente - Grazie.

00:10:10.260 --> 00:10:15.260
(Applausi)

00:10:15.260 --> 00:10:18.260
E oggi stiamo solo agli inizi di ciò che è possibile.

00:10:18.260 --> 00:10:20.260
E con il contributo della comunità

00:10:20.260 --> 00:10:22.260
e il coinvolgimento degli sviluppatori

00:10:22.260 --> 00:10:25.260
e dei ricercatori di tutto il mondo

00:10:25.260 --> 00:10:27.260
speriamo che voi possiate aiutarci a dare forma

00:10:27.260 --> 00:10:30.260
alla direzione che da qui prenderà la tecnologia.Grazie infinite.

