WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Laura Monzon-Storey
Revisor: Ricardo Aranguren

00:00:16.260 --> 00:00:18.260
Hasta ahora, la comunicación con las máquinas

00:00:18.260 --> 00:00:20.260
ha estado limitada

00:00:20.260 --> 00:00:22.260
a formas conscientes y directas.

00:00:22.260 --> 00:00:24.260
Ya sea algo simple

00:00:24.260 --> 00:00:26.260
como un interruptor de luz

00:00:26.260 --> 00:00:29.260
o complejos como la programación robótica.

00:00:29.260 --> 00:00:32.260
Siempre hemos tenido que ingresar comandos

00:00:32.260 --> 00:00:34.260
mediante uno o varios pasos

00:00:34.260 --> 00:00:37.260
para que una computadora ejecutara alguna tarea.

00:00:37.260 --> 00:00:39.260
Por otro lado, la comunicación humana

00:00:39.260 --> 00:00:42.260
es mucho más compleja y más interesante

00:00:42.260 --> 00:00:44.260
porque tiene en cuenta

00:00:44.260 --> 00:00:47.260
mucho más de lo expresado explícitamente.

00:00:47.260 --> 00:00:50.260
Mediante las expresiones y el lenguaje del cuerpo

00:00:50.260 --> 00:00:52.260
podemos intuir emociones

00:00:52.260 --> 00:00:55.260
que son parte de nuestro diálogo.

00:00:55.260 --> 00:00:57.260
Esto juega un importante rol

00:00:57.260 --> 00:00:59.260
en nuestra manera de tomar decisiones.

00:00:59.260 --> 00:01:01.260
Hoy nuestro objetivo es introducir

00:01:01.260 --> 00:01:04.260
este nuevo campo de interacción humana

00:01:04.260 --> 00:01:06.260
en la interacción entre el hombre y las computadoras

00:01:06.260 --> 00:01:08.260
para que éstas puedan comprender

00:01:08.260 --> 00:01:10.260
no sólo los comandos que les ordenamos

00:01:10.260 --> 00:01:12.260
sino que también puedan responder

00:01:12.260 --> 00:01:14.260
a nuestras expresiones faciales

00:01:14.260 --> 00:01:16.260
y nuestras emociones.

00:01:16.260 --> 00:01:18.260
Y ¿qué mejor manera de lograr esto

00:01:18.260 --> 00:01:20.260
que mediante la interpretación de señales

00:01:20.260 --> 00:01:22.260
emitidas naturalmente por el cerebro?

00:01:22.260 --> 00:01:25.260
Que es nuestro centro de control.

00:01:25.260 --> 00:01:27.260
Bien, parece una buena idea

00:01:27.260 --> 00:01:29.260
pero, como bien dijo Bruno,

00:01:29.260 --> 00:01:32.260
no es tarea fácil, por dos razones principales:

00:01:32.260 --> 00:01:35.260
primero, los algoritmos de detección.

00:01:35.260 --> 00:01:37.260
El cerebro esta conformado

00:01:37.260 --> 00:01:39.260
por miles de millones de neuronas activas

00:01:39.260 --> 00:01:42.260
cuyos axones, combinados,

00:01:42.260 --> 00:01:44.260
alcanzan una longitud de 170.000 km.

00:01:44.260 --> 00:01:46.260
Cuando las neuronas interactúan

00:01:46.260 --> 00:01:48.260
la reacción química emite un impulso eléctrico

00:01:48.260 --> 00:01:50.260
el cual puede medirse.

00:01:50.260 --> 00:01:53.260
La mayor parte de nuestro cerebro funcional

00:01:53.260 --> 00:01:55.260
se encuentra distribuido

00:01:55.260 --> 00:01:57.260
en la capa externa del cerebro.

00:01:57.260 --> 00:02:00.260
Y para lograr mayor superficie con capacidad mental

00:02:00.260 --> 00:02:03.260
la superficie cerebral está densamente plegada.

00:02:03.260 --> 00:02:05.260
Bien, los pliegues de esta corteza

00:02:05.260 --> 00:02:07.260
presentan un desafío no menor

00:02:07.260 --> 00:02:10.260
para interpretar impulsos eléctricos superficiales.

00:02:10.260 --> 00:02:12.260
La corteza de cada individuo

00:02:12.260 --> 00:02:14.260
está plegada de manera diferente,

00:02:14.260 --> 00:02:16.260
a la manera de huellas digitales.

00:02:16.260 --> 00:02:18.260
Por eso, si bien una señal

00:02:18.260 --> 00:02:21.260
puede provenir de la misma parte funcional del cerebro,

00:02:21.260 --> 00:02:23.260
la particular estructura de los pliegues

00:02:23.260 --> 00:02:25.260
hace que la posición física de esta señal

00:02:25.260 --> 00:02:27.260
varíe de individuo a individuo

00:02:27.260 --> 00:02:30.260
incluso entre hermanos gemelos.

00:02:30.260 --> 00:02:32.260
Ya no existe coherencia

00:02:32.260 --> 00:02:34.260
en la señales superficiales.

00:02:34.260 --> 00:02:36.260
Nuestro descubrimiento fue la creación de un algoritmo

00:02:36.260 --> 00:02:38.260
que despliega la corteza

00:02:38.260 --> 00:02:40.260
de tal manera que las señales pueden localizarse

00:02:40.260 --> 00:02:42.260
cerca de su origen

00:02:42.260 --> 00:02:45.260
para poder aplicarse a la población en general.

00:02:46.260 --> 00:02:48.260
El segundo desafío

00:02:48.260 --> 00:02:51.260
reside en el dispositivo para observar ondas cerebrales.

00:02:51.260 --> 00:02:53.260
La electroencefalografía requiere

00:02:53.260 --> 00:02:56.260
de una red de sensores alrededor de la cabeza

00:02:56.260 --> 00:02:59.260
como la que se ve en esta foto.

00:02:59.260 --> 00:03:01.260
Un técnico coloca los electrodos

00:03:01.260 --> 00:03:03.260
sobre el cuero cabelludo

00:03:03.260 --> 00:03:05.260
mediante un gel conductor o pasta

00:03:05.260 --> 00:03:08.260
habiendo antes preparado el cuero cabelludo

00:03:08.260 --> 00:03:10.260
con abrasivos suaves.

00:03:10.260 --> 00:03:12.260
Pero esto lleva bastante tiempo

00:03:12.260 --> 00:03:14.260
y no es un método muy agradable.

00:03:14.260 --> 00:03:16.260
Y, además, estos sistemas

00:03:16.260 --> 00:03:19.260
cuestan decenas de miles de dólares.

00:03:20.260 --> 00:03:23.260
Por eso, quiero invitar a la tarima

00:03:23.260 --> 00:03:25.260
a Evan Grant, quien fuera conferencista el año pasado,

00:03:25.260 --> 00:03:27.260
y que muy amablemente ha aceptado

00:03:27.260 --> 00:03:29.260
ayudarme a demostrar

00:03:29.260 --> 00:03:31.260
ésto que desarrollamos.

00:03:31.260 --> 00:03:37.260
(Aplauso)

00:03:37.260 --> 00:03:39.260
Este disposivo

00:03:39.260 --> 00:03:41.260
es un aparato de electroencefalografía

00:03:41.260 --> 00:03:43.260
de 14 canales y alta fidelidad.

00:03:43.260 --> 00:03:46.260
No requiere de preparación del cuero cabelludo

00:03:46.260 --> 00:03:48.260
ni geles ni pastas.

00:03:48.260 --> 00:03:51.260
Se coloca en unos pocos minutos

00:03:51.260 --> 00:03:53.260
y se espera a que aparezcan las señales.

00:03:53.260 --> 00:03:55.260
También es inalámbrico

00:03:55.260 --> 00:03:58.260
por lo que permite que nos movamos.

00:03:58.260 --> 00:04:01.260
Y en comparación con las decenas de miles de dólares

00:04:01.260 --> 00:04:04.260
de los sistemas de electroencefalografía tradicionales

00:04:04.260 --> 00:04:06.260
este casco sólo cuesta

00:04:06.260 --> 00:04:08.260
unos pocos cientos de dólares.

00:04:08.260 --> 00:04:11.260
Ahora, los algoritmos de detección.

00:04:11.260 --> 00:04:13.260
Las expresiones faciales,

00:04:13.260 --> 00:04:15.260
como lo mencioné antes mediante emociones,

00:04:15.260 --> 00:04:17.260
están diseñadas para funcionar fuera de la caja

00:04:17.260 --> 00:04:19.260
con algunos ajustes sensoriales

00:04:19.260 --> 00:04:22.260
disponibles para personalización.

00:04:22.260 --> 00:04:24.260
Pero como no tenemos mucho tiempo

00:04:24.260 --> 00:04:26.260
les quiero mostrar el conjunto cognitivo

00:04:26.260 --> 00:04:28.260
que es, básicamente,

00:04:28.260 --> 00:04:31.260
la capacidad de mover objetos virtuales con la mente.

00:04:32.260 --> 00:04:34.260
Bien, esta es la primera vez para Evan,

00:04:34.260 --> 00:04:36.260
así que lo primero que tenemos que hacer

00:04:36.260 --> 00:04:38.260
es crear un nuevo perfil para él.

00:04:38.260 --> 00:04:41.260
Obviamente no es Joanne, por lo que selecciono "agregar usuario".

00:04:41.260 --> 00:04:43.260
Evan. Bien.

00:04:43.260 --> 00:04:46.260
Así que lo primero que tenemos que hacer con el conjunto cognitivo

00:04:46.260 --> 00:04:48.260
es ejercitar

00:04:48.260 --> 00:04:50.260
una señal neutral.

00:04:50.260 --> 00:04:52.260
De esta manera, no hay nada en particular

00:04:52.260 --> 00:04:54.260
que Evan tenga que hacer.

00:04:54.260 --> 00:04:56.260
Sólo relajarse.

00:04:56.260 --> 00:04:58.260
Y la idea es establecer un punto de partida

00:04:58.260 --> 00:05:00.260
o estado normal de su cerebro,

00:05:00.260 --> 00:05:02.260
porque cada cerebro es diferente.

00:05:02.260 --> 00:05:04.260
Esto lleva ocho segundos.

00:05:04.260 --> 00:05:06.260
Ya está listo,

00:05:06.260 --> 00:05:08.260
podemos seleccionar una acción, un movimiento.

00:05:08.260 --> 00:05:10.260
Evan, debes elegir algo

00:05:10.260 --> 00:05:12.260
que puedas visualizar claramente en tu mente.

00:05:12.260 --> 00:05:14.260
Evan Grant: de acuerdo, "atraer".

00:05:14.260 --> 00:05:16.260
Tan Le: Bien. Elijo entonces "atraer".

00:05:16.260 --> 00:05:18.260
Así que la idea aquí

00:05:18.260 --> 00:05:20.260
es que Evan debe imaginar

00:05:20.260 --> 00:05:22.260
que el objeto se mueve hacia nosotros

00:05:22.260 --> 00:05:24.260
dentro de la pantalla.

00:05:24.260 --> 00:05:27.260
Una barra en la pantalla indica el progreso

00:05:27.260 --> 00:05:29.260
mientras él se concentra.

00:05:29.260 --> 00:05:31.260
La primera vez, nada va a suceder,

00:05:31.260 --> 00:05:34.260
porque el sistema no tiene idea de como él imagina "atraer".

00:05:34.260 --> 00:05:36.260
Pero intenta mantener esa idea

00:05:36.260 --> 00:05:38.260
durante los ocho segundos.

00:05:38.260 --> 00:05:41.260
Uno, dos, tres, cuatro, vamos.

00:05:49.260 --> 00:05:51.260
Bien.

00:05:51.260 --> 00:05:53.260
Al seleccionar "aceptar"

00:05:53.260 --> 00:05:55.260
el cubo se mueve.

00:05:55.260 --> 00:05:57.260
Veamos si Evan

00:05:57.260 --> 00:06:00.260
puede imaginar "atraer".

00:06:00.260 --> 00:06:02.260
Ah, ¡muy bien!

00:06:02.260 --> 00:06:05.260
(Aplauso)

00:06:05.260 --> 00:06:07.260
¡Sorprendente!

00:06:07.260 --> 00:06:11.260
(Aplauso)

00:06:11.260 --> 00:06:13.260
Aún tenemos un poquito de tiempo

00:06:13.260 --> 00:06:15.260
así que le voy a pedir a Evan

00:06:15.260 --> 00:06:17.260
que realice una tarea realmente complicada.

00:06:17.260 --> 00:06:19.260
Y digo complicada

00:06:19.260 --> 00:06:22.260
porque se trata de visualizar algo

00:06:22.260 --> 00:06:24.260
que no existe en el mundo físico.

00:06:24.260 --> 00:06:26.260
Esto es "desaparecer".

00:06:26.260 --> 00:06:28.260
Las acciones de movimiento

00:06:28.260 --> 00:06:31.260
son muy comunes, y es fácil visualizarlas.

00:06:31.260 --> 00:06:33.260
Pero para "desaparecer" no existen analogías.

00:06:33.260 --> 00:06:35.260
Así que, Evan, lo que tienes que hacer

00:06:35.260 --> 00:06:38.260
es imaginar el cubo esfumándose lentamente.

00:06:38.260 --> 00:06:41.260
Tal cual como antes. Uno, dos, tres, vamos.

00:06:50.260 --> 00:06:53.260
Bien, intentemos eso.

00:06:53.260 --> 00:06:56.260
¡Oh, cielos! ¡Qué bien lo hace!

00:06:57.260 --> 00:06:59.260
Intentemos otra vez.

00:07:04.260 --> 00:07:06.260
EG: Estoy perdiendo la concentración.

00:07:06.260 --> 00:07:08.260
(Risas)

00:07:08.260 --> 00:07:10.260
TL: Pero vemos que funciona

00:07:10.260 --> 00:07:12.260
aunque sólo puedas mantenerlo

00:07:12.260 --> 00:07:14.260
por un tiempo corto.

00:07:14.260 --> 00:07:17.260
Como decía, imaginar ésto

00:07:17.260 --> 00:07:19.260
es un proceso complicado.

00:07:19.260 --> 00:07:21.260
Y lo grandioso de esto es que

00:07:21.260 --> 00:07:23.260
sólo le indicamos al sistema una única vez

00:07:23.260 --> 00:07:26.260
cómo Evan piensa en "desaparecer".

00:07:26.260 --> 00:07:29.260
Ya que la máquina tiene un algoritmo de aprendizaje...---

00:07:29.260 --> 00:07:33.260
(Aplauso)

00:07:33.260 --> 00:07:35.260
Muchas gracias.

00:07:35.260 --> 00:07:38.260
Muy bien, buen trabajo.

00:07:38.260 --> 00:07:40.260
(Aplauso)

00:07:40.260 --> 00:07:43.260
Muchas gracias, Evan,

00:07:43.260 --> 00:07:46.260
eres un maravilloso ejemplo de la tecnología.

00:07:46.260 --> 00:07:48.260
Así que como pueden ver

00:07:48.260 --> 00:07:51.260
hay un progreso por niveles incorporado a este software

00:07:51.260 --> 00:07:53.260
por lo que mientras Evan, u otro usuario,

00:07:53.260 --> 00:07:55.260
se familiariza con el sistema,

00:07:55.260 --> 00:07:58.260
puede agregar más y más detecciones

00:07:58.260 --> 00:08:00.260
que permiten al sistema diferenciar

00:08:00.260 --> 00:08:03.260
entre distintos pensamientos.

00:08:04.260 --> 00:08:06.260
Y una vez que se han entrenado las detecciones

00:08:06.260 --> 00:08:08.260
estos pensamientos pueden ser asignados o

00:08:08.260 --> 00:08:10.260
a cualquier sistema operativo,

00:08:10.260 --> 00:08:12.260
aplicación o dispositivo.

00:08:12.260 --> 00:08:14.260
Así que quisiera mostarles algunos ejemplos

00:08:14.260 --> 00:08:16.260
de las muchas aplicaciones

00:08:16.260 --> 00:08:18.260
para esta nueva interfaz.

00:08:19.260 --> 00:08:21.260
En juegos y el mundo virtual, por ejemplo,

00:08:21.260 --> 00:08:23.260
nuestras expresiones faciales

00:08:23.260 --> 00:08:25.260
pueden ser utilizadas intuitivamente

00:08:25.260 --> 00:08:28.260
para controlar un avatar o personaje virtual.

00:08:29.260 --> 00:08:31.260
Podemos experimentar la fantasía de la magia

00:08:31.260 --> 00:08:34.260
y controlar el mundo con nuestra mente.

00:08:36.260 --> 00:08:39.260
Y también los colores, las luces,

00:08:39.260 --> 00:08:41.260
los sonidos y efectos

00:08:41.260 --> 00:08:43.260
pueden responder a nuestras emociones de manera dinámica

00:08:43.260 --> 00:08:46.260
para resaltar nuestras experiencias en tiempo real.

00:08:47.260 --> 00:08:49.260
Quiero mostrarles algunas aplicaciones

00:08:49.260 --> 00:08:52.260
desarrolladas por ingenieros en todo el mundo,

00:08:52.260 --> 00:08:55.260
con robots y máquinas simples

00:08:55.260 --> 00:08:57.260
como que un helicóptero de juguete pueda volar

00:08:57.260 --> 00:09:00.260
con sólo pensar en "elevación".

00:09:00.260 --> 00:09:02.260
Pero esta tecnología también puede aplicarse

00:09:02.260 --> 00:09:04.260
a escenarios de la vida real.

00:09:04.260 --> 00:09:06.260
En este ejemplo, una casa inteligente.

00:09:06.260 --> 00:09:09.260
Desde de

00:09:09.260 --> 00:09:11.260
para correr cortinas

00:09:11.260 --> 00:09:14.260
y luego cerrarlas.

00:09:22.260 --> 00:09:25.260
Y, por supuesto, para la iluminación:

00:09:25.260 --> 00:09:28.260
encender las luces

00:09:28.260 --> 00:09:30.260
o apagarlas.

00:09:30.260 --> 00:09:32.260
Y finalmente,

00:09:32.260 --> 00:09:34.260
aplicaciones para calidad de vida

00:09:34.260 --> 00:09:37.260
como controlar una silla de ruedas.

00:09:37.260 --> 00:09:39.260
En este ejemplo

00:09:39.260 --> 00:09:42.260
las expresiones faciales controlan los movimientos.

00:09:42.260 --> 00:09:45.260
Voz: Guiña el ojo derecho para girar a la derecha.

00:09:50.260 --> 00:09:53.260
Ahora el izquierdo para girar a la izquierda.

00:10:02.260 --> 00:10:05.260
Ahora sonríe para avanzar.

00:10:08.260 --> 00:10:10.260
TL: Estamos... muchas gracias.

00:10:10.260 --> 00:10:15.260
(Aplauso)

00:10:15.260 --> 00:10:18.260
Estamos apenas comenzando a explorar las posibilidades.

00:10:18.260 --> 00:10:20.260
Y con la contribución de la sociedad

00:10:20.260 --> 00:10:22.260
y el aporte de los ingenieros

00:10:22.260 --> 00:10:25.260
e investigadores de todo el mundo

00:10:25.260 --> 00:10:27.260
esperamos poder darle forma

00:10:27.260 --> 00:10:30.260
al nuevo rumbo de la tecnología. Muchas gracias.

