WEBVTT
Kind: captions
Language: zh-TW

00:00:00.000 --> 00:00:07.000
譯者: Jeannie Cheng
審譯者: Sunshine Wang

00:00:16.260 --> 00:00:18.260
直到現在，我們與機器的溝通

00:00:18.260 --> 00:00:20.260
仍局限於

00:00:20.260 --> 00:00:22.260
有意識和直接的模式

00:00:22.260 --> 00:00:24.260
不論是一些簡單的事情

00:00:24.260 --> 00:00:26.260
如用開關開燈

00:00:26.260 --> 00:00:29.260
或一些複雜的程式來控制機械人

00:00:29.260 --> 00:00:32.260
我們都要給機器輸入一個

00:00:32.260 --> 00:00:34.260
甚至一系列的指令

00:00:34.260 --> 00:00:37.260
才能命令它執行一些動作

00:00:37.260 --> 00:00:39.260
相反的，人與人的溝通

00:00:39.260 --> 00:00:42.260
就更加複雜和有趣得多

00:00:42.260 --> 00:00:44.260
因為我們會考慮到

00:00:44.260 --> 00:00:47.260
言語未表達的言外之意

00:00:47.260 --> 00:00:50.260
我們會觀察表情、肢體語言

00:00:50.260 --> 00:00:52.260
在對話中我們會用直覺來

00:00:52.260 --> 00:00:55.260
感受對方的感覺和情緒

00:00:55.260 --> 00:00:57.260
這些都是做決定時

00:00:57.260 --> 00:00:59.260
一些重要的因素

00:00:59.260 --> 00:01:01.260
我們的願景是引進

00:01:01.260 --> 00:01:04.260
全新的人與電腦的互動科技

00:01:04.260 --> 00:01:06.260
到人類互動的領域

00:01:06.260 --> 00:01:08.260
這麼一來電腦不只可以

00:01:08.260 --> 00:01:10.260
明白你指示它所做的事情

00:01:10.260 --> 00:01:12.260
而且也會對面部表情

00:01:12.260 --> 00:01:14.260
和情緒經歷

00:01:14.260 --> 00:01:16.260
作出反應

00:01:16.260 --> 00:01:18.260
還有什麼比從大腦的

00:01:18.260 --> 00:01:20.260
情感控制中樞直接解譯

00:01:20.260 --> 00:01:22.260
大腦產生的電波

00:01:22.260 --> 00:01:25.260
來得更好呢？

00:01:25.260 --> 00:01:27.260
這聽起來好像是不錯的主意

00:01:27.260 --> 00:01:29.260
但這個任務，正如Bruno所說

00:01:29.260 --> 00:01:32.260
並不容易，原因有兩個

00:01:32.260 --> 00:01:35.260
第一是大腦的偵查演算法

00:01:35.260 --> 00:01:37.260
我們的腦是由

00:01:37.260 --> 00:01:39.260
數十億個活躍的神經元所組成

00:01:39.260 --> 00:01:42.260
如果把神經細胞的軸索連在一起

00:01:42.260 --> 00:01:44.260
大概有十七萬公里

00:01:44.260 --> 00:01:46.260
這些神經元互動時

00:01:46.260 --> 00:01:48.260
產生的化學作用所發射出的電脈衝

00:01:48.260 --> 00:01:50.260
能夠被測量到

00:01:50.260 --> 00:01:53.260
大部分功能性腦

00:01:53.260 --> 00:01:55.260
是分佈在

00:01:55.260 --> 00:01:57.260
大腦的表層

00:01:57.260 --> 00:02:00.260
心智能力功能也位於此，為了增加表面積

00:02:00.260 --> 00:02:03.260
大腦皮質層有非常多的褶皺

00:02:03.260 --> 00:02:05.260
大腦皮質褶皺

00:02:05.260 --> 00:02:07.260
對分析電脈衝

00:02:07.260 --> 00:02:10.260
帶來一個很大的挑戰

00:02:10.260 --> 00:02:12.260
每個人大腦皮質層

00:02:12.260 --> 00:02:14.260
的褶皺都不同

00:02:14.260 --> 00:02:16.260
就像指紋一樣

00:02:16.260 --> 00:02:18.260
因此電脈衝訊息

00:02:18.260 --> 00:02:21.260
雖然來自功能腦同樣的區域

00:02:21.260 --> 00:02:23.260
但大腦皮質褶皺結構早已形成

00:02:23.260 --> 00:02:25.260
在不同的人的大腦裡

00:02:25.260 --> 00:02:27.260
即使是雙胞胎

00:02:27.260 --> 00:02:30.260
訊息發生位置也不同

00:02:30.260 --> 00:02:32.260
大腦皮質層電脈衝訊息

00:02:32.260 --> 00:02:34.260
沒有一致性

00:02:34.260 --> 00:02:36.260
我們的突破是建立一個演算法

00:02:36.260 --> 00:02:38.260
攤開大腦皮質層

00:02:38.260 --> 00:02:40.260
去勘測這些

00:02:40.260 --> 00:02:42.260
訊息的原點

00:02:42.260 --> 00:02:45.260
繼而把它運用在大眾身上

00:02:46.260 --> 00:02:48.260
第二項挑戰是

00:02:48.260 --> 00:02:51.260
觀察腦電波的儀器

00:02:51.260 --> 00:02:53.260
腦波測量基本上包括

00:02:53.260 --> 00:02:56.260
一個有許多感應器的髮網

00:02:56.260 --> 00:02:59.260
就像現在圖中所看到的

00:02:59.260 --> 00:03:01.260
技術人員會把電極

00:03:01.260 --> 00:03:03.260
用導電的膠或漿糊

00:03:03.260 --> 00:03:05.260
固定在頭皮上

00:03:05.260 --> 00:03:08.260
這個準備程序需要在頭皮製造

00:03:08.260 --> 00:03:10.260
輕微的擦傷

00:03:10.260 --> 00:03:12.260
這個程序既費時

00:03:12.260 --> 00:03:14.260
又不舒服

00:03:14.260 --> 00:03:16.260
再加上，這些系統

00:03:16.260 --> 00:03:19.260
非常昂貴，得花上數萬美金

00:03:20.260 --> 00:03:23.260
現在，我邀請Evan Grant

00:03:23.260 --> 00:03:25.260
去年的演講者上台

00:03:25.260 --> 00:03:27.260
他很樂意

00:03:27.260 --> 00:03:29.260
幫忙示範

00:03:29.260 --> 00:03:31.260
我們所設計的儀器

00:03:31.260 --> 00:03:37.260
(鼓掌)

00:03:37.260 --> 00:03:39.260
你們所看到的儀器是

00:03:39.260 --> 00:03:41.260
有十四個頻道，高傳真的

00:03:41.260 --> 00:03:43.260
腦電波訊號擷取系統

00:03:43.260 --> 00:03:46.260
不需要任何頭皮準備程序

00:03:46.260 --> 00:03:48.260
沒有導電的膠或漿糊

00:03:48.260 --> 00:03:51.260
戴上它，等訊號穩定

00:03:51.260 --> 00:03:53.260
只要幾分鐘

00:03:53.260 --> 00:03:55.260
而且是無線的

00:03:55.260 --> 00:03:58.260
它讓你活動自如

00:03:58.260 --> 00:04:01.260
比起那些幾萬美元的

00:04:01.260 --> 00:04:04.260
傳統腦電波系統

00:04:04.260 --> 00:04:06.260
這個頭戴式耳機

00:04:06.260 --> 00:04:08.260
只要幾百美金

00:04:08.260 --> 00:04:11.260
現在來談談大腦感應演算法

00:04:11.260 --> 00:04:13.260
好，面部表情--

00:04:13.260 --> 00:04:15.260
如同之前講到的情緒經驗--

00:04:15.260 --> 00:04:17.260
這套系統有令人意想不到的設計

00:04:17.260 --> 00:04:19.260
只要做一些敏感度調整

00:04:19.260 --> 00:04:22.260
就可以運用於個人化的使用

00:04:22.260 --> 00:04:24.260
但因時間的關係

00:04:24.260 --> 00:04:26.260
現在只示範認知的部份

00:04:26.260 --> 00:04:28.260
這套系統能夠讓您

00:04:28.260 --> 00:04:31.260
只用意念移動虛擬物件

00:04:32.260 --> 00:04:34.260
Evan是第一次接觸這個系統

00:04:34.260 --> 00:04:36.260
因此我們要先

00:04:36.260 --> 00:04:38.260
建立一個新的檔案

00:04:38.260 --> 00:04:41.260
他當然不是Joanne， 所以要增加一個用戶

00:04:41.260 --> 00:04:43.260
Evan，好了!

00:04:43.260 --> 00:04:46.260
首先要做的是

00:04:46.260 --> 00:04:48.260
練習發出一個

00:04:48.260 --> 00:04:50.260
中立的訊號

00:04:50.260 --> 00:04:52.260
Evan不需要做

00:04:52.260 --> 00:04:54.260
什麼特別的事

00:04:54.260 --> 00:04:56.260
就這樣放輕鬆

00:04:56.260 --> 00:04:58.260
重點是建立一個基準線

00:04:58.260 --> 00:05:00.260
或是大腦的正常狀態

00:05:00.260 --> 00:05:02.260
因為每個人的腦都不相同

00:05:02.260 --> 00:05:04.260
這大概需要八秒的時間

00:05:04.260 --> 00:05:06.260
完成了

00:05:06.260 --> 00:05:08.260
我們可以選擇一個有動作的活動

00:05:08.260 --> 00:05:10.260
Evan，你可選擇一個

00:05:10.260 --> 00:05:12.260
在你腦海中可以清楚看到的事情

00:05:12.260 --> 00:05:14.260
讓我們做一個"拉"的動作

00:05:14.260 --> 00:05:16.260
好，點選"拉"

00:05:16.260 --> 00:05:18.260
我們現在

00:05:18.260 --> 00:05:20.260
需要Evan想像

00:05:20.260 --> 00:05:22.260
一件物品在螢幕上

00:05:22.260 --> 00:05:24.260
往前移動

00:05:24.260 --> 00:05:27.260
他這樣做的時候

00:05:27.260 --> 00:05:29.260
螢幕上會出現一個測量棒

00:05:29.260 --> 00:05:31.260
第一次沒有任何事情發生

00:05:31.260 --> 00:05:34.260
因為系統還不知道他怎麼想像"拉"的動作

00:05:34.260 --> 00:05:36.260
在這八秒中

00:05:36.260 --> 00:05:38.260
持續想著這個念頭

00:05:38.260 --> 00:05:41.260
一、二、三、開始

00:05:49.260 --> 00:05:51.260
好了

00:05:51.260 --> 00:05:53.260
當我們按了接受

00:05:53.260 --> 00:05:55.260
這個方塊就活了起來

00:05:55.260 --> 00:05:57.260
讓我們看看Evan

00:05:57.260 --> 00:06:00.260
能否真的嘗試想像"拉"的動作

00:06:00.260 --> 00:06:02.260
哇! 非常好!

00:06:02.260 --> 00:06:05.260
(鼓掌)

00:06:05.260 --> 00:06:07.260
真是令人驚訝！

00:06:07.260 --> 00:06:11.260
(鼓掌)

00:06:11.260 --> 00:06:13.260
我們還有一些時間

00:06:13.260 --> 00:06:15.260
我要請Evan

00:06:15.260 --> 00:06:17.260
做一些比較困難的動作

00:06:17.260 --> 00:06:19.260
這個有點難

00:06:19.260 --> 00:06:22.260
因為要想像

00:06:22.260 --> 00:06:24.260
在物質界裡不存在的事物

00:06:24.260 --> 00:06:26.260
就是 "消失"

00:06:26.260 --> 00:06:28.260
就動作而言

00:06:28.260 --> 00:06:31.260
因為經常做這些動作，所以能"看見"它

00:06:31.260 --> 00:06:33.260
但"消失"沒有任何類似的動作

00:06:33.260 --> 00:06:35.260
Evan, 現在請你

00:06:35.260 --> 00:06:38.260
想像這個方塊慢慢消失

00:06:38.260 --> 00:06:41.260
一樣的練習。 一、二、三、開始

00:06:50.260 --> 00:06:53.260
可以了，我們試試吧

00:06:53.260 --> 00:06:56.260
我的天啊！他真的是非常厲害

00:06:57.260 --> 00:06:59.260
再試一次

00:07:04.260 --> 00:07:06.260
（EG儀器:） 失去專注力

00:07:06.260 --> 00:07:08.260
(笑聲)

00:07:08.260 --> 00:07:10.260
這套系統真的辦到了

00:07:10.260 --> 00:07:12.260
雖然只維持

00:07:12.260 --> 00:07:14.260
一段很短的時間

00:07:14.260 --> 00:07:17.260
我認為想像"消失"

00:07:17.260 --> 00:07:19.260
真的是非常困難

00:07:19.260 --> 00:07:21.260
這個系統了不起的是

00:07:21.260 --> 00:07:23.260
這套軟體只有一次機會

00:07:23.260 --> 00:07:26.260
知道Evan是怎麼想像"消失"的

00:07:26.260 --> 00:07:29.260
而這部機器便學會了演算它

00:07:29.260 --> 00:07:33.260
(鼓掌)

00:07:33.260 --> 00:07:35.260
謝謝

00:07:35.260 --> 00:07:38.260
很棒！很棒！

00:07:38.260 --> 00:07:40.260
(鼓掌)

00:07:40.260 --> 00:07:43.260
謝謝，Evan你真的是這項科技

00:07:43.260 --> 00:07:46.260
最佳的展示人員

00:07:46.260 --> 00:07:48.260
正如你們所見

00:07:48.260 --> 00:07:51.260
這個軟體有一個水準測量系統

00:07:51.260 --> 00:07:53.260
Evan或其他使用者

00:07:53.260 --> 00:07:55.260
對這個系統越熟悉

00:07:55.260 --> 00:07:58.260
就能不斷地增加更多，更多的檢測項目

00:07:58.260 --> 00:08:00.260
這個系統就能開始分辨

00:08:00.260 --> 00:08:03.260
不同的明顯想法

00:08:04.260 --> 00:08:06.260
當你訓練做這些檢測項目

00:08:06.260 --> 00:08:08.260
這些念頭、想法就能指定或聯繫到

00:08:08.260 --> 00:08:10.260
任何的電腦平台、

00:08:10.260 --> 00:08:12.260
應用程式或儀器上

00:08:12.260 --> 00:08:14.260
讓我為你們展示幾個例子

00:08:14.260 --> 00:08:16.260
這個新界面有

00:08:16.260 --> 00:08:18.260
很多可運用的應用程式

00:08:19.260 --> 00:08:21.260
例如在遊戲或虛擬世界

00:08:21.260 --> 00:08:23.260
你可以用臉部表情

00:08:23.260 --> 00:08:25.260
自然、直覺地

00:08:25.260 --> 00:08:28.260
操控遊戲角色或虛擬人物

00:08:29.260 --> 00:08:31.260
無庸置疑，你將會親身體驗幻想的魔力

00:08:31.260 --> 00:08:34.260
和運用意念來控制世界

00:08:36.260 --> 00:08:39.260
顏色，燈光

00:08:39.260 --> 00:08:41.260
聲音和音效

00:08:41.260 --> 00:08:43.260
也可以不斷地變化來反映你的情緒狀態

00:08:43.260 --> 00:08:46.260
即時強化你的感受

00:08:47.260 --> 00:08:49.260
現在來看看應用程式

00:08:49.260 --> 00:08:52.260
全世界的研發人員發明了

00:08:52.260 --> 00:08:55.260
不同的機械人和簡單的機器，例如

00:08:55.260 --> 00:08:57.260
這個例子是操作玩具直昇機

00:08:57.260 --> 00:09:00.260
只要用意念就可以讓它飛起來

00:09:00.260 --> 00:09:02.260
這項科技也可以應用在

00:09:02.260 --> 00:09:04.260
實際生活中

00:09:04.260 --> 00:09:06.260
看看智能家居的例子

00:09:06.260 --> 00:09:09.260
從使用者界面控制系統

00:09:09.260 --> 00:09:11.260
來打開

00:09:11.260 --> 00:09:14.260
或關上窗簾

00:09:22.260 --> 00:09:25.260
當然電燈也可以

00:09:25.260 --> 00:09:28.260
開

00:09:28.260 --> 00:09:30.260
或關

00:09:30.260 --> 00:09:32.260
最後

00:09:32.260 --> 00:09:34.260
是應用在改善真實生活

00:09:34.260 --> 00:09:37.260
例如能夠控制電動輪椅

00:09:37.260 --> 00:09:39.260
這個例子裡

00:09:39.260 --> 00:09:42.260
面部表情對應於移動方向的指令

00:09:42.260 --> 00:09:45.260
男聲: 現在眨右眼右轉

00:09:50.260 --> 00:09:53.260
眨左眼左轉

00:10:02.260 --> 00:10:05.260
微笑往前

00:10:08.260 --> 00:10:10.260
TL: 我們真的.... 多謝各位。

00:10:10.260 --> 00:10:15.260
(鼓掌)

00:10:15.260 --> 00:10:18.260
現今我們所做到的只是很小的一部分

00:10:18.260 --> 00:10:20.260
有研發團隊的投入

00:10:20.260 --> 00:10:22.260
及全世界的研發和

00:10:22.260 --> 00:10:25.260
研究人員的參與

00:10:25.260 --> 00:10:27.260
我們希望這一項科技能夠

00:10:27.260 --> 00:10:30.260
從這裡一路順利發展。謝謝各位。

