WEBVTT
Kind: captions
Language: en

00:00:15.260 --> 00:00:17.260
Chris Anderson: Julian, welcome.

00:00:17.260 --> 00:00:19.260
It's been reported that WikiLeaks, your baby,

00:00:19.260 --> 00:00:21.260
has, in the last few years

00:00:21.260 --> 00:00:24.260
has released more classified documents

00:00:24.260 --> 00:00:26.260
than the rest of the world's media combined.

00:00:26.260 --> 00:00:28.260
Can that possibly be true?

00:00:28.260 --> 00:00:30.260
Julian Assange: Yeah, can it possibly be true?

00:00:30.260 --> 00:00:33.260
It's a worry -- isn't it? -- that the rest of the world's media

00:00:33.260 --> 00:00:35.260
is doing such a bad job

00:00:35.260 --> 00:00:37.260
that a little group of activists

00:00:37.260 --> 00:00:39.260
is able to release more

00:00:39.260 --> 00:00:41.260
of that type of information

00:00:41.260 --> 00:00:43.260
than the rest of the world press combined.

00:00:43.260 --> 00:00:45.260
CA: How does it work?

00:00:45.260 --> 00:00:48.260
How do people release the documents?

00:00:48.260 --> 00:00:51.260
And how do you secure their privacy?

00:00:51.260 --> 00:00:53.260
JA: So these are -- as far as we can tell --

00:00:53.260 --> 00:00:55.260
classical whistleblowers,

00:00:55.260 --> 00:00:57.260
and we have a number of ways for them

00:00:57.260 --> 00:00:59.260
to get information to us.

00:00:59.260 --> 00:01:01.260
So we use this state-of-the-art encryption

00:01:01.260 --> 00:01:03.260
to bounce stuff around the Internet, to hide trails,

00:01:03.260 --> 00:01:05.260
pass it through legal jurisdictions

00:01:05.260 --> 00:01:08.260
like Sweden and Belgium

00:01:08.260 --> 00:01:11.260
to enact those legal protections.

00:01:12.260 --> 00:01:14.260
We get information in the mail,

00:01:14.260 --> 00:01:17.260
the regular postal mail,

00:01:17.260 --> 00:01:19.260
encrypted or not,

00:01:19.260 --> 00:01:22.260
vet it like a regular news organization, format it --

00:01:22.260 --> 00:01:25.260
which is sometimes something that's quite hard to do,

00:01:25.260 --> 00:01:27.260
when you're talking about

00:01:27.260 --> 00:01:29.260
giant databases of information --

00:01:29.260 --> 00:01:31.260
release it to the public

00:01:31.260 --> 00:01:33.260
and then defend ourselves

00:01:33.260 --> 00:01:36.260
against the inevitable legal and political attacks.

00:01:36.260 --> 00:01:38.260
CA: So you make an effort to ensure

00:01:38.260 --> 00:01:40.260
the documents are legitimate,

00:01:40.260 --> 00:01:42.260
but you actually

00:01:42.260 --> 00:01:45.260
almost never know who the identity of the source is?

00:01:45.260 --> 00:01:48.260
JA: That's right, yeah. Very rarely do we ever know,

00:01:49.260 --> 00:01:52.260
and if we find out at some stage

00:01:52.260 --> 00:01:55.260
then we destroy that information as soon as possible.

00:01:55.260 --> 00:01:57.260
(Phone ring) God damn it.

00:01:57.260 --> 00:02:01.260
(Laughter)

00:02:01.260 --> 00:02:03.260
CA: I think that's the CIA asking what the code is

00:02:03.260 --> 00:02:05.260
for a TED membership.

00:02:05.260 --> 00:02:08.260
(Laughter)

00:02:08.260 --> 00:02:10.260
So let's take [an] example, actually.

00:02:10.260 --> 00:02:12.260
This is something

00:02:12.260 --> 00:02:14.260
you leaked a few years ago.

00:02:14.260 --> 00:02:16.260
If we can have this document up ...

00:02:16.260 --> 00:02:18.260
So this was a story in Kenya a few years ago.

00:02:18.260 --> 00:02:21.260
Can you tell us what you leaked and what happened?

00:02:21.260 --> 00:02:23.260
JA: So this is the Kroll Report.

00:02:23.260 --> 00:02:26.260
This was a secret intelligence report

00:02:26.260 --> 00:02:28.260
commissioned by the Kenyan government

00:02:28.260 --> 00:02:31.260
after its election in 2004.

00:02:31.260 --> 00:02:33.260
Prior to 2004, Kenya was ruled

00:02:33.260 --> 00:02:35.260
by Daniel arap Moi

00:02:35.260 --> 00:02:37.260
for about 18 years.

00:02:37.260 --> 00:02:40.260
He was a soft dictator of Kenya.

00:02:40.260 --> 00:02:42.260
And when Kibaki got into power --

00:02:42.260 --> 00:02:44.260
through a coalition of forces that were trying

00:02:44.260 --> 00:02:46.260
to clean up corruption in Kenya --

00:02:46.260 --> 00:02:48.260
they commissioned this report,

00:02:48.260 --> 00:02:50.260
spent about two million pounds

00:02:50.260 --> 00:02:52.260
on this and an associated report.

00:02:52.260 --> 00:02:55.260
And then the government sat on it

00:02:55.260 --> 00:02:57.260
and used it for political leverage on Moi,

00:02:57.260 --> 00:02:59.260
who was the richest man --

00:02:59.260 --> 00:03:02.260
still is the richest man -- in Kenya.

00:03:02.260 --> 00:03:05.260
It's the Holy Grail of Kenyan journalism.

00:03:05.260 --> 00:03:08.260
So I went there in 2007,

00:03:08.260 --> 00:03:10.260
and we managed to get hold of this

00:03:10.260 --> 00:03:12.260
just prior to the election --

00:03:12.260 --> 00:03:15.260
the national election, December 28.

00:03:17.260 --> 00:03:20.260
When we released that report,

00:03:20.260 --> 00:03:23.260
we did so three days after the new president, Kibaki,

00:03:23.260 --> 00:03:25.260
had decided to pal up with

00:03:25.260 --> 00:03:27.260
the man that he was going to clean out,

00:03:27.260 --> 00:03:29.260
Daniel arap Moi,

00:03:29.260 --> 00:03:32.260
so this report then

00:03:32.260 --> 00:03:34.260
became a dead albatross

00:03:34.260 --> 00:03:37.260
around President Kibaki's neck.

00:03:38.260 --> 00:03:41.260
CA: And -- I mean, to cut a long story short --

00:03:41.260 --> 00:03:44.260
word of the report leaked into Kenya,

00:03:44.260 --> 00:03:47.260
not from the official media, but indirectly,

00:03:47.260 --> 00:03:50.260
and in your opinion, it actually shifted the election.

00:03:50.260 --> 00:03:53.260
JA: Yeah. So this became front page of the Guardian

00:03:53.260 --> 00:03:56.260
and was then printed in all the surrounding countries of Kenya,

00:03:56.260 --> 00:03:59.260
in Tanzanian and South African press.

00:03:59.260 --> 00:04:01.260
And so it came in from the outside.

00:04:01.260 --> 00:04:03.260
And that, after a couple of days,

00:04:03.260 --> 00:04:05.260
made the Kenyan press feel safe to talk about it.

00:04:05.260 --> 00:04:08.260
And it ran for 20 nights straight on Kenyan TV,

00:04:08.260 --> 00:04:11.260
shifted the vote by 10 percent,

00:04:11.260 --> 00:04:13.260
according to a Kenyan intelligence report,

00:04:13.260 --> 00:04:15.260
which changed the result of the election.

00:04:15.260 --> 00:04:17.260
CA: Wow, so your leak

00:04:17.260 --> 00:04:19.260
really substantially changed the world?

00:04:19.260 --> 00:04:21.260
JA: Yep.

00:04:21.260 --> 00:04:25.260
(Applause)

00:04:25.260 --> 00:04:27.260
CA: Here's -- We're going to just show

00:04:27.260 --> 00:04:30.260
a short clip from this

00:04:30.260 --> 00:04:32.260
Baghdad airstrike video.

00:04:32.260 --> 00:04:34.260
The video itself is longer,

00:04:34.260 --> 00:04:36.260
but here's a short clip.

00:04:36.260 --> 00:04:39.260
This is -- this is intense material, I should warn you.

00:04:39.260 --> 00:04:42.260
Radio: ... just fuckin', once you get on 'em just open 'em up.

00:04:42.260 --> 00:04:46.260
I see your element, uh, got about four Humvees, uh, out along ...

00:04:46.260 --> 00:04:49.260
You're clear. All right. Firing.

00:04:49.260 --> 00:04:52.260
Let me know when you've got them. Let's shoot.

00:04:52.260 --> 00:04:54.260
Light 'em all up.

00:04:54.260 --> 00:04:56.260
C'mon, fire!

00:04:56.260 --> 00:04:59.260
(Machine gun fire)

00:04:59.260 --> 00:05:02.260
Keep shoot 'n. Keep shoot 'n.

00:05:02.260 --> 00:05:05.260
(Machine gun fire)

00:05:05.260 --> 00:05:08.260
Keep shoot 'n.

00:05:08.260 --> 00:05:10.260
Hotel ... Bushmaster Two-Six, Bushmaster Two-Six,

00:05:10.260 --> 00:05:12.260
we need to move, time now!

00:05:12.260 --> 00:05:15.260
All right, we just engaged all eight individuals.

00:05:15.260 --> 00:05:18.260
Yeah, we see two birds [helicopters], and we're still firing.

00:05:18.260 --> 00:05:20.260
Roger. I got 'em.

00:05:20.260 --> 00:05:22.260
Two-Six, this is Two-Six, we're mobile.

00:05:22.260 --> 00:05:24.260
Oops, I'm sorry. What was going on?

00:05:24.260 --> 00:05:26.260
God damn it, Kyle. All right, hahaha. I hit 'em.

00:05:29.260 --> 00:05:32.260
CA: So, what was the impact of that?

00:05:32.260 --> 00:05:35.260
JA: The impact on the people who worked on it

00:05:35.260 --> 00:05:37.260
was severe.

00:05:37.260 --> 00:05:39.260
We ended up sending two people to Baghdad

00:05:39.260 --> 00:05:41.260
to further research that story.

00:05:41.260 --> 00:05:44.260
So this is just the first of three attacks

00:05:44.260 --> 00:05:46.260
that occurred in that scene.

00:05:46.260 --> 00:05:48.260
CA: So, I mean, 11 people died in that attack, right,

00:05:48.260 --> 00:05:50.260
including two Reuters employees?

00:05:50.260 --> 00:05:52.260
JA: Yeah. Two Reuters employees,

00:05:52.260 --> 00:05:55.260
two young children were wounded.

00:05:55.260 --> 00:05:58.260
There were between 18 and 26 people killed all together.

00:05:58.260 --> 00:06:00.260
CA: And releasing this caused

00:06:00.260 --> 00:06:02.260
widespread outrage.

00:06:02.260 --> 00:06:04.260
What was the key element of this

00:06:04.260 --> 00:06:07.260
that actually caused the outrage, do you think?

00:06:07.260 --> 00:06:09.260
JA: I don't know. I guess people can see

00:06:09.260 --> 00:06:12.260
the gross disparity in force.

00:06:12.260 --> 00:06:14.260
You have guys walking in a relaxed way down the street,

00:06:14.260 --> 00:06:17.260
and then an Apache helicopter sitting up at one kilometer

00:06:17.260 --> 00:06:19.260
firing 30-millimeter cannon shells

00:06:19.260 --> 00:06:21.260
on everyone --

00:06:21.260 --> 00:06:24.260
looking for any excuse to do so --

00:06:24.260 --> 00:06:26.260
and killing people rescuing the wounded.

00:06:26.260 --> 00:06:29.260
And there was two journalists involved that clearly weren't insurgents

00:06:29.260 --> 00:06:31.260
because that's their full-time job.

00:06:33.260 --> 00:06:36.260
CA: I mean, there's been this U.S. intelligence analyst,

00:06:36.260 --> 00:06:38.260
Bradley Manning, arrested,

00:06:38.260 --> 00:06:41.260
and it's alleged that he confessed in a chat room

00:06:41.260 --> 00:06:44.260
to have leaked this video to you,

00:06:44.260 --> 00:06:46.260
along with 280,000

00:06:46.260 --> 00:06:48.260
classified U.S. embassy cables.

00:06:48.260 --> 00:06:51.260
I mean, did he?

00:06:51.260 --> 00:06:53.260
JA: We have denied receiving those cables.

00:06:53.260 --> 00:06:55.260
He has been charged,

00:06:55.260 --> 00:06:57.260
about five days ago,

00:06:57.260 --> 00:07:00.260
with obtaining 150,000 cables

00:07:00.260 --> 00:07:02.260
and releasing 50.

00:07:02.260 --> 00:07:05.260
Now, we had released,

00:07:05.260 --> 00:07:07.260
early in the year,

00:07:07.260 --> 00:07:10.260
a cable from the Reykjavik U.S. embassy,

00:07:11.260 --> 00:07:13.260
but this is not necessarily connected.

00:07:13.260 --> 00:07:15.260
I mean, I was a known visitor of that embassy.

00:07:15.260 --> 00:07:17.260
CA: I mean, if you did receive thousands

00:07:17.260 --> 00:07:20.260
of U.S. embassy diplomatic cables ...

00:07:20.260 --> 00:07:22.260
JA: We would have released them. (CA: You would?)

00:07:22.260 --> 00:07:25.260
JA: Yeah. (CA: Because?)

00:07:25.260 --> 00:07:27.260
JA: Well, because these sort of things

00:07:27.260 --> 00:07:30.260
reveal what the true state

00:07:30.260 --> 00:07:32.260
of, say,

00:07:32.260 --> 00:07:34.260
Arab governments are like,

00:07:34.260 --> 00:07:37.260
the true human-rights abuses in those governments.

00:07:37.260 --> 00:07:39.260
If you look at declassified cables,

00:07:39.260 --> 00:07:41.260
that's the sort of material that's there.

00:07:41.260 --> 00:07:43.260
CA: So let's talk a little more broadly about this.

00:07:43.260 --> 00:07:45.260
I mean, in general, what's your philosophy?

00:07:45.260 --> 00:07:47.260
Why is it right

00:07:47.260 --> 00:07:50.260
to encourage leaking of secret information?

00:07:51.260 --> 00:07:54.260
JA: Well, there's a question as to what sort of information is important in the world,

00:07:54.260 --> 00:07:56.260
what sort of information

00:07:56.260 --> 00:07:58.260
can achieve reform.

00:07:58.260 --> 00:08:00.260
And there's a lot of information.

00:08:00.260 --> 00:08:02.260
So information that organizations

00:08:02.260 --> 00:08:05.260
are spending economic effort into concealing,

00:08:05.260 --> 00:08:07.260
that's a really good signal

00:08:07.260 --> 00:08:09.260
that when the information gets out,

00:08:09.260 --> 00:08:11.260
there's a hope of it doing some good --

00:08:11.260 --> 00:08:13.260
because the organizations that know it best,

00:08:13.260 --> 00:08:15.260
that know it from the inside out,

00:08:15.260 --> 00:08:18.260
are spending work to conceal it.

00:08:18.260 --> 00:08:20.260
And that's what we've found in practice,

00:08:20.260 --> 00:08:23.260
and that's what the history of journalism is.

00:08:23.260 --> 00:08:26.260
CA: But are there risks with that,

00:08:26.260 --> 00:08:29.260
either to the individuals concerned

00:08:29.260 --> 00:08:31.260
or indeed to society at large,

00:08:31.260 --> 00:08:33.260
where leaking can actually have

00:08:33.260 --> 00:08:35.260
an unintended consequence?

00:08:35.260 --> 00:08:37.260
JA: Not that we have seen with anything we have released.

00:08:37.260 --> 00:08:39.260
I mean, we have a harm immunization policy.

00:08:39.260 --> 00:08:41.260
We have a way of dealing with information

00:08:41.260 --> 00:08:43.260
that has sort of personal --

00:08:43.260 --> 00:08:45.260
personally identifying information in it.

00:08:46.260 --> 00:08:49.260
But there are legitimate secrets --

00:08:49.260 --> 00:08:52.260
you know, your records with your doctor;

00:08:52.260 --> 00:08:54.260
that's a legitimate secret --

00:08:54.260 --> 00:08:56.260
but we deal with whistleblowers that are coming forward

00:08:56.260 --> 00:08:59.260
that are really sort of well-motivated.

00:08:59.260 --> 00:09:01.260
CA: So they are well-motivated.

00:09:01.260 --> 00:09:03.260
And what would you say to, for example,

00:09:03.260 --> 00:09:06.260
the, you know, the parent of someone

00:09:06.260 --> 00:09:09.260
whose son is out serving the U.S. military,

00:09:09.260 --> 00:09:11.260
and he says, "You know what,

00:09:11.260 --> 00:09:13.260
you've put up something that someone had an incentive to put out.

00:09:13.260 --> 00:09:15.260
It shows a U.S. soldier laughing

00:09:15.260 --> 00:09:17.260
at people dying.

00:09:17.260 --> 00:09:19.260
That gives the impression, has given the impression,

00:09:19.260 --> 00:09:21.260
to millions of people around the world

00:09:21.260 --> 00:09:23.260
that U.S. soldiers are inhuman people.

00:09:23.260 --> 00:09:25.260
Actually, they're not. My son isn't. How dare you?"

00:09:25.260 --> 00:09:27.260
What would you say to that?

00:09:27.260 --> 00:09:29.260
JA: Yeah, we do get a lot of that.

00:09:29.260 --> 00:09:31.260
But remember, the people in Baghdad,

00:09:31.260 --> 00:09:34.260
the people in Iraq, the people in Afghanistan --

00:09:34.260 --> 00:09:36.260
they don't need to see the video;

00:09:36.260 --> 00:09:38.260
they see it every day.

00:09:38.260 --> 00:09:41.260
So it's not going to change their opinion. It's not going to change their perception.

00:09:41.260 --> 00:09:43.260
That's what they see every day.

00:09:43.260 --> 00:09:46.260
It will change the perception and opinion

00:09:46.260 --> 00:09:48.260
of the people who are paying for it all,

00:09:48.260 --> 00:09:51.260
and that's our hope.

00:09:51.260 --> 00:09:54.260
CA: So you found a way to shine light

00:09:54.260 --> 00:09:57.260
into what you see

00:09:57.260 --> 00:10:00.260
as these sort of dark secrets in companies and in government.

00:10:01.260 --> 00:10:03.260
Light is good.

00:10:03.260 --> 00:10:05.260
But do you see any irony in the fact that,

00:10:05.260 --> 00:10:07.260
in order for you to shine that light,

00:10:07.260 --> 00:10:09.260
you have to, yourself,

00:10:09.260 --> 00:10:12.260
create secrecy around your sources?

00:10:12.260 --> 00:10:15.260
JA: Not really. I mean, we don't have

00:10:15.260 --> 00:10:18.260
any WikiLeaks dissidents yet.

00:10:19.260 --> 00:10:22.260
We don't have sources who are dissidents on other sources.

00:10:23.260 --> 00:10:26.260
Should they come forward, that would be a tricky situation for us,

00:10:26.260 --> 00:10:29.260
but we're presumably acting in such a way

00:10:29.260 --> 00:10:31.260
that people feel

00:10:31.260 --> 00:10:33.260
morally compelled

00:10:33.260 --> 00:10:36.260
to continue our mission, not to screw it up.

00:10:37.260 --> 00:10:40.260
CA: I'd actually be interested, just based on what we've heard so far --

00:10:40.260 --> 00:10:43.260
I'm curious as to the opinion in the TED audience.

00:10:45.260 --> 00:10:47.260
You know, there might be a couple of views

00:10:47.260 --> 00:10:49.260
of WikiLeaks and of Julian.

00:10:49.260 --> 00:10:52.260
You know, hero -- people's hero --

00:10:52.260 --> 00:10:55.260
bringing this important light.

00:10:55.260 --> 00:10:57.260
Dangerous troublemaker.

00:10:58.260 --> 00:11:01.260
Who's got the hero view?

00:11:02.260 --> 00:11:05.260
Who's got the dangerous troublemaker view?

00:11:06.260 --> 00:11:08.260
JA: Oh, come on. There must be some.

00:11:09.260 --> 00:11:11.260
CA: It's a soft crowd, Julian, a soft crowd.

00:11:11.260 --> 00:11:13.260
We have to try better. Let's show them another example.

00:11:13.260 --> 00:11:16.260
Now here's something that you haven't yet leaked,

00:11:16.260 --> 00:11:19.260
but I think for TED you are.

00:11:19.260 --> 00:11:21.260
I mean it's an intriguing story that's just happened, right?

00:11:21.260 --> 00:11:23.260
What is this?

00:11:23.260 --> 00:11:25.260
JA: So this is a sample of what we do

00:11:25.260 --> 00:11:27.260
sort of every day.

00:11:27.260 --> 00:11:30.260
So late last year -- in November last year --

00:11:30.260 --> 00:11:32.260
there was a series of well blowouts

00:11:32.260 --> 00:11:34.260
in Albania,

00:11:34.260 --> 00:11:37.260
like the well blowout in the Gulf of Mexico,

00:11:37.260 --> 00:11:39.260
but not quite as big.

00:11:39.260 --> 00:11:42.260
And we got a report --

00:11:42.260 --> 00:11:45.260
a sort of engineering analysis into what happened --

00:11:45.260 --> 00:11:48.260
saying that, in fact, security guards

00:11:48.260 --> 00:11:51.260
from some rival, various competing oil firms

00:11:51.260 --> 00:11:54.260
had, in fact, parked trucks there and blown them up.

00:11:55.260 --> 00:11:58.260
And part of the Albanian government was in this, etc., etc.

00:11:59.260 --> 00:12:00.260
And the engineering report

00:12:00.260 --> 00:12:02.260
had nothing on the top of it,

00:12:02.260 --> 00:12:04.260
so it was an extremely difficult document for us.

00:12:04.260 --> 00:12:06.260
We couldn't verify it because we didn't know

00:12:06.260 --> 00:12:08.260
who wrote it and knew what it was about.

00:12:08.260 --> 00:12:10.260
So we were kind of skeptical that maybe it was

00:12:10.260 --> 00:12:12.260
a competing oil firm just sort of playing the issue up.

00:12:12.260 --> 00:12:14.260
So under that basis, we put it out and said,

00:12:14.260 --> 00:12:16.260
"Look, we're skeptical about this thing.

00:12:16.260 --> 00:12:18.260
We don't know, but what can we do?

00:12:18.260 --> 00:12:20.260
The material looks good, it feels right,

00:12:20.260 --> 00:12:22.260
but we just can't verify it."

00:12:22.260 --> 00:12:25.260
And we then got a letter

00:12:25.260 --> 00:12:28.260
just this week

00:12:28.260 --> 00:12:31.260
from the company who wrote it,

00:12:31.260 --> 00:12:34.260
wanting to track down the source --

00:12:34.260 --> 00:12:37.260
(Laughter)

00:12:38.260 --> 00:12:41.260
saying, "Hey, we want to track down the source."

00:12:41.260 --> 00:12:43.260
And we were like, "Oh, tell us more.

00:12:43.260 --> 00:12:46.260
What document is it, precisely, you're talking about?

00:12:46.260 --> 00:12:49.260
Can you show that you had legal authority over that document?

00:12:49.260 --> 00:12:51.260
Is it really yours?"

00:12:51.260 --> 00:12:54.260
So they sent us this screen shot

00:12:54.260 --> 00:12:56.260
with the author

00:12:56.260 --> 00:12:59.260
in the Microsoft Word ID.

00:13:01.260 --> 00:13:03.260
Yeah.

00:13:03.260 --> 00:13:08.260
(Applause)

00:13:08.260 --> 00:13:10.260
That's happened quite a lot though.

00:13:10.260 --> 00:13:12.260
This is like one of our methods

00:13:12.260 --> 00:13:15.260
of identifying, of verifying, what a material is,

00:13:15.260 --> 00:13:17.260
is to try and get these guys to write letters.

00:13:17.260 --> 00:13:20.260
CA: Yeah. Have you had information

00:13:20.260 --> 00:13:22.260
from inside BP?

00:13:22.260 --> 00:13:25.260
JA: Yeah, we have a lot, but I mean, at the moment,

00:13:25.260 --> 00:13:28.260
we are undergoing a sort of serious fundraising and engineering effort.

00:13:28.260 --> 00:13:30.260
So our publication rate

00:13:30.260 --> 00:13:32.260
over the past few months

00:13:32.260 --> 00:13:34.260
has been sort of minimized

00:13:34.260 --> 00:13:37.260
while we're re-engineering our back systems

00:13:37.260 --> 00:13:40.260
for the phenomenal public interest that we have.

00:13:40.260 --> 00:13:42.260
That's a problem.

00:13:42.260 --> 00:13:45.260
I mean, like any sort of growing startup organization,

00:13:45.260 --> 00:13:47.260
we are sort of overwhelmed

00:13:47.260 --> 00:13:49.260
by our growth,

00:13:49.260 --> 00:13:51.260
and that means we're getting enormous quantity

00:13:51.260 --> 00:13:53.260
of whistleblower disclosures

00:13:53.260 --> 00:13:55.260
of a very high caliber

00:13:55.260 --> 00:13:57.260
but don't have enough people to actually

00:13:57.260 --> 00:13:59.260
process and vet this information.

00:13:59.260 --> 00:14:01.260
CA: So that's the key bottleneck,

00:14:01.260 --> 00:14:03.260
basically journalistic volunteers

00:14:03.260 --> 00:14:06.260
and/or the funding of journalistic salaries?

00:14:06.260 --> 00:14:08.260
JA: Yep. Yeah, and trusted people.

00:14:08.260 --> 00:14:10.260
I mean, we're an organization

00:14:10.260 --> 00:14:12.260
that is hard to grow very quickly

00:14:12.260 --> 00:14:14.260
because of the sort of material we deal with,

00:14:14.260 --> 00:14:17.260
so we have to restructure

00:14:17.260 --> 00:14:19.260
in order to have people

00:14:19.260 --> 00:14:22.260
who will deal with the highest national security stuff,

00:14:22.260 --> 00:14:24.260
and then lower security cases.

00:14:24.260 --> 00:14:27.260
CA: So help us understand a bit about you personally

00:14:27.260 --> 00:14:29.260
and how you came to do this.

00:14:29.260 --> 00:14:31.260
And I think I read that as a kid

00:14:31.260 --> 00:14:34.260
you went to 37 different schools.

00:14:34.260 --> 00:14:36.260
Can that be right?

00:14:36.260 --> 00:14:39.260
JA: Well, my parents were in the movie business

00:14:39.260 --> 00:14:41.260
and then on the run from a cult,

00:14:41.260 --> 00:14:43.260
so the combination between the two ...

00:14:43.260 --> 00:14:47.260
(Laughter)

00:14:47.260 --> 00:14:49.260
CA: I mean, a psychologist might say

00:14:49.260 --> 00:14:52.260
that's a recipe for breeding paranoia.

00:14:52.260 --> 00:14:54.260
JA: What, the movie business?

00:14:54.260 --> 00:14:57.260
(Laughter)

00:14:57.260 --> 00:15:00.260
(Applause)

00:15:00.260 --> 00:15:02.260
CA: And you were also -- I mean,

00:15:02.260 --> 00:15:04.260
you were also a hacker at an early age

00:15:04.260 --> 00:15:07.260
and ran into the authorities early on.

00:15:07.260 --> 00:15:10.260
JA: Well, I was a journalist.

00:15:10.260 --> 00:15:12.260
You know, I was a very young journalist activist at an early age.

00:15:12.260 --> 00:15:14.260
I wrote a magazine,

00:15:14.260 --> 00:15:17.260
was prosecuted for it when I was a teenager.

00:15:17.260 --> 00:15:19.260
So you have to be careful with hacker.

00:15:19.260 --> 00:15:21.260
I mean there's like -- there's a method

00:15:21.260 --> 00:15:23.260
that can be deployed for various things.

00:15:23.260 --> 00:15:25.260
Unfortunately, at the moment,

00:15:25.260 --> 00:15:27.260
it's mostly deployed by the Russian mafia

00:15:27.260 --> 00:15:29.260
in order to steal your grandmother's bank accounts.

00:15:29.260 --> 00:15:32.260
So this phrase is not,

00:15:32.260 --> 00:15:34.260
not as nice as it used to be.

00:15:34.260 --> 00:15:36.260
CA: Yeah, well, I certainly don't think

00:15:36.260 --> 00:15:39.260
you're stealing anyone's grandmother's bank account,

00:15:39.260 --> 00:15:41.260
but what about

00:15:41.260 --> 00:15:43.260
your core values?

00:15:43.260 --> 00:15:46.260
Can you give us a sense of what they are

00:15:46.260 --> 00:15:48.260
and maybe some incident in your life

00:15:48.260 --> 00:15:51.260
that helped determine them?

00:15:53.260 --> 00:15:55.260
JA: I'm not sure about the incident.

00:15:55.260 --> 00:15:58.260
But the core values:

00:15:58.260 --> 00:16:01.260
well, capable, generous men

00:16:01.260 --> 00:16:03.260
do not create victims;

00:16:03.260 --> 00:16:05.260
they nurture victims.

00:16:05.260 --> 00:16:07.260
And that's something from my father

00:16:07.260 --> 00:16:10.260
and something from other capable, generous men

00:16:10.260 --> 00:16:13.260
that have been in my life.

00:16:13.260 --> 00:16:15.260
CA: Capable, generous men do not create victims;

00:16:15.260 --> 00:16:17.260
they nurture victims?

00:16:17.260 --> 00:16:19.260
JA: Yeah. And you know,

00:16:19.260 --> 00:16:23.260
I'm a combative person,

00:16:23.260 --> 00:16:25.260
so I'm not actually so big on the nurture,

00:16:25.260 --> 00:16:28.260
but some way --

00:16:28.260 --> 00:16:31.260
there is another way of nurturing victims,

00:16:31.260 --> 00:16:34.260
which is to police perpetrators

00:16:34.260 --> 00:16:36.260
of crime.

00:16:36.260 --> 00:16:38.260
And so that is something

00:16:38.260 --> 00:16:40.260
that has been in my character

00:16:40.260 --> 00:16:42.260
for a long time.

00:16:42.260 --> 00:16:45.260
CA: So just tell us, very quickly in the last minute, the story:

00:16:45.260 --> 00:16:48.260
what happened in Iceland?

00:16:48.260 --> 00:16:51.260
You basically published something there,

00:16:51.260 --> 00:16:54.260
ran into trouble with a bank,

00:16:54.260 --> 00:16:56.260
then the news service there

00:16:56.260 --> 00:16:59.260
was injuncted from running the story.

00:16:59.260 --> 00:17:01.260
Instead, they publicized your side.

00:17:01.260 --> 00:17:04.260
That made you very high-profile in Iceland. What happened next?

00:17:04.260 --> 00:17:06.260
JA: Yeah, this is a great case, you know.

00:17:06.260 --> 00:17:08.260
Iceland went through this financial crisis.

00:17:08.260 --> 00:17:10.260
It was the hardest hit of any country in the world.

00:17:10.260 --> 00:17:12.260
Its banking sector was 10 times the GDP

00:17:12.260 --> 00:17:14.260
of the rest of the economy.

00:17:14.260 --> 00:17:17.260
Anyway, so we release this report

00:17:17.260 --> 00:17:20.260
in July last year.

00:17:20.260 --> 00:17:22.260
And the national TV station was injuncted

00:17:22.260 --> 00:17:24.260
five minutes before it went on air,

00:17:24.260 --> 00:17:26.260
like out of a movie: injunction landed on the news desk,

00:17:26.260 --> 00:17:28.260
and the news reader was like,

00:17:28.260 --> 00:17:30.260
"This has never happened before. What do we do?"

00:17:30.260 --> 00:17:32.260
Well, we just show the website instead,

00:17:32.260 --> 00:17:35.260
for all that time, as a filler,

00:17:35.260 --> 00:17:37.260
and we became very famous in Iceland,

00:17:37.260 --> 00:17:40.260
went to Iceland and spoke about this issue.

00:17:40.260 --> 00:17:42.260
And there was a feeling in the community

00:17:42.260 --> 00:17:44.260
that that should never happen again,

00:17:44.260 --> 00:17:46.260
and as a result,

00:17:46.260 --> 00:17:48.260
working with Icelandic politicians

00:17:48.260 --> 00:17:50.260
and some other international legal experts,

00:17:50.260 --> 00:17:52.260
we put together a new sort of

00:17:52.260 --> 00:17:55.260
package of legislation for Iceland

00:17:55.260 --> 00:17:58.260
to sort of become an offshore haven

00:17:58.260 --> 00:18:01.260
for the free press,

00:18:01.260 --> 00:18:04.260
with the strongest journalistic protections in the world,

00:18:04.260 --> 00:18:06.260
with a new Nobel Prize

00:18:06.260 --> 00:18:08.260
for freedom of speech.

00:18:08.260 --> 00:18:10.260
Iceland's a Nordic country,

00:18:10.260 --> 00:18:13.260
so, like Norway, it's able to tap into the system.

00:18:13.260 --> 00:18:15.260
And just a month ago,

00:18:15.260 --> 00:18:18.260
this was passed by the Icelandic parliament unanimously.

00:18:18.260 --> 00:18:20.260
CA: Wow.

00:18:20.260 --> 00:18:26.260
(Applause)

00:18:26.260 --> 00:18:28.260
Last question, Julian.

00:18:28.260 --> 00:18:30.260
When you think of the future then,

00:18:30.260 --> 00:18:32.260
do you think it's more likely to be

00:18:32.260 --> 00:18:34.260
Big Brother exerting more control,

00:18:34.260 --> 00:18:36.260
more secrecy,

00:18:36.260 --> 00:18:38.260
or us watching

00:18:38.260 --> 00:18:40.260
Big Brother,

00:18:40.260 --> 00:18:43.260
or it's just all to be played for either way?

00:18:43.260 --> 00:18:45.260
JA: I'm not sure which way it's going to go.

00:18:45.260 --> 00:18:47.260
I mean, there's enormous pressures

00:18:47.260 --> 00:18:50.260
to harmonize freedom of speech legislation

00:18:50.260 --> 00:18:53.260
and transparency legislation around the world --

00:18:53.260 --> 00:18:55.260
within the E.U.,

00:18:55.260 --> 00:18:57.260
between China and the United States.

00:18:57.260 --> 00:19:00.260
Which way is it going to go? It's hard to see.

00:19:00.260 --> 00:19:02.260
That's why it's a very interesting time to be in --

00:19:02.260 --> 00:19:04.260
because with just a little bit of effort,

00:19:04.260 --> 00:19:07.260
we can shift it one way or the other.

00:19:07.260 --> 00:19:10.260
CA: Well, it looks like I'm reflecting the audience's opinion

00:19:10.260 --> 00:19:12.260
to say, Julian, be careful,

00:19:12.260 --> 00:19:14.260
and all power to you.

00:19:14.260 --> 00:19:16.260
JA: Thank you, Chris. (CA: Thank you.)

00:19:16.260 --> 00:19:26.260
(Applause)

