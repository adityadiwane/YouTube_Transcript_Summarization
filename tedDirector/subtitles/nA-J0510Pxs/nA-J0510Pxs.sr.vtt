WEBVTT
Kind: captions
Language: sr

00:00:00.000 --> 00:00:07.000
Prevodilac: Maja Budišin Lukin
Lektor: Tatjana Jevdjic

00:00:13.010 --> 00:00:14.310
Artur Č. Klark,

00:00:14.310 --> 00:00:17.505
poznati pisac naučne fantastike
iz 1950-ih

00:00:17.505 --> 00:00:21.527
je rekao: "Mi precenjujemo tehnologiju
na kratke staze

00:00:21.527 --> 00:00:24.327
i potcenjujemo je na duge staze."

00:00:24.327 --> 00:00:26.744
I mislim da je taj naš strah

00:00:26.744 --> 00:00:31.326
vezan za poslove koji nestaju
zbog veštačke inteligencije i robota.

00:00:31.326 --> 00:00:33.993
Tako precenjujemo tehnologiju
na kratke staze.

00:00:33.993 --> 00:00:39.371
Mene brine da li ćemo dobiti tehnologiju
koja nam treba na duge staze,

00:00:39.371 --> 00:00:45.085
jer će nas demografija zaista dovesti
do mnogih poslova koji treba da se urade

00:00:45.085 --> 00:00:50.460
i naše društvo će morati da se gradi
na leđima gvozdenih robota u budućnosti.

00:00:50.460 --> 00:00:53.286
Zato me plaši da nećemo imati
dovoljno robota.

00:00:53.286 --> 00:00:57.925
A strah od gubljenja poslova
zbog tehnologije je prisutan već dugo.

00:00:57.925 --> 00:01:01.877
Još je 1957. bio film
sa Spenserom Trejsijem i Ketrin Hepbern.

00:01:01.877 --> 00:01:03.325
Znate kako se završio.

00:01:03.325 --> 00:01:07.411
Spenser Trejsi je uveo kompjuter,
centralni kompjuter iz 1957.

00:01:07.411 --> 00:01:09.311
da pomogne bibliotekarima.

00:01:09.311 --> 00:01:12.788
Bibliotekari u kompaniji
bi odgovarali na pitanja direktora:

00:01:12.788 --> 00:01:16.625
"Kako se zovu irvasi Dedа Mraza?"

00:01:16.625 --> 00:01:17.810
I oni bi to potražili.

00:01:17.810 --> 00:01:20.243
Centralni kompjuter je trebalo
da im u tome pomogne.

00:01:20.243 --> 00:01:24.326
Naravno, od centralnih kompjutera
iz 1957. nije bilo mnogo pomoći.

00:01:24.326 --> 00:01:27.476
Bibliotekari su se uplašili
da će njihovi poslovi nestati,

00:01:27.476 --> 00:01:29.125
ali to se, u stvari, nije desilo.

00:01:29.125 --> 00:01:34.380
Broj bibliotekara je rastao
još dugo posle 1957.

00:01:34.380 --> 00:01:37.494
Sve dok internet nije ušao u igru,

00:01:37.494 --> 00:01:40.027
s vebom i pretraživačima,

00:01:40.027 --> 00:01:42.676
potreba za bibliotekarima nije opala.

00:01:42.676 --> 00:01:46.883
Čini mi se da su svi iz 1957.
potpuno potcenili

00:01:46.883 --> 00:01:51.643
nivo tehnologije koju danas svi nosimo
u rukama i po džepovima.

00:01:51.643 --> 00:01:57.360
Možemo samo da upitamo:
"Kako se zovu irvasi Deda Mraza?",

00:01:57.360 --> 00:01:59.111
ili bilo šta drugo i da odmah
dobijemo odgovor.

00:01:59.111 --> 00:02:04.710
Inače, plate bibliotekara su rasle brže

00:02:04.710 --> 00:02:07.709
od plata za druge poslove u SAD-u,
u istom tom periodu

00:02:07.709 --> 00:02:11.277
jer su bibliotekari i kompjuteri
postali partneri.

00:02:11.277 --> 00:02:14.160
Kompjuteri su postali sredstvo i bibliotekari
su dobili više sredstava za korišćenje

00:02:14.160 --> 00:02:16.452
i postali su efikasniji u tom periodu.

00:02:16.452 --> 00:02:18.244
Isto se dogodilo u kancelarijama.

00:02:18.244 --> 00:02:20.542
U ranijim vremenima
ljudi su koristili tabele.

00:02:20.542 --> 00:02:22.876
Tabele, na raširenim listovima papira,

00:02:22.876 --> 00:02:25.026
su se izračunavale ručno.

00:02:25.026 --> 00:02:27.393
A onda se pojavila ta zanimljiva stvar.

00:02:27.393 --> 00:02:29.683
Kompjuterskom revolucijom '80-ih,

00:02:29.683 --> 00:02:34.425
napravljeni su tabelarni programi
baš za činovnike,

00:02:34.425 --> 00:02:36.077
ne da bi ih zamenili,

00:02:36.077 --> 00:02:40.743
već za činovnike sposobne
da programiraju.

00:02:40.743 --> 00:02:43.871
Tako su činovnici
postali programeri tabela.

00:02:43.871 --> 00:02:45.962
To je povećalo njihove mogućnosti.

00:02:45.962 --> 00:02:48.541
Nisu više morali da rade
svakodnevne proračune

00:02:48.541 --> 00:02:51.476
već su mogli da urade mnogo više.

00:02:51.476 --> 00:02:54.734
Danas, počinjemo da susrećemo robote
u našim životima.

00:02:54.734 --> 00:02:57.043
Na levoj strani je IRobotov PakBot.

00:02:57.043 --> 00:03:00.475
Kada su vojnici naišli na bombe
pored puta u Iraku i Avganistanu,

00:03:00.475 --> 00:03:04.624
umesto da su obukli bombaška odela,
izašli i ubadali štapom,

00:03:04.624 --> 00:03:06.943
kako su to radili sve do 2002.,

00:03:06.943 --> 00:03:08.351
sada su slali robota.

00:03:08.351 --> 00:03:10.494
Dakle, robot preuzima opasne poslove.

00:03:10.494 --> 00:03:15.012
Na desnoj strani su neki TUG roboti
od kompanije "Aethon" iz Pitsburga.

00:03:15.012 --> 00:03:17.309
Nalaze se u stotinama bolnica
širom SAD-a.

00:03:17.309 --> 00:03:20.049
Oni odnose prljave čaršave
dole u perionicu.

00:03:20.049 --> 00:03:21.925
Vraćaju prljave sudove u kuhinju.

00:03:21.925 --> 00:03:24.010
Donose lekove iz apoteke.

00:03:24.010 --> 00:03:26.955
Tako da su medicinske sestre
i niže bolničko osoblje rasterećeni

00:03:26.955 --> 00:03:30.620
od svakodnevnog mehaničkog posla
guranja tih stvari,

00:03:30.620 --> 00:03:32.693
da bi provodili više vremena
s pacijentima.

00:03:32.693 --> 00:03:37.392
U stvari, roboti su postali sveprisutni
u našim životima na mnogo načina.

00:03:37.392 --> 00:03:42.660
Ali čini mi se kada su u pitanju
fabrički roboti, da ih se ljudi plaše,

00:03:42.660 --> 00:03:46.767
jer je opasno biti u njihovoj okolini.

00:03:46.767 --> 00:03:51.592
Da bi ih programirali morate da razumete
6-dimenzionalne vektore i kvaternione,

00:03:51.592 --> 00:03:54.742
a obični ljudi ne mogu
da komunicirijaju sa njima.

00:03:54.742 --> 00:03:57.361
Mislim da je ta tehnologija
otišla pogrešnim putem.

00:03:57.361 --> 00:04:00.994
Odvojila je radnike od tehnologije

00:04:00.994 --> 00:04:04.093
i čini mi se da zaista moramo
da imamo u vidu tehnologiju

00:04:04.093 --> 00:04:06.195
sa kojom obični radnici mogu
da komuniciraju.

00:04:06.195 --> 00:04:09.875
Danas ću vam govoriti o Baksteru,
koga sam već spominjao.

00:04:09.875 --> 00:04:14.120
Bakstera vidim kao put –
prvi talas robota

00:04:14.120 --> 00:04:18.410
sa kojim obični ljudi mogu da komuniciraju
u industrijskom okruženju.

00:04:18.410 --> 00:04:19.943
Dakle, Bakster je ovde gore.

00:04:19.943 --> 00:04:22.759
Ovo je Kris Herbert
iz "Rethink Robotics-a".

00:04:22.759 --> 00:04:24.295
Tamo imamo pokretnu traku.

00:04:24.295 --> 00:04:27.146
I ako osvetljenje nije prejako –

00:04:27.146 --> 00:04:31.192
Ah, ah! Evo ga.
Pokupio je predmet sa pokretne trake.

00:04:31.192 --> 00:04:34.042
Doći će, doneće ga ovamo
i spustiće ga.

00:04:34.042 --> 00:04:37.341
I onda će se vratiti
da bi uzeo drugi predmet.

00:04:37.341 --> 00:04:41.189
Interesantno je da Bakster
ima pomalo osnovnog zdravog razuma.

00:04:41.189 --> 00:04:43.410
Usput, šta se dešava s očima?

00:04:43.410 --> 00:04:44.910
Oči su tamo na ekranu.

00:04:44.910 --> 00:04:47.659
Oči gledaju u pravcu
u kome će se robot kretati.

00:04:47.659 --> 00:04:49.527
Osoba koja komunicira sa robotom

00:04:49.527 --> 00:04:53.093
zna kuda će ići i nije
iznenađena njegovim kretanjem.

00:04:53.093 --> 00:04:55.910
Ovde je Kris uzeo predmet
iz njegove ruke,

00:04:55.910 --> 00:04:58.142
a Bakster nije otišao
i pokušao da ga spusti;

00:04:58.142 --> 00:05:00.494
već se vratio, shvativši
da mora uzeti još jedan.

00:05:00.494 --> 00:05:03.661
Ima malo osnovnog zdravog razuma,
kreće se i skuplja predmete.

00:05:03.661 --> 00:05:05.454
Sa Baksterom se može
bezbedno komunicirati.

00:05:05.454 --> 00:05:08.219
To ne biste želeli da radite
sa sadašnjim industrijskim robotom.

00:05:08.219 --> 00:05:10.411
No Bakster vas neće povrediti.

00:05:10.411 --> 00:05:14.309
On oseća silu,
razume da je Kris tamo

00:05:14.309 --> 00:05:17.161
i ne gura ga i ne povređuje ga.

00:05:17.161 --> 00:05:20.456
Ipak, čini mi se da je najinteresantniji
Baksterov korisnički interfejs.

00:05:20.456 --> 00:05:23.802
Sada će ga Kris dohvatiti
za drugu ruku.

00:05:23.802 --> 00:05:29.216
Kada mu dohvati ruku, on je u modalitetu
nulte sile kompenzovane gravitacijom

00:05:29.216 --> 00:05:31.292
i na ekranu se pojavi grafika.

00:05:31.292 --> 00:05:35.826
Na levoj strani ekrana vidite ikone
za desnu ruku.

00:05:35.826 --> 00:05:38.620
Kris će mu staviti nešto u ruku,
robot će to doneti ovamo

00:05:38.620 --> 00:05:43.642
i pritiskom na dugme
pustiće to iz ruke.

00:05:43.642 --> 00:05:48.210
I robot razmišlja: "Ah, mora da je mislio
da ću spustiti taj predmet."

00:05:48.210 --> 00:05:49.910
Tada se upali mala ikona tamo.

00:05:49.910 --> 00:05:55.821
Kris mu skuplja prste,

00:05:55.821 --> 00:05:59.743
a robot zaključuje:
"Ah, želite da podignem predmet."

00:05:59.743 --> 00:06:01.542
Tada se upali zelena ikona tamo.

00:06:01.542 --> 00:06:06.537
Kris će označiti područje
u kome će robot da skuplja predmete.

00:06:06.537 --> 00:06:11.327
Samo ih premešta okolo i robot shvata
da je to područje za traženje.

00:06:11.327 --> 00:06:13.203
Nije morao da to izabere na meniju.

00:06:13.203 --> 00:06:16.360
I sada će otići i vežbaće
vizuelnu pojavu tog predmeta,

00:06:16.360 --> 00:06:18.076
dok mi nastavljamo s govorom.

00:06:18.076 --> 00:06:20.288
Kako nastavljamo ovde,

00:06:20.288 --> 00:06:22.459
reći ću vam kako to izgleda
u fabrikama.

00:06:22.459 --> 00:06:23.943
Ove robote otpremamo svaki dan

00:06:23.943 --> 00:06:25.493
u fabrike širom zemlje.

00:06:25.493 --> 00:06:26.675
Ovo je Mildred.

00:06:26.675 --> 00:06:28.241
Mildred je fabrička radnica
iz Konektikata.

00:06:28.241 --> 00:06:30.620
Radi na traci preko 20 godina.

00:06:30.620 --> 00:06:33.963
Sat vremena nakon što je videla svog
prvog industrijskog robota,

00:06:33.963 --> 00:06:37.023
programirala ga je
da obavlja neke poslove u fabrici.

00:06:37.023 --> 00:06:39.454
Zaključila je
da joj se roboti zaista sviđaju.

00:06:39.454 --> 00:06:44.124
I robot je radio njene pređašnje,
jednostavne i ponavljajuće poslove.

00:06:44.124 --> 00:06:45.962
Sada ima robota koji to radi.

00:06:45.962 --> 00:06:48.526
Kada smo prvi put bili na razgovoru
sa ljudima u fabrikama

00:06:48.526 --> 00:06:51.360
o tome kako da postignemo bolju
komunikaciju između robota i njih,

00:06:51.360 --> 00:06:52.926
jedno od pitanja
koje smo im postavili bilo je:

00:06:52.926 --> 00:06:55.371
"Da li želite da vaša deca
rade u fabrici?"

00:06:55.371 --> 00:06:59.743
Univerzalni odgovor je bio:
"Ne, želim bolji posao za svoju decu".

00:06:59.743 --> 00:07:03.120
Rezultat toga je
da je Mildred tipična

00:07:03.120 --> 00:07:04.975
današnja fabrička radnica u SAD.

00:07:04.975 --> 00:07:07.160
Oni su stariji i biće još stariji.

00:07:07.160 --> 00:07:09.725
Nema mnogo mladih ljudi
zaposlenih u fabrici.

00:07:09.725 --> 00:07:13.041
Pošto im njihovi zadaci
postaju sve tegobniji

00:07:13.041 --> 00:07:16.134
moramo im dati sredstva
s kojima će moći sarađivati,

00:07:16.134 --> 00:07:17.944
tako da bi roboti
mogli biti deo rešenja,

00:07:17.944 --> 00:07:22.795
da mogu da nastave s radom
i mi sa proizvodnjom u SAD.

00:07:22.795 --> 00:07:26.860
Naša vizija je da Mildred,
radnica na traci,

00:07:26.860 --> 00:07:29.777
postane Mildred – trener robota.

00:07:29.777 --> 00:07:30.922
Ona podiže svoju ulogu,

00:07:30.922 --> 00:07:35.509
kao što su činovnici u '80-im
povisili svoju ulogu.

00:07:35.509 --> 00:07:39.593
Ne dajemo im sredstva koja moraju
da uče godinama da bi ih korisitili,

00:07:39.593 --> 00:07:43.037
već njihov način rada
mogu da nauče u par minuta.

00:07:43.037 --> 00:07:47.826
Postoje dve velike zakonitosti
koje su svojevoljne, ali neizbežne.

00:07:47.826 --> 00:07:50.203
To su klimatske promene
i demografija.

00:07:50.203 --> 00:07:52.870
Demografija će zaista
promeniti naš svet.

00:07:52.870 --> 00:07:56.832
Ovo je procenat odraslih
koji su u radnim godinama.

00:07:56.832 --> 00:07:58.795
Malo više se spustio
u poslednjih 40 godina.

00:07:58.795 --> 00:08:02.675
U narednih 40 godina to će se
dramatično promeniti, čak i u Kini.

00:08:02.675 --> 00:08:08.002
Procenat odraslih u radnim godinama
dramatično opada.

00:08:08.002 --> 00:08:13.092
Posmatrano s druge strane,
broj penzionera brzo raste

00:08:13.092 --> 00:08:17.429
kako "bebi-bumeri" stižu
do godina za penziju.

00:08:17.429 --> 00:08:20.977
To znači da će biti više ljudi
s manje novca za socijalnu sigurnost

00:08:20.977 --> 00:08:23.610
u borbi za usluge.

00:08:23.610 --> 00:08:27.661
Ali više od toga,
što smo stariji postajemo slabiji

00:08:27.661 --> 00:08:29.910
i ne možemo da obavljamo
sve ranije uobičajene zadatke.

00:08:29.910 --> 00:08:33.623
Ukoliko pogledamo statistike
o starosti negovatelja,

00:08:33.623 --> 00:08:38.093
oni su sve stariji.

00:08:38.093 --> 00:08:40.092
To se statistički dešava
upravo sada.

00:08:40.092 --> 00:08:46.030
Povećavanjem starije populacije
i sve starijih penzionera,

00:08:46.030 --> 00:08:48.057
biće sve manje ljudi
da se o njima brinu.

00:08:48.057 --> 00:08:50.676
Zato mislim da ćemo stvarno morati
da imamo robote da nam pomažu.

00:08:50.676 --> 00:08:53.911
Ne mislim na robota
u smislu saputnika.

00:08:53.911 --> 00:08:57.192
Mislim na robote koji rade stvari
koje obično sami obavljamo,

00:08:57.192 --> 00:08:58.861
a koje nam postaju
napornije u starosti.

00:08:58.861 --> 00:09:01.726
Nošenje namirnica u i iz auta,
uz stepenice, do kuhinje

00:09:01.726 --> 00:09:04.121
ili čak, kad postanemo mnogo stariji,

00:09:04.121 --> 00:09:07.209
vožnja naših automobila
radi odlaska u posete.

00:09:07.209 --> 00:09:13.576
Mislim da robotika daje ljudima
mogućnost dostojanstvene starosti

00:09:13.576 --> 00:09:17.125
ako imamo rešenu kontrolu robota.

00:09:17.125 --> 00:09:20.510
Oni ne moraju da se oslanjaju na ljude
kojih je sve manje, da im pomažu.

00:09:20.510 --> 00:09:27.402
Zaista mislim
da ćemo više vremena provoditi

00:09:27.402 --> 00:09:29.703
sa robotima kao što je Bakster

00:09:29.703 --> 00:09:36.397
i da ćemo raditi sa robotima kao Bakster
u svakodnevnom životu. I da ćemo –

00:09:36.397 --> 00:09:38.877
Evo, Bakster, dobro je.

00:09:38.877 --> 00:09:43.121
I da ćemo se svi oslanjati na robote
u sledećih 40 godina

00:09:43.121 --> 00:09:45.287
koji će biti deo
našeg svakodnevnog života.

00:09:45.287 --> 00:09:46.581
Hvala, puno.

00:09:46.581 --> 00:09:49.576
(Aplauz)

