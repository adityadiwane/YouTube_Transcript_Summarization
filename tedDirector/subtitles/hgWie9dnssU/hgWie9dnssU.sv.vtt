WEBVTT
Kind: captions
Language: sv

00:00:00.000 --> 00:00:07.000
Översättare: Karl Månsson
Granskare: Annika Bidner

00:00:12.738 --> 00:00:14.735
Om du minns internets första decennium,

00:00:14.735 --> 00:00:16.990
så var det ett väldigt stelt ställe.

00:00:16.990 --> 00:00:19.235
Man kunde koppla upp sig, 
besöka webbsidor,

00:00:19.235 --> 00:00:21.748
och dessa sattes upp
av antingen organisationer

00:00:21.748 --> 00:00:23.269
som hade folk som gjorde det

00:00:23.269 --> 00:00:25.498
eller av teknikkunniga individer

00:00:25.498 --> 00:00:27.235
vid den tiden.

00:00:27.235 --> 00:00:28.810
Och med sociala mediers ökning

00:00:28.810 --> 00:00:31.209
och sociala nätverk under tidigt 2000-tal,

00:00:31.209 --> 00:00:33.998
förändrades internet
helt och hållet till en plats

00:00:33.998 --> 00:00:38.326
där majoriteten av innehållet
som vi använder

00:00:38.326 --> 00:00:40.278
läggs upp av vanliga användare,

00:00:40.278 --> 00:00:42.975
antingen med Youtube-videor
eller blogginlägg

00:00:42.975 --> 00:00:46.290
eller produktrecensioner
eller inlägg på sociala medier.

00:00:46.290 --> 00:00:48.847
Det har också blivit
en mycket mer interaktiv plats,

00:00:48.847 --> 00:00:51.274
där folk interagerar med varandra,

00:00:51.274 --> 00:00:52.970
de kommenterar, de delar,

00:00:52.970 --> 00:00:54.584
de läser inte bara.

00:00:54.584 --> 00:00:56.920
Facebook är inte den enda plats
där man gör detta

00:00:56.920 --> 00:00:57.918
men den är störst

00:00:57.918 --> 00:00:59.332
och kan illustrera siffrorna.

00:00:59.332 --> 00:01:02.809
Facebook har 1,2 miljarder
användare per månad.

00:01:02.809 --> 00:01:04.739
Så halva jordens internetbefolkning

00:01:04.739 --> 00:01:06.222
använder Facebook.

00:01:06.222 --> 00:01:08.464
De är en webbplats
som tillsammans med andra

00:01:08.464 --> 00:01:11.543
har möjliggjort för folk
att skapa sig en onlineidentitet

00:01:11.543 --> 00:01:13.625
med väldigt begränsade teknikkunskaper,

00:01:13.625 --> 00:01:15.801
och folk svarade med att lägga upp enormt

00:01:15.801 --> 00:01:17.784
mycket personlig information online.

00:01:17.784 --> 00:01:20.327
Så resultatet är att vi har behovsmässig,

00:01:20.327 --> 00:01:22.313
preferensmässig och demografisk data

00:01:22.313 --> 00:01:24.414
för hundratals miljoner människor,

00:01:24.414 --> 00:01:26.440
vilket inte tidigare funnits i historien.

00:01:26.440 --> 00:01:29.000
För en datorforskare som mig
betyder detta att

00:01:29.000 --> 00:01:30.664
jag har kunnat bygga modeller

00:01:30.664 --> 00:01:32.986
som kan förutse många gömda attribut

00:01:32.986 --> 00:01:35.270
om alla er som ni inte ens visste

00:01:35.270 --> 00:01:37.472
att ni delar mer er information om.

00:01:37.472 --> 00:01:40.304
Som forskare använder vi det för
att förbättra sättet

00:01:40.304 --> 00:01:41.968
som folk interagerar på nätet,

00:01:41.968 --> 00:01:44.467
men det finns applikationer
som är mindre osjälviska

00:01:44.467 --> 00:01:46.848
och det är ett problem
att användarna inte riktigt

00:01:46.848 --> 00:01:49.318
förstår dessa tekniker
och hur de fungerar,

00:01:49.318 --> 00:01:52.446
och även om de gjorde det,
har de inte så stor kontroll över det.

00:01:52.446 --> 00:01:54.216
Det jag vill prata med er om idag

00:01:54.216 --> 00:01:56.638
handlar om de saker
vi har en möjlighet att göra,

00:01:56.638 --> 00:01:59.401
och sen ge oss några idéer
om hur vi kan röra oss mot

00:01:59.401 --> 00:02:02.170
att ge tillbaka kontrollen
till användarna.

00:02:02.170 --> 00:02:03.756
Detta är Target, ett företag.

00:02:03.756 --> 00:02:05.064
Jag satte inte det emblemet

00:02:05.064 --> 00:02:07.250
på denna stackars gravida kvinnans mage.

00:02:07.250 --> 00:02:09.820
Du kanske har sett anekdoten
som publicerades i Forbes

00:02:09.820 --> 00:02:12.221
där Target skickade ett flygblad

00:02:12.221 --> 00:02:13.512
till en 15-årig flicka

00:02:13.512 --> 00:02:15.222
med reklam och kuponger

00:02:15.222 --> 00:02:17.636
för nappflaskor, blöjor och spjälsängar

00:02:17.636 --> 00:02:19.880
två veckor innan hon berättat
för sina föräldrar

00:02:19.880 --> 00:02:21.324
att hon var gravid.

00:02:21.324 --> 00:02:24.028
Ja, pappan var väldigt upprörd.

00:02:24.028 --> 00:02:25.744
Han sa, "Hur listade Target ut

00:02:25.744 --> 00:02:27.568
att denna gymnasietjejen var gravid

00:02:27.568 --> 00:02:29.528
innan hon berättade för sina föräldrar?".

00:02:29.528 --> 00:02:32.149
Det visade sig att de hade köphistoriken

00:02:32.149 --> 00:02:34.450
för tiotusentals kvinnor

00:02:34.450 --> 00:02:37.180
och beräknat, som de kallar det,
en graviditetspoäng,

00:02:37.180 --> 00:02:39.512
vilket inte bara räknar ut
om kvinnan är gravid,

00:02:39.512 --> 00:02:41.242
utan också när barnet kommer.

00:02:41.242 --> 00:02:42.546
De räknar inte ut det

00:02:42.546 --> 00:02:44.314
bara genom att se på det uppenbara,

00:02:44.314 --> 00:02:46.826
som att hon köper en spjälsäng
eller barnkläder,

00:02:46.826 --> 00:02:49.769
utan saker som att hon köpt mer vitaminer

00:02:49.769 --> 00:02:51.486
än vanligt

00:02:51.486 --> 00:02:52.950
eller att hon en handväska

00:02:52.950 --> 00:02:54.661
som är stor nog att rymma blöjor.

00:02:54.661 --> 00:02:56.901
Och för sig själva verkar inte dessa inköp

00:02:56.901 --> 00:02:59.040
avslöja särskilt mycket

00:02:59.040 --> 00:03:01.458
men det är ett beteendemönster, så när

00:03:01.458 --> 00:03:04.135
man sätter det i samma kontext
som tusentals andra,

00:03:04.135 --> 00:03:06.892
börjar det visa ett antal insikter.

00:03:06.892 --> 00:03:08.685
Det är den sortens saker vi gör

00:03:08.685 --> 00:03:11.252
när vi förutser saker om dig
på sociala medier.

00:03:11.252 --> 00:03:14.048
Vi letar efter små beteendemönster,

00:03:14.048 --> 00:03:16.730
som visar sig bland miljontals människor,

00:03:16.730 --> 00:03:19.436
som låter oss få reda på
alla möjliga saker.

00:03:19.436 --> 00:03:21.183
I mitt labb och med kollegor,

00:03:21.183 --> 00:03:23.200
har vi utvecklat mekanismer som låter oss

00:03:23.200 --> 00:03:24.770
förutsäga saker rätt precist

00:03:24.770 --> 00:03:26.265
som dina politiska preferenser

00:03:26.265 --> 00:03:29.997
din personlighetstyp, kön,
sexuell läggning,

00:03:29.997 --> 00:03:32.870
religion, ålder, intelligens,

00:03:32.870 --> 00:03:34.264
tillsammans med saker som

00:03:34.264 --> 00:03:36.201
hur mycket du litar på dina medmänniskor

00:03:36.201 --> 00:03:38.005
och hur starka dessa relationer är.

00:03:38.005 --> 00:03:39.790
Vi kan göra allt detta väldigt väl.

00:03:39.790 --> 00:03:41.987
Återigen, det kommer inte från vad ni tror

00:03:41.987 --> 00:03:44.089
är uppenbara saker.

00:03:44.089 --> 00:03:46.370
Mitt favoritexempel från en studie

00:03:46.370 --> 00:03:47.530
som publicerades i år

00:03:47.530 --> 00:03:49.475
i Proceedings of the National Academies.

00:03:49.475 --> 00:03:50.960
Om du googlar så hittar du den.

00:03:50.960 --> 00:03:52.632
Den är på fyra sidor och lättläst.

00:03:52.632 --> 00:03:53.632
De såg bara

00:03:53.632 --> 00:03:55.565
på folks gillningar på Facebook,

00:03:55.565 --> 00:03:57.485
så bara de saker man gillar på Facebook,

00:03:57.485 --> 00:03:59.793
och använde det
för att förutse alla attribut

00:03:59.793 --> 00:04:01.268
tillsammans med andra saker.

00:04:01.268 --> 00:04:04.229
Och i deras text listade de
de fem gillningarna

00:04:04.229 --> 00:04:07.016
som bäst indikerade hög intelligens.

00:04:07.016 --> 00:04:09.340
Bland dessa fanns en sida

00:04:09.340 --> 00:04:11.245
om curly fries. (Skratt)

00:04:11.245 --> 00:04:13.338
Curly fries är jättegoda,

00:04:13.338 --> 00:04:15.778
men att gilla dem
betyder inte nödvändigtvis

00:04:15.778 --> 00:04:18.138
att du är smartare än en
genomsnittlig person.

00:04:18.138 --> 00:04:21.155
Hur kommer det sig
att en av de starkaste indikationerna

00:04:21.155 --> 00:04:22.725
på ens intelligens

00:04:22.725 --> 00:04:24.172
är att gilla denna sida

00:04:24.172 --> 00:04:26.424
med innehåll som är totalt irrelevant

00:04:26.424 --> 00:04:28.582
för attributet som förutses?

00:04:28.951 --> 00:04:30.535
Och det visar sig att vi måste se

00:04:30.535 --> 00:04:32.253
till en massa bakomliggande teorier

00:04:32.253 --> 00:04:34.722
för att se hur vi kan göra detta.

00:04:34.722 --> 00:04:37.635
En av dem är en sociologisk teori
som kallas homofili,

00:04:37.635 --> 00:04:40.727
vilket betyder att folk är vänner
med folk som liknar dem själva.

00:04:40.727 --> 00:04:43.741
Så om du är smart känner du ofta
andra smarta människor

00:04:43.741 --> 00:04:45.921
och om du är ung
känner du ofta unga människor

00:04:45.921 --> 00:04:47.598
och detta är etablerat sen

00:04:47.598 --> 00:04:48.743
hundratals år tillbaka.

00:04:48.743 --> 00:04:49.975
Vi vet också mycket om

00:04:49.975 --> 00:04:52.525
hur information sprids genom nätverk.

00:04:52.525 --> 00:04:54.279
Det visar sig att virala videos

00:04:54.279 --> 00:04:56.685
eller Facebookgillningar
eller annan information

00:04:56.685 --> 00:04:58.653
sprider som på exakt samma sätt

00:04:58.653 --> 00:05:01.027
som sjukdomar sprider sig
genom sociala nätverk.

00:05:01.027 --> 00:05:02.818
Detta har vi studerat länge.

00:05:02.818 --> 00:05:04.394
Vi har bra modeller för det.

00:05:04.394 --> 00:05:06.551
Och man kan sätta ihop saker

00:05:06.551 --> 00:05:09.639
och börja se varför såna här saker händer.

00:05:09.639 --> 00:05:11.453
Om jag ger er en hypotes,

00:05:11.453 --> 00:05:14.640
skulle det vara att en smart kille
startade den här sidan,

00:05:14.640 --> 00:05:16.999
eller kanske att en av de första
som gillade sidan

00:05:16.999 --> 00:05:18.645
hade fått bra resultat på testet.

00:05:18.645 --> 00:05:20.643
Och de gillade det,
deras vänner såg det,

00:05:20.643 --> 00:05:23.765
och genom homofili vet vi
att han förmodligen hade smarta vänner,

00:05:23.765 --> 00:05:26.421
och så spreds det till dem,
vissa av dem gillade det,

00:05:26.421 --> 00:05:28.697
och de hade smarta vänner
och det spreds vidare,

00:05:28.697 --> 00:05:30.890
och så fortplanade det sig
genom nätverket

00:05:30.890 --> 00:05:33.359
till en samling smarta människor

00:05:33.359 --> 00:05:35.415
så till slut blev

00:05:35.415 --> 00:05:37.959
gillandet av curly fries-sidan

00:05:37.959 --> 00:05:39.734
en indikation på hög intelligens,

00:05:39.734 --> 00:05:41.377
inte på grund av innehållet,

00:05:41.377 --> 00:05:43.899
utan för att själva gillningen

00:05:43.899 --> 00:05:45.799
reflekterar vanliga attribut

00:05:45.799 --> 00:05:48.267
hos andra som har gjort det.

00:05:48.267 --> 00:05:51.164
Det är rätt komplicerade saker, eller hur?

00:05:51.164 --> 00:05:53.363
Det är svårt att sätta sig och förklara

00:05:53.363 --> 00:05:55.891
för en typisk användare,
och även om man gör det,

00:05:55.891 --> 00:05:57.211
vad kan den medelanvändaren

00:05:57.211 --> 00:05:58.509
göra åt det?

00:05:58.509 --> 00:06:00.447
Hur vet du att du gillat något

00:06:00.447 --> 00:06:01.939
som indikerar ett av dina drag

00:06:01.939 --> 00:06:05.484
som är helt irrelevant
för innehållet du gillar?

00:06:05.484 --> 00:06:08.030
Det finns mycket makt
som användaren inte har

00:06:08.030 --> 00:06:10.260
för att kontrollera hur datan används.

00:06:10.260 --> 00:06:13.372
Och jag ser det som
ett stort problem i framtiden.

00:06:13.372 --> 00:06:15.349
Jag tror det finns ett par vägar

00:06:15.349 --> 00:06:16.490
som borde kolla på

00:06:16.490 --> 00:06:18.260
om vi vill ge användarna kontroll

00:06:18.260 --> 00:06:20.000
över hur datan används,

00:06:20.000 --> 00:06:21.940
för det kommer inte alltid att användas

00:06:21.940 --> 00:06:23.321
till deras fördel.

00:06:23.321 --> 00:06:24.583
Ett exempel jag ofta ger

00:06:24.583 --> 00:06:27.139
är att om jag någonsin tröttnar på
att vara professor

00:06:27.139 --> 00:06:28.542
kommer jag starta ett företag

00:06:28.542 --> 00:06:29.966
som förutser alla attribut

00:06:29.966 --> 00:06:31.678
och saker som hur du jobbar i grupp

00:06:31.678 --> 00:06:33.849
och om du är drogmissbrukare
eller alkoholist.

00:06:33.849 --> 00:06:35.589
Vi vet hur vi ska förutse allt det.

00:06:35.589 --> 00:06:36.970
Och jag ska sälja rapporter

00:06:36.970 --> 00:06:39.070
till försäkringsbolag och storföretag

00:06:39.070 --> 00:06:40.999
som vill anställa dig.

00:06:41.343 --> 00:06:42.520
Vi kan göra det nu.

00:06:42.520 --> 00:06:44.308
Jag kan starta företaget imorgon,

00:06:44.308 --> 00:06:46.360
och du skulle inte ha någon kontroll

00:06:46.360 --> 00:06:48.498
över hur jag använder datan.

00:06:48.498 --> 00:06:50.790
Det verkar för mig vara ett stort problem.

00:06:50.790 --> 00:06:52.700
En av vägarna vi kan gå

00:06:52.700 --> 00:06:54.732
är politikens och lagens väg.

00:06:54.732 --> 00:06:57.898
I vissa avseenden tror jag
att det skulle vara det mest effektiva,

00:06:57.898 --> 00:07:00.534
men problemet är att vi faktiskt
skulle behöva göra det.

00:07:00.534 --> 00:07:03.314
Att se hur vår politiska process fungerar

00:07:03.314 --> 00:07:05.693
får mig att tro
att det är högst osannolikt

00:07:05.693 --> 00:07:07.390
att vi kommer få en massa folkvalda

00:07:07.390 --> 00:07:09.336
att sätta sig ner och lära sig om detta,

00:07:09.336 --> 00:07:11.382
och sedan få igenom avgörande förändringar

00:07:11.382 --> 00:07:13.539
på immaterialrättens lag i USA

00:07:13.539 --> 00:07:16.000
så att användarna får kontroll
över sin data.

00:07:16.000 --> 00:07:17.304
Vi kan gå politikens väg,

00:07:17.304 --> 00:07:19.113
där företag inom sociala medier säger

00:07:19.113 --> 00:07:20.635
"Vet du vad? Du äger din data.

00:07:20.645 --> 00:07:22.674
Du har kontroll över hur den används".

00:07:22.674 --> 00:07:24.522
Problemet är att intäktsmodellerna

00:07:24.522 --> 00:07:26.566
för flertalet företag inom sociala medier

00:07:26.566 --> 00:07:30.277
baserar sig på att dela eller utnyttja
användarnas data på något sätt.

00:07:30.277 --> 00:07:32.340
Det påstås ibland
om Facebook att användaren

00:07:32.340 --> 00:07:34.638
inte är kunden, utan de är varan.

00:07:34.638 --> 00:07:37.172
Hur får man ett företag

00:07:37.172 --> 00:07:39.910
att ge tillbaka kontrollen
över sin främsta tillgång

00:07:39.910 --> 00:07:41.159
till användarna?

00:07:41.159 --> 00:07:43.120
Det är möjligt, men jag tror inte att

00:07:43.120 --> 00:07:45.180
det kommer ändras särskilt snabbt.

00:07:45.180 --> 00:07:46.680
Jag tror att den andra vägen

00:07:46.680 --> 00:07:48.968
vi kan gå som är mer effektiv

00:07:48.968 --> 00:07:50.476
är en väg med mer vetenskap.

00:07:50.476 --> 00:07:52.986
Det är genom vetenskapen
som vi kan utveckla

00:07:52.986 --> 00:07:54.796
alla dessa mekanismer för beräkningar

00:07:54.796 --> 00:07:56.788
av personliga data från första början.

00:07:56.788 --> 00:08:00.294
Undersökningarna är faktiskt
väldigt lika de som vi måste göra

00:08:00.332 --> 00:08:02.718
om vi vill utveckla mekanismer

00:08:02.718 --> 00:08:04.139
som kan säga till användaren,

00:08:04.139 --> 00:08:06.718
"Det här är risken
med den handling du nyss begick".

00:08:06.718 --> 00:08:08.528
Genom att gilla den där Facebooksidan

00:08:08.528 --> 00:08:10.983
eller genom att dela en del
personlig information,

00:08:10.983 --> 00:08:13.025
har du förbättrat
min möjlighet att förutse

00:08:13.025 --> 00:08:14.621
om du använder droger eller inte

00:08:14.621 --> 00:08:17.533
eller om du kommer bra överens
med folk på jobbet eller inte.

00:08:17.533 --> 00:08:19.001
Det tror jag kan påverka

00:08:19.001 --> 00:08:20.791
om folk vill dela något,

00:08:20.791 --> 00:08:23.930
hålla det för sig själv, eller bara
vara offline helt och hållet.

00:08:23.930 --> 00:08:25.593
Vi kan också kika på saker som

00:08:25.593 --> 00:08:28.081
att låta folk kryptera uppladdade data,

00:08:28.081 --> 00:08:30.256
så det är osynligt och värdelöst

00:08:30.256 --> 00:08:31.607
för webbplatser som Facebook

00:08:31.607 --> 00:08:34.236
eller tredjepartstjänster
som använder det,

00:08:34.236 --> 00:08:38.413
men den utvalda personen
som valts av uppladdaren

00:08:38.413 --> 00:08:40.153
kommer att ha möjlighet att se det.

00:08:40.153 --> 00:08:42.319
Detta är superspännande forskning

00:08:42.319 --> 00:08:44.009
från ett intellektuellt perspektiv,

00:08:44.009 --> 00:08:45.798
och forskare kommer vilja göra det.

00:08:45.798 --> 00:08:49.408
Det ger oss ett övertag över lagsidan.

00:08:49.408 --> 00:08:51.133
Ett av problemen som folk tar upp

00:08:51.133 --> 00:08:52.758
när jag pratar om detta är,

00:08:52.758 --> 00:08:55.374
"Du vet, om folk börjar hålla
all data privat, så kommer

00:08:55.374 --> 00:08:57.487
alla metoder som du utvecklat

00:08:57.487 --> 00:09:00.140
som förutser deras karaktärsdrag
att misslyckas."

00:09:00.140 --> 00:09:03.660
Då säger jag "Absolut,
och för mig är det en succé",

00:09:03.660 --> 00:09:05.446
för som forskare

00:09:05.446 --> 00:09:09.134
är mitt mål inte att få tag på
information om användarna,

00:09:09.134 --> 00:09:11.901
utan att förbättra interaktionen
mellan folk online.

00:09:11.901 --> 00:09:15.119
Och ibland innebär det
att dra slutsatser om dem,

00:09:15.119 --> 00:09:18.261
men om användare inte vill ge mig
tillgång till den informationen,

00:09:18.271 --> 00:09:20.239
tycker jag att de har rätt att göra det.

00:09:20.239 --> 00:09:23.070
Jag vill att användare ska vara
informerade och samtyckande

00:09:23.070 --> 00:09:25.022
användare av verktygen som vi utvecklar.

00:09:25.022 --> 00:09:27.974
Och jag tycker att vi
genom att uppmuntra denna sorts vetenskap

00:09:27.974 --> 00:09:29.240
och att stötta forskare

00:09:29.240 --> 00:09:32.263
som vill ge tillbaka kontrollen
till användarna

00:09:32.263 --> 00:09:34.574
från företagen inom sociala medier

00:09:34.574 --> 00:09:37.245
betyder att vi går framåt
när dessa verktyg utvecklas

00:09:37.245 --> 00:09:38.721
och går framåt,

00:09:38.721 --> 00:09:40.225
och vi kommer få en utbildad

00:09:40.225 --> 00:09:41.809
och kraftfull användarbas,

00:09:41.809 --> 00:09:45.619
och jag tror vi är överens om
att det är rätt väg att gå framåt.

00:09:45.643 --> 00:09:47.131
Tack.

00:09:47.131 --> 00:09:50.109
(Applåder)

