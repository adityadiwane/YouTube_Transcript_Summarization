WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Dick Stada
Nagekeken door: Kevin Deamandel

00:00:12.738 --> 00:00:14.895
De eerste tien jaar was internet

00:00:14.895 --> 00:00:16.990
een nogal statische plek.

00:00:16.990 --> 00:00:19.235
Je kon online gaan 
en pagina's bekijken

00:00:19.235 --> 00:00:20.918
die erop gezet waren

00:00:20.918 --> 00:00:23.269
door organisaties,
waar teams dat deden,

00:00:23.269 --> 00:00:25.498
of door mensen die voor die tijd

00:00:25.498 --> 00:00:27.235
technisch onderlegd waren.

00:00:27.235 --> 00:00:28.810
Met de groei van sociale media

00:00:28.810 --> 00:00:31.659
en sociale netwerken
in de beginjaren 2000,

00:00:31.659 --> 00:00:33.358
veranderde het internet volkomen

00:00:33.358 --> 00:00:36.966
tot een plek waar nu
de meeste inhoud van het internet

00:00:36.966 --> 00:00:40.278
door gemiddelde gebruikers
wordt geleverd.

00:00:40.278 --> 00:00:42.975
Zij het in YouTube-video's of weblogs

00:00:42.975 --> 00:00:46.290
of productbesprekingen
of in sociale media.

00:00:46.290 --> 00:00:48.637
Het wordt ook 
een steeds interactievere plek,

00:00:48.637 --> 00:00:51.274
waar mensen interactief zijn met elkaar.

00:00:51.274 --> 00:00:52.970
Ze geven commentaar en delen,

00:00:52.970 --> 00:00:54.584
ze lezen niet alleen maar.

00:00:54.584 --> 00:00:56.450
Facebook is er niet de enige plek voor,

00:00:56.450 --> 00:00:57.548
maar wel de grootste.

00:00:57.548 --> 00:00:59.332
De cijfers spreken boekdelen.

00:00:59.332 --> 00:01:02.809
Facebook heeft 1,2 miljard
gebruikers per maand.

00:01:02.809 --> 00:01:06.389
Dus de helft van alle internetgebruikers
gebruikt Facebook.

00:01:06.392 --> 00:01:08.764
Op deze website, net als op andere,

00:01:08.764 --> 00:01:11.173
kunnen mensen 
zonder veel technische kennis

00:01:11.173 --> 00:01:13.325
een online persona creëren.

00:01:13.325 --> 00:01:14.771
Men reageerde daarop

00:01:14.771 --> 00:01:17.784
door enorm veel persoonlijke gegevens
online te zetten.

00:01:17.784 --> 00:01:21.057
Het gevolg is dat we gedrag, voorkeuren

00:01:21.057 --> 00:01:22.313
en demografische gegevens

00:01:22.313 --> 00:01:24.414
van honderden miljoenen mensen kennen,

00:01:24.414 --> 00:01:26.440
wat ongeëvenaard is in de geschiedenis.

00:01:26.440 --> 00:01:29.834
Als computerwetenschapper 
kan ik daardoor modellen maken

00:01:29.834 --> 00:01:33.226
die allerlei verborgen kenmerken
over je kunnen voorspellen

00:01:33.226 --> 00:01:35.600
waarvan jullie zelf niet eens weten

00:01:35.600 --> 00:01:37.472
dat je er informatie over deelt.

00:01:37.472 --> 00:01:39.484
Als wetenschappers
gebruiken we dat

00:01:39.484 --> 00:01:41.968
om mensen te helpen
bij hun online gedrag.

00:01:41.968 --> 00:01:44.467
Maar er zijn ook minder
menslievende toepassingen.

00:01:44.467 --> 00:01:46.848
Het probleem is dat gebruikers

00:01:46.848 --> 00:01:49.318
de werking van deze technieken 
niet goed snappen.

00:01:49.318 --> 00:01:52.446
Zelfs dan nog hebben ze er
niet veel controle over.

00:01:52.446 --> 00:01:54.636
Ik heb het vandaag over dingen

00:01:54.636 --> 00:01:56.638
die we kunnen doen

00:01:56.638 --> 00:01:59.401
om te begrijpen hoe we
vooruit kunnen gaan

00:01:59.401 --> 00:02:02.000
en die controle kunnen
teruggeven aan de gebruiker.

00:02:02.000 --> 00:02:03.576
Dit is Target, het bedrijf.

00:02:03.576 --> 00:02:05.810
Ik heb dat logo niet zomaar 
op de buik gedaan

00:02:05.810 --> 00:02:07.250
van deze arme zwangere vrouw.

00:02:07.250 --> 00:02:09.090
Misschien heb je het verhaal gelezen

00:02:09.090 --> 00:02:11.411
in het tijdschrift Forbes 
over Target, die

00:02:11.411 --> 00:02:13.612
een folder stuurde
naar een 15-jarig meisje

00:02:13.612 --> 00:02:15.482
met advertenties en tegoedbonnen

00:02:15.482 --> 00:02:17.776
voor babyflesjes en luiers en bedjes,

00:02:17.776 --> 00:02:19.890
twee weken voor ze
haar ouders vertelde

00:02:19.890 --> 00:02:21.324
dat ze zwanger was.

00:02:21.324 --> 00:02:24.028
Tja, de vader was nogal overstuur.

00:02:24.028 --> 00:02:25.634
Hij zei: "Hoe weet Target

00:02:25.634 --> 00:02:27.568
dat dit schoolkind zwanger was

00:02:27.568 --> 00:02:29.528
voordat ze het haar ouders vertelde?"

00:02:29.528 --> 00:02:32.389
Het bleek dat ze koopgegevens hebben

00:02:32.389 --> 00:02:34.450
van honderdduizenden klanten.

00:02:34.450 --> 00:02:37.180
Ze berekenen wat ze noemen
een zwangerschaps-score.

00:02:37.180 --> 00:02:39.382
Niet óf een vrouw zwanger is

00:02:39.382 --> 00:02:41.242
maar wanneer ze uitgeteld is.

00:02:41.242 --> 00:02:42.546
Ze berekenden dat niet

00:02:42.546 --> 00:02:44.364
aan de hand van bekende dingen

00:02:44.364 --> 00:02:46.906
zoals het kopen van 
een bedje of kleertjes,

00:02:46.906 --> 00:02:51.489
maar omdat ze bijvoorbeeld
meer vitaminen kocht dan normaal,

00:02:51.489 --> 00:02:52.950
of ze kocht een handtas

00:02:52.950 --> 00:02:54.841
die groot genoeg is voor luiers.

00:02:54.841 --> 00:02:57.910
En elk op zichzelf 
onthult dat niet veel

00:02:57.910 --> 00:03:01.018
maar als je deze gedragspatronen

00:03:01.018 --> 00:03:03.825
bij duizenden mensen bekijkt,

00:03:03.825 --> 00:03:06.892
geeft dit daadwerkelijk 
bepaalde inzichten.

00:03:06.892 --> 00:03:08.685
Dat zijn we aan het doen

00:03:08.685 --> 00:03:11.252
als we dingen voorspellen
over jou en sociale media.

00:03:11.252 --> 00:03:14.048
We kijken naar subtiele 
gedragspatronen die,

00:03:14.048 --> 00:03:16.730
als je dat ziet bij miljoenen mensen,

00:03:16.730 --> 00:03:19.436
allerlei dingen onthullen.

00:03:19.436 --> 00:03:21.183
In mijn lab met mijn collega's,

00:03:21.183 --> 00:03:24.520
hebben we bedacht hoe we dingen
aardig kunnen voorspellen

00:03:24.520 --> 00:03:26.245
zoals je politieke voorkeur,

00:03:26.245 --> 00:03:29.997
je persoonlijkheid, aard,
seksuele voorkeur,

00:03:29.997 --> 00:03:32.870
geloof, leeftijd, intelligentie,

00:03:32.870 --> 00:03:34.264
en nog veel meer:

00:03:34.264 --> 00:03:36.201
in hoeverre je je kennissen vertrouwt

00:03:36.201 --> 00:03:38.005
en hoe sterk je relatie met hen is.

00:03:38.005 --> 00:03:39.790
We kunnen dat behoorlijk goed.

00:03:39.790 --> 00:03:41.987
Het komt niet van wat je zou denken,

00:03:41.987 --> 00:03:44.089
uit voor de hand liggende informatie.

00:03:44.089 --> 00:03:46.370
Mijn favoriete voorbeeld
is van een onderzoek

00:03:46.370 --> 00:03:47.610
dat dit jaar stond

00:03:47.610 --> 00:03:49.405
in het tijdschrift PNAS.

00:03:49.405 --> 00:03:50.690
Googel maar eens.

00:03:50.690 --> 00:03:52.562
Vier pagina's, goed leesbaar.

00:03:52.562 --> 00:03:55.565
Ze keken alleen
naar de 'likes' op Facebook.

00:03:55.565 --> 00:03:57.625
Dus: dingen die je
leuk vindt op Facebook.

00:03:57.625 --> 00:03:59.943
Ze gebruikten dat
om die kenmerken te voorspellen

00:03:59.943 --> 00:04:01.528
en nog wat andere dingen.

00:04:01.528 --> 00:04:04.229
In hun scriptie noemden ze de vijf 'likes'

00:04:04.229 --> 00:04:07.016
die het sterkst wezen
op een hoge intelligentie.

00:04:07.016 --> 00:04:09.420
Daartussen stond ook het 'liken'

00:04:09.420 --> 00:04:11.245
van krulfriet. 
(Gelach)

00:04:11.245 --> 00:04:13.338
Krulfriet is heerlijk,

00:04:13.338 --> 00:04:15.868
maar ervan houden
betekent niet per se

00:04:15.868 --> 00:04:17.948
dat je slimmer bent dan gemiddeld.

00:04:17.948 --> 00:04:21.155
Hoe kan het dan dat
een van de sterkste aanwijzingen

00:04:21.155 --> 00:04:22.725
over je intelligentie

00:04:22.725 --> 00:04:24.172
het 'liken' van deze pagina is

00:04:24.172 --> 00:04:26.424
als de inhoud totaal los staat

00:04:26.424 --> 00:04:28.951
van het kenmerk dat voorspeld wordt?

00:04:28.951 --> 00:04:30.535
Het blijkt dat we moeten kijken

00:04:30.535 --> 00:04:32.153
naar onderliggende theorieën

00:04:32.153 --> 00:04:34.722
om te zien hoe we dat kunnen doen.

00:04:34.722 --> 00:04:37.635
Een ervan is een sociologische theorie
die homofilie heet.

00:04:37.635 --> 00:04:40.727
Je bent bevriend
met mensen zoals jezelf.

00:04:40.727 --> 00:04:42.741
Slimme mensen
hebben slimme vrienden.

00:04:42.741 --> 00:04:45.371
Als je jong bent 
heb je jonge vrienden.

00:04:45.371 --> 00:04:48.738
Dat is al eeuwen ingeburgerd.

00:04:48.738 --> 00:04:49.975
We weten ook veel over

00:04:49.975 --> 00:04:52.525
hoe informatie wordt verspreid
in netwerken.

00:04:52.525 --> 00:04:54.199
Het blijkt dat virale video's

00:04:54.199 --> 00:04:56.585
of likes op Facebook en andere informatie

00:04:56.585 --> 00:04:58.913
zich op precies dezelfde 
manier verspreiden

00:04:58.913 --> 00:05:00.847
als ziektes in een sociaal netwerk.

00:05:00.847 --> 00:05:02.608
Dat hebben we lang bestudeerd.

00:05:02.608 --> 00:05:04.394
We hebben er goede modellen voor.

00:05:04.394 --> 00:05:06.551
Je kan die dingen dus naast elkaar zetten

00:05:06.551 --> 00:05:09.539
en zien waarom zulke dingen gebeuren.

00:05:09.539 --> 00:05:12.703
Mijn hypothese is 
dat een slim iemand

00:05:12.703 --> 00:05:14.270
deze pagina is begonnen,

00:05:14.270 --> 00:05:16.749
of dat één van de eersten 
die het 'liketen'

00:05:16.749 --> 00:05:18.355
hoog scoorde in die test.

00:05:18.355 --> 00:05:20.643
Zij 'liketen' het 
en hun vrienden zagen dat,

00:05:20.643 --> 00:05:23.765
en door homofilie weten we
dat hij slimme vrienden zal hebben.

00:05:23.765 --> 00:05:26.821
Zo kregen zij het te zien
en sommigen 'liketen' het

00:05:26.821 --> 00:05:28.830
en zo kwam het bij hún slimme vrienden,

00:05:28.830 --> 00:05:30.790
en verspreidde zich 
via dit netwerk

00:05:30.790 --> 00:05:33.359
naar heel veel slimme mensen

00:05:33.359 --> 00:05:35.415
zodat aan het einde

00:05:35.415 --> 00:05:37.959
het 'liken' van de krulfriet-pagina

00:05:37.959 --> 00:05:39.574
intelligentie impliceert.

00:05:39.574 --> 00:05:41.377
Niet vanwege de inhoud

00:05:41.377 --> 00:05:43.899
maar omdat de handeling van het 'liken'

00:05:43.899 --> 00:05:45.799
de bekende eigenschappen teruggeeft

00:05:45.799 --> 00:05:48.267
van anderen die dat hebben gedaan.

00:05:48.267 --> 00:05:51.164
Dat is nogal ingewikkeld hè?

00:05:51.164 --> 00:05:53.363
Het is moeilijk uit te leggen

00:05:53.363 --> 00:05:56.211
aan de gemiddelde gebruiker,
en al leg je het uit,

00:05:56.211 --> 00:05:58.399
wat kan die gemiddelde gebruiker
eraan doen?

00:05:58.399 --> 00:06:00.447
Hoe weet je dat een 'like'

00:06:00.447 --> 00:06:01.939
iets impliceert over jou,

00:06:01.939 --> 00:06:05.484
dat helemaal los staat
van de inhoud die je 'liket'?

00:06:05.484 --> 00:06:08.030
Er is veel macht
die gebruikers niet hebben

00:06:08.030 --> 00:06:10.350
om te bepalen
hoe de gegevens worden gebruikt.

00:06:10.350 --> 00:06:13.372
Ik zie dat als een probleem
dat steeds groter wordt.

00:06:13.372 --> 00:06:16.349
Ik denk dat we een aantal 
richtingen op kunnen

00:06:16.350 --> 00:06:18.260
als we de gebruikers
willen laten bepalen

00:06:18.260 --> 00:06:20.000
hoe die gegevens worden gebruikt,

00:06:20.000 --> 00:06:23.320
want het wordt niet altijd
in hun voordeel gebruikt.

00:06:23.321 --> 00:06:26.373
Ik zeg vaak:
als professor zijn me gaat vervelen,

00:06:26.389 --> 00:06:28.042
ga ik een bedrijf beginnen

00:06:28.042 --> 00:06:29.696
dat eigenschappen voorspelt.

00:06:29.696 --> 00:06:31.268
Dingen als teamwork

00:06:31.268 --> 00:06:33.769
en of drugs gebruikt,
of je alcoholist bent.

00:06:33.769 --> 00:06:35.209
We weten hoe je dat voorspelt.

00:06:35.209 --> 00:06:36.970
Ik ga verslagen verkopen

00:06:36.970 --> 00:06:39.160
aan HR-firma's en grote ondernemingen

00:06:39.160 --> 00:06:41.053
die je willen inhuren.

00:06:41.053 --> 00:06:42.520
We kunnen dat allemaal al.

00:06:42.520 --> 00:06:44.308
Ik kan dat bedrijf morgen beginnen

00:06:44.308 --> 00:06:46.510
en jij zou niet kunnen voorkomen

00:06:46.510 --> 00:06:48.498
dat ik jouw gegevens zo gebruik.

00:06:48.498 --> 00:06:50.576
Dat lijkt me wel een probleem.

00:06:50.576 --> 00:06:52.324
Eén mogelijkheid is

00:06:52.324 --> 00:06:54.732
dat we ons richten 
op beleid en wetgeving.

00:06:54.732 --> 00:06:57.658
In sommige opzichten zou dat 
het effectiefst zijn

00:06:57.658 --> 00:07:00.534
maar het probleem is
om het daadwerkelijk te doen.

00:07:00.534 --> 00:07:03.314
Als ik kijk naar de politiek

00:07:03.314 --> 00:07:05.693
dan lijkt me het niet waarschijnlijk

00:07:05.693 --> 00:07:07.290
dat we vertegenwoordigers krijgen

00:07:07.290 --> 00:07:09.276
die zich hier 
grondig over informeren

00:07:09.276 --> 00:07:13.269
en dan het intellectueel eigendomsrecht
ingrijpend gaan veranderen,

00:07:13.269 --> 00:07:15.770
zodat gebruikers controle krijgen
over hun gegevens.

00:07:15.770 --> 00:07:17.675
Je kan het beleidsmatig doen,

00:07:17.675 --> 00:07:19.370
als sociale mediabedrijven

00:07:19.370 --> 00:07:22.154
jou volledige controle geven 
over je gegevens.

00:07:22.154 --> 00:07:26.242
Maar de verdienmodellen
van de meeste sociale mediabedrijven

00:07:26.246 --> 00:07:30.277
berusten op het delen of uitbaten
van de gebruikersgegevens.

00:07:30.277 --> 00:07:34.640
Ze zeggen van Facebook dat de gebruikers
niet de klant zijn, maar het product.

00:07:34.640 --> 00:07:37.352
Hoe krijg je dan een bedrijf zover

00:07:37.352 --> 00:07:39.910
dat ze de macht
over hun belangrijkste troef

00:07:39.910 --> 00:07:41.159
teruggeven aan de klant?

00:07:41.159 --> 00:07:42.860
Het is mogelijk, maar ik denk niet

00:07:42.860 --> 00:07:45.180
dat we dat snel 
zullen zien veranderen.

00:07:45.180 --> 00:07:48.278
Ik denk dat het op 
een effectievere manier kan

00:07:48.278 --> 00:07:50.476
door middel van 
meer wetenschap.

00:07:50.476 --> 00:07:52.376
Door wetenschap te bedrijven

00:07:52.376 --> 00:07:54.736
konden we de
mechanismes ontwikkelen

00:07:54.736 --> 00:07:56.788
om persoonlijke gegevens te berekenen.

00:07:56.788 --> 00:07:58.894
Dat is bijna hetzelfde onderzoek

00:07:58.894 --> 00:08:00.332
dat we zouden moeten doen

00:08:00.332 --> 00:08:02.718
als we mechanismes willen ontwikkelen

00:08:02.718 --> 00:08:04.139
die een gebruiker zeggen:

00:08:04.139 --> 00:08:06.368
"Dit is het risico
van wat je zojuist deed."

00:08:06.368 --> 00:08:08.598
Doordat jij deze Facebook-pagina 'liket',

00:08:08.598 --> 00:08:10.983
of deze persoonlijke informatie deelt,

00:08:10.983 --> 00:08:12.705
kan ik nu beter voorspellen

00:08:12.705 --> 00:08:14.571
of je drugs gebruikt

00:08:14.571 --> 00:08:17.433
en of je populair bent op je werk.

00:08:17.433 --> 00:08:19.701
Dat kan volgens mij 
beïnvloeden of mensen

00:08:19.701 --> 00:08:21.551
wel of niet iets willen delen,

00:08:21.551 --> 00:08:24.030
het afgeschermd houden
of het offline houden.

00:08:24.030 --> 00:08:25.593
Ook zouden we mensen

00:08:25.593 --> 00:08:28.321
in staat kunnen stellen
hun geüploade data te versleutelen

00:08:28.321 --> 00:08:30.426
zodat die onzichtbaar
en waardeloos wordt

00:08:30.426 --> 00:08:31.607
voor sites als Facebook

00:08:31.607 --> 00:08:34.236
of derde partijen die erbij kunnen.

00:08:34.236 --> 00:08:37.483
Dan bepaalt degene
die het gepost heeft

00:08:37.483 --> 00:08:40.153
welke gebruikers toegang hebben.

00:08:40.153 --> 00:08:42.379
Dat is allemaal erg spannend onderzoek

00:08:42.379 --> 00:08:43.939
vanuit intellectueel oogpunt,

00:08:43.939 --> 00:08:45.798
dus doen wetenschappers het graag.

00:08:45.798 --> 00:08:49.238
Dat geeft ons een voordeel
ten opzichte van de juridische optie.

00:08:49.238 --> 00:08:51.133
Een probleem dat mensen aandragen

00:08:51.133 --> 00:08:52.728
als ik hierover praat is:

00:08:52.728 --> 00:08:55.374
"Als mensen die gegevens
voor zichzelf houden,

00:08:55.374 --> 00:08:57.057
werken al jouw methodes

00:08:57.057 --> 00:09:00.140
om hun eigenschappen 
te voorspellen niet meer."

00:09:00.140 --> 00:09:03.660
Ik zeg dan: "Jazeker, 
en dat noem ik succes,

00:09:03.660 --> 00:09:05.446
want als wetenschapper

00:09:05.446 --> 00:09:09.134
is mijn doel niet om informatie 
over gebruikers te krijgen,

00:09:09.134 --> 00:09:11.901
maar om de interactie 
online te verbeteren.

00:09:11.901 --> 00:09:15.119
Soms houdt dat in dat
je gegevens van hen achterhaalt,

00:09:15.119 --> 00:09:18.141
maar als gebruikers
niet willen dat ik die gebruik,

00:09:18.141 --> 00:09:20.179
moeten ze dat recht hebben.

00:09:20.179 --> 00:09:22.350
Ik wil dat gebruikers geïnformeerd zijn

00:09:22.350 --> 00:09:24.942
en instemmen met de tools 
die we maken.

00:09:24.942 --> 00:09:27.774
Deze manier van wetenschap aanmoedigen

00:09:27.774 --> 00:09:29.410
en onderzoekers ondersteunen

00:09:29.410 --> 00:09:32.583
die wat zeggenschap
teruggeven aan de gebruikers

00:09:32.583 --> 00:09:34.915
ten koste van de 
sociale mediabedrijven,

00:09:34.915 --> 00:09:38.155
betekent dat we met de 
verbeteringen van deze tools

00:09:38.155 --> 00:09:41.909
ook beter onderlegde gebruikers
met betere middelen krijgen.

00:09:41.909 --> 00:09:44.089
Ik denk dat we dat allemaal

00:09:44.089 --> 00:09:46.133
een vrij ideale weg
voorwaarts vinden.

00:09:46.133 --> 00:09:47.677
Dank je wel.

00:09:47.677 --> 00:09:50.757
(Applaus)

