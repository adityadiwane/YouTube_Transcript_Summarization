WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Rik Delaet
Nagekeken door: Peter van de Ven

00:00:13.201 --> 00:00:16.827
Charlie Rose: Larry stuurde me een e-mail

00:00:16.827 --> 00:00:18.814
waarin hij in feite zei

00:00:18.814 --> 00:00:22.543
dat we ervoor moesten zorgen 
dat we er niet uitzagen

00:00:22.543 --> 00:00:27.034
als een paar saaie mannen 
van middelbare leeftijd.

00:00:27.034 --> 00:00:30.076
Ik zei dat ik me er gevleid door voelde,

00:00:30.076 --> 00:00:32.448
(Gelach)

00:00:32.448 --> 00:00:35.963
want ik ben een beetje ouder

00:00:35.963 --> 00:00:40.114
en hij heeft een beetje 
meer centen dan ik.

00:00:40.114 --> 00:00:42.713
Larry Page: Nou, dank je.

00:00:42.713 --> 00:00:45.693
CR: We gaan een gesprek hebben

00:00:45.693 --> 00:00:48.391
over het internet, over Google

00:00:48.391 --> 00:00:49.825
en over zoekopdrachten

00:00:49.825 --> 00:00:51.192
en privacy,

00:00:51.192 --> 00:00:52.747
en ook over je filosofie,

00:00:52.747 --> 00:00:55.203
over hoe je de punten hebt verbonden

00:00:55.203 --> 00:00:58.564
en dat de reis die je
een tijdje geleden begon

00:00:58.578 --> 00:01:00.473
zulke interessante perspectieven heeft.

00:01:00.473 --> 00:01:03.069
Vooral willen we praten over de toekomst.

00:01:03.069 --> 00:01:05.208
Vandaar mijn eerste vraag: 
waar is Google nu

00:01:05.208 --> 00:01:06.704
en waar gaat het naartoe?

00:01:06.704 --> 00:01:08.813
LP: Hier denken we vaak en veel over

00:01:08.813 --> 00:01:11.738
en onze missie die we 
lange tijd geleden definieerden

00:01:11.738 --> 00:01:14.001
is om alle informatie 
ter wereld te organiseren

00:01:14.001 --> 00:01:17.439
en ze universeel toegankelijk 
en bruikbaar te maken.

00:01:17.439 --> 00:01:19.481
Mensen zeggen altijd:

00:01:19.481 --> 00:01:21.696
"Zijn jullie daar echt
nog steeds mee bezig?"

00:01:21.696 --> 00:01:23.814
Ik denk daar ook vaak over

00:01:23.814 --> 00:01:26.010
en ik ben er zelf niet helemaal uit.

00:01:26.010 --> 00:01:30.017
Maar als ik nadenk over de zoekfunctie,

00:01:30.017 --> 00:01:32.633
dat is voor ons allen zo'n ernstige zaak,

00:01:32.633 --> 00:01:34.876
om echt te begrijpen wat je wilt,

00:01:34.876 --> 00:01:37.244
om de informatie 
van de wereld te begrijpen,

00:01:37.244 --> 00:01:40.776
daarin staan we nog steeds 
helemaal aan het begin,

00:01:40.776 --> 00:01:42.589
wat eigenlijk toch te gek is.

00:01:42.589 --> 00:01:45.107
We zijn er al al 15 jaar mee bezig,

00:01:45.107 --> 00:01:48.682
maar het is helemaal nog niet gedaan.

00:01:48.682 --> 00:01:51.358
CR: Hoe zal het zijn als het klaar is?

00:01:51.358 --> 00:01:54.075
LP: Nou, ik denk dat,

00:01:54.075 --> 00:01:56.475
denkend over waar we naartoe gaan --

00:01:56.475 --> 00:01:58.522
waarom het niet nog niet klaar is? --

00:01:58.522 --> 00:02:01.198
een heleboel komt gewoon neer 
op een hoop computerwerk.

00:02:01.198 --> 00:02:03.001
Je computer weet niet waar je bent,

00:02:03.001 --> 00:02:05.036
weet niet wat je doet,

00:02:05.036 --> 00:02:06.718
weet niet wat je weet,

00:02:06.718 --> 00:02:09.294
en veel van waarmee we bezig waren,

00:02:09.294 --> 00:02:12.589
komt erop neer 
je apparaten te doen werken,

00:02:12.589 --> 00:02:14.930
ze je context te doen begrijpen.

00:02:14.930 --> 00:02:16.933
Google Now, weet waar je bent,

00:02:16.933 --> 00:02:19.115
weet wat je nodig hebt.

00:02:19.115 --> 00:02:23.223
Maar computers jou laten begrijpen

00:02:23.223 --> 00:02:25.279
en die informatie laten begrijpen,

00:02:25.279 --> 00:02:27.589
dat hebben we echt nog niet gedaan.

00:02:27.589 --> 00:02:29.138
Het is nog steeds heel onhandig.

00:02:29.138 --> 00:02:31.504
CR: Als je kijkt naar wat Google doet,

00:02:31.504 --> 00:02:34.473
hoe past Deep Mind daarin?

00:02:34.473 --> 00:02:36.057
LP: Deep Mind is een bedrijf

00:02:36.057 --> 00:02:38.588
dat we onlangs overnamen.

00:02:38.588 --> 00:02:41.670
Het is in het Verenigd Koninkrijk.

00:02:41.670 --> 00:02:44.324
Ik vertel eerst hoe we ertoe kwamen.

00:02:44.324 --> 00:02:46.552
Het had te maken met de zoekfunctie

00:02:46.552 --> 00:02:48.175
en het echt begrijpen ervan,

00:02:48.175 --> 00:02:50.408
proberen om alles te begrijpen

00:02:50.408 --> 00:02:52.213
en ook de computers handiger maken,

00:02:52.213 --> 00:02:54.214
zodat ze je echt begrijpen --

00:02:54.214 --> 00:02:56.326
stemherkenning was echt belangrijk.

00:02:56.326 --> 00:02:59.187
Wat is nu de stand van zaken 
qua spraakherkenning?

00:02:59.187 --> 00:03:00.847
Niet erg goed.

00:03:00.847 --> 00:03:02.913
Het begrijpt je eigenlijk niet.

00:03:02.913 --> 00:03:05.506
Daarom begonnen we 
met onderzoek naar machinaal leren

00:03:05.506 --> 00:03:06.793
om dat te verbeteren.

00:03:06.793 --> 00:03:08.156
Dat hielp veel.

00:03:08.156 --> 00:03:10.523
We begonnen met zaken als YouTube.

00:03:10.523 --> 00:03:12.491
Kunnen we YouTube begrijpen?

00:03:12.491 --> 00:03:15.177
We pasten machinaal leren toe op YouTube

00:03:15.177 --> 00:03:19.262
en het ontdekte katten, uit zichzelf.

00:03:19.262 --> 00:03:21.353
Dat een belangrijk concept.

00:03:21.353 --> 00:03:24.344
En we beseften dat er echt iets in zat.

00:03:24.344 --> 00:03:26.461
Als we kunnen leren wat katten zijn,

00:03:26.461 --> 00:03:28.536
moet dat echt belangrijk zijn.

00:03:28.536 --> 00:03:31.165
Ik denk dat Deep Mind--

00:03:31.165 --> 00:03:33.529
wat echt geweldig is aan Deep Mind

00:03:33.529 --> 00:03:35.533
is dat het echt

00:03:35.533 --> 00:03:39.090
dingen op zichzelf kan leren.

00:03:39.090 --> 00:03:41.657
Ze begonnen met videogames,

00:03:41.657 --> 00:03:44.720
misschien kan ik de video laten zien,

00:03:44.720 --> 00:03:46.354
gewoon met videogames te spelen

00:03:46.354 --> 00:03:48.369
en leren hoe je dat automatisch kan doen.

00:03:48.369 --> 00:03:50.221
CR: Kijk eens naar de videogames

00:03:50.221 --> 00:03:52.631
en hoe machines in staat kunnen zijn

00:03:52.631 --> 00:03:55.087
om een aantal opmerkelijke dingen te doen.

00:03:55.087 --> 00:03:56.786
LP: Het verbazingwekkende hiervan

00:03:56.786 --> 00:03:58.096
is nogal duidelijk.

00:03:58.096 --> 00:03:59.570
Dit zijn oude games,

00:03:59.570 --> 00:04:04.368
maar het systeem ziet precies 
wat jij ziet, de pixels,

00:04:04.368 --> 00:04:06.799
het heeft de besturing 
en het heeft de score,

00:04:06.799 --> 00:04:09.010
en het heeft al deze games leren spelen,

00:04:09.010 --> 00:04:10.589
hetzelfde programma.

00:04:10.589 --> 00:04:12.626
Het heeft al deze games leren spelen,

00:04:12.626 --> 00:04:14.412
maar met bovenmenselijke prestaties.

00:04:14.412 --> 00:04:16.387
We zijn tot nu toe niet in staat geweest

00:04:16.387 --> 00:04:18.535
om computers dit soort
dingen te laten doen.

00:04:18.535 --> 00:04:20.080
Dit vertel ik nog even snel.

00:04:20.080 --> 00:04:22.885
Dit is boksen en het komt erachter

00:04:22.885 --> 00:04:25.519
dat het de tegenstander kan vastzetten.

00:04:25.519 --> 00:04:27.258
De computer is aan de linkerkant

00:04:27.258 --> 00:04:30.343
en hij is gewoon punten aan het scoren.

00:04:30.343 --> 00:04:32.429
Stel je voor dat dit soort intelligentie

00:04:32.429 --> 00:04:34.556
zich zou bezig houden met je planning,

00:04:34.556 --> 00:04:39.193
je informatiebehoeften 
of dat soort dingen.

00:04:39.193 --> 00:04:41.811
We staan nog maar aan het begin hiervan

00:04:41.811 --> 00:04:44.176
en daar ben ik echt enthousiast over.

00:04:44.176 --> 00:04:46.646
CR: Als je kijkt naar wat er gebeurd is

00:04:46.646 --> 00:04:49.230
met Deep Mind en het boksen,

00:04:49.230 --> 00:04:53.750
dan maakt kunstmatige intelligentie
ook deel uit van waar we naartoe gaan

00:04:54.459 --> 00:04:57.258
Waar staan we dan, 
als je hiernaar kijkt?

00:04:57.258 --> 00:04:58.813
LP: Ik denk dat dit

00:04:58.813 --> 00:05:00.546
een van de meest spannende dingen is

00:05:00.546 --> 00:05:02.458
die ik in lange tijd heb gezien.

00:05:02.458 --> 00:05:04.871
De man die het bedrijf Demis opstartte,

00:05:04.871 --> 00:05:07.649
heeft neurowetenschappen 
en computerwetenschap gestudeerd.

00:05:07.649 --> 00:05:09.279
Hij ging terug naar school

00:05:09.279 --> 00:05:12.405
voor zijn Ph.D. in hersenstudies.

00:05:12.405 --> 00:05:15.025
We zien een heleboel spannend werk

00:05:15.025 --> 00:05:18.106
in het overlappingsgebied van informatica

00:05:18.106 --> 00:05:19.856
en neurowetenschappen,

00:05:19.856 --> 00:05:22.181
in termen van echt begrijpen

00:05:22.181 --> 00:05:24.635
van wat er nodig is om iets slim te maken

00:05:24.635 --> 00:05:26.350
en echt interessante dingen doen.

00:05:26.350 --> 00:05:28.488
CR: Maar waar staan we nu?

00:05:28.488 --> 00:05:31.194
En hoe snel denk je dat we vooruitgaan?

00:05:31.194 --> 00:05:34.463
LP: Dit is de stand 
van de techniek op dit moment,

00:05:34.463 --> 00:05:37.217
het begrijpen van katten op YouTube

00:05:37.217 --> 00:05:40.024
en dingen zoals het verbeteren
van spraakherkenning.

00:05:40.024 --> 00:05:42.442
We gebruikten veel machinaal leren

00:05:42.442 --> 00:05:44.921
om dingen stap voor stap te verbeteren,

00:05:44.921 --> 00:05:48.315
maar voor mij 
is dit voorbeeld echt spannend,

00:05:48.315 --> 00:05:49.558
want het is één programma

00:05:49.558 --> 00:05:52.382
dat een heleboel 
verschillende dingen kan doen.

00:05:52.382 --> 00:05:53.900
CR: Ik weet niet of het gaat,

00:05:53.900 --> 00:05:55.645
maar het beeld van 'de kat'.

00:05:55.645 --> 00:05:57.289
Prachtig om te zien.

00:05:57.289 --> 00:05:59.158
Dit is hoe machines naar katten keken

00:05:59.158 --> 00:06:00.303
en wat ze eruit haalden.

00:06:00.303 --> 00:06:01.358
Kunnen we het zien?

00:06:02.398 --> 00:06:03.760
LP: Ja. 
CR: Zie je de kat?

00:06:03.770 --> 00:06:05.967
Ontworpen en gezien door machines.

00:06:05.967 --> 00:06:06.897
LP: Dat klopt.

00:06:06.897 --> 00:06:09.564
Dit is geleerd door alleen 
maar te kijken naar YouTube.

00:06:09.564 --> 00:06:11.371
Geen training,

00:06:11.371 --> 00:06:12.755
geen notie van een kat,

00:06:12.755 --> 00:06:15.316
maar dit concept van een kat

00:06:15.316 --> 00:06:18.124
is iets belangrijks dat jij zou begrijpen

00:06:18.124 --> 00:06:20.647
en dat de machines 
nu ook wat kunnen begrijpen.

00:06:20.647 --> 00:06:22.339
Misschien dit nog

00:06:22.339 --> 00:06:24.041
over het opzoeken.

00:06:24.041 --> 00:06:26.827
Het begon met opzoeken
en werkelijk begrijpen

00:06:26.827 --> 00:06:29.391
van de context van mensen 
en hun informatie.

00:06:29.391 --> 00:06:31.251
Ik heb een video

00:06:31.251 --> 00:06:33.261
waarmee ik snel wilde laten zien

00:06:33.261 --> 00:06:34.908
wat we eigenlijk hebben gevonden.

00:06:34.908 --> 00:06:40.020
(Video) [Soya, Kenia]

00:06:40.400 --> 00:06:42.272
Zack Matere: Niet zo lang geleden

00:06:42.272 --> 00:06:44.858
plantte ik aardappelen.

00:06:44.858 --> 00:06:48.258
Opeens gingen ze één voor één dood.

00:06:48.258 --> 00:06:51.008
Ik raadpleegde boeken 
en ze vertelden me niet veel.

00:06:51.008 --> 00:06:52.954
Daarom ging ik wat opzoeken.

00:06:52.954 --> 00:06:56.073
[Zack Matere, Boer]

00:06:57.429 --> 00:07:00.576
Aardappelziekten.

00:07:00.576 --> 00:07:02.094
Een van de websites vertelde me

00:07:02.094 --> 00:07:04.206
dat mieren het probleem 
zouden kunnen zijn.

00:07:04.206 --> 00:07:06.477
Het zei houtassen
over de planten te strooien.

00:07:06.477 --> 00:07:08.761
Na enkele dagen verdwenen de mieren.

00:07:08.761 --> 00:07:11.355
Ik werd enthousiast over het internet.

00:07:11.355 --> 00:07:13.020
Ik heb een vriend

00:07:13.020 --> 00:07:16.638
die zijn bedrijf graag wil uitbreiden.

00:07:16.638 --> 00:07:19.833
Ik ging met hem mee naar het cybercafé

00:07:19.833 --> 00:07:22.374
en we bekeken verschillende sites.

00:07:22.374 --> 00:07:25.555
Toen ik hem daarna ontmoette, 
zou hij een ​​windmolen plaatsen

00:07:25.555 --> 00:07:27.609
voor de plaatselijke school.

00:07:27.609 --> 00:07:29.213
Ik voelde me trots

00:07:29.213 --> 00:07:31.241
omdat iets dat er eerder niet was

00:07:31.241 --> 00:07:33.128
er ineens was.

00:07:33.128 --> 00:07:35.818
Ik realiseerde me dat niet iedereen

00:07:35.818 --> 00:07:38.302
toegang tot internet had zoals ik.

00:07:38.318 --> 00:07:40.676
Ik vond dat ik 
een ​​internetverbinding nodig had

00:07:40.676 --> 00:07:42.477
die mijn oma kon gebruiken.

00:07:42.477 --> 00:07:44.934
Ik dacht aan een prikbord.

00:07:44.934 --> 00:07:46.850
Een eenvoudig houten prikbord.

00:07:46.850 --> 00:07:49.165
Als ik informatie krijg 
op mijn smartphone,

00:07:49.165 --> 00:07:51.402
kan ik die informatie posten

00:07:51.402 --> 00:07:53.124
op dat prikbord.

00:07:53.124 --> 00:07:55.982
Eigenlijk als bij een computer.

00:07:55.982 --> 00:07:59.871
Ik gebruik het internet 
om mensen te helpen.

00:07:59.871 --> 00:08:03.281
Ik denk dat ik op zoek ben

00:08:03.281 --> 00:08:04.822
naar een beter leven

00:08:04.822 --> 00:08:08.936
voor mij en mijn buren.

00:08:08.936 --> 00:08:12.920
Zoveel mensen hebben 
toegang tot informatie,

00:08:12.920 --> 00:08:15.501
maar er is geen follow-up.

00:08:15.501 --> 00:08:18.009
Ik denk dat de follow-up 
ervan onze kennis is.

00:08:18.009 --> 00:08:19.615
Wanneer mensen de kennis hebben,

00:08:19.615 --> 00:08:21.245
kunnen ze oplossingen vinden

00:08:21.245 --> 00:08:23.229
zonder dat iemand ze helpt.

00:08:23.260 --> 00:08:25.381
Informatie is krachtig,

00:08:25.381 --> 00:08:29.983
maar het is hoe we ze gebruiken 
dat ons bepaalt.

00:08:30.903 --> 00:08:34.354
(Applaus)

00:08:34.364 --> 00:08:36.910
LP: Het verbazingwekkende aan die video is

00:08:36.910 --> 00:08:39.196
dat we het gewoon lazen in het nieuws,

00:08:39.196 --> 00:08:40.881
we vonden deze meneer

00:08:40.881 --> 00:08:43.196
en maakten die kleine clip.

00:08:43.196 --> 00:08:45.067
CR: Als ik met mensen over jou praat,

00:08:45.067 --> 00:08:47.192
zeggen mensen die je goed kennen:

00:08:47.192 --> 00:08:49.083
"Larry wil de wereld veranderen

00:08:49.083 --> 00:08:53.195
en hij gelooft dat technologie 
de weg kan wijzen."

00:08:53.195 --> 00:08:55.053
Dat betekent toegang tot het internet.

00:08:55.053 --> 00:08:56.784
Het heeft te maken met talen.

00:08:56.784 --> 00:08:59.613
Het betekent ook hoe mensen 
toegang kunnen krijgen

00:08:59.613 --> 00:09:02.319
en dingen doen die hun gemeenschap
zullen beïnvloeden.

00:09:02.319 --> 00:09:04.812
Dit is er een voorbeeld van.

00:09:04.812 --> 00:09:08.388
LP: Ja, dat klopt
en wat ik belangrijk vind,

00:09:08.388 --> 00:09:10.770
ik heb me meer gericht op toegang,

00:09:10.770 --> 00:09:12.968
als het gaat om de toekomst.

00:09:12.968 --> 00:09:15.642
We hebben onlangs 
het Loon Project opgestart

00:09:15.642 --> 00:09:17.942
om dat met ballonnen te doen.

00:09:17.942 --> 00:09:19.602
Het klinkt helemaal te gek.

00:09:19.602 --> 00:09:22.141
We kunnen de video hier laten zien.

00:09:22.141 --> 00:09:23.791
Twee op drie mensen in de wereld

00:09:23.791 --> 00:09:26.007
hebben nu geen goede toegang tot internet.

00:09:26.007 --> 00:09:28.913
We denken dat dit mensen echt kan helpen

00:09:28.913 --> 00:09:30.970
op een kostenefficiënte manier.

00:09:30.970 --> 00:09:34.341
CR: Het is een ballon. 
LP: Ja, toegang krijgen tot het internet.

00:09:34.341 --> 00:09:36.484
CR: En waarom geeft deze ballon toegang

00:09:36.484 --> 00:09:37.527
tot het internet?

00:09:37.527 --> 00:09:39.392
Omdat je een aantal interessante dingen

00:09:39.392 --> 00:09:40.746
moest zien te weten te komen

00:09:40.746 --> 00:09:42.617
om ballonnen mogelijk te maken

00:09:42.617 --> 00:09:44.546
die niet hoefden 
te worden aangebonden.

00:09:44.546 --> 00:09:46.707
LP: Dit is een goed 
voorbeeld van innovatie.

00:09:46.707 --> 00:09:49.251
We hebben over dit idee

00:09:49.251 --> 00:09:50.903
al vijf jaar of meer nagedacht,

00:09:50.903 --> 00:09:52.624
voordat we eraan begonnen te werken.

00:09:52.624 --> 00:09:53.943
Het ging er eigenlijk om

00:09:53.943 --> 00:09:57.463
om toegangspunten
goedkoop omhoog te krijgen.

00:09:57.463 --> 00:09:59.255
Normaal doe je dat met satellieten

00:09:59.255 --> 00:10:01.994
en dat duurt een lange tijd 
om ze te lanceren.

00:10:01.994 --> 00:10:05.208
Maar je zag daar hoe gemakkelijk 
het is om een ​​ballon te lanceren

00:10:05.208 --> 00:10:06.287
en te laten opstijgen.

00:10:06.287 --> 00:10:08.208
Dat is de kracht van het internet.

00:10:08.208 --> 00:10:09.988
Ik zocht het op

00:10:09.988 --> 00:10:12.292
en ik vond dat 30, 40 jaar geleden

00:10:12.292 --> 00:10:14.181
iemand een ballon had opgelaten

00:10:14.181 --> 00:10:16.986
die meerdere keren 
om de aarde was gegaan.

00:10:16.986 --> 00:10:19.821
Ik dacht: "Waarom kunnen 
we dat vandaag niet ook doen?"

00:10:19.821 --> 00:10:22.188
En zo kwam dit project op gang.

00:10:22.188 --> 00:10:24.648
CR: Maar je bent dan toch 
een speelbal van de wind?

00:10:24.648 --> 00:10:28.063
LP: Ja, maar we deden wat weersimulaties

00:10:28.063 --> 00:10:30.450
die waarschijnlijk 
nooit eerder waren gedaan.

00:10:30.450 --> 00:10:33.040
Als je de hoogte van de ballonnen 
kunt beïnvloeden --

00:10:33.040 --> 00:10:35.071
wat gaat door er lucht in te pompen

00:10:35.071 --> 00:10:36.893
en op andere manieren --

00:10:36.893 --> 00:10:39.822
hou je eigenlijk in de hand
waar ze ongeveer naartoe gaan.

00:10:39.822 --> 00:10:42.757
Zo kunnen we een wereldwijd 
netwerk van ballonnen opbouwen

00:10:42.757 --> 00:10:45.366
die de hele planeet kunnen dekken.

00:10:45.366 --> 00:10:48.298
CR: Voordat we gaan praten 
over de toekomst en het transport,

00:10:48.298 --> 00:10:50.133
wat al een tijdje je stokpaardje is,

00:10:50.133 --> 00:10:51.927
die fascinatie met vervoer,

00:10:51.927 --> 00:10:53.990
geautomatiseerde auto's en fietsen,

00:10:53.990 --> 00:10:55.727
wil ik het nog even hebben

00:10:55.727 --> 00:10:58.170
over wat het onderwerp was 
met Edward Snowden.

00:10:58.170 --> 00:11:01.276
Namelijk beveiliging en privacy.

00:11:01.276 --> 00:11:03.616
Daar moet je over hebben nagedacht.

00:11:03.616 --> 00:11:04.970
LP: Ja, absoluut.

00:11:04.970 --> 00:11:07.813
Ik zag gisteren de foto 
van Sergey met Edward Snowden.

00:11:07.813 --> 00:11:10.683
Sommigen van jullie 
kunnen ze gezien hebben.

00:11:10.683 --> 00:11:13.854
Maar ik denk persoonlijk

00:11:13.854 --> 00:11:17.266
dat privacy en veiligheid 
heel belangrijk zijn.

00:11:17.266 --> 00:11:19.761
We denken altijd aan beide zaken

00:11:19.761 --> 00:11:22.664
en ik denk dat je geen privacy 
kan hebben zonder veiligheid.

00:11:22.664 --> 00:11:25.035
Laat ik het daarom 
eerst over veiligheid hebben,

00:11:25.035 --> 00:11:27.631
omdat je naar Snowden en dat alles vroeg,

00:11:27.631 --> 00:11:30.072
en dan zal ik 
een beetje praten over privacy.

00:11:30.072 --> 00:11:33.872
Voor mij is het enorm teleurstellend

00:11:33.872 --> 00:11:35.311
dat de overheid

00:11:35.311 --> 00:11:38.231
stiekem al deze dingen deed 
en er ons niets over vertelde.

00:11:38.231 --> 00:11:40.944
Ik denk niet dat we 
een democratie kunnen hebben

00:11:40.944 --> 00:11:44.374
als we jou en onze gebruikers 
moeten beschermen

00:11:44.374 --> 00:11:46.070
tegen de overheid

00:11:46.070 --> 00:11:49.073
voor dingen waar we nooit over spraken.

00:11:49.073 --> 00:11:50.989
Dan bedoel ik niet dat we moeten weten

00:11:50.989 --> 00:11:53.144
over welke specifieke
terroristische aanslag

00:11:53.144 --> 00:11:54.786
ze zich zorgen maken,

00:11:54.786 --> 00:11:56.594
maar we moeten

00:11:56.594 --> 00:11:58.764
de parameters ervan kennen,

00:11:58.764 --> 00:12:01.148
wat voor soort toezicht
de overheid gaat uitoefenen

00:12:01.148 --> 00:12:02.646
en het hoe en waarom ervan,

00:12:02.646 --> 00:12:05.233
en ik denk dat we het daarover 
nog niet hebben gehad.

00:12:05.233 --> 00:12:07.490
Dus denk ik dat de overheid

00:12:07.490 --> 00:12:09.858
zichzelf een enorm slechte
dienst heeft bewezen

00:12:09.858 --> 00:12:11.819
door dat allemaal in het geheim te doen.

00:12:11.819 --> 00:12:15.064
CR: Dat ze nooit naar Google
zijn gekomen om iets te vragen.

00:12:15.064 --> 00:12:16.989
LP: Niet Google, maar het publiek.

00:12:16.989 --> 00:12:20.762
Ik denk dat we daar nodig 
eens moeten over praten

00:12:20.762 --> 00:12:23.261
als we een functionerende 
democratie willen hebben.

00:12:23.261 --> 00:12:24.667
Anders kan dat gewoon niet.

00:12:24.667 --> 00:12:26.911
Dus ben ik triest dat Google

00:12:26.911 --> 00:12:29.527
zich in de positie bevindt 
om jou en onze gebruikers

00:12:29.527 --> 00:12:31.061
tegen de overheid te beschermen

00:12:31.061 --> 00:12:33.305
die iets verborgens doet dat niemand weet.

00:12:33.305 --> 00:12:35.052
Dat slaat toch nergens op.

00:12:35.052 --> 00:12:38.042
CR: Ja, en dan is er ook nog de privacy.

00:12:38.042 --> 00:12:40.469
LP: Ja. Het privacy-aspect.

00:12:40.469 --> 00:12:42.438
De wereld verandert.

00:12:42.438 --> 00:12:46.343
Je hebt ​​een telefoon bij je
die weet waar je bent.

00:12:46.343 --> 00:12:49.428
Er is zo veel meer informatie over jou

00:12:49.428 --> 00:12:52.274
en dat is belangrijk.

00:12:52.274 --> 00:12:54.546
Het is logisch dat mensen

00:12:54.546 --> 00:12:56.582
moeilijke vragen stellen.

00:12:56.582 --> 00:13:00.409
We besteden veel tijd 
met hierover te denken

00:13:00.409 --> 00:13:02.990
en wat de problemen zijn.

00:13:02.990 --> 00:13:04.389
Ik ben een beetje --

00:13:04.389 --> 00:13:06.279
het belangrijkste 
wat we moeten doen,

00:13:06.279 --> 00:13:08.011
is mensen gewoon de keuze bieden,

00:13:08.011 --> 00:13:10.523
laten zien welke gegevens 
worden verzameld --

00:13:10.523 --> 00:13:15.274
zoekgeschiedenis, locatiegegevens.

00:13:15.274 --> 00:13:18.046
We zijn enthousiast 
over de incognitomodus in Chrome

00:13:18.046 --> 00:13:20.295
en dat te doen op meer manieren,

00:13:20.295 --> 00:13:21.691
mensen meer keuze geven

00:13:21.691 --> 00:13:24.984
en meer bewust maken 
van wat er gaande is.

00:13:24.984 --> 00:13:27.267
Ik denk ook dat het heel eenvoudig is.

00:13:27.267 --> 00:13:29.094
Waar ik me zorgen over maak,

00:13:29.094 --> 00:13:31.414
is dat we het kind
met het badwater weggooien.

00:13:31.414 --> 00:13:33.658
Ik lijk tijdens je show

00:13:33.658 --> 00:13:35.377
mijn stem te zijn kwijtgeraakt

00:13:35.377 --> 00:13:36.708
en ik heb ze niet nog terug.

00:13:36.708 --> 00:13:38.602
Ik hoop dat door tegen je te praten

00:13:38.602 --> 00:13:40.005
ik ze ga terugkrijgen.

00:13:40.005 --> 00:13:41.737
CR: Als ik iets kan doen...

00:13:41.737 --> 00:13:43.917
LP: Oké. Dus haal je voodoo-pop erbij

00:13:43.917 --> 00:13:46.336
en doe je ding.

00:13:46.336 --> 00:13:48.664
Maar ik denk, weet je wat, ik kijk ernaar,

00:13:48.664 --> 00:13:50.304
ik maakte het bekend

00:13:50.304 --> 00:13:51.711
en kreeg al deze informatie.

00:13:51.711 --> 00:13:54.440
We deden een enquête 
over de medische toestand

00:13:54.440 --> 00:13:57.811
van mensen met soortgelijke problemen

00:13:57.811 --> 00:14:02.552
en ik keek naar medische dossiers en zei:

00:14:02.552 --> 00:14:03.957
"Zou het niet geweldig zijn

00:14:03.957 --> 00:14:06.640
als de medische dossiers 
van iedereen beschikbaar waren

00:14:06.640 --> 00:14:10.326
om ze anoniem door artsen
te laten onderzoeken?"

00:14:10.326 --> 00:14:13.367
En wanneer iemand toegang 
zocht tot je medische dossier,

00:14:13.367 --> 00:14:14.976
een onderzoeksarts,

00:14:14.976 --> 00:14:17.610
dat je dan kon zien welke arts

00:14:17.610 --> 00:14:19.470
het raadpleegde en waarom.

00:14:19.470 --> 00:14:21.050
Zo kan je misschien iets leren

00:14:21.050 --> 00:14:22.450
over wat je mankeert.

00:14:22.450 --> 00:14:23.902
Ik denk dat als we dat deden,

00:14:23.902 --> 00:14:26.347
we dit jaar al 100.000 levens 
zouden kunnen redden.

00:14:26.347 --> 00:14:29.295
CR: Absoluut. Laat me --
(Applaus)

00:14:29.295 --> 00:14:32.057
LP: Ik vermoed dat ik gewoon heel bang ben

00:14:32.057 --> 00:14:33.863
dat we met internet privacy

00:14:33.863 --> 00:14:36.163
hetzelfde doen als met medische dossiers,

00:14:36.167 --> 00:14:38.696
dat we het kind weggooien 
met het badwater.

00:14:38.696 --> 00:14:40.524
We denken niet echt na

00:14:40.524 --> 00:14:42.734
over de enorme goede dingen

00:14:42.734 --> 00:14:44.925
die resulteren uit
het delen van informatie

00:14:44.925 --> 00:14:47.502
met de juiste mensen 
en op de juiste manier.

00:14:47.502 --> 00:14:49.739
CR: De noodzakelijke voorwaarde is

00:14:49.739 --> 00:14:51.441
dat mensen erop moeten vertrouwen

00:14:51.441 --> 00:14:53.896
dat hun informatie 
niet zal worden misbruikt.

00:14:53.896 --> 00:14:55.913
LP: Ja, ik had dat probleem met mijn stem.

00:14:55.913 --> 00:14:57.261
Ik was bang om het te delen.

00:14:57.261 --> 00:14:59.071
Sergey moedigde me aan om het te doen

00:14:59.071 --> 00:15:00.898
en het was een geweldig iets.

00:15:00.898 --> 00:15:02.632
CR: De respons was overweldigend.

00:15:02.632 --> 00:15:04.662
LP: Ja, en de mensen zijn superpositief.

00:15:04.662 --> 00:15:07.125
We vonden duizenden en duizenden mensen

00:15:07.125 --> 00:15:08.413
met dezelfde aandoeningen

00:15:08.413 --> 00:15:11.211
waarover vandaag geen gegevens bestaan.

00:15:11.211 --> 00:15:12.797
Dus was het echt een goede zaak.

00:15:12.797 --> 00:15:14.756
CR: Even praten over de toekomst.

00:15:14.756 --> 00:15:19.574
Hoe zit het met jou en transportsystemen?

00:15:19.574 --> 00:15:21.751
LP: Ik was daar gefrustreerd over

00:15:21.751 --> 00:15:24.290
toen ik in Michigan
op de universiteit zat.

00:15:24.290 --> 00:15:25.740
Ik moest de bus nemen

00:15:25.740 --> 00:15:27.382
en wachten tot hij kwam.

00:15:27.382 --> 00:15:29.561
Het was koud en het sneeuwde.

00:15:29.561 --> 00:15:32.216
Ik deed wat onderzoek 
over hoeveel het kostte

00:15:32.216 --> 00:15:37.451
en ik werd een beetje geobsedeerd 
door transportsystemen.

00:15:38.641 --> 00:15:41.161
CR: Zo kwam het idee 
van een geautomatiseerde auto.

00:15:41.161 --> 00:15:43.435
LP: Ja, ongeveer 18 jaar geleden hoorde ik

00:15:43.435 --> 00:15:45.887
over mensen die werken 
aan geautomatiseerde auto's

00:15:45.887 --> 00:15:47.900
en ik raakte erdoor gefascineerd.

00:15:48.620 --> 00:15:51.787
Het duurt een tijdje 
voor deze projecten van start gaan,

00:15:51.787 --> 00:15:55.384
maar ik ben superenthousiast 
over de mogelijkheden ervan

00:15:55.384 --> 00:15:57.052
om de wereld te verbeteren.

00:15:57.052 --> 00:16:01.578
Per jaar lopen 20 miljoen
of meer mensen verwondingen op.

00:16:01.578 --> 00:16:03.464
Het is de belangrijkste doodsoorzaak

00:16:03.464 --> 00:16:05.714
voor mensen onder de 34 
in de Verenigde Staten.

00:16:05.714 --> 00:16:07.625
CR: Je praat over het redden van levens.

00:16:07.625 --> 00:16:09.600
LP: Ja, en ook over ruimtebesparing

00:16:09.600 --> 00:16:13.515
en het leven beter maken.

00:16:13.515 --> 00:16:17.760
Los Angeles bestaat voor de helft 
uit parkeerplaatsen en wegen,

00:16:17.760 --> 00:16:19.493
de helft van het oppervlak,

00:16:19.493 --> 00:16:22.320
en de meeste steden lopen niet ver achter.

00:16:22.320 --> 00:16:23.744
Het is gewoon te gek

00:16:23.744 --> 00:16:25.477
waar we onze ruimte voor gebruiken.

00:16:25.477 --> 00:16:27.820
CR: En hoe snel zal het er zijn?

00:16:27.820 --> 00:16:29.746
LP: Ik denk zeer binnenkort.

00:16:29.746 --> 00:16:33.247
We hebben nu al meer dan 150.000 km

00:16:33.247 --> 00:16:37.340
volledig geautomatiseerd gereden.

00:16:37.340 --> 00:16:40.992
Ik ben superenthousiast 
dat het er snel zit aan te komen.

00:16:40.992 --> 00:16:43.867
CR: Maar het gaat niet alleen 
over geautomatiseerde auto's.

00:16:43.867 --> 00:16:45.783
Je hebt ook een idee voor fietsen.

00:16:45.783 --> 00:16:48.029
LP: Bij Google kregen we het idee

00:16:48.029 --> 00:16:51.480
dat we gewoon iedereen 
gratis fietsen moeten aanbieden

00:16:51.480 --> 00:16:54.618
en het werkt geweldig
voor de meeste verplaatsingen.

00:16:54.618 --> 00:16:55.834
Je ziet overal fietsen

00:16:55.834 --> 00:16:57.030
en de fietsen verslijten.

00:16:57.030 --> 00:16:58.694
Ze worden 24 uur per dag gebruikt.

00:16:58.694 --> 00:17:01.014
CR: Je wilt ze 
boven de straat laten rijden.

00:17:01.014 --> 00:17:02.589
LP: Ik vroeg me af hoe we mensen

00:17:02.589 --> 00:17:04.116
meer op de fiets krijgen.

00:17:04.116 --> 00:17:05.741
CR: Hier een video.

00:17:05.741 --> 00:17:07.019
LP: Daar komt ie.

00:17:07.019 --> 00:17:10.111
Ik ben er enthousiast over.

00:17:10.111 --> 00:17:14.153
(Muziek)

00:17:16.033 --> 00:17:18.458
Dit is de manier om fietsen

00:17:18.458 --> 00:17:22.087
van auto's te scheiden 
met minimale kosten.

00:17:26.531 --> 00:17:28.286
Het ziet er helemaal te gek uit,

00:17:28.286 --> 00:17:30.963
maar ik dacht eigenlijk aan onze campus,

00:17:30.963 --> 00:17:33.513
en het werken met Zippies,

00:17:33.513 --> 00:17:35.661
om de fiets veel meer te gebruiken.

00:17:35.661 --> 00:17:37.529
Ik zat te denken:

00:17:37.529 --> 00:17:39.350
hoe kun je kosten-effectief

00:17:39.350 --> 00:17:41.024
fietsen van verkeer te scheiden?

00:17:41.024 --> 00:17:43.795
Ik zocht en zocht
en dit is wat ik heb gevonden.

00:17:43.795 --> 00:17:46.390
We zijn er nog niet echt mee bezig,

00:17:46.422 --> 00:17:48.476
maar het prikkelt je fantasie.

00:17:48.476 --> 00:17:50.240
CR: Laat me hiermee eindigen.

00:17:50.240 --> 00:17:52.585
Welke filosofie zit hier achter.

00:17:52.585 --> 00:17:55.073
Je hebt dit idee van [Google X].

00:17:55.073 --> 00:17:58.069
Je wil je niet alleen maar beperken

00:17:58.069 --> 00:18:03.665
tot een klein, afgebakend gebiedje 
van de vooruitgang.

00:18:03.665 --> 00:18:05.168
LP: Ja, ik denk dat dat geldt

00:18:05.168 --> 00:18:07.509
voor veel van de dingen
waar we het over hadden,

00:18:07.509 --> 00:18:10.461
waar ze echt zijn --

00:18:10.461 --> 00:18:14.091
ik gebruik bijna het economische 
concept van additionaliteit,

00:18:14.091 --> 00:18:16.281
wat betekent dat je iets doet

00:18:16.281 --> 00:18:19.229
dat niet zou gebeuren, 
tenzij je het echt doet.

00:18:19.229 --> 00:18:22.369
En ik denk dat hoe meer 
je dat soort dingen kunt doen,

00:18:22.369 --> 00:18:24.440
des te groter de impact die je hebt,

00:18:24.440 --> 00:18:27.430
en dat is om dingen te doen

00:18:27.430 --> 00:18:31.037
die mensen niet 
voor mogelijk zouden houden.

00:18:31.037 --> 00:18:32.866
Ik was verbaasd,

00:18:32.866 --> 00:18:35.095
hoe meer ik leer over technologie,

00:18:35.095 --> 00:18:37.291
hoe meer ik besef dat ik het niet weet,

00:18:37.291 --> 00:18:40.628
en dat komt door deze
technologische horizon,

00:18:40.628 --> 00:18:43.525
het ding dat je denkt te gaan doen,

00:18:43.525 --> 00:18:45.365
hoe meer je leert over technologie,

00:18:45.365 --> 00:18:47.967
hoe meer je ontdekt wat er mogelijk is.

00:18:47.967 --> 00:18:50.213
Je leert dat de ballonnen mogelijk zijn

00:18:50.213 --> 00:18:52.550
want er bestaat materiaal 
waar dat mee gaat.

00:18:52.550 --> 00:18:54.929
CR: Wat me ook aan je interesseert,

00:18:54.929 --> 00:18:56.640
is dat we veel mensen hebben

00:18:56.640 --> 00:18:58.782
die denken over de toekomst,

00:18:58.782 --> 00:19:02.050
en ze gaan en kijken en komen terug,

00:19:02.050 --> 00:19:04.177
maar we zien nooit de implementatie.

00:19:04.177 --> 00:19:05.782
Ik denk aan iemand die je kende

00:19:05.782 --> 00:19:08.689
en waar je over las: Tesla.

00:19:08.689 --> 00:19:12.493
Welk principe speelt hier, denk je?

00:19:12.493 --> 00:19:14.538
LP: Uitvinden alleen is niet genoeg.

00:19:14.538 --> 00:19:15.679
Als je iets uitvindt --

00:19:15.679 --> 00:19:18.694
Tesla was de uitvinder 
van ons systeem van elektrische energie,

00:19:18.694 --> 00:19:21.355
maar hij kreeg het niet verkocht.

00:19:21.355 --> 00:19:23.039
Dat moesten andere mensen doen.

00:19:23.039 --> 00:19:24.665
Het duurde lang.

00:19:24.665 --> 00:19:28.532
Ik denk dat als we 
beide kunnen combineren,

00:19:28.532 --> 00:19:32.063
met focus op innovatie en inventiviteit,

00:19:32.063 --> 00:19:34.235
plus de mogelijkheid --

00:19:34.235 --> 00:19:37.033
een bedrijf dat dingen
echt kan commercialiseren

00:19:37.033 --> 00:19:38.663
en ze bij de mensen te krijgen

00:19:38.663 --> 00:19:40.738
op een positieve manier

00:19:40.738 --> 00:19:42.794
en om mensen hoop te geven.

00:19:42.794 --> 00:19:45.568
Ik stond verbaasd hoe het Loon Project

00:19:45.568 --> 00:19:48.354
mensen enthousiasmeerde,

00:19:48.354 --> 00:19:50.168
want het gaf hen hoop

00:19:50.168 --> 00:19:51.789
voor de tweederde van de wereld

00:19:51.789 --> 00:19:54.515
dat nog geen deugdelijk internet heeft.

00:19:54.515 --> 00:19:56.637
CR: Dat is nog iets over bedrijven.

00:19:56.637 --> 00:19:59.113
Je bent een van die mensen die geloven

00:19:59.113 --> 00:20:01.430
dat bedrijven iets kunnen veranderen

00:20:01.430 --> 00:20:02.901
als ze goed geleid worden.

00:20:02.901 --> 00:20:04.722
LP: Ja. Ik ben echt verbijsterd

00:20:04.722 --> 00:20:08.136
dat de meeste mensen denken dat bedrijven
in principe kwaadaardig zijn.

00:20:08.136 --> 00:20:09.782
Ze staan in een kwalijk daglicht.

00:20:09.782 --> 00:20:12.023
Ergens klopt dat een beetje.

00:20:12.023 --> 00:20:14.893
Bedrijven blijven hetzelfde 
incrementele ding doen

00:20:14.893 --> 00:20:16.656
dat ze 50 jaar geleden

00:20:16.656 --> 00:20:18.287
of 20 jaar geleden ook al deden.

00:20:18.287 --> 00:20:19.937
Dat is niet wat we nodig hebben.

00:20:19.937 --> 00:20:21.875
Met name in de technologie

00:20:21.875 --> 00:20:23.992
moet je revolutionair veranderen,

00:20:23.992 --> 00:20:25.405
niet incrementeel veranderen.

00:20:25.405 --> 00:20:26.574
CR: Je zei ooit

00:20:26.574 --> 00:20:28.392
-- ik denk dat ik het juist heb --

00:20:28.392 --> 00:20:30.037
dat je zou kunnen overwegen,

00:20:30.037 --> 00:20:33.100
in plaats van je geld weg te geven

00:20:33.100 --> 00:20:35.110
aan een of ander goed doel,

00:20:35.110 --> 00:20:37.116
je het gewoon aan Elon Musk zou geven,

00:20:37.116 --> 00:20:38.279
want je had vertrouwen

00:20:38.279 --> 00:20:40.121
dat hij de toekomst zou veranderen,

00:20:40.121 --> 00:20:41.898
en dat je dan ook --

00:20:41.898 --> 00:20:43.592
LP: Ja, als je naar Mars wilt gaan

00:20:43.592 --> 00:20:45.203
-- hij wil naar Mars gaan,

00:20:45.203 --> 00:20:47.174
als back-up voor de mensheid --

00:20:47.174 --> 00:20:49.646
dat is een waardig doel, 
maar het is een bedrijf

00:20:49.646 --> 00:20:51.401
en het is filantropisch.

00:20:51.401 --> 00:20:55.213
Ik denk dat we 
gelijkaardige doelen nastreven.

00:20:56.253 --> 00:20:58.640
We hebben bij Google veel werknemers

00:20:58.640 --> 00:21:00.655
die behoorlijk rijk zijn geworden.

00:21:00.655 --> 00:21:03.175
Mensen verdienen 
een hoop geld in de technologie.

00:21:03.175 --> 00:21:05.331
Veel mensen hier zijn nogal welvarend.

00:21:05.331 --> 00:21:07.645
Je werkt omdat je 
de wereld wil veranderen.

00:21:07.645 --> 00:21:09.407
Je wilt hem beter maken.

00:21:09.407 --> 00:21:12.852
Waarom zou het bedrijf waar je voor werkt

00:21:12.852 --> 00:21:14.795
alleen je tijd waard zijn,

00:21:14.795 --> 00:21:16.946
waarom niet ook je geld?

00:21:16.946 --> 00:21:19.178
Ik bedoel, dat komt niet bij ons op.

00:21:19.178 --> 00:21:20.972
Zo denken we niet over bedrijven

00:21:20.972 --> 00:21:22.439
en ik denk dat dat triest is,

00:21:22.439 --> 00:21:26.206
want de meeste van onze inspanningen 
gaan naar bedrijven.

00:21:26.206 --> 00:21:28.721
Daar brengen mensen de meeste tijd door,

00:21:28.721 --> 00:21:30.575
daar zit veel geld

00:21:30.575 --> 00:21:32.597
en dus denk ik dat we

00:21:32.597 --> 00:21:34.053
ze meer zouden moeten helpen.

00:21:34.053 --> 00:21:35.774
CR: Wanneer ik interviews afsluit,

00:21:35.774 --> 00:21:37.553
stel ik meestal deze vraag:

00:21:37.553 --> 00:21:39.068
welke geestesinstelling,

00:21:39.068 --> 00:21:40.877
welke eigenschap van de geest

00:21:40.877 --> 00:21:42.644
heeft je het beste gediend?

00:21:42.644 --> 00:21:45.165
Mensen als Rupert Murdoch 
zeiden 'nieuwsgierigheid',

00:21:45.165 --> 00:21:47.793
en anderen in de media 
hebben dat ook gezegd.

00:21:47.793 --> 00:21:50.817
Bill Gates en Warren Buffett 
zeiden 'focus'.

00:21:50.817 --> 00:21:52.594
Welke geestesinstelling

00:21:52.594 --> 00:21:57.148
heeft jou in staat gesteld
om over de toekomst na te denken

00:21:57.148 --> 00:21:58.795
en tegelijkertijd

00:21:58.795 --> 00:22:01.000
het heden te veranderen?

00:22:01.000 --> 00:22:02.980
LP: Ik denk dat het allerbelangrijkste --

00:22:02.980 --> 00:22:04.282
ik keek naar veel bedrijven

00:22:04.282 --> 00:22:07.585
en vroeg me af waarom ze
op de lange termijn niet slaagden.

00:22:07.585 --> 00:22:10.418
Ze kwamen en gingen steeds sneller.

00:22:10.418 --> 00:22:13.187
En ik vroeg me af 
wat ze fundamenteel verkeerd deden?

00:22:13.187 --> 00:22:15.354
Wat deden die bedrijven allemaal verkeerd?

00:22:15.354 --> 00:22:18.626
En meestal was het gewoon 
dat ze de toekomst misten.

00:22:18.626 --> 00:22:21.070
Daarom blijf ik

00:22:21.070 --> 00:22:23.494
me erop concentreren en zeggen:

00:22:23.494 --> 00:22:25.678
hoe gaat de toekomst echt worden

00:22:25.678 --> 00:22:27.465
en hoe creëren we ze

00:22:27.465 --> 00:22:32.132
en hoe kunnen we ervoor zorgen 
dat onze organisatie

00:22:32.132 --> 00:22:34.572
er echt op gefocust blijft

00:22:34.572 --> 00:22:37.897
en er ten volle voor gaat?

00:22:37.897 --> 00:22:39.257
Dat is nieuwsgierigheid,

00:22:39.257 --> 00:22:40.780
het op zoek gaan naar dingen

00:22:40.780 --> 00:22:42.708
waar mensen misschien niet aan denken,

00:22:42.708 --> 00:22:45.813
werken aan dingen
waar niemand anders aan werkt,

00:22:45.813 --> 00:22:49.119
want daar zit de toegevoegde waarde echt,

00:22:49.119 --> 00:22:50.670
en bereid zijn om dat te doen,

00:22:50.670 --> 00:22:52.052
om risico te nemen.

00:22:52.052 --> 00:22:53.117
Kijk naar Android.

00:22:53.117 --> 00:22:55.902
Ik voelde me schuldig 
om aan Android te werken

00:22:55.902 --> 00:22:57.218
toen het begon.

00:22:57.218 --> 00:22:59.586
Het was een kleine onderneming 
die we opkochten.

00:22:59.586 --> 00:23:01.846
Het was niet echt
waar wij mee bezig waren.

00:23:01.846 --> 00:23:04.341
Ik voelde me schuldig 
om er tijd in te steken.

00:23:04.341 --> 00:23:05.795
Dat was dom.

00:23:05.795 --> 00:23:07.046
Dat was de toekomst, toch?

00:23:07.046 --> 00:23:09.131
Het was een goede zaak om aan te werken.

00:23:09.131 --> 00:23:10.548
CR: Geweldig dat je er was.

00:23:10.548 --> 00:23:12.008
Geweldig je te horen

00:23:12.008 --> 00:23:14.305
en een genoegen
om met je te praten.

00:23:14.305 --> 00:23:15.233
Bedankt, Larry.

00:23:15.233 --> 00:23:17.336
LP: Dank je wel.

00:23:17.336 --> 00:23:21.268
(Applaus)

00:23:21.268 --> 00:23:24.579
CR: Larry Page.

