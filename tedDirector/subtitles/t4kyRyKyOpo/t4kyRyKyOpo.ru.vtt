WEBVTT
Kind: captions
Language: ru

00:00:00.000 --> 00:00:07.000
Переводчик: Tatiana Efremova
Редактор: Katya Roberts

00:00:12.880 --> 00:00:16.893
Обычно, если вы хотите, чтобы
компьютер сделал что-то новое,

00:00:16.893 --> 00:00:18.447
вам нужно его запрограммировать.

00:00:18.447 --> 00:00:21.858
Для тех, кто не знает:
программирование

00:00:21.858 --> 00:00:25.360
требует мучительного определения
мельчайших деталей,

00:00:25.360 --> 00:00:28.727
которые должен выполнять компьютер

00:00:28.727 --> 00:00:31.089
для достижения вашей цели.

00:00:31.089 --> 00:00:34.585
А сделать то, чего вы никогда не делали,

00:00:34.585 --> 00:00:36.648
будет очень сложно.

00:00:36.648 --> 00:00:40.131
Именно с такой сложной задачей
столкнулся этот человек, Артур Самуэль.

00:00:40.131 --> 00:00:44.208
В 1956 году он захотел,

00:00:44.208 --> 00:00:46.548
чтобы компьютер
смог обыграть его в шашки.

00:00:46.548 --> 00:00:48.588
Как написать программу,

00:00:48.588 --> 00:00:52.394
продумать её до мельчайших деталей,
чтобы она обыграла тебя в шашки?

00:00:52.394 --> 00:00:54.116
Ему в голову пришла мысль:

00:00:54.116 --> 00:00:57.840
компьютер должен сыграть тысячу партий
с самим собой,

00:00:57.840 --> 00:01:00.364
и так он научится играть в шашки.

00:01:00.364 --> 00:01:03.544
Это действительно сработало —
в 1962 году

00:01:03.544 --> 00:01:07.561
этот компьютер обыграл
чемпиона штата Коннектикут.

00:01:07.561 --> 00:01:10.534
Так Артур Самуэль стал основоположником
машинного обучения.

00:01:10.534 --> 00:01:12.251
Я в большом долгу перед ним,

00:01:12.251 --> 00:01:15.014
потому что работаю
в области машинного обучения.

00:01:15.014 --> 00:01:16.479
Я был президентом Kaggle,

00:01:16.479 --> 00:01:19.867
сообщества, объединяющего 200 000 людей,
применяющих машинное обучение.

00:01:19.867 --> 00:01:21.925
Kaggle проводит соревнования

00:01:21.925 --> 00:01:25.633
по решению ещё не решённых проблем,

00:01:25.633 --> 00:01:29.470
и участники успешно справились
с сотнями из них.

00:01:29.470 --> 00:01:31.940
У меня была отличная возможность
побольше узнать

00:01:31.940 --> 00:01:35.890
о машинном обучении
в прошлом, настоящем

00:01:35.890 --> 00:01:38.252
и будущем.

00:01:38.252 --> 00:01:42.675
Возможно, первым большим коммерческим
успехом машинного обучения стал Google.

00:01:42.675 --> 00:01:45.784
В Google доказали,
что можно находить информацию

00:01:45.784 --> 00:01:47.536
с помощью компьютерного алгоритма,

00:01:47.536 --> 00:01:50.437
а этот алгоритм был основан
на машинном обучении.

00:01:50.437 --> 00:01:54.323
С тех пор машинное обучение неоднократно
использовалось в коммерческих целях.

00:01:54.323 --> 00:01:56.160
Компании вроде Amazon и Netflix

00:01:56.160 --> 00:01:59.876
иcпользуют машинное обучение, определяя,
какие товары вы захотите купить,

00:01:59.876 --> 00:02:01.896
какие фильмы посмотреть.

00:02:01.896 --> 00:02:03.703
Иногда это даже пугает.

00:02:03.703 --> 00:02:05.637
Сети, такие как LinkedIn и Facebook,

00:02:05.637 --> 00:02:08.251
иногда предлагают людей,
которых вы можете знать,

00:02:08.251 --> 00:02:10.228
а вы не понимаете, как они их нашли.

00:02:10.228 --> 00:02:13.195
Это стало возможным
благодаря машинному обучению.

00:02:13.195 --> 00:02:17.323
Алгоритмы собирают информацию
и обучаются,

00:02:17.331 --> 00:02:19.399
а не программируются человеком.

00:02:19.399 --> 00:02:21.877
Это также объясняет успехи IBM:

00:02:21.877 --> 00:02:25.739
программа Watson обыграла
двух чемпионов мира в «Своей игре»,

00:02:25.739 --> 00:02:28.964
ответив на невероятно хитрые и каверзные
вопросы вроде этого:

00:02:28.964 --> 00:02:31.799
[В 2003 году «лев Нимруда» исчез
из музея этого города]

00:02:31.799 --> 00:02:35.034
Именно этот метод лёг в основу
технологии беспилотных автомобилей.

00:02:35.034 --> 00:02:37.856
Важно, чтобы такой автомобиль
смог отличить

00:02:37.856 --> 00:02:40.488
дерево от пешехода.

00:02:40.488 --> 00:02:43.075
Мы не знаем,
как задать такой алгоритм вручную,

00:02:43.075 --> 00:02:46.072
зато это стало возможным
с помощью машинного обучения.

00:02:46.072 --> 00:02:48.680
Этот автомобиль проехал
более 1,5 миллионов километров

00:02:48.680 --> 00:02:52.186
и ни разу не попал в аварию на трассе.

00:02:52.196 --> 00:02:56.110
Итак, мы знаем, 
что компьютеры могут учиться.

00:02:56.110 --> 00:02:58.010
Причём они могут учиться делать то,

00:02:58.010 --> 00:03:00.848
чего не умеем делать мы сами,

00:03:00.848 --> 00:03:03.733
или могут делать это лучше нас.

00:03:03.733 --> 00:03:07.928
С одним из самых невероятных примеров
машинного обучения

00:03:07.928 --> 00:03:10.320
я столкнулся, пока работал в Kaggle:

00:03:10.320 --> 00:03:13.911
команда под руководством Джеффри Хинтона

00:03:13.911 --> 00:03:15.463
из Торонтского университета

00:03:15.463 --> 00:03:18.140
выиграла конкурс по автоматизации поиска
новых лекарств.

00:03:18.140 --> 00:03:20.987
Невероятно не только то,
что их алгоритм оказался лучше

00:03:20.987 --> 00:03:25.000
всех алгоритмов, разработанных Merck
или международным научным сообществом.

00:03:25.000 --> 00:03:30.061
Никто в команде не имел никакого отношения
к химии, биологии или медицине,

00:03:30.061 --> 00:03:32.230
и на всё у них ушло две недели.

00:03:32.230 --> 00:03:33.611
Как?

00:03:34.421 --> 00:03:37.342
Благодаря уникальному алгоритму
глубинного обучения.

00:03:37.342 --> 00:03:40.291
Результаты их работы были настолько 
ошеломительны, что об этом

00:03:40.291 --> 00:03:43.412
спустя несколько недель сообщила
на первой полосе New York Times.

00:03:43.412 --> 00:03:46.147
Джеффри Хинтон слева.

00:03:46.147 --> 00:03:50.488
В основе глубинного обучения —
принципы работы человеческого мозга,

00:03:50.488 --> 00:03:52.300
и поэтому теоретически

00:03:52.300 --> 00:03:56.141
у этого алгоритма
нет ограничений применимости.

00:03:56.141 --> 00:03:58.964
Чем больше данных на входе
и времени на их обработку,

00:03:58.964 --> 00:04:00.276
тем лучше результат.

00:04:00.276 --> 00:04:02.615
В этой же статье New York Times
был упомянут

00:04:02.615 --> 00:04:04.857
другой удивительный продукт
глубинного обучения,

00:04:04.857 --> 00:04:07.569
который я вам сейчас продемонстрирую.

00:04:07.569 --> 00:04:12.510
Он доказывает,
что компьютеры могут слышать и понимать.

00:04:12.510 --> 00:04:15.221
(Видео) Ричард Рашид: Наконец,

00:04:15.221 --> 00:04:18.246
последнее, что я хочу сделать, —

00:04:18.246 --> 00:04:22.961
это поговорить с вами по-китайски.

00:04:22.961 --> 00:04:25.596
Суть в том,

00:04:25.596 --> 00:04:30.548
что мы сформировали массив записей
носителей китайского языка

00:04:30.548 --> 00:04:33.128
и разработали систему
для преобразования текста в речь,

00:04:33.128 --> 00:04:37.801
которая получает текст на китайском
и преобразует его в речь.

00:04:37.801 --> 00:04:41.929
Потом мы записали примерно час
звучания моего голоса

00:04:41.929 --> 00:04:43.820
и использовали эту запись для модуляции

00:04:43.820 --> 00:04:48.551
обычной системы
преобразования текста в речь.

00:04:48.551 --> 00:04:50.904
Если что, результат не идеален.

00:04:50.904 --> 00:04:53.552
Там есть несколько ошибок.

00:04:53.552 --> 00:04:56.036
(Говорит по-китайски)

00:04:56.036 --> 00:04:59.403
(Аплодисменты)

00:05:01.446 --> 00:05:05.022
Нам предстоит ещё много работы.

00:05:05.022 --> 00:05:08.667
(Говорит по-китайски)

00:05:08.667 --> 00:05:12.100
(Аплодисменты)

00:05:13.345 --> 00:05:16.744
Джереми Говард: Это было на конференции
по машинному обучению в Китае.

00:05:16.744 --> 00:05:19.114
На самом деле,
на научных конференциях

00:05:19.114 --> 00:05:21.011
внезапно аплодируют очень редко,

00:05:21.011 --> 00:05:24.687
в отличие от TEDx, так что не стесняйтесь.

00:05:24.687 --> 00:05:27.482
Всё это видео было записано
с помощью глубинного обучения.

00:05:27.482 --> 00:05:29.007
(Аплодисменты) Спасибо.

00:05:29.007 --> 00:05:31.289
Английские субтитры —
это глубинное обучение,

00:05:31.289 --> 00:05:34.701
перевод на китайский
и текст справа вверху — оно же,

00:05:34.701 --> 00:05:38.008
и конструирование голоса — снова оно.

00:05:38.008 --> 00:05:41.242
Глубинное обучение — невероятная вещь.

00:05:41.242 --> 00:05:44.341
Один-единственный алгоритм,
который, похоже, может почти всё.

00:05:44.341 --> 00:05:47.452
Ещё годом раньше я обнаружил,
что этот алгоритм может видеть.

00:05:47.452 --> 00:05:49.348
На малоизвестном конкурсе в Германии —

00:05:49.348 --> 00:05:52.225
«Сравнительный анализ распознавания
дорожных знаков» —

00:05:52.225 --> 00:05:55.618
глубинное обучение использовалось
для распознавания вот таких знаков.

00:05:55.618 --> 00:05:57.712
Мало того, что результаты распознавания

00:05:57.712 --> 00:05:59.470
были лучше, чем у других алгоритмов;

00:05:59.470 --> 00:06:02.189
в таблице видно,
что они превосходят человеческие

00:06:02.189 --> 00:06:04.041
примерно в два раза.

00:06:04.041 --> 00:06:06.037
Итак, к 2011 году появился

00:06:06.037 --> 00:06:09.442
первый компьютер,
который видел лучше людей.

00:06:09.442 --> 00:06:11.491
С тех пор произошло многое.

00:06:11.491 --> 00:06:15.005
В 2012 году в Google объявили,
что их алгоритм глубинного обучения

00:06:15.005 --> 00:06:16.420
использовал видео на YouTube.

00:06:16.420 --> 00:06:19.857
Данные обрабатывались
на 16 000 компьютеров в течение месяца,

00:06:19.857 --> 00:06:24.218
и компьютер самостоятельно определил,
что такое люди и кошки,

00:06:24.218 --> 00:06:26.027
на основе только видеоматериалов.

00:06:26.027 --> 00:06:28.379
Это очень похоже на то,
как учатся люди.

00:06:28.379 --> 00:06:31.119
Им не говорят, что они видят.

00:06:31.119 --> 00:06:34.450
Люди сами разбираются, что они видят.

00:06:34.450 --> 00:06:37.819
В том же 2012 году Джеффри Хинтон,
которого вы уже знаете,

00:06:37.819 --> 00:06:40.677
победил в очень известном
конкурсе ImageNet,

00:06:40.677 --> 00:06:44.818
в котором необходимо распознать,
что изображено

00:06:44.818 --> 00:06:46.256
на 1,5 миллионах картинок.

00:06:46.256 --> 00:06:49.789
К 2014 году количество ошибок
в распознавании образов

00:06:49.789 --> 00:06:51.242
сократилось до 6%.

00:06:51.242 --> 00:06:53.268
И опять же, это лучше, чем у людей.

00:06:53.268 --> 00:06:57.037
Эффективность компьютеров действительно
невероятно высока,

00:06:57.037 --> 00:06:59.306
и сейчас это применяется
в коммерческих целях.

00:06:59.306 --> 00:07:02.348
Так, в прошлом году в Google объявили,

00:07:02.348 --> 00:07:06.933
что их карты могут локализовать
любую точку во Франции за два часа:

00:07:06.933 --> 00:07:10.380
они обрабатывают фотографии улиц

00:07:10.380 --> 00:07:14.699
с помощью алгоритма глубинного обучения,
чтобы распознать и прочитать адреса.

00:07:14.699 --> 00:07:16.919
Подумайте, сколько времени
это заняло бы:

00:07:16.919 --> 00:07:20.274
понадобились бы десятки людей
и несколько лет.

00:07:20.274 --> 00:07:22.185
То же самое происходит в Китае.

00:07:22.185 --> 00:07:26.221
Baidu — это что-то вроде
китайского Google,

00:07:26.221 --> 00:07:28.504
и сверху слева вы видите картинку,

00:07:28.504 --> 00:07:32.478
которую я загрузил на вход
алгоритмов глубинного обучения Baidu,

00:07:32.478 --> 00:07:36.247
а под ней — то, как система распознала,
что изображено на картинке,

00:07:36.247 --> 00:07:38.483
и нашла похожие.

00:07:38.483 --> 00:07:41.219
Похожие изображения имеют похожий фон,

00:07:41.219 --> 00:07:42.877
морды смотрят в ту же сторону,

00:07:42.877 --> 00:07:44.665
иногда даже так же высунут язык.

00:07:44.665 --> 00:07:47.695
Это не просто поиск текста
на веб-странице.

00:07:47.695 --> 00:07:49.107
Я загрузил только картинку.

00:07:49.107 --> 00:07:53.128
Итак, теперь наши компьютеры 
действительно понимают увиденное

00:07:53.128 --> 00:07:54.752
и могут искать информацию в базах

00:07:54.752 --> 00:07:58.306
среди сотен миллионов картинок
в режиме реального времени.

00:07:58.306 --> 00:08:01.536
Значит ли это,
что компьютеры могут видеть?

00:08:01.536 --> 00:08:03.553
Это не просто умение видеть.

00:08:03.553 --> 00:08:05.622
Глубинное обучение — это намного больше.

00:08:05.622 --> 00:08:08.570
Сложные предложения со множеством
смысловых оттенков

00:08:08.570 --> 00:08:11.394
теперь понятны благодаря
алгоритмам глубинного обучения.

00:08:11.394 --> 00:08:12.687
Как видно на экране,

00:08:12.697 --> 00:08:15.975
эта стэнфордская система распознаёт
отрицательные эмоции в предложении

00:08:15.975 --> 00:08:19.384
и отмечает их красными точками сверху.

00:08:19.384 --> 00:08:22.790
Глубинное обучение
похоже на человеческое поведение

00:08:22.802 --> 00:08:27.923
в процессе распознавания того,
что и о чём сказано.

00:08:27.923 --> 00:08:30.651
Глубинное обучение использовалось
для чтения на китайском.

00:08:30.651 --> 00:08:33.807
Результат был на уровне результата
человека — носителя китайского.

00:08:33.807 --> 00:08:35.975
Этот алгоритм
был разработан в Швейцарии

00:08:35.975 --> 00:08:39.331
людьми, ни один из которых
не говорит по-китайски.

00:08:39.331 --> 00:08:41.382
Как я и сказал, глубинное обучение —

00:08:41.382 --> 00:08:43.601
это оптимальный способ
решения таких задач,

00:08:43.601 --> 00:08:48.718
даже по сравнению
с человеческим восприятием.

00:08:48.718 --> 00:08:51.542
На экране система,
разработаная в моей компании,

00:08:51.542 --> 00:08:53.728
в ней задействовано всё,
о чём я рассказал.

00:08:53.728 --> 00:08:56.189
Это картинки без описаний.

00:08:56.189 --> 00:08:58.541
Здесь я набираю предложения.

00:08:58.541 --> 00:09:01.510
В режиме реального времени
картинки распознаются,

00:09:01.510 --> 00:09:03.189
определяется их смысл,

00:09:03.189 --> 00:09:06.352
и находятся изображения,
соответствующие введённому мной тексту.

00:09:06.352 --> 00:09:09.108
Итак, вы видите, что предложения

00:09:09.108 --> 00:09:11.332
и картинки действительно распознаются.

00:09:11.332 --> 00:09:13.891
Я знаю, что вы видели
нечто похожее в Google,

00:09:13.891 --> 00:09:16.666
при вводе запроса,
по которому вам выдаются картинки,

00:09:16.666 --> 00:09:20.090
но в действительности там идёт поиск
нужного текста на веб-странице.

00:09:20.090 --> 00:09:23.091
Распознавание образов —
это принципиально новый процесс.

00:09:23.091 --> 00:09:25.843
Распознавание стало доступно
компьютерным алгоритмам

00:09:25.843 --> 00:09:29.091
впервые несколько месяцев назад.

00:09:29.091 --> 00:09:33.182
Итак, компьютеры теперь могут
не только видеть, но и читать,

00:09:33.182 --> 00:09:36.947
и, как мы уже показали,
понимать услышанное.

00:09:36.947 --> 00:09:40.389
Вы вряд ли удивитесь, если я вам скажу,
что они умеют писать.

00:09:40.389 --> 00:09:45.172
Вот текст, который я вчера получил
с помощью алгоритма глубинного обучения.

00:09:45.172 --> 00:09:49.096
А вот текст, полученный
с помощью стэнфордского алгоритма.

00:09:49.096 --> 00:09:50.860
Каждое из этих предложений составлено

00:09:50.860 --> 00:09:55.109
алгоритмом глубинного обучения
для описания этих картинок.

00:09:55.109 --> 00:09:59.581
Алгоритм ещё не встречал понятия мужчины
в чёрной рубашке, играющего на гитаре.

00:09:59.581 --> 00:10:01.801
Но ему известны понятия

00:10:01.801 --> 00:10:03.400
человека, чёрного, гитары,

00:10:03.400 --> 00:10:07.694
и алгоритм независимо формулирует
связное описание этого изображения.

00:10:07.694 --> 00:10:11.196
Мы всё ещё не дотягиваем до уровня
человека, но мы уже близки.

00:10:11.196 --> 00:10:15.264
При испытаниях люди выбирают
описания, данные компьютером,

00:10:15.264 --> 00:10:16.791
в одном случае из четырёх.

00:10:16.791 --> 00:10:18.855
Эта система была создана
две недели назад,

00:10:18.855 --> 00:10:20.701
и, скорее всего, в течение года

00:10:20.701 --> 00:10:23.502
алгоритм покажет результаты
намного лучше человеческих,

00:10:23.502 --> 00:10:25.364
если будет развиваться в том же темпе.

00:10:25.364 --> 00:10:28.413
Итак, компьютеры могут ещё и писать.

00:10:28.413 --> 00:10:31.888
Складываем всё вместе,
и нам открываются невероятные возможности.

00:10:31.888 --> 00:10:33.380
Например, в медицине.

00:10:33.380 --> 00:10:35.905
Группа учёных из Бостона открыла

00:10:35.905 --> 00:10:38.854
десятки новых клинически значимых
особенностей опухолей;

00:10:38.854 --> 00:10:43.120
это поможет врачам
давать прогнозы онкобольным.

00:10:44.220 --> 00:10:46.516
Точно так же в Стэнфорде

00:10:46.516 --> 00:10:50.179
группа учёных, проанализиров опухоли
под увеличением,

00:10:50.179 --> 00:10:52.560
создала систему
на основе машинного обучения,

00:10:52.560 --> 00:10:55.142
которая работает лучше,
чем патологоанатомы,

00:10:55.142 --> 00:10:59.519
прогнозируя исход заболевания
у онкобольных.

00:10:59.519 --> 00:11:02.764
В обоих случаях алгоритмы давали
не только более точный результат,

00:11:02.764 --> 00:11:05.266
но и новые ценные открытия.

00:11:05.276 --> 00:11:06.781
В случае с радиологией

00:11:06.781 --> 00:11:09.876
это были новые клинические показатели,
понятные для людей.

00:11:09.876 --> 00:11:11.668
В случае с патологиями

00:11:11.668 --> 00:11:16.168
алгоритм установил,
что для постановки диагноза

00:11:16.168 --> 00:11:19.508
клетки вокруг опухоли так же важны,

00:11:19.508 --> 00:11:21.260
как и сами раковые клетки.

00:11:21.260 --> 00:11:26.621
Это противоречит всему, чему
патологоанатомов учили десятилетиями.

00:11:26.621 --> 00:11:29.913
В разработке обеих систем

00:11:29.913 --> 00:11:33.534
участвовали как эксперты-врачи,
так и специалисты по машинному обучению,

00:11:33.534 --> 00:11:36.275
но в прошлом году мы смогли преодолеть
и это ограничение.

00:11:36.275 --> 00:11:39.824
На экране пример распознавания
поражённых раком

00:11:39.824 --> 00:11:42.354
человеческих тканей под микроскопом.

00:11:42.354 --> 00:11:46.967
Система, изображённая на экране,
может определить их точнее,

00:11:46.967 --> 00:11:49.742
или так же точно, как и патологоанатом.

00:11:49.742 --> 00:11:53.134
В её основе — только метод
глубинного обучения.

00:11:53.134 --> 00:11:56.380
Она разработана людьми, не имеющими
никакого отношения к медицине.

00:11:56.730 --> 00:11:59.285
Или сегментация нейронов.

00:11:59.285 --> 00:12:02.953
Теперь мы можем сегментировать нейроны
так же точно, как и вручную,

00:12:02.953 --> 00:12:05.670
и эта система так же была основана
на глубинном обучении

00:12:05.670 --> 00:12:08.921
и разработана людьми, не имеющими
медицинских знаний или опыта.

00:12:08.921 --> 00:12:12.148
Поэтому я, как человек,
никогда не занимавшийся медициной,

00:12:12.148 --> 00:12:15.875
оказался отличным кандидатом на роль
основателя новой медицинской компании.

00:12:15.875 --> 00:12:18.021
Им я и стал.

00:12:18.021 --> 00:12:19.761
Я порядком трусил,

00:12:19.761 --> 00:12:22.650
но в теории можно было

00:12:22.650 --> 00:12:28.142
разрабатывать очень полезные препараты,
используя только анализ данных.

00:12:28.142 --> 00:12:30.622
И — слава богу —
отзывы превзошли все мои ожидания,

00:12:30.622 --> 00:12:32.978
не только в СМИ,
но и от медицинского сообщества,

00:12:32.978 --> 00:12:35.322
где горячо поддержали мою идею.

00:12:35.322 --> 00:12:39.471
Идея заключается в том, что мы можем
взять промежуточный этап лечения

00:12:39.471 --> 00:12:42.364
и максимально применить к нему
наши способы анализа данных,

00:12:42.364 --> 00:12:45.429
позволив врачам заниматься тем,
что у них получается лучше всего.

00:12:45.429 --> 00:12:47.031
Приведу пример.

00:12:47.031 --> 00:12:51.975
На составление нового диагностического
теста у нас уходит 15 минут.

00:12:51.975 --> 00:12:53.929
Я покажу это в режиме реального времени,

00:12:53.929 --> 00:12:57.416
но сокращу процесс до трёх минут,
вырезав отдельные фрагменты.

00:12:57.416 --> 00:13:00.477
Вместо медицинских терминов

00:13:00.477 --> 00:13:03.846
будут изображения машин,

00:13:03.846 --> 00:13:06.068
потому что так будет понятнее всем.

00:13:06.068 --> 00:13:09.269
Итак, начнём с 1,5 миллионов
изображений машин.

00:13:09.269 --> 00:13:12.475
Я хочу придумать, как их разбить
на группы в зависимости от угла,

00:13:12.475 --> 00:13:14.698
с которого они сфотографированы.

00:13:14.698 --> 00:13:18.586
Ни одна из картинок не имеет описания,
поэтому мне придётся начинать с нуля.

00:13:18.586 --> 00:13:20.451
Наш алгоритм глубинного обучения

00:13:20.451 --> 00:13:24.158
автоматически распознаёт отдельные
компоненты на этих изображениях.

00:13:24.158 --> 00:13:27.778
Хорошо то, что человек и компьютер
могут решать задачу вместе.

00:13:27.778 --> 00:13:29.956
Человек, как вы видите,

00:13:29.956 --> 00:13:32.631
задаёт компьютеру исследуемую область,

00:13:32.631 --> 00:13:37.281
на основе которой компьютер должен
усовершенствовать свои алгоритмы.

00:13:37.281 --> 00:13:41.577
Такая система глубинного обучения работает
в 16 000-мерном пространстве.

00:13:41.577 --> 00:13:45.009
Компьютер вращает в нём данные,

00:13:45.009 --> 00:13:47.001
чтобы обнаружить новые структуры.

00:13:47.001 --> 00:13:48.782
А когда он их находит,

00:13:48.782 --> 00:13:52.786
человек, управляющий процессом,
указывает на те, что его интересуют.

00:13:52.786 --> 00:13:55.208
Итак, компьютер успешно
обнаруживает признаки,

00:13:55.208 --> 00:13:57.770
например, ракурс.

00:13:57.770 --> 00:13:59.376
В ходе исследования

00:13:59.376 --> 00:14:01.716
мы постепенно уточняем,

00:14:01.716 --> 00:14:04.144
что именно мы ищем.

00:14:04.144 --> 00:14:05.916
Представьте диагностический тест,

00:14:05.916 --> 00:14:09.266
благодаря которому врач
определяет границы патологии

00:14:09.266 --> 00:14:14.292
или радиолог — потенциально
опасные образования.

00:14:14.292 --> 00:14:16.851
Иногда алгоритм
не может справиться с задачей.

00:14:16.851 --> 00:14:18.815
Он не находит решения.

00:14:18.815 --> 00:14:21.365
Здесь капоты и багажники машин
идут вперемешку.

00:14:21.365 --> 00:14:23.437
Поэтому нам надо быть немного аккуратнее

00:14:23.437 --> 00:14:26.669
и разделить их вручную,

00:14:26.669 --> 00:14:32.175
а затем задать компьютеру тип изображений,

00:14:32.175 --> 00:14:33.523
которые нам нужны.

00:14:33.523 --> 00:14:36.200
Процесс идёт какое-то время,
пропустим немного,

00:14:36.200 --> 00:14:38.446
а потом мы обучаем наш алгоритм

00:14:38.446 --> 00:14:40.420
на основе двух объектов из сотен

00:14:40.420 --> 00:14:42.445
и надеемся, что он это усвоил.

00:14:42.445 --> 00:14:45.518
Видите, некоторые
из этих картинок поблёкли.

00:14:45.518 --> 00:14:50.226
Это означает, что теперь компьютер
распознаёт их самостоятельно.

00:14:50.226 --> 00:14:53.128
Теперь мы можем использовать
этот принцип похожих изображений.

00:14:53.128 --> 00:14:55.222
Как видите, используя эти изображения,

00:14:55.222 --> 00:14:59.241
компьютер может самостоятельно
находить только фотографии машин спереди.

00:14:59.241 --> 00:15:02.189
Теперь человек может сказать компьютеру:

00:15:02.189 --> 00:15:04.482
«Отлично, ты молодец».

00:15:05.652 --> 00:15:07.837
Иногда, конечно, даже на этом этапе

00:15:07.837 --> 00:15:11.511
всё ещё сложно выделить группы.

00:15:11.511 --> 00:15:15.395
В этом случае даже после дополнительного
вращения данных компьютером

00:15:15.399 --> 00:15:18.744
снимки машин, сделанные справа и слева,

00:15:18.744 --> 00:15:20.222
всё ещё идут вперемешку.

00:15:20.222 --> 00:15:22.362
Мы снова даём компьютеру подсказки,

00:15:22.362 --> 00:15:25.338
чтобы он нашёл плоскость,
которая разделит

00:15:25.338 --> 00:15:27.945
изображения автомобилей
справа и слева предельно точно

00:15:27.945 --> 00:15:30.067
на основе алгоритма глубинного обучения.

00:15:30.067 --> 00:15:33.009
И с этими подсказками — о, отлично,
решение найдено.

00:15:33.009 --> 00:15:35.891
Компьютер ищет, чем эти объекты

00:15:35.891 --> 00:15:38.271
отличаются от остальных.

00:15:38.271 --> 00:15:40.709
Это суть метода.

00:15:40.709 --> 00:15:48.906
Компьютер не заменяет человека,

00:15:48.906 --> 00:15:51.546
здесь они работают вместе.

00:15:51.546 --> 00:15:55.096
То, на что команда

00:15:55.096 --> 00:15:57.098
из 5—6 человек потратила бы около 7 лет,

00:15:57.098 --> 00:15:59.703
мы заменяем 15-минутной процедурой,

00:15:59.703 --> 00:16:02.208
которую выполняет всего один человек.

00:16:02.208 --> 00:16:06.158
Этот процесс выполняется
за 4—5 рабочих циклов.

00:16:06.158 --> 00:16:08.017
Как видите, теперь из наших

00:16:08.017 --> 00:16:10.976
1,5 миллионов изображений
верно классифицированы 62%.

00:16:10.976 --> 00:16:13.448
Теперь мы сможем быстро выделять

00:16:13.448 --> 00:16:14.745
отдельные большие блоки

00:16:14.745 --> 00:16:17.664
и просматривать их, чтобы убедиться,
что в них нет ошибок.

00:16:17.664 --> 00:16:21.616
Если возникают ошибки,
мы указываем на них компьютеру.

00:16:21.616 --> 00:16:24.661
Применяя эту процедуру
к разным группам по отдельности,

00:16:24.661 --> 00:16:27.148
мы получаем
около 80% верных результатов

00:16:27.148 --> 00:16:29.563
при распределении
1,5 миллионов изображений.

00:16:29.563 --> 00:16:31.641
Сейчас задача состоит только в том,

00:16:31.641 --> 00:16:35.220
чтобы найти те немногочисленные
неверно распознаные изображения,

00:16:35.220 --> 00:16:38.108
и понять, почему это произошло.

00:16:38.108 --> 00:16:39.851
Используя этот метод,

00:16:39.851 --> 00:16:43.972
за 15 минут мы получаем
результат, верный на 97%.

00:16:43.972 --> 00:16:48.572
Эта техника поможет нам справиться
с одной из важнейших проблем —

00:16:48.578 --> 00:16:51.614
нехваткой медицинских работников в мире.

00:16:51.614 --> 00:16:55.103
По данным, озвученным на Всемирном
экономическом форуме,

00:16:55.103 --> 00:16:57.777
развивающимся странам
нужно в 10—20 раз больше терапевтов

00:16:57.777 --> 00:16:59.840
и понадобится около 300 лет,

00:16:59.840 --> 00:17:02.734
чтобы обучить нужное количество людей.

00:17:02.734 --> 00:17:05.619
А теперь представьте,
что мы повысим их эффективность,

00:17:05.619 --> 00:17:08.458
используя глубинное обучение.

00:17:08.458 --> 00:17:10.690
Эти возможности приводят меня
в полный восторг,

00:17:10.690 --> 00:17:13.279
но в то же время
я отдаю отчёт в последствиях.

00:17:13.279 --> 00:17:16.403
Проблема в том, что во всех странах,
отмеченных на карте синим,

00:17:16.403 --> 00:17:20.172
80% рабочих мест приходится
на сферу услуг.

00:17:20.172 --> 00:17:21.959
Каких услуг?

00:17:21.959 --> 00:17:23.473
Вот этих услуг.

00:17:23.473 --> 00:17:27.627
А это именно то, что компьютеры
только что научились делать.

00:17:27.627 --> 00:17:31.431
Если 80% людей в развитых странах

00:17:31.431 --> 00:17:33.963
заняты тем, что теперь
умеет компьютер,

00:17:33.963 --> 00:17:35.403
то что это значит?

00:17:35.403 --> 00:17:37.986
Всё в порядке. Они сменят работу.

00:17:37.986 --> 00:17:40.693
Например, будет больше работы
для аналитиков данных.

00:17:40.693 --> 00:17:41.560
Ну или не совсем.

00:17:41.560 --> 00:17:44.628
Решение этих задач не займёт
у них много времени.

00:17:44.628 --> 00:17:47.880
Например, эти четыре алгоритма
создал один и тот же человек.

00:17:47.880 --> 00:17:50.318
Вы скажете, что человечество
с этим уже сталкивалось.

00:17:50.318 --> 00:17:54.126
В прошлом мы видели,
что когда приходят новые технологии,

00:17:54.126 --> 00:17:56.378
новые профессии приходят на смену старым,

00:17:56.378 --> 00:17:58.494
но что это будут за новые профессии?

00:17:58.494 --> 00:18:00.365
Нам очень сложно сейчас это оценить,

00:18:00.365 --> 00:18:03.274
ведь производительность человеческого
труда растёт постепенно.

00:18:03.274 --> 00:18:05.666
Однако теперь есть система
глубинного обучения,

00:18:05.666 --> 00:18:08.893
и мы знаем, что её возможности
растут по экспоненте.

00:18:08.893 --> 00:18:10.498
Итак,

00:18:10.498 --> 00:18:12.559
мы оглядываемся по сторонам:

00:18:12.559 --> 00:18:15.235
«Ведь компьютеры всё ещё
достаточно примитивны». Верно?

00:18:15.235 --> 00:18:18.664
Но через пять лет их возможности выйдут
за границы этого графика.

00:18:18.664 --> 00:18:21.999
Поэтому нам необходимо начать обдумывать
этот аспект прямо сейчас.

00:18:21.999 --> 00:18:24.579
Разумеется, такое уже случалось
в истории человечества.

00:18:24.579 --> 00:18:25.966
Промышленная революция,

00:18:25.966 --> 00:18:28.817
благодаря двигателям, дала
качественный скачок производства.

00:18:29.667 --> 00:18:32.805
Однако спустя какое-то время
мощности перестали расти.

00:18:32.805 --> 00:18:34.507
Случился социальный взрыв,

00:18:34.507 --> 00:18:37.946
но когда двигатели стали применяться
в промышленности повсеместно,

00:18:37.946 --> 00:18:40.300
был найден баланс.

00:18:40.300 --> 00:18:41.773
Революция машинного обучения

00:18:41.773 --> 00:18:44.682
будет сильно отличаться
от промышленной революции,

00:18:44.682 --> 00:18:47.632
потому что революция
машинного обучения непрерывна.

00:18:47.632 --> 00:18:50.614
Чем более интеллектуально
развиты компьютеры,

00:18:50.614 --> 00:18:54.862
тем более интеллектуально
развитые компьютеры они создают.

00:18:54.862 --> 00:18:56.770
А это приведёт к тому,

00:18:56.770 --> 00:18:59.248
с чем наш мир
никогда раньше не сталкивался,

00:18:59.248 --> 00:19:02.554
и ваши прошлые представления
о возможном изменятся.

00:19:02.974 --> 00:19:04.754
Мы это уже почувствовали на себе.

00:19:04.754 --> 00:19:08.384
В течение последней четверти века
производительность оборудования росла,

00:19:08.400 --> 00:19:12.588
в то время как производительность рабочих
оставалась прежней или немного снижалась.

00:19:13.408 --> 00:19:16.149
Я хочу, чтобы мы уже сейчас
задумались над этим.

00:19:16.149 --> 00:19:19.176
Когда я рассказываю об этом людям,

00:19:19.176 --> 00:19:20.666
они зачастую мне не верят:

00:19:20.666 --> 00:19:22.339
мол, компьютеры не могут думать,

00:19:22.339 --> 00:19:25.367
переживать, воспринимать стихи.

00:19:25.367 --> 00:19:27.888
Мы не понимаем по-настоящему,
как они работают.

00:19:27.888 --> 00:19:29.374
И что?

00:19:29.374 --> 00:19:31.178
Уже сейчас компьютеры
делают то,

00:19:31.178 --> 00:19:33.897
на что люди тратят бóльшую часть
оплачиваемого времени,

00:19:33.897 --> 00:19:35.628
так что теперь пора думать над тем,

00:19:35.628 --> 00:19:40.015
как мы будем адаптировать наши
социальные и экономические структуры,

00:19:40.015 --> 00:19:41.855
чтобы быть готовыми
к новой реальности.

00:19:41.855 --> 00:19:43.388
Спасибо.

00:19:43.388 --> 00:19:44.190
(Аплодисменты)

