WEBVTT
Kind: captions
Language: sv

00:00:00.000 --> 00:00:07.000
Översättare: Hanna Lagerquist
Granskare: Annika Bidner

00:00:12.880 --> 00:00:16.893
Det brukade vara så att om du ville
få en dator att göra något nytt

00:00:16.893 --> 00:00:18.447
så behövde du programmera den.

00:00:18.447 --> 00:00:21.858
Programmering, för dem av er
som inte har gjort det själva,

00:00:21.858 --> 00:00:23.307
kräver att man

00:00:23.307 --> 00:00:25.846
på ett olidligt detaljerat sätt

00:00:25.846 --> 00:00:28.727
anger varenda steg
man vill att datorn ska ta

00:00:28.727 --> 00:00:31.089
för att uppnå önskat mål.

00:00:31.089 --> 00:00:34.585
Men, om du vill göra något
som du inte vet själv hur man gör,

00:00:34.585 --> 00:00:36.648
då blir det här en enorm utmaning.

00:00:36.648 --> 00:00:40.131
Så det här var den utmaning som denne man,
Arthur Samuel, ställdes inför.

00:00:40.131 --> 00:00:44.208
1956 ville han få sin dator till

00:00:44.208 --> 00:00:46.548
att slå honom i spelet Dam.

00:00:46.548 --> 00:00:48.588
Hur kan du skriva ett program,

00:00:48.588 --> 00:00:52.394
och ange på ett olidligt detaljerat sätt,
hur det ska slå dig i Dam?

00:00:52.394 --> 00:00:54.116
Så han kom på en idé:

00:00:54.116 --> 00:00:57.840
han lät datorn spela
mot sig själv tusentals gånger

00:00:57.840 --> 00:01:00.364
och lära sig att spela Dam.

00:01:00.804 --> 00:01:03.544
Och det fungerade faktiskt, och vid 1962

00:01:03.544 --> 00:01:06.956
hade datorn slagit
Connecticuts statsmästare.

00:01:07.301 --> 00:01:10.534
Så Arthur Samuels
var maskininlärningens fader,

00:01:10.534 --> 00:01:12.211
och jag är skyldig honom så mycket,

00:01:12.211 --> 00:01:15.014
för att jag är verksam
inom maskininlärning.

00:01:15.014 --> 00:01:16.479
Jag var ordförande i Kaggle,

00:01:16.479 --> 00:01:19.867
en gemenskap på över 200 000
verksamma inom maskininlärning.

00:01:19.867 --> 00:01:21.925
Kaggle anordnar tävlingar

00:01:21.925 --> 00:01:25.633
för att försöka åstadkomma
lösningar på olösta problem,

00:01:25.633 --> 00:01:29.001
och det har varit framgångsrikt
vid hundratals tillfällen.

00:01:29.470 --> 00:01:31.940
Så från den synvinkeln
kunde jag få veta

00:01:31.940 --> 00:01:35.890
väldigt mycket om vad maskininlärning
kan göra i det förflutna, kan göra idag,

00:01:35.890 --> 00:01:38.252
och vad den kan tänkas göra i framtiden.

00:01:38.252 --> 00:01:41.472
Maskininlärningens första stora framgång

00:01:41.472 --> 00:01:42.942
var kanske Google.

00:01:42.942 --> 00:01:45.784
Google visade att det är möjligt
att få fram information

00:01:45.784 --> 00:01:47.536
genom att använda en datoralgoritm,

00:01:47.536 --> 00:01:50.437
en datoralgoritm som bygger
på maskininlärning.

00:01:50.437 --> 00:01:54.323
Sen dess har maskininlärning
rönt många kommersiella framgångar.

00:01:54.323 --> 00:01:55.970
Företag som Amazon och Netflix

00:01:55.970 --> 00:01:58.392
använder maskininlärning
för att föreslå produkter

00:01:58.392 --> 00:01:59.984
som du kan tänkas vilja köpa,

00:01:59.984 --> 00:02:01.896
filmer som du kan tänkas vilja se.

00:02:01.896 --> 00:02:03.523
Ibland är det nästan lite läskigt.

00:02:03.523 --> 00:02:05.447
Företag som LinkedIn och Facebook

00:02:05.447 --> 00:02:08.301
kan ibland berätta för dig
vilka dina vänner kan tänkas vara

00:02:08.301 --> 00:02:10.608
och du kan inte föreställa dig
hur det gick till

00:02:10.608 --> 00:02:13.335
och det beror på att de använder
maskininlärningens kraft.

00:02:13.335 --> 00:02:16.512
Det här är algoritmer som har lärt sig
att göra detta utifrån data

00:02:16.512 --> 00:02:19.399
snarare än att ha blivit
programmerade till det.

00:02:19.399 --> 00:02:21.877
Det här också hemligheten
bakom IBM:s framgångar

00:02:21.877 --> 00:02:25.739
med att få Watson att slå
de två världsmästarna i Jeopardy,

00:02:25.739 --> 00:02:28.964
genom att besvara otroligt subtila
och komplexa frågor som den här.

00:02:28.964 --> 00:02:31.799
[Det antika "Lion of Nimrud" försvann
från denna stads ...]

00:02:31.799 --> 00:02:35.034
Det här är också anledningen till
att vi nu ser självkörande bilar.

00:02:35.034 --> 00:02:37.856
Om du vill kunna skilja på till exempel

00:02:37.856 --> 00:02:40.488
ett träd och en fotgängare
så är det ganska viktigt.

00:02:40.488 --> 00:02:43.105
Vi vet inte hur vi skulle kunna
programmera något sånt,

00:02:43.105 --> 00:02:46.072
men med maskininlärning 
är det här nu möjligt.

00:02:46.072 --> 00:02:48.800
Och den här bilen har faktiskt
kört över 1,5 miljoner mil,

00:02:48.800 --> 00:02:51.856
utan olyckor, på vanliga vägar.

00:02:52.196 --> 00:02:56.110
Så nu vet vi att datorer kan lära sig,

00:02:56.110 --> 00:02:58.010
och datorer kan lära sig att göra saker

00:02:58.010 --> 00:03:00.848
som vi ibland faktiskt själva
inte vet hur man gör,

00:03:00.848 --> 00:03:03.733
eller så kan de göra något
bättre än vi.

00:03:03.733 --> 00:03:07.928
Ett av det mer häpnadsväckande exemplen
av maskininlärning som jag har sett

00:03:07.928 --> 00:03:10.320
tog plats i ett projekt
som jag körde på Kaggle

00:03:10.320 --> 00:03:13.911
där ett lag som leddes av en kille
som heter Geoffrey Hinton

00:03:13.911 --> 00:03:15.463
från University of Toronto

00:03:15.463 --> 00:03:18.140
vann en tävling
i automatisk medicinforskning.

00:03:18.140 --> 00:03:20.987
Men vad som var exceptionellt
var inte bara att de slog

00:03:20.987 --> 00:03:25.000
alla Mercks algoritmer och hela den
internationella akademiska gemenskapen,

00:03:25.000 --> 00:03:30.061
utan att ingen i laget hade någon bakgrund
i kemi, biologi eller livsvetenskap

00:03:30.061 --> 00:03:32.230
och de klarade det på två veckor.

00:03:32.230 --> 00:03:33.961
Hur gjorde de detta?

00:03:34.421 --> 00:03:37.342
De använde en enastående algoritm
som kallas djupinlärning.

00:03:37.342 --> 00:03:40.291
Det här var så viktigt
att det till och med rapporterades

00:03:40.291 --> 00:03:43.412
på framsidan till New York Times
några veckor senare.

00:03:43.412 --> 00:03:46.147
Här är Geoffrey Hinton till vänster.

00:03:46.147 --> 00:03:50.488
Djupinlärningsalgoritmen
är inspirerad av hur hjärnan fungerar

00:03:50.488 --> 00:03:52.300
och som en effekt av det

00:03:52.300 --> 00:03:55.921
så har den inga teoretiska begränsningar
i vad den kan åstadkomma.

00:03:55.921 --> 00:03:58.964
Ju mer data och beräkningstid du ger den,

00:03:58.964 --> 00:04:00.276
desto bättre blir den.

00:04:00.276 --> 00:04:02.615
New York Times visade
i sin artikel också på

00:04:02.615 --> 00:04:04.857
en annan exceptionell effekt
av djupinlärning

00:04:04.857 --> 00:04:07.075
som jag ska visa er nu.

00:04:07.569 --> 00:04:12.073
Den visar att datorer
kan lyssna och förstå.

00:04:12.510 --> 00:04:15.221
(Video) Richard Rashid: Det sista steget

00:04:15.221 --> 00:04:18.246
som jag vill kunna ta i den här processen

00:04:18.246 --> 00:04:22.295
är att kunna tala till er på kinesiska.

00:04:22.961 --> 00:04:25.596
Nyckeln här är att

00:04:25.596 --> 00:04:30.598
vi har kunnat ta en stor mängd information
från många som talar kinesiska

00:04:30.598 --> 00:04:33.128
och producera ett "text till tal"-system

00:04:33.128 --> 00:04:37.801
som tar kinesisk text
och konverterar den till kinesiskt språk.

00:04:38.471 --> 00:04:41.929
Sen har vi tagit en timme
eller så av min egen röst

00:04:41.929 --> 00:04:43.820
och vi har använt den till att modulera

00:04:43.820 --> 00:04:48.364
vårt grundläggande "text till tal"-system
så att det låter som jag.

00:04:48.364 --> 00:04:50.904
Återigen, resultatet är inte perfekt.

00:04:51.344 --> 00:04:53.552
Det finns fortfarande några fel.

00:04:53.552 --> 00:04:56.036
(Kinesiska)

00:04:56.036 --> 00:04:59.023
(Applåder)

00:05:01.446 --> 00:05:04.343
Det finns mycket att göra
på det här området.

00:05:05.022 --> 00:05:08.007
(Kinesiska)

00:05:08.667 --> 00:05:11.640
(Applåder)

00:05:13.345 --> 00:05:16.744
Jeremy Howard: Det där var
på en maskininlärningskonferens i Kina.

00:05:16.744 --> 00:05:19.154
Det är faktiskt inte ofta
på akademiska konferenser

00:05:19.154 --> 00:05:21.011
att man hör spontana applåder,

00:05:21.011 --> 00:05:24.687
fast på TEDx-konferenser
är det förstås välkommet.

00:05:24.687 --> 00:05:27.482
Allt ni såg där hände
med hjälp av maskininlärning.

00:05:27.482 --> 00:05:28.407
(Applåder) Tack.

00:05:28.407 --> 00:05:30.719
Avskriften till engelska
var djupinlärning.

00:05:30.719 --> 00:05:34.421
Översättningen till kinesiska och texten
i övre högra hörnet vad djupinlärning

00:05:34.421 --> 00:05:37.758
och skapandet av rösten
var också djupinlärning.

00:05:38.598 --> 00:05:41.122
Så djupinlärning är en exceptionell sak.

00:05:41.122 --> 00:05:44.461
Det är en enda algoritm som ser ut
att kunna göra nästan vad som helst,

00:05:44.461 --> 00:05:47.712
och jag upptäckte att ett år tidigare
hade den också lärt sig att se.

00:05:47.712 --> 00:05:49.298
I en obskyr tävling från Tyskland

00:05:49.298 --> 00:05:51.745
som hette German Traffic Sign
Recognition Benchmark,

00:05:51.745 --> 00:05:55.148
hade djupinlärning lärt sig
att känna igen trafikskyltar som den här.

00:05:55.148 --> 00:05:57.302
Den kunde inte bara
känna igen trafikskyltarna

00:05:57.302 --> 00:05:59.050
bättre än alla andra algoritmer,

00:05:59.050 --> 00:06:02.199
utan resultattavlan visade
att den faktiskt var bättre än människor

00:06:02.199 --> 00:06:03.981
ungefär dubbelt så bra som människor.

00:06:03.981 --> 00:06:06.167
Vid 2011 hade vi det första exemplet

00:06:06.167 --> 00:06:09.122
på en dator som kan se
bättre än människor.

00:06:09.442 --> 00:06:11.491
Sen dess har det hänt många saker.

00:06:11.491 --> 00:06:15.005
2012 meddelade Google att de hade
låtit en djupinlärningsalgoritm

00:06:15.005 --> 00:06:16.420
titta på YouTube-klipp

00:06:16.420 --> 00:06:19.857
och beräknade datan
på 16 000 datorer i en månad.

00:06:19.857 --> 00:06:24.218
Och datorn lärde sig, helt av sig själv,
om koncept som människor och katter

00:06:24.218 --> 00:06:25.907
bara genom att titta på klippen.

00:06:25.907 --> 00:06:28.379
Det här är väldigt likt
den mänskliga lärprocessen.

00:06:28.379 --> 00:06:31.199
Människor lär sig inte genom
att någon berättar vad de ser,

00:06:31.199 --> 00:06:34.060
utan de lär sig själva
vad de här sakerna är.

00:06:34.450 --> 00:06:37.819
2012 vann George Hinton,
som vi såg tidigare, också

00:06:37.819 --> 00:06:40.677
den väldigt populära ImageNet-tävlingen,

00:06:40.677 --> 00:06:44.818
när han försökte lista ut,
på basis av 1,5 miljoner bilder,

00:06:44.818 --> 00:06:46.256
vad bilderna innehöll.

00:06:46.256 --> 00:06:49.789
Nu 2014, är vi nere på
en sexprocentig felmarginal

00:06:49.789 --> 00:06:51.242
för bildigenkänning.

00:06:51.242 --> 00:06:53.268
Detta är, återigen, bättre än människor.

00:06:53.268 --> 00:06:57.037
Så maskiner gör verkligen
ett exceptionellt bra jobb här

00:06:57.037 --> 00:06:59.306
och används nu inom industrin.

00:06:59.306 --> 00:07:02.348
Till exempel meddelade Google förra året

00:07:02.348 --> 00:07:06.933
att de hade mappat varenda plats
i Frankrike på två timmar.

00:07:06.933 --> 00:07:10.180
Och de gjorde detta genom
att föda bilder av gatuvyer

00:07:10.180 --> 00:07:13.019
in i en djupinlärningsalgoritm
för att den skulle känna igen

00:07:13.019 --> 00:07:14.738
och läsa gatunummer.

00:07:14.738 --> 00:07:17.059
Föreställ er hur lång tid
detta skulle ha tagit:

00:07:17.059 --> 00:07:19.829
dussintals med människor, många år.

00:07:20.274 --> 00:07:22.185
Det här händer också i Kina.

00:07:22.185 --> 00:07:26.221
Baidu kan väl kanske sägas vara 
ett kinesiskt Google

00:07:26.221 --> 00:07:28.504
och vad ni ser här uppe till vänster

00:07:28.504 --> 00:07:30.755
är ett exempel på en bild
som jag laddade upp

00:07:30.755 --> 00:07:32.746
i Baidus djupinlärningssystem,

00:07:32.746 --> 00:07:36.247
och nedanför kan ni se att systemet
har förstått vad bilden innehåller

00:07:36.247 --> 00:07:38.483
och hittat liknande bilder.

00:07:38.483 --> 00:07:41.219
De liknande bilderna har faktiskt
liknande bakgrunder,

00:07:41.219 --> 00:07:42.877
liknande ansiktsvinklar,

00:07:42.877 --> 00:07:44.935
till och med några med utstickande tungor.

00:07:44.935 --> 00:07:47.695
Det här handlar inte om att titta
på text på en webbsida.

00:07:47.695 --> 00:07:49.447
Allt jag laddade upp var en bild.

00:07:49.447 --> 00:07:52.958
Så, nu har vi datorer
som faktiskt förstår vad de ser

00:07:52.958 --> 00:07:54.752
och därmed kan söka igenom databaser

00:07:54.752 --> 00:07:57.964
med hundra miljontals bilder i realtid.

00:07:58.306 --> 00:08:01.436
Så vad betyder det nu att datorer kan se?

00:08:01.436 --> 00:08:03.553
Det betyder inte bara
att datorer kan se.

00:08:03.553 --> 00:08:05.622
Djupinlärning har faktiskt
gjort mer än så.

00:08:05.622 --> 00:08:07.756
Komplexa, nyanserade meningar

00:08:07.756 --> 00:08:09.650
som den här kan nu förstås

00:08:09.650 --> 00:08:11.394
med djupinlärningsalgoritmer.

00:08:11.394 --> 00:08:12.337
Som ni kan se här,

00:08:12.337 --> 00:08:15.685
så har det här Stanford-baserade systemet
med den röda pricken i toppen

00:08:15.685 --> 00:08:19.134
räknat ut att den här meningen
uttrycker negativa känslor.

00:08:19.134 --> 00:08:22.362
Djupinlärning är faktiskt nära
den mänskliga prestationsförmågan

00:08:22.362 --> 00:08:24.708
när det gäller att förstå
vad meningar handlar om

00:08:24.708 --> 00:08:27.426
och vad de säger om det.

00:08:28.034 --> 00:08:30.651
Djupinlärning har också använts
till att läsa kinesiska,

00:08:30.651 --> 00:08:33.807
på, återigen, nästan modersmålsnivå.

00:08:33.807 --> 00:08:35.975
Den här algoritmen
har utvecklats i Schweitz

00:08:35.975 --> 00:08:39.331
av människor som varken talar
eller förstår kinesiska.

00:08:39.331 --> 00:08:41.472
Jag brukar säga att,
att använda djupinlärning

00:08:41.472 --> 00:08:43.831
är nära nog det bästa systemet
i världen för detta

00:08:43.831 --> 00:08:48.175
även jämfört med
mänsklig modersmålsförståelse.

00:08:48.718 --> 00:08:51.682
Det här ett system som vi satte ihop
på mitt företag

00:08:51.682 --> 00:08:53.728
som visar hur allt det här sätts ihop.

00:08:53.728 --> 00:08:56.189
De här bilderna har ingen vidhängd text,

00:08:56.189 --> 00:08:58.541
och medan jag skriver in meningar här

00:08:58.541 --> 00:09:01.510
så förstår den de här bilderna i realtid

00:09:01.510 --> 00:09:03.189
och listar ut vad de handlar om

00:09:03.189 --> 00:09:06.352
och hittar bilder som liknar
den text som jag skriver in.

00:09:06.352 --> 00:09:09.108
Så ni kan se att den faktiskt
förstår mina meningar

00:09:09.108 --> 00:09:11.332
och faktiskt förstår de här bilderna.

00:09:11.332 --> 00:09:13.891
Jag vet att ni har sett
liknande saker på Google,

00:09:13.891 --> 00:09:16.666
där du kan skriva in saker
och den visar dig bilder,

00:09:16.666 --> 00:09:20.090
men vad den faktiskt gör är
att den söker av webbsidan efter text.

00:09:20.090 --> 00:09:22.751
Det är en stor skillnad
mot att förstå bilderna.

00:09:22.751 --> 00:09:25.183
Det här är något som datorer
har kunnat göra

00:09:25.183 --> 00:09:28.507
för första gången
för bara några månader sen.

00:09:29.091 --> 00:09:33.182
Så nu kan vi se att datorer
inte bara kan se, de kan också läsa,

00:09:33.182 --> 00:09:36.667
och så har vi också visat
att de kan förstå vad de hör.

00:09:36.667 --> 00:09:39.378
Kanske är det inte överraskande
att jag nu berättar för er

00:09:39.378 --> 00:09:40.569
att de kan skriva.

00:09:40.569 --> 00:09:42.811
Här är lite text som jag genererade igår

00:09:42.811 --> 00:09:45.330
med hjälp av en djupinlärningsalgoritm.

00:09:45.963 --> 00:09:49.096
Och här är lite text som en algoritm
från Stanford har genererat.

00:09:49.096 --> 00:09:51.170
Var och en av dessa meningar
har genererats

00:09:51.170 --> 00:09:55.109
av en djupinlärningsalgoritm
för att förklara varje bild.

00:09:55.109 --> 00:09:59.521
Den här algoritmen har aldrig förut sett
en man i svart tröja som spelar gitarr.

00:09:59.521 --> 00:10:01.951
Den har sett en man förut,
den har sett svart förut,

00:10:01.951 --> 00:10:03.400
den har sett en gitarr förut,

00:10:03.400 --> 00:10:07.304
men den har helt fristående genererat
den här nya beskrivningen av bilden.

00:10:07.304 --> 00:10:10.527
Vi är ännu inte riktigt framme
vid mänsklig prestationsförmåga här,

00:10:10.527 --> 00:10:11.480
men vi är nära.

00:10:11.480 --> 00:10:15.264
Tester har visat att människor föredrar
den datorgenererade förklaringen

00:10:15.264 --> 00:10:16.791
en av fyra gånger.

00:10:16.791 --> 00:10:18.985
Det här systemet är nu bara
två veckor gammalt,

00:10:18.985 --> 00:10:20.871
så det är sannolikt att datoralgoritmen

00:10:20.871 --> 00:10:22.878
kommer att slå mänsklig prestationsförmåga

00:10:22.878 --> 00:10:23.865
inom ett år

00:10:23.865 --> 00:10:25.364
om det fortsätter i samma takt.

00:10:25.364 --> 00:10:28.413
Så, datorer kan skriva också.

00:10:28.413 --> 00:10:31.888
När vi slår samman allt det här
så ser vi väldigt spännande möjligheter.

00:10:31.888 --> 00:10:33.380
Till exempel inom läkekonsten,

00:10:33.380 --> 00:10:35.905
ett team i Boston meddelade
att de hade upptäckt

00:10:35.905 --> 00:10:38.854
dussintals nya kliniskt
relevanta kännetecken

00:10:38.854 --> 00:10:43.440
på tumörer, som hjälper läkare
att göra cancerprognoser.

00:10:43.900 --> 00:10:46.266
Också liknande,
meddelade en grupp i Stanford

00:10:46.266 --> 00:10:50.799
att de, genom att titta på vävnad
under förstoring, hade utvecklat

00:10:50.799 --> 00:10:52.560
ett maskininlärningsbaserat system

00:10:52.560 --> 00:10:55.142
som faktiskt är bättre
än mänskliga patologer

00:10:55.142 --> 00:10:57.352
på att förutse överlevnadssiffror

00:10:57.372 --> 00:10:59.062
för cancersjuka.

00:10:59.062 --> 00:11:01.146
I båda dessa fall
visade sig förutsägelserna

00:11:01.146 --> 00:11:02.620
inte bara vara mer rättvisande

00:11:02.620 --> 00:11:05.266
utan de genererade också
ny insiktsfull kunskap.

00:11:05.276 --> 00:11:06.781
I röntgenfallet

00:11:06.781 --> 00:11:09.876
var det nya kliniska indikatorer
som människor kan förstå.

00:11:09.876 --> 00:11:11.668
I patologifallet

00:11:11.668 --> 00:11:16.168
upptäckte systemet
att cellerna runt cancern

00:11:16.168 --> 00:11:19.508
är lika viktiga som cancercellerna själva

00:11:19.508 --> 00:11:21.260
för att ställa diagnos.

00:11:21.260 --> 00:11:26.164
Det här var motsatsen till vad patologer
hade fått lära sig i årtionden.

00:11:27.131 --> 00:11:29.913
I båda dessa fall var systemen utvecklade

00:11:29.913 --> 00:11:33.414
av en kombination av medicinska experter
och maskininlärningsexperter,

00:11:33.414 --> 00:11:36.275
men sedan ett år tillbaka
har vi tagit oss förbi det också.

00:11:36.275 --> 00:11:39.614
Det här är ett exempel på hur man
identifierar cancerområden

00:11:39.614 --> 00:11:42.354
i mänsklig vävnad under ett mikroskåp.

00:11:42.354 --> 00:11:46.967
Systemet som visas här kan identifiera
de områdena med större exakthet,

00:11:46.967 --> 00:11:49.742
eller ungefär lika exakt,
som mänskliga patologer,

00:11:49.742 --> 00:11:53.134
fast det enbart bygger på djupinlärning
helt utan medicinsk expertis

00:11:53.134 --> 00:11:56.480
och har byggts av människor
som inte har någon erfarenhet på området.

00:11:56.730 --> 00:11:59.495
På liknande vis, här, det här med
segmentering av neuroner.

00:11:59.495 --> 00:12:02.633
Vi kan nu segmentera neuroner
ungefär lika exakt som människor kan,

00:12:02.633 --> 00:12:05.400
men det här systemet utvecklades
med hjälp av djupinlärning

00:12:05.400 --> 00:12:08.289
av människor utan erfarenhet av läkekonst.

00:12:08.981 --> 00:12:12.148
Så jag själv, som någon som inte har
någon erfarenhet av läkekonst,

00:12:12.148 --> 00:12:15.875
tycks vara helt kvalificerad för
att starta ett nytt medicinskt företag,

00:12:15.875 --> 00:12:18.021
vilket jag gjorde.

00:12:18.021 --> 00:12:20.041
Jag var en aning livrädd för att göra det,

00:12:20.041 --> 00:12:22.650
men teoretiskt sett borde det vara möjligt

00:12:22.650 --> 00:12:28.142
att praktisera nyttig läkekonst
bara på basis av dessa dataanalystekniker.

00:12:28.142 --> 00:12:30.622
Och som tur är har återkopplingen
varit fantastisk,

00:12:30.622 --> 00:12:32.978
inte bara från media
utan också från läkarkåren,

00:12:32.978 --> 00:12:34.996
som har varit väldigt stöttande.

00:12:35.322 --> 00:12:39.471
Teorin innebär att vi kan ta mittendelen
av den medicinska processen

00:12:39.471 --> 00:12:42.364
och göra om den till dataanalys
så långt det är möjligt,

00:12:42.364 --> 00:12:45.429
och på så sätt frigöra läkarna till
att göra det de är bäst på.

00:12:45.429 --> 00:12:47.031
Jag vill ge er ett exempel.

00:12:47.031 --> 00:12:49.330
Det tar oss nu ungefär 15 minuter

00:12:49.330 --> 00:12:52.069
att ta fram ett nytt
medicinskt diagnostiskt test

00:12:52.069 --> 00:12:53.829
och jag ska visa er det i realtid nu,

00:12:53.829 --> 00:12:55.961
men jag har komprimerat det
till tre minuter

00:12:55.961 --> 00:12:57.373
genom att skära bort en del.

00:12:57.373 --> 00:13:00.717
Snarare än att visa er hur man skapar
ett medicinskt diagnostiskt test,

00:13:00.717 --> 00:13:01.730
så vill jag visa er

00:13:01.730 --> 00:13:04.123
ett diagnostiskt test på bilbilder,

00:13:04.123 --> 00:13:06.268
eftersom det är något
som vi alla kan förstå.

00:13:06.268 --> 00:13:09.269
Så vi börjar med ungefär
1,5 miljoner bilbilder,

00:13:09.269 --> 00:13:12.475
och jag vill skapa något som kan sortera
dem beroende på vilken

00:13:12.475 --> 00:13:14.698
vinkel bilden är tagen ur.

00:13:14.698 --> 00:13:18.586
De här bilderna har inga etiketter,
så jag måste börja från början.

00:13:18.586 --> 00:13:20.451
Med vår djupinlärningsalgoritm

00:13:20.451 --> 00:13:24.158
kan den automatiskt identifiera områden
med struktur i bilderna.

00:13:24.158 --> 00:13:27.778
Det fina är att nu kan människan
och datorn samarbeta.

00:13:27.778 --> 00:13:29.956
Människan, som ni ser här,

00:13:29.956 --> 00:13:33.821
talar om för datorn vilka områden
som är intressanta, den information

00:13:33.821 --> 00:13:37.533
som hon vill att datorn använder
för att förbättra algoritmen.

00:13:37.915 --> 00:13:39.639
De här djupinlärningssystemen

00:13:39.639 --> 00:13:41.933
existerar faktiskt
i en 16000-dimensionell rymd,

00:13:41.933 --> 00:13:45.009
så ni kan här se hur datorn roterar
genom den rymden

00:13:45.009 --> 00:13:47.001
och letar efter nya strukturella områden.

00:13:47.001 --> 00:13:48.782
Och när den hittar ett sånt

00:13:48.782 --> 00:13:52.786
så kan människan som styr den påpeka
att dessa områden är intressanta.

00:13:52.786 --> 00:13:55.208
Så här har datorn lyckats hitta områden,

00:13:55.208 --> 00:13:57.550
till exempel vinklar.

00:13:57.550 --> 00:13:59.546
Så medan vi går igenom den här processen,

00:13:59.546 --> 00:14:01.716
så berättar vi gradvis
mer och mer för datorn

00:14:01.716 --> 00:14:04.144
om vilka strukturer vi letar efter.

00:14:04.144 --> 00:14:05.916
I ett diagnostiskt test

00:14:05.916 --> 00:14:09.266
skulle det här motsvara en patolog
som identifierar sjuka områden

00:14:09.266 --> 00:14:14.292
eller en radiolog som identifierar
potentiellt farliga knutor.

00:14:14.292 --> 00:14:16.701
Och ibland kan det vara svårt
för algoritmen.

00:14:16.701 --> 00:14:18.965
I det här fallet blev den något förvirrad.

00:14:18.965 --> 00:14:21.485
Fronten och bakänden på bilarna
är helt ihopblandade.

00:14:21.485 --> 00:14:23.497
Så här behöver vi
vara lite mer försiktiga,

00:14:23.497 --> 00:14:26.669
och manuellt välja ut fronterna
men inte bakändarna,

00:14:26.669 --> 00:14:31.955
och sen berätta för datorn
att detta är en sorts grupp

00:14:31.955 --> 00:14:33.523
som vi är intresserade av.

00:14:33.523 --> 00:14:36.200
Så vi gör det en stund,
vi hoppar över en liten bit,

00:14:36.200 --> 00:14:38.446
och sen tränar vi
maskininlärningsalgoritmen

00:14:38.446 --> 00:14:40.160
baserat på ett par hundra saker

00:14:40.160 --> 00:14:42.495
och så hoppas vi att den har
blivit mycket bättre.

00:14:42.495 --> 00:14:45.518
Ni kan se att den nu har börjat tona ut
vissa av de här bilderna

00:14:45.518 --> 00:14:50.226
och visar oss därmed att den redan vet
hur den själv ska förstå vissa av dem.

00:14:50.226 --> 00:14:52.968
Sen kan vi använda det här konceptet
av liknande bilder

00:14:52.968 --> 00:14:54.595
och med hjälp av liknande bilder

00:14:54.595 --> 00:14:56.552
kan ni nu se att datorn vid det här laget

00:14:56.552 --> 00:14:58.994
kan hitta enbart bilder med bilfronter.

00:14:59.016 --> 00:15:02.189
Så, vid det här laget kan människan
berätta för datorn att,

00:15:02.189 --> 00:15:04.482
"Okej, bra - du har gjort
ett bra jobb med det."

00:15:05.652 --> 00:15:07.837
Ibland är det förstås
även vid det här laget

00:15:07.837 --> 00:15:11.511
svårt att skilja ut grupper.

00:15:11.511 --> 00:15:14.182
I det här fallet,
trots att vi har låtit datorn

00:15:14.182 --> 00:15:15.983
försöka rotera det här en stund,

00:15:15.983 --> 00:15:18.744
så ser vi att bilder
av vänster och höger sida

00:15:18.744 --> 00:15:20.222
har blandats ihop.

00:15:20.222 --> 00:15:22.362
Så vi kan ge datorn några tips,

00:15:22.362 --> 00:15:24.978
som "Okej, försök hitta
en projektion som skiljer ut

00:15:24.978 --> 00:15:26.621
vänstersidorna och högersidorna

00:15:26.621 --> 00:15:27.884
så gott det går

00:15:27.884 --> 00:15:30.067
med hjälp av en djupinlärningsalgoritm."

00:15:30.067 --> 00:15:33.009
Och med det tipset - ah, så lyckas den.

00:15:33.009 --> 00:15:35.891
Den har hittat ett sätt
att tänka kring de här objekten

00:15:35.891 --> 00:15:38.271
som har skiljt ut dessa tillsammans.

00:15:38.271 --> 00:15:40.709
Så ni förstår tanken här.

00:15:40.709 --> 00:15:43.591
Det här är ett fall som inte handlar om

00:15:43.591 --> 00:15:48.833
att människan ersätts av datorn,

00:15:48.833 --> 00:15:51.546
utan om att de arbetar tillsammans.

00:15:51.546 --> 00:15:55.096
Vad vi gör är att vi ersätter någonting
som brukade ta ett helt team

00:15:55.096 --> 00:15:57.098
på fem eller sex personer ungefär sju år

00:15:57.098 --> 00:15:59.703
och ersätter det med någonting
som tar 15 minuter

00:15:59.703 --> 00:16:02.208
för en person på egen hand.

00:16:02.208 --> 00:16:06.158
Så den här processen kräver ungefär
fyra eller fem upprepningar.

00:16:06.158 --> 00:16:07.827
Ni kan se att vi nu har 62 procent

00:16:07.827 --> 00:16:10.206
av våra 1,5 miljoner bilder
korrekt klassificerade.

00:16:10.206 --> 00:16:12.678
Och vid det här laget,
kan vi börja att ganska snabbt

00:16:12.678 --> 00:16:14.205
ta tag i en hela stora sektioner

00:16:14.205 --> 00:16:17.534
och kolla igenom för att säkerställa
att det inte finns några misstag.

00:16:17.534 --> 00:16:20.802
Där vi hittar misstag
kan vi uppmärksamma datorn på dem.

00:16:21.616 --> 00:16:24.661
Genom att använda den här sortens process
för alla olika grupper,

00:16:24.661 --> 00:16:26.758
är vi nu uppe i 80 procent

00:16:26.758 --> 00:16:29.563
framgångsrikt klassificerade bilder.

00:16:29.613 --> 00:16:31.841
Och vid det här laget
är det bara en fråga om

00:16:31.841 --> 00:16:35.220
att hitta de få bilder
som inte har klassificerats korrekt,

00:16:35.220 --> 00:16:38.108
och försöka förstå varför.

00:16:38.108 --> 00:16:39.851
Och på det sättet

00:16:39.851 --> 00:16:43.972
är vi efter 15 minuter uppe
i 97 procent klassificerade bilder.

00:16:43.972 --> 00:16:48.378
Det här är en teknik som skulle kunna 
bistå med att överbrygga det stora problem

00:16:48.378 --> 00:16:51.614
som utgörs av begränsad tillgång
till medicinsk expertis i världen.

00:16:51.614 --> 00:16:55.103
Världsekonomiskt forum menar
att det råder en mellan 10x och 20x

00:16:55.103 --> 00:16:57.727
brist på läkare i utvecklingsländer

00:16:57.727 --> 00:16:59.760
och att det skulle ta ungefär 300 år

00:16:59.760 --> 00:17:01.766
att lära upp tillräckligt många människor

00:17:01.766 --> 00:17:02.792
för att lösa det.

00:17:02.792 --> 00:17:05.619
Så föreställ er om vi kan hjälpa till
att öka effektiviteten

00:17:05.619 --> 00:17:08.458
med hjälp av djupinlärning.

00:17:08.458 --> 00:17:10.690
Så, de här möjligheterna
gör mig väldigt ivrig.

00:17:10.690 --> 00:17:13.279
Jag är också bekymrad över problemen.

00:17:13.279 --> 00:17:16.403
Problemet är att i alla blå områden
på den här kartan

00:17:16.403 --> 00:17:20.172
består jobben till 80 procent av tjänster.

00:17:20.172 --> 00:17:21.959
Vad är tjänster?

00:17:21.959 --> 00:17:23.473
Det här är tjänster.

00:17:23.473 --> 00:17:27.627
Det här är också precis vad datorerna
har lärt sig att göra.

00:17:27.627 --> 00:17:31.431
Så 80 procent av jobben
i den utvecklade världen

00:17:31.431 --> 00:17:33.963
utför sånt som datorer
precis har lärt sig att göra.

00:17:33.963 --> 00:17:35.403
Vad betyder det här?

00:17:35.403 --> 00:17:37.986
Nå, det blir fint.
Nya jobb kommer att ersätta dem.

00:17:37.986 --> 00:17:40.583
Till exempel blir det fler jobb
för forskare inom data.

00:17:40.583 --> 00:17:41.550
Eller, inte riktigt.

00:17:41.550 --> 00:17:44.548
Det tar inte en forskare särskilt lång tid
att bygga en sån här.

00:17:44.548 --> 00:17:47.880
De här fyra algoritmerna, till exempel,
har alla byggts av samma kille.

00:17:47.880 --> 00:17:50.318
Så, om ni tänker att,
"Åh, det här har hänt förr,

00:17:50.318 --> 00:17:54.126
vi har sett det här hända
när nya saker har uppfunnits

00:17:54.126 --> 00:17:56.378
och de har ersatts av nya jobb,

00:17:56.378 --> 00:17:58.494
vilka kommer de nya jobben att vara?"

00:17:58.494 --> 00:18:00.365
Det är väldigt svårt att räkna ut,

00:18:00.365 --> 00:18:03.104
eftersom mänsklig prestationsförmåga
utvecklas gradvis,

00:18:03.104 --> 00:18:06.016
emedan vi nu har ett system,
djupinlärning, som vi vet

00:18:06.016 --> 00:18:08.893
faktiskt utvecklas exponentiellt.

00:18:08.893 --> 00:18:10.498
Och vi är här.

00:18:10.498 --> 00:18:12.559
Så nu ser vi saker omkring oss och

00:18:12.559 --> 00:18:15.235
och vi tänker "Åh, datorer är 
rätt korkade." Eller hur?

00:18:15.235 --> 00:18:18.664
Men om fem år kommer datorerna
att ha lämnat oss långt bakom sig.

00:18:18.664 --> 00:18:22.529
Så vi behöver börja tänka på
den här förmågan redan nu.

00:18:22.529 --> 00:18:24.479
Vi har sett det en gång tidigare förstås.

00:18:24.479 --> 00:18:25.966
I den industriella revolutionen

00:18:25.966 --> 00:18:28.817
såg vi en stegvis förändring
i prestanda tack vare motorer.

00:18:29.667 --> 00:18:32.695
Saken är den, att efter en stund
flackade kurvan ut.

00:18:32.695 --> 00:18:34.377
Det orsakade social förändring,

00:18:34.377 --> 00:18:37.816
men så snart motorerna användes
för att generera kraft i alla situationer

00:18:37.816 --> 00:18:39.930
så lugnade det ner sig.

00:18:39.930 --> 00:18:41.493
Maskininlärningsrevolutionen

00:18:41.493 --> 00:18:44.332
kommer skilja sig mycket
från den industriella revolutionen,

00:18:44.332 --> 00:18:47.732
därför att maskininlärningsrevolutionen
aldrig kommer att lugna ner sig.

00:18:47.732 --> 00:18:50.254
Ju bättre datorer blir
på intellektuella aktiviteter

00:18:50.254 --> 00:18:54.502
desto bättre kan de bygga bättre datorer
som har större intellektuella förmågor,

00:18:54.502 --> 00:18:56.770
så det här kommer att bli en förändring

00:18:56.770 --> 00:18:59.178
som världen aldrig förr har upplevt,

00:18:59.178 --> 00:19:02.484
så er tidigare uppfattning
om vad som är möjligt förändras.

00:19:02.974 --> 00:19:04.754
Det här påverkar oss redan.

00:19:04.754 --> 00:19:08.384
Under de senaste 25 åren
har kapitalproduktiviteten ökat,

00:19:08.400 --> 00:19:12.588
arbetsproduktivitet är oförändrad,
faktiskt en aning minskande.

00:19:13.408 --> 00:19:16.149
Så jag vill att vi börjar
diskutera det här nu.

00:19:16.149 --> 00:19:18.976
Jag vet att ganska ofta
när jag berättar om det här,

00:19:18.976 --> 00:19:20.666
kan folk vara ganska avfärdande.

00:19:20.666 --> 00:19:22.339
Datorer kan inte tänka på riktigt,

00:19:22.339 --> 00:19:25.367
de har inga känslor,
de förstår inte poesi,

00:19:25.367 --> 00:19:27.678
vi förstår inte riktigt hur de fungerar.

00:19:27.678 --> 00:19:29.114
Så vadå?

00:19:29.114 --> 00:19:30.808
Just nu kan datorer göra det

00:19:30.808 --> 00:19:34.157
som människor ägnar det mesta
av sin tid åt att göra för att få betalt,

00:19:34.157 --> 00:19:35.798
så det är hög tid att börja tänka

00:19:35.798 --> 00:19:40.025
på hur vi ska anpassa
våra sociala och ekonomiska strukturer

00:19:40.025 --> 00:19:42.005
för att klara av den nya verkligheten.

00:19:42.005 --> 00:19:43.158
Tack.

00:19:43.158 --> 00:19:44.188
(Applåder)

