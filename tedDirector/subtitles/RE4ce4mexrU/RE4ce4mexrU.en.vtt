WEBVTT
Kind: captions
Language: en

00:00:15.260 --> 00:00:19.260
Imagine if you could record your life --

00:00:19.260 --> 00:00:22.260
everything you said, everything you did,

00:00:22.260 --> 00:00:25.260
available in a perfect memory store at your fingertips,

00:00:25.260 --> 00:00:27.260
so you could go back

00:00:27.260 --> 00:00:30.260
and find memorable moments and relive them,

00:00:30.260 --> 00:00:33.260
or sift through traces of time

00:00:33.260 --> 00:00:35.260
and discover patterns in your own life

00:00:35.260 --> 00:00:38.260
that previously had gone undiscovered.

00:00:38.260 --> 00:00:40.260
Well that's exactly the journey

00:00:40.260 --> 00:00:42.260
that my family began

00:00:42.260 --> 00:00:44.260
five and a half years ago.

00:00:44.260 --> 00:00:47.260
This is my wife and collaborator, Rupal.

00:00:47.260 --> 00:00:49.260
And on this day, at this moment,

00:00:49.260 --> 00:00:51.260
we walked into the house with our first child,

00:00:51.260 --> 00:00:53.260
our beautiful baby boy.

00:00:53.260 --> 00:00:56.260
And we walked into a house

00:00:56.260 --> 00:01:00.260
with a very special home video recording system.

00:01:07.260 --> 00:01:09.260
(Video) Man: Okay.

00:01:10.260 --> 00:01:11.260
Deb Roy: This moment

00:01:11.260 --> 00:01:14.260
and thousands of other moments special for us

00:01:14.260 --> 00:01:16.260
were captured in our home

00:01:16.260 --> 00:01:18.260
because in every room in the house,

00:01:18.260 --> 00:01:21.260
if you looked up, you'd see a camera and a microphone,

00:01:21.260 --> 00:01:23.260
and if you looked down,

00:01:23.260 --> 00:01:25.260
you'd get this bird's-eye view of the room.

00:01:25.260 --> 00:01:28.260
Here's our living room,

00:01:28.260 --> 00:01:31.260
the baby bedroom,

00:01:31.260 --> 00:01:33.260
kitchen, dining room

00:01:33.260 --> 00:01:35.260
and the rest of the house.

00:01:35.260 --> 00:01:38.260
And all of these fed into a disc array

00:01:38.260 --> 00:01:41.260
that was designed for a continuous capture.

00:01:41.260 --> 00:01:44.260
So here we are flying through a day in our home

00:01:44.260 --> 00:01:47.260
as we move from sunlit morning

00:01:47.260 --> 00:01:49.260
through incandescent evening

00:01:49.260 --> 00:01:52.260
and, finally, lights out for the day.

00:01:53.260 --> 00:01:56.260
Over the course of three years,

00:01:56.260 --> 00:01:58.260
we recorded eight to 10 hours a day,

00:01:58.260 --> 00:02:01.260
amassing roughly a quarter-million hours

00:02:01.260 --> 00:02:04.260
of multi-track audio and video.

00:02:04.260 --> 00:02:06.260
So you're looking at a piece of what is by far

00:02:06.260 --> 00:02:08.260
the largest home video collection ever made.

00:02:08.260 --> 00:02:11.260
(Laughter)

00:02:11.260 --> 00:02:13.260
And what this data represents

00:02:13.260 --> 00:02:17.260
for our family at a personal level,

00:02:17.260 --> 00:02:19.260
the impact has already been immense,

00:02:19.260 --> 00:02:22.260
and we're still learning its value.

00:02:22.260 --> 00:02:24.260
Countless moments

00:02:24.260 --> 00:02:27.260
of unsolicited natural moments, not posed moments,

00:02:27.260 --> 00:02:29.260
are captured there,

00:02:29.260 --> 00:02:32.260
and we're starting to learn how to discover them and find them.

00:02:32.260 --> 00:02:35.260
But there's also a scientific reason that drove this project,

00:02:35.260 --> 00:02:39.260
which was to use this natural longitudinal data

00:02:39.260 --> 00:02:41.260
to understand the process

00:02:41.260 --> 00:02:43.260
of how a child learns language --

00:02:43.260 --> 00:02:45.260
that child being my son.

00:02:45.260 --> 00:02:49.260
And so with many privacy provisions put in place

00:02:49.260 --> 00:02:52.260
to protect everyone who was recorded in the data,

00:02:52.260 --> 00:02:55.260
we made elements of the data available

00:02:55.260 --> 00:02:58.260
to my trusted research team at MIT

00:02:58.260 --> 00:03:01.260
so we could start teasing apart patterns

00:03:01.260 --> 00:03:04.260
in this massive data set,

00:03:04.260 --> 00:03:07.260
trying to understand the influence of social environments

00:03:07.260 --> 00:03:09.260
on language acquisition.

00:03:09.260 --> 00:03:11.260
So we're looking here

00:03:11.260 --> 00:03:13.260
at one of the first things we started to do.

00:03:13.260 --> 00:03:17.260
This is my wife and I cooking breakfast in the kitchen,

00:03:17.260 --> 00:03:20.260
and as we move through space and through time,

00:03:20.260 --> 00:03:23.260
a very everyday pattern of life in the kitchen.

00:03:23.260 --> 00:03:25.260
In order to convert

00:03:25.260 --> 00:03:28.260
this opaque, 90,000 hours of video

00:03:28.260 --> 00:03:30.260
into something that we could start to see,

00:03:30.260 --> 00:03:32.260
we use motion analysis to pull out,

00:03:32.260 --> 00:03:34.260
as we move through space and through time,

00:03:34.260 --> 00:03:37.260
what we call space-time worms.

00:03:37.260 --> 00:03:40.260
And this has become part of our toolkit

00:03:40.260 --> 00:03:43.260
for being able to look and see

00:03:43.260 --> 00:03:45.260
where the activities are in the data,

00:03:45.260 --> 00:03:48.260
and with it, trace the pattern of, in particular,

00:03:48.260 --> 00:03:50.260
where my son moved throughout the home,

00:03:50.260 --> 00:03:53.260
so that we could focus our transcription efforts,

00:03:53.260 --> 00:03:56.260
all of the speech environment around my son --

00:03:56.260 --> 00:03:59.260
all of the words that he heard from myself, my wife, our nanny,

00:03:59.260 --> 00:04:02.260
and over time, the words he began to produce.

00:04:02.260 --> 00:04:05.260
So with that technology and that data

00:04:05.260 --> 00:04:07.260
and the ability to, with machine assistance,

00:04:07.260 --> 00:04:09.260
transcribe speech,

00:04:09.260 --> 00:04:11.260
we've now transcribed

00:04:11.260 --> 00:04:14.260
well over seven million words of our home transcripts.

00:04:14.260 --> 00:04:16.260
And with that, let me take you now

00:04:16.260 --> 00:04:19.260
for a first tour into the data.

00:04:19.260 --> 00:04:21.260
So you've all, I'm sure,

00:04:21.260 --> 00:04:23.260
seen time-lapse videos

00:04:23.260 --> 00:04:26.260
where a flower will blossom as you accelerate time.

00:04:26.260 --> 00:04:28.260
I'd like you to now experience

00:04:28.260 --> 00:04:30.260
the blossoming of a speech form.

00:04:30.260 --> 00:04:32.260
My son, soon after his first birthday,

00:04:32.260 --> 00:04:35.260
would say "gaga" to mean water.

00:04:35.260 --> 00:04:38.260
And over the course of the next half-year,

00:04:38.260 --> 00:04:40.260
he slowly learned to approximate

00:04:40.260 --> 00:04:43.260
the proper adult form, "water."

00:04:43.260 --> 00:04:45.260
So we're going to cruise through half a year

00:04:45.260 --> 00:04:47.260
in about 40 seconds.

00:04:47.260 --> 00:04:49.260
No video here,

00:04:49.260 --> 00:04:52.260
so you can focus on the sound, the acoustics,

00:04:52.260 --> 00:04:54.260
of a new kind of trajectory:

00:04:54.260 --> 00:04:56.260
gaga to water.

00:04:56.260 --> 00:05:08.260
(Audio) Baby: Gagagagagaga

00:05:08.260 --> 00:05:12.260
Gaga gaga gaga

00:05:12.260 --> 00:05:17.260
guga guga guga

00:05:17.260 --> 00:05:22.260
wada gaga gaga guga gaga

00:05:22.260 --> 00:05:26.260
wader guga guga

00:05:26.260 --> 00:05:29.260
water water water

00:05:29.260 --> 00:05:35.260
water water water

00:05:35.260 --> 00:05:39.260
water water

00:05:39.260 --> 00:05:41.260
water.

00:05:41.260 --> 00:05:43.260
DR: He sure nailed it, didn't he.

00:05:43.260 --> 00:05:50.260
(Applause)

00:05:50.260 --> 00:05:52.260
So he didn't just learn water.

00:05:52.260 --> 00:05:54.260
Over the course of the 24 months,

00:05:54.260 --> 00:05:57.260
the first two years that we really focused on,

00:05:57.260 --> 00:06:01.260
this is a map of every word he learned in chronological order.

00:06:01.260 --> 00:06:04.260
And because we have full transcripts,

00:06:04.260 --> 00:06:06.260
we've identified each of the 503 words

00:06:06.260 --> 00:06:08.260
that he learned to produce by his second birthday.

00:06:08.260 --> 00:06:10.260
He was an early talker.

00:06:10.260 --> 00:06:13.260
And so we started to analyze why.

00:06:13.260 --> 00:06:16.260
Why were certain words born before others?

00:06:16.260 --> 00:06:18.260
This is one of the first results

00:06:18.260 --> 00:06:20.260
that came out of our study a little over a year ago

00:06:20.260 --> 00:06:22.260
that really surprised us.

00:06:22.260 --> 00:06:25.260
The way to interpret this apparently simple graph

00:06:25.260 --> 00:06:27.260
is, on the vertical is an indication

00:06:27.260 --> 00:06:30.260
of how complex caregiver utterances are

00:06:30.260 --> 00:06:32.260
based on the length of utterances.

00:06:32.260 --> 00:06:35.260
And the [horizontal] axis is time.

00:06:35.260 --> 00:06:37.260
And all of the data,

00:06:37.260 --> 00:06:40.260
we aligned based on the following idea:

00:06:40.260 --> 00:06:43.260
Every time my son would learn a word,

00:06:43.260 --> 00:06:46.260
we would trace back and look at all of the language he heard

00:06:46.260 --> 00:06:48.260
that contained that word.

00:06:48.260 --> 00:06:52.260
And we would plot the relative length of the utterances.

00:06:52.260 --> 00:06:55.260
And what we found was this curious phenomena,

00:06:55.260 --> 00:06:58.260
that caregiver speech would systematically dip to a minimum,

00:06:58.260 --> 00:07:01.260
making language as simple as possible,

00:07:01.260 --> 00:07:04.260
and then slowly ascend back up in complexity.

00:07:04.260 --> 00:07:06.260
And the amazing thing was

00:07:06.260 --> 00:07:08.260
that bounce, that dip,

00:07:08.260 --> 00:07:10.260
lined up almost precisely

00:07:10.260 --> 00:07:12.260
with when each word was born --

00:07:12.260 --> 00:07:14.260
word after word, systematically.

00:07:14.260 --> 00:07:16.260
So it appears that all three primary caregivers --

00:07:16.260 --> 00:07:19.260
myself, my wife and our nanny --

00:07:19.260 --> 00:07:22.260
were systematically and, I would think, subconsciously

00:07:22.260 --> 00:07:24.260
restructuring our language

00:07:24.260 --> 00:07:27.260
to meet him at the birth of a word

00:07:27.260 --> 00:07:31.260
and bring him gently into more complex language.

00:07:31.260 --> 00:07:33.260
And the implications of this -- there are many,

00:07:33.260 --> 00:07:35.260
but one I just want to point out,

00:07:35.260 --> 00:07:38.260
is that there must be amazing feedback loops.

00:07:38.260 --> 00:07:40.260
Of course, my son is learning

00:07:40.260 --> 00:07:42.260
from his linguistic environment,

00:07:42.260 --> 00:07:45.260
but the environment is learning from him.

00:07:45.260 --> 00:07:48.260
That environment, people, are in these tight feedback loops

00:07:48.260 --> 00:07:50.260
and creating a kind of scaffolding

00:07:50.260 --> 00:07:53.260
that has not been noticed until now.

00:07:54.260 --> 00:07:56.260
But that's looking at the speech context.

00:07:56.260 --> 00:07:58.260
What about the visual context?

00:07:58.260 --> 00:08:00.260
We're not looking at --

00:08:00.260 --> 00:08:02.260
think of this as a dollhouse cutaway of our house.

00:08:02.260 --> 00:08:05.260
We've taken those circular fish-eye lens cameras,

00:08:05.260 --> 00:08:07.260
and we've done some optical correction,

00:08:07.260 --> 00:08:11.260
and then we can bring it into three-dimensional life.

00:08:11.260 --> 00:08:13.260
So welcome to my home.

00:08:13.260 --> 00:08:15.260
This is a moment,

00:08:15.260 --> 00:08:18.260
one moment captured across multiple cameras.

00:08:18.260 --> 00:08:21.260
The reason we did this is to create the ultimate memory machine,

00:08:21.260 --> 00:08:24.260
where you can go back and interactively fly around

00:08:24.260 --> 00:08:27.260
and then breathe video-life into this system.

00:08:27.260 --> 00:08:29.260
What I'm going to do

00:08:29.260 --> 00:08:32.260
is give you an accelerated view of 30 minutes,

00:08:32.260 --> 00:08:34.260
again, of just life in the living room.

00:08:34.260 --> 00:08:37.260
That's me and my son on the floor.

00:08:37.260 --> 00:08:39.260
And there's video analytics

00:08:39.260 --> 00:08:41.260
that are tracking our movements.

00:08:41.260 --> 00:08:44.260
My son is leaving red ink. I am leaving green ink.

00:08:44.260 --> 00:08:46.260
We're now on the couch,

00:08:46.260 --> 00:08:49.260
looking out through the window at cars passing by.

00:08:49.260 --> 00:08:52.260
And finally, my son playing in a walking toy by himself.

00:08:52.260 --> 00:08:55.260
Now we freeze the action, 30 minutes,

00:08:55.260 --> 00:08:57.260
we turn time into the vertical axis,

00:08:57.260 --> 00:08:59.260
and we open up for a view

00:08:59.260 --> 00:09:02.260
of these interaction traces we've just left behind.

00:09:02.260 --> 00:09:05.260
And we see these amazing structures --

00:09:05.260 --> 00:09:08.260
these little knots of two colors of thread

00:09:08.260 --> 00:09:10.260
we call "social hot spots."

00:09:10.260 --> 00:09:12.260
The spiral thread

00:09:12.260 --> 00:09:14.260
we call a "solo hot spot."

00:09:14.260 --> 00:09:17.260
And we think that these affect the way language is learned.

00:09:17.260 --> 00:09:19.260
What we'd like to do

00:09:19.260 --> 00:09:21.260
is start understanding

00:09:21.260 --> 00:09:23.260
the interaction between these patterns

00:09:23.260 --> 00:09:25.260
and the language that my son is exposed to

00:09:25.260 --> 00:09:27.260
to see if we can predict

00:09:27.260 --> 00:09:29.260
how the structure of when words are heard

00:09:29.260 --> 00:09:31.260
affects when they're learned --

00:09:31.260 --> 00:09:33.260
so in other words, the relationship

00:09:33.260 --> 00:09:37.260
between words and what they're about in the world.

00:09:37.260 --> 00:09:39.260
So here's how we're approaching this.

00:09:39.260 --> 00:09:41.260
In this video,

00:09:41.260 --> 00:09:43.260
again, my son is being traced out.

00:09:43.260 --> 00:09:45.260
He's leaving red ink behind.

00:09:45.260 --> 00:09:47.260
And there's our nanny by the door.

00:09:47.260 --> 00:09:50.260
(Video) Nanny: You want water? (Baby: Aaaa.)

00:09:50.260 --> 00:09:53.260
Nanny: All right. (Baby: Aaaa.)

00:09:53.260 --> 00:09:55.260
DR: She offers water,

00:09:55.260 --> 00:09:57.260
and off go the two worms

00:09:57.260 --> 00:09:59.260
over to the kitchen to get water.

00:09:59.260 --> 00:10:01.260
And what we've done is use the word "water"

00:10:01.260 --> 00:10:03.260
to tag that moment, that bit of activity.

00:10:03.260 --> 00:10:05.260
And now we take the power of data

00:10:05.260 --> 00:10:08.260
and take every time my son

00:10:08.260 --> 00:10:10.260
ever heard the word water

00:10:10.260 --> 00:10:12.260
and the context he saw it in,

00:10:12.260 --> 00:10:15.260
and we use it to penetrate through the video

00:10:15.260 --> 00:10:18.260
and find every activity trace

00:10:18.260 --> 00:10:21.260
that co-occurred with an instance of water.

00:10:21.260 --> 00:10:23.260
And what this data leaves in its wake

00:10:23.260 --> 00:10:25.260
is a landscape.

00:10:25.260 --> 00:10:27.260
We call these wordscapes.

00:10:27.260 --> 00:10:29.260
This is the wordscape for the word water,

00:10:29.260 --> 00:10:31.260
and you can see most of the action is in the kitchen.

00:10:31.260 --> 00:10:34.260
That's where those big peaks are over to the left.

00:10:34.260 --> 00:10:37.260
And just for contrast, we can do this with any word.

00:10:37.260 --> 00:10:39.260
We can take the word "bye"

00:10:39.260 --> 00:10:41.260
as in "good bye."

00:10:41.260 --> 00:10:43.260
And we're now zoomed in over the entrance to the house.

00:10:43.260 --> 00:10:46.260
And we look, and we find, as you would expect,

00:10:46.260 --> 00:10:48.260
a contrast in the landscape

00:10:48.260 --> 00:10:51.260
where the word "bye" occurs much more in a structured way.

00:10:51.260 --> 00:10:53.260
So we're using these structures

00:10:53.260 --> 00:10:55.260
to start predicting

00:10:55.260 --> 00:10:58.260
the order of language acquisition,

00:10:58.260 --> 00:11:00.260
and that's ongoing work now.

00:11:00.260 --> 00:11:03.260
In my lab, which we're peering into now, at MIT --

00:11:03.260 --> 00:11:05.260
this is at the media lab.

00:11:05.260 --> 00:11:07.260
This has become my favorite way

00:11:07.260 --> 00:11:09.260
of videographing just about any space.

00:11:09.260 --> 00:11:11.260
Three of the key people in this project,

00:11:11.260 --> 00:11:14.260
Philip DeCamp, Rony Kubat and Brandon Roy are pictured here.

00:11:14.260 --> 00:11:16.260
Philip has been a close collaborator

00:11:16.260 --> 00:11:18.260
on all the visualizations you're seeing.

00:11:18.260 --> 00:11:21.260
And Michael Fleischman

00:11:21.260 --> 00:11:23.260
was another Ph.D. student in my lab

00:11:23.260 --> 00:11:26.260
who worked with me on this home video analysis,

00:11:26.260 --> 00:11:29.260
and he made the following observation:

00:11:29.260 --> 00:11:31.260
that "just the way that we're analyzing

00:11:31.260 --> 00:11:34.260
how language connects to events

00:11:34.260 --> 00:11:36.260
which provide common ground for language,

00:11:36.260 --> 00:11:40.260
that same idea we can take out of your home, Deb,

00:11:40.260 --> 00:11:43.260
and we can apply it to the world of public media."

00:11:43.260 --> 00:11:46.260
And so our effort took an unexpected turn.

00:11:46.260 --> 00:11:48.260
Think of mass media

00:11:48.260 --> 00:11:50.260
as providing common ground

00:11:50.260 --> 00:11:52.260
and you have the recipe

00:11:52.260 --> 00:11:55.260
for taking this idea to a whole new place.

00:11:55.260 --> 00:11:58.260
We've started analyzing television content

00:11:58.260 --> 00:12:00.260
using the same principles --

00:12:00.260 --> 00:12:03.260
analyzing event structure of a TV signal --

00:12:03.260 --> 00:12:05.260
episodes of shows,

00:12:05.260 --> 00:12:07.260
commercials,

00:12:07.260 --> 00:12:10.260
all of the components that make up the event structure.

00:12:10.260 --> 00:12:13.260
And we're now, with satellite dishes, pulling and analyzing

00:12:13.260 --> 00:12:16.260
a good part of all the TV being watched in the United States.

00:12:16.260 --> 00:12:19.260
And you don't have to now go and instrument living rooms with microphones

00:12:19.260 --> 00:12:21.260
to get people's conversations,

00:12:21.260 --> 00:12:24.260
you just tune into publicly available social media feeds.

00:12:24.260 --> 00:12:26.260
So we're pulling in

00:12:26.260 --> 00:12:28.260
about three billion comments a month,

00:12:28.260 --> 00:12:30.260
and then the magic happens.

00:12:30.260 --> 00:12:32.260
You have the event structure,

00:12:32.260 --> 00:12:34.260
the common ground that the words are about,

00:12:34.260 --> 00:12:37.260
coming out of the television feeds;

00:12:37.260 --> 00:12:39.260
you've got the conversations

00:12:39.260 --> 00:12:41.260
that are about those topics;

00:12:41.260 --> 00:12:44.260
and through semantic analysis --

00:12:44.260 --> 00:12:46.260
and this is actually real data you're looking at

00:12:46.260 --> 00:12:48.260
from our data processing --

00:12:48.260 --> 00:12:51.260
each yellow line is showing a link being made

00:12:51.260 --> 00:12:54.260
between a comment in the wild

00:12:54.260 --> 00:12:57.260
and a piece of event structure coming out of the television signal.

00:12:57.260 --> 00:12:59.260
And the same idea now

00:12:59.260 --> 00:13:01.260
can be built up.

00:13:01.260 --> 00:13:03.260
And we get this wordscape,

00:13:03.260 --> 00:13:06.260
except now words are not assembled in my living room.

00:13:06.260 --> 00:13:10.260
Instead, the context, the common ground activities,

00:13:10.260 --> 00:13:13.260
are the content on television that's driving the conversations.

00:13:13.260 --> 00:13:16.260
And what we're seeing here, these skyscrapers now,

00:13:16.260 --> 00:13:18.260
are commentary

00:13:18.260 --> 00:13:20.260
that are linked to content on television.

00:13:20.260 --> 00:13:22.260
Same concept,

00:13:22.260 --> 00:13:24.260
but looking at communication dynamics

00:13:24.260 --> 00:13:26.260
in a very different sphere.

00:13:26.260 --> 00:13:28.260
And so fundamentally, rather than, for example,

00:13:28.260 --> 00:13:31.260
measuring content based on how many people are watching,

00:13:31.260 --> 00:13:33.260
this gives us the basic data

00:13:33.260 --> 00:13:36.260
for looking at engagement properties of content.

00:13:36.260 --> 00:13:39.260
And just like we can look at feedback cycles

00:13:39.260 --> 00:13:42.260
and dynamics in a family,

00:13:42.260 --> 00:13:45.260
we can now open up the same concepts

00:13:45.260 --> 00:13:48.260
and look at much larger groups of people.

00:13:48.260 --> 00:13:51.260
This is a subset of data from our database --

00:13:51.260 --> 00:13:54.260
just 50,000 out of several million --

00:13:54.260 --> 00:13:56.260
and the social graph that connects them

00:13:56.260 --> 00:13:59.260
through publicly available sources.

00:13:59.260 --> 00:14:01.260
And if you put them on one plain,

00:14:01.260 --> 00:14:04.260
a second plain is where the content lives.

00:14:04.260 --> 00:14:07.260
So we have the programs

00:14:07.260 --> 00:14:09.260
and the sporting events

00:14:09.260 --> 00:14:11.260
and the commercials,

00:14:11.260 --> 00:14:13.260
and all of the link structures that tie them together

00:14:13.260 --> 00:14:15.260
make a content graph.

00:14:15.260 --> 00:14:19.260
And then the important third dimension.

00:14:19.260 --> 00:14:21.260
Each of the links that you're seeing rendered here

00:14:21.260 --> 00:14:23.260
is an actual connection made

00:14:23.260 --> 00:14:26.260
between something someone said

00:14:26.260 --> 00:14:28.260
and a piece of content.

00:14:28.260 --> 00:14:31.260
And there are, again, now tens of millions of these links

00:14:31.260 --> 00:14:34.260
that give us the connective tissue of social graphs

00:14:34.260 --> 00:14:37.260
and how they relate to content.

00:14:37.260 --> 00:14:39.260
And we can now start to probe the structure

00:14:39.260 --> 00:14:41.260
in interesting ways.

00:14:41.260 --> 00:14:44.260
So if we, for example, trace the path

00:14:44.260 --> 00:14:46.260
of one piece of content

00:14:46.260 --> 00:14:48.260
that drives someone to comment on it,

00:14:48.260 --> 00:14:51.260
and then we follow where that comment goes,

00:14:51.260 --> 00:14:54.260
and then look at the entire social graph that becomes activated

00:14:54.260 --> 00:14:57.260
and then trace back to see the relationship

00:14:57.260 --> 00:14:59.260
between that social graph and content,

00:14:59.260 --> 00:15:01.260
a very interesting structure becomes visible.

00:15:01.260 --> 00:15:03.260
We call this a co-viewing clique,

00:15:03.260 --> 00:15:06.260
a virtual living room if you will.

00:15:06.260 --> 00:15:08.260
And there are fascinating dynamics at play.

00:15:08.260 --> 00:15:10.260
It's not one way.

00:15:10.260 --> 00:15:13.260
A piece of content, an event, causes someone to talk.

00:15:13.260 --> 00:15:15.260
They talk to other people.

00:15:15.260 --> 00:15:18.260
That drives tune-in behavior back into mass media,

00:15:18.260 --> 00:15:20.260
and you have these cycles

00:15:20.260 --> 00:15:22.260
that drive the overall behavior.

00:15:22.260 --> 00:15:24.260
Another example -- very different --

00:15:24.260 --> 00:15:27.260
another actual person in our database --

00:15:27.260 --> 00:15:30.260
and we're finding at least hundreds, if not thousands, of these.

00:15:30.260 --> 00:15:32.260
We've given this person a name.

00:15:32.260 --> 00:15:35.260
This is a pro-amateur, or pro-am media critic

00:15:35.260 --> 00:15:38.260
who has this high fan-out rate.

00:15:38.260 --> 00:15:41.260
So a lot of people are following this person -- very influential --

00:15:41.260 --> 00:15:43.260
and they have a propensity to talk about what's on TV.

00:15:43.260 --> 00:15:46.260
So this person is a key link

00:15:46.260 --> 00:15:49.260
in connecting mass media and social media together.

00:15:49.260 --> 00:15:52.260
One last example from this data:

00:15:52.260 --> 00:15:55.260
Sometimes it's actually a piece of content that is special.

00:15:55.260 --> 00:15:59.260
So if we go and look at this piece of content,

00:15:59.260 --> 00:16:02.260
President Obama's State of the Union address

00:16:02.260 --> 00:16:04.260
from just a few weeks ago,

00:16:04.260 --> 00:16:07.260
and look at what we find in this same data set,

00:16:07.260 --> 00:16:10.260
at the same scale,

00:16:10.260 --> 00:16:12.260
the engagement properties of this piece of content

00:16:12.260 --> 00:16:14.260
are truly remarkable.

00:16:14.260 --> 00:16:16.260
A nation exploding in conversation

00:16:16.260 --> 00:16:18.260
in real time

00:16:18.260 --> 00:16:21.260
in response to what's on the broadcast.

00:16:21.260 --> 00:16:23.260
And of course, through all of these lines

00:16:23.260 --> 00:16:25.260
are flowing unstructured language.

00:16:25.260 --> 00:16:27.260
We can X-ray

00:16:27.260 --> 00:16:29.260
and get a real-time pulse of a nation,

00:16:29.260 --> 00:16:31.260
real-time sense

00:16:31.260 --> 00:16:34.260
of the social reactions in the different circuits in the social graph

00:16:34.260 --> 00:16:37.260
being activated by content.

00:16:37.260 --> 00:16:40.260
So, to summarize, the idea is this:

00:16:40.260 --> 00:16:43.260
As our world becomes increasingly instrumented

00:16:43.260 --> 00:16:45.260
and we have the capabilities

00:16:45.260 --> 00:16:47.260
to collect and connect the dots

00:16:47.260 --> 00:16:49.260
between what people are saying

00:16:49.260 --> 00:16:51.260
and the context they're saying it in,

00:16:51.260 --> 00:16:53.260
what's emerging is an ability

00:16:53.260 --> 00:16:56.260
to see new social structures and dynamics

00:16:56.260 --> 00:16:58.260
that have previously not been seen.

00:16:58.260 --> 00:17:00.260
It's like building a microscope or telescope

00:17:00.260 --> 00:17:02.260
and revealing new structures

00:17:02.260 --> 00:17:05.260
about our own behavior around communication.

00:17:05.260 --> 00:17:08.260
And I think the implications here are profound,

00:17:08.260 --> 00:17:10.260
whether it's for science,

00:17:10.260 --> 00:17:12.260
for commerce, for government,

00:17:12.260 --> 00:17:14.260
or perhaps most of all,

00:17:14.260 --> 00:17:17.260
for us as individuals.

00:17:17.260 --> 00:17:20.260
And so just to return to my son,

00:17:20.260 --> 00:17:23.260
when I was preparing this talk, he was looking over my shoulder,

00:17:23.260 --> 00:17:25.260
and I showed him the clips I was going to show to you today,

00:17:25.260 --> 00:17:28.260
and I asked him for permission -- granted.

00:17:28.260 --> 00:17:30.260
And then I went on to reflect,

00:17:30.260 --> 00:17:33.260
"Isn't it amazing,

00:17:33.260 --> 00:17:36.260
this entire database, all these recordings,

00:17:36.260 --> 00:17:38.260
I'm going to hand off to you and to your sister" --

00:17:38.260 --> 00:17:41.260
who arrived two years later --

00:17:41.260 --> 00:17:44.260
"and you guys are going to be able to go back and re-experience moments

00:17:44.260 --> 00:17:47.260
that you could never, with your biological memory,

00:17:47.260 --> 00:17:49.260
possibly remember the way you can now?"

00:17:49.260 --> 00:17:51.260
And he was quiet for a moment.

00:17:51.260 --> 00:17:53.260
And I thought, "What am I thinking?

00:17:53.260 --> 00:17:55.260
He's five years old. He's not going to understand this."

00:17:55.260 --> 00:17:58.260
And just as I was having that thought, he looked up at me and said,

00:17:58.260 --> 00:18:00.260
"So that when I grow up,

00:18:00.260 --> 00:18:02.260
I can show this to my kids?"

00:18:02.260 --> 00:18:05.260
And I thought, "Wow, this is powerful stuff."

00:18:05.260 --> 00:18:07.260
So I want to leave you

00:18:07.260 --> 00:18:09.260
with one last memorable moment

00:18:09.260 --> 00:18:12.260
from our family.

00:18:12.260 --> 00:18:14.260
This is the first time our son

00:18:14.260 --> 00:18:16.260
took more than two steps at once --

00:18:16.260 --> 00:18:18.260
captured on film.

00:18:18.260 --> 00:18:21.260
And I really want you to focus on something

00:18:21.260 --> 00:18:23.260
as I take you through.

00:18:23.260 --> 00:18:25.260
It's a cluttered environment; it's natural life.

00:18:25.260 --> 00:18:27.260
My mother's in the kitchen, cooking,

00:18:27.260 --> 00:18:29.260
and, of all places, in the hallway,

00:18:29.260 --> 00:18:32.260
I realize he's about to do it, about to take more than two steps.

00:18:32.260 --> 00:18:34.260
And so you hear me encouraging him,

00:18:34.260 --> 00:18:36.260
realizing what's happening,

00:18:36.260 --> 00:18:38.260
and then the magic happens.

00:18:38.260 --> 00:18:40.260
Listen very carefully.

00:18:40.260 --> 00:18:42.260
About three steps in,

00:18:42.260 --> 00:18:44.260
he realizes something magic is happening,

00:18:44.260 --> 00:18:47.260
and the most amazing feedback loop of all kicks in,

00:18:47.260 --> 00:18:49.260
and he takes a breath in,

00:18:49.260 --> 00:18:51.260
and he whispers "wow"

00:18:51.260 --> 00:18:55.260
and instinctively I echo back the same.

00:18:56.260 --> 00:18:59.260
And so let's fly back in time

00:18:59.260 --> 00:19:01.260
to that memorable moment.

00:19:05.260 --> 00:19:07.260
(Video) DR: Hey.

00:19:07.260 --> 00:19:09.260
Come here.

00:19:09.260 --> 00:19:12.260
Can you do it?

00:19:13.260 --> 00:19:15.260
Oh, boy.

00:19:15.260 --> 00:19:18.260
Can you do it?

00:19:18.260 --> 00:19:20.260
Baby: Yeah.

00:19:20.260 --> 00:19:23.260
DR: Ma, he's walking.

00:19:24.260 --> 00:19:26.260
(Laughter)

00:19:26.260 --> 00:19:28.260
(Applause)

00:19:28.260 --> 00:19:30.260
DR: Thank you.

00:19:30.260 --> 00:19:45.260
(Applause)

