WEBVTT
Kind: captions
Language: en

00:00:12.580 --> 00:00:16.020
How many companies
have you interacted with today?

00:00:17.060 --> 00:00:18.716
Well, you got up in the morning,

00:00:18.740 --> 00:00:19.955
took a shower,

00:00:19.980 --> 00:00:21.236
washed your hair,

00:00:21.260 --> 00:00:22.796
used a hair dryer,

00:00:22.820 --> 00:00:24.036
ate breakfast --

00:00:24.060 --> 00:00:25.918
ate cereals, fruit, yogurt, whatever --

00:00:25.942 --> 00:00:27.156
had coffee --

00:00:27.180 --> 00:00:28.556
tea.

00:00:28.580 --> 00:00:30.556
You took public transport to come here,

00:00:30.580 --> 00:00:32.420
or maybe used your private car.

00:00:33.340 --> 00:00:36.900
You interacted with the company
that you work for or that you own.

00:00:37.980 --> 00:00:39.940
You interacted with your clients,

00:00:40.580 --> 00:00:41.780
your customers,

00:00:42.460 --> 00:00:43.716
and so on and so forth.

00:00:43.740 --> 00:00:47.356
I'm pretty sure there are
at least seven companies

00:00:47.380 --> 00:00:49.140
you've interacted with today.

00:00:49.780 --> 00:00:51.780
Let me tell you a stunning statistic.

00:00:52.660 --> 00:00:57.036
One out of seven
large, public corporations

00:00:57.060 --> 00:00:59.300
commit fraud every year.

00:01:00.220 --> 00:01:03.636
This is a US academic study
that looks at US companies --

00:01:03.660 --> 00:01:06.860
I have no reason to believe
that it's different in Europe.

00:01:07.300 --> 00:01:11.516
This is a study that looks
at both detected and undetected fraud

00:01:11.540 --> 00:01:13.276
using statistical methods.

00:01:13.300 --> 00:01:15.020
This is not petty fraud.

00:01:15.940 --> 00:01:18.796
These frauds cost
the shareholders of these companies,

00:01:18.820 --> 00:01:20.076
and therefore society,

00:01:20.100 --> 00:01:23.700
on the order of
380 billion dollars per year.

00:01:24.780 --> 00:01:26.996
We can all think of some examples, right?

00:01:27.020 --> 00:01:30.820
The car industry's secrets
aren't quite so secret anymore.

00:01:31.620 --> 00:01:34.916
Fraud has become a feature,

00:01:34.940 --> 00:01:36.156
not a bug,

00:01:36.180 --> 00:01:38.116
of the financial services industry.

00:01:38.140 --> 00:01:40.356
That's not me who's claiming that,

00:01:40.380 --> 00:01:43.636
that's the president
of the American Finance Association

00:01:43.660 --> 00:01:46.596
who stated that
in his presidential address.

00:01:46.620 --> 00:01:49.356
That's a huge problem
if you think about, especially,

00:01:49.380 --> 00:01:51.076
an economy like Switzerland,

00:01:51.100 --> 00:01:55.300
which relies so much on the trust
put into its financial industry.

00:01:56.780 --> 00:01:57.996
On the other hand,

00:01:58.020 --> 00:02:01.556
there are six out of seven companies
who actually remain honest

00:02:01.580 --> 00:02:05.420
despite all temptations
to start engaging in fraud.

00:02:06.060 --> 00:02:08.356
There are whistle-blowers
like Michael Woodford,

00:02:08.380 --> 00:02:10.716
who blew the whistle on Olympus.

00:02:10.740 --> 00:02:13.436
These whistle-blowers risk their careers,

00:02:13.460 --> 00:02:14.676
their friendships,

00:02:14.700 --> 00:02:16.836
to bring out the truth
about their companies.

00:02:16.860 --> 00:02:19.476
There are journalists
like Anna Politkovskaya

00:02:19.500 --> 00:02:23.356
who risk even their lives
to report human rights violations.

00:02:23.380 --> 00:02:24.596
She got killed --

00:02:24.620 --> 00:02:25.836
every year,

00:02:25.860 --> 00:02:27.516
around 100 journalists get killed

00:02:27.540 --> 00:02:30.260
because of their conviction
to bring out the truth.

00:02:31.860 --> 00:02:33.116
So in my talk today,

00:02:33.140 --> 00:02:36.636
I want to share with you
some insights I've obtained and learned

00:02:36.660 --> 00:02:39.956
in the last 10 years
of conducting research in this.

00:02:39.980 --> 00:02:43.476
I'm a researcher,
a scientist working with economists,

00:02:43.500 --> 00:02:44.836
financial economists,

00:02:44.860 --> 00:02:46.916
ethicists, neuroscientists,

00:02:46.940 --> 00:02:48.276
lawyers and others

00:02:48.300 --> 00:02:50.396
trying to understand
what makes humans tick,

00:02:50.420 --> 00:02:55.196
and how can we address this issue
of fraud in corporations

00:02:55.220 --> 00:02:58.380
and therefore contribute
to the improvement of the world.

00:02:59.100 --> 00:03:02.636
I want to start by sharing with you
two very distinct visions

00:03:02.660 --> 00:03:04.476
of how people behave.

00:03:04.500 --> 00:03:06.340
First, meet Adam Smith,

00:03:07.020 --> 00:03:08.980
founding father of modern economics.

00:03:10.100 --> 00:03:14.396
His basic idea was that if everybody
behaves in their own self-interests,

00:03:14.420 --> 00:03:16.940
that's good for everybody in the end.

00:03:17.900 --> 00:03:20.956
Self-interest isn't
a narrowly defined concept

00:03:20.980 --> 00:03:22.916
just for your immediate utility.

00:03:22.940 --> 00:03:24.876
It has a long-run implication.

00:03:24.900 --> 00:03:26.380
Let's think about that.

00:03:26.900 --> 00:03:28.916
Think about this dog here.

00:03:28.940 --> 00:03:30.140
That might be us.

00:03:31.260 --> 00:03:32.516
There's this temptation --

00:03:32.540 --> 00:03:34.916
I apologize to all vegetarians, but --

00:03:34.940 --> 00:03:35.956
(Laughter)

00:03:35.980 --> 00:03:37.676
Dogs do like the bratwurst.

00:03:37.700 --> 00:03:40.076
(Laughter)

00:03:40.100 --> 00:03:43.196
Now, the straight-up,
self-interested move here

00:03:43.220 --> 00:03:44.796
is to go for that.

00:03:44.820 --> 00:03:47.756
So my friend Adam here might jump up,

00:03:47.780 --> 00:03:51.140
get the sausage and thereby ruin
all this beautiful tableware.

00:03:51.820 --> 00:03:53.636
But that's not what Adam Smith meant.

00:03:53.660 --> 00:03:56.316
He didn't mean
disregard all consequences --

00:03:56.340 --> 00:03:57.556
to the contrary.

00:03:57.580 --> 00:03:58.836
He would have thought,

00:03:58.860 --> 00:04:00.876
well, there may be negative consequences,

00:04:00.900 --> 00:04:02.116
for example,

00:04:02.140 --> 00:04:05.236
the owner might be angry with the dog

00:04:05.260 --> 00:04:08.860
and the dog, anticipating that,
might not behave in this way.

00:04:09.660 --> 00:04:10.916
That might be us,

00:04:10.940 --> 00:04:13.996
weighing the benefits
and costs of our actions.

00:04:14.020 --> 00:04:15.260
How does that play out?

00:04:15.780 --> 00:04:17.756
Well, many of you, I'm sure,

00:04:17.780 --> 00:04:19.316
have in your companies,

00:04:19.340 --> 00:04:21.156
especially if it's a large company,

00:04:21.180 --> 00:04:22.836
a code of conduct.

00:04:22.860 --> 00:04:26.276
And then if you behave
according to that code of conduct,

00:04:26.300 --> 00:04:29.476
that improves your chances
of getting a bonus payment.

00:04:29.500 --> 00:04:31.635
And on the other hand,
if you disregard it,

00:04:31.659 --> 00:04:34.396
then there are higher chances
of not getting your bonus

00:04:34.420 --> 00:04:35.956
or its being diminished.

00:04:35.980 --> 00:04:37.236
In other words,

00:04:37.260 --> 00:04:39.076
this is a very economic motivation

00:04:39.100 --> 00:04:41.876
of trying to get people to be more honest,

00:04:41.900 --> 00:04:45.260
or more aligned with
the corporation's principles.

00:04:46.060 --> 00:04:51.316
Similarly, reputation is a very
powerful economic force, right?

00:04:51.340 --> 00:04:52.876
We try to build a reputation,

00:04:52.900 --> 00:04:54.316
maybe for being honest,

00:04:54.340 --> 00:04:56.740
because then people
trust us more in the future.

00:04:57.780 --> 00:04:58.996
Right?

00:04:59.020 --> 00:05:01.116
Adam Smith talked about the baker

00:05:01.140 --> 00:05:04.916
who's not producing good bread
out of his benevolence

00:05:04.940 --> 00:05:07.956
for those people who consume the bread,

00:05:07.980 --> 00:05:11.020
but because he wants to sell
more future bread.

00:05:11.980 --> 00:05:14.196
In my research, we find, for example,

00:05:14.220 --> 00:05:15.596
at the University of Zurich,

00:05:15.620 --> 00:05:19.820
that Swiss banks
who get caught up in media,

00:05:20.540 --> 00:05:22.316
and in the context, for example,

00:05:22.340 --> 00:05:23.876
of tax evasion, of tax fraud,

00:05:23.900 --> 00:05:25.636
have bad media coverage.

00:05:25.660 --> 00:05:28.396
They lose net new money in the future

00:05:28.420 --> 00:05:30.036
and therefore make lower profits.

00:05:30.060 --> 00:05:32.420
That's a very powerful reputational force.

00:05:34.020 --> 00:05:35.620
Benefits and costs.

00:05:36.940 --> 00:05:39.516
Here's another viewpoint of the world.

00:05:39.540 --> 00:05:41.076
Meet Immanuel Kant,

00:05:41.100 --> 00:05:43.860
18th-century German philosopher superstar.

00:05:44.740 --> 00:05:46.356
He developed this notion

00:05:46.380 --> 00:05:49.516
that independent of the consequences,

00:05:49.540 --> 00:05:52.516
some actions are just right

00:05:52.540 --> 00:05:54.236
and some are just wrong.

00:05:54.260 --> 00:05:57.476
It's just wrong to lie, for example.

00:05:57.500 --> 00:06:00.636
So, meet my friend Immanuel here.

00:06:00.660 --> 00:06:03.476
He knows that the sausage is very tasty,

00:06:03.500 --> 00:06:05.956
but he's going to turn away
because he's a good dog.

00:06:05.980 --> 00:06:08.676
He knows it's wrong to jump up

00:06:08.700 --> 00:06:11.500
and risk ruining
all this beautiful tableware.

00:06:12.340 --> 00:06:14.756
If you believe that people
are motivated like that,

00:06:14.780 --> 00:06:16.956
then all the stuff about incentives,

00:06:16.980 --> 00:06:20.756
all the stuff about code of conduct
and bonus systems and so on,

00:06:20.780 --> 00:06:22.956
doesn't make a whole lot of sense.

00:06:22.980 --> 00:06:27.156
People are motivated
by different values perhaps.

00:06:27.180 --> 00:06:30.556
So, what are people actually motivated by?

00:06:30.580 --> 00:06:32.756
These two gentlemen here
have perfect hairdos,

00:06:32.780 --> 00:06:37.260
but they give us
very different views of the world.

00:06:37.660 --> 00:06:38.916
What do we do with this?

00:06:38.940 --> 00:06:40.596
Well, I'm an economist

00:06:40.620 --> 00:06:44.796
and we conduct so-called experiments
to address this issue.

00:06:44.820 --> 00:06:48.116
We strip away facts
which are confusing in reality.

00:06:48.140 --> 00:06:50.876
Reality is so rich,
there is so much going on,

00:06:50.900 --> 00:06:54.860
it's almost impossible to know
what drives people's behavior really.

00:06:55.340 --> 00:06:58.060
So let's do a little experiment together.

00:06:58.500 --> 00:07:01.100
Imagine the following situation.

00:07:02.220 --> 00:07:04.636
You're in a room alone,

00:07:04.660 --> 00:07:06.196
not like here.

00:07:06.220 --> 00:07:09.660
There's a five-franc coin
like the one I'm holding up right now

00:07:10.380 --> 00:07:11.956
in front of you.

00:07:11.980 --> 00:07:13.556
Here are your instructions:

00:07:13.580 --> 00:07:16.060
toss the coin four times,

00:07:17.620 --> 00:07:20.036
and then on a computer
terminal in front of you,

00:07:20.060 --> 00:07:23.716
enter the number of times tails came up.

00:07:23.740 --> 00:07:25.020
This is the situation.

00:07:25.540 --> 00:07:26.756
Here's the rub.

00:07:26.780 --> 00:07:30.156
For every time that you announce
that you had a tails throw,

00:07:30.180 --> 00:07:31.676
you get paid five francs.

00:07:31.700 --> 00:07:34.236
So if you say I had two tails throws,

00:07:34.260 --> 00:07:36.476
you get paid 10 francs.

00:07:36.500 --> 00:07:39.436
If you say you had zero,
you get paid zero francs.

00:07:39.460 --> 00:07:41.916
If you say, "I had four tails throws,"

00:07:41.940 --> 00:07:43.956
then you get paid 20 francs.

00:07:43.980 --> 00:07:45.236
It's anonymous,

00:07:45.260 --> 00:07:47.156
nobody's watching what you're doing,

00:07:47.180 --> 00:07:49.516
and you get paid that money anonymously.

00:07:49.540 --> 00:07:51.017
I've got two questions for you.

00:07:51.580 --> 00:07:53.196
(Laughter)

00:07:53.220 --> 00:07:54.860
You know what's coming now, right?

00:07:55.820 --> 00:07:59.300
First, how would you behave
in that situation?

00:08:00.060 --> 00:08:02.996
The second, look to your left
and look to your right --

00:08:03.020 --> 00:08:04.036
(Laughter)

00:08:04.060 --> 00:08:06.436
and think about how
the person sitting next to you

00:08:06.460 --> 00:08:08.116
might behave in that situation.

00:08:08.140 --> 00:08:10.276
We did this experiment for real.

00:08:10.300 --> 00:08:12.996
We did it at the Manifesta art exhibition

00:08:13.020 --> 00:08:15.476
that took place here in Zurich recently,

00:08:15.500 --> 00:08:18.356
not with students in the lab
at the university

00:08:18.380 --> 00:08:20.156
but with the real population,

00:08:20.180 --> 00:08:21.380
like you guys.

00:08:21.900 --> 00:08:24.036
First, a quick reminder of stats.

00:08:24.060 --> 00:08:27.636
If I throw the coin four times
and it's a fair coin,

00:08:27.660 --> 00:08:31.756
then the probability
that it comes up four times tails

00:08:31.780 --> 00:08:34.180
is 6.25 percent.

00:08:34.900 --> 00:08:36.556
And I hope you can intuitively see

00:08:36.580 --> 00:08:39.956
that the probability that all four
of them are tails is much lower

00:08:39.980 --> 00:08:42.100
than if two of them are tails, right?

00:08:42.580 --> 00:08:44.020
Here are the specific numbers.

00:08:45.859 --> 00:08:47.355
Here's what happened.

00:08:47.379 --> 00:08:49.580
People did this experiment for real.

00:08:50.619 --> 00:08:53.955
Around 30 to 35 percent of people said,

00:08:53.979 --> 00:08:56.380
"Well, I had four tails throws."

00:08:57.460 --> 00:08:59.276
That's extremely unlikely.

00:08:59.300 --> 00:09:01.236
(Laughter)

00:09:01.260 --> 00:09:04.396
But the really amazing thing here,

00:09:04.420 --> 00:09:05.716
perhaps to an economist,

00:09:05.740 --> 00:09:12.276
is there are around 65 percent of people
who did not say I had four tails throws,

00:09:12.300 --> 00:09:14.476
even though in that situation,

00:09:14.500 --> 00:09:16.596
nobody's watching you,

00:09:16.620 --> 00:09:18.556
the only consequence that's in place

00:09:18.580 --> 00:09:21.916
is you get more money
if you say four than less.

00:09:21.940 --> 00:09:25.220
You leave 20 francs on the table
by announcing zero.

00:09:25.860 --> 00:09:28.436
I don't know whether
the other people all were honest

00:09:28.460 --> 00:09:31.916
or whether they also said a little bit
higher or lower than what they did

00:09:31.940 --> 00:09:33.156
because it's anonymous.

00:09:33.180 --> 00:09:34.836
We only observed the distribution.

00:09:34.860 --> 00:09:37.516
But what I can tell you --
and here's another coin toss.

00:09:37.540 --> 00:09:39.036
There you go, it's tails.

00:09:39.060 --> 00:09:40.556
(Laughter)

00:09:40.580 --> 00:09:42.036
Don't check, OK?

00:09:42.060 --> 00:09:44.876
(Laughter)

00:09:44.900 --> 00:09:46.196
What I can tell you

00:09:46.220 --> 00:09:50.660
is that not everybody behaved
like Adam Smith would have predicted.

00:09:52.660 --> 00:09:54.236
So what does that leave us with?

00:09:54.260 --> 00:09:58.756
Well, it seems people are motivated
by certain intrinsic values

00:09:58.780 --> 00:10:00.580
and in our research, we look at this.

00:10:01.260 --> 00:10:05.740
We look at the idea that people have
so-called protected values.

00:10:06.580 --> 00:10:09.396
A protected value isn't just any value.

00:10:09.420 --> 00:10:15.236
A protected value is a value
where you're willing to pay a price

00:10:15.260 --> 00:10:16.516
to uphold that value.

00:10:16.540 --> 00:10:20.980
You're willing to pay a price
to withstand the temptation to give in.

00:10:22.020 --> 00:10:24.676
And the consequence is you feel better

00:10:24.700 --> 00:10:28.996
if you earn money in a way
that's consistent with your values.

00:10:29.020 --> 00:10:33.300
Let me show you this again
in the metaphor of our beloved dog here.

00:10:34.420 --> 00:10:38.476
If we succeed in getting the sausage
without violating our values,

00:10:38.500 --> 00:10:40.476
then the sausage tastes better.

00:10:40.500 --> 00:10:41.980
That's what our research shows.

00:10:42.540 --> 00:10:43.796
If, on the other hand,

00:10:43.820 --> 00:10:45.076
we do so --

00:10:45.100 --> 00:10:46.516
if we get the sausage

00:10:46.540 --> 00:10:49.996
and in doing so
we actually violate values,

00:10:50.020 --> 00:10:52.996
we value the sausage less.

00:10:53.020 --> 00:10:55.476
Quantitatively, that's quite powerful.

00:10:55.500 --> 00:10:57.956
We can measure these protected values,

00:10:57.980 --> 00:10:59.196
for example,

00:10:59.220 --> 00:11:01.140
by a survey measure.

00:11:02.180 --> 00:11:08.156
Simple, nine-item survey that's quite
predictive in these experiments.

00:11:08.180 --> 00:11:10.516
If you think about the average
of the population

00:11:10.540 --> 00:11:12.636
and then there's
a distribution around it --

00:11:12.660 --> 00:11:14.700
people are different,
we all are different.

00:11:15.300 --> 00:11:18.276
People who have a set of protected values

00:11:18.300 --> 00:11:22.476
that's one standard deviation
above the average,

00:11:22.500 --> 00:11:27.556
they discount money they receive
by lying by about 25 percent.

00:11:27.580 --> 00:11:31.196
That means a dollar received when lying

00:11:31.220 --> 00:11:33.356
is worth to them only 75 cents

00:11:33.380 --> 00:11:37.076
without any incentives you put in place
for them to behave honestly.

00:11:37.100 --> 00:11:38.836
It's their intrinsic motivation.

00:11:38.860 --> 00:11:40.716
By the way, I'm not a moral authority.

00:11:40.740 --> 00:11:43.660
I'm not saying I have
all these beautiful values, right?

00:11:44.260 --> 00:11:46.196
But I'm interested in how people behave

00:11:46.220 --> 00:11:49.596
and how we can leverage
that richness in human nature

00:11:49.620 --> 00:11:53.060
to actually improve
the workings of our organizations.

00:11:54.220 --> 00:11:57.396
So there are two
very, very different visions here.

00:11:57.420 --> 00:11:58.756
On the one hand,

00:11:58.780 --> 00:12:01.796
you can appeal to benefits and costs

00:12:01.820 --> 00:12:04.476
and try to get people
to behave according to them.

00:12:04.500 --> 00:12:06.116
On the other hand,

00:12:06.140 --> 00:12:10.156
you can select people who have the values

00:12:10.180 --> 00:12:12.396
and the desirable
characteristics, of course --

00:12:12.420 --> 00:12:15.996
competencies that go
in line with your organization.

00:12:16.020 --> 00:12:20.236
I do not yet know where
these protected values really come from.

00:12:20.260 --> 00:12:23.636
Is it nurture or is it nature?

00:12:23.660 --> 00:12:25.036
What I can tell you

00:12:25.060 --> 00:12:30.156
is that the distribution
looks pretty similar for men and women.

00:12:30.180 --> 00:12:33.956
It looks pretty similar
for those who had studied economics

00:12:33.980 --> 00:12:36.340
or those who had studied psychology.

00:12:37.820 --> 00:12:41.196
It looks even pretty similar
around different age categories

00:12:41.220 --> 00:12:42.436
among adults.

00:12:42.460 --> 00:12:45.116
But I don't know yet
how this develops over a lifetime.

00:12:45.140 --> 00:12:48.580
That will be the subject
of future research.

00:12:49.460 --> 00:12:51.116
The idea I want to leave you with

00:12:51.140 --> 00:12:53.916
is it's all right to appeal to incentives.

00:12:53.940 --> 00:12:55.156
I'm an economist;

00:12:55.180 --> 00:12:58.100
I certainly believe in the fact
that incentives work.

00:12:59.220 --> 00:13:03.236
But do think about selecting
the right people

00:13:03.260 --> 00:13:06.756
rather than having people
and then putting incentives in place.

00:13:06.780 --> 00:13:09.036
Selecting the right people
with the right values

00:13:09.060 --> 00:13:12.996
may go a long way
to saving a lot of trouble

00:13:13.020 --> 00:13:14.396
and a lot of money

00:13:14.420 --> 00:13:16.156
in your organizations.

00:13:16.180 --> 00:13:17.436
In other words,

00:13:17.460 --> 00:13:21.220
it will pay off to put people first.

00:13:21.860 --> 00:13:23.076
Thank you.

00:13:23.100 --> 00:13:26.740
(Applause)

