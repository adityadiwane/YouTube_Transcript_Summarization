WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Laszlo Kereszturi
Corector: Ariana Bleau Lugo

00:00:25.000 --> 00:00:28.000
Fac două lucruri. Proiectez calculatoare mobile și studiez creierul.

00:00:29.000 --> 00:00:31.000
Şi discursul de azi este despre creier și

00:00:31.000 --> 00:00:33.000
vai, am găsit acolo un iubitor de creiere.

00:00:33.000 --> 00:00:35.000
(Râsete)

00:00:35.000 --> 00:00:37.000
Voi prezenta, dacă prima imagine va apare aici sus,

00:00:37.000 --> 00:00:41.000
și veți vedea titlul discursului meu și cele două afilieri ale mele.

00:00:41.000 --> 00:00:45.000
Deci voi vorbi despre motivul pentru care nu avem o teorie bună a creierului,

00:00:45.000 --> 00:00:48.000
de ce este important să dezvoltăm una și ce putem face pentru asta.

00:00:48.000 --> 00:00:51.000
Și voi încerca să fac asta în 20 de minute. Am două afilieri.

00:00:51.000 --> 00:00:54.000
Majoritatea din voi mă cunoașteți din zilele mele la Palm și Handspring,

00:00:54.000 --> 00:00:57.000
dar conduc și un institut de cercetare științifică non-profit,

00:00:57.000 --> 00:00:59.000
numit Institutul de Neuroștiință Redwood în Menlo Park,

00:00:59.000 --> 00:01:01.000
și studiem neuroștiință teoretică,

00:01:01.000 --> 00:01:03.000
și studiem cum lucrează neocortexul.

00:01:03.000 --> 00:01:05.000
Voi vorbi despre asta.

00:01:05.000 --> 00:01:08.000
Am o imagine despre cealaltă viață, cea dedicată calculatoarelor, iat-o.

00:01:08.000 --> 00:01:11.000
Acestea sunt unele din produsele la care am lucrat în ultimii 20 de ani,

00:01:11.000 --> 00:01:15.000
pornind de la primele laptopuri până la calculatoarele tip touchscreen.

00:01:15.000 --> 00:01:17.000
și așa mai departe, terminând cu cel mai recent Treo,

00:01:17.000 --> 00:01:19.000
și continuăm să facem asta.

00:01:19.000 --> 00:01:21.000
Și am făcut asta fiindcă cred într-adevăr că, calculatoarele mobile

00:01:21.000 --> 00:01:24.000
sunt viitorul calculatoarelor personale, și încerc să fac lumea

00:01:24.000 --> 00:01:27.000
un pic mai bună lucrând la aceste lucruri.

00:01:27.000 --> 00:01:29.000
Dar asta a fost - trebuie să recunosc - un accident.

00:01:29.000 --> 00:01:31.000
De fapt nu am vrut să fac niciunul din aceste produse

00:01:31.000 --> 00:01:33.000
și foarte devreme în cariera mea am decis

00:01:33.000 --> 00:01:36.000
că nu voi lucra în industria calculatoarelor.

00:01:36.000 --> 00:01:38.000
Și înainte să vă vorbesc despre asta, trebuie să vă spun despre

00:01:38.000 --> 00:01:40.000
această mică poză luată de pe web zilele trecute.

00:01:40.000 --> 00:01:43.000
Căutam o poză despre graffiti, un mic limbaj de introducere a textului,

00:01:43.000 --> 00:01:46.000
și am găsit pagina web dedicată învățătorilor care vor să facă astea,

00:01:46.000 --> 00:01:49.000
textul afișat în partea de sus a tablei,

00:01:49.000 --> 00:01:52.000
și i-au adăugat graffiti, și îmi pare rău pentru asta.

00:01:52.000 --> 00:01:54.000
(Râsete)

00:01:54.000 --> 00:01:59.000
Ce s-a întâmplat a fost că pe când eram tânăr și terminasem școala de inginerie,

00:01:59.000 --> 00:02:03.000
Cornell în 1979, am decis să lucrez pentru Intel.

00:02:03.000 --> 00:02:06.000
Eram în industria computerelor și la trei luni după asta,

00:02:06.000 --> 00:02:10.000
m-am îndrăgostit de altceva, și am spus " Am ales cariera greșită aici",

00:02:10.000 --> 00:02:13.000
și m-am îndrăgostit de creier.

00:02:13.000 --> 00:02:16.000
Acesta nu este un creier real. Este poza unuia, un desen.

00:02:16.000 --> 00:02:19.000
Dar nu-mi aduc aminte cum s-a întâmplat exact,

00:02:19.000 --> 00:02:22.000
dar am o amintire, care este foarte vie în mintea mea.

00:02:22.000 --> 00:02:25.000
În septembrie 1979 a apărut revista Scientific American

00:02:25.000 --> 00:02:28.000
cu un număr despre un singur subiect: creierul. Și era destul de bun.

00:02:28.000 --> 00:02:31.000
A fost unul din cele mai bune numere. Și vorbeau despre neuron

00:02:31.000 --> 00:02:33.000
și dezvoltare și boli și viziune și toate lucrurile

00:02:33.000 --> 00:02:36.000
pe care ai vrea să le știi despre creier. A fost foarte impresionant.

00:02:36.000 --> 00:02:39.000
Și ați fi putut avea impresia că noi chiar știm multe despre creier.

00:02:39.000 --> 00:02:43.000
Dar ultimul articol din revistă era scris de Francis Crick, vestit pentru ADN.

00:02:43.000 --> 00:02:46.000
Azi este, cred, a 50-a aniversare a descoperirii [structurii] ADN-ului.

00:02:46.000 --> 00:02:48.000
Și el a scris un articol care spunea de fapt

00:02:48.000 --> 00:02:51.000
că este în regulă și este bine, dar știți ceva,

00:02:51.000 --> 00:02:53.000
noi nu știm câtuși de puțin despre creier

00:02:53.000 --> 00:02:55.000
și nimeni n-are vagă idee despre cum funcționează,

00:02:55.000 --> 00:02:57.000
așa că nu credeți ce vă spune oricine.

00:02:57.000 --> 00:03:00.000
Ăsta-i un citat din acel articol. El a spus "Ceea ce lipsește în mod vădit,"

00:03:00.000 --> 00:03:04.000
e un adevărat gentleman britanic, așa că "Ceea ce lipsește în mod vădit

00:03:04.000 --> 00:03:07.000
este un cadru larg de idei în care să interpretăm diferitele abordări."

00:03:07.000 --> 00:03:09.000
Cuvântul cadru e grozav, mă gândeam.

00:03:09.000 --> 00:03:11.000
El nu spunea că nici măcar nu avem o teorie. El spunea

00:03:11.000 --> 00:03:13.000
că nici macar nu știm cum să începem să ne gândim la ea --

00:03:13.000 --> 00:03:15.000
că nici măcar nu avem un cadru.

00:03:15.000 --> 00:03:18.000
Suntem în zilele pre-paradigmă, dacă vreți să folosiți termenul lui Thomas Kuhn.

00:03:18.000 --> 00:03:21.000
Așa că m-am îndrăgostit de asta și mi-am zis,

00:03:21.000 --> 00:03:24.000
avem toate aceste cunoștințe despre creier. Cât de greu poate fi?

00:03:24.000 --> 00:03:27.000
Iar asta e ceva la care pot lucra toată viața. Simțeam că pot contribui,

00:03:27.000 --> 00:03:31.000
și astfel am încercat să ies din afacerea calculatoarelor și să intru în afacerea creierelor

00:03:31.000 --> 00:03:33.000
Întâi m-am dus la institutul MIT, la laboratorul de Inteligență Artificială,

00:03:33.000 --> 00:03:35.000
și le-am zis: și eu vreau să construiesc mașini inteligente,

00:03:35.000 --> 00:03:38.000
dar modul în care vreau s-o fac, este să studiez întâi cum lucrează creierul.

00:03:38.000 --> 00:03:41.000
Si ei au spus, oh, nu este nevoie să faci asta.

00:03:41.000 --> 00:03:43.000
Noi vom programa calculatoare, asta-i tot ce facem.

00:03:43.000 --> 00:03:46.000
Iar eu am spus, nu, voi ar trebui să studiați creierul. Ei au spus, oh, știi,

00:03:46.000 --> 00:03:48.000
tu greșești. Și eu am spus, nu, voi greșiți, și nu am intrat.

00:03:48.000 --> 00:03:49.000
(Râsete)

00:03:50.000 --> 00:03:52.000
Dar am fost un pic dezamăgit -- destul de tânăr, dar m-am întors

00:03:52.000 --> 00:03:55.000
peste câțiva ani, de data asta în California, și m-am dus la Berkeley.

00:03:55.000 --> 00:03:59.000
Și mi-am spus, voi intra prin partea biologică.

00:03:59.000 --> 00:04:02.000
Așa că am intrat -- în programul de doctorat în Biofizică, și a fost bine,

00:04:02.000 --> 00:04:05.000
studiam creierul acum, și am zis, ei bine, vreau să studiez teoria.

00:04:05.000 --> 00:04:07.000
Iar ei au spus, oh nu, nu poți studia teoria despre creier.

00:04:07.000 --> 00:04:09.000
Asta nu se face. Nu poți primi finanțare pentru asta.

00:04:09.000 --> 00:04:13.000
Iar ca student doctorand, nu poți face asta. Așa că am zis, oh Doamne!

00:04:13.000 --> 00:04:15.000
Am fost foarte deprimat. Le-am spus: dar pot aduce o contribuție în acest domeniu.

00:04:15.000 --> 00:04:18.000
Așa că ce am făcut, m-am întors în industria calculatoarelor

00:04:18.000 --> 00:04:20.000
și am zis: va trebui să lucrez aici o vreme, să fac ceva.

00:04:20.000 --> 00:04:23.000
Atunci am proiectat acele calculatoare.

00:04:23.000 --> 00:04:24.000
(Râsete)

00:04:24.000 --> 00:04:27.000
Vroiam să fac asta patru ani, să strâng niște bani,

00:04:27.000 --> 00:04:31.000
să am o familie, să mă maturizez un pic,

00:04:31.000 --> 00:04:34.000
și poate și domeniul științei creierului se va maturiza un pic.

00:04:34.000 --> 00:04:37.000
Ei bine, a durat mai mult de 4 ani. Au trecut cam 16 .

00:04:37.000 --> 00:04:39.000
Dar mă ocup de asta acum și vă voi vorbi de ea în continuare.

00:04:39.000 --> 00:04:42.000
Deci de ce avem nevoie de o teorie bună a creierului?

00:04:42.000 --> 00:04:45.000
Sunt multe motive pentru care oamenii se ocupă de știință.

00:04:45.000 --> 00:04:48.000
Unul -- cel mai de bază -- este că oamenilor le place să știe lucruri.

00:04:48.000 --> 00:04:50.000
Suntem curioși, pur si simplu ieșim în lume să obținem cunoaștere.

00:04:50.000 --> 00:04:52.000
De ce studiem furnicile? Păi, pentru că-i interesant.

00:04:52.000 --> 00:04:55.000
Poate vom învăța ceva util din asta, dar este interesant și fascinant.

00:04:55.000 --> 00:04:57.000
Dar câteodată, o știință are și alte calități

00:04:57.000 --> 00:04:59.000
care o fac foarte, foarte interesantă.

00:04:59.000 --> 00:05:02.000
Câteodată o știință va spune ceva despre noi înșine,

00:05:02.000 --> 00:05:03.000
ne va spune cine suntem.

00:05:03.000 --> 00:05:06.000
Arareori, evoluția a facut asta și Copernic a făcut asta,

00:05:06.000 --> 00:05:08.000
dobîndim o nouă înțelegere despre cine suntem noi.

00:05:08.000 --> 00:05:12.000
Și la urma urmei, noi suntem creierul nostru. Creierul meu vorbește creierului tău.

00:05:12.000 --> 00:05:15.000
Corpurile noastre sunt și ele pe acolo, dar creierul meu vorbește creierului tău.

00:05:15.000 --> 00:05:18.000
Și dacă înțelegem cine suntem și cum simțim și percepem,

00:05:18.000 --> 00:05:20.000
vom înțelege ce este creierul.

00:05:20.000 --> 00:05:22.000
Un alt lucru este că știința conduce

00:05:22.000 --> 00:05:24.000
câteodată la mari beneficii sociale și tehnologice,

00:05:24.000 --> 00:05:26.000
sau de afaceri, sau altceva, care rezultă din ea. Și asta este

00:05:26.000 --> 00:05:29.000
fiindcă atunci când înțelegem cum lucrează creierul, vom fi în stare

00:05:29.000 --> 00:05:32.000
să construim mașini inteligente. Iar eu cred că asta este de fapt un lucru bun

00:05:32.000 --> 00:05:34.000
și va aduce beneficii imense societății,

00:05:34.000 --> 00:05:36.000
exact ca tehnologia fundamentală.

00:05:36.000 --> 00:05:38.000
Deci de ce nu avem o teorie bună a creierului?

00:05:38.000 --> 00:05:41.000
Iar oamenii lucrează la asta de 100 de ani.

00:05:41.000 --> 00:05:43.000
Întâii să ne uităm cum funcționează știința normală.

00:05:43.000 --> 00:05:45.000
Asta este știința normală.

00:05:45.000 --> 00:05:49.000
Știința normală este un frumos echilibru între teorie și experimentatori.

00:05:49.000 --> 00:05:51.000
Teoreticianul spune, păi, eu cred că asta se întâmplă,

00:05:51.000 --> 00:05:53.000
și experimentatorul spune, nu, greșești.

00:05:53.000 --> 00:05:55.000
Și tot așa, înainte și înapoi, înțelegeți?

00:05:55.000 --> 00:05:57.000
Asta funcționează în fizică și în geologie. Dar dacă asta este știința normală,

00:05:57.000 --> 00:06:00.000
cum arată știința creierului? Așa arată știința creierului.

00:06:00.000 --> 00:06:05.000
Avem acest munte de date, care provin din anatomie, fiziologie și comportament.

00:06:05.000 --> 00:06:08.000
Nu vă puteți închipui cât de multe detalii știm despre creier.

00:06:08.000 --> 00:06:12.000
28000 de oameni au participat la conferințe de știința creierului anul ăsta,

00:06:12.000 --> 00:06:14.000
și fiecare din ei face cercetare asupra creierului.

00:06:14.000 --> 00:06:18.000
O mulțime de date. Dar nu există nici o teorie. E o cutie mică, anemică acolo în vârf.

00:06:18.000 --> 00:06:23.000
Iar teoria nu a jucat niciun rol major în știința creierului.

00:06:23.000 --> 00:06:26.000
Și asta-i într-adevăr, păcat. De ce s-a ajuns la asta?

00:06:26.000 --> 00:06:28.000
Dacă întrebați cercetători ai sistemului nervos, de ce este asta starea?

00:06:28.000 --> 00:06:31.000
Ei vor recunoaște întâii. Dar dacă îi întrebați,

00:06:31.000 --> 00:06:34.000
vor spune că sunt motive diverse pentru care nu avem o teorie bună a creierului.

00:06:34.000 --> 00:06:36.000
Unii oameni spun că totuși încă nu avem destule date,

00:06:36.000 --> 00:06:39.000
trebuie să obținem mai multă informație, mai sunt toate aceste lucruri pe care nu le știm.

00:06:39.000 --> 00:06:42.000
Ei bine, tocmai v-am spus că există așa de multe date că vă ies pe urechi.

00:06:42.000 --> 00:06:45.000
Avem așa de multă informație; nu știm cum să începem s-o organizăm.

00:06:45.000 --> 00:06:47.000
La ce ar fi bună și mai multă?

00:06:47.000 --> 00:06:50.000
Poate vom avea noroc să descoperim ceva magic, dar nu cred.

00:06:50.000 --> 00:06:53.000
Acesta este de fapt un simptom al faptului că încă nu avem o teorie.

00:06:53.000 --> 00:06:56.000
Nu avem nevoie de mai multe date -- avem nevoie de o teorie bună despre creier.

00:06:56.000 --> 00:06:59.000
Altă dată oamenii spun, păi, creierul este așa de complex,

00:06:59.000 --> 00:07:01.000
încât ne va lua încă 50 de ani.

00:07:01.000 --> 00:07:03.000
Cred că chiar Chris a zis așa ceva ieri.

00:07:03.000 --> 00:07:05.000
Nu sunt sigur ce ai spus Chris, dar era ceva similar,

00:07:05.000 --> 00:07:08.000
creierul este cel mai complicat lucru din univers. Asta nu-i adevărat.

00:07:08.000 --> 00:07:10.000
Tu ești mai complicat decât creierul tău. Tu ai creier.

00:07:10.000 --> 00:07:12.000
Și mai este că, deși creierul arată foarte complicat,

00:07:12.000 --> 00:07:15.000
lucrurile par complicate până le înțelegi.

00:07:15.000 --> 00:07:18.000
Așa a fost întotdeauna. Deci putem zice e că neocortexul meu,

00:07:18.000 --> 00:07:22.000
care-i parte a creierului de care sunt interesat, are 30 de miliarde de celule.

00:07:22.000 --> 00:07:24.000
Dar știți ceva? Este foarte, foarte regulat.

00:07:24.000 --> 00:07:27.000
De fapt, arată ca același lucru repetat din nou și din nou.

00:07:27.000 --> 00:07:30.000
Nu este așa de complex cum arată. Nu asta este problema.

00:07:30.000 --> 00:07:32.000
Unii oameni spun, creierul nu poate înțelege creierul.

00:07:32.000 --> 00:07:35.000
Sună a zen. Uau. Știți --

00:07:35.000 --> 00:07:36.000
(Râsete)

00:07:36.000 --> 00:07:39.000
Sună bine, dar de ce? Adică care este sensul?

00:07:39.000 --> 00:07:42.000
Creierul este doar o grămadă de celule. Înțelegi ficatul.

00:07:42.000 --> 00:07:44.000
Și ficatul are o grămadă de celule, corect?

00:07:44.000 --> 00:07:46.000
Așa că eu nu cred că asta este adevărat.

00:07:46.000 --> 00:07:48.000
Și în final, unii oameni spun, știți,

00:07:48.000 --> 00:07:52.000
eu nu mă simt ca o grămadă de celule. Eu sunt conștient.

00:07:52.000 --> 00:07:54.000
Am această experiență, sunt în lume.

00:07:54.000 --> 00:07:56.000
Nu pot fi doar o grămadă de celule. Ei bine, știți,

00:07:56.000 --> 00:07:59.000
oamenii credeau că există o forță vitală pentru a fi viu,

00:07:59.000 --> 00:08:01.000
iar acum știm că asta nu este deloc adevărat.

00:08:01.000 --> 00:08:04.000
Și nu există nici o dovadă care să spună că alții decât oamenii

00:08:04.000 --> 00:08:06.000
ar avea dubii că celulele pot face ceea ce vor ele.

00:08:06.000 --> 00:08:09.000
Așa încât, dacă unii oameni au căzut în capcana dualismului metafizic,

00:08:09.000 --> 00:08:12.000
chiar și unii oameni foarte deștepți, dar noi putem respinge toate astea.

00:08:12.000 --> 00:08:14.000
(Râsete)

00:08:14.000 --> 00:08:17.000
Nu, vă voi spune că este altceva,

00:08:17.000 --> 00:08:19.000
și este cu adevărat fundamental, și asta este:

00:08:19.000 --> 00:08:21.000
există alt motiv pentru care nu avem o teorie bună a creierului,

00:08:21.000 --> 00:08:24.000
iar asta este fiindcă avem o supoziție intuitivă, foarte puternică,

00:08:24.000 --> 00:08:29.000
dar incorectă, care ne-a împiedicat să vedem răspunsul.

00:08:29.000 --> 00:08:32.000
Există o presupunere care ni se pare evidentă, dar e de fapt greșită.

00:08:32.000 --> 00:08:36.000
Există o istorie a acestui lucru în știință și înainte să vă spun ce este,

00:08:36.000 --> 00:08:38.000
vă voi spune puțin despre istoria lui în știință.

00:08:38.000 --> 00:08:40.000
Priviți la alte revoluții științifice,

00:08:40.000 --> 00:08:42.000
și în acest caz, vorbesc despre sistemul solar, adică Copernic,

00:08:42.000 --> 00:08:45.000
teoria evoluției al lui Darwin, și plăcile tectonice ale lui Wegener.

00:08:45.000 --> 00:08:48.000
Acestea toate au multe în comun cu știința creierului.

00:08:48.000 --> 00:08:51.000
La început au avut o mulțime de date neexplicate. O mulțime.

00:08:51.000 --> 00:08:54.000
Dar au devenit mai ușor de gestionat odată ce au avut o teorie.

00:08:54.000 --> 00:08:57.000
Cele mai bune minți erau puse în încurcătură, oameni inteligenți.

00:08:57.000 --> 00:08:59.000
Nu suntem acum mai deștepți decât erau ei atunci.

00:08:59.000 --> 00:09:01.000
Se pare însă că este foarte greu să gândești la lucruri,

00:09:01.000 --> 00:09:03.000
dar odată ce te-ai gândit, este mai ușor să le înțelegi.

00:09:03.000 --> 00:09:05.000
Fiicele mele au înțeles aceste trei teorii

00:09:05.000 --> 00:09:08.000
în forma lor de bază pe când erau în grădiniță.

00:09:08.000 --> 00:09:11.000
Și acum nu-i așa de greu, știți, aici este mărul, aici portocala,

00:09:11.000 --> 00:09:14.000
Pământul se învârtește, acest tip de lucruri.

00:09:14.000 --> 00:09:16.000
În final, un alt lucru este că răspunsul a fost acolo tot timpul,

00:09:16.000 --> 00:09:19.000
dar l-am ignorat din cauza acestei erori intuitive care părea evident corectă.

00:09:19.000 --> 00:09:22.000
Era o convingere intuitivă, puternică care era greșită. Aici e cheia.

00:09:22.000 --> 00:09:25.000
În cazul sistemului solar, idea că Pământul se învârte

00:09:25.000 --> 00:09:28.000
și suprafața Pământului se mișcă cu 1.000 mile/oră,

00:09:28.000 --> 00:09:31.000
și Pământul se rotește în sistemul solar cu aprox. 1.000.000 mile/oră.

00:09:31.000 --> 00:09:33.000
Asta-i nebunie. Știm cu toții că Pământul nu se mișcă.

00:09:33.000 --> 00:09:35.000
Simțiți că vă deplasați cu 1.000 mile/ oră?

00:09:35.000 --> 00:09:37.000
Deigur că nu. Știți, dacă cineva ar fi spus,

00:09:37.000 --> 00:09:39.000
că Pământul se învârte și este așa de imens,

00:09:39.000 --> 00:09:41.000
l-ar fi închis, și chiar asta au și făcut pe atunci.

00:09:41.000 --> 00:09:42.000
(Râsete)

00:09:42.000 --> 00:09:45.000
Deci era intuitiv și evident. Acum, despre evoluție.

00:09:45.000 --> 00:09:48.000
Povestea evoluției e la fel. I-am învățat pe copiii noștri cum zice Biblia,

00:09:48.000 --> 00:09:50.000
Dumnezeu a creat toate speciile, pisicile sunt pisici, câini sunt câini,

00:09:50.000 --> 00:09:53.000
oamenii sunt oameni, plantele plante, nu se schimbă.

00:09:53.000 --> 00:09:57.000
Noe i-a pus în arca lui în acea ordine, bla, bla, bla.

00:09:57.000 --> 00:10:01.000
Adevărul este că, dacă credeți în evoluție, noi toți avem un strămoș comun,

00:10:01.000 --> 00:10:04.000
și avem un stămoș comun cu planta din hol.

00:10:04.000 --> 00:10:07.000
Asta ne spune evoluția. Și este adevărat. Pare de necrezut.

00:10:07.000 --> 00:10:10.000
Același lucru despre plăcile tectonice.

00:10:10.000 --> 00:10:12.000
Toți munții și continentele plutesc în jur

00:10:12.000 --> 00:10:16.000
pe suprafața Pământului. Pare că n-are niciun sens.

00:10:16.000 --> 00:10:20.000
Deci care este presupunerea intuitivă, dar incorectă

00:10:20.000 --> 00:10:22.000
care ne-a ținut în urmă în înțelegerea creierului?

00:10:22.000 --> 00:10:24.000
Acum o voi spune și va fi evident că este corectă,

00:10:24.000 --> 00:10:26.000
și asta-i tocmai esența, corect? Apoi voi argumenta

00:10:26.000 --> 00:10:28.000
de ce nu aveți dreptate despre cealaltă presupunere.

00:10:28.000 --> 00:10:31.000
Lucrul intuitiv dar evident este că inteligența este cumva

00:10:31.000 --> 00:10:33.000
definită de comportamentul nostru.

00:10:33.000 --> 00:10:35.000
că suntem inteligenți din cauza modului în care facem lucrurile

00:10:35.000 --> 00:10:38.000
și a modului în care ne comportăm inteligent, și vă voi spune că e greșit.

00:10:38.000 --> 00:10:40.000
De fapt inteligența este definită de prezicere.

00:10:40.000 --> 00:10:43.000
Și vă voi trece prin câteva imagini aici,

00:10:43.000 --> 00:10:47.000
vă voi da un exemplu. Iată un sistem.

00:10:47.000 --> 00:10:50.000
Inginerilor și oamenilor de știință le place să se uite la sisteme ca acesta.

00:10:50.000 --> 00:10:53.000
Ei spun: ei bine, avem un lucru într-o cutie și avem intrările și ieșirile.

00:10:53.000 --> 00:10:56.000
Cei de la AI (inteligența artificială) spun că lucrul din cutie este un calculator programabil,

00:10:56.000 --> 00:10:58.000
fiindcă asta este echivalent unui creier, și vom alimenta niște intrări

00:10:58.000 --> 00:11:00.000
și-l vom determina să facă ceva, să aibă o anumită comportare.

00:11:00.000 --> 00:11:03.000
Iar Alan Turing a definit testul Turing, care spune în esență că

00:11:03.000 --> 00:11:06.000
vom ști dacă ceva este inteligent, dacă se comportă identic cu un om.

00:11:06.000 --> 00:11:09.000
O metrică comportamentală a inteligenței,

00:11:09.000 --> 00:11:12.000
și asta ne-a blocat înțelegerea pentru mult timp.

00:11:12.000 --> 00:11:14.000
În realitate însă eu o numesc inteligență reală.

00:11:14.000 --> 00:11:16.000
Inteligența reală este construită pe altceva.

00:11:16.000 --> 00:11:20.000
Cunoaștem lumea printr-o secvență de tipare, le stocăm,

00:11:20.000 --> 00:11:23.000
și le readucem din memorie. Iar când le accesăm, le comparăm

00:11:23.000 --> 00:11:27.000
cu realitatea, și facem predicții tot timpul.

00:11:27.000 --> 00:11:30.000
E o metrică eternă. E o metrică eternă despre noi, care parcă spune:

00:11:30.000 --> 00:11:33.000
Înțelegem lumea? Fac eu predicții? Ș.a.m.d.

00:11:33.000 --> 00:11:35.000
Toți sunteți inteligenți chiar acum, dar nu faceți ceva deosebit pentru asta.

00:11:35.000 --> 00:11:37.000
Poate vă scărpinați, sau vă scobiți nasul,

00:11:37.000 --> 00:11:39.000
nu știu, dar nu faceți ceva deosebit chiar acum,

00:11:39.000 --> 00:11:42.000
dar fiind inteligenți, voi înțelegeți ceea ce spun.

00:11:42.000 --> 00:11:44.000
Fiindcă sunteți inteligenți și vorbiți engleza,

00:11:44.000 --> 00:11:45.000
voi știți ce cuvânt este la sfârșitul acestei -- (Liniște)

00:11:45.000 --> 00:11:47.000
fraze.

00:11:47.000 --> 00:11:50.000
Cuvântul v-a venit în minte, și faceți aceste predicții tot timpul.

00:11:50.000 --> 00:11:52.000
Ceea ce spun este că

00:11:52.000 --> 00:11:54.000
prezicerea eternă este concluzia neocortexului.

00:11:54.000 --> 00:11:57.000
Și cumva această prezicere duce la comportare inteligentă.

00:11:57.000 --> 00:12:00.000
Și iată cum se întâmplă. Să pornim cu creierele non-inteligente.

00:12:00.000 --> 00:12:04.000
Voi vorbi despre un creier non-inteligent, un creier vechi,

00:12:04.000 --> 00:12:07.000
să zicem că este al unui non-mamifer, al unei reptile,

00:12:07.000 --> 00:12:09.000
să zicem un aligator, avem un aligator.

00:12:09.000 --> 00:12:12.000
Iar aligatorul are niște simțuri foarte sofisticate.

00:12:12.000 --> 00:12:15.000
Are ochi și urechi bune și simțuri tactile și așa mai departe,

00:12:15.000 --> 00:12:19.000
o gură și un nas. Are o comportare foarte complexă.

00:12:19.000 --> 00:12:23.000
Poate fugi și se poate ascunde. Are temeri si emoții. Vă poate mânca.

00:12:23.000 --> 00:12:27.000
Poate ataca. Poate face tot felul de lucruri.

00:12:27.000 --> 00:12:32.000
Dar nu considerăm un aligator inteligent, cel puțin nu într-un mod uman.

00:12:32.000 --> 00:12:34.000
Dar are deja această comportare complexă.

00:12:34.000 --> 00:12:36.000
Acum, ce s-a întâmplat în evoluție?

00:12:36.000 --> 00:12:39.000
Primul lucru care s-a întâmplat la evoluția mamiferelor

00:12:39.000 --> 00:12:41.000
am început să dezvoltăm un lucru numit neocortex.

00:12:41.000 --> 00:12:43.000
Și voi reprezenta neocortexul aici,

00:12:43.000 --> 00:12:45.000
prin această cutie lipită deasupra vechiului creier.

00:12:45.000 --> 00:12:48.000
Neocortex însemnă = strat nou. E un strat nou peste creier.

00:12:48.000 --> 00:12:51.000
Dacă nu-l știți, e partea încrețită din vârful capului,

00:12:51.000 --> 00:12:54.000
care s-a încrețit fiindcă a fost înghesuită acolo și nu a încăput.

00:12:54.000 --> 00:12:55.000
(Râsete)

00:12:55.000 --> 00:12:57.000
Nu, pe bune, așa este. Este cam de mărimea unui șervet de masă.

00:12:57.000 --> 00:13:00.000
Nu încape, așa că-i plin de cute [circumvoluțiuni], cum am desenat aici.

00:13:00.000 --> 00:13:04.000
Vechiul creier este încă acolo. Mai aveți creierul de aligator.

00:13:04.000 --> 00:13:06.000
Îl aveți. Este creierul emoțional.

00:13:06.000 --> 00:13:09.000
Sunt toate acele lucruri și toate reacțiile instinctive pe care le aveți.

00:13:09.000 --> 00:13:12.000
Iar deasupra lui avem acest sistem de memorie, numit neocortex.

00:13:12.000 --> 00:13:16.000
Și sistemul de memorie stă deasupra părții senzoriale a creierului.

00:13:16.000 --> 00:13:19.000
Pe măsură ce vin intrările senzoriale și semnalele din creierul vechi,

00:13:19.000 --> 00:13:23.000
ele se duc și sus în neocortex. Iar neocortexul doar memorează.

00:13:23.000 --> 00:13:27.000
Stă acolo spunând: voi memora toate lucrurile care se întâmplă,

00:13:27.000 --> 00:13:29.000
unde am fost, oamenii pe care i-am văzut, lucrurile care le-am auzit, ș.a.m.d.

00:13:29.000 --> 00:13:33.000
Iar în viitor, când vede din nou ceva similar,

00:13:33.000 --> 00:13:36.000
deci intr-un mediu similar, sau în exact același mediu,

00:13:36.000 --> 00:13:38.000
îl redă. Va începe să-l redea.

00:13:38.000 --> 00:13:40.000
Oh, am mai fost aici. Și când ați mai fost aici înainte,

00:13:40.000 --> 00:13:43.000
asta s-a întâmplat în continuare. Vă permite să preziceți viitorul.

00:13:43.000 --> 00:13:47.000
În mod concret redă semnalele în creier și astfel vă permite

00:13:47.000 --> 00:13:49.000
să vedeți ce se va întâmpla în continuare,

00:13:49.000 --> 00:13:52.000
să auziți cuvântul "frază" înainte ca eu să-l fi spus.

00:13:52.000 --> 00:13:55.000
Și acest feedback spre creierul vechi

00:13:55.000 --> 00:13:58.000
vă permite să luați decizii mult mai inteligente.

00:13:58.000 --> 00:14:01.000
Asta-i cea mai importantă imagine din dicurs, așa că o voi explica puțin.

00:14:01.000 --> 00:14:05.000
Așa că tot timpul spuneți, oh, eu pot prezice lucrurile.

00:14:05.000 --> 00:14:08.000
Dacă sunteți un șobolan și mergeți printr-un labirint, și apoi învățați labirintul,

00:14:08.000 --> 00:14:10.000
data următoare când sunteți în labirint, aveți aceeași comportare,

00:14:10.000 --> 00:14:12.000
dar brusc, deodată sunteți mai deștept,

00:14:12.000 --> 00:14:15.000
fiindcă spuneți, oh, eu recunosc acest labirint, știu încotro să merg,

00:14:15.000 --> 00:14:18.000
am mai fost aici înainte, pot prevedea viitorul. Și asta-i ce face.

00:14:18.000 --> 00:14:21.000
La oameni, și apropo, e adevărat pentru toate mamiferele,

00:14:21.000 --> 00:14:23.000
la oameni a devenit mult mai serios.

00:14:23.000 --> 00:14:26.000
În oameni, noi am dezvoltat partea frontală a neocortexului,

00:14:26.000 --> 00:14:30.000
numită partea anterioară. Iar natura a făcut un mic truc.

00:14:30.000 --> 00:14:32.000
A copiat partea posterioară, din spate, care este senzorială,

00:14:32.000 --> 00:14:34.000
și a pus-o în partea din față.

00:14:34.000 --> 00:14:36.000
Și oamenii au în mod unic același mecanism în partea frontală,

00:14:36.000 --> 00:14:38.000
dar noi îl folosim pentru controlul mișcării.

00:14:38.000 --> 00:14:41.000
Așa că acum suntem în stare să planificăm mișcări sofisticate.

00:14:41.000 --> 00:14:44.000
N-am timp să detaliez, dar dacă vreți să înțelegeți cum funcționează creierul,

00:14:44.000 --> 00:14:47.000
trebuie să înțelegeți cum funcționează prima parte a neocortexului mamifer,

00:14:47.000 --> 00:14:49.000
cum stocăm tiparele și cum facem predicții.

00:14:49.000 --> 00:14:52.000
Să vă dau câteva exemple de predicții.

00:14:52.000 --> 00:14:54.000
V-am spus deja cuvântul de la sfârșitul frazei. În muzică,

00:14:54.000 --> 00:14:57.000
dacă ați auzit un cântec înainte, dacă ați mai auzit-o pe Jill cântând acele cântece,

00:14:57.000 --> 00:15:00.000
când le cântă, următoarea notă apare în capul vostru imediat --

00:15:00.000 --> 00:15:02.000
anticipați cântecul pe măsură ce-l auziți. Dacă ar fi un album muzical,

00:15:02.000 --> 00:15:05.000
la sfârșitul unei piese, următoarea piesă apare în capul vostru.

00:15:05.000 --> 00:15:07.000
Și aceste lucruri se întâmplă tot timpul. Faceți aceste predicții.

00:15:07.000 --> 00:15:10.000
Am numit acest lucru experimentul ușii modificate.

00:15:10.000 --> 00:15:13.000
Iar experimentul ușii modificate spune: aveți o ușă acasă,

00:15:13.000 --> 00:15:16.000
și în timp ce sunteți aici, eu o modific, am un tip

00:15:16.000 --> 00:15:18.000
acasă la voi chiar acum, modificând ușa,

00:15:18.000 --> 00:15:20.000
și ei vor muta clanța ușii cu vreo cinci centimetri.

00:15:20.000 --> 00:15:22.000
Și când ajungeți acasă deseară, veți pune mâna acolo,

00:15:22.000 --> 00:15:24.000
veți întinde mâna spre clanță și veți observa

00:15:24.000 --> 00:15:27.000
că este în alt loc, și veți înțelege că s-a întâmplat ceva.

00:15:27.000 --> 00:15:29.000
Poate lua o secundă până înțelegeți ce s-a întâmplat, dar ceva s-a întâmplat.

00:15:29.000 --> 00:15:31.000
Aș putea modifica clanța și în alte moduri.

00:15:31.000 --> 00:15:33.000
Pot s-o fac mai mare sau mai mică, pot s-o schimb din bronz în argint,

00:15:33.000 --> 00:15:35.000
pot s-o fac de tip mâner. Pot să vă schimb ușa, s-o colorez,

00:15:35.000 --> 00:15:38.000
pot să-i pun fereastră. Pot schimba o mie de lucruri la ușa voastră,

00:15:38.000 --> 00:15:40.000
și în cele două secunde necesare ca să deschideți ușa,

00:15:40.000 --> 00:15:43.000
veți observa că ceva s-a modificat.

00:15:43.000 --> 00:15:45.000
Acum, modul ingineresc de abordare, modul AI,

00:15:45.000 --> 00:15:48.000
e să construiască o bază de date a ușii, cu toate atributele ușii.

00:15:48.000 --> 00:15:51.000
Și când mergeți la ușă, le veți verifica una câte una, pe rând.

00:15:51.000 --> 00:15:53.000
Ușă, ușă, ușă, culoare, înțelegeți ce spun.

00:15:53.000 --> 00:15:55.000
Noi nu facem așa. Creierul vostru nu face asta.

00:15:55.000 --> 00:15:57.000
Creierul vostru face predicții constante tot timpul

00:15:57.000 --> 00:15:59.000
despre ce se va întâmpla în mediul înconjurător.

00:15:59.000 --> 00:16:02.000
Când pun mâna pe această masă, mă aștept să simt că se oprește.

00:16:02.000 --> 00:16:05.000
Când mă plimb, la fiecare pas, dacă greșesc pasul cu trei milimetri,

00:16:05.000 --> 00:16:07.000
voi ști că ceva s-a modificat.

00:16:07.000 --> 00:16:09.000
Faceți în mod constant predicții despre mediul vostru.

00:16:09.000 --> 00:16:12.000
Voi vorbi pe scurt despre vedere. Asta-i poza unei femei.

00:16:12.000 --> 00:16:14.000
Și când vă uitați la oameni, ochii voștri se mișcă

00:16:14.000 --> 00:16:15.000
de 2-3 ori pe secundă.

00:16:15.000 --> 00:16:17.000
Nu sunteți conștienți de asta, dar ochii voștri se mișcă continuu.

00:16:17.000 --> 00:16:19.000
Și când vă uitați la fața cuiva,

00:16:19.000 --> 00:16:21.000
în mod tipic mergeți de la un ochi la altul, apoi la nas, apoi la gură.

00:16:21.000 --> 00:16:23.000
Acum, când ochiul vostru se duce de la ochi la ochi,

00:16:23.000 --> 00:16:25.000
dacă ar fi fost altceva acolo, să zicem un nas,

00:16:25.000 --> 00:16:27.000
ați vedea un nas acolo unde ar trebui să fie un ochi,

00:16:27.000 --> 00:16:30.000
și ați spune: ei drăcie, --

00:16:30.000 --> 00:16:31.000
(Râsete)

00:16:31.000 --> 00:16:33.000
Ceva nu-i în regulă cu această persoană.

00:16:33.000 --> 00:16:35.000
Și asta fiindcă faceți predicții.

00:16:35.000 --> 00:16:37.000
Nu e doar ca și cum ați privi acolo și ați spune : ce văd acum?

00:16:37.000 --> 00:16:40.000
Un nas, e în regulă. Nu, aveți o așteptare a ceea ce veți vedea.

00:16:40.000 --> 00:16:41.000
(Râsete)

00:16:41.000 --> 00:16:45.000
În fiecare moment. Și în final, să ne gândim cum testăm inteligența.

00:16:45.000 --> 00:16:48.000
O testăm prin predicții. Care este următorul cuvânt în acest șir ?

00:16:48.000 --> 00:16:51.000
Ce element lipsește? Care este următorul număr în această secvență?

00:16:51.000 --> 00:16:53.000
Iată trei imagini ale unui obiect. Care-i a patra?

00:16:53.000 --> 00:16:57.000
Așa testăm inteligența. Totul se reduce la predicții.

00:16:57.000 --> 00:17:00.000
Deci care este rețeta pentru teoria creierului?

00:17:00.000 --> 00:17:03.000
În primul rând, trebuie să avem un context potrivit.

00:17:03.000 --> 00:17:05.000
Și contextul este unul de memorie,

00:17:05.000 --> 00:17:07.000
nu de calcul sau comportare. E un context de memorie.

00:17:07.000 --> 00:17:11.000
Cum stocați și accesați aceste secvențe sau modele spațio-temporale?

00:17:11.000 --> 00:17:14.000
Atunci, dacă acela-i contextul, să consultăm o mulțime de teoreticieni.

00:17:14.000 --> 00:17:16.000
Acum, biologii în general nu sunt buni teoreticieni.

00:17:16.000 --> 00:17:20.000
Nu-i întotdeauna adevărat, dar în general, nu există o istorie bună a teoriei în biologie.

00:17:20.000 --> 00:17:23.000
Așa că am concluzionat că cei mai buni oameni cu care să lucrez sunt

00:17:23.000 --> 00:17:26.000
fizicienii, inginerii și matematicienii, care tind să gândească algoritmic.

00:17:26.000 --> 00:17:29.000
Apoi ei trebuie să învețe anatomia și fiziologia.

00:17:29.000 --> 00:17:33.000
Trebuie să faci aceste teorii foarte realiste în termeni anatomici.

00:17:33.000 --> 00:17:37.000
Oricine își prezintă teoria despre funcționarea creierului

00:17:37.000 --> 00:17:39.000
și nu vă spune exact cum lucrează teoria în creier

00:17:39.000 --> 00:17:41.000
și cum lucrează conexiunile din creier, nu este o teorie.

00:17:41.000 --> 00:17:44.000
Și asta facem noi la Institutul de Neuroștiință Redwood.

00:17:44.000 --> 00:17:48.000
Aș vrea să am mai mult timp să vă spun cât de fantastic progresăm

00:17:48.000 --> 00:17:50.000
și mă aștept să revin pe această scenă,

00:17:50.000 --> 00:17:52.000
poate în viitorul nu prea îndepărtat și să vă vorbesc despre asta.

00:17:52.000 --> 00:17:55.000
Sunt foarte, foarte entuziasmat. Asta nu va dura deloc 50 de ani.

00:17:55.000 --> 00:17:57.000
Deci cum va arăta teoria creierului?

00:17:57.000 --> 00:17:59.000
Întâi, va fi o teorie despre memorie.

00:17:59.000 --> 00:18:02.000
Nu ca memoria din calculatoare. Nu e deloc ca memoria calculatoarelor.

00:18:02.000 --> 00:18:04.000
E foarte diferită. Și este o memorie a acestor modele imense,

00:18:04.000 --> 00:18:07.000
multi-dimensionale, ca informațiile care vin de la ochii noștri.

00:18:07.000 --> 00:18:09.000
Este deasemenea o memorie a secvențelor.

00:18:09.000 --> 00:18:11.000
Nu puteți învăța sau reaccesa ceva în afara unei secvențe.

00:18:11.000 --> 00:18:14.000
Un cântec trebuie ascultat în secvență, în timp,

00:18:14.000 --> 00:18:17.000
și trebuie redat în secvență, în timp.

00:18:17.000 --> 00:18:20.000
Iar aceste secvențe sunt redate auto-asociativ, așa că dacă văd ceva,

00:18:20.000 --> 00:18:23.000
aud ceva, îmi reamintește de el și apoi este redat în mod automat.

00:18:23.000 --> 00:18:27.000
E o redare automată. Predicția unor viitoare intrări este rezultatul dorit.

00:18:27.000 --> 00:18:30.000
Teoria trebuie să fie precisă din punct de vedere biologic,

00:18:30.000 --> 00:18:32.000
trebuie să fie testabilă și trebuie să poată fi construită.

00:18:32.000 --> 00:18:36.000
Dacă nu o construiești, nu o înțelegi. Deci, încă o imagine aici.

00:18:36.000 --> 00:18:40.000
Care va fi rezultatul? Chiar vom construi mașini inteligente?

00:18:40.000 --> 00:18:44.000
Absolut. Și va fi diferit de ceea ce cred oamenii.

00:18:44.000 --> 00:18:47.000
Nici o îndoială că se va întâmpla.

00:18:47.000 --> 00:18:51.000
În primul rând, va fi construit, o vom face din siliciu.

00:18:51.000 --> 00:18:54.000
Aceleași tehnici pentru construirea memoriilor de siliciu în calculatoare,

00:18:54.000 --> 00:18:55.000
le putem folosi aici.

00:18:55.000 --> 00:18:57.000
Dar ele sunt tipuri de memorie foarte diferite.

00:18:57.000 --> 00:18:59.000
Și vom atașa aceste memorii la senzori,

00:18:59.000 --> 00:19:02.000
iar senzorii vor colecta în timp real date din lumea reală,

00:19:02.000 --> 00:19:04.000
și aceste sisteme vor învăța despre mediul înconjurător.

00:19:04.000 --> 00:19:07.000
E improbabil ca primele realizări pe care le veți vedea să fie roboți.

00:19:07.000 --> 00:19:10.000
Nu că roboții n-ar fi utili, oamenii pot construi roboți.

00:19:10.000 --> 00:19:14.000
Dar partea robotică e cea mai grea. Ăsta-i creierul vechi. Asta-i greu.

00:19:14.000 --> 00:19:16.000
Noul creier este de fapt mai ușor decât cel vechi.

00:19:16.000 --> 00:19:19.000
Primele lucruri pe care le vom face vor fi cele ce nu necesită multă robotică.

00:19:19.000 --> 00:19:21.000
Așa că nu-l veți vedea pe C-3PO [micul robot din Războiul Stelelor].

00:19:21.000 --> 00:19:23.000
Mai degrabă veți vedea lucruri ca automobile inteligente

00:19:23.000 --> 00:19:26.000
care chiar înțeleg ce este traficul și conducerea,

00:19:26.000 --> 00:19:29.000
și care au învățat că anumite mașini cu semnalizatoare aprinse

00:19:29.000 --> 00:19:31.000
mai mult de 1/2 minut, probabil nu vor vira totuși.

00:19:31.000 --> 00:19:32.000
(Râsete)

00:19:32.000 --> 00:19:34.000
Putem face și sisteme de securitate inteligente.

00:19:34.000 --> 00:19:38.000
Oriunde ne folosim creierul, dar nu facem multă mecanică.

00:19:38.000 --> 00:19:40.000
Acele lucruri se vor întâmpla întâi.

00:19:40.000 --> 00:19:42.000
Dar în fond, nu avem limite aici.

00:19:42.000 --> 00:19:44.000
Nu știu cum va ieși asta.

00:19:44.000 --> 00:19:46.000
Știu multă lume care a inventat microprocesorul

00:19:46.000 --> 00:19:51.000
ei știau că ceea ce-au făcut era cu adevărat semnificativ,

00:19:51.000 --> 00:19:54.000
dar nu prea știau cu exactitate ce se va întâmpla.

00:19:54.000 --> 00:19:59.000
Nu au putut anticipa telefoanele celulare și Internetul.

00:19:59.000 --> 00:20:01.000
Ei știau doar că, hei, se vor construi calculatoare

00:20:01.000 --> 00:20:03.000
și controloare pentru luminile de trafic. Dar va fi ceva măreț.

00:20:03.000 --> 00:20:06.000
În același mod, știința creierului și aceste memorii

00:20:06.000 --> 00:20:09.000
vor fi tehnologii absolut fundamentale și vor conduce

00:20:09.000 --> 00:20:12.000
la schimbări incredibile în următorii 100 de ani.

00:20:12.000 --> 00:20:16.000
Și sunt foarte entuziasmat pentru modul în care le vom folosi în știință.

00:20:16.000 --> 00:20:19.000
Cred că s-a terminat timpul meu și-mi închei discursul

00:20:19.000 --> 00:20:20.000
chiar aici.

