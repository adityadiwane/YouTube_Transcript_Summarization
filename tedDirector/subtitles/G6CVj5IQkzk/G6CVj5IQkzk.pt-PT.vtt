WEBVTT
Kind: captions
Language: pt-PT

00:00:00.000 --> 00:00:07.000
Tradutor: Pedro Ferreira
Revisora: Bruno Gomes

00:00:25.552 --> 00:00:26.923
Eu faço duas coisas.

00:00:26.923 --> 00:00:29.247
Desenho computadores
portáteis e estudo cérebros.

00:00:29.247 --> 00:00:31.428
A apresentação de hoje é sobre cérebros

00:00:31.428 --> 00:00:33.876
e eu tenho um admirador
de cérebros por ai algures.

00:00:33.876 --> 00:00:35.285
(Risos)

00:00:35.580 --> 00:00:38.247
Podem pôr o meu primeiro slide aqui,

00:00:38.247 --> 00:00:41.466
para verem o título da minha palestra
e as minhas duas afiliações.

00:00:41.466 --> 00:00:45.000
Vou dizer porque é que não temos
uma boa teoria do cérebro,

00:00:45.000 --> 00:00:48.390
porque é importante desenvolver uma
e o que podemos fazer para isso.

00:00:48.466 --> 00:00:51.485
Vou tentar fazer isso tudo em 20 minutos.
Tenho duas afiliações.

00:00:51.485 --> 00:00:54.580
Muitos de vocês conhece-me dos meus dias
de Palm e de Handspring,

00:00:54.580 --> 00:00:57.114
e dirijo um instituto
científico sem fins lucrativos,

00:00:57.114 --> 00:00:59.752
o Instituto Redwood Neuroscience
em Menlo Park,

00:00:59.752 --> 00:01:01.371
e estudamos neurociência teórica.

00:01:01.371 --> 00:01:03.400
Estudamos o funcionamento do neocórtex.

00:01:03.400 --> 00:01:05.470
Vou falar sobre isso tudo.

00:01:05.470 --> 00:01:08.114
Tenho aqui um slide da minha outra vida,
a vida dos computadores.

00:01:08.133 --> 00:01:11.438
Estes são alguns dos produtos
em que trabalhei nos últimos 20 anos,

00:01:11.438 --> 00:01:15.123
a começar no primeiro portátil original
até alguns dos primeiros "tablets"

00:01:15.123 --> 00:01:17.742
e por ai fora, acabando no Treo
recentemente,

00:01:17.742 --> 00:01:19.209
e continuamos a fazer isto.

00:01:19.209 --> 00:01:21.609
Fiz isto porque acredito
que os computadores móveis

00:01:21.609 --> 00:01:25.257
são o futuro dos computadores pessoais,
e estou a tentar fazer o mundo melhor

00:01:25.257 --> 00:01:27.000
trabalhando nestas coisas.

00:01:27.000 --> 00:01:29.133
Mas tenho de confessar, foi um acidente.

00:01:29.133 --> 00:01:31.180
Eu nunca quis fazer nenhum destes produtos

00:01:31.180 --> 00:01:33.476
e muito cedo na minha carreira decidi

00:01:33.476 --> 00:01:35.866
que não iria para a indústria
dos computadores.

00:01:36.000 --> 00:01:38.000
Antes de falar disso, tenho de falar-vos

00:01:38.000 --> 00:01:40.352
desta imagem de graffiti
que copiei da Internet.

00:01:40.352 --> 00:01:43.466
Procurava uma imagem de graffiti,
linguagem de entrada de texto,

00:01:43.466 --> 00:01:46.760
e encontrei um sitio Internet
dedicado a professores ,

00:01:46.760 --> 00:01:48.771
que querem escrever coisas
por cima do quadro negro,

00:01:48.771 --> 00:01:51.790
e eles também usaram graffiti,
e peço desculpa por isso.

00:01:52.000 --> 00:01:54.000
(Risos)

00:01:54.904 --> 00:01:59.000
Quando eu era novo
e saí da escola de engenharia,

00:01:59.000 --> 00:02:02.714
Cornell em 79, decidi
que ia trabalhar para a Intel.

00:02:02.714 --> 00:02:05.666
Já estava na indústria dos computadores
há três meses,

00:02:05.666 --> 00:02:10.000
apaixonei-me por outra coisa, e disse:
"Escolhi a carreira errada"

00:02:10.000 --> 00:02:12.352
e apaixonei-me por cérebros.

00:02:13.000 --> 00:02:16.000
Isto não é um cérebro verdadeiro.
É o desenho de um cérebro.

00:02:16.000 --> 00:02:19.000
Não me lembro exatamente como começou,

00:02:19.000 --> 00:02:22.000
mas tenho uma recordação,
bastante forte na minha mente.

00:02:22.447 --> 00:02:25.180
Em setembro de 1979,
o Scientific American saiu

00:02:25.180 --> 00:02:28.295
apenas com um tema sobre o cérebro,
que era bastante bom.

00:02:28.295 --> 00:02:30.371
Foi um dos melhores números de sempre.

00:02:30.371 --> 00:02:33.760
Falava do neurónio,
de desenvolvimento, de doença e visão

00:02:33.760 --> 00:02:34.561
e de tudo sobre cérebros.

00:02:34.561 --> 00:02:36.152
Foi realmente impressionante.

00:02:36.152 --> 00:02:39.850
Ficávamos com a impressão
de saber muito sobre cérebros.

00:02:39.850 --> 00:02:43.133
O último artigo desse número foi escrito
por Francis Crick, famoso pelo ADN.

00:02:43.237 --> 00:02:46.000
Hoje é o 50.º aniversário
da descoberta do ADN.

00:02:46.000 --> 00:02:48.470
Ele escreveu uma história dizendo:

00:02:48.470 --> 00:02:50.199
"Isto é tudo bem e bom,
mas sabem uma coisa?

00:02:50.199 --> 00:02:52.180
"não sabemos patavina sobre cérebros

00:02:52.180 --> 00:02:54.504
"e ninguém tem uma pista
de como funciona essa coisa,

00:02:54.504 --> 00:02:56.819
"por isso não acreditem
em tudo o que vos dizem".

00:02:56.819 --> 00:02:59.619
"O que manifestamente nos falta

00:02:59.619 --> 00:03:02.552
— ele é um verdadeiro
"gentleman" britânico —

00:03:02.552 --> 00:03:04.314
"é um bom enquadramento de ideias

00:03:04.314 --> 00:03:06.942
"para podermos interpretar
essas diferentes abordagens."

00:03:06.942 --> 00:03:09.333
Achei ótima a palavra "enquadramento".

00:03:09.333 --> 00:03:11.219
Não disse que não tínhamos uma teoria.

00:03:11.219 --> 00:03:13.152
Disse que não sabemos como pensar nisso

00:03:13.152 --> 00:03:15.247
nem sequer temos um "enquadramento".

00:03:15.247 --> 00:03:18.257
Estamos nos dias de pré-paradigma
para parafrasear Thomas Kuhn.

00:03:18.428 --> 00:03:20.218
Eu apaixonei-me por isto, e disse:

00:03:20.218 --> 00:03:24.000
"Temos todo este conhecimento
sobre cérebros. Será assim tão difícil?"

00:03:24.000 --> 00:03:26.457
É uma coisa que pode funcionar
no meu tempo de vida.

00:03:26.457 --> 00:03:28.000
Achei que podia fazer uma diferença,

00:03:28.000 --> 00:03:31.276
e assim tentei passar dos computadores
para o negócio dos cérebros.

00:03:31.276 --> 00:03:33.390
Fui ao MIT, ao laboratório de IA, e disse:

00:03:33.390 --> 00:03:35.571
"Também quero construir
máquinas inteligentes,

00:03:35.571 --> 00:03:38.466
mas primeiro tenho que estudar
o funcionamento do cérebro.

00:03:38.466 --> 00:03:40.800
Eles responderam:
"Não é necessário fazer isso.

00:03:40.800 --> 00:03:43.352
Nós aqui só programamos computadores,
é o suficiente".

00:03:43.352 --> 00:03:46.257
E eu: "Não, deviam estudar o cérebro.
E eles: "Estás errado".

00:03:46.257 --> 00:03:48.818
E eu: "Vocês é que estão"
e não entrei no laboratório.

00:03:48.828 --> 00:03:49.923
(Risos)

00:03:50.000 --> 00:03:52.485
Fiquei um pouco desapontado
— era bastante novo.

00:03:52.485 --> 00:03:56.900
Voltei uns anos depois,
desta vez na Califórnia, e fui a Berkeley.

00:03:56.152 --> 00:03:58.857
E disse: "Vou para a secção de biologia".

00:03:59.000 --> 00:04:02.380
Entrei no programa PhD de Biofísica,
e tudo bem,

00:04:02.380 --> 00:04:05.142
estou a estudar cérebros, e disse:
"Quero estudar a teoria.

00:04:05.142 --> 00:04:07.457
E eles: "Não podes estudar
teoria sobre cérebros.

00:04:07.457 --> 00:04:09.419
"Não se arranja financiamento para isso.

00:04:09.419 --> 00:04:11.847
"E como aluno universitário,
não podes fazer isso".

00:04:11.933 --> 00:04:15.142
Eu fiquei muito deprimido.
Eu podia fazer a diferença nesta área.

00:04:15.142 --> 00:04:18.000
Por isso, voltei para a indústria
dos computadores e disse:

00:04:18.000 --> 00:04:20.200
"Vou ter de trabalhar nisto
por uns tempos".

00:04:20.200 --> 00:04:22.447
Foi quando desenhei
todos aqueles produtos.

00:04:22.504 --> 00:04:23.838
(Risos)

00:04:24.660 --> 00:04:27.000
Queria fazer isso durante quatro anos,
ganhar algum dinheiro,

00:04:27.000 --> 00:04:31.000
— estava a formar uma família —
e ganhar alguma maturidade,

00:04:31.000 --> 00:04:34.171
e talvez a neurociência também
amadurecesse um pouco.

00:04:34.171 --> 00:04:36.790
Demorou mais de quatro anos.
Foram cerca de 16 anos.

00:04:36.790 --> 00:04:39.142
Estou a fazê-lo agora,
e vou falar-vos disso.

00:04:39.247 --> 00:04:42.000
Porque é que deveríamos ter
uma boa teoria do cérebro?

00:04:42.304 --> 00:04:45.660
Há muitas razões pelas quais
as pessoas fazem ciência.

00:04:45.660 --> 00:04:48.000
A mais básica é que as pessoas
gostam de saber coisas.

00:04:48.000 --> 00:04:50.485
Somos curiosos, e por isso
procuramos conhecimento.

00:04:50.485 --> 00:04:52.666
Porque estudamos formigas?
É interessante.

00:04:52.666 --> 00:04:55.447
Talvez venha a ser útil,
mas é interessante e fascinante.

00:04:55.447 --> 00:04:59.190
Mas por vezes, a ciência tem outros atributos
que a tornam muito interessante.

00:04:59.190 --> 00:05:01.838
Por vezes, uma ciência
diz-nos algo sobre nós próprios,

00:05:01.838 --> 00:05:03.409
diz-nos quem nós somos.

00:05:03.409 --> 00:05:06.200
Raramente a evolução fez isso
e Copérnico fez isso,

00:05:06.200 --> 00:05:08.342
temos uma nova compreensão
de quem somos.

00:05:08.342 --> 00:05:12.760
Nós somos os nossos cérebros.
O meu cérebro está a falar ao vosso cérebro.

00:05:12.760 --> 00:05:15.685
Os nossos corpos passeiam juntos,
mas é o meu cérebro que fala com o vosso.

00:05:15.685 --> 00:05:18.495
Se queremos entender quem somos,
como sentimos e entendemos,

00:05:18.495 --> 00:05:20.323
temos que perceber o que é o cérebro.

00:05:20.323 --> 00:05:23.847
Por vezes, a ciência leva-nos a grandes
benefícios sociais e tecnológicos,

00:05:23.904 --> 00:05:25.942
ou negócios, ou o que quer que saia dela.

00:05:25.942 --> 00:05:29.000
Quando entendermos
como funciona o cérebro,

00:05:29.000 --> 00:05:31.950
poderemos construir máquinas inteligentes,

00:05:31.950 --> 00:05:34.314
o que é uma coisa que vai trazer
benefícios enormes para a sociedade

00:05:34.314 --> 00:05:36.371
tal como uma tecnologia fundamental.

00:05:36.371 --> 00:05:38.838
Então, porque é que não temos
uma teoria do cérebro?

00:05:38.838 --> 00:05:41.400
As pessoas trabalham nisso há já 100 anos.

00:05:41.400 --> 00:05:43.571
Primeiro, vamos ver
o que é a ciência normal.

00:05:43.571 --> 00:05:44.980
Isto é ciência normal.

00:05:44.980 --> 00:05:49.000
Ciência normal é um bom equilíbrio
entre teoria e experimentalismo.

00:05:49.000 --> 00:05:51.266
O teórico diz: "Acho
que isto é o que se passa",

00:05:51.266 --> 00:05:53.466
e o experimentalista diz:
"Não. Estás errado".

00:05:53.466 --> 00:05:55.000
E anda de um lado para o outro.

00:05:55.000 --> 00:05:56.790
Isto funciona na física, na geologia.

00:05:56.790 --> 00:06:00.380
Mas o que se passa na neurociência? 
É isto que se passa na neurociência.

00:06:00.380 --> 00:06:05.228
Temos esta montanha de dados
— anatomia, fisiologia e comportamento.

00:06:05.228 --> 00:06:08.419
Nem imaginam o detalhe
do que sabemos sobre cérebros.

00:06:08.419 --> 00:06:12.000
Havia 28 000 pessoas na conferência
de neurociência este ano.

00:06:12.000 --> 00:06:14.390
e estão todos a fazer
investigação em cérebros.

00:06:14.390 --> 00:06:18.399
Muitos dados. Mas não há teoria.
Há ali em cima uma caixa minúscula.

00:06:18.476 --> 00:06:23.000
E a teoria ainda não teve
um papel importante na neurociência.

00:06:23.123 --> 00:06:25.742
E é pena. Porque é que isto acontece?

00:06:25.742 --> 00:06:28.438
Perguntamos aos neurocientistas:
"Porque é que assim é?"

00:06:28.438 --> 00:06:31.570
Eles começam por admiti-lo, mas dizem:

00:06:31.570 --> 00:06:33.895
"Há várias razões para não haver
uma boa teoria do cérebro.

00:06:33.895 --> 00:06:36.000
Alguns dizem: "Não temos
dados suficientes.

00:06:36.000 --> 00:06:39.000
"Precisamos de mais informação,
há muita coisa que não sabemos.

00:06:39.000 --> 00:06:41.876
Acabei de vos dizer
que já temos dados até mais não.

00:06:41.876 --> 00:06:44.866
Temos tanta informação
que nem sabemos por onde começar.

00:06:44.866 --> 00:06:46.837
O que ganhamos em ter mais informação?

00:06:46.837 --> 00:06:50.114
Podemos ter sorte e descobrir
alguma coisa mágica, mas não me parece.

00:06:50.114 --> 00:06:53.000
Isto é um sintoma de que
não temos nenhuma teoria.

00:06:53.000 --> 00:06:56.000
Não precisamos de mais dados,
precisamos de uma teoria.

00:06:56.950 --> 00:07:00.866
Às vezes diz-se: "O cérebro é tão complexo,
que vai levar outros 50 anos.

00:07:01.000 --> 00:07:03.161
Acho que o Chris disse
algo semelhante ontem.

00:07:03.161 --> 00:07:05.280
Não sei bem, Chris, mas foi algo assim:

00:07:05.280 --> 00:07:07.304
"É uma das coisas mais complicadas
do universo".

00:07:07.304 --> 00:07:10.570
Não é verdade. Nós somos
mais complicados que o cérebro.

00:07:10.570 --> 00:07:12.323
E mesmo que o cérebro
pareça muito complicado,

00:07:12.323 --> 00:07:14.809
as coisas parecem complicadas
até as percebermos.

00:07:15.190 --> 00:07:17.314
Foi sempre assim.
Assim, só podemos dizer:

00:07:17.314 --> 00:07:19.857
"O meu neocórtex,
a parte do cérebro que me interessa,

00:07:19.857 --> 00:07:21.790
"tem 30 mil milhões de células".

00:07:21.790 --> 00:07:24.000
Mas, sabem? É muito, muito regular.

00:07:24.000 --> 00:07:27.000
De facto, parece a mesma coisa
repetida vezes sem conta.

00:07:27.000 --> 00:07:29.904
Não é tão complexo como parece.
Isso não é problema.

00:07:29.904 --> 00:07:32.495
Outros dizem:
"O cérebro não pode entender o cérebro".

00:07:32.495 --> 00:07:34.123
Muito Zen. Uau!

00:07:34.200 --> 00:07:35.504
(Risos)

00:07:36.000 --> 00:07:39.000
Soa bem, mas porquê? Qual é o objetivo?

00:07:39.000 --> 00:07:42.000
É apenas um conjunto de células.
Entendemos o fígado.

00:07:42.000 --> 00:07:44.000
E tem muitas células, não tem?

00:07:44.000 --> 00:07:46.900
Portanto, acho que o problema não é esse.

00:07:46.900 --> 00:07:49.523
Finalmente, alguns dizem;
"Não me sinto um conjunto de células.

00:07:49.876 --> 00:07:51.809
"Tenho consciência.

00:07:51.809 --> 00:07:54.000
"Tenho esta experiência, estou no mundo.

00:07:54.000 --> 00:07:56.152
"Não posso ser apenas
um conjunto de células.

00:07:56.152 --> 00:07:59.352
"As pessoas pensavam que existia
uma força viva para se estar vivo,

00:07:59.352 --> 00:08:01.866
e agora sabemos
que isso não é verdade.

00:08:01.866 --> 00:08:04.790
Não há provas que o digam,
fora as pessoas que não acreditam

00:08:04.790 --> 00:08:06.771
que as células possam fazer o que fazem.

00:08:06.771 --> 00:08:09.380
Se alguém caiu no abismo
do dualismo metafisico,

00:08:09.380 --> 00:08:12.571
são pessoas muito espertas também,
mas podemos rejeitar tudo isso.

00:08:12.571 --> 00:08:14.009
(Risos)

00:08:14.285 --> 00:08:17.037
Não, vou dizer-vos que há outra coisa

00:08:17.037 --> 00:08:18.857
que é fundamental, e é isto:

00:08:18.857 --> 00:08:21.552
há outra razão para não temos
uma boa teoria do cérebro,

00:08:21.552 --> 00:08:26.247
e é porque temos um assunção
intuitiva e forte mas incorreta,

00:08:26.247 --> 00:08:29.019
que nos impede de ver a resposta.

00:08:29.019 --> 00:08:32.723
Há coisas que acreditamos estarem certas,
mas estão erradas.

00:08:32.723 --> 00:08:36.047
Há uma história semelhante na ciência
que vos vou contra.

00:08:36.047 --> 00:08:38.095
vou contar essa história na ciência.

00:08:38.095 --> 00:08:39.990
Vejamos outras revoluções cientificas,

00:08:39.990 --> 00:08:42.000
— o sistema solar e de Copérnico,

00:08:42.000 --> 00:08:45.133
a evolução de Darwin
e as placas tectónicas, de Wegener.

00:08:45.914 --> 00:08:48.038
Têm muito em comum
com a ciência do cérebro.

00:08:48.038 --> 00:08:50.914
Primeiro, tinham muitos dados
sem explicação. Muitos.

00:08:50.914 --> 00:08:54.000
Mas ficaram mais compreensíveis,
logo que se elaborou uma teoria.

00:08:54.000 --> 00:08:57.152
As melhores cabeças estavam bloqueadas,
pessoas muito inteligentes.

00:08:57.152 --> 00:08:59.123
Não somos mais espertos do que eles eram.

00:08:59.123 --> 00:09:00.809
É difícil pensar numa coisa,

00:09:00.809 --> 00:09:03.218
mas uma vez bem pensado,
é mais fácil entendê-la.

00:09:03.218 --> 00:09:06.295
As minhas filhas entenderam
estas três teorias, em linhas gerais,

00:09:06.295 --> 00:09:08.095
quando andavam no infantário.

00:09:08.095 --> 00:09:11.485
E agora não é muito difícil,
aqui está a maçã, aqui está a laranja,

00:09:11.485 --> 00:09:13.619
a terra gira, e isso tudo.

00:09:14.000 --> 00:09:16.666
Outra coisa é que a resposta
esteve lá o tempo todo,

00:09:16.666 --> 00:09:19.123
mas foi ignorada por razões óbvias,
é a realidade.

00:09:19.123 --> 00:09:22.152
Por uma forte convicção intuitiva
de que estava errada.

00:09:22.152 --> 00:09:25.628
No caso do sistema solar,
a ideia de que a Terra está a girar

00:09:25.628 --> 00:09:28.409
que a sua superfície se desloca
a milhares de km por hora,

00:09:28.409 --> 00:09:31.190
e se desloca pelo sistema solar
a um milhão de km por hora.

00:09:31.190 --> 00:09:33.295
É de lunático.
Sabemos que ela não se move.

00:09:33.295 --> 00:09:35.752
Sentem que estão a viajar
a milhares de km/h? Não.

00:09:35.752 --> 00:09:39.133
Se alguém dissesse que estava
a girar no espaço, que é enorme,

00:09:39.133 --> 00:09:41.295
trancavam-na, foi o que fizeram
naquela época.

00:09:41.295 --> 00:09:42.323
(Risos)

00:09:42.323 --> 00:09:45.076
Portanto, era intuitivo e óbvio.
E quanto à evolução?

00:09:45.076 --> 00:09:47.180
É a mesma coisa.
Ensinamos aos nossos filhos.

00:09:47.180 --> 00:09:50.457
A Bíblia diz que Deus criou todas
as espécies, gatos, cães,

00:09:50.457 --> 00:09:53.104
pessoas, plantas, eles não mudam.

00:09:53.104 --> 00:09:55.704
Noé pô-los na Arca por aquela ordem,
blá, blá, blá.

00:09:56.304 --> 00:10:00.695
O facto é que, se acreditam na evolução,
que todos temos um antepassado comum,

00:10:00.695 --> 00:10:03.704
e todos temos um antepassado comum
com a planta ali à entrada.

00:10:03.704 --> 00:10:07.438
Isto é o que a evolução nos diz.
É verdade. É mais ou menos inacreditável.

00:10:07.438 --> 00:10:09.361
O mesmo sobre as placas tectónicas.

00:10:09.361 --> 00:10:13.314
Todas as montanhas e continentes
estão a flutuar por cima da terra.

00:10:13.314 --> 00:10:15.590
É assim, não faz sentido nenhum.

00:10:15.590 --> 00:10:20.000
Portanto, qual é a intuição,
mas uma assunção incorreta,

00:10:20.000 --> 00:10:22.000
que nos impediu de entender o cérebro?

00:10:22.000 --> 00:10:24.980
Vai parecer óbvio que está correto,
e é esse o objetivo.

00:10:24.980 --> 00:10:28.171
Vou ter de explicar porque é
que estavam errados sobre a outra assunção.

00:10:28.171 --> 00:10:29.952
A coisa intuitiva mas óbvia é que,

00:10:29.952 --> 00:10:32.847
de certa forma, a inteligência
é definida pelo comportamento,

00:10:33.000 --> 00:10:35.304
que somos inteligentes
porque fazemos coisas

00:10:35.304 --> 00:10:37.752
mas vou provar que isso está errado.

00:10:37.752 --> 00:10:40.066
A inteligência é definida pela previsão.

00:10:40.685 --> 00:10:45.409
Vou mostrar-vos alguns slides,
para dar um exemplo do que isto significa.

00:10:45.581 --> 00:10:46.885
Isto é um sistema.

00:10:46.885 --> 00:10:50.114
Os engenheiros e os cientistas gostam
de desenhar os sistemas assim.

00:10:50.114 --> 00:10:52.914
Dizem: "Temos uma coisa numa caixa,
com entradas e saídas.

00:10:52.914 --> 00:10:55.952
As pessoas da IA dizem:
"Na caixa está um computador programável

00:10:55.952 --> 00:10:58.400
equivalente a um cérebro,
fornecemos-lhe informações

00:10:58.400 --> 00:11:00.514
para ele ter algum tipo de comportamento.

00:11:00.514 --> 00:11:03.952
Alan Turing definiu o teste Turing,
que diz que uma coisa é inteligente

00:11:03.952 --> 00:11:06.971
se o seu comportamento
for idêntico ao comportamento humano.

00:11:06.971 --> 00:11:09.314
Uma medida comportamental
do que é a inteligência.

00:11:09.314 --> 00:11:12.000
Isto ficou encaixado na nossa mente
durante muito tempo.

00:11:12.000 --> 00:11:14.000
Eu falo da "inteligência real".

00:11:14.000 --> 00:11:16.076
A inteligência real
é feita de outra coisa.

00:11:16.333 --> 00:11:19.447
Experimentamos o mundo através
de uma sequência de padrões

00:11:19.447 --> 00:11:21.857
que guardamos e recordamos.

00:11:22.209 --> 00:11:24.619
Quando as chamamos,
comparamo-las com a realidade,

00:11:24.619 --> 00:11:27.000
e fazemos previsões o tempo todo.

00:11:27.000 --> 00:11:30.561
É uma medida eternal que existe em nós
e podemos dizer: "Entendo o mundo?

00:11:30.561 --> 00:11:32.876
"Estarei a fazer previsões?" Etc.

00:11:32.876 --> 00:11:35.619
Vocês estão a ser inteligentes,
e não estão a fazer nada.

00:11:35.619 --> 00:11:38.057
Podem estar a coçar-se,
a meter o dedo no nariz.

00:11:38.057 --> 00:11:41.723
Não estão a fazer nada neste momento,
mas estão a entender o que eu digo.

00:11:42.000 --> 00:11:45.685
Como são inteligentes e falam inglês,
sabem que palavra existe no fim desta...

00:11:46.171 --> 00:11:47.457
... frase.

00:11:47.504 --> 00:11:50.676
A palavra surgiu-vos, e vocês estão
sempre a fazer estas previsões.

00:11:50.676 --> 00:11:54.066
O que quero dizer é que a previsão eterna
é a saída do neocórtex.

00:11:54.066 --> 00:11:57.000
De certa forma, a predição leva
ao comportamento inteligente.

00:11:57.000 --> 00:12:00.076
É assim que acontece. Comecemos
com um cérebro não inteligente.

00:12:00.076 --> 00:12:03.780
Eu digo que é um cérebro não inteligente,
porque é um cérebro velho,

00:12:03.780 --> 00:12:07.000
vamos dizer que não é de mamífero,
mas de um réptil,

00:12:07.000 --> 00:12:09.000
portanto digamos, de crocodilo.

00:12:09.000 --> 00:12:12.123
O crocodilo tem sentidos
muito sofisticados.

00:12:12.123 --> 00:12:16.428
Tem bons olhos e ouvidos e tacto e outros,
uma boca e um nariz.

00:12:17.028 --> 00:12:19.123
Tem um comportamento muito complexo.

00:12:19.123 --> 00:12:21.714
Pode correr e esconder-se.
Tem medos e emoções.

00:12:21.714 --> 00:12:24.561
Pode comer-nos, pode atacar.

00:12:24.695 --> 00:12:27.114
Pode fazer muitos tipos de coisas.

00:12:27.114 --> 00:12:31.447
Mas não consideramos o crocodilo
muito inteligente, como um ser humano.

00:12:32.000 --> 00:12:34.323
Mas tem todo este comportamento complexo.

00:12:34.323 --> 00:12:36.409
Durante a evolução, o que aconteceu?

00:12:36.647 --> 00:12:38.428
Na evolução dos mamíferos,

00:12:38.428 --> 00:12:41.000
começámos por desenvolver o neocórtex.

00:12:41.000 --> 00:12:42.714
Vou representar o neocórtex aqui,

00:12:42.714 --> 00:12:45.076
com esta caixa por cima do velho cérebro.

00:12:45.076 --> 00:12:48.523
Neocórtex significa nova camada.
É uma nova camada por cima do cérebro.

00:12:48.523 --> 00:12:50.857
É aquela coisa enrugada,
no alto da cabeça,

00:12:50.857 --> 00:12:53.847
enrugada porque foi enfiada
ali dentro mas não cabe lá.

00:12:53.847 --> 00:12:55.000
(Risos)

00:12:55.000 --> 00:12:57.114
É mesmo. Tem o tamanho
de uma toalha de mesa.

00:12:57.114 --> 00:13:00.000
Não cabe, fica enrugada.
Agora olhem como desenhei isto aqui.

00:13:00.400 --> 00:13:04.000
O velho cérebro ainda ali está.
Ainda temos o cérebro de crocodilo.

00:13:04.000 --> 00:13:06.000
Temos. É o cérebro emocional.

00:13:06.000 --> 00:13:09.000
É todas aquelas reações viscerais
que temos.

00:13:09.000 --> 00:13:12.047
Por cima dele, temos este sistema
de memória chamado neocórtex.

00:13:12.047 --> 00:13:16.000
O sistema de memória assenta
sobre a parte sensorial do cérebro.

00:13:16.000 --> 00:13:19.266
Portanto, tal como as entradas sensoriais
alimentam o velho cérebro,

00:13:19.266 --> 00:13:23.000
também vão para cima para o neocórtex.
E o neocórtex está só a memorizar.

00:13:23.200 --> 00:13:26.714
Está ali apenas a memorizar
todas as coisas que se passam,

00:13:26.714 --> 00:13:29.409
"onde estive, pessoas que vi,
coisas que ouvi", etc.

00:13:29.723 --> 00:13:33.000
No futuro, quando vê qualquer coisa
semelhante outra vez,

00:13:33.000 --> 00:13:36.000
num contexto semelhante,
ou exatamente no mesmo contexto,

00:13:36.000 --> 00:13:37.885
volta a passá-lo outra vez.

00:13:37.885 --> 00:13:41.285
"Já aqui estive antes, e depois disso
aconteceu isto a seguir".

00:13:41.285 --> 00:13:43.428
Permite-nos prever o futuro.

00:13:43.523 --> 00:13:47.000
Permite-nos, literalmente
reinjectar os sinais no cérebro,

00:13:47.000 --> 00:13:49.390
que vos permitem ver
o que vai acontecer a seguir,

00:13:49.390 --> 00:13:51.714
ouvir a palavra, antes de eu a dizer.

00:13:52.000 --> 00:13:55.000
É esta realimentação no velho cérebro

00:13:55.000 --> 00:13:58.000
que nos permite tomar decisões
muito mais inteligentes.

00:13:58.000 --> 00:14:01.571
Este é o slide mais importante da palestra,
vou insistir nele mais um pouco.

00:14:01.571 --> 00:14:05.152
Por isso estamos sempre a dizer:
"Eu consigo prever as coisas.

00:14:05.152 --> 00:14:07.790
Um rato que atravessa um labirinto
e aprende o caminho,

00:14:07.790 --> 00:14:10.266
quando volta ao labirinto,
tem o mesmo comportamento.

00:14:10.266 --> 00:14:12.447
Mas nós somos mais espertos,
porque dizemos:

00:14:12.447 --> 00:14:15.104
"Reconheço este labirinto,
sei qual o caminho a seguir".

00:14:15.104 --> 00:14:18.190
"Já aqui estive, posso prever o futuro".
É o que estamos a fazer.

00:14:18.342 --> 00:14:21.000
Isto é verdade para todos os mamíferos,

00:14:21.000 --> 00:14:23.133
mas nos seres humanos,
tornou-se muito pior.

00:14:23.133 --> 00:14:26.000
Nós desenvolvemos
a parte frontal do neocórtex

00:14:26.000 --> 00:14:29.809
— chamada a parte anterior do noecórtex —
e a natureza fez um pequeno truque.

00:14:29.809 --> 00:14:32.171
Copiou a parte posterior, que é sensorial,

00:14:32.171 --> 00:14:33.809
e pô-la na parte frontal.

00:14:33.809 --> 00:14:36.428
Só os seres humanos têm
o mesmo mecanismo na frente,

00:14:36.428 --> 00:14:38.371
mas utilizamo-lo para o controlo motor.

00:14:38.371 --> 00:14:41.019
Agora podemos planear movimentos
muito sofisticados.

00:14:41.019 --> 00:14:44.380
Não posso entrar em detalhe mas,
para entender como funciona o cérebro,

00:14:44.380 --> 00:14:45.780
têm de entender como funciona

00:14:45.780 --> 00:14:47.933
a primeira parte do neocórtex
de um mamífero,

00:14:47.933 --> 00:14:50.228
como guardamos sequências
e fazemos previsões.

00:14:50.228 --> 00:14:52.000
Vou dar alguns exemplos de previsões.

00:14:52.000 --> 00:14:53.514
Já disse a palavra "frase".

00:14:53.514 --> 00:14:57.000
Na música, se já ouviram Jill
a cantar uma canção,

00:14:57.085 --> 00:15:00.085
quando ela a canta, a nota seguinte
aparece na vossa cabeça.

00:15:00.085 --> 00:15:01.523
Vocês vão prevendo as notas.

00:15:01.523 --> 00:15:05.533
Num álbum de música, no fim de uma canção,
a canção seguinte aparece na nossa cabeça.

00:15:05.533 --> 00:15:07.666
Estão sempre a acontecer, estas previsões.

00:15:07.666 --> 00:15:10.390
Eu falo da "experiência
do pensamento da porta alterada".

00:15:10.390 --> 00:15:13.209
É o seguinte: vocês têm uma porta em casa.

00:15:13.209 --> 00:15:15.200
Enquanto estão aqui eu mudo-a.

00:15:15.200 --> 00:15:18.000
Há alguém na vossa casa neste momento,
a mudar a porta.

00:15:18.000 --> 00:15:20.180
Vai mudar o puxador da porta
dois centímetros.

00:15:20.180 --> 00:15:22.371
Quando forem para casa hoje,
vão pôr ali a mão,

00:15:22.371 --> 00:15:25.238
chegam ao puxador da porta
e notam que está no sítio errado.

00:15:25.238 --> 00:15:27.304
E dizem: "Uau! O que é que aconteceu?"

00:15:27.304 --> 00:15:29.142
Pode demorar a perceber, mas dão fé.

00:15:29.142 --> 00:15:31.885
Eu podia mudar o puxador da porta,
fazê-lo maior ou menor,

00:15:31.885 --> 00:15:34.380
mudar o material para prata,
fazer uma alavanca.

00:15:34.380 --> 00:15:36.866
colori-la, pôr-lhe janelas,

00:15:36.866 --> 00:15:38.771
mudar centenas de coisas na porta.

00:15:38.771 --> 00:15:40.914
Nos dois segundos
que levam a abrir a porta,

00:15:40.914 --> 00:15:42.828
vão notar que algo mudou.

00:15:42.828 --> 00:15:45.047
A abordagem a isto
da engenharia, da IA,

00:15:45.047 --> 00:15:48.361
é construir uma base de dados de portas,
com todos os seus atributos.

00:15:48.361 --> 00:15:51.561
Quando chegam à porta, vamos verificá-las
todas, uma de cada vez.

00:15:51.561 --> 00:15:53.371
Porta, porta, porta...

00:15:53.371 --> 00:15:55.000
O nosso cérebro não faz isso.

00:15:55.000 --> 00:15:57.247
O nosso cérebro está sempre
a fazer previsões.

00:15:57.247 --> 00:15:59.342
sobre o que vai acontecer
no nosso contexto.

00:15:59.342 --> 00:16:02.066
Quando ponho a minha mão na mesa,
espero senti-la parar.

00:16:02.066 --> 00:16:05.219
Ao andar, por cada passo,
se falho apenas um oitavo de centímetro,

00:16:05.219 --> 00:16:06.914
noto que alguma coisa mudou.

00:16:06.914 --> 00:16:09.580
Estamos sempre a fazer previsões
no nosso meio ambiente.

00:16:09.580 --> 00:16:12.028
Vou falar da visão.
Isto é uma imagem de uma mulher.

00:16:12.028 --> 00:16:14.371
Ao olhamos para uma pessoa,
os olhos são apanhados

00:16:14.371 --> 00:16:15.819
duas a três vezes por segundo.

00:16:15.819 --> 00:16:18.171
Não reparamos,
mas os olhos estão sempre a mexer.

00:16:18.190 --> 00:16:21.399
Vamos de olho para olho,
para olho, para nariz, para a boca.

00:16:21.399 --> 00:16:23.657
Quando os vossos olhos
vão de olho para olho,

00:16:23.657 --> 00:16:25.676
se estivesse ali outra coisa,
como o nariz,

00:16:25.676 --> 00:16:27.876
se vissem um nariz
onde devia estar um olho,

00:16:27.876 --> 00:16:29.257
vocês diriam: "M... "

00:16:29.257 --> 00:16:30.780
(Risos)

00:16:31.000 --> 00:16:33.142
Há algo de errado com esta pessoa.

00:16:33.142 --> 00:16:35.066
Isto porque estão a fazer uma previsão.

00:16:35.066 --> 00:16:38.037
Não disseram: "O que estou a ver agora?
Um nariz, está certo".

00:16:38.037 --> 00:16:40.171
Não, vocês têm uma expetativa
do que vão ver.

00:16:40.171 --> 00:16:41.142
(Risos)

00:16:41.142 --> 00:16:44.542
Sempre. Pensemos agora
como testamos a inteligência.

00:16:44.876 --> 00:16:47.599
Testamo-la por previsão.
Qual é a palavra seguinte aqui?

00:16:47.599 --> 00:16:51.466
Isto está para isto como isto está para isto.
Qual é o próximo número nesta frase?

00:16:51.466 --> 00:16:54.352
Aqui estão três perspetivas de um objeto.
Qual é a quarta?

00:16:54.352 --> 00:16:57.161
É assim que a testamos.
É tudo sobre previsão.

00:16:57.466 --> 00:17:00.095
Portanto qual é a receita
para uma teoria do cérebro?

00:17:00.095 --> 00:17:02.895
Em primeiro lugar,
temos de ter o "framework" certo,

00:17:02.895 --> 00:17:04.771
um "framework" de memória,

00:17:04.771 --> 00:17:07.000
não um "framework"
de computação ou comportamento.

00:17:07.000 --> 00:17:09.809
Como guardam e chamam
todas estas sequências de padrões?

00:17:09.809 --> 00:17:11.781
São sequências espácio-temporais.

00:17:11.781 --> 00:17:14.257
Depois, é preciso um grupo de teóricos.

00:17:14.257 --> 00:17:16.600
Os biólogos geralmente
não são bons teóricos.

00:17:16.600 --> 00:17:20.057
Nem sempre, mas em geral, não há
grande história de teoria em biologia.

00:17:20.057 --> 00:17:23.076
Acho que as melhores pessoas
com quem trabalhar são os físicos,

00:17:23.076 --> 00:17:26.447
engenheiros e matemáticos,
com tendência a pensar algoritmicamente.

00:17:26.447 --> 00:17:28.990
Temos de aprender anatomia e fisiologia.

00:17:29.457 --> 00:17:33.333
Temos de fazer teorias muito realistas
em termos anatómicos.

00:17:33.333 --> 00:17:36.523
Alguém que fala da sua teoria
sobre o funcionamento do cérebro

00:17:36.523 --> 00:17:38.723
mas não diz o que se passa
dentro do cérebro

00:17:38.723 --> 00:17:41.457
e como funcionam as ligações,
isso não é nenhuma teoria.

00:17:41.457 --> 00:17:44.247
É o que estamos a fazer no 
Instituto Redwood Neuroscience.

00:17:44.247 --> 00:17:48.000
Adorava poder dizer que estamos
a fazer progressos fantásticos.

00:17:48.000 --> 00:17:50.000
Espero voltar a este palco,

00:17:50.000 --> 00:17:52.400
talvez num futuro próximo,
e falar-vos sobre isso.

00:17:52.400 --> 00:17:55.000
Estou muito entusiasmado.
Isto não vai levar 50 anos.

00:17:55.000 --> 00:17:57.561
Então, como é uma teoria do cérebro?

00:17:57.561 --> 00:17:59.504
Vai ser uma teoria sobre a memória.

00:17:59.504 --> 00:18:02.361
Não como memória de computador,
não tem nada a ver com isso.

00:18:02.361 --> 00:18:05.076
É uma memória
desses padrões multidimensão,

00:18:05.076 --> 00:18:06.952
como o que nos chega dos nossos olhos.

00:18:06.952 --> 00:18:08.628
É também memória de sequências.

00:18:08.628 --> 00:18:11.457
Não podem aprender ou lembrar nada
fora de uma sequência.

00:18:11.457 --> 00:18:14.504
Uma canção tem de ser ouvida
numa sequência através do tempo,

00:18:14.504 --> 00:18:17.323
e vocês têm de a relembrar
numa sequência através do tempo.

00:18:17.323 --> 00:18:20.000
Essas sequências são chamadas
por autoassociatividade,

00:18:20.000 --> 00:18:23.514
se eu vir ou ouvir algo, lembra-me algo,
e é reproduzido automaticamente.

00:18:23.514 --> 00:18:27.676
É uma reprodução automática. A predição
da entrada futura é a saída desejada.

00:18:27.676 --> 00:18:30.561
Como eu disse, a teoria tem de ser
biologicamente exata,

00:18:30.561 --> 00:18:32.819
tem de ser testável,
e têm de poder construí-la

00:18:32.819 --> 00:18:36.400
Se não a construírem, não a compreendem.
Por isso, mais um slide aqui.

00:18:36.400 --> 00:18:38.180
Em que é que isto vai resultar?

00:18:38.180 --> 00:18:40.571
Vamos mesmo construir
máquinas inteligentes?

00:18:40.571 --> 00:18:44.352
Absolutamente. E vai ser diferente
do que as pessoas pensam.

00:18:44.352 --> 00:18:47.504
Quanto a mim, não há dúvida
de que vai acontecer.

00:18:47.504 --> 00:18:51.190
Em primeiro lugar,
vamos construí-las de silício.

00:18:51.190 --> 00:18:55.076
Podemos usar as mesmas técnicas que usamos
para construir memórias de computador,

00:18:55.076 --> 00:18:57.085
Mas são tipos de memória muito diferentes.

00:18:57.085 --> 00:18:59.000
Vamos ligar essas memórias a sensores,

00:18:59.000 --> 00:19:01.723
e os sensores vão receber
dados reais em tempo real,

00:19:01.723 --> 00:19:04.400
e estas coisas vão aprender
sobre o seu meio ambiente.

00:19:04.400 --> 00:19:07.819
É pouco provável que as primeiras coisas
que vamos ver sejam como robôs.

00:19:07.819 --> 00:19:10.333
Os robôs são úteis,
as pessoas podem fazer robôs.

00:19:10.333 --> 00:19:13.781
Mas a parte robótica é o mais difícil.
É o cérebro antigo.

00:19:13.781 --> 00:19:16.076
O novo cérebro é mais fácil que o antigo.

00:19:16.076 --> 00:19:19.352
Portanto, a primeira coisa a fazer
é o que não necessita de robótica.

00:19:19.352 --> 00:19:21.380
Por isso não vão ver o C-3PO.

00:19:21.380 --> 00:19:23.580
Vão ver coisas como carros inteligentes

00:19:23.580 --> 00:19:26.190
que percebem o que é o tráfego
e o que é conduzir,

00:19:26.190 --> 00:19:29.723
que aprenderam que carros que têm
o pisca ligado há mais de 30 segundos

00:19:29.723 --> 00:19:32.038
provavelmente não vão virar,
coisas dessas.

00:19:32.276 --> 00:19:34.895
Também podemos fazer
sistemas de segurança inteligentes.

00:19:34.895 --> 00:19:38.161
Tudo em que utilizamos o cérebro,
mas sem fazer muita mecânica.

00:19:38.161 --> 00:19:40.123
São as coisas que vão aparecer primeiro.

00:19:40.123 --> 00:19:43.380
Mas o limite aqui é o mundo.
Não sei o que é que isto vai dar.

00:19:43.380 --> 00:19:46.314
Conheço muitas pessoas
que inventaram o microprocessador.

00:19:46.685 --> 00:19:51.000
Eles sabiam que o que estavam a fazer
era realmente significativo,

00:19:51.000 --> 00:19:54.057
mas não sabiam realmente
o que iria acontecer.

00:19:54.057 --> 00:19:58.457
Não podiam prever telefones portáteis,
a Internet e todo este tipo de coisas.

00:19:58.571 --> 00:20:01.866
Só sabiam que iam construir calculadoras
e controladores de semáforos.

00:20:01.866 --> 00:20:03.838
Mas está a ser enorme.

00:20:03.838 --> 00:20:06.000
Isto é como a ciência do cérebro.

00:20:06.000 --> 00:20:09.000
Estas memórias vão ser
uma tecnologia fundamental,

00:20:09.000 --> 00:20:12.047
que vai levar-nos a mudanças incríveis
nos próximos 100 anos.

00:20:12.104 --> 00:20:15.009
Estou mais entusiasmado 
como vamos utilizá-las em ciência.

00:20:15.771 --> 00:20:19.314
Acho que o meu tempo já acabou
e vou acabar a minha palestra aqui mesmo.

