WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: Hugues Marty
Relecteur: Salome Hevin

00:00:25.000 --> 00:00:28.000
Je fais deux choses. Je conçois des ordinateurs portables, et j'étudie le cerveau.

00:00:29.000 --> 00:00:31.000
La conférence d'aujourd'hui parlera du cerveau, et

00:00:31.000 --> 00:00:33.000
super, il y a un fan des cerveaux dans la salle !

00:00:33.000 --> 00:00:35.000
(Rires)

00:00:35.000 --> 00:00:37.000
Maintenant, si on peut afficher mon premier slide là-haut,

00:00:37.000 --> 00:00:41.000
vous verrez le titre de ma conférence et mes deux affiliations.

00:00:41.000 --> 00:00:45.000
Donc, mon sujet sera la raison pour laquelle on n'a pas de bonne théorie de cerveau,

00:00:45.000 --> 00:00:48.000
pourquoi il est important qu'on en développe une, et ce qu'on peut faire pour ça.

00:00:48.000 --> 00:00:51.000
Et j'essayerai de faire tout ça en 20 minutes. J'ai deux affiliations.

00:00:51.000 --> 00:00:54.000
La plupart d'entre vous me connaissent par mon travail chez Palm et Handsprings,

00:00:54.000 --> 00:00:57.000
mais je gère aussi un institut de recherche à but non lucratif,

00:00:57.000 --> 00:00:59.000
appelé "Redwood Neuroscience Institute", à Menlo Park,

00:00:59.000 --> 00:01:01.000
où on étudie la neuroscience théorique

00:01:01.000 --> 00:01:03.000
et comment fonctionne le néocortex.

00:01:03.000 --> 00:01:05.000
C'est de cela en particulier que je vais parler.

00:01:05.000 --> 00:01:08.000
J'ai un slide qui concerne mon autre vie, ma vie informatique, c'est celui-là.

00:01:08.000 --> 00:01:11.000
Voici quelques uns des produits sur lesquels j'ai travaillé ces 20 dernières années,

00:01:11.000 --> 00:01:15.000
du tout premier ordinateur portable à certaines des premières tablettes informatiques,

00:01:15.000 --> 00:01:17.000
et ainsi de suite jusqu'au Treo le plus récemment,

00:01:17.000 --> 00:01:19.000
et on continue à travailler dessus.

00:01:19.000 --> 00:01:21.000
J'ai fait cela car je crois vraiment que l'informatique mobile

00:01:21.000 --> 00:01:24.000
est le futur de l'informatique personnelle, et j'essaie de rendre le monde

00:01:24.000 --> 00:01:27.000
un peu meilleur en travaillant sur ces choses.

00:01:27.000 --> 00:01:29.000
Mais tout cela était, je dois l'avouer, totalement un accident.

00:01:29.000 --> 00:01:31.000
En fait, je ne voulais faire aucun de ces produits

00:01:31.000 --> 00:01:33.000
et très tôt dans ma carrière j'ai décidé

00:01:33.000 --> 00:01:36.000
que je n'irais pas dans l'industrie informatique.

00:01:36.000 --> 00:01:38.000
Et avant que je ne vous raconte ça, il faut juste que je vous parle

00:01:38.000 --> 00:01:40.000
de cette petite image de graffiti que j'ai récupéré sur Internet l'autre jour.

00:01:40.000 --> 00:01:43.000
Je cherchais une image de graffiti, un petit langage de saisie de texte,

00:01:43.000 --> 00:01:46.000
et j'ai trouvé le site dédié aux enseignants qui veulent en faire,

00:01:46.000 --> 00:01:49.000
vous savez, le script qui écrit des choses en haut de leur tableau,

00:01:49.000 --> 00:01:52.000
et ils y avaient ajouté des graffiti, ce dont je suis désolé.

00:01:52.000 --> 00:01:54.000
(Rires)

00:01:54.000 --> 00:01:59.000
Donc, ce qui c'est passé, c'est que dans ma jeunesse, après être sorti de l'école d'ingénieur

00:01:59.000 --> 00:02:03.000
Cornell en 1979, j'ai décidé d'aller travailler pour Intel.

00:02:03.000 --> 00:02:06.000
J'étais dans l'industrie informatique, et au bout de trois mois là-dedans,

00:02:06.000 --> 00:02:10.000
je suis tombé amoureux d'autre chose, et je me suis dit: "Je me suis trompé de carrière",

00:02:10.000 --> 00:02:13.000
et je suis tombé amoureux des cerveaux.

00:02:13.000 --> 00:02:16.000
Ça n'est pas un vrai cerveau. C'est une image, un dessin.

00:02:16.000 --> 00:02:19.000
Je ne me souviens pas exactement comment ça s'est passé,

00:02:19.000 --> 00:02:22.000
mais j'ai un souvenir, assez net dans mon esprit.

00:02:22.000 --> 00:02:25.000
En septembre 1979, le magazine Scientific American

00:02:25.000 --> 00:02:28.000
avec un numéro spécial sur le cerveau. Et il était assez bon.

00:02:28.000 --> 00:02:31.000
Ce fut l'un de leurs meilleurs numéros. Ils parlaient de neurones,

00:02:31.000 --> 00:02:33.000
du leurs développement et de leurs maladies, de la vue,

00:02:33.000 --> 00:02:36.000
et de tout ce qu'on pouvait désirer savoir sur le cerveau. C'était vraiment impressionnant.

00:02:36.000 --> 00:02:39.000
On pouvait avoir l'impression qu'on connaissant vraiment beaucoup de choses sur le cerveau.

00:02:39.000 --> 00:02:43.000
Mais le dernier article de ce numéro était écrit par Francis Crick, connu pour l'ADN.

00:02:43.000 --> 00:02:46.000
C'est aujourd'hui, je pense, le 50ème anniversaire de la découverte de l'ADN.

00:02:46.000 --> 00:02:48.000
Et il avait écrit un article qui disait, en gros,

00:02:48.000 --> 00:02:51.000
tout ça c'est bien joli, mais vous savez quoi,

00:02:51.000 --> 00:02:53.000
on n'y connaît que dalle sur le cerveau

00:02:53.000 --> 00:02:55.000
et personne ne sait comment ce truc fonctionne,

00:02:55.000 --> 00:02:57.000
alors, ne croyez pas ce que quiconque vous dira.

00:02:57.000 --> 00:03:00.000
Dans un extrait de l'article, il dit : "Ce qui manque ostensiblement",

00:03:00.000 --> 00:03:04.000
c'était un vrai gentleman anglais, donc, "ce qui manque ostensiblement,

00:03:04.000 --> 00:03:07.000
c'est un vaste cadre d'idées au sein duquel interpréter ces différentes approches."

00:03:07.000 --> 00:03:09.000
J'ai pensé que le terme de "cadre" était formidable.

00:03:09.000 --> 00:03:11.000
Il n'a pas dit qu'on n'avait même pas de théorie. Il dit,

00:03:11.000 --> 00:03:13.000
on ne sait même pas par où commencer à y penser,

00:03:13.000 --> 00:03:15.000
on n'a même pas de cadre.

00:03:15.000 --> 00:03:18.000
On est dans un stade pré-paradigmatique, en se référant à Thomas Kohn.

00:03:18.000 --> 00:03:21.000
Je suis tombé amoureux de cela, et j'ai dit, regarde,

00:03:21.000 --> 00:03:24.000
on a tout ces connaissances à propos du cerveau. C'est si difficile que ça ?

00:03:24.000 --> 00:03:27.000
C'est quelque chose sur quoi on peut travailler aujourd'hui. J'ai senti que je pouvais faire une différence,

00:03:27.000 --> 00:03:31.000
et j'ai donc essayé de sortir de l'industrie informatique, pour entrer dans le domaine du cerveau.

00:03:31.000 --> 00:03:33.000
Premièrement, je suis entré au MIT, où se trouvait le A.l Lab (NdT : Laboratoire d'Intelligence Artificielle du M.I.T)

00:03:33.000 --> 00:03:35.000
et je me suis dit, je veux construire des machines intelligentes moi aussi,

00:03:35.000 --> 00:03:38.000
mais pour faire ça, je vais commencer par étudier le fonctionnement du cerveau.

00:03:38.000 --> 00:03:41.000
Et ils ont dit, oh, vous n'avez pas besoin de faire ça.

00:03:41.000 --> 00:03:43.000
On va juste programmer des ordinateurs, c'est tout ce qu'on doit faire.

00:03:43.000 --> 00:03:46.000
Et j'ai dit, non, vous devriez vraiment étudier le cerveau. Ils ont dit, oh, vous savez,

00:03:46.000 --> 00:03:48.000
vous avez tort. Et j'ai dit, non, vous avez tort, et je n'ai pas été pris.

00:03:48.000 --> 00:03:49.000
(Rires)

00:03:50.000 --> 00:03:52.000
Mais j'étais un peu déçu - assez jeune, mais j'y suis retourné

00:03:52.000 --> 00:03:55.000
quelques années plus tard, cette fois en Californie, et je suis allé à Berkeley.

00:03:55.000 --> 00:03:59.000
Et je me suis dit, je vais y aller par le côté biologique.

00:03:59.000 --> 00:04:02.000
Donc j'ai été pris - dans un programme doctoral en Biophysique.

00:04:02.000 --> 00:04:05.000
J'étudiais enfin le cerveau, et je me suis dit, bon, je veux étudier la théorie.

00:04:05.000 --> 00:04:07.000
Et ils ont dit, oh non, vous ne pouvez pas étudier la théorie à propos du cerveau.

00:04:07.000 --> 00:04:09.000
Ce n'est pas quelque chose qu'on fait. Vous n'aurez pas de subventions pour ça.

00:04:09.000 --> 00:04:13.000
En tant qu'étudiant en troisième cycle, vous ne pouvez pas faire ça. Donc je me suis dit, oh mon dieu.

00:04:13.000 --> 00:04:15.000
J'étais très déprimé. J'ai dit, je peux faire une différence dans ce domaine.

00:04:15.000 --> 00:04:18.000
Donc ce que j'ai fait, c'est de retourner dans l'industrie informatique,

00:04:18.000 --> 00:04:20.000
et je me suis dit, bon, il faut que je travaille là-dedans pendant un temps, il faut que je fasse quelque chose.

00:04:20.000 --> 00:04:23.000
C'est là que j'ai créé tous ces produits informatiques.

00:04:23.000 --> 00:04:24.000
(Rires)

00:04:24.000 --> 00:04:27.000
Je me suis dit, je vais faire ça pendant quatre ans, me faire de l'argent,

00:04:27.000 --> 00:04:31.000
comme j'avais une famille, et je deviendrais un peu plus mûr,

00:04:31.000 --> 00:04:34.000
et peut-être que les neurosciences mûriraient aussi un peu.

00:04:34.000 --> 00:04:37.000
Ça a mis plus longtemps que quatre ans. Ça a pris 16 ans.

00:04:37.000 --> 00:04:39.000
Mais je le fais maintenant, et je vais vous en parler.

00:04:39.000 --> 00:04:42.000
Donc, pourquoi devrions-nous avoir une bonne théorie du cerveau ?

00:04:42.000 --> 00:04:45.000
À vrai dire, il y a beaucoup de raisons pour lesquelles les gens font des sciences.

00:04:45.000 --> 00:04:48.000
L'une d'elle - la plus basique - est que les gens aiment connaître les choses.

00:04:48.000 --> 00:04:50.000
Nous sommes curieux, et nous allons juste chercher des connaissances, vous voyez ?

00:04:50.000 --> 00:04:52.000
Pourquoi est-ce qu'on étudie les fourmis ? Parce que c'est intéressant.

00:04:52.000 --> 00:04:55.000
Peut-être qu'on y apprendra quelque chose d'utile, mais c'est intéressant et fascinant.

00:04:55.000 --> 00:04:57.000
Mais parfois, une science a d'autres attributs,

00:04:57.000 --> 00:04:59.000
qui la rendent vraiment, vraiment intéressante.

00:04:59.000 --> 00:05:02.000
Parfois, une science nous dira quelque chose sur nous-mêmes,

00:05:02.000 --> 00:05:03.000
elle nous dira qui nous sommes.

00:05:03.000 --> 00:05:06.000
Pas souvent, mais la théorie de l'évolution a eu cet effet. Copernic aussi,

00:05:06.000 --> 00:05:08.000
et nous avons une meilleure compréhension de qui nous sommes.

00:05:08.000 --> 00:05:12.000
Et après tout, nous sommes notre cerveau. Mon cerveau parle à votre cerveau.

00:05:12.000 --> 00:05:15.000
Nos corps suivent, mais c'est mon cerveau qui parle à votre cerveau.

00:05:15.000 --> 00:05:18.000
Et si nous voulons comprendre qui nous sommes, comment nous ressentons et percevons,

00:05:18.000 --> 00:05:20.000
il faut vraiment comprendre ce qu'est le cerveau.

00:05:20.000 --> 00:05:22.000
Un autre élément est que parfois la science

00:05:22.000 --> 00:05:24.000
nous mène à de vraiment gros avantages sociaux et technologiques,

00:05:24.000 --> 00:05:26.000
ou commerciaux, ou autres, qui en sont issus. Et c'en est un, aussi,

00:05:26.000 --> 00:05:29.000
car quand nous comprenondrons comment le cerveau fonctionne, nous serons capables

00:05:29.000 --> 00:05:32.000
de construire des machines intelligentes, et à vrai dire je pense que c'est une bonne chose globalement,

00:05:32.000 --> 00:05:34.000
cela va avoir des avantages immenses pour la société,

00:05:34.000 --> 00:05:36.000
comme une technologie fondamentale.

00:05:36.000 --> 00:05:38.000
Donc, pourquoi n'avons-nous pas de bonne théorie du cerveau ?

00:05:38.000 --> 00:05:41.000
Et il y a des gens qui ont travaillé là-dessus depuis 100 ans.

00:05:41.000 --> 00:05:43.000
Tout d'abord, regardons ce à quoi ressemble la science normale.

00:05:43.000 --> 00:05:45.000
Voilà la science normale.

00:05:45.000 --> 00:05:49.000
La science normale est un équilibre entre théories et expérimentations.

00:05:49.000 --> 00:05:51.000
Le théoricien dit, voilà, je pense que c'est ce qui se passe,

00:05:51.000 --> 00:05:53.000
et l'expérimentateur dit, non, vous avez tort.

00:05:53.000 --> 00:05:55.000
Et ça fait des allers-retours, vous voyez ?

00:05:55.000 --> 00:05:57.000
Ça marche pour la physique. Et pour la géologie. Mais si c'est ça la science normale,

00:05:57.000 --> 00:06:00.000
à quoi ressemble la neuroscience ? Voilà à quoi la neuroscience ressemble.

00:06:00.000 --> 00:06:05.000
On a cette montagne de données, l'anatomie, la physiologie, le comportement.

00:06:05.000 --> 00:06:08.000
Vous n'imaginez pas combien de détails on connaît à propos du cerveau.

00:06:08.000 --> 00:06:12.000
Il y a 28000 personnes qui sont allées à la conférence sur la neuroscience cette année,

00:06:12.000 --> 00:06:14.000
et chacune d'entre elles faisaient des recherches sur le cerveau.

00:06:14.000 --> 00:06:18.000
Beaucoup de données. Mais il n'y a pas de théorie. Il y a une petite boîte timide là-haut.

00:06:18.000 --> 00:06:23.000
Et la théorie n'a joué aucun rôle majeur en neurosciences.

00:06:23.000 --> 00:06:26.000
C'est vraiment dommage. Comment ça se fait ?

00:06:26.000 --> 00:06:28.000
Si vous demandez à des neuroscientifiques pourquoi il en est ainsi,

00:06:28.000 --> 00:06:31.000
déjà, ils confirmeront. Mais si vous leur demandez, ils vous diront,

00:06:31.000 --> 00:06:34.000
eh bien, il y a diverses raisons pour lesquelles on n'a pas de bonne théorie du cerveau.

00:06:34.000 --> 00:06:36.000
Certains diront qu'on n'a pas encore assez de données,

00:06:36.000 --> 00:06:39.000
on doit rassembler plus d'informations, il y a toutes ces choses qu'on ignore.

00:06:39.000 --> 00:06:42.000
Mais je vous ai dit qu'on croule sous les données.

00:06:42.000 --> 00:06:45.000
On a tant d'informations qu'on ne sait pas par où commencer pour les organiser.

00:06:45.000 --> 00:06:47.000
À quoi servirait d'en avoir plus ?

00:06:47.000 --> 00:06:50.000
On sera peut-être chanceux et on découvrira quelque chose de magique, mais je n'y crois pas.

00:06:50.000 --> 00:06:53.000
C'est en fait simplement un symptôme de l'absence de théorie.

00:06:53.000 --> 00:06:56.000
On n'a pas besoin de plus de données, on a besoin d'une bonne théorie à leur sujet.

00:06:56.000 --> 00:06:59.000
Parfois, les gens disent que le cerveau est si complexe

00:06:59.000 --> 00:07:01.000
que ça prendra 50 ans de plus.

00:07:01.000 --> 00:07:03.000
Je crois même que Chris a dit quelque chose comme ça hier.

00:07:03.000 --> 00:07:05.000
Je ne suis pas sûr de ce que vous avez dit, Chris, mais c'était quelque chose dans le genre de :

00:07:05.000 --> 00:07:08.000
"C'est l'une des choses les plus compliquées de l'univers." Ce n'est pas vrai.

00:07:08.000 --> 00:07:10.000
Vous êtes plus compliqué que votre cerveau. Vous avez un cerveau.

00:07:10.000 --> 00:07:12.000
Et c'est aussi que, bien que le cerveau semble très compliqué,

00:07:12.000 --> 00:07:15.000
les choses semblent compliquées jusqu'à ce qu'on les comprennent.

00:07:15.000 --> 00:07:18.000
Ça a toujours été le cas. Donc tout ce que nous pouvons dire,

00:07:18.000 --> 00:07:22.000
c'est que mon néocortex, qui est la partie du cerveau qui m'intéresse, a 30 milliards de cellules.

00:07:22.000 --> 00:07:24.000
Mais vous savez quoi ? Il est vraiment très simple.

00:07:24.000 --> 00:07:27.000
En fait, on dirait que c'est la même chose qui se répète encore et encore et encore.

00:07:27.000 --> 00:07:30.000
Il n'est pas aussi compliqué qu'en apparence. Ce n'est pas le problème.

00:07:30.000 --> 00:07:32.000
Certains disent que le cerveau ne peut pas comprendre le cerveau.

00:07:32.000 --> 00:07:35.000
C'est très zen comme idée. Wow ! Vous savez...

00:07:35.000 --> 00:07:36.000
(Rires)

00:07:36.000 --> 00:07:39.000
Ça sonne bien mais pourquoi dire ça ? Ça mène à quoi ?

00:07:39.000 --> 00:07:42.000
C'est juste un tas de cellules. Vous comprenez votre foie.

00:07:42.000 --> 00:07:44.000
Il est aussi composé de beaucoup de cellules, pas vrai ?

00:07:44.000 --> 00:07:46.000
Donc je ne pense pas que ça soit très juste de dire ça.

00:07:46.000 --> 00:07:48.000
Et finalement, d'autres personnes disent

00:07:48.000 --> 00:07:52.000
qu'elles ne se sentent pas être un tas de cellules. Qu'elles sont conscientes.

00:07:52.000 --> 00:07:54.000
Je fais cette expérience, je vis dans ce monde.

00:07:54.000 --> 00:07:56.000
Je ne peux pas être simplement un tas de cellules.

00:07:56.000 --> 00:07:59.000
Les gens avaient l'habitude de penser qu'il y avait une force vitale,

00:07:59.000 --> 00:08:01.000
et on sait aujourd'hui que ce n'est pas du tout vrai.

00:08:01.000 --> 00:08:04.000
Et il n'y a vraiment pas de preuve qui dise... Enfin, à part les gens

00:08:04.000 --> 00:08:06.000
qui ne croient pas que les cellules puissent faire ce qu'elles font.

00:08:06.000 --> 00:08:09.000
Et donc, même si des gens sont tombés dans la fosse du dualisme métaphysique,

00:08:09.000 --> 00:08:12.000
même des gens très intelligents, hé bien on peut rejeter tout ça.

00:08:12.000 --> 00:08:14.000
(Rires)

00:08:14.000 --> 00:08:17.000
Non, je vais vous dire qu'il y a quelque chose d'autre,

00:08:17.000 --> 00:08:19.000
et c'est vraiment fondamental. Voilà ce qu'il en est :

00:08:19.000 --> 00:08:21.000
il y a une autre raison pour laquelle nous n'avons pas de théorie du cerveau satisfaisante,

00:08:21.000 --> 00:08:24.000
c'est parce qu'on a une supposition intuitive, très ferme,

00:08:24.000 --> 00:08:29.000
mais incorrecte qui nous empêche de vois la réponse.

00:08:29.000 --> 00:08:32.000
Il y a quelque chose qu'on croît évident, mais qui est faux.

00:08:32.000 --> 00:08:36.000
Il y a une histoire de ce type en science, et avant que je ne vous dise laquelle,

00:08:36.000 --> 00:08:38.000
je vais vous en dire un peu plus sur l'histoire à ce sujet en science.

00:08:38.000 --> 00:08:40.000
Si vous regardez certaines des autres révolutions scientifiques,

00:08:40.000 --> 00:08:42.000
dans le cas présent, je parle du système solaire, avec Corpernic,

00:08:42.000 --> 00:08:45.000
l'évolution de Darwin, et les plaques tectoniques de Wegener.

00:08:45.000 --> 00:08:48.000
Elles ont toutes beaucoup en commun avec la science du cerveau.

00:08:48.000 --> 00:08:51.000
Tout d'abord, il y avait toutes ces données inexpliquées. Un tas de données.

00:08:51.000 --> 00:08:54.000
Mais elles sont devenues gérables une fois qu'il y a eu une théorie.

00:08:54.000 --> 00:08:57.000
Les meilleurs esprits séchaient, des gens vraiment, vraiment intelligents.

00:08:57.000 --> 00:08:59.000
Nous ne sommes pas plus intelligents maintenant qu'à leur époque.

00:08:59.000 --> 00:09:01.000
Il s'avère juste qu'il est vraiment très difficile de penser les choses,

00:09:01.000 --> 00:09:03.000
mais une fois que vous y avez pensé, il est relativement aisé de les comprendre.

00:09:03.000 --> 00:09:05.000
Mes filles ont compris ces trois théories

00:09:05.000 --> 00:09:08.000
dans leur cadre général en maternelle.

00:09:08.000 --> 00:09:11.000
Ce n'est pas si dure, vous savez, voilà la pomme, voilà l'orange,

00:09:11.000 --> 00:09:14.000
la Terre tourne, et tout ça.

00:09:14.000 --> 00:09:16.000
Enfin, une autre chose est que la réponse était là depuis le début,

00:09:16.000 --> 00:09:19.000
mais on l'avait plus ou moins ignorée à cause de cette chose évidente.

00:09:19.000 --> 00:09:22.000
C'est cette croyance intuitive et fermement ancrée qui était fausse.

00:09:22.000 --> 00:09:25.000
Dans le cas du système solaire, l'idée que la Terre tournait

00:09:25.000 --> 00:09:28.000
et que la surface de la Terre bougeait à disons 1500 km/h,

00:09:28.000 --> 00:09:31.000
et que la Terre fonce à travers le système solaire à environ 1500000 km/h.

00:09:31.000 --> 00:09:33.000
C'est du délire. Tout le monde sait que la Terre ne bouge pas.

00:09:33.000 --> 00:09:35.000
Est-ce que vous sentez que vous bougez à 1500km/h ?

00:09:35.000 --> 00:09:37.000
Bien sûr que non. Et quelqu'un qui disait,

00:09:37.000 --> 00:09:39.000
en fait, elle tourne dans l'espace et est énorme,

00:09:39.000 --> 00:09:41.000
ils l'enfermaient, c'est ce qu'ils faisaient à cette époque.

00:09:41.000 --> 00:09:42.000
(Rires)

00:09:42.000 --> 00:09:45.000
Donc c'était intuitif et évident. Et maintenant, qu'en est-il pour l'évolution ?

00:09:45.000 --> 00:09:48.000
C'est la même chose pour l'évolution. On enseignait à nos enfants que la Bible dit

00:09:48.000 --> 00:09:50.000
que Dieu a créé toutes ces espèces, que les chats sont des chats, les chiens sont des chiens,

00:09:50.000 --> 00:09:53.000
les gens sont des gens, les plantes sont des plantes, donc ils ne changent pas.

00:09:53.000 --> 00:09:57.000
Noé les a mis dans son Arche dans cet ordre, bla bla bla.

00:09:57.000 --> 00:10:01.000
Et vous savez, le fait est que si vous croyez en l'évolution, nous avons tous un ancêtre commun,

00:10:01.000 --> 00:10:04.000
et nous avons tous une parenté commune avec la plant dans le hall.

00:10:04.000 --> 00:10:07.000
C'est ce que l'évolution nous enseigne. Et c'est vrai. C'est assez incroyable.

00:10:07.000 --> 00:10:10.000
Et c'est la même chose avec les plaques tectoniques.

00:10:10.000 --> 00:10:12.000
Toutes les montages et les continents flottent de-ci de-là

00:10:12.000 --> 00:10:16.000
sur la surface de la Terre. Ça ne fait aucun sens.

00:10:16.000 --> 00:10:20.000
Donc quelle est la supposition intuitive, mais incorrecte,

00:10:20.000 --> 00:10:22.000
qui nous empêche de comprendre le cerveau ?

00:10:22.000 --> 00:10:24.000
Je vais vous la dire, et il va sembler évident que c'est juste,

00:10:24.000 --> 00:10:26.000
et c'est là le but, non ? Ensuite je vais devoir expliquer

00:10:26.000 --> 00:10:28.000
pourquoi vous avez tort avec l'autre supposition.

00:10:28.000 --> 00:10:31.000
La chose intuitive et évidente est que quelque part l'intelligence

00:10:31.000 --> 00:10:33.000
est définie par le comportement,

00:10:33.000 --> 00:10:35.000
que nous sommes intelligents par la façon dont nous faisons les choses

00:10:35.000 --> 00:10:38.000
et la façon dont nous agissons intelligemment. Je vais vous dire que c'est une erreur.

00:10:38.000 --> 00:10:40.000
Le fait est que l'intelligence est définie par la capacité de prédiction.

00:10:40.000 --> 00:10:43.000
Je vais vous guider avec quelques slides,

00:10:43.000 --> 00:10:47.000
vous donner un exemple de ce que ça signifie. Voilà le système.

00:10:47.000 --> 00:10:50.000
Les ingénieurs aiment regarder les systèmes ainsi. Les scientifiques, eux, aiment regarder les systèmes comme ça.

00:10:50.000 --> 00:10:53.000
Ils disent "Bon, on a une chose dans une boîte, et il y a ses données d'entrée et de sortie."

00:10:53.000 --> 00:10:56.000
Les gens d'IA (intelligence artificielle) disent que cette chose dans la boîte est un ordinateur programmable

00:10:56.000 --> 00:10:58.000
car c'est équivalent à un cerveau. On lui fournit des données

00:10:58.000 --> 00:11:00.000
et on lui fait faire quelque chose, manifester des comportements.

00:11:00.000 --> 00:11:03.000
Et Alan Turing a défini le test de Turing, qui dit en gros

00:11:03.000 --> 00:11:06.000
qu'on saura si quelque chose est intelligent s'il se comporte comme un humain.

00:11:06.000 --> 00:11:09.000
C'est une mesure comportementale de ce qu'est l'intelligence,

00:11:09.000 --> 00:11:12.000
et c'est resté collé dans notre esprit pendant un long moment.

00:11:12.000 --> 00:11:14.000
La réalité, cependant, je l'appelle la véritable intelligence.

00:11:14.000 --> 00:11:16.000
La véritable intelligence est fondée sur quelque chose d'autre.

00:11:16.000 --> 00:11:20.000
On expérimente le monde à travers une séquence de motifs, qu'on stocke

00:11:20.000 --> 00:11:23.000
et dont on se rappelle. Et quand on s'en rappelle, on les confronte à la réalité,

00:11:23.000 --> 00:11:27.000
on fait des prédictions en permanence.

00:11:27.000 --> 00:11:30.000
C'est une mesure permanente. Il y a une mesure permanente à notre sujet, qui nous dit en gros,

00:11:30.000 --> 00:11:33.000
est-ce que je comprends le monde ? Est-ce que je fais des prédictions ? Et ainsi de suite.

00:11:33.000 --> 00:11:35.000
Vous êtes tous intelligents à cet instant présent, mais vous ne faites rien.

00:11:35.000 --> 00:11:37.000
Peut-être que vous vous grattez, ou vous vous mettez votre doigt dans le nez,

00:11:37.000 --> 00:11:39.000
je ne sais pas, mais vous ne faites rien à cet instant,

00:11:39.000 --> 00:11:42.000
mais vous êtes intelligents, vous comprenez ce que je dis.

00:11:42.000 --> 00:11:44.000
Parce que vous êtes intelligents et vous parlez anglais,

00:11:44.000 --> 00:11:45.000
vous savez quel mot se trouve à la fin de cette... (Silence)

00:11:45.000 --> 00:11:47.000
phrase.

00:11:47.000 --> 00:11:50.000
Le mot vous est venu à l'esprit, et vous faites ce type de prédiction tout le temps.

00:11:50.000 --> 00:11:52.000
Donc, ce que je dis,

00:11:52.000 --> 00:11:54.000
c'est que la prédiction permanente est l'output du néocortex.

00:11:54.000 --> 00:11:57.000
Et que d'une certaine façon, la prédiction mène à un comportement intelligent.

00:11:57.000 --> 00:12:00.000
Voilà comment ça se passe. Commençons avec un cerveau non-intelligent.

00:12:00.000 --> 00:12:04.000
Bon, je propose un cerveau non-intelligent, on a un vieux cerveau,

00:12:04.000 --> 00:12:07.000
on va dire que ce n'est pas un mammifère, plutôt un reptile,

00:12:07.000 --> 00:12:09.000
disons un alligator, on a un alligator.

00:12:09.000 --> 00:12:12.000
Et l'alligator a des sens très sophistiqués.

00:12:12.000 --> 00:12:15.000
Il a de bon yeux, de bonnes oreilles, un bon sens tactile, et ainsi de suite

00:12:15.000 --> 00:12:19.000
une bouche, un nez. Il a un comportement complexe.

00:12:19.000 --> 00:12:23.000
Il peut courir et se cacher. Il connaît la peur et les émotions. Il peut vous manger, vous savez.

00:12:23.000 --> 00:12:27.000
Il peut attaquer. Il peut faire tout ces trucs.

00:12:27.000 --> 00:12:32.000
Mais on ne considère pas que l'alligator est très intelligent, pas dans un sens humain.

00:12:32.000 --> 00:12:34.000
Mais il a déjà un comportement complexe.

00:12:34.000 --> 00:12:36.000
Que c'est-il passé dans l'évolution ?

00:12:36.000 --> 00:12:39.000
La première chose qui est arrivée dans l'évolution des mammifères,

00:12:39.000 --> 00:12:41.000
c'est que nous avons développé une chose appelée le néocortex.

00:12:41.000 --> 00:12:43.000
Je vais représenter un néocortex ici,

00:12:43.000 --> 00:12:45.000
par cette boîte qui vient se coller au-dessus du vieux cerveau.

00:12:45.000 --> 00:12:48.000
Le néocortex implique une nouvelle couche. C'est une nouvelle couche au-dessus de votre cerveau.

00:12:48.000 --> 00:12:51.000
Si vous ne le savez pas, c'est la chose ridée sur le dessus de la tête,

00:12:51.000 --> 00:12:54.000
elle a des rides parce qu'elle a été fourrée là-dedans et n'a pas la bonne taille.

00:12:54.000 --> 00:12:55.000
(Rires)

00:12:55.000 --> 00:12:57.000
Non, vraiment, c'est ça. Il a à peu près la taille d'une serviette de table.

00:12:57.000 --> 00:13:00.000
Et il ne tient pas là-dedans, donc il s'est ridé. Maintenant, regardez comment j'ai dessiné ça ici.

00:13:00.000 --> 00:13:04.000
Le vieux cerveau est toujours là. Vous avez toujours le cerveau d'alligator.

00:13:04.000 --> 00:13:06.000
Vous l'avez. C'est votre cerveau émotionnel.

00:13:06.000 --> 00:13:09.000
C'est toutes ces choses, toutes ces réactions instinctives que vous avez.

00:13:09.000 --> 00:13:12.000
Et par dessus, on a ce système de mémoire appelé néocortex.

00:13:12.000 --> 00:13:16.000
Et ce système de mémoire est posé sur la partie sensorielle du cerveau.

00:13:16.000 --> 00:13:19.000
Donc quand les données sensorielles arrivent du vieux cerveau,

00:13:19.000 --> 00:13:23.000
ells montent aussi dans le néocortex. Et le néocortex, c'est simplement la mémorisation.

00:13:23.000 --> 00:13:27.000
Il reste là à dire "Ah, je vais mémoriser toutes ces choses qui se produisent,

00:13:27.000 --> 00:13:29.000
où je suis allé, les gens que j'ai vus, les choses que j'ai entendues, et tout ça."

00:13:29.000 --> 00:13:33.000
Et dans le futur, quand il verra quelque chose de similaire à nouveau,

00:13:33.000 --> 00:13:36.000
dans un environnement similaire, ou exactement le même,

00:13:36.000 --> 00:13:38.000
il le rejouera. Il se mettra à le rejouer.

00:13:38.000 --> 00:13:40.000
"Oh, je suis déjà venu ici. Et quand tu es venu ici,

00:13:40.000 --> 00:13:43.000
ceci s'est produit ensuite". Cela vous permet de prédire le futur.

00:13:43.000 --> 00:13:47.000
Il renvoie littéralement le signal à votre cerveau,

00:13:47.000 --> 00:13:49.000
et vous laisse voir ce qui va se produire ensuite,

00:13:49.000 --> 00:13:52.000
vous laisse entendre le mot dans ma phrase avant que je ne l'ai dit.

00:13:52.000 --> 00:13:55.000
Et c'est ce renvoi de signal dans le vieux cerveau

00:13:55.000 --> 00:13:58.000
qui vous permet de prendre des décisions bien plus intelligentes.

00:13:58.000 --> 00:14:01.000
C'est le slide le plus important de mon propos, donc je vais m'attarder dessus un petit peu.

00:14:01.000 --> 00:14:05.000
Et donc, vous dites tout le temps, "oh je peux prédire les choses".

00:14:05.000 --> 00:14:08.000
Si vous êtes un rat qui parcourt un labyrinthe, et que vous apprenez à le connaître,

00:14:08.000 --> 00:14:10.000
la prochaine fois que vous vous y trouverez, vous aurez le même comportement,

00:14:10.000 --> 00:14:12.000
mais brusquement, vous êtes plus intelligents,

00:14:12.000 --> 00:14:15.000
parce que vous vous dites, "oh, je reconnais ce labyrinthe, je sais de quel côté aller,

00:14:15.000 --> 00:14:18.000
je suis déjà venu ici, je peux voir le future." Et c'est ce qui se produit.

00:14:18.000 --> 00:14:21.000
Chez l'homme, mais c'est valable pour tous les mammifères, au passage.

00:14:21.000 --> 00:14:23.000
C'est vrai pour tous les mammifères, et chez l'homme, c'est devenu encore pire.

00:14:23.000 --> 00:14:26.000
L'homme a en fait développé la partie frontale du néocortex,

00:14:26.000 --> 00:14:30.000
appelée partie antérieure du néocortex. Et la nature a fait un petit truc ici.

00:14:30.000 --> 00:14:32.000
Elle a copié la partie postérieure, la partie à l'arrière, qui est sensorielle,

00:14:32.000 --> 00:14:34.000
et l'a mise dans la partie avant.

00:14:34.000 --> 00:14:36.000
Et l'homme uniquement a le même mécanisme sur l'avant,

00:14:36.000 --> 00:14:38.000
mais l'utilise pour le contrôle moteur.

00:14:38.000 --> 00:14:41.000
Donc on peut maintenant effectuer des actions motrices planifiées très sophistiquées, des choses comme ça.

00:14:41.000 --> 00:14:44.000
Je n'ai pas le temps de poursuivre dans les détails, mais si vous voulez comprendre comment fonctionne un cerveau,

00:14:44.000 --> 00:14:47.000
vous devez comprendre comment la première partie du néocortex des mammifères fonctionne,

00:14:47.000 --> 00:14:49.000
et comment elle stocke des motifs et fait des prédictions.

00:14:49.000 --> 00:14:52.000
Laissez-moi donc vous donner quelques exemples de prédictions.

00:14:52.000 --> 00:14:54.000
J'ai déjà évoqué la complétion d'une phrase. En musique,

00:14:54.000 --> 00:14:57.000
si vous avez déjà entendu une chanson, si vous avez déjà entendu Jill chanter ces chansons auparavant,

00:14:57.000 --> 00:15:00.000
quand elle les chante, la prochaine note apparaît déjà dans votre esprit,

00:15:00.000 --> 00:15:02.000
vous l'anticipé au fur et à mesure. Si c'était un album de musique,

00:15:02.000 --> 00:15:05.000
à la fin d'un album, la prochaine chanson apparaît dans votre tête.

00:15:05.000 --> 00:15:07.000
Et ces choses arrivent tout le temps. Vous faites ces prédictions.

00:15:07.000 --> 00:15:10.000
J'ai cette expérience de pensée, dite de la porte modifiée,

00:15:10.000 --> 00:15:13.000
elle dit que vous avez une porte chez vous,

00:15:13.000 --> 00:15:16.000
et pendant que vous êtes ici, je la change, j'ai un type

00:15:16.000 --> 00:15:18.000
chez vous en ce moment même, qui change la porte,

00:15:18.000 --> 00:15:20.000
il va prendre la poignée et la bouger de cinq centimètres.

00:15:20.000 --> 00:15:22.000
Quand vous allez rentrer chez vous ce soir, vous allez avancer votre main

00:15:22.000 --> 00:15:24.000
pour attraper la poignée, et vous allez remarquer

00:15:24.000 --> 00:15:27.000
qu'elle se trouve au mauvais endroit, et vous vous direz, ola, quelque chose est arrivé.

00:15:27.000 --> 00:15:29.000
Ça prendra peut-être une seconde pour vous en rendre compte, mais quelque chose a changé.

00:15:29.000 --> 00:15:31.000
Mais je pourrais changer votre poignée de porte d'autres façons.

00:15:31.000 --> 00:15:33.000
Je peux la rendre plus grosse ou plus petite, je peux la faire passer de laiton à argentée,

00:15:33.000 --> 00:15:35.000
je peux changer son type. Je peux changer votre porte, la peindre,

00:15:35.000 --> 00:15:38.000
y mettre une fenêtre. Je peux changer mille chose sur votre porte,

00:15:38.000 --> 00:15:40.000
et dans les deux secondes qu'il faut pour ouvrir la porte,

00:15:40.000 --> 00:15:43.000
vous allez remarquer que quelque chose a changé.

00:15:43.000 --> 00:15:45.000
Maintenant, l'approche d'ingénieur, l'approche d'IA,

00:15:45.000 --> 00:15:48.000
c'est de créer une base de données sur la porte. Elle a tous les attributs de la porte.

00:15:48.000 --> 00:15:51.000
Et quand vous allez vers la porte, vous savez, vous les vérifier un à un.

00:15:51.000 --> 00:15:53.000
Porte, porte, porte, couleur, enfin vous voyez de quoi je parle.

00:15:53.000 --> 00:15:55.000
On ne fait pas ça. Votre cerveau ne fait pas ça.

00:15:55.000 --> 00:15:57.000
Ce que fait votre cerveau, c'est de constamment établir des prédictions

00:15:57.000 --> 00:15:59.000
sur ce qui va se produire dans votre environnement.

00:15:59.000 --> 00:16:02.000
Quand je pose ma main sur cette table, je m'attends à la sentir s'arrêter.

00:16:02.000 --> 00:16:05.000
Quand je marche, pour chaque pas, si j'en manquais un d'une fraction de centimètre,

00:16:05.000 --> 00:16:07.000
je saurais que quelque chose a changé.

00:16:07.000 --> 00:16:09.000
Vous faites constamment des prédictions sur votre environnement.

00:16:09.000 --> 00:16:12.000
Je vais parler brièvement de la vue ici. Voici l'image d'une femme.

00:16:12.000 --> 00:16:14.000
Quand vous regardez des gens, vos yeux sont attirés

00:16:14.000 --> 00:16:15.000
deux ou trois fois par seconde.

00:16:15.000 --> 00:16:17.000
Vous n'en avez pas conscience, mais vos yeux bougent tout le temps.

00:16:17.000 --> 00:16:19.000
Et donc quand vous regardez le visage de quelqu'un,

00:16:19.000 --> 00:16:21.000
vous passez typiquement d'un oeil à l'autre et du nez à la bouche.

00:16:21.000 --> 00:16:23.000
Quand votre oeil se déplace d'un oeil à l'autre,

00:16:23.000 --> 00:16:25.000
s'il y a quelque chose d'autre à cet endroit, comme un nez,

00:16:25.000 --> 00:16:27.000
vous verriez un nez où un oeil était attendu,

00:16:27.000 --> 00:16:30.000
et vous vous diriez : "Oh merde !", vous voyez...

00:16:30.000 --> 00:16:31.000
(Rires)

00:16:31.000 --> 00:16:33.000
"Il y a quelque chose qui cloche sur cette personne."

00:16:33.000 --> 00:16:35.000
C'est parce que vous faites une prédiction.

00:16:35.000 --> 00:16:37.000
Ce n'est pas comme si vous regardiez là et vous demandiez ce que vous voyez.

00:16:37.000 --> 00:16:40.000
Un nez, c'est bon. Non, vous vous attendez à voir quelque chose de particulier.

00:16:40.000 --> 00:16:41.000
(Rires)

00:16:41.000 --> 00:16:45.000
Tout le temps. Et, enfin, regardons à la façon dont on teste l'intelligence.

00:16:45.000 --> 00:16:48.000
On la teste par la prédiction : quel est le prochain mot ici ?

00:16:48.000 --> 00:16:51.000
Ceci est à cela ce que ceci est à cela. Quel est le prochain chiffre dans cette phrase ?

00:16:51.000 --> 00:16:53.000
Voici trois vues d'un objet.

00:16:53.000 --> 00:16:57.000
Quelle est la quatrième ? Voilà comment on la teste. C'est la prédiction.

00:16:57.000 --> 00:17:00.000
Dès lors, quelle est la recette pour une théorie du cerveau ?

00:17:00.000 --> 00:17:03.000
Premièrement, nous devons avoir le bon cadre de travail.

00:17:03.000 --> 00:17:05.000
C'est un système de mémoire,

00:17:05.000 --> 00:17:07.000
pas un système de calcul ou de comportement. C'est un système de mémoire.

00:17:07.000 --> 00:17:11.000
Comment est-ce que vous enregistrez et réutilisez ces séquences ou motifs ? Ce sont des motifs spatio-temporels.

00:17:11.000 --> 00:17:14.000
Maintenant, dans ce système, vous prenez un tas de théoriciens .

00:17:14.000 --> 00:17:16.000
Les biologistes ne sont généralement pas de bons théoriciens.

00:17:16.000 --> 00:17:20.000
Ce n'est pas toujours vrai, mais en général, il n'y a pas une bonne histoire de la théorie en biologie.

00:17:20.000 --> 00:17:23.000
J'ai trouvé que les meilleures personnes avec qui travailler sont les physiciens,

00:17:23.000 --> 00:17:26.000
les ingénieurs et les mathématiciens, qui ont tendance à penser avec des algorithmes.

00:17:26.000 --> 00:17:29.000
Ensuite, ils doivent apprendre l'anatomie et la physiologie.

00:17:29.000 --> 00:17:33.000
Vous devez rendre ces théories très réalistes en termes anatomiques.

00:17:33.000 --> 00:17:37.000
Quiconque se lève et vous expose sa théorie sur le fonctionnement du cerveau

00:17:37.000 --> 00:17:39.000
et ne vous explique pas exactement comment le cerveau fonctionne

00:17:39.000 --> 00:17:41.000
et comment les connexions cérébrales fonctionnent, ça ne fait pas une théorie.

00:17:41.000 --> 00:17:44.000
C'est ce que nous faisons au Redwood Neuroscience Institute.

00:17:44.000 --> 00:17:48.000
J'adorerai avoir plus de temps pour vous parler des fantastiques progrès que l'on fait là-dedans,

00:17:48.000 --> 00:17:50.000
et j'espère revenir une autre fois sur cette estrade,

00:17:50.000 --> 00:17:52.000
peut-être dans un avenir assez proche, et je vous en parlerai alors.

00:17:52.000 --> 00:17:55.000
Je suis vraiment très excité. Ça ne va absolument pas prendre 50 ans.

00:17:55.000 --> 00:17:57.000
À quoi ressemblera une théorie du cerveau ?

00:17:57.000 --> 00:17:59.000
D'abord, ça sera une théorie sur la mémoire.

00:17:59.000 --> 00:18:02.000
Pas comme de la mémoire informatique. Ça ne ressemble en rien à la mémoire informatique.

00:18:02.000 --> 00:18:04.000
C'est vraiment très différent. Et c'est une mémoire

00:18:04.000 --> 00:18:07.000
de motifs de grandes dimensions, comme les choses qui viennent de vos yeux.

00:18:07.000 --> 00:18:09.000
C'est aussi une mémoire de séquences.

00:18:09.000 --> 00:18:11.000
Vous ne pouvez pas apprendre ni vous rappeler quelque chose en dehors d'une séquence.

00:18:11.000 --> 00:18:14.000
Une chanson doit être entendue en séquence dans le temps,

00:18:14.000 --> 00:18:17.000
et vous devez la rejouer en séquence de la même façon.

00:18:17.000 --> 00:18:20.000
On se souvient de ces séquences de façon auto-associées, donc si je vois quelque chose,

00:18:20.000 --> 00:18:23.000
j'entends quelque chose, ça me le rappelle, et ça le rejoue automatiquement.

00:18:23.000 --> 00:18:27.000
C'est un playback automatique. Et la prédiction des futures données d'entrée, ce sont les données de sortie souhaitées.

00:18:27.000 --> 00:18:30.000
Et comme je l'ai dit, la théorie doit être exacte d'un point de vue biologique,

00:18:30.000 --> 00:18:32.000
elle doit être testable, et on doit pouvoir la construire.

00:18:32.000 --> 00:18:36.000
Si on ne la construit pas, on ne la comprend pas. Voici un dernier slide.

00:18:36.000 --> 00:18:40.000
Quel va être le résultat de tout cela ? Est-ce qu'on va vraiment construire des machines intelligentes ?

00:18:40.000 --> 00:18:44.000
Absolument. Et ça va être différent de ce que pensent les gens.

00:18:44.000 --> 00:18:47.000
Ça va arriver, ça ne fait aucun doute dans mon esprit.

00:18:47.000 --> 00:18:51.000
D'abord, on va le construire, créer le truc à partir de silicone.

00:18:51.000 --> 00:18:54.000
On utilisera les mêmes techniques

00:18:54.000 --> 00:18:55.000
que pour construire la mémoire informatique en silicone.

00:18:55.000 --> 00:18:57.000
Mais ce sont des types très différents de mémoires.

00:18:57.000 --> 00:18:59.000
Et on va attacher ces mémoires à des capteurs,

00:18:59.000 --> 00:19:02.000
et ceux-ci auront une expérience des données du monde réel, en temps réel,

00:19:02.000 --> 00:19:04.000
et ces choses apprendront des choses sur leur environnement.

00:19:04.000 --> 00:19:07.000
Il est très peu probable que les premières choses que vous verrez soient des robots.

00:19:07.000 --> 00:19:10.000
Non pas que les robots sont inutiles, et les gens savent construire des robots.

00:19:10.000 --> 00:19:14.000
Mais la partie robotique est la plus dure. C'est le vieux cerveau. C'est vraiment difficile.

00:19:14.000 --> 00:19:16.000
Le nouveau cerveau est en fait plutôt facile en comparaison avec le vieux cerveau.

00:19:16.000 --> 00:19:19.000
Donc les premières choses qu'on fera seront celles qui ne requièrent pas beaucoup de robotique.

00:19:19.000 --> 00:19:21.000
Donc vous ne verrez pas de C-3PO.

00:19:21.000 --> 00:19:23.000
Vous verrez des choses comme, disons, des voitures intelligentes

00:19:23.000 --> 00:19:26.000
qui comprennent vraiment ce qu'est le trafic, et ce qu'est conduire,

00:19:26.000 --> 00:19:29.000
et qui ont appris que certains types de voitures qui ont le clignotant allumé pendant trente secondes

00:19:29.000 --> 00:19:31.000
ne vont probablement pas tourner, des choses comme ça.

00:19:31.000 --> 00:19:32.000
(Rires)

00:19:32.000 --> 00:19:34.000
On peut aussi faire des systèmes de sécurité intelligents.

00:19:34.000 --> 00:19:38.000
Là où nous avons besoin de notre cerveau, en gros, mais pas de beaucoup de mécanismes.

00:19:38.000 --> 00:19:40.000
Ce sont les choses qui arriveront en premier.

00:19:40.000 --> 00:19:42.000
Mais après cela, la limite, c'est le monde.

00:19:42.000 --> 00:19:44.000
Je ne sais pas où cela va mener.

00:19:44.000 --> 00:19:46.000
Je connais beaucoup de ceux qui ont inventé le microprocesseur

00:19:46.000 --> 00:19:51.000
et si vous leur parlez, ils savaient que ce qu'ils faisaient était vraiment important,

00:19:51.000 --> 00:19:54.000
mais ils ne savaient pas vraiment ce qui allait se passer.

00:19:54.000 --> 00:19:59.000
Ils ne pouvaient pas anticiper les téléphones portables, Internet, et tous ces trucs.

00:19:59.000 --> 00:20:01.000
Ils savaient que, eh, ils allaient construire des calculatrices

00:20:01.000 --> 00:20:03.000
et des feux de signalisation. Mais ça allait être énorme.

00:20:03.000 --> 00:20:06.000
De la même façon, la science du cerveau et ces mémoires

00:20:06.000 --> 00:20:09.000
vont être une technologie fondamentale, et ça va mener

00:20:09.000 --> 00:20:12.000
à des changements incroyables dans les 100 prochaines années.

00:20:12.000 --> 00:20:16.000
Et je suis très excité quant à la façon dont on on les utilisera en science.

00:20:16.000 --> 00:20:19.000
Je pense que j'arrive à la limite de mon temps, donc je vais terminer mon discours

00:20:19.000 --> 00:20:20.000
maintenant.

