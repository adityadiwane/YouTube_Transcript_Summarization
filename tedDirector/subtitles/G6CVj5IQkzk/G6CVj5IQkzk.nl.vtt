WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Christel Foncke
Nagekeken door: Rik Delaet

00:00:25.000 --> 00:00:28.000
Ik doe twee dingen. Ik ontwerp mobiele computers en ik bestudeer hersenen.

00:00:29.000 --> 00:00:31.000
De lezing van vandaag gaat over hersenen en ...

00:00:31.000 --> 00:00:33.000
hé, blijkbaar heb ik daar ergens een brein-fan.

00:00:33.000 --> 00:00:35.000
(Gelach)

00:00:35.000 --> 00:00:37.000
Als ik mijn eerste dia krijg, zie je de titel

00:00:37.000 --> 00:00:41.000
van mijn lezing en de twee bedrijven waaraan ik verbonden ben.

00:00:41.000 --> 00:00:45.000
Ik ga het hebben over de reden waarom we nog geen goede hersentheorie hebben,

00:00:45.000 --> 00:00:48.000
en waarom het belangrijk is dat we er een ontwikkelen en hoe we dat kunnen bereiken.

00:00:48.000 --> 00:00:51.000
En dat allemaal in twintig minuten. Ik ben verbonden aan twee bedrijven.

00:00:51.000 --> 00:00:54.000
De meesten van jullie kennen me van mijn tijd bij Palm en Handspring,

00:00:54.000 --> 00:00:57.000
maar ik leid ook een non-profit wetenschappelijk onderzoeksinstituut,

00:00:57.000 --> 00:00:59.000
het Redwood Instituut voor Neurowetenschap in Menlo Park.

00:00:59.000 --> 00:01:01.000
We bestuderen theoretische neurowetenschap

00:01:01.000 --> 00:01:03.000
en hoe de neocortex werkt.

00:01:03.000 --> 00:01:05.000
Daar ga ik allerlei over vertellen.

00:01:05.000 --> 00:01:08.000
Deze dia gaat over mijn andere leven, mijn computerleven.

00:01:08.000 --> 00:01:11.000
Dit zijn een aantal producten waar ik de laatste twintig jaar aan heb gewerkt,

00:01:11.000 --> 00:01:15.000
van de allereerste originele laptop tot een paar van de eerste tablet-pc's

00:01:15.000 --> 00:01:17.000
enz.., met de Treo als de meest recente

00:01:17.000 --> 00:01:19.000
en hieraan werken we nog verder.

00:01:19.000 --> 00:01:21.000
Ik heb dit gedaan omdat ik echt geloof dat mobiel computergebruik

00:01:21.000 --> 00:01:24.000
de toekomst heeft en ik probeer de wereld

00:01:24.000 --> 00:01:27.000
een klein beetje beter te maken door aan deze dingen te werken.

00:01:27.000 --> 00:01:29.000
Maar dit was, moet ik toegeven, allemaal slechts toeval.

00:01:29.000 --> 00:01:31.000
Eigenlijk wou ik deze producten helemaal niet maken.

00:01:31.000 --> 00:01:33.000
Vroeg in mijn loopbaan besliste ik

00:01:33.000 --> 00:01:36.000
dat ik niet in de computerindustrie wilde werken.

00:01:36.000 --> 00:01:38.000
Voor ik jullie daarover vertel, moet ik jullie vertellen

00:01:38.000 --> 00:01:40.000
over dit graffitiplaatje dat ik onlangs vond op het internet.

00:01:40.000 --> 00:01:43.000
Ik zocht een graffitiplaatje, een taal met weinig tekst.

00:01:43.000 --> 00:01:46.000
Ik vond een website voor leerkrachten die

00:01:46.000 --> 00:01:49.000
slogans schrijven bovenaan hun schoolbord.

00:01:49.000 --> 00:01:52.000
Ze hadden er graffiti aan toegevoegd, mijn excuses daarvoor.

00:01:52.000 --> 00:01:54.000
(Gelach)

00:01:54.000 --> 00:01:59.000
Toen ik jong was en in '79 afstudeerde van de ingenieursschool van Cornell,

00:01:59.000 --> 00:02:03.000
besloot ik te gaan werken voor Intel.

00:02:03.000 --> 00:02:06.000
Ik zat in de computerindustrie en drie maanden later

00:02:06.000 --> 00:02:10.000
werd ik verliefd op iets anders. Ik zei: "Ik heb de verkeerde carrière gekozen."

00:02:10.000 --> 00:02:13.000
en werd verliefd op hersenen.

00:02:13.000 --> 00:02:16.000
Dit is geen echt brein. Het is een pentekening.

00:02:16.000 --> 00:02:19.000
Ik herinner me niet precies meer hoe het gegaan is,

00:02:19.000 --> 00:02:22.000
maar ik heb een herinnering die me sterk bijgebleven is.

00:02:22.000 --> 00:02:25.000
In september 1979 verscheen een uitgave van 'Scientific American'

00:02:25.000 --> 00:02:28.000
volledig gewijd aan de hersenen. Die was erg goed.

00:02:28.000 --> 00:02:31.000
Het was een van de beste uitgaven ooit. Ze spraken over het neuron,

00:02:31.000 --> 00:02:33.000
ontwikkeling, ziekte, het gezichtsvermogen en over nog veel meer

00:02:33.000 --> 00:02:36.000
wat je misschien wil weten over hersenen. Het was echt de moeite.

00:02:36.000 --> 00:02:39.000
Het gaf de indruk dat we echt veel wisten over de hersenen.

00:02:39.000 --> 00:02:43.000
Het laatste artikel in deze uitgave was geschreven door Francis Crick, beroemd van het DNA.

00:02:43.000 --> 00:02:46.000
Vandaag is het, geloof ik, de 50ste verjaardag van de ontdekking van DNA.

00:02:46.000 --> 00:02:48.000
Hij schreef iets wat neerkwam op:

00:02:48.000 --> 00:02:51.000
"Dit is allemaal goed en wel, maar

00:02:51.000 --> 00:02:53.000
we weten eigenlijk geen sikkepit over de hersenen

00:02:53.000 --> 00:02:55.000
en niemand heeft enig idee hoe ze werken.

00:02:55.000 --> 00:02:57.000
Geloof niet wat ze zeggen."

00:02:57.000 --> 00:03:00.000
Dit is een citaat uit dat artikel. Hij zegt: "Wat opvallenderwijs ontbreekt,"

00:03:00.000 --> 00:03:04.000
hij is een échte Engelse heer, dus: "Wat opvallenderwijs ontbreekt

00:03:04.000 --> 00:03:07.000
is een breed kader van ideeën om deze verschillende benaderingen te interpreteren."

00:03:07.000 --> 00:03:09.000
Ik vond het woord 'kader' goed.

00:03:09.000 --> 00:03:11.000
Hij zei niet dat we geen theorie hebben.

00:03:11.000 --> 00:03:13.000
Hij zei dat we zelfs niet weten hoe we erover moeten beginnen te denken.

00:03:13.000 --> 00:03:15.000
We hebben zelfs geen kader.

00:03:15.000 --> 00:03:18.000
We zijn in het pre-paradigmatijdperk als je Thomas Kuhn wilt gebruiken.

00:03:18.000 --> 00:03:21.000
Ik werd hier verliefd op en ik zei: “Kijk,

00:03:21.000 --> 00:03:24.000
we hebben zoveel kennis over de hersenen. Hoe moeilijk kan het zijn?”

00:03:24.000 --> 00:03:27.000
Hier kon ik mijn leven aan wijden. Ik voelde dat ik een verschil kon maken

00:03:27.000 --> 00:03:31.000
dus probeerde ik de overstap te maken van het domein van de computers naar dat van de hersenen.

00:03:31.000 --> 00:03:33.000
Eerst ging ik naar MIT, het lab voor kunstmatige intelligentie

00:03:33.000 --> 00:03:35.000
en ik zei: “Ik wil ook intelligente machines maken,

00:03:35.000 --> 00:03:38.000
maar ik wil dit doen door eerst te onderzoeken hoe de hersenen werken.”

00:03:38.000 --> 00:03:41.000
Ze zeiden: “Je hoeft dat niet te doen.

00:03:41.000 --> 00:03:43.000
We gaan gewoon computers programmeren, meer hoeft niet.”

00:03:43.000 --> 00:03:46.000
Ik zei: "Nee, je moet echt eerst de hersenen bestuderen." Zij zeiden: "Nee, je bent verkeerd."

00:03:46.000 --> 00:03:48.000
Ik zei: "Nee, jullie zijn verkeerd.", en zo werd ik niet aanvaard.

00:03:48.000 --> 00:03:49.000
(Gelach)

00:03:50.000 --> 00:03:52.000
Ik was een beetje ontgoocheld. Redelijk jong nog, maar ik ging

00:03:52.000 --> 00:03:55.000
een paar jaar later terug naar Berkeley, Californië.

00:03:55.000 --> 00:03:59.000
Ik zou het via de biologische kant benaderen.

00:03:59.000 --> 00:04:02.000
Ik werd aanvaard in het PhD programma van biofysica, en ik zat goed.

00:04:02.000 --> 00:04:05.000
Ik bestudeerde hersenen en ik zei: "Ik wil theorie studeren."

00:04:05.000 --> 00:04:07.000
Zij zeiden: "Nee, je kunt geen theorie studeren over de hersenen.

00:04:07.000 --> 00:04:09.000
Zoiets doe je niet. Je krijgt daar geen subsidies voor.

00:04:09.000 --> 00:04:13.000
Als bachelorstudent kan je dat niet doen.” Dus ik dacht: "Mijn god!"

00:04:13.000 --> 00:04:15.000
Ik was heel teleurgesteld, want ik wilde een verschil maken.

00:04:15.000 --> 00:04:18.000
Dus ging ik terug naar de computerindustrie

00:04:18.000 --> 00:04:20.000
en besefte dat ik hier even zou moeten werken, iets realiseren.

00:04:20.000 --> 00:04:23.000
Toen creëerde ik al die computerproducten.

00:04:23.000 --> 00:04:24.000
(Gelach)

00:04:24.000 --> 00:04:27.000
Ik zei: "Ik wil dit vier jaar doen en een beetje geld verdienen."

00:04:27.000 --> 00:04:31.000
Ik had ondertussen een gezin, ik zou een beetje volwassen worden

00:04:31.000 --> 00:04:34.000
en misschien zou het veld van de neurowetenschap ook wat volwassen worden.

00:04:34.000 --> 00:04:37.000
Het duurde wat langer dan vier jaar. Ondertussen al 16 jaar.

00:04:37.000 --> 00:04:39.000
Maar ik doe het nu en ik zal jullie erover vertellen.

00:04:39.000 --> 00:04:42.000
Waarom hebben we een goede hersentheorie nodig?

00:04:42.000 --> 00:04:45.000
Er zijn verschillende redenen waarom mensen aan wetenschap doen.

00:04:45.000 --> 00:04:48.000
Een ervan is: mensen weten graag dingen.

00:04:48.000 --> 00:04:50.000
We zijn nieuwsgierig en we gaan gewoon kennis opzoeken.

00:04:50.000 --> 00:04:52.000
Waarom bestuderen we mieren? Omdat het interessant is.

00:04:52.000 --> 00:04:55.000
We leren misschien iets nuttig, maar het is vooral interessant en fascinerend.

00:04:55.000 --> 00:04:57.000
Maar soms heeft een wetenschap nog andere kenmerken

00:04:57.000 --> 00:04:59.000
wat ze écht interessant maakt.

00:04:59.000 --> 00:05:02.000
Soms zal een wetenschap iets over onszelf vertellen,

00:05:02.000 --> 00:05:03.000
ons vertellen wie we zijn.

00:05:03.000 --> 00:05:06.000
Dit gebeurt maar heel af en toe zoals met de evolutietheorie en Copernicus,

00:05:06.000 --> 00:05:08.000
waardoor we een nieuw begrip kregen over wie we zijn.

00:05:08.000 --> 00:05:12.000
Uiteindelijk zijn we onze hersenen. Mijn brein praat nu met jouw brein.

00:05:12.000 --> 00:05:15.000
Onze lichamen volgen gewoon, maar mijn brein praat met jouw brein.

00:05:15.000 --> 00:05:18.000
Als we willen begrijpen wie we zijn en hoe we voelen en waarnemen,

00:05:18.000 --> 00:05:20.000
moeten we echt begrijpen wat hersenen zijn.

00:05:20.000 --> 00:05:22.000
Iets anders nog: wetenschap

00:05:22.000 --> 00:05:24.000
leidt soms tot grote maatschappelijke en technologische voordelen,

00:05:24.000 --> 00:05:26.000
bedrijven of om het even wat eruit voortkomt. Dit is er ook een van.

00:05:26.000 --> 00:05:29.000
Als we weten hoe de hersenen werken, zullen we

00:05:29.000 --> 00:05:32.000
intelligente machines kunnen maken en ik denk dat dit uiteindelijk iets goed is.

00:05:32.000 --> 00:05:34.000
Het zal enorme voordelen hebben voor onze maatschappij

00:05:34.000 --> 00:05:36.000
net zoals een fundamentele technologie.

00:05:36.000 --> 00:05:38.000
Waarom hebben we dan geen goede hersentheorie?

00:05:38.000 --> 00:05:41.000
We zijn er al honderd jaar naar op zoek.

00:05:41.000 --> 00:05:43.000
Laten we eerst kijken naar hoe normale wetenschap eruit ziet.

00:05:43.000 --> 00:05:45.000
Dit is normale wetenschap.

00:05:45.000 --> 00:05:49.000
Normale wetenschap is een mooie balans tussen theorie en experimenten.

00:05:49.000 --> 00:05:51.000
Degenen die de theorie bedenken zeggen: "Ik denk dat dit gebeurt.",

00:05:51.000 --> 00:05:53.000
terwijl degenen die de experimenten uitvoeren zeggen: "Nee, je zit verkeerd."

00:05:53.000 --> 00:05:55.000
Zo gaat dat over en weer, snap je?

00:05:55.000 --> 00:05:57.000
Zo gaat dat in fysica. Zo gaat dat in geologie. Maar als dit normale wetenschap is,

00:05:57.000 --> 00:06:00.000
hoe ziet neurowetenschap er dan uit? Zo ziet neurowetenschap eruit.

00:06:00.000 --> 00:06:05.000
We hebben een berg data, bestaande uit anatomie, fysiologie en gedrag.

00:06:05.000 --> 00:06:08.000
Je kunt je niet voorstellen hoeveel details we weten over de hersenen.

00:06:08.000 --> 00:06:12.000
Dit jaar kwamen 28.000 mensen naar de neurowetenschapsconferentie

00:06:12.000 --> 00:06:14.000
en stuk voor stuk deden ze aan hersenonderzoek.

00:06:14.000 --> 00:06:18.000
Een heleboel data. Maar er is geen theorie. Je ziet slechts een klein kadertje daarboven.

00:06:18.000 --> 00:06:23.000
Theorie heeft nog nooit een grote rol gespeeld in de neurowetenschap.

00:06:23.000 --> 00:06:26.000
Het is echt zonde. Hoe is dit nu gekomen?

00:06:26.000 --> 00:06:28.000
Als je aan neurowetenschappers vraagt waarom dit nu de stand van zaken is,

00:06:28.000 --> 00:06:31.000
zullen ze dat eerst toegeven. Maar als je het vraagt

00:06:31.000 --> 00:06:34.000
zeggen ze wel: “Er zijn verscheidene redenen waarom we geen goede hersentheorie hebben.”

00:06:34.000 --> 00:06:36.000
Sommigen zeggen dat we nog steeds niet genoeg data hebben.

00:06:36.000 --> 00:06:39.000
We hebben meer informatie nodig, er zijn nog zoveel dingen die we niet weten.

00:06:39.000 --> 00:06:42.000
Ik vertelde net dat er zoveel data is dat het je oren uitkomt.

00:06:42.000 --> 00:06:45.000
We hebben zo veel informatie, maar weten niet hoe we ze moeten organiseren.

00:06:45.000 --> 00:06:47.000
Waarom zouden we er nog meer nodig hebben?

00:06:47.000 --> 00:06:50.000
Misschien hebben we geluk en ontdekken we plots iets magisch, maar dat geloof ik niet.

00:06:50.000 --> 00:06:53.000
Dit is eigenlijk een symptoom van het feit dat we geen theorie hebben.

00:06:53.000 --> 00:06:56.000
We hebben niet nog meer data nodig, we hebben een goede theorie nodig.

00:06:56.000 --> 00:06:59.000
Mensen zeggen ook soms dat de hersenen zo complex zijn dat

00:06:59.000 --> 00:07:01.000
het nog eens 50 jaar zal duren.

00:07:01.000 --> 00:07:03.000
Ik denk zelfs dat Chris gisteren zoiets zei.

00:07:03.000 --> 00:07:05.000
Ik weet niet zeker wat je zei Chris, maar iets als:

00:07:05.000 --> 00:07:08.000
"Het is een van de meest gecompliceerde dingen in het universum." Dat is niet waar.

00:07:08.000 --> 00:07:10.000
Jij bent gecompliceerder dan je brein. Je hebt een brein.

00:07:10.000 --> 00:07:12.000
En hoewel het brein er heel gecompliceerd uitziet,

00:07:12.000 --> 00:07:15.000
lijken dingen enkel gecompliceerd tot je ze begrijpt.

00:07:15.000 --> 00:07:18.000
Dat is al altijd zo geweest. Al wat we kunnen zeggen is dat

00:07:18.000 --> 00:07:22.000
onze neocortex, het stuk van de hersenen waarin ik geïnteresseerd ben, 30 miljard cellen heeft.

00:07:22.000 --> 00:07:24.000
Maar weet je wat? Ze zijn eigenlijk heel gelijkmatig.

00:07:24.000 --> 00:07:27.000
Eigenlijk lijkt het alsof hetzelfde patroon zich steeds opnieuw herhaalt.

00:07:27.000 --> 00:07:30.000
Het is niet zo complex als het eruit ziet. Dat is niet het probleem.

00:07:30.000 --> 00:07:32.000
Sommigen zeggen, hersenen kunnen geen andere hersenen begrijpen.

00:07:32.000 --> 00:07:35.000
Heel Zen-achtig.

00:07:35.000 --> 00:07:36.000
(Gelach)

00:07:36.000 --> 00:07:39.000
Het klinkt goed, maar waarom? Maar wat is het punt?

00:07:39.000 --> 00:07:42.000
Het is slechts een hoopje cellen. Je begrijpt je lever.

00:07:42.000 --> 00:07:44.000
Die heeft ook een heleboel cellen.

00:07:44.000 --> 00:07:46.000
Dus ik geloof dat dit niet klopt.

00:07:46.000 --> 00:07:48.000
En uiteindelijk zijn er sommigen die zeggen:

00:07:48.000 --> 00:07:52.000
ik voel me niet als een hoopje cellen, ik ben bewust.

00:07:52.000 --> 00:07:54.000
Ik heb deze ervaring, ik sta in de wereld,

00:07:54.000 --> 00:07:56.000
ik kan niet alleen maar een hoopje cellen zijn.

00:07:56.000 --> 00:07:59.000
Mensen geloofden ooit dat er een levenskracht nodig was om te kunnen leven.

00:07:59.000 --> 00:08:01.000
We weten ondertussen dat dat helemaal niet waar is.

00:08:01.000 --> 00:08:04.000
Er is eigenlijk geen enkel bewijs, buiten het feit dat mensen

00:08:04.000 --> 00:08:06.000
gewoon niet geloven dat cellen kunnen doen wat ze doen.

00:08:06.000 --> 00:08:09.000
Zo zijn sommige mensen in de val van het metafysisch dualisme getrapt,

00:08:09.000 --> 00:08:12.000
ook hele slimme mensen, maar dat kunnen we allemaal negeren.

00:08:12.000 --> 00:08:14.000
(Gelach)

00:08:14.000 --> 00:08:17.000
Ik ga jullie vertellen dat er iets anders is,

00:08:17.000 --> 00:08:19.000
iets heel fundamenteels, namelijk dit:

00:08:19.000 --> 00:08:21.000
er is een andere reden waarom we geen goede hersentheorie hebben.

00:08:21.000 --> 00:08:24.000
Dat is omdat we een sterk intuïtieve,

00:08:24.000 --> 00:08:29.000
maar verkeerde aanname hebben, die ons ervan weerhoudt het antwoord te zien.

00:08:29.000 --> 00:08:32.000
We geloven dat iets gewoon vanzelfsprekend is, maar het is verkeerd.

00:08:32.000 --> 00:08:36.000
Dit heeft een geschiedenis in de wetenschap en vooraleer ik je vertel wat het is,

00:08:36.000 --> 00:08:38.000
ga ik een beetje vertellen over de geschiedenis ervan in de wetenschap.

00:08:38.000 --> 00:08:40.000
Als je kijkt naar wetenschappelijke revoluties,

00:08:40.000 --> 00:08:42.000
in dit geval heb ik het over het zonnestelsel, Copernicus,

00:08:42.000 --> 00:08:45.000
de evolutieleer van Darwin en de tektonische platen van Wegener.

00:08:45.000 --> 00:08:48.000
Ze hebben allemaal veel gemeen met neurowetenschap.

00:08:48.000 --> 00:08:51.000
Eerst hadden ze ook een hoop onverklaarde data. Een heleboel.

00:08:51.000 --> 00:08:54.000
Het werd echter meer werkbaar toen ze een theorie hadden.

00:08:54.000 --> 00:08:57.000
De slimste koppen stonden voor een raadsel, heel slimme mensen.

00:08:57.000 --> 00:08:59.000
We zijn nu niet slimmer dan zij toen waren.

00:08:59.000 --> 00:09:01.000
Het blijkt gewoon dat het heel moeilijk is om bepaalde dingen te bedenken,

00:09:01.000 --> 00:09:03.000
maar eenmaal bedacht, is het redelijk gemakkelijk om ze te begrijpen.

00:09:03.000 --> 00:09:05.000
Mijn dochters begrepen de basisprincipes

00:09:05.000 --> 00:09:08.000
van deze drie theorieën toen ze nog op de kleuterschool zaten.

00:09:08.000 --> 00:09:11.000
Het is niet zo moeilijk, hier is de appel, hier is de sinaasappel,

00:09:11.000 --> 00:09:14.000
de aarde draait rond, dat soort zaken.

00:09:14.000 --> 00:09:16.000
Het antwoord was er al de hele tijd, maar we

00:09:16.000 --> 00:09:19.000
negeerden het omwille van dat vanzelfsprekende idee en dat bedoel ik nu.

00:09:19.000 --> 00:09:22.000
Het was een intuïtief, vastgeroest geloof maar een verkeerd geloof.

00:09:22.000 --> 00:09:25.000
In het geval van het zonnestelsel bijvoorbeeld, het idee dat de aarde draait

00:09:25.000 --> 00:09:28.000
en het oppervlak van de aarde een snelheid haalt van 1600 km per uur,

00:09:28.000 --> 00:09:31.000
en dat de aarde zich met een snelheid van 1,6 miljoen km per uur door het zonnestelsel verplaatst.

00:09:31.000 --> 00:09:33.000
Dit is krankzinnig. We weten allemaal dat de aarde niet beweegt.

00:09:33.000 --> 00:09:35.000
Voelt het alsof je met 1600 km per uur beweegt?

00:09:35.000 --> 00:09:37.000
Natuurlijk niet. En iemand die beweerde

00:09:37.000 --> 00:09:39.000
dat we ronddraaien in deze enorme ruimte,

00:09:39.000 --> 00:09:41.000
hebben ze opgesloten.

00:09:41.000 --> 00:09:42.000
(Gelach)

00:09:42.000 --> 00:09:45.000
De oude aanname leek zo intuïtief en vanzelfsprekend. Wat met de evolutieleer?

00:09:45.000 --> 00:09:48.000
Evolutie is hetzelfde. We leerden onze kinderen dat, volgens de Bijbel,

00:09:48.000 --> 00:09:50.000
God al deze levensvormen creëerde, katten zijn katten, honden zijn honden,

00:09:50.000 --> 00:09:53.000
mensen zijn mensen, planten zijn planten, ze veranderen niet.

00:09:53.000 --> 00:09:57.000
Noah zette hen op de Ark in die volgorde, bla bla bla.

00:09:57.000 --> 00:10:01.000
Maar als je in evolutie gelooft, hebben we allemaal dezelfde voorouder

00:10:01.000 --> 00:10:04.000
en hebben we allemaal dezelfde afkomst als die plant in de lobby.

00:10:04.000 --> 00:10:07.000
Dit vertelt de evolutie ons. Ook weer een beetje moeilijk om te geloven.

00:10:07.000 --> 00:10:10.000
Hetzelfde met tektonische platen.

00:10:10.000 --> 00:10:12.000
Dat al die bergen en continenten zo maar wat ronddrijven

00:10:12.000 --> 00:10:16.000
op de aarde lijkt geen steek te houden.

00:10:16.000 --> 00:10:20.000
Wat is dan de intuïtieve, maar verkeerde aanname,

00:10:20.000 --> 00:10:22.000
die ons ervan weerhoudt hersenen te begrijpen?

00:10:22.000 --> 00:10:24.000
Wat ik jullie ga vertellen, gaat vanzelfsprekend juist lijken.

00:10:24.000 --> 00:10:26.000
En daar gaat het toch om, niet? Ik moet een argument vinden

00:10:26.000 --> 00:10:28.000
waarom je verkeerd zit met die andere aanname.

00:10:28.000 --> 00:10:31.000
Het intuïtieve, vanzelfsprekende is dat intelligentie

00:10:31.000 --> 00:10:33.000
bepaald lijkt te worden door gedrag,

00:10:33.000 --> 00:10:35.000
dat we intelligent zijn door de manier waarop we dingen doen

00:10:35.000 --> 00:10:38.000
en de manier waarop we ons intelligent gedragen. Ik ga jullie vertellen dat dat verkeerd is.

00:10:38.000 --> 00:10:40.000
Intelligentie wordt eigenlijk bepaald door voorspelling.

00:10:40.000 --> 00:10:43.000
Ik zal het jullie verduidelijken door een aantal dia's

00:10:43.000 --> 00:10:47.000
met voorbeelden. Hier heb je een systeem.

00:10:47.000 --> 00:10:50.000
Ingenieurs en wetenschappers kijken graag naar dergelijke systemen.

00:10:50.000 --> 00:10:53.000
Ze zeggen: “We hebben iets in een doos en er gaat wat in en er komt wat uit..”

00:10:53.000 --> 00:10:56.000
Volgens de mensen van kunstmatige intelligentie zat er in de doos een programmeerbare computer

00:10:56.000 --> 00:10:58.000
omdat dat gelijk is aan een brein. We geven het wat input

00:10:58.000 --> 00:11:00.000
en het zal iets doen, het zal gedrag vertonen.

00:11:00.000 --> 00:11:03.000
Alan Turing stelde de Turingtest op, die in principe zegt:

00:11:03.000 --> 00:11:06.000
“We weten of iets intelligent is als het zich identiek gedraagt als een mens.”

00:11:06.000 --> 00:11:09.000
Een gedragsmatige maatstaf van wat intelligentie is.

00:11:09.000 --> 00:11:12.000
Dit idee is lang meegegaan.

00:11:12.000 --> 00:11:14.000
Maar in werkelijkheid vind ik

00:11:14.000 --> 00:11:16.000
dat échte intelligentie gebaseerd is op iets anders.

00:11:16.000 --> 00:11:20.000
We ervaren de wereld door een opeenvolging van patronen. We slaan ze op

00:11:20.000 --> 00:11:23.000
en roepen ze opnieuw op. En wanneer we ze oproepen, toetsen we ze

00:11:23.000 --> 00:11:27.000
aan de werkelijkheid. We maken voortdurend voorspellingen.

00:11:27.000 --> 00:11:30.000
Het is een voortdurende controle die blijft nagaan

00:11:30.000 --> 00:11:33.000
of we de wereld begrijpen? Maak ik voorspellingen? Enzoverder.

00:11:33.000 --> 00:11:35.000
Jullie zijn nu allemaal intelligent bezig, maar jullie doen niets.

00:11:35.000 --> 00:11:37.000
Misschien krab je jezelf of zit je in je neus,

00:11:37.000 --> 00:11:39.000
ik weet het niet, maar je doet niets op dit moment,

00:11:39.000 --> 00:11:42.000
Maar je bent intelligent bezig want je begrijpt wat ik zeg.

00:11:42.000 --> 00:11:44.000
Omdat je intelligent bent en je Engels spreekt,

00:11:44.000 --> 00:11:45.000
weet je welk woord er komt op het einde van deze... (stilte)

00:11:45.000 --> 00:11:47.000
... zin.

00:11:47.000 --> 00:11:50.000
Dat woord bedacht je zelf, je maakt voortdurend dergelijke voorspellingen.

00:11:50.000 --> 00:11:52.000
Wat ik bedoel is

00:11:52.000 --> 00:11:54.000
dat de eeuwige voorspelling de output is van de neocortex.

00:11:54.000 --> 00:11:57.000
en dat, op een of andere manier, voorspelling leidt tot intelligent gedrag.

00:11:57.000 --> 00:12:00.000
Hoe gebeurt dit nu? Laten we van start gaan met een niet-intelligent brein.

00:12:00.000 --> 00:12:04.000
Ik zeg nadrukkelijk: een niet-intelligent brein, een oud brein.

00:12:04.000 --> 00:12:07.000
Laten we zeggen dat het geen zoogdier is, maar een reptiel,

00:12:07.000 --> 00:12:09.000
bijvoorbeeld een alligator.

00:12:09.000 --> 00:12:12.000
Deze alligator heeft zeer goed ontwikkelde zintuigen.

00:12:12.000 --> 00:12:15.000
Hij heeft goede ogen, oren, tastzintuigen,

00:12:15.000 --> 00:12:19.000
een mond en een neus. Hij vertoont complex gedrag.

00:12:19.000 --> 00:12:23.000
Hij kan lopen en zich verbergen. Hij heeft angsten en emoties. Hij kan je opeten,

00:12:23.000 --> 00:12:27.000
hij kan aanvallen. Hij kan allerlei dingen doen.

00:12:27.000 --> 00:12:32.000
Maar we beschouwen de alligator niet echt als intelligent, niet op de manier waarop mensen dat zijn.

00:12:32.000 --> 00:12:34.000
Toch vertoont hij complex gedrag.

00:12:34.000 --> 00:12:36.000
Wat gebeurde er in de evolutie?

00:12:36.000 --> 00:12:39.000
Het eerste wat zoogdieren in de evolutie ontwikkelden

00:12:39.000 --> 00:12:41.000
was de neocortex.

00:12:41.000 --> 00:12:43.000
Ik zal de neocortex hier afbeelden

00:12:43.000 --> 00:12:45.000
aan de hand van deze doos die bovenop het oude brein plakt.

00:12:45.000 --> 00:12:48.000
Neocortex betekent letterlijk 'nieuwe laag'. Een nieuwe laag bovenop je brein.

00:12:48.000 --> 00:12:51.000
Mocht je het niet kennen: het is dat gekreukeld ding boven in je hoofd.

00:12:51.000 --> 00:12:54.000
Het raakte gekreukeld omdat het erin werd geduwd. Het past er niet goed in.

00:12:54.000 --> 00:12:55.000
(Gelach)

00:12:55.000 --> 00:12:57.000
Nee, echt waar. Het heeft ongeveer de grootte van een servet.

00:12:57.000 --> 00:13:00.000
Het paste niet, dus het raakte helemaal verkreukeld. Kijk hoe ik dit getekend heb.

00:13:00.000 --> 00:13:04.000
Het oude brein is er nog. Je hebt nog steeds dat alligatorbrein.

00:13:04.000 --> 00:13:06.000
Dat is je emotionele brein.

00:13:06.000 --> 00:13:09.000
Het zijn al die dingen en alle instinctieve reacties die je hebt.

00:13:09.000 --> 00:13:12.000
Daarboven hebben we het geheugensysteem dat de neocortex heet.

00:13:12.000 --> 00:13:16.000
Het geheugensysteem zit over het zintuiglijke deel van het brein.

00:13:16.000 --> 00:13:19.000
Als de zintuiglijke input binnenkomt via het oude brein

00:13:19.000 --> 00:13:23.000
gaat hij ook omhoog naar de neocortex. De neocortex registreert gewoon

00:13:23.000 --> 00:13:27.000
en onthoudt alle gebeurtenissen.

00:13:27.000 --> 00:13:29.000
Waar ik geweest ben, de mensen die ik gezien heb, dingen die ik hoorde, enz.

00:13:29.000 --> 00:13:33.000
In de toekomst, wanneer hij nog eens iets gelijkaardigs ziet

00:13:33.000 --> 00:13:36.000
in een gelijkaardige of in dezelfde omgeving,

00:13:36.000 --> 00:13:38.000
zal hij het opnieuw afspelen.

00:13:38.000 --> 00:13:40.000
O, ik ben hier al eens geweest. Toen ik hier was,

00:13:40.000 --> 00:13:43.000
gebeurde dit. Het laat je toe de toekomst te voorspellen.

00:13:43.000 --> 00:13:47.000
Hij stuurt letterlijk signalen, die je laten zien wat er straks

00:13:47.000 --> 00:13:49.000
gaat gebeuren, terug naar je brein.

00:13:49.000 --> 00:13:52.000
Je hoort het woord 'zin' nog voor ik het uitspreek.

00:13:52.000 --> 00:13:55.000
Het is dit terugkoppelen naar het oude brein

00:13:55.000 --> 00:13:58.000
dat je toelaat meer intelligente beslissingen te nemen.

00:13:58.000 --> 00:14:01.000
Dit is de belangrijkste dia van mijn lezing, ik blijf er even bij stilstaan.

00:14:01.000 --> 00:14:05.000
Telkens opnieuw merk je dat je dingen kan voorspellen.

00:14:05.000 --> 00:14:08.000
Als je een rat bent en je gaat door een doolhof, dan leer je de doolhof.

00:14:08.000 --> 00:14:10.000
De volgende keer wanneer je in de doolhof bent, gedraag je je hetzelfde

00:14:10.000 --> 00:14:12.000
maar plots ben je nu slimmer

00:14:12.000 --> 00:14:15.000
omdat je merkt dat je deze doolhof herkent en weet welke kant je uit moet.

00:14:15.000 --> 00:14:18.000
Je bent hier al geweest, je ziet de toekomst voor je. Dat is wat het doet.

00:14:18.000 --> 00:14:21.000
Bij mensen, trouwens dit geldt voor alle zoogdieren,

00:14:21.000 --> 00:14:23.000
maar bij mensen ging het nog veel verder.

00:14:23.000 --> 00:14:26.000
Bij mensen ontwikkelden we zelfs het voorste stuk van de neocortex

00:14:26.000 --> 00:14:30.000
het anterieure deel van de neocortex. De natuur gebruikte hier een trucje:

00:14:30.000 --> 00:14:32.000
zij kopieerde het posterieure deel, het achterste deel, het zintuiglijke,

00:14:32.000 --> 00:14:34.000
en stopte het in het voorste deel.

00:14:34.000 --> 00:14:36.000
Enkel bij mensen hebben we hetzelfde mechanisme vooraan.

00:14:36.000 --> 00:14:38.000
We gebruiken het voor motorische controle.

00:14:38.000 --> 00:14:41.000
Dus we kunnen nu een heel verfijnde motorische planning maken, dat soort dingen.

00:14:41.000 --> 00:14:44.000
Ik heb geen tijd om hier dieper op in te gaan, maar als je wilt weten hoe de hersenen werken,

00:14:44.000 --> 00:14:47.000
moet je begrijpen hoe het eerste deel van de neocortex van zoogdieren werkt,

00:14:47.000 --> 00:14:49.000
hoe we patronen opslaan en voorspellingen maken.

00:14:49.000 --> 00:14:52.000
Laat me jullie een paar voorbeelden geven van voorspellingen.

00:14:52.000 --> 00:14:54.000
Ik zei bijvoorbeeld al het woord 'zin'. Op muzikaal vlak:

00:14:54.000 --> 00:14:57.000
als je een lied al eens hebt gehoord, als je Jill die liedjes al hebt horen zingen,

00:14:57.000 --> 00:15:00.000
schieten de volgende noten je al te binnen wanneer ze zingt.

00:15:00.000 --> 00:15:02.000
Je anticipeert op wat volgt. Als je een volledig album beluistert,

00:15:02.000 --> 00:15:05.000
zal bij het einde van een lied, het volgende lied je al te binnen schieten.

00:15:05.000 --> 00:15:07.000
Deze dingen gebeuren constant. Je maakt voorspellingen.

00:15:07.000 --> 00:15:10.000
Ik heb een experiment het 'gewijzigde-deur-gedachte-experiment' genoemd.

00:15:10.000 --> 00:15:13.000
In dit experiment gaan we ervan uit dat je thuis een deur hebt.

00:15:13.000 --> 00:15:16.000
Terwijl je hier bent, verander ik de deur. Ik heb een mannetje

00:15:16.000 --> 00:15:18.000
dat nu bij jou thuis die deur aan het bewerken is.

00:15:18.000 --> 00:15:20.000
Hij gaat je deurknop vijf centimeter verplaatsen.

00:15:20.000 --> 00:15:22.000
Als je vanavond naar huis gaat, ga je je hand uitsteken,

00:15:22.000 --> 00:15:24.000
naar de deurknop reiken en merken

00:15:24.000 --> 00:15:27.000
dat die op de verkeerde plaats zit. Je merkt dat er iets is veranderd.

00:15:27.000 --> 00:15:29.000
Het duurt misschien even voor je het beseft, maar er is iets veranderd.

00:15:29.000 --> 00:15:31.000
Ik kan je deurknop op verschillende manieren veranderen.

00:15:31.000 --> 00:15:33.000
Ik kan hem groter of kleiner maken, het koper in zilver veranderen,

00:15:33.000 --> 00:15:35.000
hem in een hendel veranderen. Ik kan je deur veranderen, ze schilderen.

00:15:35.000 --> 00:15:38.000
Ik kan er ramen in plaatsen. Ik kan duizend dingen aan je deur veranderen

00:15:38.000 --> 00:15:40.000
en in de twee seconden die je nodig hebt om je deur te openen,

00:15:40.000 --> 00:15:43.000
zal je merken dat er iets veranderd is.

00:15:43.000 --> 00:15:45.000
Een ingenieur of kunstmatige intelligentie zou hiervoor

00:15:45.000 --> 00:15:48.000
een database bouwen die alle deurattributen bevat.

00:15:48.000 --> 00:15:51.000
Wanneer je de deur benadert, ga je ze allemaal aflopen.

00:15:51.000 --> 00:15:53.000
Deur, deur, deur, je weet wel, kleur, je weet wat ik bedoel.

00:15:53.000 --> 00:15:55.000
Wij doen dit niet. Je brein doet dat niet.

00:15:55.000 --> 00:15:57.000
Je brein maakt constante voorspellingen

00:15:57.000 --> 00:15:59.000
over wat er gaat gebeuren in je omgeving.

00:15:59.000 --> 00:16:02.000
Als ik mijn hand op deze tafel leg, verwacht ik te voelen waar ze eindigt.

00:16:02.000 --> 00:16:05.000
Als ik rondloop en de tafel op een haar na zou missen,

00:16:05.000 --> 00:16:07.000
zal ik weten dat er iets veranderd is.

00:16:07.000 --> 00:16:09.000
Je maakt voortdurend voorspellingen over je omgeving.

00:16:09.000 --> 00:16:12.000
Ik zal het kort hebben over zien. Dit is een plaatje van een vrouw.

00:16:12.000 --> 00:16:14.000
Wanneer je mensen aankijkt, bewegen je ogen

00:16:14.000 --> 00:16:15.000
ongeveer 2 à 3 keer per seconde over en weer.

00:16:15.000 --> 00:16:17.000
Je doet dit onbewust, je ogen zijn constant in beweging.

00:16:17.000 --> 00:16:19.000
Wanneer je naar iemand zijn gezicht kijkt,

00:16:19.000 --> 00:16:21.000
ga je normaal van oog naar oog naar oog naar neus naar mond.

00:16:21.000 --> 00:16:23.000
Wanneer je beweegt van oog naar oog,

00:16:23.000 --> 00:16:25.000
en er zou daar iets anders staan, bijvoorbeeld een neus,

00:16:25.000 --> 00:16:27.000
zou je een neus zien op de plaats van het oog.

00:16:27.000 --> 00:16:30.000
Je zou denken: "Oh shit."

00:16:30.000 --> 00:16:31.000
(Gelach)

00:16:31.000 --> 00:16:33.000
“Er is iets mis met deze persoon.”

00:16:33.000 --> 00:16:35.000
Dat is omdat je een voorspelling maakt.

00:16:35.000 --> 00:16:37.000
Het is niet alsof je er gewoon naar kijkt en zegt: “Wat zie ik nu?

00:16:37.000 --> 00:16:40.000
Een neus, oké.” Nee, je hebt een verwachting van wat je gaat zien.

00:16:40.000 --> 00:16:41.000
(Gelach)

00:16:41.000 --> 00:16:45.000
Ten laatste, laten we eens denken over hoe we intelligentie testen.

00:16:45.000 --> 00:16:48.000
We testen het volgens voorspelling. Wat is het volgende woord in deze …

00:16:48.000 --> 00:16:51.000
Dit verhoudt zich tot dit zoals dit zich verhoudt tot dat. Wat is het volgende nummer in deze rij?

00:16:51.000 --> 00:16:53.000
Hier zijn drie beelden van een object.

00:16:53.000 --> 00:16:57.000
Welke is het vierde? Zo testen we dat. Het draait allemaal rond voorspellingen.

00:16:57.000 --> 00:17:00.000
Dus wat is het recept voor een hersentheorie?

00:17:00.000 --> 00:17:03.000
Ten eerste: we moeten het juiste kader hebben.

00:17:03.000 --> 00:17:05.000
Dat kader is een geheugenkader,

00:17:05.000 --> 00:17:07.000
geen berekenings- of een gedragskader. Een geheugenkader.

00:17:07.000 --> 00:17:11.000
Hoe sla je al deze reeksen en patronen op? Het zijn tijdelijke ruimtelijke patronen.

00:17:11.000 --> 00:17:14.000
Vertrekkend vanuit dat kader, zoek je een paar theoretici.

00:17:14.000 --> 00:17:16.000
Over het algemeen zijn biologen geen goede theoretici.

00:17:16.000 --> 00:17:20.000
Het is niet altijd zo, maar over het algemeen is er geen goede geschiedenis van theorie in biologie.

00:17:20.000 --> 00:17:23.000
Voor mij zijn de beste mensen om mee te werken de natuurkundigen,

00:17:23.000 --> 00:17:26.000
ingenieurs en wiskundigen, die meestal algoritmisch denken.

00:17:26.000 --> 00:17:29.000
Dan moeten zij de anatomie leren en ook de fysiologie.

00:17:29.000 --> 00:17:33.000
Je moet deze theorieën realistisch maken in anatomische termen.

00:17:33.000 --> 00:17:37.000
Iemand die je zijn theorie vertelt over hoe het brein werkt

00:17:37.000 --> 00:17:39.000
en je niet exact vertelt hoe het werkt in het brein

00:17:39.000 --> 00:17:41.000
en hoe de connecties werken in de hersenen, heeft geen theorie.

00:17:41.000 --> 00:17:44.000
Dat doen we aan het Redwood Instituut voor Neurowetenschap.

00:17:44.000 --> 00:17:48.000
Ik had graag meer tijd gehad, we boeken fantastische vooruitgang

00:17:48.000 --> 00:17:50.000
en ik verwacht mezelf in de nabije toekomst

00:17:50.000 --> 00:17:52.000
terug op dit podium om jullie erover te vertellen.

00:17:52.000 --> 00:17:55.000
Ik zie het volledig zitten. Dit gaat geen 50 jaar duren.

00:17:55.000 --> 00:17:57.000
Hoe gaat de hersentheorie eruit zien?

00:17:57.000 --> 00:17:59.000
Eerst en vooral zal het een geheugentheorie zijn.

00:17:59.000 --> 00:18:02.000
Niet zoals computergeheugen. Helemaal niet zoals computergeheugen.

00:18:02.000 --> 00:18:04.000
Het is helemaal anders. Het is een geheugen van

00:18:04.000 --> 00:18:07.000
hoog-dimensionale patronen, vergelijkbaar met hetgeen je ogen produceren.

00:18:07.000 --> 00:18:09.000
Het is ook een geheugen van sequenties.

00:18:09.000 --> 00:18:11.000
Je kunt niets leren of onthouden buiten een sequentie.

00:18:11.000 --> 00:18:14.000
Een liedje moet gehoord worden in een volgorde van tijd,

00:18:14.000 --> 00:18:17.000
en je moet het terug afspelen in volgorde van tijd.

00:18:17.000 --> 00:18:20.000
En deze volgorde wordt auto-associatief opgeroepen, ik zie en hoor iets

00:18:20.000 --> 00:18:23.000
dat mij eraan doet denken en ze wordt automatisch terug afgespeeld.

00:18:23.000 --> 00:18:27.000
Het is een automatische playback. En voorspelling van toekomstige inputs is de gewenste output.

00:18:27.000 --> 00:18:30.000
Zoals ik zei moet de theorie biologisch accuraat zijn,

00:18:30.000 --> 00:18:32.000
ze moet toetsbaar zijn en je moet ze kunnen opbouwen.

00:18:32.000 --> 00:18:36.000
Als je ze niet opbouwt, begrijp je haar niet. Nog een dia.

00:18:36.000 --> 00:18:40.000
Wat zal het resultaat zijn? Gaan we intelligente machines maken?

00:18:40.000 --> 00:18:44.000
Absoluut. En het zal anders zijn dan de mensen zich voorstellen.

00:18:44.000 --> 00:18:47.000
Voor mij is er geen twijfel mogelijk dat het zal gebeuren.

00:18:47.000 --> 00:18:51.000
Eerst en vooral bouwen we ze op en zullen we dingen maken van silicium.

00:18:51.000 --> 00:18:54.000
We kunnen hier dezelfde technieken gebruiken

00:18:54.000 --> 00:18:55.000
zoals bij het bouwen van computergeheugens van silicium.

00:18:55.000 --> 00:18:57.000
Maar het zijn zeer verschillende geheugentypes.

00:18:57.000 --> 00:18:59.000
We zullen deze geheugens aan sensoren koppelen,

00:18:59.000 --> 00:19:02.000
al de sensoren zullen real-live data ontvangen,

00:19:02.000 --> 00:19:04.000
en deze dingen zullen leren over hun omgeving.

00:19:04.000 --> 00:19:07.000
Het is zeer onwaarschijnlijk dat robots de eerste dingen zullen zijn die je zult zien.

00:19:07.000 --> 00:19:10.000
Robots zijn nuttig en mensen kunnen ze maken.

00:19:10.000 --> 00:19:14.000
Maar het robotgedeelte is het moeilijkste stuk. Dat is het oude brein. Behoorlijk moeilijk.

00:19:14.000 --> 00:19:16.000
Het nieuwe brein is eigenlijk gemakkelijker dan het oude brein.

00:19:16.000 --> 00:19:19.000
De eerste dingen die we gaan doen, zijn dingen die niet veel robotica nodig hebben.

00:19:19.000 --> 00:19:21.000
Je gaat geen C-3PO zien.

00:19:21.000 --> 00:19:23.000
Je gaat eerder dingen als intelligente auto's zien

00:19:23.000 --> 00:19:26.000
die echt begrijpen wat verkeer is en hoe je moet rijden.

00:19:26.000 --> 00:19:29.000
Die geleerd hebben dat auto’s die langer dan een halve minuut met knipperlichten aan rijden,

00:19:29.000 --> 00:19:31.000
waarschijnlijk niet gaan afslaan, dat soort dingen.

00:19:31.000 --> 00:19:32.000
(Gelach)

00:19:32.000 --> 00:19:34.000
We kunnen ook intelligente beveiligingssystemen maken.

00:19:34.000 --> 00:19:38.000
Overal waar we onze hersenen gebruiken, maar eigenlijk niet veel mechanisch doen.

00:19:38.000 --> 00:19:40.000
Dat gaat eerst gebeuren.

00:19:40.000 --> 00:19:42.000
Maar uiteindelijk zit er geen limiet op.

00:19:42.000 --> 00:19:44.000
Ik weet niet hoe dit zal verlopen.

00:19:44.000 --> 00:19:46.000
Ik ken een aantal mensen die de microprocessor uitvonden.

00:19:46.000 --> 00:19:51.000
Ze wisten dat ze aan iets heel belangrijk werkten,

00:19:51.000 --> 00:19:54.000
maar ze wisten ook niet wat er ging gebeuren.

00:19:54.000 --> 00:19:59.000
Ze konden niet anticiperen op mobiele telefoons en het internet.

00:19:59.000 --> 00:20:01.000
Ze wisten gewoon dat ze rekenmachines gingen maken

00:20:01.000 --> 00:20:03.000
en verkeerslichtsystemen. Maar het zal groots worden.

00:20:03.000 --> 00:20:06.000
Op dezelfde manier is dit zoals neurowetenschap en deze geheugens

00:20:06.000 --> 00:20:09.000
gaan zeer fundamentele technologie worden. Het zal leiden

00:20:09.000 --> 00:20:12.000
tot ongelofelijke veranderingen in de volgende 100 jaar.

00:20:12.000 --> 00:20:16.000
Ik ben zeer benieuwd hoe we ze gaan gebruiken in wetenschap.

00:20:16.000 --> 00:20:19.000
Ik geloof dat mijn tijd er op zit, ik zit er eigenlijk al over.

00:20:19.000 --> 00:20:20.000
Daarmee eindigt dan mijn lezing.

