WEBVTT
Kind: captions
Language: en

00:00:25.095 --> 00:00:26.874
I'm really excited to be here today.

00:00:26.898 --> 00:00:30.000
I'll show you some stuff
that's just ready to come out of the lab,

00:00:30.024 --> 00:00:32.800
literally, and I'm really glad
that you guys

00:00:32.824 --> 00:00:35.296
are going to be among
the first to see it in person,

00:00:35.320 --> 00:00:37.809
because I really think this is going
to really change

00:00:37.833 --> 00:00:40.315
the way we interact
with machines from this point on.

00:00:40.339 --> 00:00:43.014
Now, this is a rear-projected
drafting table.

00:00:43.038 --> 00:00:44.260
It's about 36 inches wide

00:00:44.284 --> 00:00:46.367
and it's equipped
with a multi-touch sensor.

00:00:46.391 --> 00:00:48.035
Normal touch sensors that you see,

00:00:48.059 --> 00:00:50.196
like on a kiosk
or interactive whiteboards,

00:00:50.220 --> 00:00:52.803
can only register one point
of contact at a time.

00:00:53.137 --> 00:00:56.852
This thing allows you to have
multiple points at the same time.

00:00:56.876 --> 00:01:00.190
They can use both my hands;
I can use chording actions;

00:01:00.214 --> 00:01:03.151
I can just go right up and use
all 10 fingers if I wanted to.

00:01:03.597 --> 00:01:04.754
You know, like that.

00:01:04.778 --> 00:01:09.321
Now, multi-touch sensing
isn't completely new.

00:01:09.345 --> 00:01:12.598
People like Bill Buxton have been
playing around with it in the '80s.

00:01:12.622 --> 00:01:16.650
However, the approach I built here
is actually high-resolution,

00:01:16.674 --> 00:01:19.650
low-cost, and probably
most importantly, very scalable.

00:01:20.000 --> 00:01:22.337
So, the technology, you know,

00:01:22.361 --> 00:01:24.807
isn't the most exciting thing
here right now,

00:01:24.831 --> 00:01:27.149
other than probably
its newfound accessibility.

00:01:27.173 --> 00:01:30.698
What's really interesting here
is what you can do with it

00:01:30.722 --> 00:01:33.340
and the kind of interfaces
you can build on top of it.

00:01:34.141 --> 00:01:35.277
So let's see.

00:01:36.111 --> 00:01:40.424
So, for instance, we have
a lava lamp application here.

00:01:40.448 --> 00:01:42.150
Now, you can see,

00:01:42.174 --> 00:01:45.603
I can use both of my hands to kind
of squeeze and put the blobs together.

00:01:45.627 --> 00:01:48.170
I can inject heat into the system here,

00:01:48.194 --> 00:01:50.376
or I can pull it apart
with two of my fingers.

00:01:50.400 --> 00:01:53.130
It's completely intuitive;
there's no instruction manual.

00:01:53.154 --> 00:01:54.976
The interface just kind of disappears.

00:01:55.000 --> 00:01:56.920
This started out as a screensaver app

00:01:56.944 --> 00:01:59.991
that one of the Ph.D. students
in our lab, Ilya Rosenberg, made.

00:02:00.015 --> 00:02:04.036
But I think its true identity
comes out here.

00:02:05.153 --> 00:02:08.076
Now what's great about a multi-touch
sensor is that, you know,

00:02:08.100 --> 00:02:10.837
I could be doing this
with as many fingers here,

00:02:10.861 --> 00:02:13.839
but of course multi-touch
also inherently means multi-user.

00:02:13.863 --> 00:02:16.362
Chris could be interacting
with another part of Lava,

00:02:16.386 --> 00:02:18.020
while I play around with it here.

00:02:18.044 --> 00:02:20.140
You can imagine
a new kind of sculpting tool,

00:02:20.164 --> 00:02:23.143
where I'm kind of warming something up,
making it malleable,

00:02:23.167 --> 00:02:26.425
and then letting it cool down
and solidifying in a certain state.

00:02:30.712 --> 00:02:33.659
Google should have
something like this in their lobby.

00:02:33.683 --> 00:02:38.976
(Laughter)

00:02:39.000 --> 00:02:42.272
I'll show you a little more
of a concrete example here,

00:02:42.296 --> 00:02:43.629
as this thing loads.

00:02:44.181 --> 00:02:46.898
This is a photographer's
light-box application.

00:02:46.922 --> 00:02:50.899
Again, I can use both of my hands
to interact and move photos around.

00:02:50.923 --> 00:02:54.478
But what's even cooler
is that if I have two fingers,

00:02:54.502 --> 00:02:58.632
I can actually grab a photo and then
stretch it out like that really easily.

00:02:58.656 --> 00:03:02.122
I can pan, zoom
and rotate it effortlessly.

00:03:02.146 --> 00:03:04.477
I can do that grossly
with both of my hands,

00:03:04.501 --> 00:03:07.705
or I can do it just with two fingers
on each of my hands together.

00:03:07.729 --> 00:03:10.756
If I grab the canvas, I can do
the same thing -- stretch it out.

00:03:10.780 --> 00:03:12.939
I can do it simultaneously,
holding this down,

00:03:12.963 --> 00:03:15.262
and gripping on another one,
stretching this out.

00:03:15.286 --> 00:03:17.514
Again, the interface just disappears here.

00:03:17.538 --> 00:03:18.571
There's no manual.

00:03:18.595 --> 00:03:20.897
This is exactly what you expect,

00:03:20.921 --> 00:03:23.976
especially if you haven't interacted
with a computer before.

00:03:24.000 --> 00:03:26.704
Now, when you have initiatives
like the $100 laptop,

00:03:26.728 --> 00:03:28.261
I kind of cringe at the idea

00:03:28.285 --> 00:03:30.862
of introducing a whole new
generation to computing

00:03:30.886 --> 00:03:33.624
with this standard
mouse-and-windows-pointer interface.

00:03:33.648 --> 00:03:36.784
This is something that I think
is really the way

00:03:36.808 --> 00:03:39.449
we should be interacting
with machines from now on.

00:03:39.473 --> 00:03:45.976
(Applause)

00:03:46.000 --> 00:03:48.000
Now, of course, I can bring up a keyboard.

00:03:48.024 --> 00:03:50.322
(Laughter)

00:03:53.000 --> 00:03:55.745
And I can bring that around,
put that up there.

00:03:56.213 --> 00:03:58.071
Obviously, this is a standard keyboard,

00:03:58.095 --> 00:04:01.177
but of course I can rescale it
to make it work well for my hands.

00:04:01.201 --> 00:04:04.534
That's really important, because
there's no reason in this day and age

00:04:04.558 --> 00:04:06.898
that we should be conforming
to a physical device.

00:04:06.922 --> 00:04:08.669
That leads to bad things, like RSI.

00:04:08.693 --> 00:04:11.470
We have so much technology nowadays

00:04:11.494 --> 00:04:15.523
that these interfaces
should start conforming to us.

00:04:15.547 --> 00:04:19.524
There's so little applied now
to actually improving

00:04:19.548 --> 00:04:22.127
the way we interact with interfaces
from this point on.

00:04:22.151 --> 00:04:25.342
This keyboard is probably actually
the really wrong direction to go.

00:04:25.366 --> 00:04:28.668
You can imagine, in the future,
as we develop this kind of technology,

00:04:28.692 --> 00:04:32.095
a keyboard that kind of automatically
drifts as your hand moves away,

00:04:32.119 --> 00:04:35.634
and really intelligently anticipates
which key you're trying to stroke.

00:04:36.477 --> 00:04:38.770
So -- again, isn't this great?

00:04:40.051 --> 00:04:42.023
(Laughter)

00:04:42.047 --> 00:04:43.810
Audience: Where's your lab?

00:04:43.834 --> 00:04:46.406
Jeff Han: I'm a research scientist
at NYU in New York.

00:04:50.341 --> 00:04:53.976
Here's an example of another kind of app.
I can make these little fuzz balls.

00:04:54.000 --> 00:04:56.334
It'll remember the strokes I'm making.

00:04:56.358 --> 00:04:58.277
Of course I can do it with all my hands.

00:04:58.301 --> 00:04:59.592
It's pressure-sensitive.

00:05:00.905 --> 00:05:02.461
What's neat about that is,

00:05:02.485 --> 00:05:05.450
I showed that two-finger gesture
that zooms in really quickly.

00:05:05.474 --> 00:05:07.681
Because you don't have
to switch to a hand tool

00:05:07.705 --> 00:05:09.111
or the magnifying glass tool,

00:05:09.135 --> 00:05:11.674
you can just continuously make things

00:05:11.698 --> 00:05:14.052
in real multiple scales,
all at the same time.

00:05:14.076 --> 00:05:16.089
I can create big things out here,

00:05:16.113 --> 00:05:18.211
but I can go back
and really quickly go back

00:05:18.235 --> 00:05:20.935
to where I started,
and make even smaller things here.

00:05:22.271 --> 00:05:24.158
This is going to be really important

00:05:24.182 --> 00:05:27.215
as we start getting to things
like data visualization.

00:05:27.239 --> 00:05:29.906
For instance, I think
we all enjoyed Hans Rosling's talk,

00:05:29.930 --> 00:05:33.456
and he really emphasized the fact
I've been thinking about for a long time:

00:05:33.480 --> 00:05:34.831
We have all this great data,

00:05:34.855 --> 00:05:36.952
but for some reason,
it's just sitting there.

00:05:36.976 --> 00:05:38.095
We're not accessing it.

00:05:38.119 --> 00:05:41.642
And one of the reasons why I think that is

00:05:41.666 --> 00:05:46.382
will be helped by things like graphics
and visualization and inference tools,

00:05:46.406 --> 00:05:48.267
but I also think a big part of it

00:05:48.291 --> 00:05:50.347
is going to be having better interfaces,

00:05:50.371 --> 00:05:52.611
to be able to drill down
into this kind of data,

00:05:52.635 --> 00:05:54.973
while still thinking
about the big picture here.

00:05:55.460 --> 00:05:58.439
Let me show you another app here.
This is called WorldWind.

00:05:58.463 --> 00:05:59.602
It's done by NASA.

00:05:59.626 --> 00:06:02.456
We've all seen Google Earth;

00:06:02.480 --> 00:06:04.438
this is an open-source version of that.

00:06:04.462 --> 00:06:07.986
There are plug-ins to be able
to load in different data sets

00:06:08.010 --> 00:06:09.809
that NASA's collected over the years.

00:06:09.833 --> 00:06:12.453
As you can see, I can use
the same two-fingered gestures

00:06:12.477 --> 00:06:14.959
to go down and go in really seamlessly.

00:06:14.983 --> 00:06:16.363
There's no interface, again.

00:06:16.387 --> 00:06:19.658
It really allows anybody
to kind of go in --

00:06:19.682 --> 00:06:22.645
and it just does
what you'd expect, you know?

00:06:22.669 --> 00:06:25.941
Again, there's just no interface here.
The interface just disappears.

00:06:28.000 --> 00:06:29.876
I can switch to different data views.

00:06:29.900 --> 00:06:32.094
That's what's neat about this app here.

00:06:32.118 --> 00:06:33.275
NASA's really cool.

00:06:33.299 --> 00:06:36.061
These hyper-spectral images
are false-colored so you can --

00:06:36.085 --> 00:06:40.028
it's really good for determining
vegetative use.

00:06:40.887 --> 00:06:42.473
Well, let's go back to this.

00:06:45.312 --> 00:06:47.486
The great thing
about mapping applications --

00:06:47.510 --> 00:06:49.000
it's not really 2D, it's 3D.

00:06:49.024 --> 00:06:52.516
So, again, with a multi-point interface,
you can do a gesture like this --

00:06:52.540 --> 00:06:55.977
so you can be able
to tilt around like that --

00:06:56.001 --> 00:06:57.875
(Surprised laughter)

00:06:57.899 --> 00:07:01.081
It's not just simply relegated
to a kind of 2D panning and motion.

00:07:01.105 --> 00:07:03.740
This gesture is just putting
two fingers down --

00:07:03.764 --> 00:07:07.417
it's defining an axis of tilt --
and I can tilt up and down that way.

00:07:07.441 --> 00:07:09.519
We just came up with that on the spot,

00:07:09.543 --> 00:07:11.480
it's probably not the right thing to do,

00:07:11.504 --> 00:07:14.733
but there's such interesting things
you can do with this interface.

00:07:16.000 --> 00:07:18.934
It's just so much fun
playing around with it, too.

00:07:18.958 --> 00:07:20.311
(Laughter)

00:07:20.335 --> 00:07:22.976
And so the last thing
I want to show you is --

00:07:23.000 --> 00:07:25.677
I'm sure we can all think
of a lot of entertainment apps

00:07:25.701 --> 00:07:27.225
that you can do with this thing.

00:07:27.249 --> 00:07:31.299
I'm more interested in the creative
applications we can do with this.

00:07:31.323 --> 00:07:34.560
Now, here's a simple application here --
I can draw out a curve.

00:07:36.201 --> 00:07:39.467
And when I close it,
it becomes a character.

00:07:39.785 --> 00:07:42.762
But the neat thing about it
is I can add control points.

00:07:42.786 --> 00:07:46.763
And then what I can do is manipulate them
with both of my fingers at the same time.

00:07:46.787 --> 00:07:48.690
And you notice what it does.

00:07:49.253 --> 00:07:51.808
It's kind of a puppeteering thing,

00:07:51.832 --> 00:07:57.050
where I can use as many fingers
as I have to draw and make --

00:08:03.274 --> 00:08:05.976
Now, there's a lot of actual math
going on under here

00:08:06.000 --> 00:08:10.442
for this to control this mesh
and do the right thing.

00:08:11.183 --> 00:08:16.875
This technique of being able to manipulate
a mesh here, with multiple control points,

00:08:16.899 --> 00:08:18.375
is actually state of the art.

00:08:18.399 --> 00:08:20.223
It was released at SIGGRAPH last year.

00:08:20.247 --> 00:08:23.017
It's a great example
of the kind of research I really love:

00:08:23.041 --> 00:08:25.840
all this compute power
to make things do the right things,

00:08:25.864 --> 00:08:28.585
intuitive things,
to do exactly what you expect.

00:08:32.000 --> 00:08:36.658
So, multi-touch interaction research
is a very active field right now in HCI.

00:08:37.000 --> 00:08:40.476
I'm not the only one doing it,
a lot of other people are getting into it.

00:08:40.500 --> 00:08:43.745
This kind of technology is going to let
even more people get into it,

00:08:43.769 --> 00:08:47.261
I'm looking forward to interacting
with all of you over the next few days

00:08:47.285 --> 00:08:49.822
and seeing how it can apply
to your respective fields.

00:08:49.846 --> 00:08:51.004
Thank you.

00:08:51.028 --> 00:08:53.597
(Applause)

