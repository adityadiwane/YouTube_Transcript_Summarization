WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Maximiliano Díaz
Revisor: Diego Leal

00:00:25.000 --> 00:00:27.000
Estoy muy, muy emocionado de estar aquí hoy,

00:00:27.000 --> 00:00:30.000
porque les mostrare algo que está, literalmente, listo para salir del

00:00:30.000 --> 00:00:34.000
laboratorio, y estoy realmente contento que ustedes estén entre los primeros en

00:00:34.000 --> 00:00:36.000
verlo en persona, porque honestamente creo que esto cambiará

00:00:36.000 --> 00:00:40.000
-- realmente cambiará -- la manera en la que interactuamos con las máquinas de ahora en adelante.

00:00:40.000 --> 00:00:44.000
Ahora, éste es una mesa de dibujo de proyección trasera. Mide aproximadamente 36 pulgadas de ancho,

00:00:44.000 --> 00:00:47.000
y está equipada con un sensor multi-táctil. Los sensores táctiles normales que

00:00:47.000 --> 00:00:50.000
pueden ver, en un kiosco o en pizarras interactivas,

00:00:50.000 --> 00:00:53.000
sólo pueden registrar un punto de contacto a la vez.

00:00:53.000 --> 00:00:56.000
Esta mesa les permite tener múltiples puntos al mismo tiempo.

00:00:56.000 --> 00:01:00.000
Puede usar mis dos manos, puedo ejecutar acciones coordinadas,

00:01:00.000 --> 00:01:03.000
y puedo seguir aumentando y usar los 10 dedos si quisiera.

00:01:03.000 --> 00:01:05.000
Así, de este modo.

00:01:05.000 --> 00:01:09.000
Ahora, la sensibilidad multi-táctil no es completamente nueva.

00:01:09.000 --> 00:01:12.000
Personas como Bill Buxton han estado jugando con esto desde los 80's.

00:01:12.000 --> 00:01:17.000
Sin embargo, el enfoque que he construido es de alta resolución,

00:01:17.000 --> 00:01:20.000
bajo costo, y probablemente lo más importante, muy escalable.

00:01:20.000 --> 00:01:24.000
Entonces, la tecnología, sabrán, no es lo más emocionante de esto,

00:01:24.000 --> 00:01:27.000
exceptuando probablemente su renovada accesibilidad.

00:01:27.000 --> 00:01:31.000
Lo que es realmente interesante es lo que pueden hacer con esto,

00:01:31.000 --> 00:01:36.000
y los tipos de interfaces que se pueden construir sobre ella. Entonces, veamos.

00:01:36.000 --> 00:01:42.000
Por ejemplo, tenemos una aplicación de lámpara de lava. Ahora, como pueden ver,

00:01:42.000 --> 00:01:45.000
puedo usar ambas manos para apretar y juntar

00:01:45.000 --> 00:01:48.000
las manchas. Puedo inyectar calor al sistema,

00:01:48.000 --> 00:01:50.000
o separarlo con dos de mis dedos.

00:01:50.000 --> 00:01:52.000
Es completamente intuitivo; no hay manual de instrucciones.

00:01:52.000 --> 00:01:55.000
La interfaz prácticamente desaparece.

00:01:55.000 --> 00:01:58.000
Esto empezó como salvapantallas que uno de los estudiantes del Ph. D.

00:01:58.000 --> 00:02:05.000
en nuestro laboratorio, Ilya Rosenberg, construyó. Pero creo que su verdadera identidad aparece acá.

00:02:05.000 --> 00:02:08.000
Ahora, lo que es genial respecto al sensor multi-táctil es que

00:02:08.000 --> 00:02:11.000
podría estar haciendo esto con todos los dedos,

00:02:11.000 --> 00:02:14.000
pero, por supuesto, multi-táctil también significa, inherentemente, multi-usuario.

00:02:14.000 --> 00:02:16.000
Entonces, Chris podría estar aquí interactuando con otra parte de la lava,

00:02:16.000 --> 00:02:20.000
mientras yo juego por este lado. Pueden imaginar una nueva herramienta escultórica,

00:02:20.000 --> 00:02:23.000
donde yo estoy calentando algo, volviéndolo maleable,

00:02:23.000 --> 00:02:31.000
y después dejándolo enfriar y solidificándolo en un estado particular.

00:02:31.000 --> 00:02:39.000
Google debería tener algo así en su lobby. (Risas).

00:02:39.000 --> 00:02:44.000
Les mostraré algo -- un ejemplo algo más concreto, mientras esto carga.

00:02:44.000 --> 00:02:47.000
Ésta es una caja de luz para fotógrafos.

00:02:47.000 --> 00:02:51.000
De nuevo, puedo usar mis dos manos para interactuar y mover las fotos.

00:02:51.000 --> 00:02:55.000
Pero lo que es aún más genial es que si uso dos dedos,

00:02:55.000 --> 00:02:58.000
puedo agarrar una foto y estirarla de esta manera con mucha facilidad.

00:02:58.000 --> 00:03:02.000
Puedo moverla, acercarla y girarla sin esfuerzo.

00:03:02.000 --> 00:03:04.000
Puedo hacer eso con ambas manos,

00:03:04.000 --> 00:03:08.000
o puedo hacerlo sólo con dos dedos de cada una de mis manos.

00:03:08.000 --> 00:03:10.000
Si tomo el lienzo, puedo hacer más o menos lo mismo -- estirarlo.

00:03:10.000 --> 00:03:12.000
Puedo hacerlo simultáneamente, lo sostengo

00:03:12.000 --> 00:03:15.000
y agarro otro, estirándolo de esta manera.

00:03:15.000 --> 00:03:17.000
De nuevo, la interfaz simplemente desaparece.

00:03:17.000 --> 00:03:21.000
No hay manual. Esto es exactamente lo que esperarían,

00:03:21.000 --> 00:03:24.000
especialmente si no han interactuado con un computador antes.

00:03:24.000 --> 00:03:27.000
Ahora, cuando existen iniciativas como el computador portátil de 100 dólares,

00:03:27.000 --> 00:03:29.000
Me estremezco con la idea de introducir a toda una nueva generación

00:03:29.000 --> 00:03:34.000
de personas a la computación con la interfaz estándar de ratón y ventanas.

00:03:34.000 --> 00:03:38.000
Yo pienso que esta es la manera en la que deberíamos interactuar con las máquinas

00:03:38.000 --> 00:03:46.000
desde este momento. (Aplausos)

00:03:46.000 --> 00:03:53.000
Ahora, por supuesto, puedo sacar un teclado.

00:03:53.000 --> 00:03:57.000
Puedo moverlo, ponerlo allá arriba.

00:03:57.000 --> 00:03:58.000
Obviamente, esta es una especie de teclado estándar,

00:03:58.000 --> 00:04:01.000
pero por supuesto, puedo escalarlo para que funcione bien con mis manos.

00:04:01.000 --> 00:04:04.000
Y eso es bastante importante, porque no hay ninguna razón en estos días por la que

00:04:04.000 --> 00:04:06.000
debamos estar confinados a un dispositivo físico.

00:04:06.000 --> 00:04:09.000
Eso lleva a cosas malas, como LER. (Lesiones por Esfuerzo Repetitivo)

00:04:09.000 --> 00:04:12.000
Tenemos tanta tecnología estos días que

00:04:12.000 --> 00:04:16.000
las interfaces deben empezar a adaptarse a nosotros.

00:04:16.000 --> 00:04:20.000
Se ha invertido tan poco en mejorar

00:04:20.000 --> 00:04:22.000
la manera en la que interactuamos con las interfaces.

00:04:22.000 --> 00:04:25.000
Lo más probable es que este teclado sea en realidad la dirección incorrecta para continuar.

00:04:25.000 --> 00:04:29.000
Pueden imaginar, en el futuro, a medida que desarrollamos este tipo de tecnología,

00:04:29.000 --> 00:04:32.000
un teclado que siga su mano mientras se aleja,

00:04:32.000 --> 00:04:36.000
y anticipe inteligentemente qué tecla están tratando de presionar.

00:04:36.000 --> 00:04:41.000
¿No es esto genial?

00:04:41.000 --> 00:04:44.000
Audiencia: ¿Donde está tu laboratorio?

00:04:44.000 --> 00:04:46.000
Jeff Han: Soy un investigador de la Universidad de Nueva York (NYU).

00:04:50.000 --> 00:04:54.000
Aca hay un ejemplo de otro tipo de aplicación. Puedo crear estas pelotitas.

00:04:54.000 --> 00:04:58.000
La aplicación recordará los trazos que realizo. Desde luego, puedo hacerlo con ambas manos.

00:04:58.000 --> 00:05:01.000
Es sensible a la presión, como notarán.

00:05:01.000 --> 00:05:04.000
Pero lo entretenido es, nuevamente, que como les mostré antes, con un gesto de dos dedos puedo

00:05:04.000 --> 00:05:07.000
hacer zoom rápidamente. No tienen que cambiar a otra herramienta

00:05:07.000 --> 00:05:08.000
o usar una herramienta de lupa;

00:05:08.000 --> 00:05:14.000
pueden hacer cosas continuamente en múltiples escalas reales, todo al mismo tiempo.

00:05:14.000 --> 00:05:18.000
Puedo crear cosas grandes, pero puedo volver rápidamente a

00:05:18.000 --> 00:05:22.000
donde comencé, y hacer cosas aún más pequeñas.

00:05:22.000 --> 00:05:26.000
Ahora, esto será muy importante a medida que nos involucremos con cosas como

00:05:26.000 --> 00:05:30.000
la visualización de datos. Por ejemplo, creo que todos disfrutamos la charla de Hans Rosling,

00:05:30.000 --> 00:05:33.000
y él puso mucho énfasis en algo en lo que he estado pensando por mucho tiempo:

00:05:33.000 --> 00:05:36.000
tenemos todos estos datos geniales, pero por alguna razón, simplemente están ahí.

00:05:36.000 --> 00:05:43.000
No los estamos usando. Y creo que una de las razones, es porque

00:05:43.000 --> 00:05:46.000
-- tendremos el apoyo de cosas como gráficas y herramientas de visualización e inferencia.

00:05:46.000 --> 00:05:50.000
Pero pienso que una gran parte de eso será comenzar a contar con mejores interfaces,

00:05:50.000 --> 00:05:56.000
para poder acceder a este tipo de información, sin dejar de pensar en el panorama global.

00:05:56.000 --> 00:05:58.000
Déjenme mostrarles otra aplicación. Esta se llama WorldWind.

00:05:58.000 --> 00:06:02.000
Es desarrollada por NASA. Es un tipo de -- todos hemos visto Google Earth;

00:06:02.000 --> 00:06:07.000
esta es una versión de código abierto de eso mismo. Hay plug-ins que permiten

00:06:07.000 --> 00:06:10.000
cargar distintos conjuntos de datos que NASA ha recolectado durante años.

00:06:10.000 --> 00:06:11.000
Pero como pueden ver, puedo usar los mismos gestos con dos dedos

00:06:11.000 --> 00:06:16.000
para bajar y acercarme a la perfección. De nuevo, no hay una interfaz.

00:06:16.000 --> 00:06:21.000
Realmente permite que cualquiera se acerque -- y, hace justamente lo que esperas que haga,

00:06:21.000 --> 00:06:28.000
Nuevamente, acá no hay una interfaz. La interfaz desaparece.

00:06:28.000 --> 00:06:32.000
Puedo cambiar a diferentes vistas de datos. Eso es lo genial de esta aplicación.

00:06:32.000 --> 00:06:34.000
Ahí lo tienen. NASA es genial. Tienen estas imágenes hiper-espectrales

00:06:34.000 --> 00:06:41.000
que están falsamente coloreadas para que puedan -- es muy útil para determinar el uso vegetativo. Bueno, volvamos.

00:06:41.000 --> 00:06:46.000
Ahora, lo mejor de las aplicaciones de cartografía --

00:06:46.000 --> 00:06:51.000
no es el 2D, es el 3D. Entonces, nuevamente, con una interfaz multi-punto

00:06:51.000 --> 00:06:56.000
pueden hacer un gesto como este -- para que puedan inclinar la cámara,

00:06:56.000 --> 00:07:01.000
No está relegada al movimiento y al paneo 2D.

00:07:01.000 --> 00:07:03.000
Ahora, este gesto que hemos desarrollado, funciona colocando dos dedos en la superficie,

00:07:03.000 --> 00:07:07.000
definiendo un eje de inclinación, y puedo inclinar arriba y abajo de esa forma.

00:07:07.000 --> 00:07:09.000
Fue algo que se nos ocurrió en el momento,

00:07:09.000 --> 00:07:11.000
y probablemente no sea lo correcto,

00:07:11.000 --> 00:07:16.000
pero hay tantas cosas interesantes que se pueden hacer con este tipo de interfaz.

00:07:16.000 --> 00:07:20.000
Es muy entretenido jugar con ella también. (Risas)

00:07:20.000 --> 00:07:23.000
Y lo último que quería mostrarles --

00:07:23.000 --> 00:07:25.000
Estoy seguro que todos podemos pensar en muchas aplicaciones de entretenimiento

00:07:25.000 --> 00:07:27.000
que se pueden hacer con esto.

00:07:27.000 --> 00:07:31.000
Estoy algo más interesado en el tipo de aplicaciones creativas que se pueden hacer.

00:07:31.000 --> 00:07:36.000
Aquí hay una aplicación muy simple -- Puedo dibujar una curva.

00:07:36.000 --> 00:07:40.000
Y cuando la cierro, se convierte en un personaje.

00:07:40.000 --> 00:07:43.000
Pero lo genial, es que puedo añadir puntos de control.

00:07:43.000 --> 00:07:47.000
Y lo que puedo hacer es manipularlos con mis dos dedos al mismo tiempo.

00:07:47.000 --> 00:07:50.000
Y se pueden dar cuenta de lo que hace.

00:07:50.000 --> 00:07:53.000
Es como una marioneta, donde puedo usar

00:07:53.000 --> 00:07:58.000
cuantos dedos tenga para dibujar y hacer --

00:08:03.000 --> 00:08:06.000
Ahora, hay un montón de matemáticas tras esto

00:08:06.000 --> 00:08:11.000
para que controle este objeto correctamente.

00:08:11.000 --> 00:08:15.000
Lo que quiero decir, es que esta técnica que permite manipular este objeto,

00:08:15.000 --> 00:08:18.000
con múltiples puntos de control, es algo totalmente nuevo.

00:08:18.000 --> 00:08:20.000
Fue publicado en Siggraph recién el año pasado,

00:08:20.000 --> 00:08:22.000
pero es un gran ejemplo del tipo de investigación que me encanta.

00:08:22.000 --> 00:08:25.000
Todo este poder computacional aplicado a hacer que las cosas hagan las cosas correctas,

00:08:25.000 --> 00:08:28.000
cosas intuitivas. Hacer exactamente lo que esperas.

00:08:32.000 --> 00:08:37.000
Bueno, la interaccion multi-táctil es un campo muy activo ahora en la IPC (Interacción persona-computador)

00:08:37.000 --> 00:08:40.000
No soy el único haciéndolo, hay muchas personas investigando.

00:08:40.000 --> 00:08:43.000
Este tipo de tecnología va a permitir que aún más gente se interese,

00:08:43.000 --> 00:08:45.000
y estoy muy ansioso de interactuar con todos ustedes

00:08:45.000 --> 00:08:48.000
en los próximos días y ver cómo esto se puede aplicar a sus respectivos campos.

00:08:48.000 --> 00:08:50.000
Gracias.

00:08:50.000 --> 00:08:56.000
(Aplausos)

