WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Sebastian Betti
Revisor: Amalia Gómez

00:00:11.820 --> 00:00:15.636
A lo mejor tienen la impresión,
como la mayoría de la gente,

00:00:15.660 --> 00:00:19.316
de que nuestro país
está cada vez más polarizado;

00:00:19.340 --> 00:00:22.796
de que la división
entre izquierda y derecha

00:00:22.820 --> 00:00:26.356
es mucho más grande de
lo que hemos vivido nunca.

00:00:26.380 --> 00:00:31.660
Quizá se pregunten si hay investigaciones
que respalden su intuición.

00:00:32.380 --> 00:00:37.060
Y en pocas palabras,
la respuesta es tristemente que sí.

00:00:38.740 --> 00:00:40.756
Estudio tras estudio observamos

00:00:40.780 --> 00:00:44.460
que liberales y conservadores
se han alejado cada vez más.

00:00:45.260 --> 00:00:50.036
Se aíslan cada vez más
en unos silos ideológicos,

00:00:50.060 --> 00:00:54.196
leyendo diferentes noticias, hablando
con gente con las mismas ideas

00:00:54.220 --> 00:00:57.460
y eligiendo, más y más, vivir
en partes diferentes del país.

00:00:58.540 --> 00:01:01.756
Y creo que lo más alarmante

00:01:01.780 --> 00:01:05.580
es la creciente hostilidad
de ambas partes.

00:01:06.260 --> 00:01:07.916
Liberales y conservadores,

00:01:07.940 --> 00:01:09.836
demócratas y republicanos,

00:01:09.860 --> 00:01:12.980
se gustan cada vez menos.

00:01:14.140 --> 00:01:16.156
Se puede observar en muchas actitudes.

00:01:16.180 --> 00:01:19.836
No quieren ser amigos.
No quieren salir juntos.

00:01:19.860 --> 00:01:23.156
Si lo hacen y se enteran,
se encuentran menos atractivos

00:01:23.180 --> 00:01:26.276
y quieren, cada vez menos, ver 
a sus hijos casados con

00:01:26.300 --> 00:01:27.996
partidarios de la contra,

00:01:28.020 --> 00:01:29.780
una estadística escalofriante.

00:01:31.460 --> 00:01:34.276
En mi laboratorio,
hablo con mis estudiantes

00:01:34.300 --> 00:01:37.756
sobre patrones sociales.

00:01:37.780 --> 00:01:41.316
Soy un gran aficionado al cine
y a veces pregunto:

00:01:41.340 --> 00:01:44.300
¿a qué película pertenecemos
con este patrón?

00:01:44.900 --> 00:01:48.180
¿En qué tipo de película participamos
con la polarización política?

00:01:48.900 --> 00:01:51.620
Podría ser una película de desastres.

00:01:52.700 --> 00:01:54.380
Desde luego parece un desastre.

00:01:54.740 --> 00:01:56.740
Podría ser una película de guerra.

00:01:57.460 --> 00:01:58.660
También encaja.

00:01:59.300 --> 00:02:03.116
Pero lo que yo creo es que estamos
en una película de apocalipsis zombi.

00:02:03.140 --> 00:02:04.596
(Risas)

00:02:04.620 --> 00:02:06.916
¿Verdad? Ya saben de qué hablo.

00:02:06.940 --> 00:02:09.356
Hay gente vagando en grupos,

00:02:09.380 --> 00:02:11.156
sin pensar por sí mismos,

00:02:11.180 --> 00:02:12.796
siguiendo la ideología de la masa

00:02:12.820 --> 00:02:16.060
intentando extender su enfermedad
y destruir a la sociedad.

00:02:17.300 --> 00:02:19.636
Y probablemente Uds. piensan, como yo,

00:02:19.660 --> 00:02:23.116
que son los buenos en la película
del apocalipsis zombi

00:02:23.140 --> 00:02:26.836
y que este odio y esta polarización
lo propagan los otros.

00:02:26.860 --> 00:02:28.740
Nosotros somos Brad Pitt, ¿no?

00:02:29.580 --> 00:02:32.476
Librepensadores, honrados,

00:02:32.500 --> 00:02:34.796
intentando aferrarnos
a lo que nos importa,

00:02:34.820 --> 00:02:38.396
ya saben, no somos soldados
del ejército de los no muertos.

00:02:38.420 --> 00:02:39.876
Eso no.

00:02:39.900 --> 00:02:41.100
Eso nunca.

00:02:41.900 --> 00:02:43.396
Pero este es el quid:

00:02:43.420 --> 00:02:46.140
¿En qué película piensan que están ellos?

00:02:47.300 --> 00:02:48.516
¿No?

00:02:48.540 --> 00:02:51.076
Ellos están convencidos
de ser los buenos

00:02:51.100 --> 00:02:52.956
en la película del apocalipsis zombi.

00:02:52.980 --> 00:02:55.956
Y, créanlo, piensan
que ellos son Brad Pitt

00:02:55.980 --> 00:02:58.100
y que nosotros somos los zombis.

00:03:00.940 --> 00:03:03.300
¿Y quién dice que se equivocan?

00:03:04.260 --> 00:03:07.380
Creo que la verdad es que
todos somos parte de esto.

00:03:08.060 --> 00:03:11.220
Lo bueno es que podemos
ser parte de la solución.

00:03:12.100 --> 00:03:14.100
Así que, ¿qué vamos a hacer?

00:03:15.140 --> 00:03:19.396
¿Qué podemos hacer para socavar
la polarización en el día a día?

00:03:19.420 --> 00:03:23.236
¿Cómo podríamos conectarnos
y comunicarnos

00:03:23.260 --> 00:03:24.980
con nuestros homólogos políticos?

00:03:25.540 --> 00:03:29.676
Esas eran exactamente las preguntas
que a mi colega Matt Feinberg y a mí

00:03:29.700 --> 00:03:31.558
nos fascinaron hace unos años

00:03:31.582 --> 00:03:33.782
y empezamos a investigar
sobre ese tema.

00:03:34.740 --> 00:03:37.716
Una de las primeras cosas
que descubrimos,

00:03:37.740 --> 00:03:41.196
que creo muy útil
para entender la polarización,

00:03:41.220 --> 00:03:42.436
es entender

00:03:42.460 --> 00:03:46.876
que la división política del país se basa
en una división moral más profunda.

00:03:46.900 --> 00:03:51.676
Uno de los descubrimientos más importantes
en la historia de la psicología política

00:03:51.700 --> 00:03:55.396
es este patrón identificado
por Jon Haidt y Jesse Graham,

00:03:55.420 --> 00:03:56.636
psicólogos,

00:03:56.660 --> 00:04:00.676
de que los liberales y los conservadores
tienden a respaldar diferentes valores

00:04:00.700 --> 00:04:01.900
a diferentes niveles.

00:04:02.420 --> 00:04:07.916
Por ejemplo, descubrimos que los liberales
tienden a apoyar valores como la igualdad,

00:04:07.940 --> 00:04:11.596
la justicia, el cuidado,
y la protección contra el peligro

00:04:11.620 --> 00:04:13.756
más que los conservadores.

00:04:13.780 --> 00:04:19.036
Y los conservadores tienden a apoyar
valores como la lealtad, el patriotismo,

00:04:19.060 --> 00:04:22.516
el respeto a la autoridad
y la pureza moral

00:04:22.540 --> 00:04:24.620
más que los liberales.

00:04:25.740 --> 00:04:29.796
Matt y yo pensamos que es posible
que esta división moral

00:04:29.820 --> 00:04:32.916
sea útil para entender cómo es que

00:04:32.940 --> 00:04:35.356
los liberales y los
conservadores hablan

00:04:35.380 --> 00:04:37.796
y la mayor parte del tiempo
no se escuchan

00:04:37.820 --> 00:04:39.036
al hablar.

00:04:39.060 --> 00:04:41.036
Así que realizamos un estudio

00:04:41.060 --> 00:04:44.156
donde buscamos liberales
para un estudio

00:04:44.180 --> 00:04:46.636
en el que tenían que escribir
un ensayo persuasivo

00:04:46.660 --> 00:04:51.100
y convincente para un conservador
en apoyo al matrimonio homosexual.

00:04:51.620 --> 00:04:54.876
Nos dimos cuenta de que los liberales
tendían a argumentar

00:04:54.900 --> 00:04:59.076
en términos de valores morales liberales
de igualdad y de justicia.

00:04:59.100 --> 00:05:00.836
Decían cosas como

00:05:00.860 --> 00:05:04.236
"Todo el mundo debería tener el derecho
de amar a quien elija",

00:05:04.260 --> 00:05:06.836
y "Ellos" - "ellos" los
estadounidenses gays --

00:05:06.860 --> 00:05:09.620
"merecen los mismos derechos
que el resto de la población".

00:05:10.180 --> 00:05:13.396
En suma, descubrimos
que el 69 % de los liberales

00:05:13.420 --> 00:05:18.836
recurrió a uno de los valores morales
más liberales al escribir su ensayo,

00:05:18.860 --> 00:05:22.556
y que solo el 9 % recurrió
a uno de los más conservadores,

00:05:22.580 --> 00:05:25.996
incluso cuando se supone que tenían
que convencer a los conservadores.

00:05:26.020 --> 00:05:30.316
Cuando estudiamos a los conservadores
al escribir argumentos convincentes

00:05:30.340 --> 00:05:33.236
para apoyar el hacer del inglés
la lengua oficial de EE.UU.,

00:05:33.260 --> 00:05:35.796
una posición política
clásica conservadora,

00:05:35.820 --> 00:05:38.036
descubrimos que no lo hicieron
mejor que los liberales.

00:05:38.060 --> 00:05:39.676
El 59 % argumentó

00:05:39.700 --> 00:05:42.396
en términos de valores
morales conservadores

00:05:42.420 --> 00:05:44.916
y solo un 8 % recurrió
un valor moral liberal,

00:05:44.940 --> 00:05:48.300
incluso aunque se supone que estaban
dirigiéndose a los liberales.

00:05:49.300 --> 00:05:53.340
Ven dónde está el problema, ¿no?

00:05:54.100 --> 00:05:57.596
Los valores morales de la gente
son sus más profundas creencias.

00:05:57.620 --> 00:06:01.020
La gente está dispuesta a luchar
y a morir por sus valores.

00:06:01.540 --> 00:06:04.236
¿Por qué renunciar a ellos
solo por coincidir con usted

00:06:04.260 --> 00:06:07.796
en algo sobre lo que de todas formas
no quiero estar de acuerdo?

00:06:07.820 --> 00:06:11.076
Si ese convincente argumento
que le hacen a su tío republicano

00:06:11.100 --> 00:06:13.516
significa que no solo tiene
que cambiar su punto de vista,

00:06:13.540 --> 00:06:15.706
tiene que cambiar
sus valores subyacentes, también.

00:06:15.730 --> 00:06:17.290
no van a llegar muy lejos.

00:06:17.900 --> 00:06:19.220
¿Qué funcionaría mejor?

00:06:20.020 --> 00:06:24.316
Creemos que una técnica que
se llama reformulación moral

00:06:24.340 --> 00:06:26.956
y que hemos estudiado
en una serie de experimentos.

00:06:26.980 --> 00:06:28.476
En uno de estos experimentos

00:06:28.500 --> 00:06:31.636
buscamos a liberales y conservadores
para un estudio

00:06:31.660 --> 00:06:33.956
en el que leen tres ensayos

00:06:33.980 --> 00:06:37.020
antes de responder a una encuesta
sobre su postura medioambiental.

00:06:37.460 --> 00:06:38.956
El primero de los ensayos

00:06:38.980 --> 00:06:42.356
era un ensayo proambiental
relativamente convencional

00:06:42.380 --> 00:06:46.396
que recurría a los valores liberales
de cuidado y protección ante el daño.

00:06:46.420 --> 00:06:48.956
Decía cosas como
"estamos causando daños reales

00:06:48.980 --> 00:06:51.796
muy graves de muchas maneras
a los lugares en los que vivimos"

00:06:51.820 --> 00:06:54.636
y "es imprescindible
que empecemos a actuar

00:06:54.660 --> 00:06:57.580
para prevenir una mayor destrucción
del planeta Tierra".

00:06:58.940 --> 00:07:00.356
A otro grupo de participantes

00:07:00.380 --> 00:07:02.596
se les asignó un ensayo muy diferente

00:07:02.620 --> 00:07:07.060
diseñado para apelar al valor
conservador de pureza moral.

00:07:08.010 --> 00:07:09.996
También era un ensayo proambiental

00:07:10.020 --> 00:07:11.516
y decía cosas como

00:07:11.540 --> 00:07:15.780
"proteger nuestros bosques, agua
y cielos puros es de vital importancia".

00:07:16.820 --> 00:07:18.316
"Deberíamos considerar la contaminación

00:07:18.340 --> 00:07:20.380
de los lugares en los que vivimos
algo repugnante".

00:07:20.980 --> 00:07:23.076
Y "reducir la contaminación
puede ayudarnos a preservar

00:07:23.100 --> 00:07:26.260
lo pureza y la belleza de los
lugares en los que vivimos".

00:07:27.700 --> 00:07:29.116
Al tercer grupo

00:07:29.140 --> 00:07:31.636
se le asignó un ensayo no político.

00:07:31.660 --> 00:07:34.396
Era simplemente un grupo de
comparación para tener una referencia.

00:07:34.420 --> 00:07:36.373
Descubrimos que
cuando encuestamos a la gente

00:07:36.397 --> 00:07:38.596
sobre sus posturas medioambientales,

00:07:38.620 --> 00:07:41.556
descubrimos que no importaba qué ensayo
hubiesen leído los liberales.

00:07:41.580 --> 00:07:44.676
En cualquier caso tendían
a tener posturas proambientales.

00:07:44.700 --> 00:07:47.116
Los liberales apoyan
la protección del medioambiente.

00:07:47.140 --> 00:07:48.356
Los conservadores, por el contrario,

00:07:48.380 --> 00:07:52.796
apoyaban mucho más las políticas
medioambientales progresistas

00:07:52.820 --> 00:07:54.356
y la protección medioambiental

00:07:54.380 --> 00:07:56.436
si habían leído el ensayo
de la pureza moral

00:07:56.460 --> 00:07:58.860
que si habían leído
los otros dos ensayos.

00:07:59.980 --> 00:08:03.076
Incluso descubrimos que los conservadores
que leyeron el ensayo de la pureza moral

00:08:03.100 --> 00:08:06.596
tenían mucha más tendencia a decir
que creían en el calentamiento global

00:08:06.620 --> 00:08:08.525
y que les preocupaba

00:08:08.549 --> 00:08:11.276
incluso cuando el ensayo ni siquiera
mencionaba el calentamiento global.

00:08:11.300 --> 00:08:13.756
Es simplemente un problema
medioambiental relacionado.

00:08:13.780 --> 00:08:16.860
Pero así de fuerte era el efecto
de la reformulación moral.

00:08:17.780 --> 00:08:21.516
Y lo hemos estudiado en un montón
de problemas políticos.

00:08:21.540 --> 00:08:25.276
Si quieren llegar a los conservadores

00:08:25.300 --> 00:08:28.396
en cuestiones como el matrimonio
homosexual o el seguro de salud nacional

00:08:28.420 --> 00:08:31.876
es útil relacionar estas cuestiones
liberales con valores conservadores

00:08:31.900 --> 00:08:34.700
como el patriotismo y la pureza moral.

00:08:35.620 --> 00:08:37.716
También lo hemos estudiado al revés.

00:08:37.740 --> 00:08:41.556
Si quieren el apoyo de los liberales
en cuestiones políticas conservadores

00:08:41.580 --> 00:08:46.196
como el gasto militar y hacer del inglés
la lengua oficial de EE.UU.,

00:08:46.220 --> 00:08:47.876
serán más convincentes

00:08:47.900 --> 00:08:51.236
si relacionan esas cuestiones
conservadoras a valores liberales

00:08:51.260 --> 00:08:53.140
como la igualdad y la justicia.

00:08:54.460 --> 00:08:57.316
Todos estos estudios
tienen un mensaje claro:

00:08:57.340 --> 00:09:00.276
si quieren persuadir a alguien
de alguna política

00:09:00.300 --> 00:09:04.140
es útil conectar esa política con
sus valores morales subyacentes.

00:09:05.340 --> 00:09:09.036
Dicho así parece muy obvio, ¿no?

00:09:09.060 --> 00:09:10.836
Como ¿por qué hemos venido
aquí esta noche?

00:09:10.860 --> 00:09:12.076
¿Por qué...

00:09:12.100 --> 00:09:13.636
(Risas)

00:09:13.660 --> 00:09:15.700
Es increíblemente intuitivo.

00:09:17.220 --> 00:09:20.516
Pues aunque lo es, es algo 
que cuesta mucho hacer.

00:09:20.540 --> 00:09:24.396
Parece ser que cuando vamos a persuadir
a alguien de una cuestión política

00:09:24.420 --> 00:09:27.156
hablamos como si lo hiciéramos
frente a un espejo.

00:09:27.180 --> 00:09:31.556
No persuadimos tanto sino que
explicamos nuestras razones

00:09:31.580 --> 00:09:34.460
sobre por qué creemos
un tipo de posición política.

00:09:35.220 --> 00:09:39.636
No paramos de repetir, al diseñar
estos argumentos reformulados moralmente

00:09:39.660 --> 00:09:42.300
"empatía y respeto, empatía y respeto".

00:09:42.860 --> 00:09:44.316
Si pueden apelar a eso,

00:09:44.340 --> 00:09:45.996
pueden conectar

00:09:46.020 --> 00:09:48.820
y pueden ser capaces de persuadir
a alguien en el país.

00:09:49.380 --> 00:09:51.796
Así que pensando, otra vez,

00:09:51.820 --> 00:09:54.100
sobre en qué película estamos,

00:09:55.020 --> 00:09:56.596
quizá antes me haya dejado llevar.

00:09:56.620 --> 00:09:58.580
Puede que no estemos
en un apocalipsis zombi.

00:09:59.340 --> 00:10:01.260
Puede que estemos en una peli
de dos compañeros policía.

00:10:01.860 --> 00:10:03.876
(Risas)

00:10:03.900 --> 00:10:05.916
Tan solo déjense llevar, por favor.

00:10:05.940 --> 00:10:07.380
(Risas)

00:10:08.300 --> 00:10:10.996
Ya saben, hay un policía blanco 
y un policía negro

00:10:11.020 --> 00:10:13.156
o quizá un policía desastre
y otro organizado.

00:10:13.180 --> 00:10:15.236
Da igual, no encajan

00:10:15.260 --> 00:10:16.546
por esta diferencia.

00:10:17.340 --> 00:10:20.556
Pero al final, cuando tienen
que aunar esfuerzos y cooperar

00:10:20.580 --> 00:10:22.516
la solidaridad que sienten

00:10:22.540 --> 00:10:26.180
es mayor por ese puente que 
tuvieron que cruzar, ¿verdad?

00:10:27.100 --> 00:10:29.076
Y recuerden que en estas películas

00:10:29.100 --> 00:10:31.996
normalmente el peor
es el segundo acto

00:10:32.020 --> 00:10:34.420
cuando ambas direcciones
están más separadas que nunca.

00:10:35.260 --> 00:10:37.596
A lo mejor es ahí donde estamos
en este país;

00:10:37.620 --> 00:10:39.796
al final del segundo acto
en una película de policías

00:10:39.820 --> 00:10:42.396
(Risas)

00:10:42.420 --> 00:10:45.500
divididos pero a punto
de ponernos de acuerdo.

00:10:47.220 --> 00:10:48.876
Suena bien,

00:10:48.900 --> 00:10:50.756
pero si queremos que pase,

00:10:50.780 --> 00:10:53.500
creo que la responsabilidad
es nuestra.

00:10:54.340 --> 00:10:56.500
Por eso les pido:

00:10:57.300 --> 00:10:59.300
unamos otra vez a este país.

00:11:00.900 --> 00:11:03.956
Hagámoslo a pesar de los políticos,

00:11:03.980 --> 00:11:06.836
los medios, Facebook, Twitter,

00:11:06.860 --> 00:11:08.396
la división distrital del Congreso

00:11:08.420 --> 00:11:11.140
y todo eso, todo lo que nos divide.

00:11:12.180 --> 00:11:14.420
Hagámoslo porque es lo correcto.

00:11:15.740 --> 00:11:20.156
Y hagámoslo porque este odio 
y este desprecio

00:11:20.180 --> 00:11:22.340
que fluye a través de nosotros cada día

00:11:23.220 --> 00:11:26.396
nos afea y nos corrompe

00:11:26.420 --> 00:11:29.740
y amenaza al propio tejido
de nuestra sociedad.

00:11:31.780 --> 00:11:34.436
Nos debemos los unos
a los otros y a nuestro país

00:11:34.460 --> 00:11:36.620
tender la mano e intentar conectar.

00:11:37.820 --> 00:11:40.980
No podemos permitirnos odiarlos más,

00:11:42.020 --> 00:11:44.220
y no podemos permitirnos
dejarles odiarnos tampoco.

00:11:45.700 --> 00:11:47.060
Empatía y respeto.

00:11:47.700 --> 00:11:48.940
Empatía y respeto.

00:11:49.740 --> 00:11:53.540
Si lo piensan, es lo mínimo que 
les debemos a nuestros conciudadanos.

00:11:54.220 --> 00:11:55.436
Gracias.

00:11:55.460 --> 00:11:58.460
(Aplausos)

