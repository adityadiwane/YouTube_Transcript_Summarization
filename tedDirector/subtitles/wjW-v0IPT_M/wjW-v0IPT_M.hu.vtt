WEBVTT
Kind: captions
Language: hu

00:00:00.000 --> 00:00:07.000
Fordító: Edit Dr. Kósa
Lektor: Krisztian Stancz

00:00:16.260 --> 00:00:19.260
Dr. David Hanson vagyok, és személyiséggel rendelkező robotokat építek.

00:00:19.260 --> 00:00:21.260
És ez alatt azt értem,

00:00:21.260 --> 00:00:23.260
hogy olyan robotokat fejlesztek ki, amelyek egyéniségek,

00:00:23.260 --> 00:00:26.260
de olyan robotokat is, amelyek egy nap

00:00:26.260 --> 00:00:28.260
együtt fognak érezni önökkel.

00:00:28.260 --> 00:00:30.260
Szóval a különféle technológiákkal kezdjük,

00:00:30.260 --> 00:00:34.260
amelyek ezekben a beszélő személyiségű robotokban csúcsosodnak ki,

00:00:34.260 --> 00:00:36.260
a robotokban, amelyek látják az arcokat, szemkontaktust teremtenek az emberrel,

00:00:36.260 --> 00:00:39.260
az arckifejezések teljes körét mutatják, megértik a beszédet,

00:00:39.260 --> 00:00:43.260
és elkezdik modellezni, hogyan érez az ember,

00:00:43.260 --> 00:00:46.260
és kicsoda, és kapcsolatot építenek vele.

00:00:46.260 --> 00:00:48.260
Egy sor olyan technológiát fejlesztettem ki,

00:00:48.260 --> 00:00:51.260
amelyek lehetővé tették, hogy a robotok élethűbb mimikát mutassanak

00:00:51.260 --> 00:00:53.260
a korábbiaknál, kevesebb energiával,

00:00:53.260 --> 00:00:57.260
amely lehetővé tette az első két lábon járó robotokat, az első androidokat.

00:00:57.260 --> 00:00:59.260
Az arckifejezések teljes skálája

00:00:59.260 --> 00:01:01.260
szimulálja az emberi arc összes fő izmát;

00:01:01.260 --> 00:01:03.260
nagyon kis akkumulátorról működik,

00:01:03.260 --> 00:01:05.260
rendkívül könnyű.

00:01:05.260 --> 00:01:08.260
Az anyag, amely lehetővé tette az akkumulátorról üzemeltetett mimikát,

00:01:08.260 --> 00:01:10.260
a Frubber nevű anyag,

00:01:10.260 --> 00:01:12.260
és tulajdonképpen három fő újítás van

00:01:12.260 --> 00:01:14.260
ebben az anyagban, amely lehetővé teszi, hogy ez megtörténjen.

00:01:14.260 --> 00:01:16.260
Az egyik a hierarchikus pórusok,

00:01:16.260 --> 00:01:20.260
a másik pedig egy makromolekuláris, nanoméretű porozitású anyag.

00:01:20.260 --> 00:01:23.260
Tessék, járni kezd.

00:01:23.260 --> 00:01:26.260
Ez a Koreai Tudományos és Technológiai Speciális Intézetben van.

00:01:26.260 --> 00:01:30.260
Én építettem a fejet. Ők építették a testet.

00:01:30.260 --> 00:01:33.260
Tehát itt az a cél, hogy érzelmet érjünk el a gépekben,

00:01:33.260 --> 00:01:37.260
sőt nem csak érzelmet, hanem empátiát.

00:01:37.260 --> 00:01:39.260
A Gépi Észlelés Laboratóriummal dolgozunk

00:01:39.260 --> 00:01:41.260
a Kaliforniai Egyetemen San Diegoban.

00:01:41.260 --> 00:01:44.260
Nekik van ez az igazán figyelemre méltó mimikai technológiájuk,

00:01:44.260 --> 00:01:46.260
ami felismeri az arckifejezéseket,

00:01:46.260 --> 00:01:48.260
hogy milyen mimikát használ az ember.

00:01:48.260 --> 00:01:51.260
Azt is felismeri, hova néz, a fej tájolását.

00:01:51.260 --> 00:01:53.260
Mi utánozzuk az összes jelentős arckifejezést,

00:01:53.260 --> 00:01:55.260
majd a Karaktermotor nevű

00:01:55.260 --> 00:01:57.260
szoftverrel ellenőrizzük.

00:01:57.260 --> 00:02:01.260
És itt van egy kicsi abból a technológiából, amit ez tartalmaz.

00:02:01.260 --> 00:02:09.260
Nos, most... innen kihúzom, ide bedugom,

00:02:09.260 --> 00:02:12.260
és most lássuk, eltalálja-e az én saját arckifejezésemet.

00:02:12.260 --> 00:02:17.260
Oké. Mosolygok.

00:02:17.260 --> 00:02:19.260
(Nevetés)

00:02:19.260 --> 00:02:21.260
Most összeráncolom a szemöldököm.

00:02:21.260 --> 00:02:25.260
És ez nagyon erősen van hátulról megvilágítva.

00:02:25.260 --> 00:02:27.260
Oké, megvagyunk.

00:02:27.260 --> 00:02:29.260
Ó, olyan szomorú.

00:02:29.260 --> 00:02:32.260
Rendben van, mosolyogsz, szemöldököt ráncolsz.

00:02:32.260 --> 00:02:34.260
Szóval az ember érzelmi állapotának az észlelése

00:02:34.260 --> 00:02:38.260
nagyon fontos ahhoz, hogy a gépek hatékonyan empatikusak legyenek.

00:02:38.260 --> 00:02:41.260
A gépek gyorsan képessé válnak

00:02:41.260 --> 00:02:45.260
az olyan dolgokra, mint a gyilkolás. Igaz?

00:02:45.260 --> 00:02:47.260
Azokban a gépekben nincs hely az empátia számára.

00:02:47.260 --> 00:02:49.260
És dollármilliárdokat költenek arra.

00:02:49.260 --> 00:02:51.260
A karakterrobotika elültetheti a magot

00:02:51.260 --> 00:02:53.260
az olyan robotok számára, amelyekben ténylegesen van empátia.

00:02:53.260 --> 00:02:55.260
Így, ha elérik az emberi szintű intelligenciát,

00:02:55.260 --> 00:02:59.260
vagy, elégé valószínűleg, az emberi szintű intelligenciánál is nagyobbat,

00:02:59.260 --> 00:03:02.260
ez lehet a remény magja a jövőnk számára.

00:03:02.260 --> 00:03:06.260
20 robotot készítettünk az elmúlt nyolc évben, a PhD-m megszerzése során.

00:03:06.260 --> 00:03:08.260
Aztán elindítottam a Hanson Robotikát,

00:03:08.260 --> 00:03:12.260
amely a tömeggyártáshoz fejleszti ezeket a dolgokat.

00:03:12.260 --> 00:03:14.260
Ez az egyik robotunk,

00:03:14.260 --> 00:03:16.260
amelyet pár évvel ezelőtt mutattunk be a Wired NextFest kiállításon.

00:03:16.260 --> 00:03:19.260
Ez több embert lát egy helyszínen,

00:03:19.260 --> 00:03:21.260
megjegyzi, hol vannak az egyes emberek,

00:03:21.260 --> 00:03:25.260
és emberről emberre néz, emlékszik az emberekre.

00:03:25.260 --> 00:03:27.260
Szóval két dolgot veszünk bele.

00:03:27.260 --> 00:03:29.260
Egy, az emberek észlelése,

00:03:29.260 --> 00:03:33.260
és kettő, a természetes csatolás,

00:03:33.260 --> 00:03:35.260
a csatolás természetes formája,

00:03:35.260 --> 00:03:38.260
így, az ember ösztönösebben kommunikál a robottal.

00:03:38.260 --> 00:03:41.260
Az ember kezdi azt hinni, hogy a robot él, és tudatos.

00:03:41.260 --> 00:03:44.260
Az egyik kedvenc projektem az volt, hogy ezeket a dolgokat összehozzam

00:03:44.260 --> 00:03:47.260
Philip K. Dick science-fiction író

00:03:47.260 --> 00:03:49.260
android portréjának művészi megjelenítésében.

00:03:49.260 --> 00:03:52.260
Ő olyan nagyszerű munkákat írt, mint az "Álmodnak-e az androidok elektromos bárányokkal?",

00:03:52.260 --> 00:03:54.260
amely a "Szárnyas fejvadász" című film alapja volt.

00:03:54.260 --> 00:03:57.260
Ezekben a történetekben a robotok gyakran azt hiszik,

00:03:57.260 --> 00:03:59.260
hogy ők emberek, és egyfajta életre kelnek.

00:03:59.260 --> 00:04:02.260
Szóval az írásait, a leveleit,

00:04:02.260 --> 00:04:05.260
az interjúit, a levelezését

00:04:05.260 --> 00:04:07.260
beleraktuk egy több ezer oldalas, hatalmas az adatbázisba,

00:04:07.260 --> 00:04:09.260
majd valami természetes nyelvi feldolgozást használtunk,

00:04:09.260 --> 00:04:11.260
hogy lehetővé tegyük a tényleges beszélgetést vele.

00:04:11.260 --> 00:04:13.260
Ez valamiképpen kísérteties volt, mert úgy mondja ezeket a dolgokat,

00:04:13.260 --> 00:04:16.260
hogy úgy hangoznak, mintha valóban megértené az embert.

00:04:16.260 --> 00:04:19.260
És ez az egyik legizgalmasabb projekt, amit fejlesztünk,

00:04:19.260 --> 00:04:22.260
amely egy kicsi karakter, azaz egy beszélőbot,

00:04:22.260 --> 00:04:25.260
a barátságos, mesterséges intelligenciához, a felhasználóbarát gépi intelligenciához.

00:04:25.260 --> 00:04:27.260
És ezt elkezdjük tömegesen gyártani.

00:04:27.260 --> 00:04:30.260
Úgy alakítottuk ki, hogy ténylegesen megvalósítható legyen,

00:04:30.260 --> 00:04:33.260
nagyon-nagyon alacsony költségű anyagokból

00:04:33.260 --> 00:04:37.260
azért, hogy a gyerekek társa lehessen.

00:04:37.260 --> 00:04:40.260
Az internethez kapcsolódva az évek során egyre okosabb lesz.

00:04:40.260 --> 00:04:43.260
Ahogy a mesterséges intelligencia fejlődik, úgy fejlődik az ő intelligenciája is.

00:04:43.260 --> 00:04:45.260
Chris Anderson: Nagyon köszönjük. Ez hihetetlen.

00:04:45.260 --> 00:04:52.260
(Taps)

