WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: Elisabeth Buffard
Relecteur: Marine Putman

00:00:16.260 --> 00:00:19.260
Je suis le Dr David Hanson, et je construis des robots qui ont du caractère.

00:00:19.260 --> 00:00:21.260
Et par là, je veux dire

00:00:21.260 --> 00:00:23.260
que je développe des robots qui sont des personnages,

00:00:23.260 --> 00:00:26.260
mais aussi des robots qui à terme

00:00:26.260 --> 00:00:28.260
en viendront à sympathiser avec vous.

00:00:28.260 --> 00:00:30.260
Nous partons donc d'une variété de technologies

00:00:30.260 --> 00:00:34.260
qui ont convergées vers ces robots ayant une personnalité, capables de converser

00:00:34.260 --> 00:00:36.260
pouvant voir les visages, établir un contact visuel avec vous,

00:00:36.260 --> 00:00:39.260
offrir une gamme complète d'expressions faciales, comprendre la parole,

00:00:39.260 --> 00:00:43.260
et commencer à modéliser la façon dont vous vous sentez,

00:00:43.260 --> 00:00:46.260
qui vous êtes, et construire une relation avec vous.

00:00:46.260 --> 00:00:48.260
J'ai développé une série de technologies

00:00:48.260 --> 00:00:51.260
qui a permis aux robots d'avoir des expresssions du visage plus réalistes

00:00:51.260 --> 00:00:53.260
que ce qu'on avait obtenu précédemment, en utilisant moins d'énergie,

00:00:53.260 --> 00:00:57.260
ce qui a permis des robots bipèdes qui marchent, les premiers androïdes.

00:00:57.260 --> 00:00:59.260
Donc, il s'agit d'une gamme complète d'expressions faciales

00:00:59.260 --> 00:01:01.260
qui simulent tous les principaux muscles du visage humain,

00:01:01.260 --> 00:01:03.260
et fonctionnent sur de très petites batteries,

00:01:03.260 --> 00:01:05.260
extrêmement légères.

00:01:05.260 --> 00:01:08.260
Les matériaux qui ont permis l'alimentation par batteries des expressions faciales

00:01:08.260 --> 00:01:10.260
sont fait d'une matière que nous appelons Frubber,

00:01:10.260 --> 00:01:12.260
et il y a en fait trois innovations majeures

00:01:12.260 --> 00:01:14.260
dans le matériau qui permettent que cela se produise.

00:01:14.260 --> 00:01:16.260
Tout d'abord des pores hiérarchiques.

00:01:16.260 --> 00:01:20.260
Et ensuite une porosité macro-moléculaire à l’échelle du nanomètre dans le matériau.

00:01:20.260 --> 00:01:23.260
Là, il commence à marcher.

00:01:23.260 --> 00:01:26.260
Ceci se passe à l'Institut Coréen des Sciences et des Technologies.

00:01:26.260 --> 00:01:30.260
J'ai construit la tête. Ils ont construit le corps.

00:01:30.260 --> 00:01:33.260
Et donc le but est ici de parvenir à une "sentience" dans les machines,

00:01:33.260 --> 00:01:37.260
et pas seulement de la sentience, mais de l'empathie.

00:01:37.260 --> 00:01:39.260
Nous travaillons avec le Laboratoire de Perception des Machines

00:01:39.260 --> 00:01:41.260
à l'Université de Californie de San Diego.

00:01:41.260 --> 00:01:44.260
Ils ont cette technologie tout à fait remarquable d'expression faciale

00:01:44.260 --> 00:01:46.260
qui reconnaît les expressions faciales,

00:01:46.260 --> 00:01:48.260
quelles expressions faciales vous adoptez.

00:01:48.260 --> 00:01:51.260
Il reconnaît aussi la direction de votre regard, l'orientation de votre tête.

00:01:51.260 --> 00:01:53.260
Nous simulons toutes les grandes expressions du visage,

00:01:53.260 --> 00:01:55.260
et puis nous le contrôlons avec le logiciel

00:01:55.260 --> 00:01:57.260
que nous appelons le Moteur de Personnalité.

00:01:57.260 --> 00:02:01.260
Et voici un peu de la technologie qui est impliqué dans ce processus.

00:02:01.260 --> 00:02:09.260
En fait, en ce moment - on le branche à partir d'ici, puis on le rebranche ici,

00:02:09.260 --> 00:02:12.260
et maintenant nous allons voir s'il comprend mes expressions faciales.

00:02:12.260 --> 00:02:17.260
Okay. Je suis donc souriant.

00:02:17.260 --> 00:02:19.260
(Rires)

00:02:19.260 --> 00:02:21.260
Maintenant, je fais la moue.

00:02:21.260 --> 00:02:25.260
Et c'est vraiment très à contre-jour ici.

00:02:25.260 --> 00:02:27.260
Okay, allons-y.

00:02:27.260 --> 00:02:29.260
Oh, c'est si triste.

00:02:29.260 --> 00:02:32.260
Bon, donc vous souriez, vous faites la moue.

00:02:32.260 --> 00:02:34.260
Et sa perception de vos états émotionnels

00:02:34.260 --> 00:02:38.260
est très importante pour que les machines deviennent effectivement empathiques.

00:02:38.260 --> 00:02:41.260
Les machines deviennent capables de façon dévastatrice

00:02:41.260 --> 00:02:45.260
de tuer et d'actions de ce genre. N'est-ce pas ?

00:02:45.260 --> 00:02:47.260
Ces machines n'ont pas de place pour l'empathie.

00:02:47.260 --> 00:02:49.260
Et on dépense des milliards de dollars là-dessus.

00:02:49.260 --> 00:02:51.260
La robotique de personnalité pourrait semer la graine

00:02:51.260 --> 00:02:53.260
qui produirait des robots qui aient réellement de l'empathie.

00:02:53.260 --> 00:02:55.260
Donc, si ils finissent par obtenir une intelligence de niveau humain

00:02:55.260 --> 00:02:59.260
ou, très probablement, supérieure aux niveaux humains d'intelligence,

00:02:59.260 --> 00:03:02.260
cela pourrait être les germes d'espoir pour notre avenir.

00:03:02.260 --> 00:03:06.260
Donc, nous avons réalisé 20 robots au cours des huit dernières années, pendant mes études de doctorat.

00:03:06.260 --> 00:03:08.260
Et puis j'ai créé Hanson Robotics,

00:03:08.260 --> 00:03:12.260
qui a développé ces choses-là pour la fabrication de masse.

00:03:12.260 --> 00:03:14.260
Voici l'un de nos robots

00:03:14.260 --> 00:03:16.260
que nous avons montré au Wired NextFest il y a a environ deux ans.

00:03:16.260 --> 00:03:19.260
Et il voit plusieurs personnes dans une scène,

00:03:19.260 --> 00:03:21.260
se souvient où les personnes se trouvent individuellement,

00:03:21.260 --> 00:03:25.260
et regarde d'une personne à l'autre, se souvenant des personnes.

00:03:25.260 --> 00:03:27.260
Donc, nous mettons en oeuvre deux choses.

00:03:27.260 --> 00:03:29.260
Un, la perception des gens.

00:03:29.260 --> 00:03:33.260
Et deux, l'interface naturelle,

00:03:33.260 --> 00:03:35.260
la forme naturelle de l'interface,

00:03:35.260 --> 00:03:38.260
afin qu'elle soit plus intuitive pour vous permettre d'interagir avec le robot.

00:03:38.260 --> 00:03:41.260
Vous commencez à croire qu'il est vivant et conscient.

00:03:41.260 --> 00:03:44.260
Donc un de mes projets préférés était de rassembler tout cela

00:03:44.260 --> 00:03:47.260
dans une exposition artistique d'un portrait androïde

00:03:47.260 --> 00:03:49.260
de l'écrivain de science-fiction Philip K. Dick,

00:03:49.260 --> 00:03:52.260
qui a écrit de grandes oeuvres du genre : "Les androides rêvent-ils de moutons électriques ?"

00:03:52.260 --> 00:03:54.260
qui a été à la base du film "Blade Runner."

00:03:54.260 --> 00:03:57.260
Dans ces histoires, les robots pensent souvent

00:03:57.260 --> 00:03:59.260
qu'ils sont humains. Et ils prennent vie en quelque sorte.

00:03:59.260 --> 00:04:02.260
Nous avons donc placé ses écrits, lettres,

00:04:02.260 --> 00:04:05.260
ses interviews, correspondances,

00:04:05.260 --> 00:04:07.260
dans une immense base de données de milliers de pages,

00:04:07.260 --> 00:04:09.260
et ensuite utilisé un traitement du langage naturel

00:04:09.260 --> 00:04:11.260
pour vous permettre d'avoir une vraie conversation avec lui.

00:04:11.260 --> 00:04:13.260
Et ça donnait des frissons. Parce qu'il disait ces choses

00:04:13.260 --> 00:04:16.260
qui donnaient l'impression qu'il vous comprenait vraiment.

00:04:16.260 --> 00:04:19.260
Et voici l'un des projets les plus excitants que nous développons

00:04:19.260 --> 00:04:22.260
qui est un petit personnage qui est une robot porte-parole

00:04:22.260 --> 00:04:25.260
pour l'intelligence artificielle amicale, pour l'intelligence de la machine conviviale.

00:04:25.260 --> 00:04:27.260
Et nous le faisons fabriquer en grande quantité.

00:04:27.260 --> 00:04:30.260
Nous lui avons donné des spécifications pour qu'il soit réalisable

00:04:30.260 --> 00:04:33.260
avec un très, très faible coût de matériaux,

00:04:33.260 --> 00:04:37.260
pour qu'il puisse devenir un compagnon pour les enfants.

00:04:37.260 --> 00:04:40.260
En l'interfaçant avec Internet, il devient plus intelligent au fil des ans.

00:04:40.260 --> 00:04:43.260
Avec l'évolution de l'intelligence artificielle, son intelligence évolue aussi.

00:04:43.260 --> 00:04:45.260
Chris Anderson : Merci beaucoup. C'est incroyable.

00:04:45.260 --> 00:04:52.260
(Applaudissements)

