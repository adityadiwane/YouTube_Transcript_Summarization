WEBVTT
Kind: captions
Language: fa

00:00:00.000 --> 00:00:07.000
Translator: soheila Jafari
Reviewer: Maral Salehi

00:00:16.260 --> 00:00:19.260
من دکتر دیوید هانسون هستم، و رباتهايی با ويژگي انساني ساختم.

00:00:19.260 --> 00:00:21.260
منظورم اینه که

00:00:21.260 --> 00:00:23.260
رباتهایی که شخصيت دارند را به وجود آوردم،

00:00:23.260 --> 00:00:26.260
چنانکه آنها دقیقا"

00:00:26.260 --> 00:00:28.260
با شما همدلي می کنند.

00:00:28.260 --> 00:00:30.260
خب، ما با انواعي از تكنولوژي‌ها شروع كرديم

00:00:30.260 --> 00:00:34.260
كه در اين رباتهای انسانی سخنگو گرد آمده‌اند

00:00:34.260 --> 00:00:36.260
و می توانند چهره‌ها را ببینند، و با شما ارتباط چشمي برقرار كنند،

00:00:36.260 --> 00:00:39.260
و طيف کاملي از حالت‌هاي چهره را بیافرینند، صحبتها را بفهمند،

00:00:39.260 --> 00:00:43.260
و احساسات شما

00:00:43.260 --> 00:00:46.260
و اینکه شما که هستید را بازآفريني كنند، و با شما ارتباط برقرار کنند.

00:00:46.260 --> 00:00:48.260
من یک سری تکنولوژی ايجاد كردم

00:00:48.260 --> 00:00:51.260
که به رباتها امكان اين را می داد که حالتهای واقعي‌تري از چهره را

00:00:51.260 --> 00:00:53.260
نسبت به آنچه كه قبلا ساخته شده بود كه توانايي كمتري داشت، نشان بدهند

00:00:53.260 --> 00:00:57.260
که ما را قادر به داشتن اولین رباتی که روی دوپا راه می رود كرد، يعني نخستين آدم‌سان مكانيكي.

00:00:57.260 --> 00:00:59.260
خب، آن طیف وسیعی از حالتهای چهره را دارد

00:00:59.260 --> 00:01:01.260
که همه ماهیچه‌های اصلی صورت انسان را شبیه‌سازی میکند،

00:01:01.260 --> 00:01:03.260
و با باتري‌های بسيار کوچک كار كرده

00:01:03.260 --> 00:01:05.260
و بسیار هم سبک است.

00:01:05.260 --> 00:01:08.260
موادی که اين امكان را مي‌دهند كه حالت‌هاي چهره ايجاد شود

00:01:08.260 --> 00:01:10.260
ماده‌اي است كه فابر نامیده می شود،

00:01:10.260 --> 00:01:12.260
و در واقع سه چيز جديد

00:01:12.260 --> 00:01:14.260
در اين ماده هست که امكان ايجاد حالت‌هاي چهره را مي‌دهد.

00:01:14.260 --> 00:01:16.260
یکی از آنها منافذ ريز و درشت است.

00:01:16.260 --> 00:01:20.260
و دیگري ضريب تخلخل ماکرو مولکولی در مقیاس نانو است.

00:01:20.260 --> 00:01:23.260
در آنجا او شروع به راه رفتن کرد.

00:01:23.260 --> 00:01:26.260
این در موسسه علوم و فناوری پیشرفته کره جنوبی است.

00:01:26.260 --> 00:01:30.260
من سر آن را ساختم و آنها بدنش را.

00:01:30.260 --> 00:01:33.260
خب ، در اینجا هدف دستيابي به حساسيت در ماشین‌ها است،

00:01:33.260 --> 00:01:37.260
و نه تنها حساسیت، بلکه همدلی.

00:01:37.260 --> 00:01:39.260
ما با آزمایشگاه ادراک ماشین در

00:01:39.260 --> 00:01:41.260
سن دیاگو کار کردیم

00:01:41.260 --> 00:01:44.260
آنها اين فن‌آوری واقعا فوق‌العاده بيان حالتهای چهره را دارند

00:01:44.260 --> 00:01:46.260
که حالتهای چهره را می‌شناسد،

00:01:46.260 --> 00:01:48.260
هر حالت چهره که شما به خود بگیريد.

00:01:48.260 --> 00:01:51.260
همچنین اینکه شما به کجا نگاه می کنید و جهت حرکت سر شما را تشخیص می دهند‌.

00:01:51.260 --> 00:01:53.260
ما در حال تقليد تمامی حالتهای اصلی چهره هستیم،

00:01:53.260 --> 00:01:55.260
و بعد آنها را با نرم‌افزاري کنترل می‌کنیم

00:01:55.260 --> 00:01:57.260
که آن را موتور شخصیت می‌نامیم.

00:01:57.260 --> 00:02:01.260
کمی فن‌آوری در آن دخیل است.

00:02:01.260 --> 00:02:09.260
در واقع، همين حالا، این را از اینجا، و بعد در اينجا به برق متصل می کنیم،

00:02:09.260 --> 00:02:12.260
اجازه بدهید ببینیم آیا حالتهای چهره مرا به خود می‌گیرد.

00:02:12.260 --> 00:02:17.260
خب من لبخند می‌زنم.

00:02:17.260 --> 00:02:19.260
( خنده تماشاگران)

00:02:19.260 --> 00:02:21.260
من اخم می‌کنم.

00:02:21.260 --> 00:02:25.260
این به شدت پور نور است.

00:02:25.260 --> 00:02:27.260
خب، بفرمائید.

00:02:27.260 --> 00:02:29.260
این بسیار غمگین است.

00:02:29.260 --> 00:02:32.260
خب تو لبخند می زنی، اخم می کنی.

00:02:32.260 --> 00:02:34.260
خب، درک او از حالات هیجانی شما

00:02:34.260 --> 00:02:38.260
برای همدلي موثر بسیار مهم است.

00:02:38.260 --> 00:02:41.260
ماشین‌ها دارند توان كارهاي

00:02:41.260 --> 00:02:45.260
ويرانگري مانند كشتار را پيدا مي‌كنند. درسته؟

00:02:45.260 --> 00:02:47.260
در آن ماشین‌ها جايي براي همدلي نیست.

00:02:47.260 --> 00:02:49.260
در حالي كه میلیاردها دلار صرف آن شده است.

00:02:49.260 --> 00:02:51.260
شخصیتهای رباتی می‌توانند بذر

00:02:51.260 --> 00:02:53.260
رباتهایی که واقعا" دارای همدردی هستند را بكارند.

00:02:53.260 --> 00:02:55.260
خب، اگر آنها به سطح هوش انسان برسند

00:02:55.260 --> 00:02:59.260
یا به بالاتر از هوش انسان برند، كه خيلي امكان دارد برسند،

00:02:59.260 --> 00:03:02.260
آنگاه این می تواند بذر امیدي برای آینده ما باشد.

00:03:02.260 --> 00:03:06.260
خب، ما در هشت سال گذشته، يعني در طی دوره دکترایم، 20 عدد از این ربا‌‌ت‌ها ساخته‌ایم.

00:03:06.260 --> 00:03:08.260
و بعد من ماشين‌هاي رباتی هانسون را شروع کردم،

00:03:08.260 --> 00:03:12.260
که در حال توليد انبوه اين چيزها است.

00:03:12.260 --> 00:03:14.260
این یکی از رباتهای ماست

00:03:14.260 --> 00:03:16.260
که ما در جشنواره (Wired NextFest) چند سال پیش نشان داديم.

00:03:16.260 --> 00:03:19.260
و این ربات چند نفر را همزمان می‌بیند،

00:03:19.260 --> 00:03:21.260
و جاي هر فرد خاص را به خاطر می‌سپارد،

00:03:21.260 --> 00:03:25.260
و به تک تک افراد نگاه می‌کند، و افراد را به ياد مي‌آورد.

00:03:25.260 --> 00:03:27.260
خب، ما درگیر دو چیز هستیم.

00:03:27.260 --> 00:03:29.260
یکی ، درک افراد است.

00:03:29.260 --> 00:03:33.260
و دومی مواجهه طبیعی،

00:03:33.260 --> 00:03:35.260
يعني شكل طبیعی يك مواجهه.

00:03:35.260 --> 00:03:38.260
تا تعامل با ربات برای شما ملموس‌تر باشد.

00:03:38.260 --> 00:03:41.260
شما باور مي‌کنيد که این یک موجود زنده و آگاه است.

00:03:41.260 --> 00:03:44.260
بنابراين یکی از پروژه‌های مورد علاقه من این بود که همه اینها را با هم

00:03:44.260 --> 00:03:47.260
در يك نمايش هنري از رباتي گرد آورم كه

00:03:47.260 --> 00:03:49.260
چهره نويسنده علمی تخیلی فیلیپ كي. دیک را داشته باشد،

00:03:49.260 --> 00:03:52.260
کسی که کتابهای عالی مانند "آیا رباتهاي آدم‌سان خواب گوسفند الكتريكي را مي‌بينند؟" را نوشته است،

00:03:52.260 --> 00:03:54.260
که بر اساس آن فیلم "بليد رانر"(Bladerunner) ساخته شد.

00:03:54.260 --> 00:03:57.260
در اینگونه داستان‌ها، رباتها اغلب فکر می کنند

00:03:57.260 --> 00:03:59.260
که انسان هستند. و مي‌خواهند مثل انسانها زندگي كنند.

00:03:59.260 --> 00:04:02.260
خب، ما نوشته‌ها، نامه‌ها،

00:04:02.260 --> 00:04:05.260
مصاحبه‌ها، مکاتبات اين ربات را

00:04:05.260 --> 00:04:07.260
در یک بانک اطلاعاتی عظیم شامل هزاران صفحه وارد کردیم،

00:04:07.260 --> 00:04:09.260
و سپس از يك روش پردازش زبان عادي استفاده کردیم

00:04:09.260 --> 00:04:11.260
تا بتوانيد با او گفتگو کنید.

00:04:11.260 --> 00:04:13.260
مثل افسانه بود. زیرا او چیزهایی را مي‌گفت

00:04:13.260 --> 00:04:16.260
که به نظر می آمد انگار او واقعا" تو را می شناسد.

00:04:16.260 --> 00:04:19.260
و این یکی از هیجان‌انگیزترین پروژه‌هایي است كه ما داريم پيش مي‌بريم،

00:04:19.260 --> 00:04:22.260
که یک شخصیت كوچوك است يك ربات

00:04:22.260 --> 00:04:25.260
با هوش مصنوعی صميمي، هوش ماشینی دوستانه.

00:04:25.260 --> 00:04:27.260
ما در حال تولید انبوه هستیم.

00:04:27.260 --> 00:04:30.260
در واقع ما این را تنظیم کردیم

00:04:30.260 --> 00:04:33.260
با هزینه بسيار كم براي مواد اولیه، قابل انجام باشد،

00:04:33.260 --> 00:04:37.260
تا بتواند یک همبازی برای کودکان باشد.

00:04:37.260 --> 00:04:40.260
با اينترنت مرتبط باشد، در طی سالها با هوش‌تر شود.

00:04:40.260 --> 00:04:43.260
همچنان كه هوش مصنوعی تكامل مي‌يابد، هوش او هم تكامل يابد.

00:04:43.260 --> 00:04:45.260
از شما بسیار سپاسگزارم. باورکردنی نیست.

00:04:45.260 --> 00:04:52.260
(تشویق تماشاگران)

