WEBVTT
Kind: captions
Language: sr

00:00:00.000 --> 00:00:07.000
Prevodilac: Jelena Nedjic
Lektor: Ana Zivanovic-Nenadovic

00:00:16.260 --> 00:00:19.260
Ja sam dr Dejvid Henson i ja pravim robote sa karakterom.

00:00:19.260 --> 00:00:21.260
Pri tome mislim

00:00:21.260 --> 00:00:23.260
da stvaram robote određenog karaktera,

00:00:23.260 --> 00:00:26.260
ali isto tako i robote koji će na kraju

00:00:26.260 --> 00:00:28.260
saosećati sa vama.

00:00:28.260 --> 00:00:30.260
Počeli smo sa primenom različitih tehnologija

00:00:30.260 --> 00:00:34.260
koje su zajedno primenjene kod ovih robota sa karakterom koji govore,

00:00:34.260 --> 00:00:36.260
koji mogu videti lica, uspostavljaju konakt očima sa vama,

00:00:36.260 --> 00:00:39.260
ispoljavaju puni spektar facijalnih ekspresija, razumeju govor

00:00:39.260 --> 00:00:43.260
i počinju da modeluju kako se osećate

00:00:43.260 --> 00:00:46.260
i ko ste vi, i mogu da izgrade odnos sa vama.

00:00:46.260 --> 00:00:48.260
Razvio sam čitav serijal tehnologija

00:00:48.260 --> 00:00:51.260
koje omogućuju ovim robotima da prave uverljivije izraze lica

00:00:51.260 --> 00:00:53.260
u odnosu na ranije postignute, uz manje energije,

00:00:53.260 --> 00:00:57.260
koji je omogućio robotima da hodaju na dve noge, to su prvi androidi.

00:00:57.260 --> 00:00:59.260
Tako da pričamo o punom spektru izraza lica

00:00:59.260 --> 00:01:01.260
koji simuliraju glavne mišiće ljudskog lica,

00:01:01.260 --> 00:01:03.260
a napajaju se veoma malim baterijama

00:01:03.260 --> 00:01:05.260
neverovatno lake težine.

00:01:05.260 --> 00:01:08.260
Materijal koji je omogućio da uspostavimo ove facijalne ekspresije kojim

00:01:08.260 --> 00:01:10.260
upravljaju baterije nazivamo "Frubber",

00:01:10.260 --> 00:01:12.260
i u njemu su satkana tri glavna izuma

00:01:12.260 --> 00:01:14.260
koji omogućavaju da se to desi.

00:01:14.260 --> 00:01:16.260
Pre svega, hijerarhija pora,

00:01:16.260 --> 00:01:20.260
i druga stvar su makro-molekularne nanomreže poroznsoti u materijalu.

00:01:20.260 --> 00:01:23.260
Ovde počinje da korača.

00:01:23.260 --> 00:01:26.260
Ovo se dešava na Institutu za naprednu nauku i tehnologiju u Koreji.

00:01:26.260 --> 00:01:30.260
Ja sam napravio glavu. Oni su napravili telo.

00:01:30.260 --> 00:01:33.260
Naš cilj je da osposobimo mašine da osećaju

00:01:33.260 --> 00:01:37.260
i ne samo da osećaju, već i da saosećaju.

00:01:37.260 --> 00:01:39.260
Sarađujemo sa laboratorijom koja se bavi percepcijom kod mašina

00:01:39.260 --> 00:01:41.260
na Univerzitetu Kalifornije u San Dijegu.

00:01:41.260 --> 00:01:44.260
Oni poseduju zadivljujuću tehnologiju kontrole facijalne ekspresije

00:01:44.260 --> 00:01:46.260
pomoću koje je moguće prepoznati izraze lica,

00:01:46.260 --> 00:01:48.260
tip izraza lica koje ispoljavate.

00:01:48.260 --> 00:01:51.260
Takođe uočava šta posmatrate, položaj vaše glave.

00:01:51.260 --> 00:01:53.260
Mi oponašamo glavne izraze lica

00:01:53.260 --> 00:01:55.260
a potom ih uz pomoć softvera kontrolišemo,

00:01:55.260 --> 00:01:57.260
a to nazivamo "Mašina sa karakterom".

00:01:57.260 --> 00:02:01.260
Ovo je mali prikaz tehnologije koju za to koristimo.

00:02:01.260 --> 00:02:09.260
U stvari, sada ćemo da ga uključimo ovde, pa uključimo tamo,

00:02:09.260 --> 00:02:12.260
i videćemo da li uočava moj izraz lica.

00:02:12.260 --> 00:02:17.260
Okej. Smešim se.

00:02:17.260 --> 00:02:19.260
(smeh)

00:02:19.260 --> 00:02:21.260
Sada se mrštim.

00:02:21.260 --> 00:02:25.260
Ovo je snažno osvetljeno od pozadi.

00:02:25.260 --> 00:02:27.260
Okej, idemo.

00:02:27.260 --> 00:02:29.260
Ah, tako je tužno.

00:02:29.260 --> 00:02:32.260
Okej, smešiš se, mrštiš.

00:02:32.260 --> 00:02:34.260
Njegova percepcija vašeg emotivnog stanja

00:02:34.260 --> 00:02:38.260
je veoma značajna kako bi mašine postale efektivno empatične.

00:02:38.260 --> 00:02:41.260
Mašine postaju nezamislivo vešte u

00:02:41.260 --> 00:02:45.260
ubijanju. Zar ne?

00:02:45.260 --> 00:02:47.260
Kod takvih mašina nema mesta za empatiju.

00:02:47.260 --> 00:02:49.260
Trošimo milijarde dolara na to.

00:02:49.260 --> 00:02:51.260
Robotika sa karakterom može utrti put za razvoj

00:02:51.260 --> 00:02:53.260
robota koji zaista saosećaju.

00:02:53.260 --> 00:02:55.260
Ukoliko dosegnu ljudski nivo inteligencije,

00:02:55.260 --> 00:02:59.260
ili, što je verovatno, premaše ljudski nivo inteligencije,

00:02:59.260 --> 00:03:02.260
to bi moglo da bude seme nade za budućnost.

00:03:02.260 --> 00:03:06.260
U toku poslednjih osam godina, za vreme izrade mog doktorata, napravili smo 20 robota.

00:03:06.260 --> 00:03:08.260
Potom sam osnovao firmu Henson Robotika,

00:03:08.260 --> 00:03:12.260
koja se bavi razvojem ovih stvari za masovnu proizvodnju.

00:03:12.260 --> 00:03:14.260
Ovo je jedan od naših robota kog

00:03:14.260 --> 00:03:16.260
smo prikazali na "Wired NextFest" manifestaciji pre dve godine.

00:03:16.260 --> 00:03:19.260
Ono vidi mnogo ljudi na sceni,

00:03:19.260 --> 00:03:21.260
pamti gde su pojedine osobe,

00:03:21.260 --> 00:03:25.260
i posmatra i pamti osobu po osobu.

00:03:25.260 --> 00:03:27.260
Uključujemo tu dve stvari.

00:03:27.260 --> 00:03:29.260
Pod jedan, uočavanje ljudi

00:03:29.260 --> 00:03:33.260
i pod dva, prirodni izgled uređaja,

00:03:33.260 --> 00:03:35.260
izgled prirodnog oblika,

00:03:35.260 --> 00:03:38.260
kako bi vam bilo prirodnije da imate interakciju sa robotom.

00:03:38.260 --> 00:03:41.260
Počinjete da verujete da je živ i svestan.

00:03:41.260 --> 00:03:44.260
Jedan od mojih omiljenih projekata je za zadatak imao da sve ovo spoji

00:03:44.260 --> 00:03:47.260
u umetničkom prikazu portreta androida

00:03:47.260 --> 00:03:49.260
u liku pisca naučne fantastike Filipa K. Dika,

00:03:49.260 --> 00:03:52.260
on je napisao dela kao što je "Da li androidi sanjaju o električnim ovcama?"

00:03:52.260 --> 00:03:54.260
po kom je snimljen film "Bladerunner".

00:03:54.260 --> 00:03:57.260
Često u ovim pričama robot

00:03:57.260 --> 00:03:59.260
misli da je ljudsko biće, i na neki način roboti ožive.

00:03:59.260 --> 00:04:02.260
Tako da smo od njegovih pisanih dela, pisama,

00:04:02.260 --> 00:04:05.260
intervjua, prepiski,

00:04:05.260 --> 00:04:07.260
napravili ogormnu bazu podataka od hiljada stranica,

00:04:07.260 --> 00:04:09.260
a potom smo primenili prirodni procesor jezika

00:04:09.260 --> 00:04:11.260
kako bismo vam omogućili da vodite razgovor sa njim.

00:04:11.260 --> 00:04:13.260
Bilo je zastrašujuće na neki način, jer stvari koje je izgovarao su

00:04:13.260 --> 00:04:16.260
zvučale kao da vas je zaista razumeo.

00:04:16.260 --> 00:04:19.260
Ovo je jedan od najuzbudljivijih projekata koje razvijamo,

00:04:19.260 --> 00:04:22.260
a to je robot koji priča, mališan

00:04:22.260 --> 00:04:25.260
koji predstavlja prijateljsku, veštačku inteligenciju, prijateljsku, inteligentnu mašinu.

00:04:25.260 --> 00:04:27.260
Mi ovo masovno proizvodimo.

00:04:27.260 --> 00:04:30.260
Pojednostavili smo proces tako da možemo to da napravimo

00:04:30.260 --> 00:04:33.260
od veoma jeftinog materijala,

00:04:33.260 --> 00:04:37.260
pa može postati prijatelj u detinjstvu.

00:04:37.260 --> 00:04:40.260
Komunicira sa internetom, postaje pametniji kako godine prolaze.

00:04:40.260 --> 00:04:43.260
Njegova inteligencija evoluira sa evolucijom veštačke inteligencije.

00:04:43.260 --> 00:04:45.260
Kris Anderson: Hvala puno. Ovo je neverovatno.

00:04:45.260 --> 00:04:52.260
(aplauz)

