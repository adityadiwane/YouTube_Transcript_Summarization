WEBVTT
Kind: captions
Language: fr-CA

00:00:00.000 --> 00:00:07.000
Translator: Chantale Marchand
Reviewer: Pascal GANAYE

00:00:16.260 --> 00:00:19.260
Je suis David Hanson et je fabrique des robots dotés de personnalité,

00:00:19.260 --> 00:00:21.260
c'est-à-dire

00:00:21.260 --> 00:00:23.260
des robots qui sont des personnages,

00:00:23.260 --> 00:00:26.260
mais a terme

00:00:26.260 --> 00:00:28.260
pourront sympathiser avec vous.

00:00:28.260 --> 00:00:30.260
Un éventail de technologies,

00:00:30.260 --> 00:00:34.260
nous en sommes donc arrivés à ces robots capables de converser

00:00:34.260 --> 00:00:36.260
qui voient les visages, établissent un contact visuel,

00:00:36.260 --> 00:00:39.260
reproduisent des expressions faciales variées, comprennent votre voix

00:00:39.260 --> 00:00:43.260
commencent à recentir vos émotions,

00:00:43.260 --> 00:00:46.260
qui vous êtes, et sympathiser avec vous.

00:00:46.260 --> 00:00:48.260
J'ai mis au point une série de technologies

00:00:48.260 --> 00:00:51.260
permettant aux robots d'adopter des expressions faciales plus réalistes

00:00:51.260 --> 00:00:53.260
que jamais, en utilisant moins d'énergie.

00:00:53.260 --> 00:00:57.260
Ceci a permis les premiers robots bipèdes qui marchent, les premiers androïdes.

00:00:57.260 --> 00:00:59.260
Une gamme complete d'expressions faciales

00:00:59.260 --> 00:01:01.260
simule les principaux muscles du visage humain,

00:01:01.260 --> 00:01:03.260
fonctionnant avec de très petites batteries,

00:01:03.260 --> 00:01:05.260
extrêmement légères.

00:01:05.260 --> 00:01:08.260
Le matériau qui rendu possibles ces expressions faciales

00:01:08.260 --> 00:01:10.260
s'appele le Frubber.

00:01:10.260 --> 00:01:12.260
Il y a trois innovations majeures

00:01:12.260 --> 00:01:14.260
dans le matériau.

00:01:14.260 --> 00:01:16.260
Notamment les pores hiérarchiques

00:01:16.260 --> 00:01:20.260
Et aussi la nanoporosité macromoléculaire du matériau.

00:01:20.260 --> 00:01:23.260
Nous le voyons ici qui commence à marcher.

00:01:23.260 --> 00:01:26.260
Ça se passe à l'Institut des sciences et des technologies avancées de Corée.

00:01:26.260 --> 00:01:30.260
J'ai construit la tête; ils ont fabriqué le corps.

00:01:30.260 --> 00:01:33.260
Le but ici est donc de doter les machines de perception,

00:01:33.260 --> 00:01:37.260
et non seulement de perception, mais également d'empathie.

00:01:37.260 --> 00:01:39.260
Nous travaillons avec le Laboratoire de perception machine

00:01:39.260 --> 00:01:41.260
de l'Université de San Diego.

00:01:41.260 --> 00:01:44.260
Ils possèdent cette technologie remarquable pour les expressions faciales;

00:01:44.260 --> 00:01:46.260
qui reconnaît les expressions faciales,

00:01:46.260 --> 00:01:48.260
les expressions que vous faites.

00:01:48.260 --> 00:01:51.260
La machine peut savoir où vous regardez et déterminer la direction de votre tête.

00:01:51.260 --> 00:01:53.260
Toutes les principales expressions faciales peuvent être émulées

00:01:53.260 --> 00:01:55.260
et contrôlées à l'aide du logiciel

00:01:55.260 --> 00:01:57.260
que l'on appelle le "moteur de personnalité".

00:01:57.260 --> 00:02:01.260
Voici un aperçu de cette technologie.

00:02:01.260 --> 00:02:09.260
En fait, voyons ça maintenant -- branchons à partir d'ici, puis là-dedans.

00:02:09.260 --> 00:02:12.260
Voyons s'il peut reconnaître mes expressions faciales.

00:02:12.260 --> 00:02:17.260
Bon. Alors, je souris.

00:02:17.260 --> 00:02:19.260
(Rires)

00:02:19.260 --> 00:02:21.260
Maintenant, je fronce les sourcils.

00:02:21.260 --> 00:02:25.260
C'est très rétroéclairé.

00:02:25.260 --> 00:02:27.260
Bon, on y va.

00:02:27.260 --> 00:02:29.260
Ah! comme c'est triste.

00:02:29.260 --> 00:02:32.260
D'accord, souriez, froncez les sourcils.

00:02:32.260 --> 00:02:34.260
La perception de vos états émotifs

00:02:34.260 --> 00:02:38.260
est donc très importante pour que les machines deviennent empathiques.

00:02:38.260 --> 00:02:41.260
Les machines sont de plus en plus capables de détruire,

00:02:41.260 --> 00:02:45.260
de tuer même, n'est-ce pas?

00:02:45.260 --> 00:02:47.260
Des machines de ce genre ne possèdent aucune empathie.

00:02:47.260 --> 00:02:49.260
Et on dépense pourtant des milliards de dollars pour ça.

00:02:49.260 --> 00:02:51.260
La robotique de personnalité pourrait être à l'origine

00:02:51.260 --> 00:02:53.260
de robots qui seront empathiques.

00:02:53.260 --> 00:02:55.260
Si ces robots atteignent un jour un niveau d'intelligence humain,

00:02:55.260 --> 00:02:59.260
ou, très probablement, supérieur à celui des humains,

00:02:59.260 --> 00:03:02.260
cette capacité pourrait représenter une lueur d'espoir pour notre futur.

00:03:02.260 --> 00:03:06.260
Nous avons donc construit 20 robots au cours des vingt dernières années, pendant mes études de doctorat.

00:03:06.260 --> 00:03:08.260
J'ai créé par la suite Hanson Robotics

00:03:08.260 --> 00:03:12.260
qui développe ces machines pour la fabrication en série.

00:03:12.260 --> 00:03:14.260
Voici un des robots

00:03:14.260 --> 00:03:16.260
que nous avons présentés au Wired NextFest il y a quelques années.

00:03:16.260 --> 00:03:19.260
Il voit plusieurs personnes dans une scène,

00:03:19.260 --> 00:03:21.260
se souvient de leur place,

00:03:21.260 --> 00:03:25.260
regarde de l'une à l'autre en se souvenant de chacune d'elles.

00:03:25.260 --> 00:03:27.260
Il y a donc deux éléments importants ici, soit:

00:03:27.260 --> 00:03:29.260
la perception des gens

00:03:29.260 --> 00:03:33.260
et l'interface naturelle,

00:03:33.260 --> 00:03:35.260
la forme naturelle de l'interface

00:03:35.260 --> 00:03:38.260
qui permet d'interagir de façon plus intuitive avec le robot.

00:03:38.260 --> 00:03:41.260
Avec le temps, vous commencez à croire qu'il est vivant et conscient.

00:03:41.260 --> 00:03:44.260
L'un de mes projets préférés est celui où j'ai combiné tout ca

00:03:44.260 --> 00:03:47.260
lors d'une exposition artistique de l'androïde

00:03:47.260 --> 00:03:49.260
de l'auteur de science-fiction Philip K. Dick,

00:03:49.260 --> 00:03:52.260
qui a écrit de grandes oeuvres comme "Les androïdes rêvent-ils de moutons électriques?",

00:03:52.260 --> 00:03:54.260
la nouvelle à l'origine du film "Bladerunner".

00:03:54.260 --> 00:03:57.260
Dans ce genre d'histoires, les robots pensent souvent

00:03:57.260 --> 00:03:59.260
qu'ils sont humains et ils le deviennent en quelque sorte.

00:03:59.260 --> 00:04:02.260
Nous avons donc rassemblé ses écrits, ses lettres,

00:04:02.260 --> 00:04:05.260
ses entrevues et sa correspondance

00:04:05.260 --> 00:04:07.260
dans une immense base de données qui compte des milliers de pages.

00:04:07.260 --> 00:04:09.260
Nous avons ensuite utilisé un logiciel de traitement du langage naturel

00:04:09.260 --> 00:04:11.260
qui a permis d'avoir une conversation avec lui.

00:04:11.260 --> 00:04:13.260
Ça donnait des frissons parce qu'il disait des choses

00:04:13.260 --> 00:04:16.260
qui donnaient l'impression qu'il vous comprenait vraiment.

00:04:16.260 --> 00:04:19.260
Voici un des projets les plus excitants sur lequels nous travaillons.

00:04:19.260 --> 00:04:22.260
C'est un petit personnage, un robot conversationnel

00:04:22.260 --> 00:04:25.260
pour l'intelligence artificielle amicale, l'intelligence robot amicale.

00:04:25.260 --> 00:04:27.260
Il sera produit en série.

00:04:27.260 --> 00:04:30.260
Ses spécifications nous permettent de le fabriquer

00:04:30.260 --> 00:04:33.260
avec un coût de matériaux vraiment très bas.

00:04:33.260 --> 00:04:37.260
Il peut ainsi devenir un compagnon de jeu pour les enfants.

00:04:37.260 --> 00:04:40.260
Comme il est interfacé avec Internet, il devient plus intelligent avec les années.

00:04:40.260 --> 00:04:43.260
Son intelligence grandit au fur et à mesure que l'intelligence artificielle évolue.

00:04:43.260 --> 00:04:45.260
Chris Anderson : Merci infiniment. C'est incroyable.

00:04:45.260 --> 00:04:52.260
(Applaudissements)

