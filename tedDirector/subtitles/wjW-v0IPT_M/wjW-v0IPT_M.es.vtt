WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Nerea Llopis
Revisor: Andrea Gigliani

00:00:16.260 --> 00:00:19.260
Soy el Dr. David Hanson y construyo robots con personalidad.

00:00:19.260 --> 00:00:21.260
Y con eso quiero decir

00:00:21.260 --> 00:00:23.260
que desarrollo robots que son personajes,

00:00:23.260 --> 00:00:26.260
pero también robots que con el tiempo

00:00:26.260 --> 00:00:28.260
establecerán lazos de empatía contigo.

00:00:28.260 --> 00:00:30.260
Empezamos con una variedad de tecnologías

00:00:30.260 --> 00:00:34.260
que han convergido en estos robots personajes conversacionales

00:00:34.260 --> 00:00:36.260
que ven rostros, establecen contacto visual contigo,

00:00:36.260 --> 00:00:39.260
tienen un rango completo de expresiones faciales, entienden el habla,

00:00:39.260 --> 00:00:43.260
y comienzan a modelar cómo te sientes,

00:00:43.260 --> 00:00:46.260
y quién eres, y construyen una relación contigo.

00:00:46.260 --> 00:00:48.260
He desarrollado una serie de tecnologías

00:00:48.260 --> 00:00:51.260
que permiten a los robots realizar expresiones faciales más realistas

00:00:51.260 --> 00:00:53.260
que antes, con menos energía,

00:00:53.260 --> 00:00:57.260
lo que posibilitó la existencia de los robots bípedos andantes, los primeros androides.

00:00:57.260 --> 00:00:59.260
Es un rango completo de expresiones faciales

00:00:59.260 --> 00:01:01.260
que simulan los principales músculos del rostro humano,

00:01:01.260 --> 00:01:03.260
funciona con unas baterías muy pequeñas,

00:01:03.260 --> 00:01:05.260
extremadamente ligeras.

00:01:05.260 --> 00:01:08.260
Los materiales que permitieron las expresiones faciales mediante baterías

00:01:08.260 --> 00:01:10.260
es un material que llamamos Frubber,

00:01:10.260 --> 00:01:12.260
y el material tiene tres innovaciones principales

00:01:12.260 --> 00:01:14.260
que permiten que esto suceda.

00:01:14.260 --> 00:01:16.260
Una son los poros jerárquicos.

00:01:16.260 --> 00:01:20.260
Y la otra es una porosidad macromolecular a escala nanométrica en el material.

00:01:20.260 --> 00:01:23.260
Ahí está empezando a caminar.

00:01:23.260 --> 00:01:26.260
Esto es en el Instituto Avanzado de Ciencia y Tecnología de Corea.

00:01:26.260 --> 00:01:30.260
Yo hice la cabeza. Ellos hicieron el cuerpo.

00:01:30.260 --> 00:01:33.260
El objetivo aquí es conseguir percepción en las máquinas,

00:01:33.260 --> 00:01:37.260
y no sólo percepción, sino también empatía.

00:01:37.260 --> 00:01:39.260
Estamos trabajando con el Laboratorio de Percepción de las Máquinas

00:01:39.260 --> 00:01:41.260
de la Universidad de San Diego.

00:01:41.260 --> 00:01:44.260
Tienen una extraordinaria tecnología de expresión facial

00:01:44.260 --> 00:01:46.260
que reconoce expresiones faciales,

00:01:46.260 --> 00:01:48.260
qué expresiones faciales estás haciendo.

00:01:48.260 --> 00:01:51.260
También reconoce dónde estás mirando, la orientación de tu cabeza.

00:01:51.260 --> 00:01:53.260
Estamos emulando las principales expresiones faciales,

00:01:53.260 --> 00:01:55.260
y luego las controlamos con el software

00:01:55.260 --> 00:01:57.260
que llamamos el Motor de Personalidad.

00:01:57.260 --> 00:02:01.260
Y aquí tenemos parte de la tecnología implicada en ese proceso.

00:02:01.260 --> 00:02:09.260
De hecho, ahora mismo, lo enchufamos aquí, y luego aquí,

00:02:09.260 --> 00:02:12.260
y vamos a ver si reconoce mis expresiones faciales.

00:02:12.260 --> 00:02:17.260
Vale. Estoy sonriendo.

00:02:17.260 --> 00:02:19.260
(Risas)

00:02:19.260 --> 00:02:21.260
Ahora estoy enfadado.

00:02:21.260 --> 00:02:25.260
Y estamos a contraluz.

00:02:25.260 --> 00:02:27.260
Vale, vamos allá.

00:02:27.260 --> 00:02:29.260
Ay, qué triste.

00:02:29.260 --> 00:02:32.260
Vale, sonríes, enfadado.

00:02:32.260 --> 00:02:34.260
Su percepción de tus estados emocionales

00:02:34.260 --> 00:02:38.260
es muy importante para que las máquinas muestren empatía de forma eficaz.

00:02:38.260 --> 00:02:41.260
Las máquinas se están volviendo totalmente capaces

00:02:41.260 --> 00:02:45.260
de cosas como matar. ¿Verdad?

00:02:45.260 --> 00:02:47.260
En esas máquinas no tiene sentido la empatía.

00:02:47.260 --> 00:02:49.260
Y se están gastando miles de millones de dólares en eso.

00:02:49.260 --> 00:02:51.260
La robótica de la personalidad podría plantar la semilla

00:02:51.260 --> 00:02:53.260
para que los robots mostraran empatía de verdad.

00:02:53.260 --> 00:02:55.260
Si obtienen una inteligencia al nivel humano

00:02:55.260 --> 00:02:59.260
o, muy posiblemente, niveles de inteligencia mayores que el humano,

00:02:59.260 --> 00:03:02.260
esto podría ser la semilla de esperanza para nuestro futuro.

00:03:02.260 --> 00:03:06.260
Hemos hecho 20 robots en los últimos ocho años, mientras obtenía mi Doctorado.

00:03:06.260 --> 00:03:08.260
Y luego creé Hanson Robotics,

00:03:08.260 --> 00:03:12.260
que se dedica a desarrollar estas cosas para su fabricación en serie.

00:03:12.260 --> 00:03:14.260
Este es uno de nuestros robots

00:03:14.260 --> 00:03:16.260
que mostramos en Wired NextFest hace un par de años.

00:03:16.260 --> 00:03:19.260
Y ve que hay varias personas en un lugar,

00:03:19.260 --> 00:03:21.260
recuerda dónde se encuentra cada individuo,

00:03:21.260 --> 00:03:25.260
y mira de persona a persona, recordando a la gente.

00:03:25.260 --> 00:03:27.260
Así que estamos mezclando dos cosas.

00:03:27.260 --> 00:03:29.260
Una, la percepción de la gente.

00:03:29.260 --> 00:03:33.260
Y dos, la interfaz natural,

00:03:33.260 --> 00:03:35.260
la forma natural de la interfaz,

00:03:35.260 --> 00:03:38.260
para que así resulte más intuitivo interactuar con el robot.

00:03:38.260 --> 00:03:41.260
Empiezas a creer que está vivo y es consciente de las cosas.

00:03:41.260 --> 00:03:44.260
Uno de mis proyectos favoritos fue juntar todo esto

00:03:44.260 --> 00:03:47.260
en una manifestación artística de un retrato androide

00:03:47.260 --> 00:03:49.260
del escritor de ciencia ficción Philip K. Dick,

00:03:49.260 --> 00:03:52.260
que escribió grandes obras como, "¿Sueñan los androides con ovejas eléctricas?",

00:03:52.260 --> 00:03:54.260
en la que se basó la película "Blade Runner".

00:03:54.260 --> 00:03:57.260
En estas historias, los robots a menudo piensan

00:03:57.260 --> 00:03:59.260
que son humanos. Y, de alguna forma, cobran vida.

00:03:59.260 --> 00:04:02.260
Pusimos sus escritos, cartas,

00:04:02.260 --> 00:04:05.260
sus entrevistas, correspondencia,

00:04:05.260 --> 00:04:07.260
en una base de datos enorme, con miles de páginas,

00:04:07.260 --> 00:04:09.260
y luego usamos un procesador de lenguaje natural

00:04:09.260 --> 00:04:11.260
que te permite tener una conversación con él.

00:04:11.260 --> 00:04:13.260
Y era espeluznante. Porque decía cosas

00:04:13.260 --> 00:04:16.260
que sonaban como si realmente te estuviera entendiendo.

00:04:16.260 --> 00:04:19.260
Y este es uno de los proyectos más emocionantes que estamos desarrollando,

00:04:19.260 --> 00:04:22.260
que es un personaje robot

00:04:22.260 --> 00:04:25.260
con inteligencia artificial amistosa, inteligencia amistosa de las máquinas.

00:04:25.260 --> 00:04:27.260
Y los estamos fabricando en serie.

00:04:27.260 --> 00:04:30.260
Lo hemos diseñado para que sea factible

00:04:30.260 --> 00:04:33.260
con un coste muy, muy bajo de materiales,

00:04:33.260 --> 00:04:37.260
para que se pueda convertir en un compañero para los niños.

00:04:37.260 --> 00:04:40.260
Al interactuar con Internet, se hace más listo con el paso de los años.

00:04:40.260 --> 00:04:43.260
Y con la evolución de la inteligencia artificial, también evoluciona su inteligencia.

00:04:43.260 --> 00:04:45.260
Chris Anderson: Muchísimas gracias. Es increíble.

00:04:45.260 --> 00:04:52.260
(Aplausos)

