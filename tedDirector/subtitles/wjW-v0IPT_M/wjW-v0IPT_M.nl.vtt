WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Els De Keyser
Nagekeken door: Christel Foncke

00:00:16.260 --> 00:00:19.260
Ik ben Dr. David Hanson, en ik bouw robots met karakter.

00:00:19.260 --> 00:00:21.260
Daarmee bedoel ik

00:00:21.260 --> 00:00:23.260
dat ik robots ontwerp die personages zijn,

00:00:23.260 --> 00:00:26.260
maar ook robots die uiteindelijk

00:00:26.260 --> 00:00:28.260
empathie met jou zullen voelen.

00:00:28.260 --> 00:00:30.260
We beginnen dus met een reeks van technologieën

00:00:30.260 --> 00:00:34.260
die zijn geconvergeerd naar conversatie-robotpersonages,

00:00:34.260 --> 00:00:36.260
die gezichten kunnen zien, oogcontact met je maken,

00:00:36.260 --> 00:00:39.260
een volledige reeks gelaatsuitdrukkingen kennen, spraak begrijpen,

00:00:39.260 --> 00:00:43.260
en een model beginnen te maken van jouw gevoelens,

00:00:43.260 --> 00:00:46.260
van wie je bent, en die een relatie met je opbouwen.

00:00:46.260 --> 00:00:48.260
Ik heb een reeks technologieën ontwikkeld

00:00:48.260 --> 00:00:51.260
waardoor de robots realistischer gelaatsuitdrukkingen kunnen hebben

00:00:51.260 --> 00:00:53.260
dan tevoren, met minder elektriciteit,

00:00:53.260 --> 00:00:57.260
waardoor we lopende tweevoeters kregen, de eerste androïden.

00:00:57.260 --> 00:00:59.260
Het is een volledig gamma gelaatsuitdrukkingen,

00:00:59.260 --> 00:01:01.260
die alle hoofdspieren in het menselijke gelaat nabootsen,

00:01:01.260 --> 00:01:03.260
en op zeer kleine batterijen werken,

00:01:03.260 --> 00:01:05.260
zeer licht van gewicht.

00:01:05.260 --> 00:01:08.260
Het materiaal dat de gelaatsuitdrukkingen op batterijen mogelijk maakte,

00:01:08.260 --> 00:01:10.260
is een materiaal dat we Frubber noemen.

00:01:10.260 --> 00:01:12.260
Het bevat drie grote innovaties

00:01:12.260 --> 00:01:14.260
in het materiaal die dit mogelijk maken.

00:01:14.260 --> 00:01:16.260
Eén ervan zijn hiërarchische poriën.

00:01:16.260 --> 00:01:20.260
Het andere is macromoleculaire nanoschaal-porositeit in het materiaal.

00:01:20.260 --> 00:01:23.260
Daar gaat hij lopen.

00:01:23.260 --> 00:01:26.260
Dit is aan het Koreaans Voortgezet Instituut voor Wetenschap en Technologie.

00:01:26.260 --> 00:01:30.260
Ik heb het hoofd gebouwd. Zij hebben het lichaam gebouwd.

00:01:30.260 --> 00:01:33.260
Het doel is om bewustzijn te bereiken bij machines,

00:01:33.260 --> 00:01:37.260
en meer nog dan bewustzijn, empathie.

00:01:37.260 --> 00:01:39.260
We werken samen met het Laboratorium voor Machineperceptie,

00:01:39.260 --> 00:01:41.260
aan de UC San Diego.

00:01:41.260 --> 00:01:44.260
Ze beschikken over merkwaardige gelaatsuitdrukkingstechnologie

00:01:44.260 --> 00:01:46.260
die gelaatsuitdrukkingen herkent,

00:01:46.260 --> 00:01:48.260
de uitdrukkingen op je gezicht.

00:01:48.260 --> 00:01:51.260
Het herkent ook waar je naar kijkt, de oriëntatie van je hoofd.

00:01:51.260 --> 00:01:53.260
We evenaren alle belangrijke gelaatsuitdrukkingen

00:01:53.260 --> 00:01:55.260
en controleren ze dan met de software

00:01:55.260 --> 00:01:57.260
die we de Karaktermotor noemen.

00:01:57.260 --> 00:02:01.260
Hier is een deel van de technologie die daarbij komt kijken.

00:02:01.260 --> 00:02:09.260
Op dit eigenste moment -- steek het hier in, en dan daar,

00:02:09.260 --> 00:02:12.260
en nu even kijken of het mijn gelaatsuitdrukking herkent.

00:02:12.260 --> 00:02:17.260
Oké. Ik ben aan het glimlachen.

00:02:17.260 --> 00:02:19.260
(Gelach)

00:02:19.260 --> 00:02:21.260
Nu frons ik.

00:02:21.260 --> 00:02:25.260
En hier staat zware belichting op.

00:02:25.260 --> 00:02:27.260
Daar gaan we.

00:02:27.260 --> 00:02:29.260
Het is zo droevig.

00:02:29.260 --> 00:02:32.260
Je glimlacht, je fronst.

00:02:32.260 --> 00:02:34.260
Zijn perceptie van je emotionele toestand

00:02:34.260 --> 00:02:38.260
is erg belangrijk opdat machines echt empatisch zouden worden.

00:02:38.260 --> 00:02:41.260
Machines worden verpletterend handig in dingen

00:02:41.260 --> 00:02:45.260
zoals moorden. Niet?

00:02:45.260 --> 00:02:47.260
Die machines hebben geen plaats voor empathie.

00:02:47.260 --> 00:02:49.260
Daar worden miljarden aan gespendeerd.

00:02:49.260 --> 00:02:51.260
Karakter-robotica zou het zaad kunnen planten

00:02:51.260 --> 00:02:53.260
voor robots die echt empathisch zijn.

00:02:53.260 --> 00:02:55.260
Als ze het niveau van menselijke intelligentie bereiken,

00:02:55.260 --> 00:02:59.260
of - dat is goed mogelijk - zouden overstijgen,

00:02:59.260 --> 00:03:02.260
dan zou dit het zaad van de hoop voor onze toekomst kunnen zijn.

00:03:02.260 --> 00:03:06.260
We hebben de afgelopen jaren 20 robots gemaakt, tijdens het behalen van mijn doctoraat.

00:03:06.260 --> 00:03:08.260
Vervolgens startte ik Hanson Robotics,

00:03:08.260 --> 00:03:12.260
dat deze dingen verder heeft ontwikkeld voor massaproductie.

00:03:12.260 --> 00:03:14.260
Dit is één van onze robots

00:03:14.260 --> 00:03:16.260
die we een paar jaar geleden hebben getoond op Wired NextFest.

00:03:16.260 --> 00:03:19.260
Het ziet meerdere mensen in een omgeving,

00:03:19.260 --> 00:03:21.260
onthoudt waar de individuen zich bevinden,

00:03:21.260 --> 00:03:25.260
kijkt van persoon naar persoon, onthoudt mensen.

00:03:25.260 --> 00:03:27.260
We betrekken er twee dingen bij.

00:03:27.260 --> 00:03:29.260
Eén: de perceptie van de mensen.

00:03:29.260 --> 00:03:33.260
Twee: de natuurlijke interface,

00:03:33.260 --> 00:03:35.260
de natuurlijke vorm van de interface,

00:03:35.260 --> 00:03:38.260
zodat het voor jou natuurlijker is om met de robot te interageren.

00:03:38.260 --> 00:03:41.260
Je begint te geloven dat de robot leeft en bewust is.

00:03:41.260 --> 00:03:44.260
Eén van mijn favoriete projecten was om dit alles samen te brengen

00:03:44.260 --> 00:03:47.260
in een artistieke voorstelling van een androïde portret

00:03:47.260 --> 00:03:49.260
van science fictionauteur Philip K. DIck,

00:03:49.260 --> 00:03:52.260
die geweldige werken schreef, zoals 'Dromen androids van elektrische schapen?',

00:03:52.260 --> 00:03:54.260
de basis van de film 'Bladerunner'.

00:03:54.260 --> 00:03:57.260
In deze verhalen denken robots vaak

00:03:57.260 --> 00:03:59.260
dat ze mensen zijn. Ze komen zo'n beetje tot leven.

00:03:59.260 --> 00:04:02.260
We hebben zijn geschriften, brieven,

00:04:02.260 --> 00:04:05.260
interviews, correspondenties

00:04:05.260 --> 00:04:07.260
in een gigantische database van duizenden pagina's gestopt,

00:04:07.260 --> 00:04:09.260
en dan wat natuurlijke taalverwerking gebruikt

00:04:09.260 --> 00:04:11.260
zodat je een echt gesprek met hem kan voeren.

00:04:11.260 --> 00:04:13.260
Het was spookachtig. Want hij zei dingen

00:04:13.260 --> 00:04:16.260
die klonken alsof hij je echt begreep.

00:04:16.260 --> 00:04:19.260
Dit is één van de spannendste projecten die we ontwikkelen,

00:04:19.260 --> 00:04:22.260
een klein personage dat een woordvoerder-robot is

00:04:22.260 --> 00:04:25.260
voor vriendelijke kunstmatige intelligentie.

00:04:25.260 --> 00:04:27.260
We gaan dit op grote schaal produceren.

00:04:27.260 --> 00:04:30.260
We hebben de specificaties gemaakt zodat het kan

00:04:30.260 --> 00:04:33.260
tegen een zeer lage materiaalkost,

00:04:33.260 --> 00:04:37.260
zodat het een vriendje kan worden voor kinderen.

00:04:37.260 --> 00:04:40.260
Er is een interface over het internet, en hij wordt slimmer met de jaren.

00:04:40.260 --> 00:04:43.260
Naarmate kunstmatige intelligentie evolueert, evolueert ook zijn intelligentie.

00:04:43.260 --> 00:04:45.260
Chris Anderson: Zeer hartelijk dank. Dat is ongelooflijk.

00:04:45.260 --> 00:04:52.260
(Applaus)

