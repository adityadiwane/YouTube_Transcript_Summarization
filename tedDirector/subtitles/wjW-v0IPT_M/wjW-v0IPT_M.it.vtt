WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Marianna Alboraci
Revisore: Giacomo Boschi

00:00:16.260 --> 00:00:19.260
Sono il dott. David Hanson e costruisco robot che hanno personalità.

00:00:19.260 --> 00:00:21.260
Con questo voglio dire

00:00:21.260 --> 00:00:23.260
che creo robot che sono personaggi,

00:00:23.260 --> 00:00:26.260
ma che con il tempo sono anche in grado

00:00:26.260 --> 00:00:28.260
di identificarsi con i nostri stati d'animo.

00:00:28.260 --> 00:00:30.260
Stiamo iniziando con una varietà di tecnologie

00:00:30.260 --> 00:00:34.260
che sono confluite in questi personaggi-robot conversazionali

00:00:34.260 --> 00:00:36.260
in grado di riconoscere le facce, stabilire un contatto visivo con noi,

00:00:36.260 --> 00:00:39.260
che hanno una gamma completa di espressioni facciali, capiscono discorsi

00:00:39.260 --> 00:00:43.260
e iniziano a modellare i nostri sentimenti

00:00:43.260 --> 00:00:46.260
e ciò che siamo, e costruiscono una relazione con noi.

00:00:46.260 --> 00:00:48.260
Ho sviluppato una serie di tecnologie

00:00:48.260 --> 00:00:51.260
che permettono ai robot di assumere espressioni facciali più realistiche

00:00:51.260 --> 00:00:53.260
che mai e con l'utilizzo di meno energia,

00:00:53.260 --> 00:00:57.260
ciò che ha reso possibile l'esistenza dei robot bipedi, i primi androidi.

00:00:57.260 --> 00:00:59.260
È una gamma completa di espressioni facciali

00:00:59.260 --> 00:01:01.260
che simula i principali muscoli del viso umano,

00:01:01.260 --> 00:01:03.260
funziona con batterie molto piccole,

00:01:03.260 --> 00:01:05.260
estremamente leggere.

00:01:05.260 --> 00:01:08.260
Ciò che ha reso possibile l'alimentazione a batteria delle espressioni facciali

00:01:08.260 --> 00:01:10.260
è un materiale che noi chiamiamo Frubber,

00:01:10.260 --> 00:01:12.260
ha infatti tre innovazioni principali

00:01:12.260 --> 00:01:14.260
che permettono che questo accada.

00:01:14.260 --> 00:01:16.260
Una è data dai pori gerarchici,

00:01:16.260 --> 00:01:20.260
l'altra è la porosità macromolecolare del materiale a scala nanometrica.

00:01:20.260 --> 00:01:23.260
Qui sta iniziando a camminare.

00:01:23.260 --> 00:01:26.260
Questo è l'Istituto Avanzato di Scienza e Tecnologia della Corea.

00:01:26.260 --> 00:01:30.260
Io ho creato la testa. Loro hanno costruito il corpo.

00:01:30.260 --> 00:01:33.260
Qui l'obiettivo è di raggiungere una sensibilità nelle macchine,

00:01:33.260 --> 00:01:37.260
non solo sensibilità, ma empatia.

00:01:37.260 --> 00:01:39.260
Stiamo lavorando con il Laboratorio di Percezione delle Macchine

00:01:39.260 --> 00:01:41.260
dell' Università di San Diego.

00:01:41.260 --> 00:01:44.260
Hanno una tecnologia di espressione facciale straordinaria

00:01:44.260 --> 00:01:46.260
che riconosce le espressioni del viso,

00:01:46.260 --> 00:01:48.260
le espressioni del viso che facciamo.

00:01:48.260 --> 00:01:51.260
Può anche capire dove stiamo guardando, la posizione della testa.

00:01:51.260 --> 00:01:53.260
Stiamo simulando le principali espressioni facciali,

00:01:53.260 --> 00:01:55.260
poi le controlliamo con un software

00:01:55.260 --> 00:01:57.260
che chiamiamo Motore di Personalità.

00:01:57.260 --> 00:02:01.260
Qui vediamo parte della tecnologia coinvolta in questo processo.

00:02:01.260 --> 00:02:09.260
Ora infatti lo collego qui, e poi qui...

00:02:09.260 --> 00:02:12.260
e vediamo se riconosce le espressioni del mio viso.

00:02:12.260 --> 00:02:17.260
Bene. Sto sorridendo.

00:02:17.260 --> 00:02:19.260
(Risate)

00:02:19.260 --> 00:02:21.260
Ora sono imbronciato.

00:02:21.260 --> 00:02:25.260
E siamo in controluce.

00:02:25.260 --> 00:02:27.260
Bene, andiamo.

00:02:27.260 --> 00:02:29.260
Oh, com'è triste.

00:02:29.260 --> 00:02:32.260
Bene. Stai sorridendo, ora sei imbronciato.

00:02:32.260 --> 00:02:34.260
La percezione che ha del nostro stato d'animo

00:02:34.260 --> 00:02:38.260
è molto importante affinché la macchina possa diventare empatica.

00:02:38.260 --> 00:02:41.260
Le macchine stanno diventando mostruosamente capaci

00:02:41.260 --> 00:02:45.260
di compiere azioni come uccidere. Giusto?

00:02:45.260 --> 00:02:47.260
Quei tipi di macchine non lasciano spazio all'empatia.

00:02:47.260 --> 00:02:49.260
Per quelle macchine vengono spesi miliardi di dollari.

00:02:49.260 --> 00:02:51.260
I robot con personalità potrebbero aprire la strada

00:02:51.260 --> 00:02:53.260
a robot in grado di provare realmente emozioni.

00:02:53.260 --> 00:02:55.260
Se riuscissero a raggiungere un livello d'intelligenza umana,

00:02:55.260 --> 00:02:59.260
o, cosa possibile, maggiore del livello d'intelligenza umana,

00:02:59.260 --> 00:03:02.260
questo aprirebbe una strada più felice per il futuro.

00:03:02.260 --> 00:03:06.260
Dunque... Abbiamo creato 20 robot negli ultimi 8 anni, durante il mio dottorato.

00:03:06.260 --> 00:03:08.260
Poi ho creato la Hanson Robotics,

00:03:08.260 --> 00:03:12.260
che ha sviluppato queste cose per la sua fabbricazione in serie.

00:03:12.260 --> 00:03:14.260
Questo è uno dei nostri robot

00:03:14.260 --> 00:03:16.260
che è stato mostrato al Wired NextFest due anni fa.

00:03:16.260 --> 00:03:19.260
Vede che ci sono più persone in un luogo,

00:03:19.260 --> 00:03:21.260
ricorda dove si trova la singola persona,

00:03:21.260 --> 00:03:25.260
e guarda da persona persona, ricordandosi delle singole persone.

00:03:25.260 --> 00:03:27.260
Ci stiamo mettendo all'opera per due cose.

00:03:27.260 --> 00:03:29.260
Una, la percezione delle persone.

00:03:29.260 --> 00:03:33.260
E due, l'interfaccia naturale,

00:03:33.260 --> 00:03:35.260
la forma naturale dell'interfaccia

00:03:35.260 --> 00:03:38.260
affinché l'interazione con il robot possa essere più intuitiva.

00:03:38.260 --> 00:03:41.260
Inizi a credere che sia vivo e cosciente.

00:03:41.260 --> 00:03:44.260
Uno dei miei progetti preferiti è stato quando abbiamo riassemblato tutto

00:03:44.260 --> 00:03:47.260
in un'esposizione artistica di un ritratto di un androide

00:03:47.260 --> 00:03:49.260
dello scrittore di fantascienza Philip K. Dick,

00:03:49.260 --> 00:03:52.260
che ha scritto ottime opere come "Ma gli androidi sognano pecore elettriche?",

00:03:52.260 --> 00:03:54.260
l'opera che ha ispirato il film "Bladerunner".

00:03:54.260 --> 00:03:57.260
In queste storie spesso i robot pensano

00:03:57.260 --> 00:03:59.260
di essere umani. E in qualche modo prendono vita.

00:03:59.260 --> 00:04:02.260
Abbiamo poi messo i suoi scritti, le lettere

00:04:02.260 --> 00:04:05.260
le sue interviste e la corrispondenza

00:04:05.260 --> 00:04:07.260
in un enorme database di migliaia di pagine,

00:04:07.260 --> 00:04:09.260
poi abbiamo utilizzato un processore di linguaggio naturale

00:04:09.260 --> 00:04:11.260
per permettere di avere una vera conversazione con lui.

00:04:11.260 --> 00:04:13.260
È stato da brividi. Perché diceva cose

00:04:13.260 --> 00:04:16.260
che suonavano come se riuscisse a capirti veramente.

00:04:16.260 --> 00:04:19.260
Ed ecco uno dei progetti più emozionanti che stiamo sviluppando,

00:04:19.260 --> 00:04:22.260
è un personaggio piccolo, un portaparole

00:04:22.260 --> 00:04:25.260
per una macchina dall'intelligenza artificiale amichevole.

00:04:25.260 --> 00:04:27.260
Lo stiamo per fabbricare in serie.

00:04:27.260 --> 00:04:30.260
Lo stiamo strutturando in modo che sia realizzabile

00:04:30.260 --> 00:04:33.260
con un costo molto, molto basso dei materiali,

00:04:33.260 --> 00:04:37.260
per renderlo un compagno di giochi per i bambini.

00:04:37.260 --> 00:04:40.260
Interfacciandosi a Internet, diventa più intelligente anno dopo anno.

00:04:40.260 --> 00:04:43.260
Con l'evoluzione dell'intelligenza artificiale, anche la sua intelligenza evolve.

00:04:43.260 --> 00:04:45.260
Chris Anderson: Grazie mille. E' incredibile.

00:04:45.260 --> 00:04:52.260
(Applausi)

