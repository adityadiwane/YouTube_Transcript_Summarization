WEBVTT
Kind: captions
Language: pl

00:00:00.000 --> 00:00:07.000
Tłumaczenie: Jacek Kubiak
Korekta: Przemysaw Baka

00:00:16.260 --> 00:00:19.260
Nazywam się dr David Hanson i buduję roboty z charakterem.

00:00:19.260 --> 00:00:21.260
Rozumiem przez to,

00:00:21.260 --> 00:00:23.260
że tworzę roboty, które są charakterystycznymi postaciami

00:00:23.260 --> 00:00:26.260
lecz również roboty, które w końcowym etapie

00:00:26.260 --> 00:00:28.260
będą wykazywały się ludzką empatią.

00:00:28.260 --> 00:00:30.260
Zaczęliśmy pracę nad różnymi technologiami,

00:00:30.260 --> 00:00:34.260
a następnie wykorzystaliśmy je przy tych konwersacyjnych robotach,

00:00:34.260 --> 00:00:36.260
które widzą twarze, utrzymują kontakt wzrokowy,

00:00:36.260 --> 00:00:39.260
posiadają cały wachlarz min, rozumieją mowę,

00:00:39.260 --> 00:00:43.260
zaczynają budować schematy tego co czujesz

00:00:43.260 --> 00:00:46.260
i kim jesteś, budują z tobą więź.

00:00:46.260 --> 00:00:48.260
Opracowałem szereg technologii

00:00:48.260 --> 00:00:51.260
pozwalających robotom na bardziej realistyczne ruchy twarzy

00:00:51.260 --> 00:00:53.260
niż kiedykolwiek wcześniej, przy mniejszym zużyciu energii,

00:00:53.260 --> 00:00:57.260
co umożliwiło pracę nad dwunożnymi, chodzącymi robotami, pierwszymi androidami.

00:00:57.260 --> 00:00:59.260
Mamy więc pełny wachlarz ludzkich min

00:00:59.260 --> 00:01:01.260
symulujących większość głównych mięśni ludzkiej twarzy,

00:01:01.260 --> 00:01:03.260
zasilanych bardzo małymi bateriami,

00:01:03.260 --> 00:01:05.260
niezwykle lekkimi.

00:01:05.260 --> 00:01:08.260
Materiał, który umożliwił robienie min zasilanych przez baterie

00:01:08.260 --> 00:01:10.260
jest materiałem, który nazywamy "Frubber" (ang. rubber - guma)

00:01:10.260 --> 00:01:12.260
i wprowadza trzy spore innowacje

00:01:12.260 --> 00:01:14.260
jeżeli chodzi o użyty materiał.

00:01:14.260 --> 00:01:16.260
Jedna z nich to hierarchiczny układ porów.

00:01:16.260 --> 00:01:20.260
Kolejna to makro-molekularna nano porowatość materiału.

00:01:20.260 --> 00:01:23.260
Tutaj zaczyna chodzić.

00:01:23.260 --> 00:01:26.260
To jest w Koreańskim Instytucie Nauki i Technologii (ang. KAIST)

00:01:26.260 --> 00:01:30.260
Ja zbudowałem głowę, oni ciało.

00:01:30.260 --> 00:01:33.260
Celem jest zbudowanie maszyny, która odbiera świat zmysłami,

00:01:33.260 --> 00:01:37.260
ale nie tylko to, również takiej, która posiada empatię.

00:01:37.260 --> 00:01:39.260
Pracujemy z Laboratorium Percepcji Maszyn.

00:01:39.260 --> 00:01:41.260
na University of California w San Diego.

00:01:41.260 --> 00:01:44.260
Posiadają tam naprawdę wspaniałą technologię mimiki twarzy,

00:01:44.260 --> 00:01:46.260
która rozpoznaje miny,

00:01:46.260 --> 00:01:48.260
jakie robisz w danym momencie.

00:01:48.260 --> 00:01:51.260
Potrafi określić też gdzie patrzysz i jak masz ułożoną głowę.

00:01:51.260 --> 00:01:53.260
Generujemy wszystkie charakterystyczne wyrazy twarzy,

00:01:53.260 --> 00:01:55.260
a następnie kontrolujemy za pomocą oprogramowania,

00:01:55.260 --> 00:01:57.260
które nazywamy Silnikiem Charakteru (ang. Character Engine).

00:01:57.260 --> 00:02:01.260
Tu widzimy odrobinę zaangażowanej w to technologii.

00:02:01.260 --> 00:02:09.260
W zasadzie możemy teraz... podłączamy tutaj...i teraz tutaj,

00:02:09.260 --> 00:02:12.260
zobaczmy teraz czy odczyta mój wyraz twarzy.

00:02:12.260 --> 00:02:17.260
Więc, teraz się uśmiecham.

00:02:17.260 --> 00:02:19.260
(śmiech)

00:02:19.260 --> 00:02:21.260
Teraz robię niezadowoloną minę.

00:02:21.260 --> 00:02:25.260
Jest naprawdę mocno podświetlony.

00:02:25.260 --> 00:02:27.260
No dobrze, jedziemy.

00:02:27.260 --> 00:02:29.260
Och, jest taki smutny.

00:02:29.260 --> 00:02:32.260
OK, więc się uśmiechasz, jesteś niezadowolony.

00:02:32.260 --> 00:02:34.260
Tak więc percepcja naszych stanów emocjonalnych

00:02:34.260 --> 00:02:38.260
jest dla maszyn bardzo ważnym elementem w wytworzeniu empatii.

00:02:38.260 --> 00:02:41.260
Maszyny stają się zatrważająco zdolne

00:02:41.260 --> 00:02:45.260
do rzeczy takich jak zabijanie. Prawda?

00:02:45.260 --> 00:02:47.260
W tych maszynach nie ma miejsca na empatię.

00:02:47.260 --> 00:02:49.260
I wydaje się na to miliardy dolarów.

00:02:49.260 --> 00:02:51.260
Roboty z charakterem mogą zasiać ziarno,

00:02:51.260 --> 00:02:53.260
z którego powstaną roboty z rzeczywistą empatią.

00:02:53.260 --> 00:02:55.260
Jeśli więc osiągną poziom ludzkiej inteligencji

00:02:55.260 --> 00:02:59.260
lub też prawdopodobnie poziom inteligencji wyższy od ludzkiej,

00:02:59.260 --> 00:03:02.260
może to być ziarno nadziei na naszą przyszłość.

00:03:02.260 --> 00:03:06.260
Zrobiliśmy więc 20 robotów w ciągu ostatnich 8 lat, kiedy to zdobywałem stopień doktora.

00:03:06.260 --> 00:03:08.260
Następnie założyłem firmę Hanson Robotics,

00:03:08.260 --> 00:03:12.260
która tworzy takie rzeczy na skale przemysłową.

00:03:12.260 --> 00:03:14.260
To jeden z naszych robotów,

00:03:14.260 --> 00:03:16.260
którego pokazaliśmy na Wired NextFest parę lat temu.

00:03:16.260 --> 00:03:19.260
Widzi różnych ludzi na scenie,

00:03:19.260 --> 00:03:21.260
zapamiętuje gdzie są poszczególne osoby

00:03:21.260 --> 00:03:25.260
i patrząc po ludziach zapamiętuje ich.

00:03:25.260 --> 00:03:27.260
Tak więc wykorzystujemy tu dwie rzeczy.

00:03:27.260 --> 00:03:29.260
Postrzeganie ludzi

00:03:29.260 --> 00:03:33.260
oraz naturalny interfejs,

00:03:33.260 --> 00:03:35.260
naturalną formę interfejsu,

00:03:35.260 --> 00:03:38.260
żeby interakcja z robotem przebiegała bardziej intuicyjnie.

00:03:38.260 --> 00:03:41.260
Zaczynasz wtedy wierzyć, że jest czymś żywym i świadomym.

00:03:41.260 --> 00:03:44.260
Jednym z moich ulubionych projektów było połączenie tego wszystkiego

00:03:44.260 --> 00:03:47.260
w androidzie, który był portretem na wystawie artystycznej.

00:03:47.260 --> 00:03:49.260
Portretem pisarza science-fiction Phillip'a K. Dick'a,

00:03:49.260 --> 00:03:52.260
który napisał tak wspaniałe dzieła jak "Czy androidy śnią o elektrycznych owcach?",

00:03:52.260 --> 00:03:54.260
na którego podstawie nakręcono film "Łowca Androidów" (ang. Bladerunner).

00:03:54.260 --> 00:03:57.260
W tych opowiadaniach roboty często myślą,

00:03:57.260 --> 00:03:59.260
że są ludźmi. I jakby ożywają.

00:03:59.260 --> 00:04:02.260
Włożyliśmy więc jego dzieła, listy,

00:04:02.260 --> 00:04:05.260
wywiady, korespondencję,

00:04:05.260 --> 00:04:07.260
do wielkiej bazy danych,

00:04:07.260 --> 00:04:09.260
i użyliśmy pewnego naturalnego procesora mowy,

00:04:09.260 --> 00:04:11.260
który umożliwił przeprowadzenie rzeczywistej rozmowy z autorem.

00:04:11.260 --> 00:04:13.260
I było to nawet odrobinę przerażające. Ponieważ rozmowa wyglądała tak

00:04:13.260 --> 00:04:16.260
jakby on rzeczywiście wiedział i rozumiał co się do niego mówi.

00:04:16.260 --> 00:04:19.260
A to jeden z najbardziej ekscytujących projektów nad jakimi pracujemy.

00:04:19.260 --> 00:04:22.260
Jest to mała mówiąca robopostać.

00:04:22.260 --> 00:04:25.260
Ma przyjaźnie nastawioną sztuczną inteligencję.

00:04:25.260 --> 00:04:27.260
I będziemy je produkować masowo.

00:04:27.260 --> 00:04:30.260
Jesteśmy w stanie wyprodukować go

00:04:30.260 --> 00:04:33.260
naprawdę tanim kosztem,

00:04:33.260 --> 00:04:37.260
żeby mógł zostać dziecięcym kompanem.

00:04:37.260 --> 00:04:40.260
Interfejs połączony z internetem umożliwia jego uczenie się przez lata.

00:04:40.260 --> 00:04:43.260
W miarę rozwoju sztucznej inteligencji, jego inteligencja również będzie się rozwijać.

00:04:43.260 --> 00:04:45.260
Chris Anderson: Dziękujemy bardzo. To niesamowite.

00:04:45.260 --> 00:04:52.260
(oklaski)

