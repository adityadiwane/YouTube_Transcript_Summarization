WEBVTT
Kind: captions
Language: en

00:00:12.708 --> 00:00:16.462
Chris Anderson: Hello.
Welcome to this TED Dialogues.

00:00:16.486 --> 00:00:20.073
It's the first of a series
that's going to be done

00:00:20.097 --> 00:00:23.409
in response to the current
political upheaval.

00:00:24.085 --> 00:00:25.254
I don't know about you;

00:00:25.278 --> 00:00:28.889
I've become quite concerned about
the growing divisiveness in this country

00:00:28.913 --> 00:00:30.409
and in the world.

00:00:30.433 --> 00:00:32.793
No one's listening to each other. Right?

00:00:33.384 --> 00:00:34.547
They aren't.

00:00:34.571 --> 00:00:38.307
I mean, it feels like we need
a different kind of conversation,

00:00:38.331 --> 00:00:44.259
one that's based on -- I don't know,
on reason, listening, on understanding,

00:00:44.283 --> 00:00:45.950
on a broader context.

00:00:46.660 --> 00:00:49.687
That's at least what we're going to try
in these TED Dialogues,

00:00:49.711 --> 00:00:50.903
starting today.

00:00:50.927 --> 00:00:53.553
And we couldn't have anyone with us

00:00:53.577 --> 00:00:56.386
who I'd be more excited to kick this off.

00:00:56.410 --> 00:01:00.260
This is a mind right here that thinks
pretty much like no one else

00:01:00.284 --> 00:01:02.055
on the planet, I would hasten to say.

00:01:02.079 --> 00:01:03.238
I'm serious.

00:01:03.262 --> 00:01:04.524
(Yuval Noah Harari laughs)

00:01:04.548 --> 00:01:05.712
I'm serious.

00:01:05.736 --> 00:01:10.674
He synthesizes history
with underlying ideas

00:01:10.698 --> 00:01:12.868
in a way that kind of takes
your breath away.

00:01:12.892 --> 00:01:16.301
So, some of you will know
this book, "Sapiens."

00:01:16.325 --> 00:01:18.068
Has anyone here read "Sapiens"?

00:01:18.092 --> 00:01:19.304
(Applause)

00:01:19.328 --> 00:01:22.473
I mean, I could not put it down.

00:01:22.497 --> 00:01:26.371
The way that he tells the story of mankind

00:01:26.395 --> 00:01:30.197
through big ideas that really make you
think differently --

00:01:30.221 --> 00:01:31.956
it's kind of amazing.

00:01:31.980 --> 00:01:33.204
And here's the follow-up,

00:01:33.228 --> 00:01:36.304
which I think is being published
in the US next week.

00:01:36.328 --> 00:01:37.479
YNH: Yeah, next week.

00:01:37.503 --> 00:01:38.677
CA: "Homo Deus."

00:01:38.701 --> 00:01:41.766
Now, this is the history
of the next hundred years.

00:01:42.341 --> 00:01:44.191
I've had a chance to read it.

00:01:44.215 --> 00:01:46.605
It's extremely dramatic,

00:01:46.629 --> 00:01:50.894
and I daresay, for some people,
quite alarming.

00:01:51.425 --> 00:01:52.668
It's a must-read.

00:01:52.692 --> 00:01:58.270
And honestly, we couldn't have
someone better to help

00:01:58.294 --> 00:02:02.270
make sense of what on Earth
is happening in the world right now.

00:02:02.294 --> 00:02:06.451
So a warm welcome, please,
to Yuval Noah Harari.

00:02:06.475 --> 00:02:09.868
(Applause)

00:02:14.720 --> 00:02:18.465
It's great to be joined by our friends
on Facebook and around the Web.

00:02:18.489 --> 00:02:20.066
Hello, Facebook.

00:02:20.090 --> 00:02:24.016
And all of you, as I start
asking questions of Yuval,

00:02:24.040 --> 00:02:25.692
come up with your own questions,

00:02:25.716 --> 00:02:28.363
and not necessarily about
the political scandal du jour,

00:02:28.387 --> 00:02:33.156
but about the broader understanding
of: Where are we heading?

00:02:34.337 --> 00:02:36.103
You ready? OK, we're going to go.

00:02:36.127 --> 00:02:37.402
So here we are, Yuval:

00:02:37.426 --> 00:02:41.146
New York City, 2017,
there's a new president in power,

00:02:41.170 --> 00:02:44.291
and shock waves rippling around the world.

00:02:44.315 --> 00:02:45.784
What on Earth is happening?

00:02:46.935 --> 00:02:49.181
YNH: I think the basic thing that happened

00:02:49.205 --> 00:02:51.495
is that we have lost our story.

00:02:51.964 --> 00:02:54.431
Humans think in stories,

00:02:54.455 --> 00:02:58.117
and we try to make sense of the world
by telling stories.

00:02:58.141 --> 00:02:59.558
And for the last few decades,

00:02:59.582 --> 00:03:02.452
we had a very simple
and very attractive story

00:03:02.476 --> 00:03:04.225
about what's happening in the world.

00:03:04.249 --> 00:03:07.413
And the story said that,
oh, what's happening is

00:03:07.437 --> 00:03:10.053
that the economy is being globalized,

00:03:10.077 --> 00:03:12.220
politics is being liberalized,

00:03:12.244 --> 00:03:16.243
and the combination of the two
will create paradise on Earth,

00:03:16.267 --> 00:03:19.366
and we just need to keep on
globalizing the economy

00:03:19.390 --> 00:03:21.201
and liberalizing the political system,

00:03:21.225 --> 00:03:23.130
and everything will be wonderful.

00:03:23.154 --> 00:03:25.886
And 2016 is the moment

00:03:25.910 --> 00:03:29.870
when a very large segment,
even of the Western world,

00:03:29.894 --> 00:03:32.300
stopped believing in this story.

00:03:32.324 --> 00:03:34.456
For good or bad reasons --
it doesn't matter.

00:03:34.480 --> 00:03:36.701
People stopped believing in the story,

00:03:36.725 --> 00:03:40.501
and when you don't have a story,
you don't understand what's happening.

00:03:41.032 --> 00:03:44.999
CA: Part of you believes that that story
was actually a very effective story.

00:03:45.023 --> 00:03:46.217
It worked.

00:03:46.241 --> 00:03:47.718
YNH: To some extent, yes.

00:03:47.742 --> 00:03:49.804
According to some measurements,

00:03:49.828 --> 00:03:52.413
we are now in the best time ever

00:03:52.437 --> 00:03:53.864
for humankind.

00:03:53.888 --> 00:03:56.328
Today, for the first time in history,

00:03:56.352 --> 00:04:00.765
more people die from eating too much
than from eating too little,

00:04:00.789 --> 00:04:02.561
which is an amazing achievement.

00:04:02.585 --> 00:04:05.268
(Laughter)

00:04:05.292 --> 00:04:06.993
Also for the first time in history,

00:04:07.017 --> 00:04:11.152
more people die from old age
than from infectious diseases,

00:04:11.176 --> 00:04:13.970
and violence is also down.

00:04:13.994 --> 00:04:15.424
For the first time in history,

00:04:15.448 --> 00:04:20.779
more people commit suicide
than are killed by crime and terrorism

00:04:20.803 --> 00:04:22.643
and war put together.

00:04:22.667 --> 00:04:26.827
Statistically, you are
your own worst enemy.

00:04:26.851 --> 00:04:28.857
At least, of all the people in the world,

00:04:28.881 --> 00:04:32.003
you are most likely
to be killed by yourself --

00:04:32.027 --> 00:04:33.294
(Laughter)

00:04:33.318 --> 00:04:36.362
which is, again,
very good news, compared --

00:04:36.386 --> 00:04:38.010
(Laughter)

00:04:38.034 --> 00:04:42.335
compared to the level of violence
that we saw in previous eras.

00:04:42.359 --> 00:04:44.595
CA: But this process
of connecting the world

00:04:44.619 --> 00:04:48.518
ended up with a large group of people
kind of feeling left out,

00:04:48.542 --> 00:04:50.173
and they've reacted.

00:04:50.197 --> 00:04:52.183
And so we have this bombshell

00:04:52.207 --> 00:04:54.518
that's sort of ripping
through the whole system.

00:04:54.542 --> 00:04:57.934
I mean, what do you make
of what's happened?

00:04:57.958 --> 00:05:01.236
It feels like the old way
that people thought of politics,

00:05:01.260 --> 00:05:04.116
the left-right divide,
has been blown up and replaced.

00:05:04.140 --> 00:05:05.737
How should we think of this?

00:05:05.761 --> 00:05:10.145
YNH: Yeah, the old 20th-century
political model of left versus right

00:05:10.169 --> 00:05:11.876
is now largely irrelevant,

00:05:11.900 --> 00:05:16.402
and the real divide today
is between global and national,

00:05:16.426 --> 00:05:18.215
global or local.

00:05:18.239 --> 00:05:21.096
And you see it again all over the world

00:05:21.120 --> 00:05:23.265
that this is now the main struggle.

00:05:23.289 --> 00:05:26.725
We probably need completely
new political models

00:05:26.749 --> 00:05:31.809
and completely new ways
of thinking about politics.

00:05:32.319 --> 00:05:37.849
In essence, what you can say
is that we now have global ecology,

00:05:37.873 --> 00:05:41.814
we have a global economy
but we have national politics,

00:05:41.838 --> 00:05:43.575
and this doesn't work together.

00:05:43.599 --> 00:05:45.825
This makes the political
system ineffective,

00:05:45.849 --> 00:05:49.373
because it has no control
over the forces that shape our life.

00:05:49.397 --> 00:05:52.676
And you have basically two solutions
to this imbalance:

00:05:52.700 --> 00:05:57.274
either de-globalize the economy
and turn it back into a national economy,

00:05:57.298 --> 00:05:59.466
or globalize the political system.

00:06:00.768 --> 00:06:05.433
CA: So some, I guess
many liberals out there

00:06:05.457 --> 00:06:11.893
view Trump and his government
as kind of irredeemably bad,

00:06:11.917 --> 00:06:14.576
just awful in every way.

00:06:14.600 --> 00:06:21.023
Do you see any underlying narrative
or political philosophy in there

00:06:21.047 --> 00:06:22.851
that is at least worth understanding?

00:06:22.875 --> 00:06:24.920
How would you articulate that philosophy?

00:06:24.944 --> 00:06:27.243
Is it just the philosophy of nationalism?

00:06:28.074 --> 00:06:33.474
YNH: I think the underlying
feeling or idea

00:06:33.498 --> 00:06:37.990
is that the political system --
something is broken there.

00:06:38.014 --> 00:06:41.784
It doesn't empower
the ordinary person anymore.

00:06:41.808 --> 00:06:45.308
It doesn't care so much
about the ordinary person anymore,

00:06:45.332 --> 00:06:50.151
and I think this diagnosis
of the political disease is correct.

00:06:50.175 --> 00:06:53.534
With regard to the answers,
I am far less certain.

00:06:53.558 --> 00:06:57.041
I think what we are seeing
is the immediate human reaction:

00:06:57.065 --> 00:06:59.623
if something doesn't work, let's go back.

00:06:59.647 --> 00:07:01.268
And you see it all over the world,

00:07:01.292 --> 00:07:05.718
that people, almost nobody
in the political system today,

00:07:05.742 --> 00:07:09.935
has any future-oriented vision
of where humankind is going.

00:07:09.959 --> 00:07:12.985
Almost everywhere,
you see retrograde vision:

00:07:13.009 --> 00:07:15.055
"Let's make America great again,"

00:07:15.079 --> 00:07:18.508
like it was great -- I don't know --
in the '50s, in the '80s, sometime,

00:07:18.532 --> 00:07:19.702
let's go back there.

00:07:19.726 --> 00:07:24.447
And you go to Russia
a hundred years after Lenin,

00:07:24.471 --> 00:07:26.342
Putin's vision for the future

00:07:26.366 --> 00:07:29.563
is basically, ah, let's go back
to the Tsarist empire.

00:07:29.587 --> 00:07:31.979
And in Israel, where I come from,

00:07:32.003 --> 00:07:35.255
the hottest political vision
of the present is:

00:07:35.279 --> 00:07:37.130
"Let's build the temple again."

00:07:37.154 --> 00:07:40.132
So let's go back 2,000 years backwards.

00:07:40.156 --> 00:07:44.982
So people are thinking
sometime in the past we've lost it,

00:07:45.006 --> 00:07:48.744
and sometimes in the past, it's like
you've lost your way in the city,

00:07:48.768 --> 00:07:51.918
and you say OK, let's go back
to the point where I felt secure

00:07:51.942 --> 00:07:53.304
and start again.

00:07:53.328 --> 00:07:54.901
I don't think this can work,

00:07:54.925 --> 00:07:57.827
but a lot of people,
this is their gut instinct.

00:07:57.851 --> 00:07:59.503
CA: But why couldn't it work?

00:07:59.527 --> 00:08:03.166
"America First" is a very
appealing slogan in many ways.

00:08:03.190 --> 00:08:07.067
Patriotism is, in many ways,
a very noble thing.

00:08:07.091 --> 00:08:09.832
It's played a role
in promoting cooperation

00:08:09.856 --> 00:08:11.446
among large numbers of people.

00:08:11.470 --> 00:08:15.352
Why couldn't you have a world
organized in countries,

00:08:15.376 --> 00:08:18.153
all of which put themselves first?

00:08:19.193 --> 00:08:22.512
YNH: For many centuries,
even thousands of years,

00:08:22.536 --> 00:08:25.298
patriotism worked quite well.

00:08:25.322 --> 00:08:27.201
Of course, it led to wars an so forth,

00:08:27.225 --> 00:08:30.180
but we shouldn't focus
too much on the bad.

00:08:30.204 --> 00:08:33.746
There are also many,
many positive things about patriotism,

00:08:33.770 --> 00:08:37.544
and the ability to have
a large number of people

00:08:37.568 --> 00:08:38.982
care about each other,

00:08:39.006 --> 00:08:40.612
sympathize with one another,

00:08:40.636 --> 00:08:43.850
and come together for collective action.

00:08:43.874 --> 00:08:46.569
If you go back to the first nations,

00:08:46.593 --> 00:08:48.418
so, thousands of years ago,

00:08:48.442 --> 00:08:51.848
the people who lived along
the Yellow River in China --

00:08:51.872 --> 00:08:54.315
it was many, many different tribes

00:08:54.339 --> 00:08:58.709
and they all depended on the river
for survival and for prosperity,

00:08:58.733 --> 00:09:03.042
but all of them also suffered
from periodical floods

00:09:03.066 --> 00:09:04.666
and periodical droughts.

00:09:04.690 --> 00:09:07.725
And no tribe could really do
anything about it,

00:09:07.749 --> 00:09:11.909
because each of them controlled
just a tiny section of the river.

00:09:11.933 --> 00:09:14.697
And then in a long
and complicated process,

00:09:14.721 --> 00:09:18.645
the tribes coalesced together
to form the Chinese nation,

00:09:18.669 --> 00:09:21.303
which controlled the entire Yellow River

00:09:21.327 --> 00:09:26.774
and had the ability to bring
hundreds of thousands of people together

00:09:26.798 --> 00:09:31.049
to build dams and canals
and regulate the river

00:09:31.073 --> 00:09:34.260
and prevent the worst floods and droughts

00:09:34.284 --> 00:09:37.384
and raise the level
of prosperity for everybody.

00:09:37.408 --> 00:09:40.025
And this worked in many places
around the world.

00:09:40.049 --> 00:09:43.175
But in the 21st century,

00:09:43.199 --> 00:09:46.634
technology is changing all that
in a fundamental way.

00:09:46.658 --> 00:09:49.372
We are now living -- all people
in the world --

00:09:49.396 --> 00:09:53.213
are living alongside the same cyber river,

00:09:53.237 --> 00:09:58.843
and no single nation can regulate
this river by itself.

00:09:58.867 --> 00:10:02.910
We are all living together
on a single planet,

00:10:02.934 --> 00:10:05.695
which is threatened by our own actions.

00:10:05.719 --> 00:10:09.735
And if you don't have some kind
of global cooperation,

00:10:09.759 --> 00:10:14.902
nationalism is just not on the right level
to tackle the problems,

00:10:14.926 --> 00:10:18.629
whether it's climate change
or whether it's technological disruption.

00:10:19.581 --> 00:10:21.772
CA: So it was a beautiful idea

00:10:21.796 --> 00:10:25.744
in a world where most of the action,
most of the issues,

00:10:25.768 --> 00:10:28.124
took place on national scale,

00:10:28.148 --> 00:10:30.946
but your argument is that the issues
that matter most today

00:10:30.970 --> 00:10:34.114
no longer take place on a national scale
but on a global scale.

00:10:34.138 --> 00:10:37.947
YNH: Exactly. All the major problems
of the world today

00:10:37.971 --> 00:10:40.360
are global in essence,

00:10:40.384 --> 00:10:41.875
and they cannot be solved

00:10:41.899 --> 00:10:45.796
unless through some kind
of global cooperation.

00:10:45.820 --> 00:10:47.449
It's not just climate change,

00:10:47.473 --> 00:10:50.877
which is, like, the most obvious
example people give.

00:10:50.901 --> 00:10:53.979
I think more in terms
of technological disruption.

00:10:54.003 --> 00:10:57.053
If you think about, for example,
artificial intelligence,

00:10:57.077 --> 00:11:00.070
over the next 20, 30 years

00:11:00.094 --> 00:11:03.978
pushing hundreds of millions of people
out of the job market --

00:11:04.002 --> 00:11:06.253
this is a problem on a global level.

00:11:06.277 --> 00:11:09.780
It will disrupt the economy
of all the countries.

00:11:09.804 --> 00:11:13.467
And similarly, if you think
about, say, bioengineering

00:11:13.491 --> 00:11:16.446
and people being afraid of conducting,

00:11:16.470 --> 00:11:19.131
I don't know, genetic engineering
research in humans,

00:11:19.155 --> 00:11:24.444
it won't help if just
a single country, let's say the US,

00:11:24.468 --> 00:11:27.792
outlaws all genetic experiments in humans,

00:11:27.816 --> 00:11:31.446
but China or North Korea
continues to do it.

00:11:31.470 --> 00:11:34.210
So the US cannot solve it by itself,

00:11:34.234 --> 00:11:39.117
and very quickly, the pressure on the US
to do the same will be immense

00:11:39.141 --> 00:11:44.031
because we are talking about
high-risk, high-gain technologies.

00:11:44.055 --> 00:11:48.763
If somebody else is doing it,
I can't allow myself to remain behind.

00:11:48.787 --> 00:11:54.475
The only way to have regulations,
effective regulations,

00:11:54.499 --> 00:11:56.592
on things like genetic engineering,

00:11:56.616 --> 00:11:58.628
is to have global regulations.

00:11:58.652 --> 00:12:03.690
If you just have national regulations,
nobody would like to stay behind.

00:12:03.714 --> 00:12:05.722
CA: So this is really interesting.

00:12:05.746 --> 00:12:07.677
It seems to me that this may be one key

00:12:07.701 --> 00:12:11.173
to provoking at least
a constructive conversation

00:12:11.197 --> 00:12:12.870
between the different sides here,

00:12:12.894 --> 00:12:16.036
because I think everyone can agree
that the start point

00:12:16.060 --> 00:12:18.757
of a lot of the anger
that's propelled us to where we are

00:12:18.781 --> 00:12:21.529
is because of the legitimate
concerns about job loss.

00:12:21.553 --> 00:12:25.194
Work is gone, a traditional
way of life has gone,

00:12:25.218 --> 00:12:28.593
and it's no wonder
that people are furious about that.

00:12:28.617 --> 00:12:33.169
And in general, they have blamed
globalism, global elites,

00:12:33.193 --> 00:12:35.940
for doing this to them
without asking their permission,

00:12:35.964 --> 00:12:38.059
and that seems like
a legitimate complaint.

00:12:38.083 --> 00:12:41.392
But what I hear you saying
is that -- so a key question is:

00:12:41.416 --> 00:12:46.877
What is the real cause of job loss,
both now and going forward?

00:12:46.901 --> 00:12:49.677
To the extent that it's about globalism,

00:12:49.701 --> 00:12:53.823
then the right response,
yes, is to shut down borders

00:12:53.847 --> 00:12:57.827
and keep people out
and change trade agreements and so forth.

00:12:57.851 --> 00:12:59.207
But you're saying, I think,

00:12:59.231 --> 00:13:04.022
that actually the bigger cause of job loss
is not going to be that at all.

00:13:04.046 --> 00:13:07.760
It's going to originate
in technological questions,

00:13:07.784 --> 00:13:09.796
and we have no chance of solving that

00:13:09.820 --> 00:13:11.915
unless we operate as a connected world.

00:13:11.939 --> 00:13:13.458
YNH: Yeah, I think that,

00:13:13.482 --> 00:13:16.723
I don't know about the present,
but looking to the future,

00:13:16.747 --> 00:13:19.824
it's not the Mexicans or Chinese
who will take the jobs

00:13:19.848 --> 00:13:21.415
from the people in Pennsylvania,

00:13:21.439 --> 00:13:23.182
it's the robots and algorithms.

00:13:23.206 --> 00:13:27.390
So unless you plan to build a big wall
on the border of California --

00:13:27.414 --> 00:13:28.548
(Laughter)

00:13:28.572 --> 00:13:32.263
the wall on the border with Mexico
is going to be very ineffective.

00:13:32.287 --> 00:13:38.635
And I was struck when I watched
the debates before the election,

00:13:38.659 --> 00:13:44.396
I was struck that certainly Trump
did not even attempt to frighten people

00:13:44.420 --> 00:13:46.996
by saying the robots will take your jobs.

00:13:47.020 --> 00:13:49.319
Now even if it's not true,
it doesn't matter.

00:13:49.343 --> 00:13:52.861
It could have been an extremely
effective way of frightening people --

00:13:52.885 --> 00:13:53.886
(Laughter)

00:13:53.910 --> 00:13:55.071
and galvanizing people:

00:13:55.095 --> 00:13:56.704
"The robots will take your jobs!"

00:13:56.728 --> 00:13:58.083
And nobody used that line.

00:13:58.107 --> 00:14:00.799
And it made me afraid,

00:14:00.823 --> 00:14:04.871
because it meant
that no matter what happens

00:14:04.895 --> 00:14:07.041
in universities and laboratories,

00:14:07.065 --> 00:14:09.830
and there, there is already
an intense debate about it,

00:14:09.854 --> 00:14:13.948
but in the mainstream political system
and among the general public,

00:14:13.972 --> 00:14:16.082
people are just unaware

00:14:16.106 --> 00:14:20.616
that there could be an immense
technological disruption --

00:14:20.640 --> 00:14:24.762
not in 200 years,
but in 10, 20, 30 years --

00:14:24.786 --> 00:14:27.356
and we have to do something about it now,

00:14:27.380 --> 00:14:33.656
partly because most of what we teach
children today in school or in college

00:14:33.680 --> 00:14:39.681
is going to be completely irrelevant
to the job market of 2040, 2050.

00:14:39.705 --> 00:14:43.063
So it's not something we'll need
to think about in 2040.

00:14:43.087 --> 00:14:46.680
We need to think today
what to teach the young people.

00:14:46.704 --> 00:14:49.357
CA: Yeah, no, absolutely.

00:14:50.415 --> 00:14:54.332
You've often written about
moments in history

00:14:54.356 --> 00:15:01.215
where humankind has ...
entered a new era, unintentionally.

00:15:01.626 --> 00:15:04.494
Decisions have been made,
technologies have been developed,

00:15:04.518 --> 00:15:06.889
and suddenly the world has changed,

00:15:06.913 --> 00:15:09.380
possibly in a way
that's worse for everyone.

00:15:09.404 --> 00:15:11.479
So one of the examples
you give in "Sapiens"

00:15:11.503 --> 00:15:13.594
is just the whole agricultural revolution,

00:15:13.618 --> 00:15:17.172
which, for an actual person
tilling the fields,

00:15:17.196 --> 00:15:20.376
they just picked up a 12-hour
backbreaking workday

00:15:20.400 --> 00:15:26.648
instead of six hours in the jungle
and a much more interesting lifestyle.

00:15:26.672 --> 00:15:27.714
(Laughter)

00:15:27.738 --> 00:15:30.927
So are we at another possible
phase change here,

00:15:30.951 --> 00:15:35.439
where we kind of sleepwalk into a future
that none of us actually wants?

00:15:35.878 --> 00:15:38.611
YNH: Yes, very much so.

00:15:38.635 --> 00:15:40.472
During the agricultural revolution,

00:15:40.496 --> 00:15:44.916
what happened is that immense
technological and economic revolution

00:15:44.940 --> 00:15:47.805
empowered the human collective,

00:15:47.829 --> 00:15:50.782
but when you look at actual
individual lives,

00:15:50.806 --> 00:15:54.300
the life of a tiny elite
became much better,

00:15:54.324 --> 00:15:58.562
and the lives of the majority of people
became considerably worse.

00:15:58.586 --> 00:16:01.291
And this can happen again
in the 21st century.

00:16:01.315 --> 00:16:06.181
No doubt the new technologies
will empower the human collective.

00:16:06.205 --> 00:16:08.925
But we may end up again

00:16:08.949 --> 00:16:13.406
with a tiny elite reaping
all the benefits, taking all the fruits,

00:16:13.430 --> 00:16:17.616
and the masses of the population
finding themselves worse

00:16:17.640 --> 00:16:18.941
than they were before,

00:16:18.965 --> 00:16:21.753
certainly much worse than this tiny elite.

00:16:22.477 --> 00:16:25.132
CA: And those elites
might not even be human elites.

00:16:25.156 --> 00:16:26.913
They might be cyborgs or --

00:16:26.937 --> 00:16:29.144
YNH: Yeah, they could be
enhanced super humans.

00:16:29.168 --> 00:16:30.423
They could be cyborgs.

00:16:30.447 --> 00:16:32.804
They could be completely
nonorganic elites.

00:16:32.828 --> 00:16:35.356
They could even be
non-conscious algorithms.

00:16:35.380 --> 00:16:40.291
What we see now in the world
is authority shifting away

00:16:40.315 --> 00:16:42.584
from humans to algorithms.

00:16:42.608 --> 00:16:46.132
More and more decisions --
about personal lives,

00:16:46.156 --> 00:16:48.828
about economic matters,
about political matters --

00:16:48.852 --> 00:16:51.331
are actually being taken by algorithms.

00:16:51.355 --> 00:16:53.989
If you ask the bank for a loan,

00:16:54.013 --> 00:16:58.710
chances are your fate is decided
by an algorithm, not by a human being.

00:16:58.734 --> 00:17:04.921
And the general impression
is that maybe Homo sapiens just lost it.

00:17:04.945 --> 00:17:09.505
The world is so complicated,
there is so much data,

00:17:09.529 --> 00:17:12.083
things are changing so fast,

00:17:12.107 --> 00:17:15.708
that this thing that evolved
on the African savanna

00:17:15.732 --> 00:17:17.439
tens of thousands of years ago --

00:17:17.463 --> 00:17:20.960
to cope with a particular environment,

00:17:20.984 --> 00:17:24.468
a particular volume
of information and data --

00:17:24.492 --> 00:17:28.828
it just can't handle the realities
of the 21st century,

00:17:28.852 --> 00:17:31.749
and the only thing
that may be able to handle it

00:17:31.773 --> 00:17:33.845
is big-data algorithms.

00:17:33.869 --> 00:17:40.050
So no wonder more and more authority
is shifting from us to the algorithms.

00:17:40.677 --> 00:17:44.526
CA: So we're in New York City
for the first of a series of TED Dialogues

00:17:44.550 --> 00:17:46.847
with Yuval Harari,

00:17:46.871 --> 00:17:50.715
and there's a Facebook Live
audience out there.

00:17:50.739 --> 00:17:52.390
We're excited to have you with us.

00:17:52.414 --> 00:17:54.516
We'll start coming
to some of your questions

00:17:54.540 --> 00:17:56.254
and questions of people in the room

00:17:56.278 --> 00:17:57.443
in just a few minutes,

00:17:57.467 --> 00:17:59.431
so have those coming.

00:17:59.455 --> 00:18:03.352
Yuval, if you're going
to make the argument

00:18:03.376 --> 00:18:09.511
that we need to get past nationalism
because of the coming technological ...

00:18:11.038 --> 00:18:12.879
danger, in a way,

00:18:12.903 --> 00:18:14.848
presented by so much of what's happening

00:18:14.872 --> 00:18:17.315
we've got to have
a global conversation about this.

00:18:17.339 --> 00:18:20.767
Trouble is, it's hard to get people
really believing that, I don't know,

00:18:20.791 --> 00:18:22.952
AI really is an imminent
threat, and so forth.

00:18:22.976 --> 00:18:25.702
The things that people,
some people at least,

00:18:25.726 --> 00:18:27.761
care about much more immediately, perhaps,

00:18:27.785 --> 00:18:29.369
is climate change,

00:18:29.393 --> 00:18:34.286
perhaps other issues like refugees,
nuclear weapons, and so forth.

00:18:34.310 --> 00:18:39.356
Would you argue that where
we are right now

00:18:39.380 --> 00:18:42.929
that somehow those issues
need to be dialed up?

00:18:42.953 --> 00:18:45.113
You've talked about climate change,

00:18:45.137 --> 00:18:48.793
but Trump has said
he doesn't believe in that.

00:18:48.817 --> 00:18:51.256
So in a way, your most powerful argument,

00:18:51.280 --> 00:18:54.026
you can't actually use to make this case.

00:18:54.050 --> 00:18:56.236
YNH: Yeah, I think with climate change,

00:18:56.260 --> 00:18:59.967
at first sight, it's quite surprising

00:18:59.991 --> 00:19:02.495
that there is a very close correlation

00:19:02.519 --> 00:19:05.841
between nationalism and climate change.

00:19:05.865 --> 00:19:10.452
I mean, almost always, the people
who deny climate change are nationalists.

00:19:10.476 --> 00:19:12.557
And at first sight, you think: Why?

00:19:12.581 --> 00:19:13.734
What's the connection?

00:19:13.758 --> 00:19:16.544
Why don't you have socialists
denying climate change?

00:19:16.568 --> 00:19:18.919
But then, when you think
about it, it's obvious --

00:19:18.943 --> 00:19:22.687
because nationalism has no solution
to climate change.

00:19:22.711 --> 00:19:25.907
If you want to be a nationalist
in the 21st century,

00:19:25.931 --> 00:19:27.803
you have to deny the problem.

00:19:27.827 --> 00:19:32.314
If you accept the reality of the problem,
then you must accept that, yes,

00:19:32.338 --> 00:19:35.114
there is still room in the world
for patriotism,

00:19:35.138 --> 00:19:39.289
there is still room in the world
for having special loyalties

00:19:39.313 --> 00:19:43.947
and obligations towards your own people,
towards your own country.

00:19:43.971 --> 00:19:47.791
I don't think anybody is really
thinking of abolishing that.

00:19:47.815 --> 00:19:50.816
But in order to confront climate change,

00:19:50.840 --> 00:19:55.051
we need additional loyalties
and commitments

00:19:55.075 --> 00:19:57.080
to a level beyond the nation.

00:19:57.104 --> 00:19:59.547
And that should not be impossible,

00:19:59.571 --> 00:20:03.263
because people can have
several layers of loyalty.

00:20:03.287 --> 00:20:05.691
You can be loyal to your family

00:20:05.715 --> 00:20:07.228
and to your community

00:20:07.252 --> 00:20:08.581
and to your nation,

00:20:08.605 --> 00:20:12.233
so why can't you also be loyal
to humankind as a whole?

00:20:12.257 --> 00:20:15.656
Of course, there are occasions
when it becomes difficult,

00:20:15.680 --> 00:20:17.463
what to put first,

00:20:17.487 --> 00:20:19.310
but, you know, life is difficult.

00:20:19.334 --> 00:20:20.485
Handle it.

00:20:20.509 --> 00:20:23.153
(Laughter)

00:20:23.177 --> 00:20:27.675
CA: OK, so I would love to get
some questions from the audience here.

00:20:27.699 --> 00:20:29.617
We've got a microphone here.

00:20:29.641 --> 00:20:32.858
Speak into it, and Facebook,
get them coming, too.

00:20:32.882 --> 00:20:36.316
Howard Morgan: One of the things that has
clearly made a huge difference

00:20:36.340 --> 00:20:38.126
in this country and other countries

00:20:38.150 --> 00:20:40.364
is the income distribution inequality,

00:20:40.388 --> 00:20:44.602
the dramatic change
in income distribution in the US

00:20:44.626 --> 00:20:46.328
from what it was 50 years ago,

00:20:46.352 --> 00:20:47.503
and around the world.

00:20:47.527 --> 00:20:50.670
Is there anything we can do
to affect that?

00:20:50.694 --> 00:20:53.535
Because that gets at a lot
of the underlying causes.

00:20:56.103 --> 00:21:01.417
YNH: So far I haven't heard a very
good idea about what to do about it,

00:21:01.441 --> 00:21:05.169
again, partly because most ideas
remain on the national level,

00:21:05.193 --> 00:21:06.961
and the problem is global.

00:21:06.985 --> 00:21:09.963
I mean, one idea that we hear
quite a lot about now

00:21:09.987 --> 00:21:11.819
is universal basic income.

00:21:11.843 --> 00:21:12.994
But this is a problem.

00:21:13.018 --> 00:21:14.670
I mean, I think it's a good start,

00:21:14.694 --> 00:21:18.416
but it's a problematic idea because
it's not clear what "universal" is

00:21:18.440 --> 00:21:20.281
and it's not clear what "basic" is.

00:21:20.305 --> 00:21:23.686
Most people when they speak
about universal basic income,

00:21:23.710 --> 00:21:26.495
they actually mean national basic income.

00:21:26.519 --> 00:21:28.263
But the problem is global.

00:21:28.287 --> 00:21:33.937
Let's say that you have AI and 3D printers
taking away millions of jobs

00:21:33.961 --> 00:21:35.117
in Bangladesh,

00:21:35.141 --> 00:21:38.389
from all the people who make
my shirts and my shoes.

00:21:38.413 --> 00:21:39.719
So what's going to happen?

00:21:39.743 --> 00:21:46.282
The US government will levy taxes
on Google and Apple in California,

00:21:46.306 --> 00:21:50.887
and use that to pay basic income
to unemployed Bangladeshis?

00:21:50.911 --> 00:21:53.547
If you believe that,
you can just as well believe

00:21:53.571 --> 00:21:57.234
that Santa Claus will come
and solve the problem.

00:21:57.258 --> 00:22:02.384
So unless we have really universal
and not national basic income,

00:22:02.408 --> 00:22:05.543
the deep problems
are not going to go away.

00:22:05.567 --> 00:22:08.299
And also it's not clear what basic is,

00:22:08.323 --> 00:22:10.956
because what are basic human needs?

00:22:10.980 --> 00:22:13.790
A thousand years ago,
just food and shelter was enough.

00:22:13.814 --> 00:22:17.425
But today, people will say
education is a basic human need,

00:22:17.449 --> 00:22:19.022
it should be part of the package.

00:22:19.046 --> 00:22:22.825
But how much? Six years?
Twelve years? PhD?

00:22:22.849 --> 00:22:24.682
Similarly, with health care,

00:22:24.706 --> 00:22:27.391
let's say that in 20, 30, 40 years,

00:22:27.415 --> 00:22:31.188
you'll have expensive treatments
that can extend human life

00:22:31.212 --> 00:22:33.127
to 120, I don't know.

00:22:33.151 --> 00:22:38.342
Will this be part of the basket
of basic income or not?

00:22:38.366 --> 00:22:39.795
It's a very difficult problem,

00:22:39.819 --> 00:22:46.077
because in a world where people
lose their ability to be employed,

00:22:46.101 --> 00:22:49.682
the only thing they are going to get
is this basic income.

00:22:49.706 --> 00:22:54.833
So what's part of it is a very,
very difficult ethical question.

00:22:54.857 --> 00:22:58.161
CA: There's a bunch of questions
on how the world affords it as well,

00:22:58.185 --> 00:22:59.345
who pays.

00:22:59.369 --> 00:23:02.181
There's a question here
from Facebook from Lisa Larson:

00:23:02.205 --> 00:23:04.780
"How does nationalism in the US now

00:23:04.804 --> 00:23:08.219
compare to that between
World War I and World War II

00:23:08.243 --> 00:23:09.664
in the last century?"

00:23:09.688 --> 00:23:14.136
YNH: Well the good news, with regard
to the dangers of nationalism,

00:23:14.160 --> 00:23:18.083
we are in a much better position
than a century ago.

00:23:18.107 --> 00:23:20.779
A century ago, 1917,

00:23:20.803 --> 00:23:23.936
Europeans were killing
each other by the millions.

00:23:23.960 --> 00:23:28.311
In 2016, with Brexit,
as far as I remember,

00:23:28.335 --> 00:23:33.572
a single person lost their life,
an MP who was murdered by some extremist.

00:23:33.596 --> 00:23:35.129
Just a single person.

00:23:35.153 --> 00:23:37.838
I mean, if Brexit was about
British independence,

00:23:37.862 --> 00:23:42.613
this is the most peaceful
war of independence in human history.

00:23:42.637 --> 00:23:48.426
And let's say that Scotland
will now choose to leave the UK

00:23:48.450 --> 00:23:50.626
after Brexit.

00:23:50.650 --> 00:23:52.634
So in the 18th century,

00:23:52.658 --> 00:23:55.890
if Scotland wanted -- and the Scots
wanted several times --

00:23:55.914 --> 00:23:59.447
to break out of the control of London,

00:23:59.471 --> 00:24:03.769
the reaction of the government
in London was to send an army up north

00:24:03.793 --> 00:24:07.264
to burn down Edinburgh
and massacre the highland tribes.

00:24:07.288 --> 00:24:12.844
My guess is that if, in 2018,
the Scots vote for independence,

00:24:12.868 --> 00:24:16.277
the London government
will not send an army up north

00:24:16.301 --> 00:24:17.904
to burn down Edinburgh.

00:24:17.928 --> 00:24:22.195
Very few people are now willing
to kill or be killed

00:24:22.219 --> 00:24:24.941
for Scottish or for British independence.

00:24:24.965 --> 00:24:29.985
So for all the talk
of the rise of nationalism

00:24:30.009 --> 00:24:32.252
and going back to the 1930s,

00:24:32.276 --> 00:24:36.051
to the 19th century, in the West at least,

00:24:36.075 --> 00:24:42.659
the power of national sentiments
today is far, far smaller

00:24:42.683 --> 00:24:44.223
than it was a century ago.

00:24:44.247 --> 00:24:48.084
CA: Although some people now,
you hear publicly worrying

00:24:48.108 --> 00:24:50.864
about whether that might be shifting,

00:24:50.888 --> 00:24:54.286
that there could actually be
outbreaks of violence in the US

00:24:54.310 --> 00:24:56.657
depending on how things turn out.

00:24:56.681 --> 00:24:58.220
Should we be worried about that,

00:24:58.244 --> 00:25:00.310
or do you really think
things have shifted?

00:25:00.334 --> 00:25:01.825
YNH: No, we should be worried.

00:25:01.849 --> 00:25:03.474
We should be aware of two things.

00:25:03.498 --> 00:25:05.135
First of all, don't be hysterical.

00:25:05.159 --> 00:25:08.606
We are not back
in the First World War yet.

00:25:08.630 --> 00:25:11.570
But on the other hand,
don't be complacent.

00:25:11.594 --> 00:25:16.968
We reached from 1917 to 2017,

00:25:16.992 --> 00:25:19.174
not by some divine miracle,

00:25:19.198 --> 00:25:21.222
but simply by human decisions,

00:25:21.246 --> 00:25:23.909
and if we now start making
the wrong decisions,

00:25:23.933 --> 00:25:28.418
we could be back
in an analogous situation to 1917

00:25:28.442 --> 00:25:29.948
in a few years.

00:25:29.972 --> 00:25:32.293
One of the things I know as a historian

00:25:32.317 --> 00:25:35.992
is that you should never
underestimate human stupidity.

00:25:36.016 --> 00:25:38.899
(Laughter)

00:25:38.923 --> 00:25:42.007
It's one of the most powerful
forces in history,

00:25:42.031 --> 00:25:44.358
human stupidity and human violence.

00:25:44.382 --> 00:25:48.487
Humans do such crazy things
for no obvious reason,

00:25:48.511 --> 00:25:50.221
but again, at the same time,

00:25:50.245 --> 00:25:53.849
another very powerful force
in human history is human wisdom.

00:25:53.873 --> 00:25:55.039
We have both.

00:25:55.063 --> 00:25:57.965
CA: We have with us here
moral psychologist Jonathan Haidt,

00:25:57.989 --> 00:25:59.612
who I think has a question.

00:26:00.691 --> 00:26:02.174
Jonathan Haidt: Thanks, Yuval.

00:26:02.198 --> 00:26:04.681
So you seem to be a fan
of global governance,

00:26:04.705 --> 00:26:08.225
but when you look at the map of the world
from Transparency International,

00:26:08.249 --> 00:26:11.577
which rates the level of corruption
of political institutions,

00:26:11.601 --> 00:26:14.681
it's a vast sea of red with little bits
of yellow here and there

00:26:14.705 --> 00:26:16.310
for those with good institutions.

00:26:16.334 --> 00:26:18.835
So if we were to have
some kind of global governance,

00:26:18.859 --> 00:26:21.690
what makes you think it would end up
being more like Denmark

00:26:21.714 --> 00:26:23.754
rather than more like Russia or Honduras,

00:26:23.778 --> 00:26:25.279
and aren't there alternatives,

00:26:25.303 --> 00:26:27.389
such as we did with CFCs?

00:26:27.413 --> 00:26:30.520
There are ways to solve global problems
with national governments.

00:26:30.544 --> 00:26:32.758
What would world government
actually look like,

00:26:32.782 --> 00:26:34.503
and why do you think it would work?

00:26:34.527 --> 00:26:38.287
YNH: Well, I don't know
what it would look like.

00:26:38.311 --> 00:26:41.363
Nobody still has a model for that.

00:26:41.387 --> 00:26:44.015
The main reason we need it

00:26:44.039 --> 00:26:48.333
is because many of these issues
are lose-lose situations.

00:26:48.357 --> 00:26:51.249
When you have
a win-win situation like trade,

00:26:51.273 --> 00:26:54.189
both sides can benefit
from a trade agreement,

00:26:54.213 --> 00:26:56.477
then this is something you can work out.

00:26:56.501 --> 00:26:58.847
Without some kind of global government,

00:26:58.871 --> 00:27:01.725
national governments each
have an interest in doing it.

00:27:01.749 --> 00:27:05.720
But when you have a lose-lose situation
like with climate change,

00:27:05.744 --> 00:27:07.385
it's much more difficult

00:27:07.409 --> 00:27:12.295
without some overarching
authority, real authority.

00:27:12.319 --> 00:27:15.081
Now, how to get there
and what would it look like,

00:27:15.105 --> 00:27:16.465
I don't know.

00:27:16.489 --> 00:27:20.226
And certainly there is no obvious reason

00:27:20.250 --> 00:27:22.530
to think that it would look like Denmark,

00:27:22.554 --> 00:27:24.142
or that it would be a democracy.

00:27:24.166 --> 00:27:26.752
Most likely it wouldn't.

00:27:26.776 --> 00:27:32.807
We don't have workable democratic models

00:27:32.831 --> 00:27:34.927
for a global government.

00:27:34.951 --> 00:27:38.016
So maybe it would look more
like ancient China

00:27:38.040 --> 00:27:39.739
than like modern Denmark.

00:27:39.763 --> 00:27:44.986
But still, given the dangers
that we are facing,

00:27:45.010 --> 00:27:50.130
I think the imperative of having
some kind of real ability

00:27:50.154 --> 00:27:54.282
to force through difficult decisions
on the global level

00:27:54.306 --> 00:27:58.436
is more important
than almost anything else.

00:27:59.411 --> 00:28:01.509
CA: There's a question from Facebook here,

00:28:01.533 --> 00:28:03.426
and then we'll get the mic to Andrew.

00:28:03.450 --> 00:28:05.646
So, Kat Hebron on Facebook,

00:28:05.670 --> 00:28:07.338
calling in from Vail:

00:28:07.362 --> 00:28:11.573
"How would developed nations manage
the millions of climate migrants?"

00:28:12.638 --> 00:28:14.792
YNH: I don't know.

00:28:14.816 --> 00:28:16.708
CA: That's your answer, Kat. (Laughter)

00:28:16.732 --> 00:28:18.878
YNH: And I don't think
that they know either.

00:28:18.902 --> 00:28:20.696
They'll just deny the problem, maybe.

00:28:20.720 --> 00:28:23.745
CA: But immigration, generally,
is another example of a problem

00:28:23.769 --> 00:28:26.342
that's very hard to solve
on a nation-by-nation basis.

00:28:26.366 --> 00:28:27.836
One nation can shut its doors,

00:28:27.860 --> 00:28:30.394
but maybe that stores up
problems for the future.

00:28:30.418 --> 00:28:34.290
YNH: Yes, I mean --
it's another very good case,

00:28:34.314 --> 00:28:36.543
especially because it's so much easier

00:28:36.567 --> 00:28:38.398
to migrate today

00:28:38.422 --> 00:28:42.111
than it was in the Middle Ages
or in ancient times.

00:28:42.135 --> 00:28:46.598
CA: Yuval, there's a belief
among many technologists, certainly,

00:28:46.622 --> 00:28:48.973
that political concerns
are kind of overblown,

00:28:48.997 --> 00:28:52.694
that actually, political leaders
don't have that much influence

00:28:52.718 --> 00:28:53.884
in the world,

00:28:53.908 --> 00:28:57.877
that the real determination of humanity
at this point is by science,

00:28:57.901 --> 00:28:59.347
by invention, by companies,

00:28:59.371 --> 00:29:03.763
by many things
other than political leaders,

00:29:03.787 --> 00:29:06.198
and it's actually very hard
for leaders to do much,

00:29:06.222 --> 00:29:08.580
so we're actually worrying
about nothing here.

00:29:09.825 --> 00:29:12.061
YNH: Well, first, it should be emphasized

00:29:12.085 --> 00:29:17.082
that it's true that political leaders'
ability to do good is very limited,

00:29:17.106 --> 00:29:20.149
but their ability to do harm is unlimited.

00:29:20.173 --> 00:29:22.773
There is a basic imbalance here.

00:29:22.797 --> 00:29:26.365
You can still press the button
and blow everybody up.

00:29:26.389 --> 00:29:27.975
You have that kind of ability.

00:29:27.999 --> 00:29:31.568
But if you want, for example,
to reduce inequality,

00:29:31.592 --> 00:29:33.469
that's very, very difficult.

00:29:33.493 --> 00:29:34.889
But to start a war,

00:29:34.913 --> 00:29:36.764
you can still do so very easily.

00:29:36.788 --> 00:29:40.380
So there is a built-in imbalance
in the political system today

00:29:40.404 --> 00:29:42.015
which is very frustrating,

00:29:42.039 --> 00:29:46.940
where you cannot do a lot of good
but you can still do a lot of harm.

00:29:46.964 --> 00:29:51.108
And this makes the political system
still a very big concern.

00:29:51.632 --> 00:29:53.783
CA: So as you look at
what's happening today,

00:29:53.807 --> 00:29:55.561
and putting your historian's hat on,

00:29:55.585 --> 00:29:59.111
do you look back in history at moments
when things were going just fine

00:29:59.135 --> 00:30:04.468
and an individual leader really took
the world or their country backwards?

00:30:05.127 --> 00:30:07.756
YNH: There are quite a few examples,

00:30:07.780 --> 00:30:10.599
but I should emphasize,
it's never an individual leader.

00:30:10.623 --> 00:30:12.257
I mean, somebody put him there,

00:30:12.281 --> 00:30:15.564
and somebody allowed him
to continue to be there.

00:30:15.588 --> 00:30:19.671
So it's never really just the fault
of a single individual.

00:30:19.695 --> 00:30:24.308
There are a lot of people
behind every such individual.

00:30:24.332 --> 00:30:27.810
CA: Can we have the microphone
here, please, to Andrew?

00:30:30.952 --> 00:30:34.516
Andrew Solomon: You've talked a lot
about the global versus the national,

00:30:34.540 --> 00:30:36.166
but increasingly, it seems to me,

00:30:36.190 --> 00:30:38.833
the world situation
is in the hands of identity groups.

00:30:38.857 --> 00:30:41.167
We look at people within the United States

00:30:41.191 --> 00:30:42.818
who have been recruited by ISIS.

00:30:42.842 --> 00:30:45.033
We look at these other groups
which have formed

00:30:45.057 --> 00:30:47.019
which go outside of national bounds

00:30:47.043 --> 00:30:49.204
but still represent
significant authorities.

00:30:49.228 --> 00:30:51.656
How are they to be integrated
into the system,

00:30:51.680 --> 00:30:55.393
and how is a diverse set of identities
to be made coherent

00:30:55.417 --> 00:30:57.755
under either national
or global leadership?

00:30:59.200 --> 00:31:02.421
YNH: Well, the problem
of such diverse identities

00:31:02.445 --> 00:31:04.501
is a problem from nationalism as well.

00:31:05.049 --> 00:31:09.404
Nationalism believes
in a single, monolithic identity,

00:31:09.428 --> 00:31:13.544
and exclusive or at least
more extreme versions of nationalism

00:31:13.568 --> 00:31:17.137
believe in an exclusive loyalty
to a single identity.

00:31:17.161 --> 00:31:20.077
And therefore, nationalism has had
a lot of problems

00:31:20.101 --> 00:31:22.977
with people wanting to divide
their identities

00:31:23.001 --> 00:31:25.064
between various groups.

00:31:25.088 --> 00:31:29.963
So it's not just a problem, say,
for a global vision.

00:31:30.360 --> 00:31:34.212
And I think, again, history shows

00:31:34.236 --> 00:31:40.363
that you shouldn't necessarily
think in such exclusive terms.

00:31:40.387 --> 00:31:43.795
If you think that there is just
a single identity for a person,

00:31:43.819 --> 00:31:48.859
"I am just X, that's it, I can't be
several things, I can be just that,"

00:31:48.883 --> 00:31:50.979
that's the start of the problem.

00:31:51.003 --> 00:31:53.791
You have religions, you have nations

00:31:53.815 --> 00:31:56.997
that sometimes demand exclusive loyalty,

00:31:57.021 --> 00:31:58.752
but it's not the only option.

00:31:58.776 --> 00:32:01.158
There are many religions and many nations

00:32:01.182 --> 00:32:05.060
that enable you to have
diverse identities at the same time.

00:32:05.084 --> 00:32:09.441
CA: But is one explanation
of what's happened in the last year

00:32:09.465 --> 00:32:14.645
that a group of people have got
fed up with, if you like,

00:32:14.669 --> 00:32:17.836
the liberal elites,
for want of a better term,

00:32:17.860 --> 00:32:22.233
obsessing over many, many different
identities and them feeling,

00:32:22.257 --> 00:32:26.116
"But what about my identity?
I am being completely ignored here.

00:32:26.140 --> 00:32:29.114
And by the way, I thought
I was the majority"?

00:32:29.138 --> 00:32:32.119
And that that's actually
sparked a lot of the anger.

00:32:32.738 --> 00:32:35.883
YNH: Yeah. Identity is always problematic,

00:32:35.907 --> 00:32:40.217
because identity is always based
on fictional stories

00:32:40.241 --> 00:32:43.130
that sooner or later collide with reality.

00:32:43.710 --> 00:32:45.228
Almost all identities,

00:32:45.252 --> 00:32:48.663
I mean, beyond the level
of the basic community

00:32:48.687 --> 00:32:50.156
of a few dozen people,

00:32:50.180 --> 00:32:52.109
are based on a fictional story.

00:32:52.133 --> 00:32:53.774
They are not the truth.

00:32:53.798 --> 00:32:55.113
They are not the reality.

00:32:55.137 --> 00:32:58.231
It's just a story that people invent
and tell one another

00:32:58.255 --> 00:32:59.746
and start believing.

00:32:59.770 --> 00:33:05.090
And therefore all identities
are extremely unstable.

00:33:05.114 --> 00:33:07.641
They are not a biological reality.

00:33:07.665 --> 00:33:09.671
Sometimes nationalists, for example,

00:33:09.695 --> 00:33:12.622
think that the nation
is a biological entity.

00:33:12.646 --> 00:33:16.259
It's made of the combination
of soil and blood,

00:33:16.283 --> 00:33:17.985
creates the nation.

00:33:18.009 --> 00:33:21.101
But this is just a fictional story.

00:33:21.125 --> 00:33:23.688
CA: Soil and blood
kind of makes a gooey mess.

00:33:23.712 --> 00:33:25.534
(Laughter)

00:33:25.558 --> 00:33:28.582
YNH: It does, and also
it messes with your mind

00:33:28.606 --> 00:33:33.390
when you think too much
that I am a combination of soil and blood.

00:33:33.414 --> 00:33:36.281
If you look from a biological perspective,

00:33:36.305 --> 00:33:39.783
obviously none of the nations
that exist today

00:33:39.807 --> 00:33:42.050
existed 5,000 years ago.

00:33:42.074 --> 00:33:45.932
Homo sapiens is a social animal,
that's for sure.

00:33:45.956 --> 00:33:48.383
But for millions of years,

00:33:48.407 --> 00:33:53.046
Homo sapiens and our hominid ancestors
lived in small communities

00:33:53.070 --> 00:33:55.399
of a few dozen individuals.

00:33:55.423 --> 00:33:57.550
Everybody knew everybody else.

00:33:57.574 --> 00:34:01.595
Whereas modern nations
are imagined communities,

00:34:01.619 --> 00:34:04.170
in the sense that I don't even know
all these people.

00:34:04.194 --> 00:34:07.042
I come from a relatively
small nation, Israel,

00:34:07.066 --> 00:34:09.209
and of eight million Israelis,

00:34:09.233 --> 00:34:11.223
I never met most of them.

00:34:11.247 --> 00:34:13.555
I will never meet most of them.

00:34:13.579 --> 00:34:16.141
They basically exist here.

00:34:16.165 --> 00:34:18.914
CA: But in terms of this identity,

00:34:18.938 --> 00:34:24.375
this group who feel left out
and perhaps have work taken away,

00:34:24.399 --> 00:34:26.693
I mean, in "Homo Deus,"

00:34:26.717 --> 00:34:29.828
you actually speak of this group
in one sense expanding,

00:34:29.852 --> 00:34:33.474
that so many people
may have their jobs taken away

00:34:33.498 --> 00:34:37.878
by technology in some way
that we could end up with

00:34:37.902 --> 00:34:41.073
a really large -- I think you call it
a "useless class" --

00:34:41.097 --> 00:34:43.200
a class where traditionally,

00:34:43.224 --> 00:34:45.955
as viewed by the economy,
these people have no use.

00:34:45.979 --> 00:34:47.177
YNH: Yes.

00:34:47.201 --> 00:34:50.132
CA: How likely a possibility is that?

00:34:50.156 --> 00:34:52.900
Is that something
we should be terrified about?

00:34:52.924 --> 00:34:55.583
And can we address it in any way?

00:34:55.607 --> 00:34:57.854
YNH: We should think about it
very carefully.

00:34:57.878 --> 00:35:00.849
I mean, nobody really knows
what the job market will look like

00:35:00.873 --> 00:35:02.563
in 2040, 2050.

00:35:02.587 --> 00:35:05.295
There is a chance
many new jobs will appear,

00:35:05.319 --> 00:35:07.073
but it's not certain.

00:35:07.097 --> 00:35:09.308
And even if new jobs do appear,

00:35:09.332 --> 00:35:11.316
it won't necessarily be easy

00:35:11.340 --> 00:35:14.339
for a 50-year old unemployed truck driver

00:35:14.363 --> 00:35:17.396
made unemployed by self-driving vehicles,

00:35:17.420 --> 00:35:21.073
it won't be easy
for an unemployed truck driver

00:35:21.097 --> 00:35:25.883
to reinvent himself or herself
as a designer of virtual worlds.

00:35:25.907 --> 00:35:30.089
Previously, if you look at the trajectory
of the industrial revolution,

00:35:30.113 --> 00:35:34.270
when machines replaced humans
in one type of work,

00:35:34.294 --> 00:35:38.575
the solution usually came
from low-skill work

00:35:38.599 --> 00:35:41.187
in new lines of business.

00:35:41.211 --> 00:35:44.613
So you didn't need any more
agricultural workers,

00:35:44.637 --> 00:35:50.051
so people moved to working
in low-skill industrial jobs,

00:35:50.075 --> 00:35:53.544
and when this was taken away
by more and more machines,

00:35:53.568 --> 00:35:56.538
people moved to low-skill service jobs.

00:35:56.562 --> 00:35:59.922
Now, when people say there will
be new jobs in the future,

00:35:59.946 --> 00:36:02.375
that humans can do better than AI,

00:36:02.399 --> 00:36:04.229
that humans can do better than robots,

00:36:04.253 --> 00:36:06.893
they usually think about high-skill jobs,

00:36:06.917 --> 00:36:10.788
like software engineers
designing virtual worlds.

00:36:10.812 --> 00:36:16.206
Now, I don't see how
an unemployed cashier from Wal-Mart

00:36:16.230 --> 00:36:20.853
reinvents herself or himself at 50
as a designer of virtual worlds,

00:36:20.877 --> 00:36:22.348
and certainly I don't see

00:36:22.372 --> 00:36:25.839
how the millions of unemployed
Bangladeshi textile workers

00:36:25.863 --> 00:36:27.474
will be able to do that.

00:36:27.498 --> 00:36:29.218
I mean, if they are going to do it,

00:36:29.242 --> 00:36:32.598
we need to start teaching
the Bangladeshis today

00:36:32.622 --> 00:36:34.376
how to be software designers,

00:36:34.400 --> 00:36:35.643
and we are not doing it.

00:36:35.667 --> 00:36:38.158
So what will they do in 20 years?

00:36:38.182 --> 00:36:42.096
CA: So it feels like you're really
highlighting a question

00:36:42.120 --> 00:36:46.303
that's really been bugging me
the last few months more and more.

00:36:46.327 --> 00:36:49.182
It's almost a hard question
to ask in public,

00:36:49.206 --> 00:36:52.597
but if any mind has some wisdom
to offer in it, maybe it's yours,

00:36:52.621 --> 00:36:54.166
so I'm going to ask you:

00:36:54.190 --> 00:36:56.068
What are humans for?

00:36:57.052 --> 00:36:58.986
YNH: As far as we know, for nothing.

00:36:59.010 --> 00:37:00.722
(Laughter)

00:37:00.746 --> 00:37:06.272
I mean, there is no great cosmic drama,
some great cosmic plan,

00:37:06.296 --> 00:37:09.137
that we have a role to play in.

00:37:09.161 --> 00:37:12.185
And we just need to discover
what our role is

00:37:12.209 --> 00:37:15.201
and then play it to the best
of our ability.

00:37:15.225 --> 00:37:20.203
This has been the story of all religions
and ideologies and so forth,

00:37:20.227 --> 00:37:23.705
but as a scientist, the best I can say
is this is not true.

00:37:23.729 --> 00:37:29.087
There is no universal drama
with a role in it for Homo sapiens.

00:37:29.111 --> 00:37:30.792
So --

00:37:30.816 --> 00:37:33.309
CA: I'm going to push back on you
just for a minute,

00:37:33.333 --> 00:37:34.527
just from your own book,

00:37:34.551 --> 00:37:35.875
because in "Homo Deus,"

00:37:35.899 --> 00:37:40.958
you give really one of the most coherent
and understandable accounts

00:37:40.982 --> 00:37:43.214
about sentience, about consciousness,

00:37:43.238 --> 00:37:46.196
and that unique sort of human skill.

00:37:46.220 --> 00:37:48.713
You point out that it's different
from intelligence,

00:37:48.737 --> 00:37:51.071
the intelligence
that we're building in machines,

00:37:51.095 --> 00:37:54.753
and that there's actually a lot
of mystery around it.

00:37:54.777 --> 00:37:58.154
How can you be sure there's no purpose

00:37:58.178 --> 00:38:02.229
when we don't even understand
what this sentience thing is?

00:38:02.253 --> 00:38:04.829
I mean, in your own thinking,
isn't there a chance

00:38:04.853 --> 00:38:09.165
that what humans are for
is to be the universe's sentient things,

00:38:09.189 --> 00:38:12.612
to be the centers of joy and love
and happiness and hope?

00:38:12.636 --> 00:38:15.671
And maybe we can build machines
that actually help amplify that,

00:38:15.695 --> 00:38:18.359
even if they're not going to become
sentient themselves?

00:38:18.383 --> 00:38:19.534
Is that crazy?

00:38:19.558 --> 00:38:23.041
I kind of found myself hoping that,
reading your book.

00:38:23.065 --> 00:38:26.922
YNH: Well, I certainly think that the most
interesting question today in science

00:38:26.946 --> 00:38:29.369
is the question
of consciousness and the mind.

00:38:29.393 --> 00:38:32.891
We are getting better and better
in understanding the brain

00:38:32.915 --> 00:38:34.175
and intelligence,

00:38:34.199 --> 00:38:36.736
but we are not getting much better

00:38:36.760 --> 00:38:39.103
in understanding the mind
and consciousness.

00:38:39.127 --> 00:38:42.489
People often confuse intelligence
and consciousness,

00:38:42.513 --> 00:38:44.812
especially in places like Silicon Valley,

00:38:44.836 --> 00:38:48.593
which is understandable,
because in humans, they go together.

00:38:48.617 --> 00:38:52.196
I mean, intelligence basically
is the ability to solve problems.

00:38:52.220 --> 00:38:54.762
Consciousness is the ability
to feel things,

00:38:54.786 --> 00:38:59.998
to feel joy and sadness
and boredom and pain and so forth.

00:39:00.022 --> 00:39:04.061
In Homo sapiens and all other mammals
as well -- it's not unique to humans --

00:39:04.085 --> 00:39:06.732
in all mammals and birds
and some other animals,

00:39:06.756 --> 00:39:09.406
intelligence and consciousness
go together.

00:39:09.430 --> 00:39:13.008
We often solve problems by feeling things.

00:39:13.032 --> 00:39:14.525
So we tend to confuse them.

00:39:14.549 --> 00:39:16.014
But they are different things.

00:39:16.038 --> 00:39:19.126
What's happening today
in places like Silicon Valley

00:39:19.150 --> 00:39:22.776
is that we are creating
artificial intelligence

00:39:22.800 --> 00:39:24.622
but not artificial consciousness.

00:39:24.646 --> 00:39:28.026
There has been an amazing development
in computer intelligence

00:39:28.050 --> 00:39:29.612
over the last 50 years,

00:39:29.636 --> 00:39:33.837
and exactly zero development
in computer consciousness,

00:39:33.861 --> 00:39:37.547
and there is no indication that computers
are going to become conscious

00:39:37.571 --> 00:39:40.102
anytime soon.

00:39:40.126 --> 00:39:45.776
So first of all, if there is
some cosmic role for consciousness,

00:39:45.800 --> 00:39:47.930
it's not unique to Homo sapiens.

00:39:47.954 --> 00:39:50.273
Cows are conscious, pigs are conscious,

00:39:50.297 --> 00:39:53.130
chimpanzees are conscious,
chickens are conscious,

00:39:53.154 --> 00:39:57.007
so if we go that way, first of all,
we need to broaden our horizons

00:39:57.031 --> 00:40:01.756
and remember very clearly we are not
the only sentient beings on Earth,

00:40:01.780 --> 00:40:03.575
and when it comes to sentience --

00:40:03.599 --> 00:40:06.911
when it comes to intelligence,
there is good reason to think

00:40:06.935 --> 00:40:10.231
we are the most intelligent
of the whole bunch.

00:40:10.255 --> 00:40:12.829
But when it comes to sentience,

00:40:12.853 --> 00:40:16.011
to say that humans are more
sentient than whales,

00:40:16.035 --> 00:40:20.182
or more sentient than baboons
or more sentient than cats,

00:40:20.206 --> 00:40:22.500
I see no evidence for that.

00:40:22.524 --> 00:40:26.131
So first step is, you go
in that direction, expand.

00:40:26.155 --> 00:40:30.137
And then the second question
of what is it for,

00:40:30.161 --> 00:40:31.943
I would reverse it

00:40:31.967 --> 00:40:36.203
and I would say that I don't think
sentience is for anything.

00:40:36.227 --> 00:40:40.399
I think we don't need
to find our role in the universe.

00:40:40.423 --> 00:40:46.236
The really important thing
is to liberate ourselves from suffering.

00:40:46.260 --> 00:40:49.253
What characterizes sentient beings

00:40:49.277 --> 00:40:51.997
in contrast to robots, to stones,

00:40:52.021 --> 00:40:53.204
to whatever,

00:40:53.228 --> 00:40:57.019
is that sentient beings
suffer, can suffer,

00:40:57.043 --> 00:40:59.383
and what they should focus on

00:40:59.407 --> 00:41:03.527
is not finding their place
in some mysterious cosmic drama.

00:41:03.551 --> 00:41:07.370
They should focus on understanding
what suffering is,

00:41:07.394 --> 00:41:10.753
what causes it and how
to be liberated from it.

00:41:11.392 --> 00:41:14.869
CA: I know this is a big issue for you,
and that was very eloquent.

00:41:14.893 --> 00:41:18.307
We're going to have a blizzard
of questions from the audience here,

00:41:18.331 --> 00:41:20.251
and maybe from Facebook as well,

00:41:20.275 --> 00:41:21.948
and maybe some comments as well.

00:41:21.972 --> 00:41:23.768
So let's go quick.

00:41:23.792 --> 00:41:25.222
There's one right here.

00:41:26.872 --> 00:41:29.681
Keep your hands held up
at the back if you want the mic,

00:41:29.705 --> 00:41:31.124
and we'll get it back to you.

00:41:31.148 --> 00:41:34.267
Question: In your work, you talk a lot
about the fictional stories

00:41:34.291 --> 00:41:35.635
that we accept as truth,

00:41:35.659 --> 00:41:37.376
and we live our lives by it.

00:41:37.400 --> 00:41:39.899
As an individual, knowing that,

00:41:39.923 --> 00:41:43.669
how does it impact the stories
that you choose to live your life,

00:41:43.693 --> 00:41:47.433
and do you confuse them
with the truth, like all of us?

00:41:48.066 --> 00:41:49.277
YNH: I try not to.

00:41:49.301 --> 00:41:52.069
I mean, for me, maybe the most
important question,

00:41:52.093 --> 00:41:54.571
both as a scientist and as a person,

00:41:54.595 --> 00:41:58.470
is how to tell the difference
between fiction and reality,

00:41:58.494 --> 00:42:01.090
because reality is there.

00:42:01.114 --> 00:42:03.196
I'm not saying that everything is fiction.

00:42:03.220 --> 00:42:06.272
It's just very difficult for human beings
to tell the difference

00:42:06.296 --> 00:42:07.913
between fiction and reality,

00:42:07.937 --> 00:42:12.882
and it has become more and more difficult
as history progressed,

00:42:12.906 --> 00:42:15.357
because the fictions
that we have created --

00:42:15.381 --> 00:42:18.549
nations and gods and money
and corporations --

00:42:18.573 --> 00:42:20.083
they now control the world.

00:42:20.107 --> 00:42:21.284
So just to even think,

00:42:21.308 --> 00:42:24.453
"Oh, this is just all fictional entities
that we've created,"

00:42:24.477 --> 00:42:25.924
is very difficult.

00:42:25.948 --> 00:42:28.228
But reality is there.

00:42:28.863 --> 00:42:30.868
For me the best ...

00:42:30.892 --> 00:42:33.015
There are several tests

00:42:33.039 --> 00:42:35.809
to tell the difference
between fiction and reality.

00:42:35.833 --> 00:42:39.259
The simplest one, the best one
that I can say in short,

00:42:39.283 --> 00:42:40.864
is the test of suffering.

00:42:40.888 --> 00:42:42.441
If it can suffer, it's real.

00:42:43.012 --> 00:42:44.706
If it can't suffer, it's not real.

00:42:44.730 --> 00:42:46.195
A nation cannot suffer.

00:42:46.219 --> 00:42:47.789
That's very, very clear.

00:42:47.813 --> 00:42:49.751
Even if a nation loses a war,

00:42:49.775 --> 00:42:53.840
we say, "Germany suffered a defeat
in the First World War,"

00:42:53.864 --> 00:42:55.029
it's a metaphor.

00:42:55.053 --> 00:42:57.610
Germany cannot suffer.
Germany has no mind.

00:42:57.634 --> 00:42:59.287
Germany has no consciousness.

00:42:59.311 --> 00:43:02.969
Germans can suffer, yes,
but Germany cannot.

00:43:02.993 --> 00:43:05.962
Similarly, when a bank goes bust,

00:43:05.986 --> 00:43:07.757
the bank cannot suffer.

00:43:07.781 --> 00:43:11.172
When the dollar loses its value,
the dollar doesn't suffer.

00:43:11.196 --> 00:43:13.446
People can suffer. Animals can suffer.

00:43:13.470 --> 00:43:14.626
This is real.

00:43:14.650 --> 00:43:19.179
So I would start, if you
really want to see reality,

00:43:19.203 --> 00:43:21.267
I would go through the door of suffering.

00:43:21.291 --> 00:43:24.245
If you can really understand
what suffering is,

00:43:24.269 --> 00:43:26.492
this will give you also the key

00:43:26.516 --> 00:43:28.533
to understand what reality is.

00:43:28.557 --> 00:43:31.340
CA: There's a Facebook question
here that connects to this,

00:43:31.364 --> 00:43:34.341
from someone around the world
in a language that I cannot read.

00:43:34.365 --> 00:43:36.582
YNH: Oh, it's Hebrew.
CA: Hebrew. There you go.

00:43:36.606 --> 00:43:37.668
(Laughter)

00:43:37.692 --> 00:43:38.856
Can you read the name?

00:43:38.880 --> 00:43:40.755
YNH: Or Lauterbach Goren.

00:43:40.779 --> 00:43:42.623
CA: Well, thank you for writing in.

00:43:42.647 --> 00:43:47.202
The question is: "Is the post-truth era
really a brand-new era,

00:43:47.226 --> 00:43:51.613
or just another climax or moment
in a never-ending trend?

00:43:52.521 --> 00:43:55.850
YNH: Personally, I don't connect
with this idea of post-truth.

00:43:55.874 --> 00:43:58.582
My basic reaction as a historian is:

00:43:58.606 --> 00:44:02.501
If this is the era of post-truth,
when the hell was the era of truth?

00:44:02.525 --> 00:44:03.776
CA: Right.

00:44:03.800 --> 00:44:05.120
(Laughter)

00:44:05.144 --> 00:44:09.827
YNH: Was it the 1980s, the 1950s,
the Middle Ages?

00:44:09.851 --> 00:44:14.243
I mean, we have always lived
in an era, in a way, of post-truth.

00:44:14.703 --> 00:44:17.014
CA: But I'd push back on that,

00:44:17.038 --> 00:44:19.708
because I think what people
are talking about

00:44:19.732 --> 00:44:26.692
is that there was a world
where you had fewer journalistic outlets,

00:44:26.716 --> 00:44:30.364
where there were traditions,
that things were fact-checked.

00:44:30.388 --> 00:44:34.333
It was incorporated into the charter
of those organizations

00:44:34.357 --> 00:44:36.524
that the truth mattered.

00:44:36.548 --> 00:44:38.297
So if you believe in a reality,

00:44:38.321 --> 00:44:40.544
then what you write is information.

00:44:40.568 --> 00:44:44.389
There was a belief that that information
should connect to reality in a real way,

00:44:44.413 --> 00:44:47.374
and if you wrote a headline,
it was a serious, earnest attempt

00:44:47.398 --> 00:44:49.701
to reflect something
that had actually happened.

00:44:49.725 --> 00:44:51.576
And people didn't always get it right.

00:44:51.600 --> 00:44:53.609
But I think the concern now is you've got

00:44:53.633 --> 00:44:55.951
a technological system
that's incredibly powerful

00:44:55.975 --> 00:45:00.145
that, for a while at least,
massively amplified anything

00:45:00.169 --> 00:45:02.949
with no attention paid to whether
it connected to reality,

00:45:02.973 --> 00:45:06.127
only to whether it connected
to clicks and attention,

00:45:06.151 --> 00:45:07.767
and that that was arguably toxic.

00:45:07.791 --> 00:45:10.227
That's a reasonable concern, isn't it?

00:45:10.251 --> 00:45:12.537
YNH: Yeah, it is. I mean,
the technology changes,

00:45:12.561 --> 00:45:17.789
and it's now easier to disseminate
both truth and fiction and falsehood.

00:45:17.813 --> 00:45:19.816
It goes both ways.

00:45:19.840 --> 00:45:24.419
It's also much easier, though, to spread
the truth than it was ever before.

00:45:24.443 --> 00:45:28.128
But I don't think there
is anything essentially new

00:45:28.152 --> 00:45:32.872
about this disseminating
fictions and errors.

00:45:32.896 --> 00:45:36.930
There is nothing that -- I don't know --
Joseph Goebbels, didn't know

00:45:36.954 --> 00:45:42.393
about all this idea of fake
news and post-truth.

00:45:42.417 --> 00:45:46.135
He famously said that if you repeat
a lie often enough,

00:45:46.159 --> 00:45:47.980
people will think it's the truth,

00:45:48.004 --> 00:45:50.360
and the bigger the lie, the better,

00:45:50.384 --> 00:45:56.407
because people won't even think
that something so big can be a lie.

00:45:56.431 --> 00:46:02.089
I think that fake news
has been with us for thousands of years.

00:46:02.113 --> 00:46:04.014
Just think of the Bible.

00:46:04.038 --> 00:46:05.425
(Laughter)

00:46:05.449 --> 00:46:06.736
CA: But there is a concern

00:46:06.760 --> 00:46:10.777
that the fake news is associated
with tyrannical regimes,

00:46:10.801 --> 00:46:13.378
and when you see an uprise in fake news

00:46:13.402 --> 00:46:18.124
that is a canary in the coal mine
that there may be dark times coming.

00:46:19.944 --> 00:46:26.906
YNH: Yeah. I mean, the intentional use
of fake news is a disturbing sign.

00:46:27.632 --> 00:46:32.213
But I'm not saying that it's not bad,
I'm just saying that it's not new.

00:46:32.640 --> 00:46:35.394
CA: There's a lot of interest
on Facebook on this question

00:46:35.418 --> 00:46:40.418
about global governance
versus nationalism.

00:46:41.112 --> 00:46:42.620
Question here from Phil Dennis:

00:46:42.644 --> 00:46:46.140
"How do we get people, governments,
to relinquish power?

00:46:46.164 --> 00:46:50.079
Is that -- is that --
actually, the text is so big

00:46:50.103 --> 00:46:51.643
I can't read the full question.

00:46:51.667 --> 00:46:53.206
But is that a necessity?

00:46:53.230 --> 00:46:55.842
Is it going to take war to get there?

00:46:55.866 --> 00:46:59.556
Sorry Phil -- I mangled your question,
but I blame the text right here.

00:46:59.580 --> 00:47:01.680
YNH: One option
that some people talk about

00:47:01.704 --> 00:47:06.443
is that only a catastrophe
can shake humankind

00:47:06.467 --> 00:47:11.731
and open the path to a real system
of global governance,

00:47:11.755 --> 00:47:15.903
and they say that we can't do it
before the catastrophe,

00:47:15.927 --> 00:47:18.728
but we need to start
laying the foundations

00:47:18.752 --> 00:47:21.252
so that when the disaster strikes,

00:47:21.276 --> 00:47:23.458
we can react quickly.

00:47:23.482 --> 00:47:27.482
But people will just not have
the motivation to do such a thing

00:47:27.506 --> 00:47:29.518
before the disaster strikes.

00:47:29.542 --> 00:47:31.807
Another thing that I would emphasize

00:47:31.831 --> 00:47:36.885
is that anybody who is really
interested in global governance

00:47:36.909 --> 00:47:39.810
should always make it very, very clear

00:47:39.834 --> 00:47:46.418
that it doesn't replace or abolish
local identities and communities,

00:47:46.442 --> 00:47:49.398
that it should come both as --

00:47:49.422 --> 00:47:52.729
It should be part of a single package.

00:47:52.753 --> 00:47:56.131
CA: I want to hear more on this,

00:47:56.155 --> 00:47:59.208
because the very words "global governance"

00:47:59.232 --> 00:48:03.821
are almost the epitome of evil
in the mindset of a lot of people

00:48:03.845 --> 00:48:05.171
on the alt-right right now.

00:48:05.195 --> 00:48:08.149
It just seems scary, remote, distant,
and it has let them down,

00:48:08.173 --> 00:48:12.289
and so globalists,
global governance -- no, go away!

00:48:12.313 --> 00:48:15.995
And many view the election
as the ultimate poke in the eye

00:48:16.019 --> 00:48:17.497
to anyone who believes in that.

00:48:17.521 --> 00:48:21.072
So how do we change the narrative

00:48:21.096 --> 00:48:24.071
so that it doesn't seem
so scary and remote?

00:48:24.095 --> 00:48:26.839
Build more on this idea
of it being compatible

00:48:26.863 --> 00:48:29.484
with local identity, local communities.

00:48:29.508 --> 00:48:32.108
YNH: Well, I think again we should start

00:48:32.132 --> 00:48:35.264
really with the biological realities

00:48:35.288 --> 00:48:37.299
of Homo sapiens.

00:48:37.323 --> 00:48:41.441
And biology tells us two things
about Homo sapiens

00:48:41.465 --> 00:48:43.722
which are very relevant to this issue:

00:48:43.746 --> 00:48:46.775
first of all, that we are
completely dependent

00:48:46.799 --> 00:48:49.394
on the ecological system around us,

00:48:49.418 --> 00:48:52.877
and that today we are talking
about a global system.

00:48:52.901 --> 00:48:54.258
You cannot escape that.

00:48:54.282 --> 00:48:57.904
And at the same time, biology tells us
about Homo sapiens

00:48:57.928 --> 00:49:00.175
that we are social animals,

00:49:00.199 --> 00:49:04.836
but that we are social
on a very, very local level.

00:49:04.860 --> 00:49:08.405
It's just a simple fact of humanity

00:49:08.429 --> 00:49:13.226
that we cannot have intimate familiarity

00:49:13.250 --> 00:49:17.125
with more than about 150 individuals.

00:49:17.149 --> 00:49:21.446
The size of the natural group,

00:49:21.470 --> 00:49:24.572
the natural community of Homo sapiens,

00:49:24.596 --> 00:49:27.940
is not more than 150 individuals,

00:49:27.964 --> 00:49:34.363
and everything beyond that is really
based on all kinds of imaginary stories

00:49:34.387 --> 00:49:36.434
and large-scale institutions,

00:49:36.458 --> 00:49:40.834
and I think that we can find a way,

00:49:40.858 --> 00:49:45.428
again, based on a biological
understanding of our species,

00:49:45.452 --> 00:49:47.534
to weave the two together

00:49:47.558 --> 00:49:50.634
and to understand that today
in the 21st century,

00:49:50.658 --> 00:49:56.194
we need both the global level
and the local community.

00:49:56.218 --> 00:49:58.235
And I would go even further than that

00:49:58.259 --> 00:50:01.582
and say that it starts
with the body itself.

00:50:02.320 --> 00:50:06.662
The feelings that people today have
of alienation and loneliness

00:50:06.686 --> 00:50:09.902
and not finding their place in the world,

00:50:09.926 --> 00:50:15.655
I would think that the chief problem
is not global capitalism.

00:50:16.105 --> 00:50:19.131
The chief problem is that over
the last hundred years,

00:50:19.155 --> 00:50:22.859
people have been becoming disembodied,

00:50:22.883 --> 00:50:26.042
have been distancing themselves
from their body.

00:50:26.066 --> 00:50:28.962
As a hunter-gatherer or even as a peasant,

00:50:28.986 --> 00:50:33.184
to survive, you need to be
constantly in touch

00:50:33.208 --> 00:50:35.391
with your body and with your senses,

00:50:35.415 --> 00:50:36.596
every moment.

00:50:36.620 --> 00:50:38.767
If you go to the forest
to look for mushrooms

00:50:38.791 --> 00:50:41.168
and you don't pay attention
to what you hear,

00:50:41.192 --> 00:50:43.068
to what you smell, to what you taste,

00:50:43.092 --> 00:50:44.243
you're dead.

00:50:44.267 --> 00:50:46.418
So you must be very connected.

00:50:46.442 --> 00:50:51.038
In the last hundred years,
people are losing their ability

00:50:51.062 --> 00:50:53.934
to be in touch with their body
and their senses,

00:50:53.958 --> 00:50:56.144
to hear, to smell, to feel.

00:50:56.168 --> 00:50:59.294
More and more attention goes to screens,

00:50:59.318 --> 00:51:00.838
to what is happening elsewhere,

00:51:00.862 --> 00:51:02.083
some other time.

00:51:02.107 --> 00:51:04.538
This, I think, is the deep reason

00:51:04.562 --> 00:51:08.456
for the feelings of alienation
and loneliness and so forth,

00:51:08.480 --> 00:51:10.982
and therefore part of the solution

00:51:11.006 --> 00:51:15.270
is not to bring back
some mass nationalism,

00:51:15.294 --> 00:51:19.418
but also reconnect with our own bodies,

00:51:19.442 --> 00:51:22.705
and if you are back
in touch with your body,

00:51:22.729 --> 00:51:25.899
you will feel much more at home
in the world also.

00:51:25.923 --> 00:51:29.608
CA: Well, depending on how things go,
we may all be back in the forest soon.

00:51:29.632 --> 00:51:31.981
We're going to have
one more question in the room

00:51:32.005 --> 00:51:33.508
and one more on Facebook.

00:51:33.532 --> 00:51:36.913
Ama Adi-Dako: Hello. I'm from Ghana,
West Africa, and my question is:

00:51:36.937 --> 00:51:41.539
I'm wondering how do you present
and justify the idea of global governance

00:51:41.563 --> 00:51:44.574
to countries that have been
historically disenfranchised

00:51:44.598 --> 00:51:46.643
by the effects of globalization,

00:51:46.667 --> 00:51:49.413
and also, if we're talking about
global governance,

00:51:49.437 --> 00:51:53.061
it sounds to me like it will definitely
come from a very Westernized idea

00:51:53.085 --> 00:51:55.259
of what the "global"
is supposed to look like.

00:51:55.283 --> 00:51:58.573
So how do we present and justify
that idea of global

00:51:58.597 --> 00:52:01.590
versus wholly nationalist

00:52:01.614 --> 00:52:04.949
to people in countries like Ghana
and Nigeria and Togo

00:52:04.973 --> 00:52:07.149
and other countries like that?

00:52:07.951 --> 00:52:14.365
YNH: I would start by saying
that history is extremely unfair,

00:52:14.389 --> 00:52:18.311
and that we should realize that.

00:52:18.824 --> 00:52:21.873
Many of the countries that suffered most

00:52:21.897 --> 00:52:26.036
from the last 200 years of globalization

00:52:26.060 --> 00:52:28.020
and imperialism and industrialization

00:52:28.044 --> 00:52:33.754
are exactly the countries
which are also most likely to suffer most

00:52:33.778 --> 00:52:36.567
from the next wave.

00:52:36.591 --> 00:52:40.585
And we should be very,
very clear about that.

00:52:41.297 --> 00:52:44.348
If we don't have a global governance,

00:52:44.372 --> 00:52:47.575
and if we suffer from climate change,

00:52:47.599 --> 00:52:49.856
from technological disruptions,

00:52:49.880 --> 00:52:53.481
the worst suffering will not be in the US.

00:52:53.505 --> 00:52:58.601
The worst suffering will be in Ghana,
will be in Sudan, will be in Syria,

00:52:58.625 --> 00:53:01.362
will be in Bangladesh,
will be in those places.

00:53:01.386 --> 00:53:07.422
So I think those countries
have an even greater incentive

00:53:07.446 --> 00:53:12.173
to do something about
the next wave of disruption,

00:53:12.197 --> 00:53:14.722
whether it's ecological
or whether it's technological.

00:53:14.746 --> 00:53:17.592
Again, if you think about
technological disruption,

00:53:17.616 --> 00:53:22.232
so if AI and 3D printers and robots
will take the jobs

00:53:22.256 --> 00:53:24.625
from billions of people,

00:53:24.649 --> 00:53:27.774
I worry far less about the Swedes

00:53:27.798 --> 00:53:31.403
than about the people in Ghana
or in Bangladesh.

00:53:31.427 --> 00:53:36.655
And therefore,
because history is so unfair

00:53:36.679 --> 00:53:41.025
and the results of a calamity

00:53:41.049 --> 00:53:43.417
will not be shared equally
between everybody,

00:53:43.441 --> 00:53:47.874
as usual, the rich
will be able to get away

00:53:47.898 --> 00:53:51.370
from the worst consequences
of climate change

00:53:51.394 --> 00:53:54.239
in a way that the poor
will not be able to.

00:53:55.167 --> 00:53:58.575
CA: And here's a great question
from Cameron Taylor on Facebook:

00:53:58.599 --> 00:54:00.720
"At the end of 'Sapiens,'"

00:54:00.744 --> 00:54:02.807
you said we should be asking the question,

00:54:02.831 --> 00:54:05.187
'What do we want to want?'

00:54:05.211 --> 00:54:08.198
Well, what do you think
we should want to want?"

00:54:08.222 --> 00:54:11.753
YNH: I think we should want
to want to know the truth,

00:54:11.777 --> 00:54:14.427
to understand reality.

00:54:15.027 --> 00:54:20.141
Mostly what we want is to change reality,

00:54:20.165 --> 00:54:23.883
to fit it to our own desires,
to our own wishes,

00:54:23.907 --> 00:54:27.627
and I think we should first
want to understand it.

00:54:27.651 --> 00:54:31.415
If you look at the long-term
trajectory of history,

00:54:31.439 --> 00:54:34.175
what you see is that
for thousands of years

00:54:34.199 --> 00:54:37.535
we humans have been gaining
control of the world outside us

00:54:37.559 --> 00:54:41.053
and trying to shape it
to fit our own desires.

00:54:41.077 --> 00:54:44.265
And we've gained control
of the other animals,

00:54:44.289 --> 00:54:45.820
of the rivers, of the forests,

00:54:45.844 --> 00:54:49.337
and reshaped them completely,

00:54:49.361 --> 00:54:52.722
causing an ecological destruction

00:54:52.746 --> 00:54:55.924
without making ourselves satisfied.

00:54:55.948 --> 00:54:59.750
So the next step
is we turn our gaze inwards,

00:54:59.774 --> 00:55:04.322
and we say OK, getting control
of the world outside us

00:55:04.346 --> 00:55:06.210
did not really make us satisfied.

00:55:06.234 --> 00:55:08.933
Let's now try to gain control
of the world inside us.

00:55:08.957 --> 00:55:11.120
This is the really big project

00:55:11.144 --> 00:55:15.440
of science and technology
and industry in the 21st century --

00:55:15.464 --> 00:55:18.986
to try and gain control
of the world inside us,

00:55:19.010 --> 00:55:23.933
to learn how to engineer and produce
bodies and brains and minds.

00:55:23.957 --> 00:55:28.599
These are likely to be the main
products of the 21st century economy.

00:55:28.623 --> 00:55:32.444
When people think about the future,
very often they think in terms,

00:55:32.468 --> 00:55:36.415
"Oh, I want to gain control
of my body and of my brain."

00:55:36.439 --> 00:55:39.249
And I think that's very dangerous.

00:55:39.273 --> 00:55:42.539
If we've learned anything
from our previous history,

00:55:42.563 --> 00:55:46.476
it's that yes, we gain
the power to manipulate,

00:55:46.500 --> 00:55:49.290
but because we didn't really
understand the complexity

00:55:49.314 --> 00:55:51.119
of the ecological system,

00:55:51.143 --> 00:55:54.833
we are now facing an ecological meltdown.

00:55:54.857 --> 00:56:00.263
And if we now try to reengineer
the world inside us

00:56:00.287 --> 00:56:02.419
without really understanding it,

00:56:02.443 --> 00:56:06.759
especially without understanding
the complexity of our mental system,

00:56:06.783 --> 00:56:11.443
we might cause a kind of internal
ecological disaster,

00:56:11.467 --> 00:56:15.010
and we'll face a kind of mental
meltdown inside us.

00:56:16.090 --> 00:56:18.532
CA: Putting all the pieces
together here --

00:56:18.556 --> 00:56:21.236
the current politics,
the coming technology,

00:56:21.260 --> 00:56:23.410
concerns like the one
you've just outlined --

00:56:23.434 --> 00:56:26.529
I mean, it seems like you yourself
are in quite a bleak place

00:56:26.553 --> 00:56:28.174
when you think about the future.

00:56:28.198 --> 00:56:29.780
You're pretty worried about it.

00:56:29.804 --> 00:56:30.996
Is that right?

00:56:31.020 --> 00:56:37.708
And if there was one cause for hope,
how would you state that?

00:56:37.732 --> 00:56:41.895
YNH: I focus on the most
dangerous possibilities

00:56:41.919 --> 00:56:44.940
partly because this is like
my job or responsibility

00:56:44.964 --> 00:56:46.745
as a historian or social critic.

00:56:46.769 --> 00:56:51.531
I mean, the industry focuses mainly
on the positive sides,

00:56:51.555 --> 00:56:54.916
so it's the job of historians
and philosophers and sociologists

00:56:54.940 --> 00:56:59.381
to highlight the more dangerous potential
of all these new technologies.

00:56:59.405 --> 00:57:01.888
I don't think any of that is inevitable.

00:57:01.912 --> 00:57:04.951
Technology is never deterministic.

00:57:04.975 --> 00:57:06.692
You can use the same technology

00:57:06.716 --> 00:57:09.707
to create very different
kinds of societies.

00:57:09.731 --> 00:57:11.769
If you look at the 20th century,

00:57:11.793 --> 00:57:14.574
so, the technologies
of the Industrial Revolution,

00:57:14.598 --> 00:57:17.655
the trains and electricity and all that

00:57:17.679 --> 00:57:20.731
could be used to create
a communist dictatorship

00:57:20.755 --> 00:57:23.560
or a fascist regime
or a liberal democracy.

00:57:23.584 --> 00:57:26.112
The trains did not tell you
what to do with them.

00:57:26.136 --> 00:57:30.588
Similarly, now, artificial intelligence
and bioengineering and all of that --

00:57:30.612 --> 00:57:34.126
they don't predetermine a single outcome.

00:57:34.706 --> 00:57:37.883
Humanity can rise up to the challenge,

00:57:37.907 --> 00:57:39.598
and the best example we have

00:57:39.622 --> 00:57:43.362
of humanity rising up
to the challenge of a new technology

00:57:43.386 --> 00:57:45.109
is nuclear weapons.

00:57:45.133 --> 00:57:48.142
In the late 1940s, '50s,

00:57:48.166 --> 00:57:50.305
many people were convinced

00:57:50.329 --> 00:57:54.635
that sooner or later the Cold War
will end in a nuclear catastrophe,

00:57:54.659 --> 00:57:56.434
destroying human civilization.

00:57:56.458 --> 00:57:57.938
And this did not happen.

00:57:57.962 --> 00:58:04.382
In fact, nuclear weapons prompted
humans all over the world

00:58:04.406 --> 00:58:09.147
to change the way that they manage
international politics

00:58:09.171 --> 00:58:11.540
to reduce violence.

00:58:11.564 --> 00:58:14.803
And many countries basically took out war

00:58:14.827 --> 00:58:16.701
from their political toolkit.

00:58:16.725 --> 00:58:20.995
They no longer tried to pursue
their interests with warfare.

00:58:21.400 --> 00:58:24.670
Not all countries have done so,
but many countries have.

00:58:24.694 --> 00:58:28.628
And this is maybe
the most important reason

00:58:28.652 --> 00:58:34.754
why international violence
declined dramatically since 1945,

00:58:34.778 --> 00:58:38.116
and today, as I said,
more people commit suicide

00:58:38.140 --> 00:58:40.347
than are killed in war.

00:58:40.371 --> 00:58:45.200
So this, I think, gives us a good example

00:58:45.224 --> 00:58:49.066
that even the most frightening technology,

00:58:49.090 --> 00:58:51.625
humans can rise up to the challenge

00:58:51.649 --> 00:58:54.672
and actually some good can come out of it.

00:58:54.696 --> 00:58:58.983
The problem is, we have very little
margin for error.

00:58:59.007 --> 00:59:01.216
If we don't get it right,

00:59:01.240 --> 00:59:04.911
we might not have
a second option to try again.

00:59:06.157 --> 00:59:07.724
CA: That's a very powerful note,

00:59:07.748 --> 00:59:10.553
on which I think we should draw
this to a conclusion.

00:59:10.577 --> 00:59:13.688
Before I wrap up, I just want to say
one thing to people here

00:59:13.712 --> 00:59:19.258
and to the global TED community
watching online, anyone watching online:

00:59:19.282 --> 00:59:22.175
help us with these dialogues.

00:59:22.199 --> 00:59:24.749
If you believe, like we do,

00:59:24.773 --> 00:59:27.753
that we need to find
a different kind of conversation,

00:59:27.777 --> 00:59:30.010
now more than ever, help us do it.

00:59:30.034 --> 00:59:32.057
Reach out to other people,

00:59:33.089 --> 00:59:35.829
try and have conversations
with people you disagree with,

00:59:35.853 --> 00:59:37.036
understand them,

00:59:37.060 --> 00:59:38.590
pull the pieces together,

00:59:38.614 --> 00:59:42.506
and help us figure out how to take
these conversations forward

00:59:42.530 --> 00:59:44.784
so we can make a real contribution

00:59:44.808 --> 00:59:47.553
to what's happening
in the world right now.

00:59:47.577 --> 00:59:50.896
I think everyone feels more alive,

00:59:50.920 --> 00:59:53.230
more concerned, more engaged

00:59:53.254 --> 00:59:55.783
with the politics of the moment.

00:59:55.807 --> 00:59:58.261
The stakes do seem quite high,

00:59:58.285 --> 01:00:02.797
so help us respond to it
in a wise, wise way.

01:00:02.821 --> 01:00:04.416
Yuval Harari, thank you.

01:00:04.440 --> 01:00:07.748
(Applause)

