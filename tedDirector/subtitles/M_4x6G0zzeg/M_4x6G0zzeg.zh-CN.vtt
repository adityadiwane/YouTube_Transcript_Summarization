WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:07.000
翻译人员: Wei Shao
校对人员: Chen Zou 

00:00:12.530 --> 00:00:17.070
人们借助各种媒体来谈性
已经有着很长的历史了

00:00:17.530 --> 00:00:20.820
比如说情书、电话性爱以及裸照

00:00:21.410 --> 00:00:27.400
甚至有这样一个女孩与一个通过
电报认识的男子私奔的故事

00:00:27.400 --> 00:00:28.890
在1886年

00:00:30.400 --> 00:00:35.360
直到今天，我们演变出了一种短信称之为[色情短信]
我是这方面的专家

00:00:35.500 --> 00:00:37.990
我作为专家是研究它的
可不擅长于发这个

00:00:38.650 --> 00:00:42.820
嗯，我想在座的各位和我一样
十分清楚这代表着什么

00:00:42.850 --> 00:00:44.220
（这指代着男性的阴茎）

00:00:44.220 --> 00:00:46.300
（观众笑声）

00:00:48.190 --> 00:00:54.200
自从2008年媒体开始关注以来
我一直致力于研究色情短信

00:00:54.320 --> 00:00:57.520
我撰写了一本书专门讨论
色情短信的出现所引起的道德恐慌

00:00:57.540 --> 00:00:59.160
这是我发现的：

00:00:59.180 --> 00:01:02.380
大部分的人都在担心
错误的事情

00:01:02.380 --> 00:01:06.350
他们试图从根源上
防止色情短信的产生

00:01:06.620 --> 00:01:07.770
但是我不禁要问：

00:01:08.040 --> 00:01:12.760
只要是完全自愿的
色情短信的问题在哪儿？

00:01:13.060 --> 00:01:17.080
人们试图去理清各种各样的事
甚至是与自己毫不相干的事

00:01:17.100 --> 00:01:19.230
比如蓝奶酪或香菜

00:01:19.420 --> 00:01:21.060
（观众笑声）

00:01:22.420 --> 00:01:26.560
色情短信和其它好玩的事情一样
是绝对有风险性的

00:01:26.580 --> 00:01:33.280
但是只要你给愿意接受的人们发

00:01:33.300 --> 00:01:34.480
也未尝不可

00:01:35.020 --> 00:01:37.720
我认为这其中一个严重的问题

00:01:37.740 --> 00:01:41.000
是人们未经他人同意

00:01:41.020 --> 00:01:42.540
分享他人的隐私照片

00:01:43.180 --> 00:01:45.590
与其忧心于色情短信本身

00:01:45.590 --> 00:01:50.100
我想我们该更关注的
是数字时代的个人隐私

00:01:50.700 --> 00:01:52.490
关键是同意

00:01:53.500 --> 00:01:56.800
现在很多人在想着
色情短信本身

00:01:56.820 --> 00:01:59.530
而完全忽略了
“他人的同意”

00:02:00.220 --> 00:02:04.160
你们知道我们现在在将青少年
发送色情短信违法化吗？

00:02:05.220 --> 00:02:08.680
它可以是一个罪犯是由于
它可以被当作儿童色情

00:02:08.700 --> 00:02:11.560
如果有一个当事人18岁以下的照片

00:02:11.600 --> 00:02:14.810
是否他们自愿拍照以及自愿
分享照片

00:02:14.810 --> 00:02:17.140
是无关紧要的

00:02:17.620 --> 00:02:20.600
结果我们就有了这种
怪异的法律情况

00:02:20.620 --> 00:02:25.050
即在美国大多数州
两个17岁的孩子可以合法性交

00:02:25.050 --> 00:02:27.060
但不能把它拍出来

00:02:28.380 --> 00:02:32.640
一些州还试图对色情短信立法

00:02:32.660 --> 00:02:35.680
但是这些立法都重复了同样的问题

00:02:35.700 --> 00:02:39.460
因为他们仍然使得
两厢情愿的性短信违法

00:02:40.340 --> 00:02:44.210
通过禁止所有形式的色情短信
来试图解决隐私侵权问题

00:02:44.210 --> 00:02:46.210
其实都是徒劳

00:02:46.390 --> 00:02:47.920
这种做法就像是

00:02:47.920 --> 00:02:53.340
让我们通过宣布约会违法
来解决约会强奸的问题

00:02:54.940 --> 00:03:00.410
大部分青少年不会因发送色情短信而被捕
不过你们能猜到谁被捕了？

00:03:00.410 --> 00:03:05.360
就是那些不被发送色情短信的
对象的父母喜欢的人

00:03:05.360 --> 00:03:10.140
这也许源于阶层差异
种族歧视以及对同性恋的憎恶

00:03:10.780 --> 00:03:13.600
大部分的检举人还很明智

00:03:13.600 --> 00:03:19.220
不对青少年以儿童色情罪起诉
但是有一些人这么做

00:03:19.540 --> 00:03:23.190
根据新罕布什尔大学的调查研究

00:03:23.190 --> 00:03:28.880
因儿童色情被捕的人群中
有百分之七都是青少年

00:03:28.900 --> 00:03:31.900
而他们都是两厢情愿的发送色情短信

00:03:33.300 --> 00:03:35.840
儿童色情是重罪

00:03:35.860 --> 00:03:39.540
但是与青少年的色情短信
还是有所差异的

00:03:40.860 --> 00:03:44.280
很多父母和教育工作者
也都往往不假思索的

00:03:44.300 --> 00:03:47.440
对色情短信作出反应
而不去认真思考同意的问题

00:03:47.460 --> 00:03:51.580
他们往往冷冰冰的告诉孩子们
不要这么做

00:03:52.020 --> 00:03:55.720
我也完全明白
这其中包含很严重的法律风险

00:03:55.720 --> 00:03:58.830
当然，也可能触犯私人隐私

00:03:59.220 --> 00:04:00.480
你们还是青少年的时候

00:04:00.500 --> 00:04:03.900
肯定也按吩咐办事，对吧？

00:04:05.260 --> 00:04:08.720
你可能认为
我的孩子从不发色情短信

00:04:08.740 --> 00:04:12.200
的确，你的小宝贝
可能不会发色情短信

00:04:12.220 --> 00:04:15.360
因为16到17岁这个年龄段里

00:04:15.380 --> 00:04:17.740
只有百分之三十三的人
会发送色情短信

00:04:19.020 --> 00:04:23.640
但是，当他们长大些
概率是他们会发送色情短信

00:04:23.660 --> 00:04:29.860
每一个我所看过的研究显示
18到24岁人群中发送色情短信的人数过半

00:04:30.460 --> 00:04:33.360
大多情况下，这也没有出现什么问题

00:04:33.620 --> 00:04:39.000
人们总问我
发色情短信不是很危险吗？

00:04:39.020 --> 00:04:42.600
就像你不会把你的钱包
落在公园椅子上

00:04:42.620 --> 00:04:46.060
因为你觉得这样做
钱包会被偷，对吧？

00:04:46.700 --> 00:04:48.160
我觉得是这样的：

00:04:48.180 --> 00:04:52.120
发色情短信就如把钱包
丢在了男友家里一样

00:04:52.140 --> 00:04:53.860
如果你第二天回来

00:04:53.860 --> 00:04:56.860
发现钱都没了的话

00:04:56.860 --> 00:04:59.110
你真的可以把他甩了

00:04:59.510 --> 00:05:01.680
（观众笑声）

00:05:03.180 --> 00:05:05.550
所以，与其将发送色情短信
违法化

00:05:05.550 --> 00:05:08.160
以此来试图防止
隐私侵犯

00:05:08.370 --> 00:05:11.440
我们可以将同意当作

00:05:11.440 --> 00:05:15.490
我们如何看待我们隐私信息的
传播的中心

00:05:16.190 --> 00:05:20.560
每个新的媒体技术
都会引起隐私问题

00:05:20.580 --> 00:05:25.200
实际上，在美国
关于隐私的最初辩论

00:05:25.220 --> 00:05:29.720
是对当时崭新的科技
的回应

00:05:29.740 --> 00:05:33.540
19世纪末，人们担心那较过去

00:05:33.540 --> 00:05:37.120
突然轻便许多的照相机

00:05:37.140 --> 00:05:39.640
以及报纸上的八卦板块

00:05:39.660 --> 00:05:43.480
他们担心照相机会获取他们的信息

00:05:43.500 --> 00:05:46.700
断章取义
大肆宣扬

00:05:47.060 --> 00:05:48.680
听起来是不是很熟悉？

00:05:48.700 --> 00:05:53.560
就像我们担忧社交媒体
和无人机摄像头

00:05:53.580 --> 00:05:55.220
当然，还有色情短信

00:05:55.740 --> 00:05:57.290
这些对于科技的恐惧

00:05:57.290 --> 00:05:59.020
不无道理

00:05:59.020 --> 00:06:02.460
因为科技能够展露出

00:06:02.460 --> 00:06:05.380
并放大我们最为糟糕的品质与行为

00:06:06.040 --> 00:06:08.490
但这是有解决方法的

00:06:08.490 --> 00:06:12.110
我们就曾经历过一个危险的新科技

00:06:12.240 --> 00:06:16.320
1908年，福特推出了T系车

00:06:16.340 --> 00:06:18.920
交通死亡率不断上升

00:06:18.940 --> 00:06:21.740
这曾是一个严重的问题--
它看起来很安全，对吧？

00:06:23.900 --> 00:06:27.880
我们第一反应是
尝试改变司机的驾驶行为

00:06:27.900 --> 00:06:31.620
所以我们建立了速度限制
并通过罚款来强制实行

00:06:32.060 --> 00:06:33.920
但在此后的几十年里

00:06:33.940 --> 00:06:39.440
我们开始认识到汽车技术
本身不是一成不变的

00:06:39.460 --> 00:06:42.680
我们可以设计出更安全的汽车

00:06:42.700 --> 00:06:46.160
于是上世纪20年代，我们有了
抗碎挡风玻璃

00:06:46.180 --> 00:06:48.680
到了50年代有了安全带

00:06:48.700 --> 00:06:51.780
到了90年代，安全气囊

00:06:52.260 --> 00:06:54.640
这三个领域：

00:06:54.660 --> 00:06:59.040
法律，个人及工业
可以随着时间的推移集合在一起

00:06:59.040 --> 00:07:03.240
来帮助解决新科技
所造成的问题

00:07:03.260 --> 00:07:06.500
我们在数字信息隐私
上亦可以如法炮制

00:07:06.980 --> 00:07:09.740
当然，这又回到同意的话题上来

00:07:10.180 --> 00:07:11.400
我有个想法

00:07:11.420 --> 00:07:15.240
在任何人可以传播
你的个人信息之前

00:07:15.260 --> 00:07:17.500
他们应该得到你的同意

00:07:18.060 --> 00:07:22.880
明确同意的观点源自于反性侵害人士

00:07:22.900 --> 00:07:26.680
他们告诉我们对于每个性行为
都需要得到双方同意

00:07:26.700 --> 00:07:31.140
我们在很多领域对待同意
都有着极高的标准

00:07:31.160 --> 00:07:33.160
比如做手术

00:07:33.180 --> 00:07:34.800
医生需要确认

00:07:34.820 --> 00:07:38.860
你了解并同意医疗程序

00:07:39.340 --> 00:07:43.040
这可不像你同意iTunes服务条款一样

00:07:43.060 --> 00:07:46.720
直接滑到屏幕底部
然后一个劲地点同意

00:07:46.740 --> 00:07:48.460
（观众笑声）

00:07:48.980 --> 00:07:54.240
如果我们多考虑他人是否同意
我们会有更好隐私法

00:07:54.260 --> 00:07:57.680
现在，我们没有
那么多的保护

00:07:57.700 --> 00:08:01.280
如果你的前夫或前妻
为人很不好

00:08:01.300 --> 00:08:05.520
他们可以把你的裸照
发到色情网站上去

00:08:05.540 --> 00:08:08.760
想把那些照片删掉
是很难的

00:08:08.780 --> 00:08:10.000
在许多州里

00:08:10.020 --> 00:08:13.840
你自己拍照其实会更好点

00:08:13.860 --> 00:08:16.660
因为这样你就可以
申请版权了

00:08:17.140 --> 00:08:19.200
（观众笑声）

00:08:19.220 --> 00:08:22.200
现在，如果再有人侵犯了你的隐私

00:08:22.220 --> 00:08:26.420
不管是个人还是
企业还是美国国安局

00:08:27.100 --> 00:08:29.840
你都可以提起诉讼

00:08:29.860 --> 00:08:32.000
尽管诉讼结果可能并不成功

00:08:32.020 --> 00:08:36.800
因为很多法院觉得
保护数字信息隐私是不可能的

00:08:36.820 --> 00:08:40.260
所以他们不愿意去
惩罚那些触犯的人

00:08:41.020 --> 00:08:43.920
我还是能听到
人们不停的问我

00:08:43.940 --> 00:08:49.240
数字图像模糊了公共和私人的界限

00:08:49.260 --> 00:08:50.900
因为它是数字的，对吗？

00:08:51.420 --> 00:08:52.760
不！不！

00:08:52.780 --> 00:08:56.120
每一个数位化产品并不是
自然而然就成为公众的

00:08:56.140 --> 00:08:58.040
那太没道理了

00:08:58.060 --> 00:09:01.560
正如纽约大学法学者
Helen Nissenbaum告诉我们

00:09:01.580 --> 00:09:04.200
我们有着法律，政策以及准则

00:09:04.220 --> 00:09:07.360
来保护各类私人信息

00:09:07.380 --> 00:09:10.800
不论它是不是数字信息

00:09:10.820 --> 00:09:13.480
你所有的医疗记录都是数字化的

00:09:13.500 --> 00:09:16.640
但你的医生却不能
将它们分享给任何人

00:09:16.660 --> 00:09:21.120
你所有的财务信息
都储存在数字数据库里

00:09:21.140 --> 00:09:25.380
但你的信用卡公司不能将
你的购买记录发布到网上

00:09:26.900 --> 00:09:32.360
更好的法律可以在侵犯隐私的问题
发生之后帮助解决

00:09:32.380 --> 00:09:34.900
但我们可以做的最为简便的事情之一

00:09:34.900 --> 00:09:39.460
就是从个人上做出改变来
帮助保护他人的隐私

00:09:40.180 --> 00:09:41.990
我们总是被告知隐私

00:09:41.990 --> 00:09:45.160
是我们自己的，独有的
个人的责任

00:09:45.180 --> 00:09:49.440
我们被告知要经常监控
并更新隐私设置

00:09:49.460 --> 00:09:54.260
我们被告知永远别把不想被
全世界知道的东西分享出去

00:09:55.220 --> 00:09:56.440
这很没道理

00:09:56.460 --> 00:09:59.440
数字媒体就是社会环境

00:09:59.460 --> 00:10:03.740
我们每天无时无刻地将
事情分享给我们所信任的人

00:10:04.580 --> 00:10:07.560
就如普林斯顿研究员Janet Vertesi表示

00:10:07.580 --> 00:10:11.600
我们的数据和隐私
不单单是私人的

00:10:11.620 --> 00:10:14.200
它们实际上是一种人与人之间相互的

00:10:14.220 --> 00:10:17.480
所以，我们能做的
很简单的一件事

00:10:17.500 --> 00:10:22.600
就是在你分享别人信息之前
取得别人的同意

00:10:22.620 --> 00:10:27.160
你想把某人的照片传到网上
先经过那人的同意

00:10:27.180 --> 00:10:29.430
如果你想转寄一封电子邮件

00:10:29.500 --> 00:10:31.040
先经过当事人同意

00:10:31.060 --> 00:10:33.840
如果你想分享某人的裸体自拍

00:10:33.860 --> 00:10:36.140
显然，先经过当事人同意

00:10:37.380 --> 00:10:41.840
这些个人行为的改变可以
帮助我们保护彼此的隐私

00:10:41.860 --> 00:10:45.660
但我们同样需要科技公司的帮忙

00:10:46.180 --> 00:10:50.680
科技公司几乎没有动机
来保护我们的隐私

00:10:50.700 --> 00:10:52.750
因为他们的业务模式依靠于
我们分享我们的每件事

00:10:52.750 --> 00:10:56.260
与尽可能多的人

00:10:56.900 --> 00:10:58.840
现在，如果我发给你一张照片

00:10:58.860 --> 00:11:01.960
你可以转发给任何人

00:11:01.980 --> 00:11:06.240
但如果我来决定这张照片
可不可以被转发会怎样？

00:11:06.260 --> 00:11:10.320
这就会告诉你，你没有我的
批准去发送这张照片

00:11:10.340 --> 00:11:14.480
我们一直这样做
来保护我们的版权

00:11:14.500 --> 00:11:19.280
如果你买了本电子书
你不能随意把它寄给别人

00:11:19.300 --> 00:11:21.860
所以为什么不
如法炮制到手机上去呢？

00:11:22.780 --> 00:11:27.560
我们可以让科技公司
给我们的设备和平台

00:11:27.580 --> 00:11:31.320
默认装上这些保护

00:11:31.340 --> 00:11:34.760
毕竟，你可以选择
你自己车子的颜色

00:11:34.780 --> 00:11:37.620
但安全气囊总是有固定标准的

00:11:39.900 --> 00:11:43.720
如果我们不多思考
数字隐私和同意的问题

00:11:43.740 --> 00:11:46.460
就可能会有严重后果

00:11:47.180 --> 00:11:49.440
有一位来自俄亥俄的少女--

00:11:49.460 --> 00:11:52.300
为了保护她的隐私
我们就叫她Jennifer吧

00:11:52.940 --> 00:11:56.520
她把她的裸照分享给了
她高中的男朋友

00:11:56.540 --> 00:11:58.060
觉得他可以信任

00:11:59.540 --> 00:12:01.480
不幸的是，男友背叛了她

00:12:01.500 --> 00:12:04.480
把她的照片传遍学校

00:12:04.500 --> 00:12:08.020
让Jennifer难堪，备受羞辱

00:12:08.620 --> 00:12:12.760
她的同学非但没有同情她
反而对她进行骚扰

00:12:12.780 --> 00:12:14.640
他们说她是个荡妇，妓女

00:12:14.660 --> 00:12:16.620
使她的生活痛苦不堪

00:12:17.180 --> 00:12:20.860
Jennifer开始缺课，成绩下滑

00:12:21.340 --> 00:12:25.140
最终，Jennifer决定
结束了她的生命

00:12:26.540 --> 00:12:29.240
Jennifer没做错什么

00:12:29.260 --> 00:12:31.520
她不过将她的裸照分享

00:12:31.540 --> 00:12:34.360
给了她认为
可以信任的人

00:12:34.380 --> 00:12:37.000
可我们的法律告诉她

00:12:37.020 --> 00:12:41.180
她犯了和儿童色情一样
可怕的罪行

00:12:41.740 --> 00:12:43.240
我们的性别规范告诉她

00:12:43.260 --> 00:12:46.480
给自己拍裸照

00:12:46.500 --> 00:12:49.700
是她做过的最为可怕
羞耻的事

00:12:50.220 --> 00:12:54.440
当我们觉得保护隐私
在数字媒体环境下是不可能的时候

00:12:54.460 --> 00:12:59.980
我们完全无视男朋友的
不道德行为

00:13:01.020 --> 00:13:06.760
人们还是在不停地对那些
隐私受侵犯的受害者们说

00:13:06.780 --> 00:13:08.040
“你在想些什么啊？

00:13:08.060 --> 00:13:10.540
你就不该发那照片的”

00:13:11.460 --> 00:13:15.460
如果你尝试换种说法
试试这个

00:13:15.980 --> 00:13:19.500
想象下你碰到一个
滑雪时摔断腿的朋友

00:13:20.060 --> 00:13:24.420
他们当时冒险做了些好玩的动作
结果腿摔断了

00:13:24.660 --> 00:13:27.200
但你不太可能蠢到说

00:13:27.220 --> 00:13:29.660
”唉，我觉得你就不该去滑雪的。”

00:13:31.900 --> 00:13:34.040
如果我们多考虑他人是否同意

00:13:34.060 --> 00:13:37.320
我们便能看见
侵犯隐私的受害者们

00:13:37.340 --> 00:13:39.080
得到了我们的同情

00:13:39.100 --> 00:13:43.700
而不是遭到定罪，羞辱
骚扰或是惩罚

00:13:44.260 --> 00:13:48.760
我们可以支持这些受害者
通过法律，个人和科技上的改变

00:13:48.780 --> 00:13:53.100
来防止侵权隐私的发生

00:13:53.660 --> 00:13:59.480
因为问题不在于色情信息的发送
而在于数字隐私

00:13:59.500 --> 00:14:01.860
解决方法之一就是获得他人的同意

00:14:02.500 --> 00:14:07.080
所以下次一个隐私受侵犯的人
来找你的时候

00:14:07.100 --> 00:14:09.840
不要责备他们
而是这么做

00:14:09.860 --> 00:14:13.280
让我们转变我们对数字隐私的看法

00:14:13.300 --> 00:14:15.940
并以同情作为回应

00:14:16.500 --> 00:14:17.720
谢谢

