WEBVTT
Kind: captions
Language: pt-PT

00:00:00.000 --> 00:00:07.000
Tradutor: Catarina Mendes
Revisora: Margarida Ferreira

00:00:12.767 --> 00:00:17.720
Há muito tempo que as pessoas têm 
usado os "media" para falar sobre sexo.

00:00:17.420 --> 00:00:20.950
Cartas de amor, sexo telefónico, 
fotos escandalosas.

00:00:21.300 --> 00:00:25.298
Até a história de uma rapariga
que fugiu com um homem

00:00:25.298 --> 00:00:29.238
que conheceu por telégrafo em 1886.

00:00:30.380 --> 00:00:35.476
Hoje temos o "sexting"
e eu sou uma especialista.

00:00:35.500 --> 00:00:38.320
Não sou uma especialista 
em fazê-lo.

00:00:38.938 --> 00:00:43.210
Mas sei o que isto quer dizer
— acho que vocês também sabem.

00:00:42.941 --> 00:00:44.267
[É um pénis]

00:00:44.429 --> 00:00:46.361
(Risos)

00:00:48.180 --> 00:00:54.306
Eu tenho estudado o "sexting" desde que
chamou a atenção dos "media" em 2008.

00:00:54.540 --> 00:00:57.516
Escrevi um livro
sobre o pânico moral do "sexting".

00:00:57.621 --> 00:00:59.319
E foi isto que descobri:

00:00:59.416 --> 00:01:02.450
a maior parte das pessoas
preocupa-se com a coisa errada.

00:01:02.538 --> 00:01:06.432
Estão a tentar impedir que o "sexting"
aconteça completamente.

00:01:06.620 --> 00:01:08.365
Mas vou perguntar o seguinte:

00:01:08.365 --> 00:01:13.036
Contanto que seja consensual, 
qual é o problema do "sexting"?

00:01:13.060 --> 00:01:17.203
As pessoas gostam de todo o tipo
de coisas que talvez vocês não gostem,

00:01:17.203 --> 00:01:19.696
é como o queijo azul e coentros.

00:01:19.801 --> 00:01:21.732
(Risos)

00:01:22.420 --> 00:01:26.628
O "sexting" certamente é arriscado, 
como qualquer outra coisa divertida,

00:01:26.628 --> 00:01:33.276
mas, contanto que vocês não enviem 
fotos para alguém que não as queira,

00:01:33.300 --> 00:01:35.076
não há problema.

00:01:35.100 --> 00:01:37.716
O que eu considero ser problemático

00:01:37.740 --> 00:01:41.259
é quando as pessoas partilham
as fotos privadas de outras pessoas

00:01:41.274 --> 00:01:43.049
sem a permissão delas.

00:01:43.180 --> 00:01:45.734
Em vez de nos preocuparmos 
com o "sexting",

00:01:45.734 --> 00:01:50.463
acho que precisamos de pensar mais
na privacidade digital.

00:01:50.700 --> 00:01:53.163
A chave é o consentimento.

00:01:53.500 --> 00:01:56.796
Neste momento, a maioria das pessoas
estão a pensar em "sexting"

00:01:56.820 --> 00:01:59.925
sem pensarem realmente no consentimento.

00:02:00.220 --> 00:02:04.345
Sabiam que atualmente criminalizamos
o "sexting" entre adolescentes?

00:02:05.220 --> 00:02:09.010
Pode ser um crime pois é considerado
pornografia infantil,

00:02:09.010 --> 00:02:11.628
se houver uma foto
de um menor de 18 anos,

00:02:11.628 --> 00:02:13.261
e não importa

00:02:13.261 --> 00:02:17.403
se tiraram a foto a eles próprios
e partilharam por vontade própria.

00:02:17.620 --> 00:02:20.768
Então, temos uma situação legal bizarra
em que, nos EUA,

00:02:20.768 --> 00:02:25.056
dois adolescentes podem ter
relações sexuais legalmente,

00:02:25.356 --> 00:02:27.687
mas não podem fotografá-las.

00:02:28.380 --> 00:02:32.636
Alguns Estados também tentaram 
decretar o "sexting" como pequeno delito

00:02:32.684 --> 00:02:36.160
mas estas leis têm todas o mesmo problema

00:02:36.160 --> 00:02:39.714
ainda tornam o "sexting"
consensual num ato ilegal.

00:02:40.340 --> 00:02:42.480
Não faz sentido nenhum

00:02:42.480 --> 00:02:46.110
tentar proibir o "sexting" para retificar
violações de privacidade.

00:02:46.380 --> 00:02:48.066
É como dizer,

00:02:48.066 --> 00:02:53.676
vamos resolver as violações em encontros,
tornando os encontros ilegais.

00:02:54.940 --> 00:02:58.030
A maioria dos jovens
não são presos por "sexting"

00:02:58.030 --> 00:03:00.385
mas adivinham quem é preso?

00:03:00.467 --> 00:03:05.052
São os jovens de quem os pais
dos companheiros não gostam.

00:03:05.558 --> 00:03:10.203
Isto pode ser por causa de preconceitos
de classe social, racismo ou homofobia.

00:03:10.780 --> 00:03:13.990
A maioria dos acusadores
são inteligentes o suficiente

00:03:13.990 --> 00:03:19.260
para não acusar de pornografia infantil
adolescentes, mas alguns fazem-no.

00:03:19.540 --> 00:03:23.196
De acordo com investigadores da
Universidade de New Hampshire

00:03:23.220 --> 00:03:28.876
7% das prisões por posse
de pornografia infantil são de jovens,

00:03:28.900 --> 00:03:32.190
a fazerem "sexting" consensualmente 
com outros jovens.

00:03:33.300 --> 00:03:36.108
A pornografia infantil é um crime grave,

00:03:36.108 --> 00:03:40.012
mas não é a mesma coisa que o 
"sexting" entre jovens.

00:03:40.860 --> 00:03:44.276
Os pais e educadores estão
a lidar com o "sexting"

00:03:44.300 --> 00:03:47.390
sem pensarem muito
sobre consentimento.

00:03:47.460 --> 00:03:51.734
Frequentemente a mensagem para 
os jovens é: "Não o façam".

00:03:52.020 --> 00:03:55.725
E eu compreendo
— existem riscos legais graves

00:03:55.725 --> 00:03:59.196
e claro, as potenciais violações
de privacidade.

00:03:59.220 --> 00:04:00.776
E quando vocês era jovens,

00:04:00.776 --> 00:04:04.263
tenho a certeza que vocês faziam
tudo o que vos diziam, certo?

00:04:05.332 --> 00:04:08.716
Provavelmente estão a pensar:
"O meu filho nunca faria isso".

00:04:08.930 --> 00:04:12.414
E é verdade, os vossos anjinhos
podem não estar a fazer "sexting"

00:04:12.414 --> 00:04:15.937
porque apenas 33% dos jovens

00:04:15.937 --> 00:04:18.412
entre 16 e 17 anos o praticam.

00:04:19.020 --> 00:04:23.754
Mas quando eles crescerem,
há grandes probabilidades de o fazerem.

00:04:23.754 --> 00:04:29.960
Todos os estudos que vi avaliam uma taxa 
superior a 50% entre os 18 e os 24 anos.

00:04:30.540 --> 00:04:33.750
E na maioria das vezes, nada corre mal. 

00:04:34.270 --> 00:04:39.150
As pessoas perguntam-me coisas como:
"Mas o 'sexting' não é muito perigoso?"

00:04:39.277 --> 00:04:43.030
Imaginem, vocês não deixariam
a carteira no banco de um parque

00:04:43.030 --> 00:04:46.478
e esperavam que ela fosse roubada
se o fizessem, certo?

00:04:46.700 --> 00:04:48.410
Eu penso desta forma:

00:04:48.410 --> 00:04:52.116
o "sexting" é como se deixassem
a carteira em casa do vosso namorado.

00:04:52.140 --> 00:04:54.179
Se voltarem no dia seguinte

00:04:54.179 --> 00:04:56.583
e todo o dinheiro tiver desaparecido,

00:04:56.860 --> 00:04:59.480
precisam mesmo de acabar com essa pessoa.

00:04:59.628 --> 00:05:01.798
(Risos)

00:05:03.180 --> 00:05:05.718
Então em vez de criminalizarmos
o "sexting",

00:05:05.718 --> 00:05:08.346
para tentar evitar
estas violações de privacidade,

00:05:08.346 --> 00:05:11.785
precisamos de tornar o consentimento
num fator central

00:05:11.785 --> 00:05:15.934
de como pensamos sobre a circulação
das nossas informações privadas.

00:05:16.300 --> 00:05:20.556
Qualquer nova tecnologia levanta
questões quanto à privacidade.

00:05:20.580 --> 00:05:25.196
De facto, os primeiros grandes debates 
sobre privacidade nos EUA,

00:05:25.220 --> 00:05:30.025
realizaram-se em resposta às tecnologias 
que eram relativamente novas na altura.

00:05:30.025 --> 00:05:34.160
No final do século XIX, as pessoas 
estavam preocupadas com as câmaras,

00:05:34.160 --> 00:05:37.116
que, de repente,
eram mais portáteis do que nunca

00:05:37.140 --> 00:05:39.836
e com as colunas de mexericos 
dos jornais.

00:05:39.836 --> 00:05:43.666
Estavam preocupadas pois as câmaras 
podiam capturar informações sobre eles,

00:05:43.666 --> 00:05:46.954
tirar a informação do contexto 
e divulgá-la amplamente.

00:05:47.060 --> 00:05:48.757
Isto soa-vos familiar?

00:05:49.800 --> 00:05:51.382
É exatamente o que nos preocupa

00:05:51.382 --> 00:05:53.728
nas redes sociais
e nas câmaras dos "drones",

00:05:53.728 --> 00:05:55.538
e, claro, no "sexting".

00:05:55.740 --> 00:05:59.183
Estes medos da tecnologia fazem sentido

00:05:59.220 --> 00:06:03.045
porque as tecnologias podem
ampliar e trazer para fora

00:06:03.045 --> 00:06:06.690
as nossas piores qualidades 
e comportamentos.

00:06:05.980 --> 00:06:08.356
Mas há soluções.

00:06:08.643 --> 00:06:12.321
Nós já passámos por isto
com uma nova tecnologia perigosa.

00:06:12.540 --> 00:06:16.416
Em 1908, quando Ford apresentou 
o carro Model T.

00:06:16.712 --> 00:06:19.349
As taxas de acidentes de trânsito 
estavam a subir.

00:06:19.349 --> 00:06:22.448
Era um grave problema
— parece-vos seguro, certo?

00:06:23.900 --> 00:06:28.003
A nossa primeira resposta foi tentar 
mudar o comportamento dos condutores,

00:06:28.003 --> 00:06:32.000
desenvolvemos limites de velocidade 
que aplicámos através de multas.

00:06:32.060 --> 00:06:34.216
Mas ao longo das décadas seguintes,

00:06:34.216 --> 00:06:39.436
começámos a perceber que a tecnologia 
do carro em si não é apenas neutra.

00:06:39.669 --> 00:06:42.676
Podíamos projetar o carro para 
torná-lo mais seguro.

00:06:42.858 --> 00:06:46.465
Então, na década de 1920, tínhamos 
para-brisas resistentes à quebra.

00:06:46.465 --> 00:06:49.470
Na década de 1950, cintos de segurança.

00:06:49.470 --> 00:06:51.780
E na década de 1990, "airbags".

00:06:52.260 --> 00:06:54.836
Todas estas três áreas:

00:06:54.836 --> 00:06:59.636
lei, indivíduos e indústria foram-se 
juntando ao longo do tempo

00:06:59.636 --> 00:07:03.236
para ajudar a resolver o problema 
que uma nova tecnologia causava.

00:07:03.260 --> 00:07:06.980
E podemos fazer o mesmo com a 
privacidade digital.

00:07:06.980 --> 00:07:09.940
Claro, voltamos ao consentimento.

00:07:10.180 --> 00:07:11.723
Aqui está a ideia.

00:07:11.723 --> 00:07:15.390
Antes que alguém possa distribuir
as vossas informações privadas,

00:07:15.390 --> 00:07:18.520
deviam ter de obter a vossa permissão.

00:07:18.060 --> 00:07:22.876
Esta ideia de consentimento afirmativo 
vem de ativistas anti-violação

00:07:22.900 --> 00:07:26.676
que nos dizem que precisamos de 
consentimento para todos os atos sexuais.

00:07:26.790 --> 00:07:31.157
E temos padrões realmente altos de
consentimento em muitas outras áreas.

00:07:31.300 --> 00:07:33.365
Pensem em fazer uma cirurgia.

00:07:33.434 --> 00:07:35.205
O vosso médico tem de se certificar

00:07:35.205 --> 00:07:39.269
que vocês estão conscientes
e que consentem esse procedimento médico.

00:07:39.340 --> 00:07:43.408
Não é o mesmo tipo de consentimento, 
que os Termos de Serviço do iTunes

00:07:43.408 --> 00:07:46.716
em que apenas fazemos "scroll"
e, concordo, concordo, seja o que for.

00:07:47.149 --> 00:07:48.760
(Risos)

00:07:48.980 --> 00:07:54.126
Se pensarmos mais em consentimento, 
podemos ter melhores leis de privacidade.

00:07:54.260 --> 00:07:57.776
Agora, nós não temos muitas proteções.

00:07:57.776 --> 00:08:01.276
Se o nosso ex-marido ou a nossa 
ex-mulher forem pessoas horríveis,

00:08:01.300 --> 00:08:05.643
podem pegar nas nossas fotos nuas
e enviá-las para um site de pornografia.

00:08:05.643 --> 00:08:08.756
Pode ser muito difícil
tirar essas fotos da Internet.

00:08:08.780 --> 00:08:10.368
E em muitos Estados,

00:08:10.368 --> 00:08:13.836
vocês estão muito melhor
se foram vocês que tiraram as fotos

00:08:13.860 --> 00:08:16.950
porque aí podem fazer uma queixa 
por direitos de autor.

00:08:17.140 --> 00:08:19.123
(Risos)

00:08:19.220 --> 00:08:22.196
Agora, se alguém viola 
a nossa privacidade,

00:08:22.220 --> 00:08:26.574
quer se trate de um indivíduo ou 
de uma empresa ou da NSA,

00:08:27.100 --> 00:08:30.163
podemos tentar meter uma ação judicial,

00:08:30.163 --> 00:08:32.223
apesar de podermos não ser bem sucedidos

00:08:32.223 --> 00:08:36.796
porque muitos tribunais assumem
que a privacidade digital é impossível.

00:08:36.938 --> 00:08:40.450
Então não estão dispostos
a punir alguém por a violar.

00:08:41.020 --> 00:08:43.916
As pessoas ainda me perguntam:

00:08:43.940 --> 00:08:49.236
"Uma imagem digital não é algo
que está entre o público e o privado

00:08:49.260 --> 00:08:51.118
"porque é digital?"

00:08:51.420 --> 00:08:52.756
Não! Não!

00:08:52.970 --> 00:08:56.116
Tudo o que é digital não é 
automaticamente público.

00:08:56.140 --> 00:08:58.036
Isto não faz sentido nenhum.

00:08:58.196 --> 00:09:01.556
Como a professora de direito da NYU 
Helen Nissenbaum diz,

00:09:01.580 --> 00:09:04.368
nós temos leis, políticas e normas

00:09:04.368 --> 00:09:07.356
que protegem todo o tipo de 
informação que é privada,

00:09:07.380 --> 00:09:10.796
e não faz diferença se esta informação 
é digital ou não.

00:09:10.820 --> 00:09:13.657
Todos os nossos registos de saúde 
estão digitalizados

00:09:13.657 --> 00:09:16.636
mas o nosso médico não pode
partilhá-los com ninguém.

00:09:16.660 --> 00:09:21.116
As nossas informações financeiras
são mantidas em bases de dados digitais,

00:09:21.140 --> 00:09:25.734
mas o nosso banco não pode publicar
o nosso histórico de compras "online".

00:09:26.900 --> 00:09:30.592
Melhores leis podiam resolver
violações de privacidade

00:09:30.592 --> 00:09:32.456
depois de estas acontecerem,

00:09:32.456 --> 00:09:36.937
mas uma das coisas mais fáceis
que podemos fazer são mudanças pessoais

00:09:36.937 --> 00:09:39.960
para ajudar a proteger
a nossa privacidade.

00:09:40.180 --> 00:09:42.357
Dizem-nos sempre
que a nossa privacidade

00:09:42.357 --> 00:09:45.483
é da nossa exclusiva 
responsabilidade individual.

00:09:45.483 --> 00:09:49.436
É-nos dito para monitorizarmos
as configurações de privacidade;

00:09:49.460 --> 00:09:54.460
para nunca partilharmos algo
que não queremos que o mundo inteiro veja.

00:09:55.189 --> 00:09:56.596
Isto não faz sentido.

00:09:56.596 --> 00:09:59.436
Os meios digitais são meios sociais

00:09:59.460 --> 00:10:04.130
e partilhamos coisas com pessoas
em quem confiamos todos os dias.

00:10:04.580 --> 00:10:07.556
Como a investigadora de Princeton
Janet Vertesi argumenta,

00:10:07.580 --> 00:10:11.596
os nossos dados e a nossa privacidade
não são apenas pessoais,

00:10:11.620 --> 00:10:13.986
são interpessoais.

00:10:14.220 --> 00:10:17.476
Então, uma coisa muito fácil 
que podemos fazer

00:10:17.500 --> 00:10:20.047
é começar a pedir permissão

00:10:20.047 --> 00:10:22.756
antes de partilhar informações
de outras pessoas.

00:10:22.965 --> 00:10:27.156
Se querem publicar uma foto de alguém 
"online", peçam permissão.

00:10:27.180 --> 00:10:29.636
Se querem reencaminhar um email,

00:10:29.660 --> 00:10:31.263
peçam permissão.

00:10:31.263 --> 00:10:33.836
E se querem partilhar
a "selfie" nua de alguém,

00:10:33.860 --> 00:10:36.358
obviamente, peçam permissão.

00:10:37.380 --> 00:10:41.836
Estas mudanças individuais podem
ajudar-nos a proteger a nossa privacidade,

00:10:41.836 --> 00:10:45.799
mas também precisamos das empresas 
de tecnologia na mesma onda.

00:10:46.180 --> 00:10:50.676
Estas empresas têm poucos incentivos
para proteger a nossa privacidade

00:10:50.700 --> 00:10:54.368
porque os seus modelos de negócio 
dependem de nós partilharmos tudo

00:10:54.368 --> 00:10:56.678
com o máximo de pessoas possível.

00:10:57.000 --> 00:10:59.226
Agora, se eu vos mandar uma foto,

00:10:59.226 --> 00:11:01.956
vocês podem reencaminhá-la
para qualquer pessoa.

00:11:02.170 --> 00:11:06.236
Mas e se eu pudesse decidir se esta foto
era reencaminhável ou não?

00:11:06.414 --> 00:11:10.316
Isso dir-vos-ia que não tinham permissão 
para enviar esta imagem.

00:11:10.458 --> 00:11:14.476
Nós fartamo-nos de fazer este tipo de 
coisa para proteger os direitos de autor.

00:11:14.645 --> 00:11:19.276
Se compramos um e-book, não podemos 
enviá-lo às pessoas que quisermos.

00:11:19.490 --> 00:11:22.232
Então, porque não fazer o mesmo
com os telemóveis?

00:11:22.780 --> 00:11:27.674
Podemos exigir que as empresas
de tecnologia adicionem estas proteções

00:11:27.674 --> 00:11:31.316
aos nossos dispositivos
e às nossas plataformas, obrigatoriamente.

00:11:31.521 --> 00:11:34.756
Afinal, podemos escolher
a cor do nosso carro,

00:11:34.780 --> 00:11:38.010
mas os "airbags" são sempre obrigatórios.

00:11:39.900 --> 00:11:43.960
Se não pensarmos mais
em privacidade digital e em consentimento,

00:11:43.960 --> 00:11:46.714
pode haver graves consequências.

00:11:47.180 --> 00:11:49.581
Uma adolescente do Ohio

00:11:49.581 --> 00:11:52.645
— vamos chamar-lhe Jennifer, 
para mantermos a sua privacidade.

00:11:52.940 --> 00:11:56.516
Ela partilhou fotos dela nua
com o seu namorado da secundária,

00:11:56.540 --> 00:11:58.496
pensando que podia confiar nele.

00:11:59.540 --> 00:12:01.657
Infelizmente, ele traiu-a

00:12:01.657 --> 00:12:04.312
e mandou as fotos para a escola toda.

00:12:04.500 --> 00:12:08.247
Jennifer sentiu-se 
envergonhada e humilhada,

00:12:08.620 --> 00:12:12.756
mas, em vez de terem compaixão, 
os colegas gozaram com ela.

00:12:12.780 --> 00:12:15.036
Chamaram-lhe cabra e prostituta

00:12:15.036 --> 00:12:17.156
e transformaram-lhe a vida num inferno.

00:12:17.180 --> 00:12:21.014
Jennifer começou a faltar à escola 
e as suas notas desceram.

00:12:21.340 --> 00:12:25.558
Por fim, Jennifer decidiu acabar 
com a sua própria vida.

00:12:26.540 --> 00:12:29.236
Jennifer não fez nada mal.

00:12:29.260 --> 00:12:31.943
Tudo o que fez foi partilhar 
uma foto dela nua

00:12:31.943 --> 00:12:34.356
com alguém que ela pensava 
poder confiar.

00:12:34.380 --> 00:12:36.996
No entanto, as nossas leis dizem-lhe

00:12:37.020 --> 00:12:41.489
que ela cometeu um crime horrível 
equivalente à pornografia infantil.

00:12:41.740 --> 00:12:43.481
As nossas normas sexuais dizem

00:12:43.481 --> 00:12:46.476
que, ao tirar a foto dela nua,

00:12:46.500 --> 00:12:49.990
ela, de alguma forma, fez a coisa 
mais horrível e vergonhosa.

00:12:50.220 --> 00:12:54.581
E quando assumimos que a privacidade 
nos meios digitais é impossível,

00:12:54.581 --> 00:13:00.270
estamos a desculpar completamente
o mau comportamento do namorado.

00:13:01.020 --> 00:13:06.310
As pessoas ainda dizem às vítimas 
de violações de privacidade,

00:13:06.780 --> 00:13:08.490
"Em que é que estavas a pensar?

00:13:08.490 --> 00:13:11.040
"Tu nunca devias ter enviado essa foto."

00:13:11.460 --> 00:13:15.541
Se estão a tentar descobrir o que dizer, 
tentem isto.

00:13:15.980 --> 00:13:19.781
Imaginem que encontram um amigo 
que partiu a perna a fazer esquii.

00:13:20.060 --> 00:13:24.417
Ele correu o risco de fazer algo 
divertido, e não acabou bem.

00:13:24.660 --> 00:13:27.332
Mas provavelmente
vocês não lhe vão dizer:

00:13:27.332 --> 00:13:30.050
"Bem, não devias ter ido esquiar."

00:13:31.900 --> 00:13:34.226
Se pensarmos mais no consentimento,

00:13:34.226 --> 00:13:37.316
podemos ver que as vítimas
de violações de privacidade

00:13:37.340 --> 00:13:39.366
merecem a nossa compaixão,

00:13:39.366 --> 00:13:43.836
não que as criminalizemos, 
envergonhemos ou castiguemos.

00:13:44.260 --> 00:13:48.992
Nós podemos apoiar as vítimas
e evitar algumas violações de privacidade

00:13:48.992 --> 00:13:53.245
ao fazermos estas mudanças legais, 
individuais e tecnológicas.

00:13:53.660 --> 00:13:59.366
Porque o problema não é o "sexting", 
o problema é a privacidade digital.

00:13:59.500 --> 00:14:02.241
E uma solução passa pelo consentimento.

00:14:02.500 --> 00:14:04.100
Então, da próxima vez

00:14:04.100 --> 00:14:07.154
que uma vítima de violação de privacidade
for ter convosco,

00:14:07.154 --> 00:14:09.836
em vez de a culparem, 
façam isto:

00:14:10.132 --> 00:14:13.394
vamos mudar as nossas ideias 
sobre a privacidade digital,

00:14:13.394 --> 00:14:16.167
e vamos responder com compaixão.

00:14:16.500 --> 00:14:17.716
Obrigada.

00:14:17.876 --> 00:14:20.939
(Aplausos)

