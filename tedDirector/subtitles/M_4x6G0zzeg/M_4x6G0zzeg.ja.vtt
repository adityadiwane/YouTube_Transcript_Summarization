WEBVTT
Kind: captions
Language: ja

00:00:00.000 --> 00:00:07.000
翻訳: Yasushi Aoki
校正: Eriko T

00:00:12.540 --> 00:00:16.820
人々は昔から性的な会話に
メディアを使ってきました

00:00:17.420 --> 00:00:20.860
ラブレター テレホンセックス 
きわどいポラロイド写真

00:00:21.300 --> 00:00:27.240
電報で知り合った男と駆け落ちした
少女の話さえあります

00:00:27.240 --> 00:00:29.320
1886年のことです

00:00:30.380 --> 00:00:35.380
現在はセクスティングがあり 
私はそのエキスパートです

00:00:35.380 --> 00:00:38.250
セクスティングする
エキスパートじゃありませんよ

00:00:38.470 --> 00:00:42.956
でもこれが何を意味するかは知っています
皆さんもご存じでしょうけど

00:00:42.956 --> 00:00:44.195
[これはペニスの意]

00:00:44.220 --> 00:00:46.580
(笑)

00:00:48.180 --> 00:00:54.260
セクスティングがメディアに注目され出した
2008年から 私は研究するようになり

00:00:54.260 --> 00:00:57.636
セクスティングに関わる
モラルの混乱について本も書きました

00:00:57.636 --> 00:00:59.156
それでわかったのは

00:00:59.180 --> 00:01:02.396
多くの人が的外れなことを
心配していることです

00:01:02.420 --> 00:01:06.596
みんなセクスティング自体を
なくそうとしています

00:01:06.620 --> 00:01:08.156
でも考えてほしいんです

00:01:08.180 --> 00:01:13.036
完全な合意の上でなら セクスティングの
何が問題だというのでしょう？

00:01:13.060 --> 00:01:17.076
世の中 変なものが
好きな人もいます

00:01:17.100 --> 00:01:19.396
ブルーチーズとか パクチーとか

00:01:19.420 --> 00:01:21.060
(笑)

00:01:22.420 --> 00:01:26.556
楽しいことの例に漏れず 
セクスティングにはリスクがあります

00:01:26.580 --> 00:01:33.276
でも 受け取りたくない人に
きわどい写真を送ったりしない限りは

00:01:33.300 --> 00:01:35.076
害はありません

00:01:35.100 --> 00:01:37.716
本当に問題があるのは

00:01:37.740 --> 00:01:40.270
他人のプライベートな写真を

00:01:40.270 --> 00:01:43.100
許可も得ずに
公開することです

00:01:43.120 --> 00:01:45.716
セクスティングについて
心配をするよりも

00:01:45.716 --> 00:01:50.500
私たちがすべきなのは デジタル情報の
プライバシーについて考えることで

00:01:50.500 --> 00:01:52.900
その鍵になるのは「合意」です

00:01:53.500 --> 00:01:56.796
現在のところ 多くの人は
セクスティングについて考えるとき

00:01:56.820 --> 00:02:00.020
合意の有無を
まったく考慮していません

00:02:00.070 --> 00:02:05.020
現在 ティーンのセクスティングは
犯罪だとされているのをご存じですか？

00:02:05.220 --> 00:02:06.830
犯罪になる理由は

00:02:06.830 --> 00:02:11.440
18歳未満の裸の画像は
児童ポルノと見なされるためで

00:02:11.440 --> 00:02:15.396
たとえそれが自分で撮って
合意の上で渡されたものであっても

00:02:15.396 --> 00:02:17.140
関係ありません

00:02:17.620 --> 00:02:20.596
そのため法的に
非常に奇妙な状況が生じます

00:02:20.620 --> 00:02:25.156
アメリカのほとんどの州で 
17歳の男女は合法的にセックスできますが

00:02:25.180 --> 00:02:27.530
その写真を撮ることは
できないのです

00:02:28.380 --> 00:02:32.636
州によってはセクスティングのための
軽犯罪法を作ろうとしていますが

00:02:32.660 --> 00:02:35.676
同じ間違いを
繰り返しています

00:02:35.700 --> 00:02:39.820
合意の上でのセクスティングを
違法としているからです

00:02:40.340 --> 00:02:42.996
プライバシー侵害に
対処するために

00:02:42.996 --> 00:02:46.356
セクスティング自体を
禁止しようとするのは筋違いです

00:02:46.380 --> 00:02:49.306
それはデートレイプをなくすために

00:02:49.306 --> 00:02:53.540
デート自体を違法にしようと
するようなものです

00:02:54.780 --> 00:03:00.376
ティーンの多くはセクスティングで逮捕されはしませんが 
逮捕されているのがどんな人か分かりますか？

00:03:00.376 --> 00:03:05.210
相手の親に嫌われている
ティーンです

00:03:05.210 --> 00:03:10.690
そしてその本当の理由は 階級意識や 人種差別や 
同性愛嫌悪のためかも知れません

00:03:10.720 --> 00:03:13.556
もちろん検事の多くは
馬鹿じゃありませんから

00:03:13.580 --> 00:03:19.310
子供を児童ポルノで訴えたりは
しませんが する人もいます

00:03:19.540 --> 00:03:23.170
ニューハンプシャー大学の
研究者らによると

00:03:23.170 --> 00:03:26.640
児童ポルノ所持で
逮捕されたうちの７％が

00:03:26.640 --> 00:03:32.220
合意の上でセクスティングしていた
ティーンだったそうです

00:03:33.300 --> 00:03:35.836
児童ポルノは
重大な犯罪ですが

00:03:35.860 --> 00:03:40.080
ティーンのセクスティングは
まったく別の話です

00:03:40.860 --> 00:03:42.480
親や教師というのも

00:03:42.480 --> 00:03:47.436
合意について考慮せずに
セクスティングに反応しています

00:03:47.460 --> 00:03:52.000
彼らのメッセージはたいてい
「一切やめろ」です

00:03:52.020 --> 00:03:53.650
理解は出来ます

00:03:53.650 --> 00:03:59.150
深刻な法的リスクや
プライバシー侵害の危険がありますから

00:03:59.150 --> 00:04:00.686
皆さんは10代の頃

00:04:00.686 --> 00:04:04.400
言い付けを何でも
良く守っていたことでしょう

00:04:05.060 --> 00:04:08.690
我が子に限ってセクスティングなんか
するわけがないと

00:04:08.690 --> 00:04:12.386
それはそうです 皆さんの
天使のようなお子さんはしないでしょうとも

00:04:12.386 --> 00:04:15.356
16〜17歳でセクスティング
しているのは

00:04:15.380 --> 00:04:17.900
33%だけですから

00:04:19.020 --> 00:04:23.636
でも大人になるまでには 
セクスティングするようになる可能性が高いです

00:04:23.660 --> 00:04:30.230
私の見てきたどの調査でも 
18〜24歳の50%以上がセクスティングしています

00:04:30.450 --> 00:04:33.596
そしてほとんどの場合 
悪いことは何も起こりません

00:04:33.620 --> 00:04:38.900
「でもセクスティングはやっぱり
危ないんじゃないの？」とよく聞かれます

00:04:38.900 --> 00:04:42.736
公園のベンチに財布を
置き忘れないようにするのと同じで

00:04:42.736 --> 00:04:46.330
そんなの盗まれるに
決まっているでしょうと

00:04:46.700 --> 00:04:48.156
私に言わせると

00:04:48.180 --> 00:04:52.116
セクスティングは彼氏の家に
財布を置き忘れるようなものです

00:04:52.140 --> 00:04:53.916
次の日に行くと

00:04:53.940 --> 00:04:56.800
財布のお金が全部
なくなっていたとしたら

00:04:56.820 --> 00:04:59.420
そんな男とはすぐ
別れるべきでしょう

00:04:59.420 --> 00:05:01.680
(笑)

00:05:03.180 --> 00:05:05.500
プライバシー侵害を防ぐために

00:05:05.540 --> 00:05:08.156
セクスティングを
犯罪化するのではなく

00:05:08.180 --> 00:05:11.476
個人のプライベートな
情報を流すときに

00:05:11.500 --> 00:05:15.650
合意を第一に考えるべきです

00:05:16.170 --> 00:05:20.556
新しいメディア技術はいつも
プライバシーへの懸念を生んできました

00:05:20.580 --> 00:05:25.196
事実アメリカにおいて最初の
プライバシーに関する議論は

00:05:25.220 --> 00:05:29.710
当時 比較的新しかった技術への
反応として起こりました

00:05:29.710 --> 00:05:32.830
1800年代末
人々が懸念を抱いたのは

00:05:32.830 --> 00:05:36.800
以前よりも ずっと
持ち運びやすくなったカメラと

00:05:36.800 --> 00:05:39.636
新聞のゴシップ欄でした

00:05:39.660 --> 00:05:43.350
自分の情報が
カメラで写し取られ

00:05:43.350 --> 00:05:46.880
元の文脈を離れて
広められたりはしないかと

00:05:46.880 --> 00:05:48.886
聞いたことのある
ような話ですよね？

00:05:48.886 --> 00:05:53.676
私たちがまさに今 懸念していることです
ソーシャルメディアに カメラ搭載ドローン

00:05:53.676 --> 00:05:55.610
そしてもちろんセクスティング

00:05:55.740 --> 00:05:57.940
そういったテクノロジーに
対する恐怖は

00:05:57.940 --> 00:05:59.286
理にかなっています

00:05:59.286 --> 00:06:03.096
テクノロジーには
私たちの最低な面や振る舞いを

00:06:03.096 --> 00:06:05.890
引き出し増幅する
力がありますから

00:06:05.980 --> 00:06:08.356
しかし解決法があります

00:06:08.380 --> 00:06:12.190
危険な新技術というのは
以前にもありました

00:06:12.540 --> 00:06:16.316
1908年 T型フォードが発売され

00:06:16.340 --> 00:06:18.916
交通死亡事故が増加しました

00:06:18.940 --> 00:06:22.230
深刻な問題です
なんて安全そうな車でしょう！

00:06:23.900 --> 00:06:27.876
最初の反応は ドライバーの行動を
変えようというものでした

00:06:27.900 --> 00:06:31.990
それで速度制限が設けられ 
違反には罰金が科せられました

00:06:31.990 --> 00:06:33.916
しかしその後の
数十年の間に

00:06:33.940 --> 00:06:39.436
自動車の技術は中立的なんかじゃないと
気付くようになりました

00:06:39.460 --> 00:06:42.676
より安全な車を
デザインすることもできるのです

00:06:42.700 --> 00:06:46.156
それで1920年代に
飛散防止フロントガラスができ

00:06:46.180 --> 00:06:48.676
1950年代にはシートベルトが

00:06:48.700 --> 00:06:52.200
1990年代にはエアバッグが
装備されるようになりました

00:06:52.220 --> 00:06:54.916
法・個人・業界の三者が歩み寄り

00:06:54.916 --> 00:06:58.770
時間を掛けて
新技術が引き起こす問題を

00:06:58.770 --> 00:07:03.236
解決していきました

00:07:03.260 --> 00:07:06.960
デジタルプライバシーについても
同じことができるはずです

00:07:06.980 --> 00:07:10.020
もちろん鍵になるのは合意です

00:07:10.180 --> 00:07:11.396
考え方としては

00:07:11.420 --> 00:07:15.236
誰かのプライベートな情報を
配布する場合には

00:07:15.260 --> 00:07:18.110
その人の許可を得る必要がある
ということです

00:07:18.110 --> 00:07:20.850
この積極的合意という考え方は

00:07:20.850 --> 00:07:26.676
どんな性行為にも合意が必要という 
反レイプ活動家から来ています

00:07:26.700 --> 00:07:31.200
他の様々な分野では 合意について
とても高い基準があります

00:07:31.200 --> 00:07:33.156
手術を受ける場合を
考えてください

00:07:33.180 --> 00:07:37.446
自分の受ける医療について 患者が
確かに理解した上で合意していることを

00:07:37.446 --> 00:07:39.330
医者は確認する
必要があります

00:07:39.340 --> 00:07:43.036
iTunesの利用規約への合意なんかとは
わけが違います

00:07:43.060 --> 00:07:46.956
みんなただスクロールして 
何か知らずにOKしてると思いますが

00:07:46.956 --> 00:07:48.460
(笑)

00:07:48.980 --> 00:07:54.236
合意についてみんながもっとよく考えるなら 
もっと良いプライバシー保護法ができるはずです

00:07:54.260 --> 00:07:57.676
現在はそんなに
保護されてはいません

00:07:57.700 --> 00:08:01.120
元夫や元妻が酷い人間で

00:08:01.120 --> 00:08:05.516
自分の裸の写真をポルノサイトに
アップロードされたとしたら

00:08:05.540 --> 00:08:08.756
そういった写真をすっかり
削除するのは大変です

00:08:08.780 --> 00:08:09.996
多くの州では

00:08:10.020 --> 00:08:13.836
その写真を自分で
撮っていた方が好都合です

00:08:13.860 --> 00:08:16.940
著作権を主張できますから

00:08:17.140 --> 00:08:19.196
(笑)

00:08:19.220 --> 00:08:22.686
現在のところ 
個人であれ企業であれNSAであれ

00:08:22.686 --> 00:08:26.860
誰かにプライバシーを
侵害されたというとき

00:08:26.910 --> 00:08:29.836
法に訴えることはできますが

00:08:29.860 --> 00:08:31.996
うまくいかない可能性が
多分にあります

00:08:32.020 --> 00:08:36.796
多くの裁判所が デジタルプライバシーは
実現不能だと考えているからです

00:08:36.820 --> 00:08:40.620
だからプライバシー侵害での裁判を
したがらないのです

00:08:41.020 --> 00:08:43.840
未だに絶えず聞かれるのは

00:08:43.840 --> 00:08:46.160
デジタル画像だと

00:08:46.160 --> 00:08:51.380
私的なものと公のものの区別が
曖昧になるのでは という話です

00:08:51.380 --> 00:08:52.756
そんなことありません！

00:08:52.780 --> 00:08:56.116
デジタルだと自動的に
公のものになるわけじゃありません

00:08:56.140 --> 00:08:58.036
そんな道理はありません

00:08:58.060 --> 00:09:01.556
ニューヨーク大学の法学者
ヘレン・ニッセンバウムが言っています

00:09:01.580 --> 00:09:04.326
あらゆる種類の
プライベートな情報を保護する

00:09:04.326 --> 00:09:07.320
法・方針・規範があるが

00:09:07.320 --> 00:09:10.856
デジタルかどうかは
区別されていないと

00:09:10.856 --> 00:09:13.576
医療データはデジタル化
されていますが

00:09:13.576 --> 00:09:16.636
医者がそれを漏らす
ことはできません

00:09:16.660 --> 00:09:21.116
個人のファイナンス情報は
デジタルのデータベースに保存されていますが

00:09:21.140 --> 00:09:25.960
クレジットカード会社は人の購入履歴を
勝手にネットで公開したりできません

00:09:26.710 --> 00:09:32.416
より良い法律は 起きてしまった
プライバシー侵害に対処することができますが

00:09:32.416 --> 00:09:34.920
もっと簡単なのは

00:09:34.920 --> 00:09:39.910
お互いのプライバシーを守るよう
個々人が変わることです

00:09:40.180 --> 00:09:43.176
プライバシーは
その人自身の責任だと

00:09:43.176 --> 00:09:45.156
ずっと言われてきました

00:09:45.180 --> 00:09:49.436
プライバシー設定にいつも注意を払って
更新するようにとか

00:09:49.460 --> 00:09:55.090
世界中の人に見られて困るようなものは
共有してはいけないとか言われてきました

00:09:55.110 --> 00:09:56.436
そんなの変です

00:09:56.460 --> 00:09:59.436
デジタルメディアというのは
社会的な環境であり

00:09:59.460 --> 00:10:04.260
人々は信用している相手に対して
絶えず共有をしています

00:10:04.580 --> 00:10:07.556
プリンストン大学の研究者
ジャネット・ヴァーテッシは

00:10:07.580 --> 00:10:11.550
データやプライバシーというのは
単なる個人のものではなく

00:10:11.550 --> 00:10:14.246
個人間のものなのだ
と言っています

00:10:14.246 --> 00:10:17.476
皆さんにできる
簡単なことは

00:10:17.500 --> 00:10:22.596
他の人の情報を共有する時には
本人の許可を得るということです

00:10:22.620 --> 00:10:27.156
誰かの写真をネットに上げようと思ったら 
許可を得ましょう

00:10:27.180 --> 00:10:29.636
メールを転送しようと思ったら

00:10:29.660 --> 00:10:31.010
許可を得ましょう

00:10:31.010 --> 00:10:33.946
誰かの裸の自撮り写真を
共有したいと思ったら

00:10:33.946 --> 00:10:36.480
言うまでもなく
許可を得ましょう

00:10:37.380 --> 00:10:41.836
そういった個々人の変化は 
お互いのプライバシーを守る助けになりますが

00:10:41.860 --> 00:10:45.980
テクノロジー企業にも
協力してもらう必要があります

00:10:46.180 --> 00:10:50.676
そういった会社は
プライバシーを守る動機が低いものです

00:10:50.700 --> 00:10:54.296
みんながあらゆるものを
可能な限り多くの人と共有することに

00:10:54.296 --> 00:10:56.870
彼らのビジネスモデルが
依存しているからです

00:10:56.900 --> 00:10:58.976
現在は 私が皆さんに
写真を送ったら

00:10:58.976 --> 00:11:01.956
皆さんはそれを
誰にでも転送できます

00:11:01.980 --> 00:11:06.236
でも転送して良いかどうかを
私が決められたとしたらどうでしょう？

00:11:06.260 --> 00:11:10.316
「この画像の送信は許可されていません」と
言えるとしたら？

00:11:10.340 --> 00:11:14.476
著作権を守るためであれば 
そういうことは よく行われています

00:11:14.500 --> 00:11:19.276
電子書籍を買っても 
それをいろんな人に送ったりはできません

00:11:19.300 --> 00:11:22.160
携帯でも同じように
したらどうでしょう？

00:11:22.780 --> 00:11:26.110
私たちにできることは 
デバイスやプラットフォームに

00:11:26.110 --> 00:11:31.316
そういう保護を標準で付けるよう 
テクノロジー企業に求めることです

00:11:31.340 --> 00:11:34.756
車だって ボディカラーは
好きに選べても

00:11:34.780 --> 00:11:37.850
エアバッグは常に標準品です

00:11:39.900 --> 00:11:43.716
デジタルプライバシーと合意について
ちゃんと考えないなら

00:11:43.740 --> 00:11:46.810
大変な結果を招くことに
なるかもしれません

00:11:47.180 --> 00:11:49.436
オハイオ州に
ある十代の女の子がいました

00:11:49.460 --> 00:11:52.820
彼女の名を仮に
ジェニファーとしておきましょう

00:11:52.850 --> 00:11:56.516
彼女は自分の裸の画像を
高校のボーイフレンドにあげました

00:11:56.540 --> 00:11:58.660
彼を信用できると思ったんです

00:11:59.540 --> 00:12:01.476
不幸にも彼女は裏切られ

00:12:01.500 --> 00:12:04.476
彼はその写真を
学校のみんなに送りました

00:12:04.500 --> 00:12:08.510
ジェニファーは さらし者にされて
恥ずかしい思いをし

00:12:08.530 --> 00:12:12.700
クラスメートは同情するどころか
彼女をいじめました

00:12:12.700 --> 00:12:14.906
彼女をあばずれだの
売女だのと罵り

00:12:14.906 --> 00:12:17.130
彼女の人生を
みじめなものにしました

00:12:17.130 --> 00:12:21.320
ジェニファーは学校を休みがちになり 
成績が落ちました

00:12:21.340 --> 00:12:25.670
最終的に彼女は
自らの命を絶つことを選びました

00:12:26.540 --> 00:12:29.236
ジェニファーは何も悪いことを
したわけではありません

00:12:29.260 --> 00:12:31.516
ただ信用できると思った人に

00:12:31.540 --> 00:12:34.356
裸の写真を送ったというだけです

00:12:34.380 --> 00:12:36.440
それなのに法律では

00:12:36.440 --> 00:12:41.470
彼女が児童ポルノに等しい
大変な罪を犯したことにされてしまいます

00:12:41.740 --> 00:12:43.236
我々の性の規範では

00:12:43.260 --> 00:12:46.240
自分のヌード写真を撮ることは

00:12:46.240 --> 00:12:49.980
甚だしい恥ずべき行為だと
されているんです

00:12:50.220 --> 00:12:54.436
デジタルメディアでプライバシーを
守ることは不可能だと考えるのは

00:12:54.460 --> 00:13:00.430
彼女のボーイフレンドの
極めて悪い行為を忘れ 許すことになります

00:13:01.020 --> 00:13:06.500
人々はいまだプライバシーを侵害された
被害者たちに こう言っています

00:13:06.500 --> 00:13:08.306
「いったい何を考えているんだ？

00:13:08.306 --> 00:13:10.780
そんな写真を送る方が悪い」

00:13:11.460 --> 00:13:15.890
どう言うべきか迷っているなら 
こう考えてみてください

00:13:15.930 --> 00:13:19.820
スキーで脚を折った友達に
ばったり出会ったとしましょう

00:13:20.060 --> 00:13:24.636
何か楽しいことをやろうとリスクを冒し 
まずい結果になったわけです

00:13:24.660 --> 00:13:26.440
でも皆さんはそういう人に

00:13:26.440 --> 00:13:30.760
「スキーなんかに行くのが悪い」
などと言うイヤな奴ではないでしょう

00:13:31.900 --> 00:13:34.036
合意について
よく考えたなら

00:13:34.060 --> 00:13:37.316
プライバシー侵害の被害者は
同情すべきであって

00:13:37.340 --> 00:13:40.746
犯罪者扱いしたり 辱めたり 
嫌がらせしたり

00:13:40.746 --> 00:13:43.990
罰したりすべきではないと
分かるはずです

00:13:44.260 --> 00:13:48.756
被害者を支え 
プライバシー侵害をある程度防ぐことが

00:13:48.780 --> 00:13:53.630
お話ししたような法的・個人的・技術的な
変化によって可能です

00:13:53.660 --> 00:13:59.476
問題なのはセクスティングではなく 
デジタルプライバシーだからです

00:13:59.500 --> 00:14:02.470
そして解決法の１つは
合意を得ることです

00:14:02.500 --> 00:14:07.076
だから今度プライバシー侵害の
被害者に会うことがあれば

00:14:07.100 --> 00:14:09.836
その人を非難するのではなく

00:14:09.860 --> 00:14:13.276
デジタルプライバシーに
対する考えを変え

00:14:13.300 --> 00:14:16.510
思いやりの気持ちをもって
あたりましょう

00:14:16.510 --> 00:14:17.716
ありがとうございました

00:14:17.740 --> 00:14:23.876
(拍手)

