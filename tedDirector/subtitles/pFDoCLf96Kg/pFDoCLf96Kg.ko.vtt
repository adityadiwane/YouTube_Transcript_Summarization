WEBVTT
Kind: captions
Language: ko

00:00:00.000 --> 00:00:07.000
번역: JY Kang
검토: Young-ho Park

00:00:15.260 --> 00:00:18.260
그럼, 조지오웰에 영감을 얻어 제작된

00:00:18.260 --> 00:00:20.260
광고로 강연을 시작할까 합니다.

00:00:20.260 --> 00:00:23.260
1984년 애플사가 제작한 것입니다.

00:00:32.260 --> 00:00:34.260
(영상) 빅브라더 : 우리는 하나의 의지,

00:00:34.260 --> 00:00:37.260
하나의 결의, 하나의 동기를 가진

00:00:37.260 --> 00:00:39.260
하나의 민족이다.

00:00:39.260 --> 00:00:42.260
우리의 적들은 죽을때까지 말만 할것이고,

00:00:42.260 --> 00:00:45.260
우리는 그들의 혼란을 무기로 그들과 싸울 것이다.

00:00:47.260 --> 00:00:49.260
우리는 승리할 것이다.

00:00:52.260 --> 00:00:54.260
해설자: 1월 24일.

00:00:54.260 --> 00:00:57.260
애플 컴퓨터가 맥킨토시를 선보입니다.

00:00:57.260 --> 00:01:00.260
이제 당신은 1984년이

00:01:00.260 --> 00:01:02.260
소설 1984와 다른 이유를 알게 되실 겁니다.

00:01:02.260 --> 00:01:05.260
RM : 이 영상에 담겨진 메세지는

00:01:05.260 --> 00:01:08.260
오늘날에도 강력한 의미를 갖습니다.

00:01:08.260 --> 00:01:11.260
혁신적인 기업에 의해 창조된 기술은

00:01:11.260 --> 00:01:14.260
우리 모두를 자유롭게 하겠죠.

00:01:14.260 --> 00:01:17.260
그 후, 20년이 더 지난 후의 상황을 보죠.

00:01:17.260 --> 00:01:20.260
애플은 중국에서 아이폰 판매를 시작했고,

00:01:20.260 --> 00:01:22.260
달라이라마 앱(App)을 금지시켰죠.

00:01:22.260 --> 00:01:25.260
그 외에도 정치적으로 민감한 몇몇 프로그램들을

00:01:25.260 --> 00:01:27.260
중국정부의 요청에 따라

00:01:27.260 --> 00:01:29.260
중국 앱스토어에서 삭제했고요.

00:01:29.260 --> 00:01:31.260
미국의 시사만화가인

00:01:31.260 --> 00:01:33.260
마크 피오레의 경우도,

00:01:33.260 --> 00:01:35.260
그의 풍자 어플리케이션이

00:01:35.260 --> 00:01:37.260
미국내에서 금지되었지요.

00:01:37.260 --> 00:01:39.260
그 앱이 일부 그룹의 사람들에게

00:01:39.260 --> 00:01:42.260
모욕적일 수도 있다고 애플이 판단했기 때문이죠.

00:01:42.260 --> 00:01:44.260
그 앱은 그가 퓰리처 상을

00:01:44.260 --> 00:01:47.260
받은 후에야 판매금지가 풀렸습니다.

00:01:47.260 --> 00:01:50.260
독일의 시사주간지 슈테른(Stern)도

00:01:50.260 --> 00:01:52.260
그들의 앱의 일부를 가위질 당했지요.

00:01:52.260 --> 00:01:54.260
그 이유는 내숭을 떠는 애플사가

00:01:54.260 --> 00:01:57.260
그 앱이 다소 외설적이라고 생각했기 때문이었죠.

00:01:57.260 --> 00:01:59.260
그 잡지는 독일 전역의 신문 가판대에서

00:01:59.260 --> 00:02:01.260
완전히 합법적으로 판매되고

00:02:01.260 --> 00:02:04.260
있는데도 그런 처분을 받았던 거죠.

00:02:04.260 --> 00:02:06.260
더욱 논쟁이 되었던 것은, 최근에

00:02:06.260 --> 00:02:09.260
이스라엘 정부가 팔레스타인 '항의 앱'이

00:02:09.260 --> 00:02:12.260
무력 공격을 준비하는데 사용될 수 있다며

00:02:12.260 --> 00:02:15.260
항의한 후 애플이 판매를 금지시켰죠.

00:02:15.260 --> 00:02:17.260
바로 그런게 문제죠.

00:02:17.260 --> 00:02:19.260
우리가 처한 현재 상황은

00:02:19.260 --> 00:02:22.260
사기업들이 가끔 지나치게 독단적이며,

00:02:22.260 --> 00:02:25.260
민주주의 사회의 헌법이 보장하는

00:02:25.260 --> 00:02:27.260
표현의 자유에 비해

00:02:27.260 --> 00:02:29.260
훨씬 더 제한적인

00:02:29.260 --> 00:02:31.260
검열을 한다는 것입니다.

00:02:31.260 --> 00:02:34.260
혹은 국민의 의견을 무시하는

00:02:34.260 --> 00:02:36.260
권위주의 체제의 검열요구에

00:02:36.260 --> 00:02:38.260
화답하고 있는 것일 수도 있죠.

00:02:38.260 --> 00:02:41.260
어쩌면 거론되고 있는

00:02:41.260 --> 00:02:45.260
인터넷 콘텐트와 관련된 많은 사용자와 관객들에게

00:02:45.260 --> 00:02:48.260
사법권을 행사하지 못하는

00:02:48.260 --> 00:02:51.260
정부의 근심과 요청에 응하는 것일지 모르죠.

00:02:51.260 --> 00:02:53.260
간단히 말씀드리자면,

00:02:53.260 --> 00:02:55.260
인터넷이 없었던 과거에는

00:02:55.260 --> 00:02:58.260
모든 사람의 신체적인

00:02:58.260 --> 00:03:00.260
자유에 대한 사법권은

00:03:00.260 --> 00:03:02.260
거의 모든 경우에 그들의

00:03:02.260 --> 00:03:04.260
국가들이 가지고 있었죠.

00:03:04.260 --> 00:03:06.260
하지만 오늘의 사이버

00:03:06.260 --> 00:03:08.260
공간에서는 사적인 주체가

00:03:08.260 --> 00:03:10.260
주권을 가지고 있지요.

00:03:10.260 --> 00:03:12.260
그리고 소프트웨어 코딩, 엔지니어링,

00:03:12.260 --> 00:03:15.260
디자인 및 사용약관 등에 대한 그들의 결정은

00:03:15.260 --> 00:03:17.260
마치 일종의 법규처럼 우리들이

00:03:17.260 --> 00:03:21.260
디지털 세계에서 무엇을 할 수 있고 할 수 없는가를 규정하지요.

00:03:21.260 --> 00:03:23.260
그리고, 교차되고

00:03:23.260 --> 00:03:25.260
세계적으로 상호연결되는

00:03:25.260 --> 00:03:27.260
그들의 자주권은 통상적인

00:03:27.260 --> 00:03:29.260
국민국가의 자주권에 매우

00:03:29.260 --> 00:03:31.260
흥미있는 형식으로 도전할 수도 있지요.

00:03:31.260 --> 00:03:33.260
또한 우리들이 정보로

00:03:33.260 --> 00:03:35.260
무엇을 할 수 있고,

00:03:35.260 --> 00:03:37.260
무엇을 할 수 없는가를

00:03:37.260 --> 00:03:39.260
통제하는 것이 우리의

00:03:39.260 --> 00:03:41.260
물리적 세계에서 권력을 행사하는데

00:03:41.260 --> 00:03:43.260
이전 보다 더 큰 영향을 주는 오늘날

00:03:43.260 --> 00:03:45.260
사적인 자주권의 영향력은

00:03:45.260 --> 00:03:48.260
종종 더 확장될 수도 있지요.

00:03:48.260 --> 00:03:50.260
이제는 자유진영의 리더조차도

00:03:50.260 --> 00:03:53.260
다음번 선거에서 당선되려면

00:03:53.260 --> 00:03:56.260
페이스북 왕국 지배자의 도움이 약간은 필요하죠.

00:03:56.260 --> 00:03:58.260
그리고 그러한 플랫폼은

00:03:58.260 --> 00:04:00.260
지난 봄 이후 튜지니아와

00:04:00.260 --> 00:04:03.260
이집트의 정치운동가들에게

00:04:03.260 --> 00:04:05.260
실제로 큰 도움이 되었지요.

00:04:05.260 --> 00:04:08.260
와엘 고님(Wael Ghonim)은

00:04:08.260 --> 00:04:11.260
낮에는 구글 이집트의 이사직을 맡고 있고,

00:04:11.260 --> 00:04:13.260
밤에는 몰래 페이스북으로 정치운동을 했는데

00:04:13.260 --> 00:04:15.260
그는 무바라크 정권이 물러난 후

00:04:15.260 --> 00:04:17.260
CNN 에 이런 유명한 말을 남겼습니다.

00:04:17.260 --> 00:04:19.260
"어느 국가에 자유를 주려면

00:04:19.260 --> 00:04:21.260
그들에게 인터넷을 주면 됩니다"

00:04:21.260 --> 00:04:23.260
하지만, 정권을 뒤집는건 어쩔지 몰라도

00:04:23.260 --> 00:04:25.260
안정된 민주주의를 건설하는 것은

00:04:25.260 --> 00:04:27.260
약간은 더 어려운 문제입니다.

00:04:27.260 --> 00:04:30.260
왼쪽 사진은 지난 3월에 이집트의

00:04:30.260 --> 00:04:32.260
보안국 사무실을 급습했던 사람의

00:04:32.260 --> 00:04:35.260
하나였던 이집트 정치 운동가가 찍은것이죠.

00:04:35.260 --> 00:04:37.260
그당시 많은 보안기관 요원들은

00:04:37.260 --> 00:04:39.260
파기할 수 있는 문서들을

00:04:39.260 --> 00:04:41.260
모두 파기하고 쓰레기로 남겼죠.

00:04:41.260 --> 00:04:44.260
하지만 그들이 미처 파기하지 못한 서류들에서

00:04:44.260 --> 00:04:46.260
정치운동가들 몇 명은

00:04:46.260 --> 00:04:49.260
그들 자신을 대상으로 한 감시 자료,

00:04:49.260 --> 00:04:52.260
주고 받았던 이메일 내용 전체와

00:04:52.260 --> 00:04:54.260
휴대폰 문자메세지 내용은 물론이고

00:04:54.260 --> 00:04:56.260
스카이프 대화내용까지 찾아냈습니다.

00:04:56.260 --> 00:04:58.260
그리고 어떤 정치운동가 한명은

00:04:58.260 --> 00:05:01.260
서방국가 회사가 이집트 보안 기관에게

00:05:01.260 --> 00:05:03.260
감시 장비를 판다는 내용의

00:05:03.260 --> 00:05:05.260
계약서도 찾아냈죠.

00:05:05.260 --> 00:05:07.260
그런데 이집트 정치운동가들은

00:05:07.260 --> 00:05:09.260
이집트 과도정부가

00:05:09.260 --> 00:05:11.260
아직도 그런 감시 장비를

00:05:11.260 --> 00:05:14.260
사용하고 있다고 믿지요.

00:05:15.260 --> 00:05:18.260
그리고 튀니지에서는 벤 알리 대통령

00:05:18.260 --> 00:05:20.260
시절 만큼 광범위하지는 않지만

00:05:20.260 --> 00:05:23.260
5월부터 인터넷 검열이 다시 시작됐지요.

00:05:23.260 --> 00:05:25.260
그리고, 과도정부가 판단하기에

00:05:25.260 --> 00:05:27.260
폭력사태를 조장한다고 보이는

00:05:27.260 --> 00:05:29.260
페이스북 페이지와 다른 몇몇 웹사이트에

00:05:29.260 --> 00:05:31.260
이용자가 접근하려고 하면

00:05:31.260 --> 00:05:34.260
이런 웹 페이지가 나오지요.

00:05:34.260 --> 00:05:36.260
이러한 조치에 대항하여,

00:05:36.260 --> 00:05:38.260
벤 알리 대통령 시절에

00:05:38.260 --> 00:05:40.260
수감된 적도 있었던

00:05:40.260 --> 00:05:42.260
슬림 아마모우 라는 블로거는

00:05:42.260 --> 00:05:44.260
과도정부의 행동에 반대하는 의미로

00:05:44.260 --> 00:05:47.260
과도정부 내각에서 사퇴했지요.

00:05:47.260 --> 00:05:49.260
튀니지에서는 이러한 문제를 어떻게

00:05:49.260 --> 00:05:51.260
다룰 것인가에 대해 많은 논쟁이 있었지죠.

00:05:51.260 --> 00:05:53.260
사실, 트위터에서도

00:05:53.260 --> 00:05:55.260
사회혁명을 지지했던 많은 사람들이

00:05:55.260 --> 00:05:57.260
"우리는 민주주의와

00:05:57.260 --> 00:05:59.260
표현의 자유를 원하지만

00:05:59.260 --> 00:06:02.260
민주주의를 붕괴시킬 수 있는 지나친

00:06:02.260 --> 00:06:05.260
발언들은 금지돼야 한다." 라고 말했죠.

00:06:05.260 --> 00:06:07.260
하지만 문제는

00:06:07.260 --> 00:06:10.260
이러한 판단을 내릴 수 있는 권력이 누구에게 있는가와

00:06:10.260 --> 00:06:12.260
그들이 그런 권력을 악용하지 않는다는것을

00:06:12.260 --> 00:06:14.260
어떻게 보장할 수 있냐는 거죠.

00:06:14.260 --> 00:06:16.260
리아드 구어팔리라는

00:06:16.260 --> 00:06:18.260
튀니지의 고참 인터넷 정치운동가는

00:06:18.260 --> 00:06:20.260
이에 대해서 이렇게 언급했습니다.

00:06:20.260 --> 00:06:22.260
"전에는 모든 것이 단순해서

00:06:22.260 --> 00:06:25.260
좋은 사람, 나쁜 사람을 구별하기 쉬웠지만

00:06:25.260 --> 00:06:28.260
지금은 구별하기가 훨씬 더 힘들죠".

00:06:28.260 --> 00:06:31.260
튀니지와 이집트 국민 여러분들, 민주주의에 오신 것을

00:06:31.260 --> 00:06:33.260
환영합니다만. 하지만 사실은

00:06:33.260 --> 00:06:36.260
오늘 날의 민주주의 사회에서 조차

00:06:36.260 --> 00:06:38.260
디지털 네트워크 안에서의

00:06:38.260 --> 00:06:40.260
안보와 법률집행이라는 측면과

00:06:40.260 --> 00:06:43.260
시민적 자유의 보호와 표현의 자유라는

00:06:43.260 --> 00:06:45.260
두가지 측면이 올바른 균형을

00:06:45.260 --> 00:06:47.260
이룰 수 있는 좋은 해법을

00:06:47.260 --> 00:06:49.260
아직 찾아내지 못하고 있습니다.

00:06:49.260 --> 00:06:51.260
사실, 미국에서 터졌던

00:06:51.260 --> 00:06:54.260
줄리앙 어샌지 사건이 그렇죠.

00:06:54.260 --> 00:06:57.260
그를 별로 좋아하지 않는 사람들조차

00:06:57.260 --> 00:06:59.260
미국 정부와 몇몇 기업들이

00:06:59.260 --> 00:07:02.260
Wikileaks 사이트를 다뤘던 방법에 대해 크게 우려하지요.

00:07:02.260 --> 00:07:05.260
아마존은 미 상원의원 조 리버만로 부터 항의를 받은 후

00:07:05.260 --> 00:07:09.260
Wikileaks 사이트의 호스팅 서비스를 거부했었죠.

00:07:09.260 --> 00:07:11.260
Wikileaks가 어떤 범죄로도

00:07:11.260 --> 00:07:13.260
기소 당하거나

00:07:13.260 --> 00:07:15.260
유죄선고를

00:07:15.260 --> 00:07:18.260
받지 않았는데 말입니다.

00:07:18.260 --> 00:07:20.260
이제 우리는 인터넷이

00:07:20.260 --> 00:07:23.260
국경을 허무는 기술이라고 믿습니다.

00:07:23.260 --> 00:07:26.260
이것은 전세계의 소셜 네트워크를 보여주는 지도입니다.

00:07:26.260 --> 00:07:29.260
페이스북이 전세계의 대부분을 정복했죠.

00:07:29.260 --> 00:07:31.260
이 점은 페이스북의 서비스 관리 방법을

00:07:31.260 --> 00:07:33.260
보는 관점에 따라

00:07:33.260 --> 00:07:35.260
좋을 수도 있고 나쁠 수도 있습니다.

00:07:35.260 --> 00:07:37.260
예를들면 브라질과 일본의 경우

00:07:37.260 --> 00:07:39.260
그 나라의 문화적 특성과

00:07:39.260 --> 00:07:41.260
언어 문제로 인해

00:07:41.260 --> 00:07:44.260
사이버 공간에도 아직 국경이 남아있지요.

00:07:44.260 --> 00:07:46.260
하지만, 중국과 베트남 그리고

00:07:46.260 --> 00:07:49.260
과거 소련의 몇몇 나라의 경우

00:07:49.260 --> 00:07:51.260
더 염려스러운 일들이 발생하고 있죠.

00:07:51.260 --> 00:07:53.260
이들 나라들에서는

00:07:53.260 --> 00:07:55.260
정부와 소셜네트워크 기업들간의

00:07:55.260 --> 00:07:58.260
유착관계가

00:07:58.260 --> 00:08:00.260
형성되어 있는데

00:08:00.260 --> 00:08:02.260
바로 그러한

00:08:02.260 --> 00:08:05.260
유착관계로 인해

00:08:05.260 --> 00:08:07.260
이러한 플랫폼들의

00:08:07.260 --> 00:08:09.260
잠재적인 영향력이

00:08:09.260 --> 00:08:11.260
실질적으로 제한되고 있지요.

00:08:11.260 --> 00:08:13.260
오늘 날 중국에서는

00:08:13.260 --> 00:08:15.260
이른 바 "거대 방화벽" 이라는 것이 있어서

00:08:15.260 --> 00:08:17.260
페이스북을 차단하고

00:08:17.260 --> 00:08:20.260
트위터, 구글+ 그리고

00:08:20.260 --> 00:08:23.260
많은 해외 웹사이트들이 차단되고 있습니다.

00:08:23.260 --> 00:08:26.260
그런데 그런 검열작업의 일부는 서방국가의 도움을 받아서 했죠.

00:08:26.260 --> 00:08:29.260
이야기는 여기서 끝나지 않습니다.

00:08:29.260 --> 00:08:31.260
또 다른 일면에서는

00:08:31.260 --> 00:08:34.260
중국내에 인터넷 서비스를 제공하는 모든 기업들에 대해서

00:08:34.260 --> 00:08:37.260
중국 정부가 이른 바 "자가 정화 시스템"이라는 것을

00:08:37.260 --> 00:08:39.260
요구하고 있다는 것입니다.

00:08:39.260 --> 00:08:42.260
간단히 말하면 그들의 고객을

00:08:42.260 --> 00:08:44.260
검열하고 감시하라는 말이지요.

00:08:44.260 --> 00:08:47.260
이것은 2009년에 제가 참석했던 어느 시상식 장면입니다.

00:08:47.260 --> 00:08:50.260
중국 인터넷협회가 자제심을 잘 발휘한,

00:08:50.260 --> 00:08:53.260
말하자면 인터넷 감찰활동을 잘 해낸

00:08:53.260 --> 00:08:56.260
20개 중국 기업을 선정하여

00:08:56.260 --> 00:08:58.260
시상한 행사였습니다.

00:08:58.260 --> 00:09:01.260
중국의 유력 검색엔진인

00:09:01.260 --> 00:09:03.260
바이두(Baidu)의 로빈 리 사장도

00:09:03.260 --> 00:09:06.260
수상자 중의 한사람이었죠.

00:09:06.260 --> 00:09:10.260
러시아에서는 일반적으로 인터넷을 차단하거나

00:09:10.260 --> 00:09:12.260
웹사이트를 직접 검열하지 않지요.

00:09:12.260 --> 00:09:14.260
그렇지만 로스필(Rospil)이라는

00:09:14.260 --> 00:09:16.260
부정부패 추방 사이트는

00:09:16.260 --> 00:09:18.260
올해 초에, 한 사건으로

00:09:18.260 --> 00:09:20.260
논란에 휘말린 적이 있었지요.

00:09:20.260 --> 00:09:23.260
얀덱스 머니라는 지불결제 시스템을 통해서

00:09:23.260 --> 00:09:25.260
이 로스필 사이트에

00:09:25.260 --> 00:09:27.260
기부금을 냈던 사람들이

00:09:27.260 --> 00:09:29.260
국민당 당원으로 부터

00:09:29.260 --> 00:09:32.260
협박전화를 받은 사건이었죠.

00:09:32.260 --> 00:09:34.260
국민당 당원들은 로스필 사이트로

00:09:34.260 --> 00:09:37.260
기부금을 낸 사람에 대한 정보를

00:09:37.260 --> 00:09:39.260
정보부 요원으로 부터 받았는데

00:09:39.260 --> 00:09:42.260
그 정보부 요원은 그 정보를 어떤

00:09:42.260 --> 00:09:45.260
야덱스 머니 직원으로 부터 받았지요.

00:09:45.260 --> 00:09:47.260
이 사건은 인터넷을 사용하고,

00:09:47.260 --> 00:09:49.260
정부가 인터넷에 대한 책임을

00:09:49.260 --> 00:09:52.260
지게 하는데 큰 악영향을 미쳤지요.

00:09:52.260 --> 00:09:54.260
요즈음은 주로 사립 회사가

00:09:54.260 --> 00:09:56.260
소유하고 운영하는

00:09:56.260 --> 00:09:59.260
인터넷 서비스를 통해 국민과

00:09:59.260 --> 00:10:02.260
정부간의 관계가 조정되는

00:10:02.260 --> 00:10:04.260
상황이 일어나는데 이런 국가들의

00:10:04.260 --> 00:10:08.260
수는 계속 늘어나고 있지요.

00:10:08.260 --> 00:10:10.260
그래서, 저는 인터넷이 좋은 편을

00:10:10.260 --> 00:10:12.260
도울 것인지 나쁜 편을 도울 것인지를

00:10:12.260 --> 00:10:15.260
의논하는 것은 중요하지 않다고 생각하죠.

00:10:15.260 --> 00:10:17.260
물론, 상대방 보다

00:10:17.260 --> 00:10:20.260
인터넷을 더 잘 이해하고

00:10:20.260 --> 00:10:22.260
인터넷 기술을 더 잘 사용하는

00:10:22.260 --> 00:10:25.260
쪽이 더 권력을 많이 가지게 되겠지요.

00:10:25.260 --> 00:10:28.260
지금 우리에게 주어진

00:10:28.260 --> 00:10:30.260
가장 시급한 과제는

00:10:30.260 --> 00:10:32.260
어떻게 하면 국민을 중심으로 인터넷을

00:10:32.260 --> 00:10:35.260
발전시키냐는 것입니다.

00:10:35.260 --> 00:10:37.260
왜냐하면, 정부가 존재하는

00:10:37.260 --> 00:10:40.260
유일하게 정당한 목적은 국민을

00:10:40.260 --> 00:10:42.260
섬기기 위한 것이니까요.

00:10:42.260 --> 00:10:44.260
그리고 저는 기술이 존재하는

00:10:44.260 --> 00:10:46.260
유일하게 정당한 목적은 우리를

00:10:46.260 --> 00:10:48.260
조종하거나 노예로 만드는 것이 아니고

00:10:48.260 --> 00:10:52.260
인류의 삶을 개선하는데 있다고 믿지요.

00:10:53.260 --> 00:10:55.260
우리는 정부가 그들의 행동에 대한

00:10:55.260 --> 00:10:57.260
책임을 지게 만드는 방법을 알죠.

00:10:57.260 --> 00:10:59.260
우리는 정부의 책임을 제대로 추궁하지

00:10:59.260 --> 00:11:02.260
못할지는 몰라도 그렇게 할 수 있는

00:11:02.260 --> 00:11:04.260
정치적이나 제도적인 모델이 무엇인지는 알죠.

00:11:04.260 --> 00:11:06.260
기업 경영자 대부분이 자신들의 의무는

00:11:06.260 --> 00:11:08.260
주주의 이익을 극대화라고 주장하는 상황하에서

00:11:08.260 --> 00:11:10.260
어떻게 하면 사이버 공간의

00:11:10.260 --> 00:11:12.260
군주들이 공공이익에 대한

00:11:12.260 --> 00:11:14.260
책임을 지게 할 수 있을까요?

00:11:14.260 --> 00:11:16.260
그리고 정부의 통제가

00:11:16.260 --> 00:11:18.260
오히려 도움이 되지 않는 경우도 많죠.

00:11:18.260 --> 00:11:20.260
예를 들면, 프랑스에서는 이런 일이 있었죠.

00:11:20.260 --> 00:11:22.260
사르코지 대통령이

00:11:22.260 --> 00:11:24.260
인테넷 회사 경영자들에게 이런 말을 했죠.

00:11:24.260 --> 00:11:26.260
"오로지 우리의 정부만이 공공이익을

00:11:26.260 --> 00:11:28.260
합법적으로 대표할 수 있다"

00:11:28.260 --> 00:11:30.260
하지만 그 후에 그는

00:11:30.260 --> 00:11:32.260
파일을 공유한 사람의 인터넷을

00:11:32.260 --> 00:11:34.260
차단시키는 악명높은 삼진아웃법

00:11:34.260 --> 00:11:36.260
같은 법안을 옹호했는데

00:11:36.260 --> 00:11:39.260
UN 의사표현의 자유 특별보고관은

00:11:39.260 --> 00:11:41.260
그것이 정도가 지나친

00:11:41.260 --> 00:11:44.260
의사소통 권리의

00:11:44.260 --> 00:11:46.260
침해라고 비난했죠.

00:11:46.260 --> 00:11:49.260
그 일은 시민 단체들 사이에

00:11:49.260 --> 00:11:51.260
정치가들이 국민들의

00:11:51.260 --> 00:11:53.260
권리를 보호하는 것 보다

00:11:53.260 --> 00:11:55.260
오락산업계의 이익을 보호하는데에

00:11:55.260 --> 00:11:58.260
더 관심을 갖고 있는 것이 아닌가 하는

00:11:58.260 --> 00:12:00.260
의구심을 불어일으켰지요.

00:12:00.260 --> 00:12:02.260
그리고 이곳 영국에서는

00:12:02.260 --> 00:12:04.260
디지털경제법이라는

00:12:04.260 --> 00:12:06.260
법에 대한 우려가 대두되고 있는데

00:12:06.260 --> 00:12:08.260
그 법은 개인 컨텐츠 중개자들에게

00:12:08.260 --> 00:12:10.260
인터넷 사용자의 행동을 감시하는

00:12:10.260 --> 00:12:14.260
책임을 더 맡기지요.

00:12:14.260 --> 00:12:16.260
그래서, 우리가 기억해야 할 것은

00:12:16.260 --> 00:12:18.260
우리가 앞으로 국민중심의

00:12:18.260 --> 00:12:21.260
인터넷을 가지려면 인터넷 자유화 운동을

00:12:21.260 --> 00:12:23.260
더 널리 퍼트리고, 또한 그 운동을

00:12:23.260 --> 00:12:25.260
더 지속적으로 지지해야 합니다.

00:12:25.260 --> 00:12:28.260
과거의 경험으로 볼때 기업들이

00:12:28.260 --> 00:12:31.260
지하수 오염을 멈추고, 10살난 아이들에게

00:12:31.260 --> 00:12:33.260
일을 더 이상 시키지 않게 된것도

00:12:33.260 --> 00:12:35.260
기업 경영자들이 어느 날 아침에 일어나서

00:12:35.260 --> 00:12:38.260
그렇게 하는게 옳다고 결정했기 때문이 아니죠.

00:12:38.260 --> 00:12:40.260
그것은 수십 년 동안 지속된 정치적 행동주의,

00:12:40.260 --> 00:12:42.260
주주권 옹호, 그리고 소비자 옹호의

00:12:42.260 --> 00:12:44.260
결과였습니다.

00:12:44.260 --> 00:12:48.260
이와 마찬가지로, 정부들이 좋은 환경법과

00:12:48.260 --> 00:12:51.260
노동보호법을 만들게 된 것도 정치가들이

00:12:51.260 --> 00:12:54.260
어느 날 갑자기 훌륭한 영감을 받고 한일이 아니죠.

00:12:54.260 --> 00:12:56.260
이것은 오랜기간에 걸쳐

00:12:56.260 --> 00:12:58.260
공정한 법규와

00:12:58.260 --> 00:13:00.260
올바른 기업 활동을 요구하는

00:13:00.260 --> 00:13:02.260
정치활동을 벌려 온 결과지요.

00:13:02.260 --> 00:13:04.260
인터넷에 있어서도 그와 동일한

00:13:04.260 --> 00:13:06.260
방법을 사용해야 합니다.

00:13:06.260 --> 00:13:08.260
정치적 혁신 또한

00:13:08.260 --> 00:13:10.260
필요하겠지요.

00:13:10.260 --> 00:13:13.260
약 800년 전,

00:13:13.260 --> 00:13:15.260
영국의 귀족들은

00:13:15.260 --> 00:13:17.260
왕의 신성한 권리라는 개념은

00:13:17.260 --> 00:13:20.260
더이상 자신들에게 먹혀들어 가지

00:13:20.260 --> 00:13:22.260
않는다며 존 왕이

00:13:22.260 --> 00:13:25.260
마그나카르타 대헌장에

00:13:25.260 --> 00:13:27.260
강제로 서명하게 만들었죠.

00:13:27.260 --> 00:13:29.260
신성한 지배권을 가졌다고

00:13:29.260 --> 00:13:32.260
자처하는 왕 조차도 기본적인 법규의

00:13:32.260 --> 00:13:35.260
테두리 안에 있음을 인정하는 내용이었죠.

00:13:35.260 --> 00:13:38.260
그리하여, 이른바

00:13:38.260 --> 00:13:40.260
정치적 혁신의 토대가 구축되었고

00:13:40.260 --> 00:13:43.260
결과적으로 '피통치인의 동의'라는 개념이 생겼는데

00:13:43.260 --> 00:13:46.260
그 개념은 대서양을 건너 미국의

00:13:46.260 --> 00:13:49.260
급진적이고 혁명적인 정부에 의해

00:13:49.260 --> 00:13:52.260
처음으로 현실화 되었지요.

00:13:52.260 --> 00:13:55.260
우리는 이제 네티즌의 동의를

00:13:55.260 --> 00:13:57.260
얻는 방법을 찾아내야 합니다.

00:13:57.260 --> 00:13:59.260
그것은 어떤 형태를 가질까요?

00:13:59.260 --> 00:14:02.260
현재로서는 알 수 없죠.

00:14:02.260 --> 00:14:06.260
네티즌의 동의를 얻으려면

00:14:06.260 --> 00:14:09.260
우리는 정치적이나

00:14:09.260 --> 00:14:11.260
지정학적 문제에만

00:14:11.260 --> 00:14:13.260
집중할 것이 아니라

00:14:13.260 --> 00:14:15.260
투자가행동,

00:14:15.260 --> 00:14:18.260
소비자의 선택 그리고

00:14:18.260 --> 00:14:21.260
심지어는 소프트웨어 디자인과

00:14:21.260 --> 00:14:23.260
소프트웨어 엔지니어링에

00:14:23.260 --> 00:14:27.260
이르기까지 혁신적인 변화가 필요할 것입니다.

00:14:27.260 --> 00:14:30.260
우리가 정부와 기술을 위해 살지 않고

00:14:30.260 --> 00:14:33.260
정부와 기술이 우리에게 이바지하는

00:14:33.260 --> 00:14:36.260
그런 세상을 건설하기 위해서는

00:14:36.260 --> 00:14:39.260
우리 각자의 역할이 절대적으로 중요합니다.

00:14:39.260 --> 00:14:41.260
경청해 주셔서 고맙습니다.

00:14:41.260 --> 00:14:46.260
(박수)

