WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: Nicolas Abgrall
Relecteur: Zeineb Trabelsi

00:00:12.556 --> 00:00:15.943
Nos émotions influencent
tous les aspects de notre vie,

00:00:15.943 --> 00:00:16.943
de notre santé et 
notre façon d'apprendre

00:00:16.943 --> 00:00:19.179
à la manière dont 
nous faisons des affaires,

00:00:19.179 --> 00:00:21.922
et prenons des décisions, 
petites ou grandes.

00:00:22.672 --> 00:00:26.162
Elles influencent aussi la manière 
dont nous interagissons ensemble.

00:00:27.132 --> 00:00:31.108
Nous avons évolué pour vivre 
dans un monde qui ressemble à ça,

00:00:31.108 --> 00:00:35.797
mais nous vivons nos vies de plus
en plus plutôt comme ceci --

00:00:35.807 --> 00:00:38.561
c'est le message que ma fille 
m'a envoyé hier soir --

00:00:38.561 --> 00:00:41.301
dans un monde dépourvu d'émotion.

00:00:41.301 --> 00:00:43.252
Ma mission est de changer tout ça.

00:00:43.252 --> 00:00:47.343
Je veux ramener l'expression de nos
émotions dans nos expériences numériques.

00:00:48.223 --> 00:00:51.300
J'ai commencé de travailler 
dans cette direction il y a 15 ans.

00:00:51.300 --> 00:00:53.366
J'étais informaticienne en Égypte,

00:00:53.366 --> 00:00:57.711
et venais juste d'être acceptée dans 
un programme de thèse à Cambridge.

00:00:57.711 --> 00:00:59.984
Alors j'ai fait quelque chose
d'assez inhabituel

00:00:59.984 --> 00:01:04.209
pour une jeune musulmane égyptienne
et tout juste mariée :

00:01:05.599 --> 00:01:08.598
avec le soutien de mon mari
qui devait rester en Égypte,

00:01:08.598 --> 00:01:11.616
j'ai fait mes bagages et suis partie 
pour l'Angleterre.

00:01:11.616 --> 00:01:14.844
A Cambridge, à des milliers 
de kilomètres de chez moi,

00:01:14.844 --> 00:01:18.257
j'ai réalisé que je passais
plus d'heures sur mon ordinateur

00:01:18.257 --> 00:01:20.486
qu'avec n'importe quel humain.

00:01:20.486 --> 00:01:25.339
Pourtant, malgré cette intimité, 
il n'avait absolument aucune idée

00:01:25.339 --> 00:01:28.550
de ce que je ressentais. 
Il ne savait pas si j'étais heureuse,

00:01:28.550 --> 00:01:31.538
si j'avais eu une mauvaise journée,
si j'étais stressée

00:01:31.538 --> 00:01:34.460
ou confuse et ça devenait 
vraiment frustrant.

00:01:35.600 --> 00:01:38.031
Le pire, c'était que lorsque 
je communiquais en ligne

00:01:38.031 --> 00:01:41.031
avec ma famille à la maison,

00:01:41.031 --> 00:01:44.703
j'avais l'impression que toutes
mes émotions disparaissaient

00:01:44.703 --> 00:01:49.858
dans cet espace virtuel. J'avais le mal 
du pays, je me sentais seule

00:01:49.858 --> 00:01:53.026
et me mettais même 
à pleurer certains jours.

00:01:53.026 --> 00:01:56.806
Mais tout ce que j'avais pour partager
ces émotions, c'était ça. (Rires)

00:01:56.806 --> 00:02:01.780
La technologie moderne a beaucoup
de Q.I. mais aucun Q.E.: c'est-à-dire

00:02:01.780 --> 00:02:04.956
beaucoup d'intelligence 
cognitive mais pas émotionnelle.

00:02:04.956 --> 00:02:07.153
Je me suis alors demandée

00:02:07.153 --> 00:02:10.777
ce que ça changerait si notre technologie
pouvait percevoir nos émotions ?

00:02:10.777 --> 00:02:14.853
Que se passerait-il si nos appareils 
pouvaient les percevoir et réagir

00:02:14.853 --> 00:02:17.866
en fonction, exactement 
comme un ami le ferait ?

00:02:18.666 --> 00:02:22.230
Ces questions nous ont menés,
mon équipe et moi

00:02:22.230 --> 00:02:26.607
à développer des technologies qui peuvent
lire et réagir à nos émotions,

00:02:26.607 --> 00:02:29.697
à partir du visage humain.

00:02:30.577 --> 00:02:33.750
Il se trouve que le visage est
un des moyens d'expression

00:02:33.750 --> 00:02:37.766
les plus puissants que nous utilisons 
pour communiquer notre état social

00:02:37.766 --> 00:02:40.776
ou émotionnel, 
tout de la joie, la surprise,

00:02:40.776 --> 00:02:44.979
la compassion à la curiosité.

00:02:44.979 --> 00:02:49.907
En science des émotions, chacun des 
mouvements du visage est appelé action.

00:02:49.907 --> 00:02:52.522
Par exemple, action numéro 12

00:02:52.522 --> 00:02:54.870
n'est pas le nom 
du dernier succès hollywoodien,

00:02:54.870 --> 00:02:58.312
mais l'action de tirer le coin des lèvres,
autrement dit de sourire.

00:02:58.312 --> 00:03:01.240
Essayez ! Faisons tous 
nos plus beaux sourires !

00:03:01.240 --> 00:03:03.954
Autre exemple, action numéro 4,
le froncement de sourcils.

00:03:03.954 --> 00:03:06.192
C'est lorsque vous plissez les sourcils

00:03:06.192 --> 00:03:08.459
ensemble et créez
toutes ces rides et textures.

00:03:08.459 --> 00:03:12.244
On ne les aime pas mais c'est un très bon
indicateur d'émotion négative.

00:03:12.244 --> 00:03:14.960
Nous avons environ 45 de ces actions

00:03:14.960 --> 00:03:18.350
que nous combinons pour exprimer 
des centaines d'émotions.

00:03:18.350 --> 00:03:21.831
Enseigner à un ordinateur comment 
reconnaître ces expressions faciales

00:03:21.831 --> 00:03:24.913
est difficile parce qu'elles peuvent être
rapides, sont subtiles,

00:03:24.913 --> 00:03:27.777
et peuvent former beaucoup 
de combinaisons différentes.

00:03:27.777 --> 00:03:31.515
Prenez par exemple, 
un sourire normal ou un sourire narquois.

00:03:31.515 --> 00:03:35.268
Ils sont en soi assez similaires, mais
ont une signification bien différente.

00:03:35.268 --> 00:03:36.866
(Rires)

00:03:36.866 --> 00:03:39.450
Le sourire normal est positif,

00:03:39.450 --> 00:03:41.260
le sourire narquois souvent négatif.

00:03:41.260 --> 00:03:45.136
Un sourire narquois peut même 
vous rendre célèbre parfois !

00:03:45.136 --> 00:03:47.960
Mais plus sérieusement,
il est très important

00:03:47.960 --> 00:03:50.815
que l'ordinateur puisse différencier 
ces deux expressions.

00:03:50.815 --> 00:03:52.627
Alors comment y arrive-t-on ?

00:03:52.627 --> 00:03:54.414
On donne à nos algorithmes

00:03:54.414 --> 00:03:58.524
des dizaines de milliers d'exemples 
spécifiques de personnes

00:03:58.524 --> 00:04:01.589
en train de sourire, 
d'origines, âge, sexe différents

00:04:01.589 --> 00:04:04.160
et on fait la même chose pour 
des sourires narquois.

00:04:04.160 --> 00:04:06.174
Ensuite par un processus 
d'apprentissage,

00:04:06.174 --> 00:04:08.810
l'algorithme assimile 
toutes ces textures, ces rides

00:04:08.810 --> 00:04:11.390
et mouvements de notre visage,

00:04:11.390 --> 00:04:14.592
apprend les caractéristiques 
générales d'un sourire,

00:04:14.592 --> 00:04:17.773
et en associe de plus spécifiques 
aux sourires narquois.

00:04:17.773 --> 00:04:20.141
Ainsi au prochain visage qu'il voit,

00:04:20.141 --> 00:04:22.440
l'algorithme peut essentiellement

00:04:22.440 --> 00:04:25.473
reconnaître les caractéristiques 
d'un sourire et dire :

00:04:25.473 --> 00:04:29.751
« ha ! je reconnais cette expression, 
c'est un sourire. »

00:04:30.011 --> 00:04:33.181
Le meilleur moyen d'illustrer 
comment cette technologie fonctionne

00:04:33.181 --> 00:04:35.317
est une démonstration en direct

00:04:35.317 --> 00:04:39.230
alors j'aurais besoin d'un volontaire, 
de préférence quelqu'un avec un visage.

00:04:39.230 --> 00:04:41.564
(Rires)

00:04:41.564 --> 00:04:44.335
Cloe sera notre volontaire aujourd'hui.

00:04:45.325 --> 00:04:49.533
Au cours des 5 dernières années, 
notre groupe de recherche au MIT

00:04:49.533 --> 00:04:50.939
est devenu une entreprise,

00:04:50.939 --> 00:04:54.601
dans laquelle mon équipe a travaillé dur
pour que cette technologie marche,

00:04:54.601 --> 00:04:56.700
dans la vie de tous les jours,
comme on dit.

00:04:56.700 --> 00:04:59.210
Nous l'avons aussi optimisée 
pour qu'elle fonctionne

00:04:59.210 --> 00:05:02.530
sur n'importe quel appareil pourvu
d'une caméra, comme cet iPad.

00:05:02.530 --> 00:05:05.316
Mais essayons plutôt.

00:05:06.756 --> 00:05:10.680
Comme vous le voyez, l'algorithme 
trouve essentiellement le visage de Cloe

00:05:10.680 --> 00:05:12.372
dans cette zone encadrée blanche,

00:05:12.372 --> 00:05:14.943
et décèle les mouvements 
des points principaux

00:05:14.943 --> 00:05:17.799
tels que ses sourcils, ses yeux, 
sa bouche et son nez.

00:05:17.799 --> 00:05:20.786
La question est alors de savoir
s'il peut reconnaître ses expressions.

00:05:20.786 --> 00:05:22.457
Essayons donc de le tester.

00:05:22.457 --> 00:05:26.643
Tout d'abord, montrez moi un visage
impassible. Oui, parfait ! (Rires)

00:05:26.643 --> 00:05:29.406
Et maintenant un sourire franc, 
en voilà un beau, parfait.

00:05:29.406 --> 00:05:32.066
Vous voyez, l'indicateur vert 
monte quand elle sourit.

00:05:32.066 --> 00:05:33.418
C'était un beau sourire ça.

00:05:33.418 --> 00:05:35.891
Pouvez-vous faire 
un sourire plus subtil pour voir ?

00:05:35.891 --> 00:05:37.782
Oui, le programme 
le reconnaît aussi.

00:05:37.782 --> 00:05:39.897
On a travaillé dur pour que ça marche.

00:05:39.897 --> 00:05:43.439
Là, les sourcils relevés déclenchent
l'indicateur de surprise.

00:05:43.439 --> 00:05:47.688
Le sillon des sourcils, lui, 
est l'indicateur de confusion.

00:05:47.688 --> 00:05:51.695
Froncez les sourcils. Oui, parfait.

00:05:51.695 --> 00:05:55.188
Tout ça vous montre différentes 
actions, il y en a beaucoup d'autres.

00:05:55.188 --> 00:05:57.220
C'est juste une démonstration épurée.

00:05:57.220 --> 00:06:00.368
Chaque action reconnue est 
une point de donnée émotionnelle

00:06:00.368 --> 00:06:03.707
et l'ensemble de ces données 
peut décrire différentes émotions.

00:06:03.707 --> 00:06:07.730
Sur la droite ici
regardez comme vous êtes heureuse.

00:06:07.730 --> 00:06:09.444
L'indicateur de joie se déclenche.

00:06:09.444 --> 00:06:11.371
Maintenant exprimez le dégoût.

00:06:11.371 --> 00:06:14.903
Souvenez-vous du départ 
de Zayn de One Direction.

00:06:14.903 --> 00:06:16.223
(Rires)

00:06:16.223 --> 00:06:21.495
Voilà, le nez se ride. Super.

00:06:21.495 --> 00:06:25.226
La capacité est en fait assez négative, 
vous deviez vraiment être fan !

00:06:25.226 --> 00:06:28.096
Cette jauge montre si l'expérience
est positive ou négative,

00:06:28.096 --> 00:06:30.712
la jauge d'engagement montre 
le niveau d'expression.

00:06:30.712 --> 00:06:34.126
Imaginez que Cloe ait accès direct 
à ce flux d'émotions en temps réel,

00:06:34.126 --> 00:06:36.935
elle pourrait alors le partager
avec qui elle voudrait.

00:06:36.935 --> 00:06:39.078
Merci.

00:06:39.078 --> 00:06:44.479
(Applaudissements)

00:06:45.749 --> 00:06:51.019
Jusqu'à présent nous avons accumulé 
12 milliards de ces données émotionnelles.

00:06:51.019 --> 00:06:53.730
C'est la plus grande base de données
de ce type au monde,

00:06:53.730 --> 00:06:57.023
construite à partir de 2,9 millions 
de vidéos de visages de personnes

00:06:57.023 --> 00:06:59.493
qui acceptent de partager 
leurs émotions avec nous

00:06:59.493 --> 00:07:02.398
et provenant de 75 pays différents.

00:07:02.398 --> 00:07:04.113
Et ça continue tous les jours.

00:07:04.603 --> 00:07:06.670
Ça me fascine totalement que l'on puisse

00:07:06.670 --> 00:07:09.965
à présent quantifier quelque chose
d'aussi personnel que nos émotions,

00:07:09.965 --> 00:07:12.100
et qu'on le fasse à cette échelle.

00:07:12.100 --> 00:07:14.277
Qu'a-t-on appris de tout ça
jusqu'à présent ?

00:07:15.057 --> 00:07:17.388
En ce qui concerne le genre :

00:07:17.388 --> 00:07:20.504
nos données confirment ce dont 
vous vous doutiez probablement,

00:07:20.504 --> 00:07:22.891
les femmes sont plus expressives
que les hommes.

00:07:22.891 --> 00:07:25.814
Non seulement elles sourient plus, 
mais aussi plus longtemps,

00:07:25.814 --> 00:07:28.298
et on peut maintenant vraiment 
quantifier ce à quoi

00:07:28.298 --> 00:07:30.664
les hommes et les femmes 
réagissent différemment.

00:07:30.664 --> 00:07:32.904
Pour l'influence culturelle :
aux États-Unis

00:07:32.904 --> 00:07:36.228
si les femmes sont 40% plus expressives
que les hommes, curieusement,

00:07:36.228 --> 00:07:39.753
on ne voit aucune différence
à ce niveau-là au Royaume Uni.

00:07:39.753 --> 00:07:42.259
(Rires)

00:07:43.296 --> 00:07:47.323
Pour l'âge : les personnes 
de 50 ans et plus

00:07:47.323 --> 00:07:50.759
sont 25% plus émotives que 
les personnes plus jeunes.

00:07:51.489 --> 00:07:55.751
Les femmes dans leur vingtaine sourient
beaucoup plus que les hommes du même âge,

00:07:55.751 --> 00:07:59.320
peut-être par nécessité 
pour faire des rencontres.

00:07:59.320 --> 00:08:02.207
Mais ce qui nous a surpris le plus 
dans toutes ces données,

00:08:02.207 --> 00:08:05.140
c'est que nous sommes en fait
constamment expressifs,

00:08:05.140 --> 00:08:08.243
mais lorsque nous sommes assis 
tout seuls en face de nos écrans,

00:08:08.243 --> 00:08:11.517
et pas seulement à regarder 
des vidéos de chats sur Facebook.

00:08:12.217 --> 00:08:15.027
Nous sommes expressifs 
quand on écrit un mail, un texto,

00:08:15.027 --> 00:08:17.837
quand on achète en ligne et 
même quand on paie nos impôts.

00:08:17.837 --> 00:08:20.199
Pour quoi utilise-t-on 
ces données aujourd'hui ?

00:08:20.199 --> 00:08:23.282
Ça va de comprendre comment 
nous interagissons avec les médias,

00:08:23.282 --> 00:08:25.506
les phénomènes viraux, 
les dynamiques de vote,

00:08:25.506 --> 00:08:28.886
à doter nos technologies
de capacités émotionnelles,

00:08:28.886 --> 00:08:32.527
et j'aimerais partager avec vous 
quelques exemples qui me tiennent à cœur.

00:08:33.197 --> 00:08:36.265
Des lunettes à lecture émotionnelle
peuvent aider les malvoyants

00:08:36.265 --> 00:08:39.493
à décrypter les expressions 
sur le visage des autres,

00:08:39.493 --> 00:08:43.680
et peuvent aider les personnes atteintes
d'autisme à interpréter les émotions,

00:08:43.680 --> 00:08:46.458
ce qu'elles ont beaucoup de mal à faire.

00:08:47.568 --> 00:08:50.777
Pour l'éducation, imaginez que 
les applications d'apprentissage

00:08:50.777 --> 00:08:53.587
perçoivent votre confusion 
et ralentissent,

00:08:53.587 --> 00:08:55.744
qu'elles perçoivent votre ennui 
et accélèrent

00:08:55.744 --> 00:08:58.803
tout comme un bon enseignant 
le ferait dans la salle de classe.

00:08:59.043 --> 00:09:01.644
Imaginez que votre montre 
puisse déceler votre humeur,

00:09:01.644 --> 00:09:04.267
ou que votre voiture puisse
percevoir votre fatigue,

00:09:04.267 --> 00:09:07.455
ou peut-être que votre frigo 
puisse sentir que vous êtes stressé

00:09:07.455 --> 00:09:11.091
et se verrouiller pour empêcher 
toute frénésie alimentaire. (Rires)

00:09:11.091 --> 00:09:15.668
J'apprécierais ça, oui.

00:09:15.668 --> 00:09:17.595
Que se serait-il passé si à Cambridge

00:09:17.595 --> 00:09:19.908
j'avais eu accès à ces données 
émotionnelles

00:09:19.908 --> 00:09:23.437
pour les partager tout naturellement 
avec ma famille à la maison

00:09:23.437 --> 00:09:27.408
comme si nous avions tous été 
dans la même pièce ?

00:09:27.408 --> 00:09:30.550
Je pense que d'ici cinq ans,

00:09:30.550 --> 00:09:32.887
tous nos appareils auront 
une puce émotionnelle,

00:09:32.887 --> 00:09:35.151
et on ne se souviendra même plus
du temps où,

00:09:35.151 --> 00:09:38.041
quand on fronçait les sourcils 
devant l'un d'eux,

00:09:38.041 --> 00:09:41.200
il ne nous retournait pas un, 
« hmm, ça ne t'a pas plu, hein ? »

00:09:41.200 --> 00:09:42.200
Notre plus grand défit est qu'il existe

00:09:42.200 --> 00:09:44.961
tellement d'applications 
à cette technologie.

00:09:44.961 --> 00:09:45.961
Mon équipe et moi nous rendons 
bien compte que

00:09:45.961 --> 00:09:47.864
nous ne pouvons pas
tout faire nous-même

00:09:47.864 --> 00:09:50.650
et avons donc rendu 
cette technologie publique

00:09:50.650 --> 00:09:53.474
pour que d'autres puissent
la développer et être créatifs.

00:09:53.474 --> 00:09:57.560
Nous sommes conscients
des risques potentiels

00:09:57.560 --> 00:09:59.627
et des possibilités d'abus,

00:09:59.627 --> 00:10:02.576
mais personnellement, 
après avoir passé des années à faire ça,

00:10:02.576 --> 00:10:05.548
je pense que les bénéfices 
que l'humanité peut recevoir

00:10:05.548 --> 00:10:07.823
d'une technologie 
émotionnellement intelligente

00:10:07.823 --> 00:10:11.399
dépassent de loin les risques potentiels
de mauvais usage.

00:10:11.399 --> 00:10:13.930
Je vous invite tous 
à prendre part à la discussion.

00:10:13.930 --> 00:10:16.484
Plus de gens seront au courant
de cette technologie,

00:10:16.484 --> 00:10:19.991
mieux on pourra en définir 
ensemble les termes d'usage.

00:10:21.081 --> 00:10:25.655
Alors que de plus en plus de notre vie
passe au digital, nous nous lançons

00:10:25.655 --> 00:10:29.153
dans une lutte perdue d'avance pour
restreindre notre usage d'appareils

00:10:29.153 --> 00:10:32.632
et reconquérir nos émotions.
Ce que j'essaie

00:10:32.632 --> 00:10:36.536
de faire au contraire est d'amener
nos émotions dans notre technologie

00:10:36.536 --> 00:10:38.765
et la rendre ainsi plus réactive.

00:10:38.765 --> 00:10:42.025
Je veux que ces appareils qui 
nous séparaient les uns des autres,

00:10:42.025 --> 00:10:44.347
finalement nous rapprochent.

00:10:44.347 --> 00:10:48.485
En rendant notre technologie plus humaine,
nous avons également l'opportunité

00:10:48.485 --> 00:10:51.782
de revoir la façon dont 
nous interagissons avec les machines,

00:10:51.782 --> 00:10:56.263
et par là-même la façon 
dont nous, humains,

00:10:56.263 --> 00:10:58.167
interagissons ensemble.

00:10:58.167 --> 00:10:59.097
Merci.

00:10:59.097 --> 00:11:03.640
(Applaudissements)

