WEBVTT
Kind: captions
Language: uk

00:00:00.000 --> 00:00:07.000
Перекладач: Olga Makhnyk
Утверджено: Khrystyna Romashko

00:00:12.556 --> 00:00:16.573
Наші емоції впливають на кожен аспект
нашого життя,

00:00:16.573 --> 00:00:20.149
від здоров'я і навчання, до того, як ми
ведемо справи і приймаємо рішення,

00:00:20.149 --> 00:00:21.922
великі чи малі.

00:00:22.672 --> 00:00:26.162
Наші емоції також впливають на те,
як ми налагоджуємо контакти з іншими.

00:00:27.132 --> 00:00:31.108
Ми звикли жити
в такому світі,

00:00:31.108 --> 00:00:35.427
але незважаючи на це,
наше життя стає все більше таким --

00:00:35.427 --> 00:00:38.561
це вчорашнє повідомлення
від моєї доньки --

00:00:38.561 --> 00:00:41.301
у світі, що позбавлений емоцій.

00:00:41.301 --> 00:00:43.252
Тому моє завдання - змінити це.

00:00:43.252 --> 00:00:47.343
Я хочу повернути емоції 
у наші цифрові комунікації.

00:00:48.223 --> 00:00:51.300
На цей шлях я стала 15 років тому.

00:00:51.300 --> 00:00:53.366
Я була програмістом в Єгипті,

00:00:53.366 --> 00:00:57.871
і мене якраз зарахували на докторську 
програму в Кембриджському університеті.

00:00:57.871 --> 00:00:59.984
Я зробила щось незвичне

00:00:59.984 --> 00:01:04.209
як для молодої, щойно одруженої 
єгипетської жінки-мусульманки:

00:01:05.599 --> 00:01:08.598
завдяки підтримці мого чоловіка,
який залишився в Єгипті,

00:01:08.598 --> 00:01:11.616
я спакувала речі і переїхала до Англії.

00:01:11.616 --> 00:01:14.844
В Кембриджі, за тисячі миль від дому,

00:01:14.844 --> 00:01:18.257
я усвідомила, що проводжу більше годин
за комп'ютером,

00:01:18.257 --> 00:01:20.486
ніж спілкуючись з іншими людьми.

00:01:20.486 --> 00:01:25.339
Проте, незважаючи на цю близькість, мій
комп'ютер не знав, як я почуваюся.

00:01:25.339 --> 00:01:28.550
Він не знав, чи я щаслива,

00:01:28.550 --> 00:01:31.538
чи в мене поганий день, чи я стресована,
розгублена,

00:01:31.538 --> 00:01:34.460
і це було розчаруванням.

00:01:35.600 --> 00:01:40.831
Навіть гірше: коли я розмовляла зі своїми,

00:01:41.421 --> 00:01:44.703
то відчула, що всі емоції
зникають в кіберпросторі.

00:01:44.703 --> 00:01:49.858
Я сумувала за домом, була одинокою,
і інколи навіть плакала,

00:01:49.858 --> 00:01:54.786
але все, що я могла висловити,
було ось це.

00:01:54.786 --> 00:01:56.806
(Сміх)

00:01:56.806 --> 00:02:01.780
Технології сьогодення мають багато IQ,
але не мають емоційної якості.

00:02:01.780 --> 00:02:04.956
Багато пізнавального інтелекту
та відсутність емоційного інтелекту.

00:02:04.956 --> 00:02:07.153
Це змусило мене задуматися,

00:02:07.153 --> 00:02:10.777
а що, якщо технології 
зможуть відчувати наші емоції?

00:02:10.777 --> 00:02:14.853
А що, якщо наші пристрої зможуть відчути,
як ми почуваємося і відповідно відреагувати,

00:02:14.853 --> 00:02:17.866
так, як емоційно розвинений друг?

00:02:18.666 --> 00:02:22.230
Ці питання привели мене і мою команду

00:02:22.230 --> 00:02:26.607
до створення технологій, що можуть читати
і відповідати на наші емоції,

00:02:26.607 --> 00:02:29.697
і нашою стартовою точкою 
було обличчя людини.

00:02:30.577 --> 00:02:33.750
Наше обличчя є одним з найпотужніших
каналів,

00:02:33.750 --> 00:02:37.766
який ми використовуємо, щоб висловити
соціальний та емоційний стан,

00:02:37.766 --> 00:02:40.776
все, починаючи з веселощів, здивування,

00:02:40.776 --> 00:02:44.979
співчуття і допитливості.

00:02:44.979 --> 00:02:49.907
В науці емоцій, кожен порух м'язів обличчя
ми називаємо одиницею поведінки.

00:02:49.907 --> 00:02:52.832
Наприклад, одиниця поведінки 12,

00:02:52.832 --> 00:02:54.870
це не голлівудський блокбастер,

00:02:54.870 --> 00:02:58.312
це, власне, розширення кутиків губ,
що є основним елементом усмішки.

00:02:58.312 --> 00:03:01.300
Спробуйте всі. 
Давайте посміхнемося.

00:03:01.300 --> 00:03:03.954
Інший приклад - одиниця поведінки 4,
зморшка на лобі.

00:03:03.954 --> 00:03:06.192
Це коли ви зводите брови разом

00:03:06.192 --> 00:03:08.459
і утворюються всі ці нерівності і зморшки.

00:03:08.459 --> 00:03:12.754
Ми не любимо їх, але це очевидна ознака
негативної емоції.

00:03:12.754 --> 00:03:14.960
У нас близько 45 таких одиниць поведінки,

00:03:14.960 --> 00:03:18.350
і вони, в поєднанні, можуть виразити
сотні емоцій.

00:03:18.350 --> 00:03:22.251
Навчити комп'ютер зчитувати емоції обличчя
є досить важко,

00:03:22.251 --> 00:03:25.223
оскільки ці одиниці поведінки
можуть бути швидкими, ледь помітними,

00:03:25.223 --> 00:03:27.777
і вони поєднуються в різний спосіб.

00:03:27.777 --> 00:03:31.515
Наприклад, подивимося на посмішку та
самовдоволену посмішку.

00:03:31.515 --> 00:03:35.268
Вони виглядають дещо однаково,
але означають зовсім різне.

00:03:35.268 --> 00:03:36.986
(Сміх)

00:03:36.986 --> 00:03:39.990
Посмішка є позитивною,

00:03:39.990 --> 00:03:41.260
а самовдоволена посмішка
зазвичай негативна.

00:03:41.260 --> 00:03:45.136
Іноді самовдоволена посмішка може вас
зробити відомим.

00:03:45.136 --> 00:03:47.960
Але, насправді, важливо,
щоб комп'ютер міг

00:03:47.960 --> 00:03:50.815
розрізнити ці два вирази.

00:03:50.815 --> 00:03:52.627
Отже, як ми це робимо?

00:03:52.627 --> 00:03:54.414
У нас є алгоритми

00:03:54.414 --> 00:03:58.524
десятків тисяч прикладів людей,
які посміхаються,

00:03:58.524 --> 00:04:01.589
з різних етнічних груп, різного віку
та статей,

00:04:01.589 --> 00:04:04.400
і такі ж приклади ми маємо 
для самовдоволених посмішок.

00:04:04.400 --> 00:04:05.954
Поглиблено вивчаючи

00:04:05.954 --> 00:04:08.810
алгоритм шукає всі ці
нерівності і зморшки,

00:04:08.810 --> 00:04:11.390
і зміни обрисів на нашому обличчі,

00:04:11.390 --> 00:04:14.592
і досліджує, що посмішки мають
спільні риси,

00:04:14.592 --> 00:04:17.773
а самовдоволені посмішки мають
інші риси.

00:04:17.773 --> 00:04:20.141
Наступного разу, коли він бачить
нове обличчя,

00:04:20.141 --> 00:04:22.440
він вивчає,

00:04:22.440 --> 00:04:25.473
що це обличчя має характеристики посмішки,

00:04:25.473 --> 00:04:29.751
і каже: "Ага. Я це розумію.
Це - усмішка."

00:04:30.381 --> 00:04:33.181
Щоб найкраще продемонструвати,
як працює ця технологія,

00:04:33.181 --> 00:04:35.317
зробимо це наживо.

00:04:35.317 --> 00:04:39.230
Мені потрібен волонтер,
бажано з обличчям.

00:04:39.230 --> 00:04:41.564
(Сміх)

00:04:41.564 --> 00:04:44.335
Хлоя буде нашим добровольцем.

00:04:45.325 --> 00:04:49.783
За останні 5 років ми переросли
з проекту в Массачусетському інституті

00:04:49.783 --> 00:04:50.939
в компанію,

00:04:50.939 --> 00:04:54.131
в котрій моя команда дуже старалася,
щоби ця технологія запрацювала,

00:04:54.131 --> 00:04:56.540
як ми кажемо, в диких умовах.

00:04:56.540 --> 00:04:59.210
Ми також зменшили її, щоб
ядро машини емоцій

00:04:59.210 --> 00:05:02.530
працювало на мобільних пристроях
з камерами, таких як iPad.

00:05:02.530 --> 00:05:05.316
Давайте спробуємо.

00:05:06.756 --> 00:05:10.680
Бачите, алгоритм знайшов 
обличчя Хлої,

00:05:10.680 --> 00:05:12.372
це ця біла рамка,

00:05:12.372 --> 00:05:14.943
і слідкує за основними рисами її обличчя,

00:05:14.943 --> 00:05:17.799
за бровами, очима,
ротом та носом.

00:05:17.799 --> 00:05:20.786
Питання: чи розрізнить він
її вираз обличчя?

00:05:20.786 --> 00:05:22.457
Протестуємо цю машину.

00:05:22.457 --> 00:05:26.643
Перш за все, покажи мені
"кам'яне обличчя". Так, чудово. (Сміх)

00:05:26.643 --> 00:05:29.456
Тепер, коли вона посміхається,
це справжня усмішка, чудово.

00:05:29.456 --> 00:05:31.756
Бачите, як зелене кільце піднімається,
коли вона посміхається.

00:05:31.756 --> 00:05:32.978
Це була широка посмішка.

00:05:32.978 --> 00:05:36.021
Можеш злегка посміхнутись, щоб
побачити, чи комп'ютер зрозуміє?

00:05:36.021 --> 00:05:38.352
Він розрізняє малопомітні усмішки також.

00:05:38.352 --> 00:05:40.477
Ми тяжко працювали,
щоб це вийшло.

00:05:40.477 --> 00:05:43.439
Піднята брова,
індикатор подиву.

00:05:43.439 --> 00:05:47.688
Глибока зморшка між бровами - 
індикатор збентеження.

00:05:47.688 --> 00:05:51.695
Насуплення. Ідеально.

00:05:51.695 --> 00:05:55.188
Це все різні одиниці поведінки.
Їх є значно більше.

00:05:55.188 --> 00:05:57.220
Це лише скорочене демо.

00:05:57.220 --> 00:06:00.368
Кожне впізнання емоцій ми називаємо
емоційними даними,

00:06:00.368 --> 00:06:03.337
і вони можуть, поєднуючись,
відображати різні емоції.

00:06:03.337 --> 00:06:07.990
В правій частині демо --
виглядає, що ти щаслива.

00:06:07.990 --> 00:06:09.444
Отже, це - щастя. 
Щастя підсвічується.

00:06:09.444 --> 00:06:11.371
Зараз спробуй показати огиду.

00:06:11.371 --> 00:06:15.643
Пригадай, як це - коли Зайн вийшов
з групи One Direction.

00:06:15.643 --> 00:06:17.153
(Сміх)

00:06:17.153 --> 00:06:21.495
Так, наморщи носа. Чудово.

00:06:21.495 --> 00:06:25.226
Результат доволі негативний, 
ти, мабуть, їхня велика шанувальниця.

00:06:25.226 --> 00:06:27.926
Валентність показує, наскільки
позитивним чи негативним є досвід,

00:06:27.926 --> 00:06:30.712
а вмикання кольорів, наскільки 
єкспресивною вона є.

00:06:30.712 --> 00:06:34.126
Уявімо, якби Хлоя мала доступ
до емоційного потоку онлайн,

00:06:34.126 --> 00:06:36.935
вона могла б поділитися,
з ким хотіла.

00:06:36.935 --> 00:06:39.858
Дякую.

00:06:39.858 --> 00:06:44.479
(Оплески)

00:06:45.749 --> 00:06:51.019
Зараз ми маємо 12 мільярдів 
таких емоційних даних.

00:06:51.019 --> 00:06:53.630
Це найбільша емоційна база у всьому світі.

00:06:53.630 --> 00:06:56.593
Ми зібрали її з 2,9 мільйонів відео,

00:06:56.593 --> 00:06:59.193
від людей, які погодилися 
розділити свої емоції з нами,

00:06:59.193 --> 00:07:02.398
із 75 різних країн світу.

00:07:02.398 --> 00:07:04.113
Вона збільшується щодня.

00:07:04.603 --> 00:07:06.670
Це захоплююче,

00:07:06.670 --> 00:07:09.865
як ми можемо підрахувати щось
таке особисте як емоції,

00:07:09.865 --> 00:07:12.100
і можемо це зробити за допомогою шкали.

00:07:12.100 --> 00:07:14.277
Що ми враховуємо?

00:07:15.057 --> 00:07:17.388
Стать.

00:07:17.388 --> 00:07:21.034
Наші дані підтверджують те,
що ви підозрюєте.

00:07:21.034 --> 00:07:22.891
Жінки більш експресивні, ніж чоловіки.

00:07:22.891 --> 00:07:25.574
Вони не лише посміхаються частіше,
їхня посмішка триваліша,

00:07:25.574 --> 00:07:28.478
і ми можемо справді підрахувати,
на що жінки і чоловіки

00:07:28.478 --> 00:07:30.614
реагують по-різному.

00:07:30.614 --> 00:07:32.904
Розглянемо культурний аспект: у США,

00:07:32.904 --> 00:07:36.108
жінки на 40% експресивніші за чоловіків,

00:07:36.108 --> 00:07:39.753
але цікавіше, що в Англії жодної різниці
між чоловіками і жінками.

00:07:39.753 --> 00:07:42.259
(Сміх)

00:07:43.296 --> 00:07:47.323
ВІк: люди, котрим 50 і вище

00:07:47.323 --> 00:07:50.759
на 25% емоційніші за молодших віком.

00:07:51.899 --> 00:07:55.751
ЖІнки у свої 20 посміхаються більше,
ніж чоловіки того ж віку,

00:07:55.751 --> 00:07:59.590
мабуть, просто необхідність 
для побачень.

00:07:59.590 --> 00:08:02.207
Але найбільше нас здивувало,

00:08:02.207 --> 00:08:05.410
що ми виражаємо емоції постійно,

00:08:05.410 --> 00:08:08.243
навіть тоді, коли ми наодинці
зі своїми пристроями,

00:08:08.243 --> 00:08:11.517
і це не лише тоді, коли ми довимося відео
про котів на Facebook.

00:08:12.217 --> 00:08:15.227
Ми виявляємо емоції, коли пишемо мейли,
смс чи робимо покупки онлайн,

00:08:15.227 --> 00:08:17.527
навіть, коли маємо справу з податками.

00:08:17.527 --> 00:08:19.919
Де можливо застосувати ці дані сьогодні?

00:08:19.919 --> 00:08:22.682
Для розуміння того,
як ми пов'язуємо себе з медіа,

00:08:22.682 --> 00:08:25.166
розуміння поширення веб-контенту
і поведінки вибору,

00:08:25.166 --> 00:08:27.906
а також, щоб розуміти могутню
чи емоційно адаптовану технологію.

00:08:27.906 --> 00:08:32.527
Хочу показати вам кілька прикладів,
які особливо близькі для мене.

00:08:33.197 --> 00:08:36.265
Емоційно адапотовані окуляри можуть
допомогти тим,

00:08:36.265 --> 00:08:39.493
хто погано бачить,
читати обличчя інших,

00:08:39.493 --> 00:08:43.680
і також допоможе аутистам
зрозуміти емоції,

00:08:43.680 --> 00:08:46.458
те, з чим їм дійсно важко розібратися.

00:08:47.918 --> 00:08:50.777
Щодо освіти, то уявіть, якби
ваші додатки для навчання

00:08:50.777 --> 00:08:53.587
відчували, що ви збентежені
і сповільнювалися при цьому.

00:08:53.587 --> 00:08:55.444
Або відчули, що вам нудно,
і пришвидшувалися,

00:08:55.444 --> 00:08:58.413
так само, як хороший вчитель
зробив би у класі.

00:08:59.043 --> 00:09:01.644
Якби ваш годинник відслідковував
ваш настрій,

00:09:01.644 --> 00:09:04.337
чи ваша машина відчула, що ви втомлені,

00:09:04.337 --> 00:09:06.885
чи ваш холодильник був в курсі, 
що ви переживаєте стрес,

00:09:06.885 --> 00:09:12.951
і автоматично закривався, щоб
не дозволити вам переїдати. (Сміх)

00:09:12.951 --> 00:09:15.668
Мені б таке сподобалося.

00:09:15.668 --> 00:09:17.595
Якби тоді, коли я була у Кембриджі,

00:09:17.595 --> 00:09:19.908
я мала доступ до емоційного потоку 
онлайн,

00:09:19.908 --> 00:09:23.437
і могла б поділитися всім зі своєю сім'єю
вдома у звичний спосіб,

00:09:23.437 --> 00:09:27.408
так, наче б ми сиділи всі разом
в одній кімнаті?

00:09:27.408 --> 00:09:30.550
Гадаю, що за п'ять років,

00:09:30.550 --> 00:09:32.887
всі наші пристрої матимуть емоційний чіп,

00:09:32.887 --> 00:09:36.951
і ми вже не пам'ятатимемо часи, коли
не можна було насупитися до пристрою

00:09:36.951 --> 00:09:41.200
і він нам відповів би: "Гмм, 
тобі це не подобається, чи не так?"

00:09:41.200 --> 00:09:44.961
Найбільшою трудністю є те, що ця 
технологія має багато додатків.

00:09:44.961 --> 00:09:47.864
Ми з командою усвідомили,
що не зможемо створити її самі,

00:09:47.864 --> 00:09:51.360
тому ми зробили так, щоб ця технологія стала
доступною для інших розробників

00:09:51.360 --> 00:09:53.474
і вони могли працювати,
і бути креативними.

00:09:53.474 --> 00:09:57.560
Ми також усвідомлюємо, що існують 
потенційні ризики

00:09:57.560 --> 00:09:59.627
і зловживання,

00:09:59.627 --> 00:10:02.576
але я, особисто пропрацюваваши 
багато років над цим,

00:10:02.576 --> 00:10:05.548
вірю, що користь для суспільства

00:10:05.548 --> 00:10:07.823
від емоційно спроможних технологій

00:10:07.823 --> 00:10:11.399
значно переважатиме можливе
їх зловживання.

00:10:11.399 --> 00:10:13.930
Запрошую вас усіх приєднатися 
до діалогу.

00:10:13.930 --> 00:10:16.484
Чим більшій кількості людей 
відомо про цю технологію,

00:10:16.484 --> 00:10:19.661
тим більше ми знатимемо,
як її використовувати.

00:10:21.081 --> 00:10:25.655
Так як наше життя 
стає все більш цифровим,

00:10:25.655 --> 00:10:29.153
ми залучені в битву, яку програємо, намагаючись
обмежити використання нами пристроїв,

00:10:29.153 --> 00:10:31.382
щоби повернути наші емоції.

00:10:32.622 --> 00:10:36.536
Тож я намагаюся натомість
внести емоції в наші технології

00:10:36.536 --> 00:10:38.765
і зробити їх більш чутливими.

00:10:38.765 --> 00:10:41.435
Мені б хотілося, щоб ці пристрої,
які нас роз'єднують,

00:10:41.435 --> 00:10:43.897
поєднали нас знову.

00:10:43.897 --> 00:10:48.485
Гуманізуючи технології,
ми отримуємо надзвичайну можливість

00:10:48.485 --> 00:10:51.782
переосмислити те, як ми з'єднуємося 
з машинами,

00:10:51.782 --> 00:10:56.263
і, відповідно, як ми, люди,

00:10:56.263 --> 00:10:58.167
спілкуємося один з одним.

00:10:58.167 --> 00:11:00.327
Дякую.

00:11:00.327 --> 00:11:03.640
(Оплески)

