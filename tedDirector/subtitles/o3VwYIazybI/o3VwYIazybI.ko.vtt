WEBVTT
Kind: captions
Language: ko

00:00:00.000 --> 00:00:07.000
번역: Jina Bae
검토: Jihyeon J. Kim

00:00:12.556 --> 00:00:16.573
우리의 감정들은 
삶의 모든 면에 영향을 줍니다,

00:00:16.573 --> 00:00:20.149
우리의 건강과 학습부터
사업의 방식과 의사결정까지요.

00:00:20.149 --> 00:00:21.922
큰 일이든 작은 일이든지요.

00:00:22.672 --> 00:00:26.162
또한 감정은 우리가 서로를 어떻게 
연결시키는지 영향을 주죠.

00:00:27.132 --> 00:00:31.108
우리는 이런 세상에서 
살기위해 진화해왔죠.

00:00:31.108 --> 00:00:35.027
그러나 대신에 우리는 점점 더
이런 삶 속에 살고 있습니다.

00:00:35.027 --> 00:00:38.561
어젯밤 제 딸의 문자 메세지입니다.

00:00:38.561 --> 00:00:41.301
감정이 결여된 세상이죠.

00:00:41.301 --> 00:00:43.252
저는 그것을 바꾸는 과제에 착수했어요.

00:00:43.252 --> 00:00:47.343
감정을 디지털 공간의 
경험안에 도입시키고 싶었죠.

00:00:48.223 --> 00:00:50.900
전 이걸 15년 전에 시작했어요.

00:00:50.900 --> 00:00:53.366
저는 이집트에서 컴퓨터 공학자였고

00:00:53.366 --> 00:00:57.871
막 캠브리지의 박사 학위 
과정에 입학했었습니다.

00:00:57.871 --> 00:00:59.984
그래서 저는 좀 다른 것을 했습니다.

00:00:59.984 --> 00:01:04.209
어린 신혼의 무슬림 
이집트 부인으로서요.

00:01:05.599 --> 00:01:08.598
이집트에 남아야했던 남편의 지원 덕분에

00:01:08.598 --> 00:01:11.616
저는 짐을 꾸려 영국으로 갔습니다.

00:01:11.616 --> 00:01:14.844
고향에서 수천 마일 떨어진 캠브리지에서

00:01:14.844 --> 00:01:20.377
사람들과 지내는 시간보다 많은 시간을 
노트북과 보내고 있음을 알았습니다.

00:01:20.377 --> 00:01:25.339
이런 친밀성에도 불구하고
제 노트북은 저의 감정을 알 수 없었죠.

00:01:25.339 --> 00:01:29.260
이것은 제가 행복한지, 기분이 안 좋은지,

00:01:29.260 --> 00:01:32.118
스트레스를 받는지, 혼란스러운지 
알지 못했습니다.

00:01:32.118 --> 00:01:34.460
그게 답답했어요.

00:01:35.600 --> 00:01:40.441
더 안 좋은 상황은 온라인상으로 
고향 가족들과 대화할 때

00:01:41.421 --> 00:01:44.703
제 모든 감정들이 사이버 공간에서 
사라진다고 느껴졌어요.

00:01:44.703 --> 00:01:46.878
저는 향수병을 앓았고, 외로웠으며,

00:01:46.878 --> 00:01:49.858
그리고 어떤날은 정말로 울었죠.

00:01:49.858 --> 00:01:52.516
그러나 제가 표현할 수 있는 방법은

00:01:53.586 --> 00:01:54.786
이것뿐이었습니다.

00:01:54.786 --> 00:01:56.806
(웃음)

00:01:56.806 --> 00:01:59.670
오늘날의 기술은 높은 I.Q를 
가지고 있습니다.

00:01:59.670 --> 00:02:00.980
그러나 E.Q는 없어요.

00:02:00.980 --> 00:02:04.956
인지 지능이 있으나 감성 지능은 없죠.

00:02:04.956 --> 00:02:07.153
그래서 생각하게 됐습니다.

00:02:07.153 --> 00:02:10.777
기술이 우리의 감정을 느낀다면 어떨까?

00:02:10.777 --> 00:02:14.853
장비들이 우리의 감정을 느끼고 
그에 따라 반응한다면 어떨까?

00:02:14.853 --> 00:02:17.866
감수성이 있는 친구가 
반응하듯이 말이죠.

00:02:18.806 --> 00:02:22.816
이런 의문들 때문에 저와 동료들이

00:02:22.816 --> 00:02:26.607
감정을 읽고 반응하는 
기술을 만들었습니다.

00:02:26.607 --> 00:02:29.697
우리의 시작점은 인간의 얼굴이었죠.

00:02:30.577 --> 00:02:33.750
인간의 얼굴은 하나의 강력한 경로인데

00:02:33.750 --> 00:02:37.956
사회적, 감정적 상태의 
소통을 위해 모두가 사용하죠.

00:02:37.956 --> 00:02:45.006
즐거움, 놀람, 공감과 
호기심같은 감정들입니다.

00:02:45.006 --> 00:02:49.939
감정 과학에서 각 얼굴 근육의 움직임을 
활동 단위라고 합니다.

00:02:49.939 --> 00:02:52.832
예를들어, 활동 단위 12번은

00:02:52.832 --> 00:02:54.870
이건 헐리우드 대작이 아니예요.

00:02:54.870 --> 00:02:58.312
입술의 가장자리를 당기는 것입니다.
웃음의 주요 구성 부분이죠.

00:02:58.312 --> 00:03:00.622
모두 시도해보세요. 웃어 보세요.

00:03:00.622 --> 00:03:04.141
다른 예로 활동 단위 4번은 
눈썹을 찡그리는 것입니다.

00:03:04.141 --> 00:03:07.892
당신이 두 눈썹을 함께 모을 때
이런 느낌과 주름살이 생깁니다.

00:03:07.892 --> 00:03:09.505
우리가 별로 좋아하지 않죠.

00:03:09.505 --> 00:03:12.754
그건 부정적 감정의 강한 지표입니다.

00:03:12.754 --> 00:03:14.960
약 45개의 활동 단위가 있어요.

00:03:14.960 --> 00:03:18.350
조합해서 수백개의 감정표현이 생깁니다.

00:03:18.350 --> 00:03:22.262
이런 표정을 읽도록 컴퓨터를 
가르치는 것은 힘듭니다.

00:03:22.262 --> 00:03:25.281
활동 단위들은 빠를 수도 있고, 
미묘할 수 도 있으며

00:03:25.281 --> 00:03:27.777
수 많은 방법으로 조합되기 때문입니다.

00:03:27.777 --> 00:03:31.515
예로 웃음과 억지웃음을 들어봅시다.

00:03:31.515 --> 00:03:33.480
그것들은 다소 비슷해 보이죠.

00:03:33.480 --> 00:03:35.268
그러나 매우 의미가 다릅니다.

00:03:35.268 --> 00:03:36.986
(웃음)

00:03:36.986 --> 00:03:39.430
웃음은 긍정적이고,

00:03:39.430 --> 00:03:41.260
억지웃음은 보통은 부정적입니다.

00:03:41.260 --> 00:03:45.136
가끔 억지웃음으로 
유명해질 수 있어요.

00:03:45.136 --> 00:03:50.435
농담이 아니라 컴퓨터가 두 표정의 차이를 
구별하는 것은 중요합니다.

00:03:50.435 --> 00:03:52.627
그래서 저희는 어떻게 했을까요?

00:03:52.627 --> 00:03:54.414
저희는 컴퓨터 알고리즘에

00:03:54.414 --> 00:03:58.524
십만개의 웃는 사람들 
예시를 입력했습니다.

00:03:58.524 --> 00:04:01.589
인종, 나이, 성별이 다양합니다.

00:04:01.589 --> 00:04:04.080
억지웃음도 그렇게 했습니다.

00:04:04.080 --> 00:04:05.954
딥 러닝 인공지능을 사용해서

00:04:05.954 --> 00:04:11.460
알고리즘이 느낌과 주름살, 
얼굴의 형태 변화를 찾습니다.

00:04:11.460 --> 00:04:14.620
모든 웃는 얼굴에 공통적 특징이 
있다는 것을 학습하게 됩니다.

00:04:14.620 --> 00:04:17.773
모든 억지웃음은 미묘하게 
다른 특징을 가지고 있어요.

00:04:17.773 --> 00:04:20.141
그리고나서 이것은 
새로운 얼굴을 관찰합니다.

00:04:20.141 --> 00:04:25.500
이 얼굴이 웃음과 같은 
특징을 가진다는 것을 알고

00:04:25.500 --> 00:04:29.331
말합니다."아하, 알겠습니다. 
이건 웃는 표정입니다."

00:04:30.381 --> 00:04:33.181
이 기술이 어떻게 작동하는지
보여주는 가장 좋은 방법은

00:04:33.181 --> 00:04:35.317
실제 시연을 시도하는 것이죠.

00:04:35.317 --> 00:04:36.688
저는 지원자 한 분이 필요해요.

00:04:36.688 --> 00:04:39.230
얼굴을 가진 분을 선호합니다.

00:04:39.230 --> 00:04:41.564
(웃음)

00:04:41.564 --> 00:04:44.335
클로이가 오늘 지원해줄 겁니다.

00:04:45.325 --> 00:04:46.783
지난 5년 동안, 

00:04:46.783 --> 00:04:50.943
우리는 MIT에서 연구로 시작해 
한 회사를 설립했습니다.

00:04:50.943 --> 00:04:54.131
저희 팀이 이 기술을 
실현하려고 노력하는 곳이죠.

00:04:54.131 --> 00:04:56.540
저희는 야생의 상태라고 불러요.

00:04:56.540 --> 00:04:58.350
그리고 우리는 기술을 소형화해서

00:04:58.350 --> 00:05:02.560
핵심 감정 엔진이 아이패드처럼 카메라달린 
이동식 장치에도 쓸 수 있게 했습니다.

00:05:02.560 --> 00:05:05.316
자, 시도해봅시다.

00:05:06.756 --> 00:05:07.756
여러분이 보듯이,

00:05:07.756 --> 00:05:10.680
이것은 클로이의 얼굴을 
감지하고 있습니다.

00:05:10.680 --> 00:05:12.372
여기 하얀 테두리가 있죠.

00:05:12.372 --> 00:05:14.943
이것은 그녀의 얼굴의 
눈썹, 눈, 입과 코와 같은

00:05:14.943 --> 00:05:17.799
주요 특정 부분을 추적하고 있습니다.

00:05:17.799 --> 00:05:20.786
궁금한것은 이게 그녀의 표정을 
인식할 수 있을까요?

00:05:20.786 --> 00:05:22.457
그래서 이 기계를 시험해볼거예요.

00:05:22.457 --> 00:05:26.673
먼저 무표정을 해주세요. 
좋아요, 멋지네요. (웃음)

00:05:26.673 --> 00:05:29.449
순수한 웃음이죠, 멋져요.

00:05:29.449 --> 00:05:31.782
웃을 때 녹색 막대가 
증가하는 것을 볼 수 있죠.

00:05:31.782 --> 00:05:34.587
함박웃음이었어요.
미묘한 웃음을 해보시겠어요?

00:05:34.587 --> 00:05:36.961
컴퓨터가 인식하는지 보려고요.
미묘한 웃음도 인식합니다.

00:05:36.961 --> 00:05:39.391
이것을 만들려고 정말 노력했어요.

00:05:39.391 --> 00:05:43.453
눈썹이 올라가면 놀람의 표시이죠.

00:05:43.453 --> 00:05:47.688
이마의 주름살은 혼란의 표시입니다.

00:05:47.688 --> 00:05:49.449
찡그려주세요.

00:05:49.449 --> 00:05:51.695
네, 완벽하네요.

00:05:51.695 --> 00:05:54.775
이것은 각각 다른 활동단위이고
더 많이 있습니다.

00:05:54.778 --> 00:05:57.250
이건 몇가지만 보여드린 겁니다.

00:05:57.250 --> 00:06:00.009
저희는 각각의 인식을 
감정 정보점이라고 합니다.

00:06:00.009 --> 00:06:03.339
이것이 함께 여러가지 
감정을 나타나게 합니다.

00:06:03.339 --> 00:06:07.460
오른쪽에는 당신이 행복해 보입니다.

00:06:07.460 --> 00:06:09.444
이것은 기쁨입니다.
기쁨 기능이 작동하죠.

00:06:09.444 --> 00:06:11.851
혐오하는 표정을 지어주세요.

00:06:11.851 --> 00:06:15.643
자인이 One Direction을 
탈퇴했다고 생각해보세요.

00:06:15.643 --> 00:06:16.936
(웃음)

00:06:16.936 --> 00:06:20.486
네, 코에 주름을 잡아보세요. 좋아요.

00:06:21.495 --> 00:06:25.570
유의성이 부정적이네요,
그러니까 진짜 팬이었나보네요.

00:06:25.570 --> 00:06:27.926
유의성은 한 경험이 얼마나
긍정적 또는 부정적인지 나타냅니다.

00:06:27.926 --> 00:06:30.712
참여도는 얼마나 표현력이 
있느냐를 보여줍니다.

00:06:30.712 --> 00:06:34.126
클로이가 실시간 감정 변화에 
접근할 수 있다고 상상해 보세요.

00:06:34.126 --> 00:06:36.936
그녀는 이것을 원하는 사람과 
공유할 수 있겠죠.

00:06:36.936 --> 00:06:38.508
감사합니다.

00:06:38.508 --> 00:06:44.479
(박수)

00:06:45.749 --> 00:06:51.040
지금까지 120억개의 
감정 정보점을 수집했습니다.

00:06:51.040 --> 00:06:53.460
세상에서 가장 큰 감정 데이터베이스죠.

00:06:53.460 --> 00:06:56.593
2,900만개의 
얼굴 영상에서 모았습니다.

00:06:56.593 --> 00:06:59.193
감정 공유에 동의한 분들이고

00:06:59.193 --> 00:07:02.398
세계의 75개국에서 모았습니다.

00:07:02.398 --> 00:07:04.113
이것은 매일 늘어나고 있습니다.

00:07:04.603 --> 00:07:06.670
저는 이것이 놀랍습니다.

00:07:06.670 --> 00:07:09.884
지금 우리는 감정과 같은
개인적인 것을 수량화 할 수 있는거죠.

00:07:09.884 --> 00:07:12.100
그리고 이런 규모로 할 수 있습니다.

00:07:12.100 --> 00:07:14.277
최근까지 연구한 것은 무엇일까요?

00:07:15.057 --> 00:07:17.388
성별입니다.

00:07:17.388 --> 00:07:21.068
저희 정보가 여러분이 
설마하는 것을 확인시켜 줄 겁니다.

00:07:21.068 --> 00:07:22.891
여자가 남자보다 표현력이 있습니다.

00:07:22.891 --> 00:07:25.574
더 많이 웃고 더 오래 웃어요.

00:07:25.574 --> 00:07:27.794
우리는 수량화할 수 있어요.

00:07:27.794 --> 00:07:30.614
여성과 남성이 다르게 반응하는 것을요.

00:07:30.614 --> 00:07:36.169
문화적으로는 미국에서 여성들이 
남성보다 40% 더 표현력이 좋아요.

00:07:36.169 --> 00:07:39.748
그런데 신기하게도 
영국에서는 차이가 없네요.

00:07:39.753 --> 00:07:42.259
(웃음)

00:07:43.296 --> 00:07:45.220
나이는요.

00:07:45.220 --> 00:07:50.453
50대 혹은 그 이상의 사람들이
젊은 사람들보다 25% 더 감정적입니다.

00:07:51.469 --> 00:07:55.815
20대 여성들은 또래 남성보다 
25% 더 많이 웃습니다.

00:07:55.815 --> 00:07:59.548
아마 데이트를 위해 필요한 것이겠죠.

00:07:59.548 --> 00:08:02.207
하지만 이 자료에서 놀라운 점은

00:08:02.207 --> 00:08:05.410
우리가 언제나 표현력이 
있다는 것입니다.

00:08:05.410 --> 00:08:08.243
혼자 기계 앞에 앉아 있을때도요.

00:08:08.243 --> 00:08:11.847
페이스북의 고양이 영상을 
볼 때 뿐만 아니라

00:08:11.847 --> 00:08:15.227
메일을 보낼 때, 문자를 할 때, 
그리고 온라인 쇼핑을 하거나

00:08:15.227 --> 00:08:17.527
심지어 세금을 지불할 때도 표현합니다.

00:08:17.527 --> 00:08:19.919
오늘날 이 자료가 어디에 사용될까요?

00:08:19.919 --> 00:08:22.682
우리가 매체와 소통하는 방법과

00:08:22.682 --> 00:08:25.166
대박영상 특징이나 
투표 성향을 이해하고

00:08:25.166 --> 00:08:28.544
그리고 자율권을 주거나 
감정 기능 기술을 이해하는 겁니다.

00:08:28.544 --> 00:08:32.030
제 마음에 가장 와닿는 
예를 보여드리고 싶습니다.

00:08:33.197 --> 00:08:36.265
이 감정 기능 안경은 
사람들을 돕습니다.

00:08:36.265 --> 00:08:39.522
시각기능이 약화된 사람들이
다른 이들의 감정을 읽게 해줍니다.

00:08:39.522 --> 00:08:43.690
또한 자폐증이 있는 사람이 
감정을 해석하게 해줍니다.

00:08:43.690 --> 00:08:46.458
정말로 힘들어 하는 것이지요.

00:08:47.558 --> 00:08:53.578
교육에서 학습프로그램이 당신이 
혼란스럽고 지쳐간다는 것을 감지하거나

00:08:53.587 --> 00:08:55.444
또는 지루하거나, 흥분하는 것을 
감지하는 걸 상상해 보세요.

00:08:55.444 --> 00:08:58.413
교실에서 정말 좋은 선생님이 
그러는 것처럼요.

00:08:59.043 --> 00:09:01.644
손목시계가 감정을 감지한다면 어떨까요.

00:09:01.644 --> 00:09:04.337
자동차가 여러분이 
피곤하다는 것을 안다면요.

00:09:04.337 --> 00:09:06.885
아니면 냉장고가 당신이 
스트레스를 받았다는 것을 알아서

00:09:06.885 --> 00:09:11.397
냉장고가 자동으로 잠궈서 
폭식을 막아 준다면요. (웃음)

00:09:11.403 --> 00:09:13.471
전 좋을거 같아요.

00:09:15.643 --> 00:09:17.804
제가 캠프리지에 있었을때,

00:09:17.804 --> 00:09:19.468
이 실시간 감정 흐름에 
접근할 수 있었다면 어땠을까요.

00:09:19.468 --> 00:09:21.602
고향에 가족과 공유할 수 있었을겁니다.

00:09:21.602 --> 00:09:26.707
매우 자연스럽게 
모두 같은 방에 있는 것처럼요.

00:09:27.692 --> 00:09:30.550
제 생각에 5년 후에는

00:09:30.550 --> 00:09:32.887
모든 기계들이 감정칩을 가질겁니다.

00:09:32.887 --> 00:09:37.303
이렇게 반응하는 기기가 
어땠는지 기억도 못할 겁니다.

00:09:37.303 --> 00:09:40.437
기기앞에서 그저 찌푸리지만 않고
"별로 안좋으신가봐요, 그렇죠?" 하는 겁니다.

00:09:41.200 --> 00:09:44.961
가장 큰 과제는 이 기술에 
많은 응용이 있다는 것입니다.

00:09:44.961 --> 00:09:48.269
저희 팀원들은 우리가 모든 것을 
만들 수 없다는 걸 깨달았습니다.

00:09:48.269 --> 00:09:53.490
그래서 다른 개발자들이 함께
이 기술을 사용할 수 있게 했습니다.

00:09:53.490 --> 00:09:59.650
저희는 잠재적인 위험성과 
악용의 가능성이 있음을 압니다.

00:09:59.650 --> 00:10:02.827
그러나 개인적으로 이 일에 
수년을 보낸 사람으로서

00:10:02.827 --> 00:10:07.463
감정 지능 기술이 인류에게 줄 혜택이

00:10:07.463 --> 00:10:10.759
악용의 가능성보다 
훨씬 크다고 믿습니다.

00:10:11.399 --> 00:10:13.930
여러분이 이 대화의 부분으로 
참여하도록 초대했어요.

00:10:13.930 --> 00:10:16.484
더 많은 사람들이 이 기술을 알수록

00:10:16.484 --> 00:10:20.231
어떻게 사용되는지 
더 많은 의견을 들을 수 있어요.

00:10:21.081 --> 00:10:25.655
점점 더 우리의 삶이 디지털화 되면서

00:10:25.655 --> 00:10:31.002
우리 감정을 되찾고자 기기사용을 억제하는 
승산없는 싸움을 하고 있습니다.

00:10:32.622 --> 00:10:34.000
대신에 제가 시도하는 것은

00:10:34.000 --> 00:10:36.536
감정들을 기술로 가져오는 것이에요.

00:10:36.536 --> 00:10:38.765
기술이 보다 반응할 수 있도록 만들죠.

00:10:38.765 --> 00:10:41.435
우리를 갈라놓은 기계들이

00:10:41.435 --> 00:10:43.897
우리를 재화합할 수 있게 하고 싶어요.

00:10:43.897 --> 00:10:45.790
기술을 인간적이게 만들어서

00:10:45.790 --> 00:10:48.485
우리는 최고의 기회를 얻었죠.

00:10:48.485 --> 00:10:51.763
어떻게 우리가 기계들과 
소통하는지 재고하는 겁니다.

00:10:51.763 --> 00:10:58.173
따라서 우리 인간이 다른 이들과 
소통하는 방법도 재고하는 겁니다.

00:10:58.173 --> 00:10:59.654
감사합니다.

00:10:59.654 --> 00:11:02.604
(박수)

