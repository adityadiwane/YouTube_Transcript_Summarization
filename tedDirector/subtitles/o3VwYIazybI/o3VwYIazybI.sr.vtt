WEBVTT
Kind: captions
Language: sr

00:00:00.000 --> 00:00:07.000
Prevodilac: Marija Kojić
Lektor: Tijana Mihajlović

00:00:12.556 --> 00:00:16.463
Naše emocije utiču
na svaki aspekt naših života,

00:00:16.463 --> 00:00:18.053
od našeg zdravlja i načina učenja

00:00:18.053 --> 00:00:20.229
do načina obavljanja posla
i donošenja odluka,

00:00:20.229 --> 00:00:22.462
bile one velike ili male.

00:00:22.462 --> 00:00:26.262
Naše emocije takođe utiču na to
kako se povezujemo jedni sa drugima.

00:00:27.192 --> 00:00:31.108
Razvili smo se za život
u svetu kao što je ovaj,

00:00:31.108 --> 00:00:35.267
ali umesto toga,
živimo sve više naše živote ovako -

00:00:35.267 --> 00:00:39.011
ovo je SMS poruka
koju mi je ćerka poslala sinoć -

00:00:39.011 --> 00:00:41.301
u svetu koji je lišen emocija.

00:00:41.301 --> 00:00:43.252
Tako sam na misiji to da promenim.

00:00:43.252 --> 00:00:46.783
Želim da vratim emocije
u naše digitalno iskustvo.

00:00:48.223 --> 00:00:50.970
Krenula sam ovim putem pre 15 godina.

00:00:50.970 --> 00:00:53.516
Bila sam kompjuterski naučnik u Egiptu

00:00:53.516 --> 00:00:55.031
i samo što su me primili

00:00:55.031 --> 00:00:57.751
na doktorski program
na univerzitetu u Kembridžu.

00:00:57.751 --> 00:00:59.984
Tako sam uradila nešto prilično neobično

00:00:59.984 --> 00:01:03.489
za jednu mladu, tek venčanu ženu
koja je muslimanska Egipćanka:

00:01:03.489 --> 00:01:05.779
(Smeh)

00:01:05.779 --> 00:01:08.598
uz podršku mog muža
koji je morao da ostane u Egiptu,

00:01:08.598 --> 00:01:11.616
spakovala sam kofere
i preselila se u Englesku.

00:01:11.616 --> 00:01:14.764
Na Kembridžu, kilometrima daleko od kuće,

00:01:14.764 --> 00:01:17.837
shvatila sam da više vremena
provodim sa laptopom

00:01:17.837 --> 00:01:20.486
nego sa bilo kojim drugim ljudskim bićem.

00:01:20.486 --> 00:01:25.339
Ipak, i pored ove prisnosti, moj laptop
nije imao pojma kako se osećam.

00:01:25.339 --> 00:01:28.550
Nije imao pojma da li sam srećna,

00:01:28.550 --> 00:01:31.538
da li sam imala loš dan,
da li sam pod stresom, zbunjena,

00:01:31.538 --> 00:01:34.460
tako da je to postalo frustrirajuće.

00:01:35.520 --> 00:01:39.811
Još gore, dok sam komunicirala
sa porodicom kod kuće preko mreže,

00:01:41.001 --> 00:01:44.703
osećala sam da sve moje emocije
nestaju u sajber prostoru.

00:01:44.703 --> 00:01:49.858
Nedostajala mi je kuća, bila sam usamljena
i nekih dana sam zapravo i plakala,

00:01:49.858 --> 00:01:54.786
ali sve što sam imala
da iskažem ove emocije bilo je ovo.

00:01:54.786 --> 00:01:56.806
(Smeh)

00:01:56.806 --> 00:02:00.980
Današnja tehnologija ima 
mnogo IQ-a, ali nema EQ;

00:02:00.980 --> 00:02:04.956
mnogo kognitivne inteligencije,
ali nimalo emocionalne inteligencije,

00:02:04.956 --> 00:02:07.153
te me je to nagnalo na razmišljanje.

00:02:07.153 --> 00:02:10.887
Šta ako bi naša tehnologija mogla
da oseti naše emocije?

00:02:10.887 --> 00:02:14.823
Šta ako bi uređaji mogli
da prepoznaju i reaguju na naša osećanja,

00:02:14.823 --> 00:02:18.666
baš kao što bi reagovao
i emocionalno inteligentan prijatelj?

00:02:18.666 --> 00:02:23.470
Ta pitanja su navela mene i moj tim
da napravimo tehnologiju

00:02:23.470 --> 00:02:26.607
koja može da čita
i reaguje na naše emocije,

00:02:26.607 --> 00:02:29.697
a naša početna tačka bilo je ljudsko lice.

00:02:30.577 --> 00:02:33.750
Dakle, ljudsko lice
je jedno od najmoćnijih kanala

00:02:33.750 --> 00:02:37.766
koje koristimo da prenesemo
društvena i emocionalna stanja,

00:02:37.766 --> 00:02:41.256
sve od zadovoljstva, iznenađenja,

00:02:41.256 --> 00:02:44.979
empatije do radoznalosti.

00:02:44.979 --> 00:02:46.107
U nauci o emocijama,

00:02:46.107 --> 00:02:49.907
sve pokrete facijalnih mišića
nazivamo akcijskim jedinicama.

00:02:49.907 --> 00:02:54.722
Tako, na primer, akcijska jedinica 12
nije holivudski blokbaster,

00:02:54.722 --> 00:02:58.122
nego se radi o podizanju ugla usana,
što je glavna komponenta osmeha.

00:02:58.122 --> 00:03:01.010
Probajte to. Hajde da svi nabacimo osmehe.

00:03:01.010 --> 00:03:03.884
Još jedan primer je akcijska jedinica 4.
To je boranje obrve.

00:03:03.884 --> 00:03:07.762
To je kada skupite obrve
i stvorite sve ove teksture i bore.

00:03:07.762 --> 00:03:11.774
Ne volimo ih, ali one su jasan pokazatelj
neke negativne emocije.

00:03:11.774 --> 00:03:14.250
Tako imamo oko 45 ovih akcijskih jedinica

00:03:14.250 --> 00:03:18.240
i one se kombinuju
da izraze stotine emocija.

00:03:18.240 --> 00:03:22.251
Podučavanje kompjutera
da čita ove facijalne emocije je teško

00:03:22.251 --> 00:03:25.223
zato što ove akcijske jedinice
mogu biti brze, suptilne

00:03:25.223 --> 00:03:27.587
i kombinuju se na mnogo različitih načina.

00:03:27.587 --> 00:03:31.515
Uzmite tako, na primer,
osmeh i zloban osmeh.

00:03:31.515 --> 00:03:35.048
Izgledaju pomalo slično
ali imaju veoma različita značenja.

00:03:35.048 --> 00:03:36.986
(Smeh)

00:03:36.986 --> 00:03:39.250
Dakle, osmeh je pozitivan,

00:03:39.250 --> 00:03:40.920
a zloban osmeh je često negativan.

00:03:40.920 --> 00:03:45.136
Ponekad jedan zloban osmeh može
da vas napravi poznatim.

00:03:45.136 --> 00:03:47.960
Ozbiljno, važno je
da kompjuter bude u stanju

00:03:47.960 --> 00:03:50.505
da prepozna razliku između
ova dva izraza.

00:03:50.505 --> 00:03:52.297
Dakle, kako to postižemo?

00:03:52.297 --> 00:03:54.154
Obezbeđujemo svojim algoritmima

00:03:54.154 --> 00:03:58.524
desetine hiljada primera ljudi
za koje znamo da se osmehuju,

00:03:58.524 --> 00:04:01.589
ljudi različitih etničkih pripadnosti, 
godina, različitog pola,

00:04:01.589 --> 00:04:04.040
a to isto činimo za podsmehe.

00:04:04.040 --> 00:04:05.954
Onda, uz dubinski pristup učenju,

00:04:05.954 --> 00:04:08.810
algoritam traži sve ove teksture i bore

00:04:08.810 --> 00:04:11.270
i promene oblika na našim licima,

00:04:11.270 --> 00:04:14.592
i u suštini uči da svi osmesi imaju
zajedničke osobine,

00:04:14.592 --> 00:04:17.773
da se svi zlobni osmesi suptilno razlikuju
od osmeha po osobinama.

00:04:17.773 --> 00:04:20.141
I sledeći put kada vidi novo lice,

00:04:20.141 --> 00:04:25.490
u suštini uči da ovo lice ima
iste osobine osmeha

00:04:25.490 --> 00:04:28.891
i kaže „Aha, prepoznajem ovo.
Ovo je izraz osmeha.”

00:04:30.381 --> 00:04:33.181
Najbolji način da pokažemo
kako ova tehnologija funkcioniše

00:04:33.181 --> 00:04:36.747
jeste da probamo demo-verziju uživo,
tako da mi treba dobrovoljac.

00:04:36.747 --> 00:04:38.650
Poželjno je da taj neko ima lice.

00:04:38.650 --> 00:04:41.564
(Smeh)

00:04:41.564 --> 00:04:44.335
Kloi će nam danas biti dobrovoljac.

00:04:45.325 --> 00:04:49.783
Dakle, u zadnjih pet godina,
od istraživačkog projekta na MIT-u

00:04:49.783 --> 00:04:50.891
postali smo kompanija,

00:04:50.891 --> 00:04:53.970
u kojoj je moj tim vredno radio
da ova tehnologija uspe,

00:04:53.970 --> 00:04:56.030
kako mi volimo da kažemo, u divljini.

00:04:56.030 --> 00:04:58.920
Takođe smo je smanjili
tako da osnovni emotivni motor

00:04:58.920 --> 00:05:02.520
radi na bilo kom mobilnom uređaju
koji ima kameru, kao što je ovaj Ajped.

00:05:02.520 --> 00:05:05.236
Dakle, hajde da probamo.

00:05:06.746 --> 00:05:10.730
Kao što možete da vidite, 
algoritam je pronašao Kloino lice.

00:05:10.730 --> 00:05:12.372
To je ovaj beli granični okvir,

00:05:12.372 --> 00:05:14.943
koji prati glavne tačke odlika
na njenom licu,

00:05:14.943 --> 00:05:17.799
dakle, njene obrve, njene oči,
njena usta i njen nos.

00:05:17.799 --> 00:05:20.366
Pitanje je, da li može prepoznati
njen izraz lica?

00:05:20.366 --> 00:05:21.827
Dakle, testiraćemo mašinu.

00:05:21.827 --> 00:05:24.933
Pre svega, da vidimo tvoje
pokeraško lice. Da, super.

00:05:24.933 --> 00:05:26.843
(Smeh)

00:05:26.843 --> 00:05:29.296
Onda, kada se osmehne,
ovo je iskren osmeh, odlično.

00:05:29.296 --> 00:05:31.586
Vidite da se zelena traka
puni kada se osmehuje.

00:05:31.586 --> 00:05:32.638
To je bio širok osmeh.

00:05:32.638 --> 00:05:35.681
A jedan suptilan osmeh da vidimo
da li kompjuter ume da prepozna?

00:05:35.681 --> 00:05:37.342
Prepoznaje i suptilne osmehe.

00:05:37.342 --> 00:05:39.707
Vredno smo radili da ovo ostvarimo.

00:05:39.707 --> 00:05:43.299
Zatim podignute obrve,
pokazatelj iznenađenja.

00:05:43.299 --> 00:05:47.688
Boranje obrva,
što je pokazatelj zbunjenosti.

00:05:47.688 --> 00:05:51.695
Mrštenje. Da, savršeno.

00:05:51.695 --> 00:05:54.648
Ovo su različite akcijske jedinice.
Postoji ih još mnogo više.

00:05:54.648 --> 00:05:57.050
Ovo je samo skraćena demo verzija.

00:05:57.050 --> 00:06:00.368
Svako čitanje nazivamo
tačkom emotivnih podataka

00:06:00.368 --> 00:06:03.337
i one mogu zajedno da rade
da iskažu različite emocije.

00:06:03.337 --> 00:06:07.230
Dakle, na desnoj strani demo verzije -
izgledaj kao da si srećna.

00:06:07.230 --> 00:06:09.444
Dakle, to je radost. Radost se povećava.

00:06:09.444 --> 00:06:11.251
Sad mi pokaži izraz gađenja.

00:06:11.251 --> 00:06:14.973
Pokušaj da se setiš kako si se osećala 
kada je Zejn napustio „One Direction".

00:06:14.973 --> 00:06:16.003
(Smeh)

00:06:16.003 --> 00:06:19.511
Da, naboraj nos. Super.

00:06:21.495 --> 00:06:25.016
Valenca je stvarno krajnje negativna,
tako da mora da si bila veliki fan.

00:06:25.016 --> 00:06:27.926
Valenca označava koliko je
iskustvo pozitivno ili negativno,

00:06:27.926 --> 00:06:30.712
a angažman je taj koji označava 
koliko je ona ekspresivna.

00:06:30.712 --> 00:06:34.126
Zamislite da Kloi ima pristup
ovom emotivnom prenosu u realnom vremenu

00:06:34.126 --> 00:06:36.935
i da može da ga podeli sa kim god želi.

00:06:36.935 --> 00:06:38.208
Hvala ti.

00:06:38.208 --> 00:06:41.599
(Aplauz)

00:06:45.749 --> 00:06:50.739
Dakle, do sada smo nagomilali 12 milijardi
ovih tačaka emotivnih podataka.

00:06:50.739 --> 00:06:53.440
To je najveća baza emocija u svetu.

00:06:53.440 --> 00:06:56.593
Sakupili smo je
kroz 2,9 miliona klipova lica,

00:06:56.593 --> 00:06:59.193
ljudi koji su pristali da podele
svoje emocije sa nama,

00:06:59.193 --> 00:07:02.398
a to iz 75 zemalja širom sveta.

00:07:02.398 --> 00:07:04.113
Broj svaki dan raste.

00:07:04.603 --> 00:07:06.330
Raspamećuje me

00:07:06.330 --> 00:07:09.865
to da sada možemo odrediti količinu
nečega tako ličnog kao što su emocije

00:07:09.865 --> 00:07:12.100
i da to možemo obaviti na ovom nivou.

00:07:12.100 --> 00:07:14.277
Dakle, šta smo naučili do sada?

00:07:15.057 --> 00:07:16.268
Pol.

00:07:17.248 --> 00:07:21.034
Naši podaci potvrđuju ono
što možda pretpostavljate.

00:07:21.034 --> 00:07:22.891
Žene su eskpresivnije od muškaraca.

00:07:22.891 --> 00:07:25.574
Ne samo da se više osmehuju,
njihovi osmesi traju duže.

00:07:25.574 --> 00:07:28.478
Sada stvarno možemo odrediti
šta je to na šta muškarci i žene

00:07:28.478 --> 00:07:30.614
reaguju drugačije.

00:07:30.614 --> 00:07:32.954
Pozabavimo se kulturom.
U Sjedinjenim Državama,

00:07:32.954 --> 00:07:36.108
žene su 40% ekspresivnije od muškaraca,

00:07:36.108 --> 00:07:39.753
ali neobično je to da nema razlike
u UK između muškaraca i žena.

00:07:39.753 --> 00:07:42.259
(Smeh)

00:07:43.296 --> 00:07:47.323
Godine. Ljudi koji imaju 
50 godina ili stariji od toga

00:07:47.323 --> 00:07:50.759
su 25% emotivniji od mlađih ljudi.

00:07:51.469 --> 00:07:55.681
Žene u dvadesetima osmehuju se
mnogo više od muškaraca istih godina,

00:07:55.681 --> 00:07:58.560
što je možda neophodno pri zabavljanju.

00:07:59.590 --> 00:08:02.077
Ipak, možda najveće iznenađenje
u vezi ovih podataka

00:08:02.077 --> 00:08:05.230
je to da smo stalno izražajni,

00:08:05.230 --> 00:08:08.243
čak i kada sedimo sami
ispred naših uređaja,

00:08:08.243 --> 00:08:11.517
i to ne samo kada gledamo 
klipove sa mačkama na Fejbuku.

00:08:12.217 --> 00:08:15.227
Izražajni smo kada šaljemo i-mejlove,
SMS-ove, kupujemo onlajn,

00:08:15.227 --> 00:08:17.527
čak i kada obrađujemo porez.

00:08:17.527 --> 00:08:19.919
Gde se ovi podaci koriste danas?

00:08:19.919 --> 00:08:22.682
Kada treba da razumemo
kako da se angažujemo na mrežama,

00:08:22.682 --> 00:08:25.166
da razumemo viralnost
i ponašanja pri glasanju,

00:08:25.166 --> 00:08:28.436
kao i da razumemo tehnologije
koje osnažuju i omogućuju emocije.

00:08:28.436 --> 00:08:32.527
Želim takođe da podelim
i primere koji su mi posebno dragi.

00:08:33.197 --> 00:08:36.265
Naočare koje omogućuju emocije
mogu da pomognu pojedincima

00:08:36.265 --> 00:08:39.493
koji imaju oštećen vid
da čitaju lica drugih ljudi

00:08:39.493 --> 00:08:43.030
i mogu da pomognu pojedincima
sa autizmom da protumače emocije,

00:08:43.030 --> 00:08:45.658
nešto sa čim stvarno imaju problema.

00:08:47.678 --> 00:08:50.777
U obrazovanju, zamislite
kada bi vaše aplikacije za učenje

00:08:50.777 --> 00:08:53.587
mogle da osete kada ste zbunjeni i uspore,

00:08:53.587 --> 00:08:55.324
ili kada vam je dosadno i ubrzaju,

00:08:55.324 --> 00:08:57.793
kao što bi dobar profesor
uradio u učionici.

00:08:58.673 --> 00:09:01.784
Šta bi bilo ako bi vaš ručni sat
mogao da prati vaše raspoloženje,

00:09:01.784 --> 00:09:04.337
ili kada bi vaš auto mogao
da oseti kada ste umorni,

00:09:04.337 --> 00:09:06.885
ili kada bi vaš frižider
znao kada ste pod stresom,

00:09:06.885 --> 00:09:11.071
pa se automatski zatvori
da vas spreči da se opsesivno prejedate?

00:09:11.071 --> 00:09:12.498
Da, i ja bih to volela.

00:09:12.498 --> 00:09:13.858
(Smeh)

00:09:15.668 --> 00:09:17.385
Šta bi bilo da sam na Kembridžu

00:09:17.385 --> 00:09:19.968
imala pristup svom emotivnom prenosu
u realnom vremenu,

00:09:19.968 --> 00:09:23.487
da sam mogla da ga podelim to
sa porodicom kod kuće na prirodan način,

00:09:23.497 --> 00:09:27.408
kao što bih uradila
da smo svi u istoj sobi zajedno?

00:09:27.408 --> 00:09:30.230
Mislim da će kroz pet godina,

00:09:30.230 --> 00:09:32.887
svi naši uređaji imati emotivni čip

00:09:32.887 --> 00:09:34.741
i nećemo se sećati kako je bilo

00:09:34.741 --> 00:09:37.091
kada nismo mogli
samo da se namrštimo uređajima,

00:09:37.091 --> 00:09:40.370
a da oni ne kažu:
„Hmm, to ti se nije baš svidelo, zar ne?”

00:09:41.200 --> 00:09:44.801
Naš najveći izazov je 
veliki broj korisnika ove tehnologije.

00:09:44.801 --> 00:09:47.864
Moj tim i ja smo shvatili
da je ne možemo napraviti sami,

00:09:47.864 --> 00:09:51.190
pa smo ovu tehnologiju učinili dostupnom
tako da i drugi programeri

00:09:51.190 --> 00:09:53.594
mogu da počnu sa građenjem
i iskažu kreativnost.

00:09:53.594 --> 00:09:57.560
Razumemo da su mogući i rizici

00:09:57.560 --> 00:09:59.627
i da je moguća zloupotreba,

00:09:59.627 --> 00:10:02.476
ali, budući da sam mnogo godina
provela u radu na ovome,

00:10:02.476 --> 00:10:04.758
verujem da su prednosti čovečanstva

00:10:04.758 --> 00:10:07.503
sa emocionalno inteligentnom tehnologijom

00:10:07.503 --> 00:10:11.079
važnije od moguće zloupotrebe.

00:10:11.079 --> 00:10:13.930
Pozivam vas sve da budete deo te rasprave.

00:10:13.930 --> 00:10:16.484
Što više ljudi zna za ovu tehnologiju,

00:10:16.484 --> 00:10:19.661
to će više nas imati pravo
da odlučuje kako će se ona koristiti.

00:10:21.081 --> 00:10:25.655
Dakle, kako naši životi postaju
sve više i više digitalni,

00:10:25.655 --> 00:10:29.153
sve više gubimo bitku u pokušaju
da smanjimo korišćenje ovih uređaja

00:10:29.153 --> 00:10:31.382
da bismo povratili naše emocije.

00:10:32.482 --> 00:10:36.536
Dakle, ono što ja pokušavam umesto toga
je da uvedem emocije u našu tehnologiju

00:10:36.536 --> 00:10:38.765
da bi tehnologija bila prijemčivija.

00:10:38.765 --> 00:10:43.045
Dakle, želim da nas ovi uređaji 
koji su nas rastavili ponovo spoje.

00:10:44.137 --> 00:10:48.485
Kada damo ljudska svojstva tehnologiji,
dobijamo zlatnu priliku

00:10:48.485 --> 00:10:52.062
da obnovimo način
na koji se povezujemo sa mašinama

00:10:52.062 --> 00:10:56.013
i stoga, kako se mi, kao ljudska bića,

00:10:56.013 --> 00:10:58.167
povezujemo jedni sa drugima.

00:10:58.167 --> 00:10:58.887
Hvala vam.

00:10:58.887 --> 00:11:02.074
(Aplauz)

