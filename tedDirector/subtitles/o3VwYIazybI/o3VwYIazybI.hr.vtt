WEBVTT
Kind: captions
Language: hr

00:00:00.000 --> 00:00:07.000
Prevoditelj: Anja Kolobarić
Recezent: Vanja Kovac

00:00:12.556 --> 00:00:16.573
Naše emocije utječu
na svako područje naših života,

00:00:16.573 --> 00:00:20.149
od zdravlja i načina na koji učimo
do toga kako radimo i donosimo odluke,

00:00:20.149 --> 00:00:21.922
bile one velike ili male.

00:00:22.672 --> 00:00:26.162
Naše emocije također utječu
na način na koji se povezujemo s drugima.

00:00:27.132 --> 00:00:31.108
Razvili smo se za život u ovakvom svijetu,

00:00:31.108 --> 00:00:35.427
no umjesto toga
sve više i više živimo ovako -

00:00:35.427 --> 00:00:38.561
ovo je sinoćnji SMS moje kćeri -

00:00:38.561 --> 00:00:41.301
u svijetu lišenom emocija.

00:00:41.301 --> 00:00:43.252
Ja to želim promijeniti.

00:00:43.252 --> 00:00:47.343
Želim vratiti emocije u digitalni svijet.

00:00:48.223 --> 00:00:51.300
U to sam se upustila prije 15 godina.

00:00:51.300 --> 00:00:53.366
Bila sam računalna znanstvenica u Egiptu

00:00:53.366 --> 00:00:57.871
i bila sam primljena na doktorski studij
na sveučilištu u Cambridgeu.

00:00:57.871 --> 00:00:59.984
Učinila sam nešto prilično neuobičajeno

00:00:59.984 --> 00:01:04.209
za egipatsku muslimansku mladenku:

00:01:05.599 --> 00:01:08.598
uz potporu supruga koji je ostao u Egiptu,

00:01:08.598 --> 00:01:11.616
spakirala sam kofere
i preselila u Englesku.

00:01:11.616 --> 00:01:14.844
Na Cambridgeu, kilometrima daleko od kuće,

00:01:14.844 --> 00:01:18.257
shvatila sam da više vremena
provodim s laptopom

00:01:18.257 --> 00:01:20.486
nego s bilo kojim drugim ljudskim bićem.

00:01:20.486 --> 00:01:25.339
Unatoč ovoj intimnosti moj laptop
nije imao pojma kako se ja osjećam.

00:01:25.339 --> 00:01:28.550
Nije znao jesam li sretna,

00:01:28.550 --> 00:01:31.538
tužna, pod stresom, zbunjena,

00:01:31.538 --> 00:01:34.460
što je postalo frustrirajuće.

00:01:35.600 --> 00:01:40.831
Tim više, dok sam
online kontaktirala s obitelji,

00:01:41.421 --> 00:01:44.703
osjećala sam kako sve moje emocije
nestaju u cyber-prostoru.

00:01:44.703 --> 00:01:49.858
Nedostajala mi je kuća, bila sam usamljena,
a nekada sam znala čak i zaplakati,

00:01:49.858 --> 00:01:54.786
ali svoje sam emocije
mogla prenijeti samo ovako.

00:01:54.786 --> 00:01:56.806
(Smijeh)

00:01:56.806 --> 00:02:01.780
Suvremena tehnologija
ima puno IQ-a, a ništa EQ-a,

00:02:01.780 --> 00:02:04.956
puno kognitivne inteligencije,
ništa emocionalne inteligencije,

00:02:04.956 --> 00:02:07.153
što mi je dalo na razmišljanje -

00:02:07.153 --> 00:02:10.777
što kad bi naša tehnologija
mogla osjetiti naše emocije?

00:02:10.777 --> 00:02:14.853
Što kad bi sve naprave mogle osjetiti
naše raspoloženje i reagirati na njih

00:02:14.853 --> 00:02:17.866
onako kako bi to napravio 
emocionalno inteligentan prijatelj.

00:02:18.666 --> 00:02:22.230
Ta su pitanja mene i moj tim naveli

00:02:22.230 --> 00:02:26.607
na razvijanje tehnologije koja
očitava i odgovara na naše emocije,

00:02:26.607 --> 00:02:29.697
a početna točka bilo nam je ljudsko lice.

00:02:30.577 --> 00:02:33.750
Ljudsko lice jedno je
od najmoćnijih kanala

00:02:33.750 --> 00:02:37.766
za prijenos društvenih
i emocionalnih stanja,

00:02:37.766 --> 00:02:40.776
sve od užitka, iznenađenja,

00:02:40.776 --> 00:02:44.979
empatije i znatiželje.

00:02:44.979 --> 00:02:49.907
U znanosti emocija svaki je pokret
facijalnih mišića akcijska jedinica.

00:02:49.907 --> 00:02:52.832
Npr. akcijska jedinica 12,

00:02:52.832 --> 00:02:54.870
nije to holivudski blockbuster,

00:02:54.870 --> 00:02:58.312
nego se radi o podizanju kuta usnice,
što je osnovna sastavnica osmijeha.

00:02:58.312 --> 00:03:01.300
Probajte. Da vidimo te osmijehe.

00:03:01.300 --> 00:03:03.954
Drugi je primjer akcijska jedinica 4:
boranje obrva.

00:03:03.954 --> 00:03:06.192
To je kada skupite obrve

00:03:06.192 --> 00:03:08.459
čime stvarate ovakve teksture i bore.

00:03:08.459 --> 00:03:12.754
Ne volimo ih, ali snažan su
pokazatelj negativnih emocija.

00:03:12.754 --> 00:03:14.960
Imamo oko 45 ovakvih akcijskih jedinica

00:03:14.960 --> 00:03:18.350
koje se kombiniraju 
kako bi izrazile stotine emocija.

00:03:18.350 --> 00:03:22.251
Teško je naučiti računalo da ih očitava

00:03:22.251 --> 00:03:25.223
jer mogu biti brze, suptilne su

00:03:25.223 --> 00:03:27.777
i mogu se kombinirati na različite načine.

00:03:27.777 --> 00:03:31.515
Npr. smijeh i podsmijeh.

00:03:31.515 --> 00:03:35.268
Izgledaju koliko-toliko slično,
ali znače različite stvari.

00:03:35.268 --> 00:03:36.986
(Smijeh)

00:03:36.986 --> 00:03:39.990
Osmijeh je pozitivan,

00:03:39.990 --> 00:03:41.260
a podsmijeh negativan.

00:03:41.260 --> 00:03:45.136
Nekad vas podsmijeh može proslaviti.

00:03:45.136 --> 00:03:47.960
No ozbiljno, za računalo je važno da može

00:03:47.960 --> 00:03:50.815
razlikovati ova dva izraza.

00:03:50.815 --> 00:03:52.627
Kako da to izvedemo?

00:03:52.627 --> 00:03:54.414
Tako da algoritmima damo

00:03:54.414 --> 00:03:58.524
desetke tisuća primjera osmijeha ljudi

00:03:58.524 --> 00:04:01.589
različitih nacionalnosti, dobi, spolova,

00:04:01.589 --> 00:04:04.400
a isto to učinimo i za podsmijehe.

00:04:04.400 --> 00:04:05.954
Zatim koristeći dubinsko učenje,

00:04:05.954 --> 00:04:08.810
algoritam traži sve te teksture i bore

00:04:08.810 --> 00:04:11.390
i promjene oblika lica

00:04:11.390 --> 00:04:14.592
te nauči da svi osmjesi
imaju zajedničke karakteristike,

00:04:14.592 --> 00:04:17.773
a svi podsmjesi neznatno
različite karakteristike.

00:04:17.773 --> 00:04:20.141
Sljedeći put kad ugleda novo lice,

00:04:20.141 --> 00:04:22.440
nauči da

00:04:22.440 --> 00:04:25.473
to lice ima iste karakteristike osmijeha

00:04:25.473 --> 00:04:29.751
pa kaže: "Aha, znam što je to - osmijeh."

00:04:30.381 --> 00:04:33.181
Najbolji način demonstracije
funkcioniranja ove tehnologije

00:04:33.181 --> 00:04:35.317
jest demonstracija uživo.

00:04:35.317 --> 00:04:39.230
Trebat će mi dobrovoljac,
po mogućnosti netko s licem.

00:04:39.230 --> 00:04:41.564
(Smijeh)

00:04:41.564 --> 00:04:44.335
Cloe će biti naša dobrovoljka.

00:04:45.325 --> 00:04:49.783
Tijekom zadnjih pet godina
iz istraživačkog projekta na MIT-u

00:04:49.783 --> 00:04:50.939
prerasli smo u tvrtku

00:04:50.939 --> 00:04:54.131
koja naporno radi da omogući
funkcioniranje ove tehnologije,

00:04:54.131 --> 00:04:56.540
kako mi to nazivamo, u divljini.

00:04:56.540 --> 00:04:59.210
Smanjili smo je tako da
ključni motor za emocije

00:04:59.210 --> 00:05:02.530
radi na bilo kakvom uređaju
s kamerom, poput ovog iPada.

00:05:02.530 --> 00:05:05.316
Isprobajmo ga.

00:05:06.756 --> 00:05:10.680
Kao što možete vidjeti,
algoritam je prepoznao Chloeino lice

00:05:10.680 --> 00:05:12.372
vidljivo u ovoj bijeloj kutijici

00:05:12.372 --> 00:05:14.943
i prati njezine glavne crte lica,

00:05:14.943 --> 00:05:17.799
dakle obrve, oči, usta i nos.

00:05:17.799 --> 00:05:20.786
Pitanje glasi: prepoznaje li izraz lica?

00:05:20.786 --> 00:05:22.457
Testirat ćemo uređaj.

00:05:22.457 --> 00:05:26.643
Prvo mi pokaži pokerašku facu.
Odlično. (Smijeh)

00:05:26.643 --> 00:05:29.456
I onda kako se smije,
ovo je iskren osmijeh, sjajno.

00:05:29.456 --> 00:05:31.756
Zelena se pokazatelj
povećava kako se smije.

00:05:31.756 --> 00:05:32.978
To je bio veliki osmijeh.

00:05:32.978 --> 00:05:36.021
Sad probaj nešto manje očito
da vidimo hoće li ga prepoznati.

00:05:36.021 --> 00:05:38.352
Prepoznaje i manje očite osmjehe.

00:05:38.352 --> 00:05:40.477
Naporno smo radili da to postignemo.

00:05:40.477 --> 00:05:43.439
Zatim podignute obrve,
pokazatelj iznenađenja.

00:05:43.439 --> 00:05:47.688
Naborane obrve, pokazatelj zbunjenosti.

00:05:47.688 --> 00:05:51.695
Namrgodi se. Tako, savršeno.

00:05:51.695 --> 00:05:55.188
To su sve različite akcijske jedinice,
a ima ih još jako puno.

00:05:55.188 --> 00:05:57.220
Ovo je samo osnovna demonstracija.

00:05:57.220 --> 00:06:00.368
Svako očitanje nazivamo
točkom emocionalnih podataka

00:06:00.368 --> 00:06:03.337
i zajedno mogu izraziti različite emocije.

00:06:03.337 --> 00:06:07.990
Na desnoj strani izgledaj sretno.

00:06:07.990 --> 00:06:09.444
To je sreća, povećava se.

00:06:09.444 --> 00:06:11.371
Sad nam pokaži gađenje.

00:06:11.371 --> 00:06:15.643
Sjeti se kako si se osjećala
kad je Zayn napustio One Direction.

00:06:15.643 --> 00:06:17.153
(Smijeh)

00:06:17.153 --> 00:06:21.495
Da, naboraj nos. Odlično.

00:06:21.495 --> 00:06:25.226
Valencija je prilično negativna,
mora da si bila njegov veliki fan.

00:06:25.226 --> 00:06:27.926
Valencija pokazuje
pozitivnost, tj. negativnost iskustva,

00:06:27.926 --> 00:06:30.712
a angažman pokazuje koliko je ekspresivna.

00:06:30.712 --> 00:06:34.126
Zamislite da Cloe ima pristup
ovom emocionalnom prijenosu uživo

00:06:34.126 --> 00:06:36.935
i da ga može podijeliti
s bilo kime s kime želi.

00:06:36.935 --> 00:06:39.858
Hvala.

00:06:39.858 --> 00:06:44.479
(Pljesak)

00:06:45.749 --> 00:06:51.019
Dosad smo prikupili 12 milijardi
ovih jedinica emocionalnih podataka.

00:06:51.019 --> 00:06:53.630
To je najveća baza podataka
za emocije u svijetu.

00:06:53.630 --> 00:06:56.593
Prikupili smo ih
iz 2,9 milijuna snimaka lica

00:06:56.593 --> 00:06:59.193
ljudi koji su pristali podijeliti
svoje emocije s nama

00:06:59.193 --> 00:07:02.398
iz 75 zemalja diljem svijeta.

00:07:02.398 --> 00:07:04.113
Svakim je danom sve veća.

00:07:04.603 --> 00:07:06.670
Svakim me danom sve više oduševljava

00:07:06.670 --> 00:07:09.865
kako možemo kvantificirati
nešto tako osobno poput emocija,

00:07:09.865 --> 00:07:12.100
i to možemo prikazati na ovoj skali.

00:07:12.100 --> 00:07:14.277
Što smo dosad naučili?

00:07:15.057 --> 00:07:17.388
Spol.

00:07:17.388 --> 00:07:21.034
Prikupljeni podatci potvrđuju
nešto na što ste vjerojatno sumnjali.

00:07:21.034 --> 00:07:22.891
Žene su ekspresivnije od muškaraca.

00:07:22.891 --> 00:07:25.574
Žene se više smiješe,
a i osmjesi im dulje traju

00:07:25.574 --> 00:07:28.478
te sada možemo zaista
kvantificirati na što to muškarci i žene

00:07:28.478 --> 00:07:30.614
drugačije reagiraju.

00:07:30.614 --> 00:07:32.904
Prijeđimo na kulturu. U SAD-u

00:07:32.904 --> 00:07:36.108
žene su 40% eskspresivnije od muškaraca,

00:07:36.108 --> 00:07:39.753
ali zanimljivo je da tu razliku ne vidlmo
u UK-u između muškaraca i žena.

00:07:39.753 --> 00:07:42.259
(Smijeh)

00:07:43.296 --> 00:07:47.323
Dob: ljudi od pedeset godina i više

00:07:47.323 --> 00:07:50.759
25% su emotivniji od mlađih ljudi.

00:07:51.899 --> 00:07:55.751
Žene u dvadesetima smiju se
više nego muškarci iste dobi,

00:07:55.751 --> 00:07:59.590
što je vjerojatno nužno
za romantične veze.

00:07:59.590 --> 00:08:02.207
Vjerojatno najnevjerojatnija spoznaja

00:08:02.207 --> 00:08:05.410
jest da da smo ekspresivni cijelo vrijeme,

00:08:05.410 --> 00:08:08.243
čak i kad sami sjedimo ispred uređaja,

00:08:08.243 --> 00:08:11.517
a ne samo kad gledamo
snimke mačaka na Facebooku.

00:08:12.217 --> 00:08:15.227
Ekspresivni smo dok pišemo mejlove,
poruke, kupujemo online

00:08:15.227 --> 00:08:17.527
ili pak računamo porez.

00:08:17.527 --> 00:08:19.919
Gdje se ovi podatci danas koriste?

00:08:19.919 --> 00:08:22.682
U razumijevanju toga kako
funkcioniramo s medijima,

00:08:22.682 --> 00:08:25.166
dakle razumijevanje marketinga
i glasačkog ponašanja,

00:08:25.166 --> 00:08:27.906
ali i u osnaživanju
ili tehnologiji u službi emocija.

00:08:27.906 --> 00:08:32.527
Željela bih vam pokazati
neke meni drage primjere.

00:08:33.197 --> 00:08:36.265
Naočale za očitavanje emocija
pomažu osobama

00:08:36.265 --> 00:08:39.493
oštećenog vida da čitaju emocije drugih,

00:08:39.493 --> 00:08:43.680
a mogu pomoći i autistima
da prepoznaju emocije,

00:08:43.680 --> 00:08:46.458
nešto što je njima zaista teško.

00:08:47.918 --> 00:08:50.777
Zamislite kad bi
aplikacije za učenje u obrazovanju

00:08:50.777 --> 00:08:53.587
mogle osjetiti da ste zbunjeni i usporiti

00:08:53.587 --> 00:08:55.444
ili da vam je dosadno, pa ubrzati,

00:08:55.444 --> 00:08:58.413
baš poput odličnog učitelja u učionici.

00:08:59.043 --> 00:09:01.644
Što kad bi vam ručni sat
mogao pratiti raspoloženje

00:09:01.644 --> 00:09:04.337
ili kad bi automobil osjetio da ste umorni

00:09:04.337 --> 00:09:06.885
ili da hladnjak zna da ste pod stresom,

00:09:06.885 --> 00:09:11.241
pa se automatski zaključa
da se ne bi prejedali. (Smijeh)

00:09:11.631 --> 00:09:14.348
Meni bi to bilo super.

00:09:15.668 --> 00:09:17.595
Što da sam, dok sam bila na Cambridgeu,

00:09:17.595 --> 00:09:19.908
imala pristup emocionalnom prijenosu uživo

00:09:19.908 --> 00:09:23.437
i da sam to mogla podijeliti
sa svojom obitelji na prirodan način,

00:09:23.437 --> 00:09:27.408
kao što bih to učinila
da smo zajedno u istoj prostoriji?

00:09:27.408 --> 00:09:30.550
Mislim da će za pet godina

00:09:30.550 --> 00:09:32.887
svi naši uređaji imati emocionalni čip

00:09:32.887 --> 00:09:36.951
i bit će nam teško zamisliti kako je bilo
kad se nismo mogli samo namrštiti uređaju,

00:09:36.951 --> 00:09:41.200
a da nam on ne kaže:
"Hmm, to ti se nije svidjelo, zar ne?"

00:09:41.200 --> 00:09:44.961
Izazov je u tome što ovu tehnologiju
možemo primijeniti na razne načine,

00:09:44.961 --> 00:09:47.864
a moj tim i ja shvaćamo da
ne možemo sve to napraviti sami.

00:09:47.864 --> 00:09:51.360
Stoga smo tu tehnologiju podijelili 
s drugim razvojnim inženjerima

00:09:51.360 --> 00:09:53.474
da je nastave razvijati i biti kreativni.

00:09:53.474 --> 00:09:57.560
Shvaćamo potencijalne rizike,

00:09:57.560 --> 00:09:59.627
kao i potencijal za zloupotrebu,

00:09:59.627 --> 00:10:02.576
ali osobno, nakon što sam tolike godine
provela radeći na tome,

00:10:02.576 --> 00:10:05.548
vjerujem da su koristi za čovječanstvo

00:10:05.548 --> 00:10:07.823
od emocionalno inteligentne tehnologije

00:10:07.823 --> 00:10:11.399
puno veće od potencijalne zloupotrebe.

00:10:11.399 --> 00:10:13.930
Sve vas pozivam da budete dio rasprave.

00:10:13.930 --> 00:10:16.484
Što je više ljudi upoznato
s tom tehnologijom,

00:10:16.484 --> 00:10:19.661
to će više nas imati pravo
izabrati kako će se koristiti.

00:10:21.081 --> 00:10:25.655
Što se naši životi
sve više digitaliziraju,

00:10:25.655 --> 00:10:29.153
to smo više osuđeni na propast
u pokušaju da smanjimo upotrebu uređaja

00:10:29.153 --> 00:10:31.382
kako bismo povratili emocije.

00:10:32.622 --> 00:10:36.536
Ono što ja želim napraviti jest
donijeti emocije u tehnologiju

00:10:36.536 --> 00:10:38.765
te je učiniti osjetljivijom na nas.

00:10:38.765 --> 00:10:41.435
Želim da nas ti uređaji
koji su nas razdvajali

00:10:41.435 --> 00:10:43.897
ponovno spoje.

00:10:43.897 --> 00:10:48.485
Humaniziranjem tehnologije
dobivamo jedinstvenu priliku

00:10:48.485 --> 00:10:51.782
ponovnog interpretiranja
načina na koji se povezujemo sa strojevima

00:10:51.782 --> 00:10:56.263
te samim time i kako se
mi kao ljudska bića

00:10:56.263 --> 00:10:58.167
povezujemo jedni s drugima.

00:10:58.167 --> 00:10:59.367
Hvala vam.

00:10:59.367 --> 00:11:02.680
(Pljesak)

