WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:07.000
翻译人员: Li Li
校对人员: Huazhe Xie

00:00:12.556 --> 00:00:16.573
我们的情感影响着我们生活的方方面面，

00:00:16.573 --> 00:00:20.149
它影响我们的健康，影响我们如何学习、做生意以及做决定，

00:00:20.149 --> 00:00:21.922
影响着大大小小各各方面。

00:00:22.672 --> 00:00:26.162
我们的情感还影响着我们与他人的联系的方式。

00:00:27.132 --> 00:00:31.108
我们进化成可以生活在现在这样的世界，

00:00:31.108 --> 00:00:35.427
然而我们却越来越生活成这样子——

00:00:35.427 --> 00:00:38.561
这是我女儿昨晚给我发的短信——

00:00:38.561 --> 00:00:41.301
这是个缺乏情感的世界。

00:00:41.301 --> 00:00:43.252
所以我现在正致力于改变那种情况。

00:00:43.252 --> 00:00:47.343
我想把情感带回到我们的数字体验中来。

00:00:48.223 --> 00:00:51.300
15年前我就开始走上了这条道路。

00:00:51.300 --> 00:00:53.366
那时我是一个生活在埃及的计算机科学家，

00:00:53.366 --> 00:00:57.871
并且刚刚接受了剑桥大学的博士学位项目。

00:00:57.871 --> 00:00:59.984
我做了一件对于一个年轻的

00:00:59.984 --> 00:01:04.209
埃及穆斯林新婚妻子来说非常不寻常的事情：

00:01:05.599 --> 00:01:08.598
我的丈夫不能离开埃及，但在他的支持下，

00:01:08.598 --> 00:01:11.616
我独自收拾行李搬到英国去了。

00:01:11.616 --> 00:01:14.844
在离家数千里之外的剑桥，

00:01:14.844 --> 00:01:18.257
我意识到我花在笔记本电脑上的时间

00:01:18.257 --> 00:01:20.486
要多于我与其他人相处的时间。

00:01:20.486 --> 00:01:25.339
然而尽管我和电脑如此亲密，电脑却对我的感受毫无所知。

00:01:25.339 --> 00:01:28.550
它根本不知道我是快乐，

00:01:28.550 --> 00:01:31.538
还是经历着糟糕的一天，或者是感到有压力、困惑，

00:01:31.538 --> 00:01:34.460
这就很让人不爽。

00:01:35.600 --> 00:01:40.831
而且更糟的是，当我回家后在线跟家人聊天时，

00:01:41.421 --> 00:01:44.703
我觉得我所有的情感都在网络空间中消失了。

00:01:44.703 --> 00:01:49.858
我想家，我感到孤独，而且有些日子我真的哭了，

00:01:49.858 --> 00:01:54.786
而我也仅仅只能用这个表情来表达我的情感。

00:01:54.786 --> 00:01:56.806
（笑声）

00:01:56.806 --> 00:02:01.780
现今有很多技术具有智商，但是还没有具有情商的，

00:02:01.780 --> 00:02:04.956
很多技术具有认知性智能，但还没有具有情绪性智能的。

00:02:04.956 --> 00:02:07.153
这让我想到，

00:02:07.153 --> 00:02:10.777
如果我们的技术可以识别我们的情绪将会怎样？

00:02:10.777 --> 00:02:14.853
如果我们的设备能识别我们的感受并做出相应的反应，

00:02:14.853 --> 00:02:17.866
就像情商高的朋友所做的那样将会怎样？

00:02:18.666 --> 00:02:22.230
这些问题引导着我和我的团队

00:02:22.230 --> 00:02:26.607
去创造可以阅读我们的情绪并做出反应的技术，

00:02:26.607 --> 00:02:29.697
我们的起点是人脸。

00:02:30.577 --> 00:02:33.750
人脸是交流的最强大的渠道之一，

00:02:33.750 --> 00:02:37.766
我们所有人都用它来表达社会和情绪状态，

00:02:37.766 --> 00:02:40.776
从喜悦、惊讶

00:02:40.776 --> 00:02:44.979
到同情、好奇等等。

00:02:44.979 --> 00:02:49.907
在情感科学中，我们将每一个面肌运动称为一个动作单元。

00:02:49.907 --> 00:02:52.832
例如，动作单元12，

00:02:52.832 --> 00:02:54.870
这不是好莱坞大片，

00:02:54.870 --> 00:02:58.312
这就是简单的嘴角上扬，它是微笑的主要构成。

00:02:58.312 --> 00:03:01.300
大家都试一下。让我们都微笑起来。

00:03:01.300 --> 00:03:03.954
另一个例子是动作单元4。它是眉间纹。

00:03:03.954 --> 00:03:06.192
当你将眉毛拧到一起的时候

00:03:06.192 --> 00:03:08.459
你就创造出了这些纹理和皱纹。

00:03:08.459 --> 00:03:12.754
我们不喜欢它，但它是一个非常强的负面情绪指示器。

00:03:12.754 --> 00:03:14.960
我们大概有45个这样的单元，

00:03:14.960 --> 00:03:18.350
它们的组合可以表达上百种情绪。

00:03:18.350 --> 00:03:22.251
教会电脑去读取这些面部情绪很难，

00:03:22.251 --> 00:03:25.223
因为这些动作单元行动很微妙，而且稍纵即逝，

00:03:25.223 --> 00:03:27.777
而且它们有很多的组合方式。

00:03:27.777 --> 00:03:31.515
例如，微笑和假笑。

00:03:31.515 --> 00:03:35.268
它们看起来有几分相似，但意味却是天差地别。

00:03:35.268 --> 00:03:36.986
（笑声）

00:03:36.986 --> 00:03:39.990
微笑是正面的，

00:03:39.990 --> 00:03:41.260
假笑常常是负面的。

00:03:41.260 --> 00:03:45.136
有时一个假笑可以让你出名。

00:03:45.136 --> 00:03:47.960
但是严肃地讲，让电脑能够

00:03:47.960 --> 00:03:50.815
描述这两种表情的区别是很重要的。

00:03:50.815 --> 00:03:52.627
那我们是如何做的呢？

00:03:52.627 --> 00:03:54.414
我们给我们的算法

00:03:54.414 --> 00:03:58.524
成千上万的不同种族、年龄和性别的人们

00:03:58.524 --> 00:04:01.589
正在微笑的例子，

00:04:01.589 --> 00:04:04.400
然后我们也用同样的方法研究假笑。

00:04:04.400 --> 00:04:05.954
然后使用深度学习，

00:04:05.954 --> 00:04:08.810
算法可以观察我们脸上的所有这些纹理和皱纹

00:04:08.810 --> 00:04:11.390
以及形状变化，

00:04:11.390 --> 00:04:14.592
并且基本上得知所有的微笑都有共同特性，

00:04:14.592 --> 00:04:17.773
而所有的假笑都有些微的不同特性。

00:04:17.773 --> 00:04:20.141
然后下一次当它看到一个新面孔时，

00:04:20.141 --> 00:04:22.440
它就基本上能知道

00:04:22.440 --> 00:04:25.473
这张面孔上有和微笑相同的特性，

00:04:25.473 --> 00:04:29.751
然后它就会说：“啊哈，我知道了，这是一个微笑的表情。”

00:04:30.381 --> 00:04:33.181
所以展示这种技术如何工作的最好方式

00:04:33.181 --> 00:04:35.317
是来一个现场演示，

00:04:35.317 --> 00:04:39.230
所以我需要一位志愿者，最好是个“有脸”的人。

00:04:39.230 --> 00:04:41.564
（笑声）

00:04:41.564 --> 00:04:44.335
克洛将成为我们今天的志愿者。

00:04:45.325 --> 00:04:49.783
在过去的5年间，我们从只是麻省理工学院的一个研究项目

00:04:49.783 --> 00:04:50.939
到成立一个公司，

00:04:50.939 --> 00:04:54.131
在公司里我的团队非常非常努力地工作以使这项技术成功，

00:04:54.131 --> 00:04:56.540
就像我们说的那样，我们在荒野里生存。

00:04:56.540 --> 00:04:59.210
我们还将它缩小了，这样的话这个核心情绪引擎

00:04:59.210 --> 00:05:02.530
就能在一个带摄像头的移动设备上运行，比如这个iPad。

00:05:02.530 --> 00:05:05.316
让我们来试一试。

00:05:06.756 --> 00:05:10.680
正如你们看到的，此算法基本上找到了克洛的脸，

00:05:10.680 --> 00:05:12.372
就是这个白色的边界框，

00:05:12.372 --> 00:05:14.943
它在跟踪她脸上的主要特征点，

00:05:14.943 --> 00:05:17.799
她的眉毛、眼睛、嘴巴和鼻子。

00:05:17.799 --> 00:05:20.786
问题是，它能识别她的表情吗？

00:05:20.786 --> 00:05:22.457
那么我们测试一下这台机器。

00:05:22.457 --> 00:05:26.643
首先，做一个面无表情的样子。嗯，好极了。（笑声）

00:05:26.643 --> 00:05:29.456
然后当她微笑时，这是一个真诚的微笑，很好。

00:05:29.456 --> 00:05:31.756
大家可以看到当她微笑时这些绿条增长了。

00:05:31.756 --> 00:05:32.978
这是一个大大的微笑。

00:05:32.978 --> 00:05:36.021
你能试着轻轻微笑一下，看看电脑能否识别出来吗？

00:05:36.021 --> 00:05:38.352
它确实也能识别轻轻的微笑。

00:05:38.352 --> 00:05:40.477
我们付出了很多的努力才使它能够做到这些。

00:05:40.477 --> 00:05:43.439
眉毛上扬，是惊喜的标志。

00:05:43.439 --> 00:05:47.688
眉间的皱纹，是困惑的标志。

00:05:47.688 --> 00:05:51.695
皱眉。嗯，很完美。

00:05:51.695 --> 00:05:55.188
这些都是不同的行动单元。还有很多这样的行动单元。

00:05:55.188 --> 00:05:57.220
这只是一个小型的演示。

00:05:57.220 --> 00:06:00.368
我们称每一次读取为一个情感数据点，

00:06:00.368 --> 00:06:03.337
然后它们可以组合在一起来描绘不同的情绪。

00:06:03.337 --> 00:06:07.990
因此在演示的右边，你看起来很开心。

00:06:07.990 --> 00:06:09.444
那表示快乐，快乐就被启动了。

00:06:09.444 --> 00:06:11.371
再做一个厌恶的表情。

00:06:11.371 --> 00:06:15.643
试着回想一下当泽恩离开单向乐队时的情景。

00:06:15.643 --> 00:06:17.153
（笑声）

00:06:17.153 --> 00:06:21.495
是的，皱一下鼻。很好。

00:06:21.495 --> 00:06:25.226
而“抗体效价”一项也呈现负值，因此你一定是他们的铁杆粉丝。

00:06:25.226 --> 00:06:27.926
抗体效价是用来描述一种体验的积极或消极程度的，

00:06:27.926 --> 00:06:30.712
而“参与度”是用来描述她的表现力的。

00:06:30.712 --> 00:06:34.126
所以大家可以想象一下如果克洛能够使用这种实时的情感流，

00:06:34.126 --> 00:06:36.935
并且能分享给任何她想分享的人的情景。

00:06:36.935 --> 00:06:39.858
谢谢。

00:06:39.858 --> 00:06:44.479
（掌声）

00:06:45.749 --> 00:06:51.019
迄今为止，我们已经积累了120亿这种情感数据点。

00:06:51.019 --> 00:06:53.630
这是世界上最大的情感数据库。

00:06:53.630 --> 00:06:56.593
我们是从两百九十万个面部视频中去收集的，

00:06:56.593 --> 00:06:59.193
这些视频来自那些同意将他们的情感与我们一起分享的人们，

00:06:59.193 --> 00:07:02.398
并且这些人们来自全世界75个国家。

00:07:02.398 --> 00:07:04.113
它每天都在发展。

00:07:04.603 --> 00:07:06.670
它发散了我的思维：

00:07:06.670 --> 00:07:09.865
原来我们可以将情绪这么个性化的东西进行量化，

00:07:09.865 --> 00:07:12.100
并且是在这样的规模下去做这件事。

00:07:12.100 --> 00:07:14.277
到现在我们从这些数据中学到了什么呢？

00:07:15.057 --> 00:07:17.388
性别差异。

00:07:17.388 --> 00:07:21.034
我们的数据证实了某些你可能正在猜测的事情。

00:07:21.034 --> 00:07:22.891
女性比男性更具表现力。

00:07:22.891 --> 00:07:25.574
不仅是她们笑得更多，更因为她们笑得更久，

00:07:25.574 --> 00:07:28.478
并且我们现在可以真实地量化男性和女性

00:07:28.478 --> 00:07:30.614
在反应方面的差异性。

00:07:30.614 --> 00:07:32.904
让我们从文化方面来看：在美国，

00:07:32.904 --> 00:07:36.108
女性的表现力要比男性高40%，

00:07:36.108 --> 00:07:39.753
但奇怪的是，在英国我们看不到男女在这方面的任何差异。

00:07:39.753 --> 00:07:42.259
（笑声）

00:07:43.296 --> 00:07:47.323
在年龄方面：50岁及以上的人

00:07:47.323 --> 00:07:50.759
情绪化比小于50岁的人高25%。

00:07:51.899 --> 00:07:55.751
女性在20来岁的时候要比同龄的男性笑得更多，

00:07:55.751 --> 00:07:59.590
也许这是约会的必需品。

00:07:59.590 --> 00:08:02.207
但也许这些数据带给我们最大的惊喜是

00:08:02.207 --> 00:08:05.410
我们每时每刻都在表达，

00:08:05.410 --> 00:08:08.243
即使当我们独自坐在电子设备前，

00:08:08.243 --> 00:08:11.517
而且不仅是我们在脸书上看猫的视频时。

00:08:12.217 --> 00:08:15.227
不管我们在发邮件、发短信、网购，甚至报税的时候

00:08:15.227 --> 00:08:17.527
我们无时无刻不在表达自己。

00:08:17.527 --> 00:08:19.919
那么如今这些数据用在何处呢？

00:08:19.919 --> 00:08:22.682
用在弄明白我们如何和传媒结合，

00:08:22.682 --> 00:08:25.166
从而搞明白网络扩散和投票行为，

00:08:25.166 --> 00:08:27.906
以及情绪授权技术。

00:08:27.906 --> 00:08:32.527
我想分享一些触动我心的例子。

00:08:33.197 --> 00:08:36.265
情绪授权可佩戴眼镜

00:08:36.265 --> 00:08:39.493
可以帮助那些视力受损的人读懂他人的脸部表情，

00:08:39.493 --> 00:08:43.680
也可帮助患有自闭症的人们解读情绪，

00:08:43.680 --> 00:08:46.458
因为解读情绪对他们来说是很困难的。

00:08:47.918 --> 00:08:50.777
在教育方面，想象如果你的学习类应用程序

00:08:50.777 --> 00:08:53.587
察觉出你有困惑，应用程序会放慢速度，

00:08:53.587 --> 00:08:55.444
或者你无聊了，它则会加快进程，

00:08:55.444 --> 00:08:58.413
就像教室里经验丰富的老师一样。

00:08:59.043 --> 00:09:01.644
再想象一下你的手表可以感知你的情绪，

00:09:01.644 --> 00:09:04.337
或你的车可以觉察出你疲惫了，

00:09:04.337 --> 00:09:06.885
或者说你的冰箱知道你有压力，

00:09:06.885 --> 00:09:12.951
所以它会自动上锁防止你暴饮暴食。（笑声）

00:09:12.951 --> 00:09:15.668
我会喜欢这个的，没错。

00:09:15.668 --> 00:09:17.595
设想当我在剑桥时，

00:09:17.595 --> 00:09:19.908
我可以连接到实时情绪流，

00:09:19.908 --> 00:09:23.437
我可以和我家里的亲人
用很自然的方式分享一些东西，

00:09:23.437 --> 00:09:27.408
就像我和家人在同一间房里所做的事一样将会怎样？

00:09:27.408 --> 00:09:30.550
我猜想也就在五年后，

00:09:30.550 --> 00:09:32.887
所有的电子设备都会有一个情绪芯片，

00:09:32.887 --> 00:09:36.951
我们将会体验到我们皱眉后电子设备回应
“嗯，你不喜欢这个，对吧？”

00:09:36.951 --> 00:09:41.200
这一举动实现时的感受。

00:09:41.200 --> 00:09:44.961
我们最大的挑战就是
现在关于这方面的科技有许多用途，

00:09:44.961 --> 00:09:47.864
我和我的团队意识到我们无法
靠我们自己就把所有事情都完成，

00:09:47.864 --> 00:09:51.360
所以我们把这项科技开放，

00:09:51.360 --> 00:09:53.474
这样其他开发者就能创造创新。

00:09:53.474 --> 00:09:57.560
我们知道这有潜在的风险，

00:09:57.560 --> 00:09:59.627
还有可能被滥用，

00:09:59.627 --> 00:10:02.576
但就我个人来说，花了这么多年做这件事，

00:10:02.576 --> 00:10:05.548
我相信情绪智能技术

00:10:05.548 --> 00:10:07.823
给人类带来的好处

00:10:07.823 --> 00:10:11.399
远超过被滥用的可能性。

00:10:11.399 --> 00:10:13.930
所以我邀请大家一起加入。

00:10:13.930 --> 00:10:16.484
越多的人知道这项技术，

00:10:16.484 --> 00:10:19.661
我们就越能说出如何使用的想法。

00:10:21.081 --> 00:10:25.655
所以随着我们的生活越来越数字化，

00:10:25.655 --> 00:10:29.153
我们其实在打一场处于劣势的战争，试图去控制我们的电子设备的用途

00:10:29.153 --> 00:10:31.382
从而开拓我们的情绪。

00:10:32.622 --> 00:10:36.536
所以相反地，我所做的就是把情绪带到我们的科技中

00:10:36.536 --> 00:10:38.765
让我们的科技更加有响应性。

00:10:38.765 --> 00:10:41.435
我想要那些把我们分离开来的电子设备

00:10:41.435 --> 00:10:43.897
重新把我们聚在一起。

00:10:43.897 --> 00:10:48.485
现在是黄金时机，我们可以通过人性化科技

00:10:48.485 --> 00:10:51.782
重新想象我们该如何和这些机器交流结合，

00:10:51.782 --> 00:10:56.263
从而重新想象，作为人类的我们

00:10:56.263 --> 00:10:58.167
如何与彼此交流结合。

00:10:58.167 --> 00:11:00.327
谢谢。

00:11:00.327 --> 00:11:03.640
（掌声）

