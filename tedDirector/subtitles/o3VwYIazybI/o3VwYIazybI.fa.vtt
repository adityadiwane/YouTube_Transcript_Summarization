WEBVTT
Kind: captions
Language: fa

00:00:00.000 --> 00:00:07.000
Translator: Kimia Kiani
Reviewer: Leila Ataei

00:00:12.556 --> 00:00:16.573
احساسات ما روی همه‌ی جنبه‌های زندگیمان
تأثیر می‌گذارد،

00:00:16.573 --> 00:00:20.149
از سلامتی و چگونگی یادگیریمان گرفته، 
تا شیوه‌ی کسب و کار و تصمیم‌گیریمان،

00:00:20.149 --> 00:00:21.922
از ریز تا درشت.

00:00:22.672 --> 00:00:26.162
احساساتمان روی برقراری ارتباطمات 
با دیگران نیز تأثیر می‌گذارد.

00:00:27.132 --> 00:00:31.108
ما چنان رشد کرده‌ایم 
تا در جهانی این‌چنین زندگی کنیم،

00:00:31.108 --> 00:00:35.427
ولی در مقابل، بیشتر این‌گونه
زندگی می‌کنیم --

00:00:35.427 --> 00:00:38.561
این پیامک را دخترم،
شب گذشته برایم فرستاده است --

00:00:38.561 --> 00:00:41.301
در جهانی که خالی از احساسات است.

00:00:41.301 --> 00:00:43.252
من مأموریت دارم که وضعیت را
تغییر دهم.

00:00:43.252 --> 00:00:47.343
می‌خواهم احساسات را
به تجربه‌ی دیجیتال بیاورم.

00:00:48.223 --> 00:00:51.300
این راه را ۱۵ سال پیش آغاز کردم.

00:00:51.300 --> 00:00:53.366
من یک دانشمند کامپیوتر در مصر بودم،

00:00:53.366 --> 00:00:57.871
و به‌تازگی در یک برنامه‌ی دکترا
در دانشگاه کمبریج پذیرفته شده‌ بودم.

00:00:57.871 --> 00:00:59.984
من کاری به نسبت غیر معمول

00:00:59.984 --> 00:01:04.209
برای یک زن مسلمان مصری تازه عروس
انجام دادم:

00:01:05.599 --> 00:01:08.598
با حمایت همسرم که 
باید در مصر می‌ماند

00:01:08.598 --> 00:01:11.616
چمدان‌هایم را برداشتم و به انگلیس رفتم.

00:01:11.616 --> 00:01:14.844
در کمبریج، هزاران مایل
دور از خانه،

00:01:14.844 --> 00:01:18.257
فهمیدم که بیشتر ساعات را
با لپ‌تاپم سپری می‌کنم

00:01:18.257 --> 00:01:20.486
تا با دیگر انسان‌ها.

00:01:20.486 --> 00:01:25.339
با وجود این صمیمیت، لپ‌تاپ من هیچ ایده‌ای 
درباره‌ی آن‌چه من احساس می‌کردم نداشت.

00:01:25.339 --> 00:01:28.550
هیچ ایده‌ای درباره‌ی این که من خوش‌حالم

00:01:28.550 --> 00:01:31.538
روز بدی را گذرانده‌ام، استرس داشته‌ام، 
یا گیجم،

00:01:31.538 --> 00:01:34.460
و خب، این‌ها ناامید‌کننده شد.

00:01:35.600 --> 00:01:40.831
حتی بدتر، هنگامی که با خانواده‌ام، 
به صورت آنلاین ارتباط برقرار می‌کردم،

00:01:41.421 --> 00:01:44.703
احساس می‌کردم که تمام احساسات من 
در فضای سایبری ناپدید می‌شوند.

00:01:44.703 --> 00:01:49.858
من دلتنگ خانه بودم، تنها بودم، 
و بعضی روز‌ها واقعا گریه می‌کردم،

00:01:49.858 --> 00:01:54.786
ولی تنها راه ابراز احساساتم
این شکلک بود.

00:01:54.786 --> 00:01:56.806
(خنده‌ی حضار)

00:01:56.806 --> 00:02:01.780
تکنولوژیِ امروز، بهره‌ی هوشی بالایی دارد
ولی بهره‌ی احساسی ندارد؛

00:02:01.780 --> 00:02:04.956
هوشِ شناختیِ فراوانی دارد،
ولی هوش احساسی ندارد.

00:02:04.956 --> 00:02:07.153
این مرا به فکر فرو برد،

00:02:07.153 --> 00:02:10.777
اگر تکنولوژی می‌توانست 
احساسات ما را بفهمد، چه می‌شد؟

00:02:10.777 --> 00:02:14.853
چه می‌شد اگر وسایل ما می‌توانستند 
احساست ما را بفهمند و با توجه به آن‌ها واکنش نشان‌دهند،

00:02:14.853 --> 00:02:17.866
مثل هر یک از دوستان ما که هوش احساسی دارد 
و واکنش نشان می‌دهد؟

00:02:18.666 --> 00:02:22.230
این سؤالات، من و تیمم را

00:02:22.230 --> 00:02:26.607
به ساخت تکنولوژی‌هایی که بتوانند احساساتِ 
ما را بخوانند و به آن‌ پاسخ بدهند سوق داد،

00:02:26.607 --> 00:02:29.697
و نقطه‌ی شروع ما چهره‌ی انسان‌ها بود.

00:02:30.577 --> 00:02:33.750
چهره‌ی انسان‌، یکی از قوی‌ترین کانال‌هاست

00:02:33.750 --> 00:02:37.766
که همه‌ی ما از آن استفاده می‌کنیم، تا 
حالت‌های اجتماعی و احساسی را ابراز کنیم،

00:02:37.766 --> 00:02:40.776
همه‌چیز، شوق و شگفتی‌ِمان،

00:02:40.776 --> 00:02:44.979
هم‌دلی و کنجکاویمان.

00:02:44.979 --> 00:02:49.907
در دانش احساسات، ما به هر حرکت عضلات صورت
یک واحد حرکت می‌گوییم.

00:02:49.907 --> 00:02:52.832
در نتیجه، برای مثال، حرکتِ واحدِ ۱۲،

00:02:52.832 --> 00:02:54.870
یک فیلم پرفروش هالیوودی نیست،

00:02:54.870 --> 00:02:58.312
بلکه در حقیقت، بالا رفتن گوشه‌ی لب است، 
که یک جز‌ٔ اصلی لب‌خند است.

00:02:58.312 --> 00:03:01.300
همه امتحانش کنید. بیایید
چندین لبخند داشته‌باشیم.

00:03:01.300 --> 00:03:03.954
مثال دیگر، حرکتِ واحدِ ۴ است،
که حرکتِ چروک انداختن ابرو است.

00:03:03.954 --> 00:03:06.192
زمانی که شما ابرو‌هایتان را درهم می‌‌کشید

00:03:06.192 --> 00:03:08.459
و همه‌ی این الگو‌ها و چین‌ها را می‌سازید.

00:03:08.459 --> 00:03:12.754
ما اخم را دوست نداریم، ولی این حرکت 
نشانگری قوی برای احساسات منفی است.

00:03:12.754 --> 00:03:14.960
ما حدود ۴۵ واحد حرکتی داریم،

00:03:14.960 --> 00:03:18.350
و همه‌ی آن‌ها با هم ترکیب می‌شوند 
تا صد‌ها احساس را ابراز و بیان کنند.

00:03:18.350 --> 00:03:22.251
آموزش خواندن احساسات چهره 
به یک کامپیوتر سخت است،

00:03:22.251 --> 00:03:25.223
زیرا این واحد‌های حرکتی می‌توانند 
سریع، دقیق، و ماهرانه باشند.

00:03:25.223 --> 00:03:27.777
و به شکل‌های مختلف با هم ترکیب شوند.

00:03:27.777 --> 00:03:31.515
برای مثال، لبخند و پوزخند زدن را 
در نظر بگیرید.

00:03:31.515 --> 00:03:35.268
آن‌ها از جهاتی، شبیه به هم هستند،
ولی معانی کاملا متفاوتی دارند.

00:03:35.268 --> 00:03:36.986
(خنده‌ی حضار)

00:03:36.986 --> 00:03:39.990
لبخند مثبت است،

00:03:39.990 --> 00:03:41.260
و پوزخند معمولاً منفی‌.

00:03:41.260 --> 00:03:45.136
بعضی اوقات، یک پوزخند 
می‌تواند شما را معروف کند.

00:03:45.136 --> 00:03:47.960
ولی جداً، برای یک کامپیوتر 
مهم است که بتواند

00:03:47.960 --> 00:03:50.815
دو حالت متفاوت را 
از هم تشخیص دهد.

00:03:50.815 --> 00:03:52.627
حال، ما این کار را چگونه
انجام می‌دهیم؟

00:03:52.627 --> 00:03:54.414
ما به الگوریتم‌هایمان

00:03:54.414 --> 00:03:58.524
ده‌ها مثال از صد‌ها مثالی که 
مردم در آن‌ها می‌خندند را می‌دهیم،

00:03:58.524 --> 00:04:01.589
از فرهنگ‌ها، سنین، و جنسیت‌های متفاوت،

00:04:01.589 --> 00:04:04.400
و همین کار را برای پوزخند‌ها 
انجام می‌دهیم.

00:04:04.400 --> 00:04:05.954
و سپس، با کمک یادگیری عمیق،‌

00:04:05.954 --> 00:04:08.810
الگوریتمْ به همه‌ی این الگو‌ها 
و چین‌و‌چروک‌ها

00:04:08.810 --> 00:04:11.390
و تغییرات قالبِ چهره‌مان نگاه می‌کند،

00:04:11.390 --> 00:04:14.592
و به طور اساسی یاد می‌گیرد که 
همه‌ی لبخند‌ها ویژگی‌های مشابهی دارند

00:04:14.592 --> 00:04:17.773
و همه‌ی پوزخند‌ها، ویژگی‌های ماهرانه‌، 
اما متفاوتی دارند.

00:04:17.773 --> 00:04:20.141
و دفعه‌ی بعد که 
یک چهره‌ی جدید را می‌بیند،

00:04:20.141 --> 00:04:22.440
ضرورتاً می‌فهمد

00:04:22.440 --> 00:04:25.473
که این چهره، ویژگی‌های یک لبخند را دارد،

00:04:25.473 --> 00:04:29.751
و می‌گوید: «آها، من این را تشخیص می‌دهم. 
این جلوه‌ی یک لبخند است.»

00:04:30.381 --> 00:04:33.181
پس بهترین راه برای نشان‌دادن 
چگونگی عمل‌کرد این تکنولوژی

00:04:33.181 --> 00:04:35.317
اجرای یک نمایش زنده است،

00:04:35.317 --> 00:04:39.230
پس من یک داوطلب می‌خواهم، 
ترجیحاً فردی با یک صورت.

00:04:39.230 --> 00:04:41.564
(خنده‌ی حضار)

00:04:41.564 --> 00:04:44.335
کلوی داوطلب امروز ما خواهد بود.

00:04:45.325 --> 00:04:49.783
در پنج سالِ گذشته، ما از یک 
پروژه‌ی تحقیقاتی در MIT،

00:04:49.783 --> 00:04:50.939
به یک شرکت تبدیل شدیم،

00:04:50.939 --> 00:04:54.131
جایی که تیم من، به سختی کار کرده‌است 
تا این تکنولوژی کار کند،

00:04:54.131 --> 00:04:56.540
که چیزی است که می‌خواهیم
در واقعیت بگوییم تا در تئوری.

00:04:56.540 --> 00:04:59.210
هم‌چنین ما، آن را کوچک کرده‌ایم 
تا هسته‌ی موتور احساسات

00:04:59.210 --> 00:05:02.530
روی هر دستگاه موبایلِ مجهز به دوربین،
مانند این آی‌پد، کار کند.

00:05:02.530 --> 00:05:05.316
پس بیایید امتحانش کنیم.

00:05:06.756 --> 00:05:10.680
همان‌طور که می‌توانید مشاهده‌کنید، 
الگوریتم صورت کلوی را یافته‌ است،

00:05:10.680 --> 00:05:12.372
پس این جعبه‌ی سفید 
کادر صورت را نشان می‌دهد،

00:05:12.372 --> 00:05:14.943
که دارد خصوصیات اصلی صورتش را
دنبال می‌کند؛

00:05:14.943 --> 00:05:17.799
ابرو‌هایش، چشمانش، دهانش، و دماغش.

00:05:17.799 --> 00:05:20.786
سؤال این است که 
آیا می‌تواند احساساتش را نیز شناسایی کند؟

00:05:20.786 --> 00:05:22.457
پس ما دستگاه را تست می‌کنیم.

00:05:22.457 --> 00:05:26.643
اول از همه، صورت بدون احساست را
به من نشان بده. بله، عالی است! (خنده‌ی حضار)

00:05:26.643 --> 00:05:29.456
حالا او می‌خندد،
این یک خنده‌ی خالص است، عالی است.

00:05:29.456 --> 00:05:31.756
می‌توانید ببینید که نوار سبز
با خندیدن او بزرگ می‌شود.

00:05:31.756 --> 00:05:32.978
این یک خنده‌ی بزرگ بود.

00:05:32.978 --> 00:05:36.021
می‌توانی کمی ملایم بخندی تا ببینیم 
کامپیوتر می‌تواند آن را شناسایی کند؟

00:05:36.021 --> 00:05:38.352
بله، می‌تواند خنده‌ی ماهرانه را هم
به همین ترتیب شناسایی کند.

00:05:38.352 --> 00:05:40.477
ما واقعا سخت کار کرده‌ایم 
تا این کار را انجام دهیم.

00:05:40.477 --> 00:05:43.439
و بعد، بالا رفتن ابرو‌ها، 
که نشان‌دهنده‌ی شگفتی است.

00:05:43.439 --> 00:05:47.688
چین‌خوردگی پیشانی،
نشان‌دهنده‌ی گیجی است.

00:05:47.688 --> 00:05:51.695
رو ترش کُن. بله، عالی است.

00:05:51.695 --> 00:05:55.188
پس این‌‌ها همه‌ی واحد‌هایِ حرکتیِ‌ متفاوت
هستند. چندین حرکت دیگر نیز وجود دارد.

00:05:55.188 --> 00:05:57.220
این یک نمایش کوچک‌شده است.

00:05:57.220 --> 00:06:00.368
ما به هر خواندن، یک 
نقطه‌ی داده‌ی احساسات می‌گوییم.

00:06:00.368 --> 00:06:03.337
و این نقاط می‌توانند با هم ترکیب شوند 
تا نشان‌دهنده‌ی احساسات متفاوت باشند.

00:06:03.337 --> 00:06:07.990
پس در سمتِ راستِ نمونه‌ی نمایشی--
نشان بده که خوشحالی.

00:06:07.990 --> 00:06:09.444
این شوق است. 
شوق زیاد می‌شود.

00:06:09.444 --> 00:06:11.371
و حالا به من یک صورت منزجر نشان بده.

00:06:11.371 --> 00:06:15.643
احساست را، زمانی که زِین، گروهِ 
وان‌دایرِکشن را ترک کرد، به خاطر بیاور.

00:06:15.643 --> 00:06:17.153
(خنده‌ی حضار)

00:06:17.153 --> 00:06:21.495
بله، دماغت را چین بده. عالی است.

00:06:21.495 --> 00:06:25.226
و نشان‌گر ظرفیت تا حدودی منفی شد، 
پس حتما یک طرفدار واقعی هستی.

00:06:25.226 --> 00:06:27.926
معیارِ ظرفیت، مثبت یا منفی بودنِ تجربه را
نشان می‌دهد،

00:06:27.926 --> 00:06:30.712
و معیارِ درگیری نشان‌دهنده‌ی تأثیری است 
که حالت صورت فرد خواهد گذاشت.

00:06:30.712 --> 00:06:34.126
پس زمانی را تصور کنید که کلوی
به این رشته‌ی احساسات بی‌درنگ دسترسی داشت،

00:06:34.126 --> 00:06:36.935
و می‌توانست آن را با هر کسی که می‌خواهد
در میان بگذارد.

00:06:36.935 --> 00:06:39.858
متشکرم.

00:06:39.858 --> 00:06:44.479
(تشویق حضار)

00:06:45.749 --> 00:06:51.019
تابه‌حال، ما ۱۲ میلیارد از این نقاطِ 
احساسی را جمع‌آوری کرده‌ایم.

00:06:51.019 --> 00:06:53.630
این مجموعه، بزرگ‌ترین پایگاه‌داده‌ی 
احساسات در دنیاست.

00:06:53.630 --> 00:06:56.593
آن را از ۲/۹ میلیون ویدیوی چهره
جمع‌آوری کرده‌ایم،

00:06:56.593 --> 00:06:59.193
که شرکت‌کنندگان با در اختیار گذاشتن
احساساتشان موافقت کرده‌اند،

00:06:59.193 --> 00:07:02.398
و از ۷۵ کشور در سراسر جهان 
شرکت کرده‌اند.

00:07:02.398 --> 00:07:04.113
این مجموعه، 
هر روز رو به رشد است.

00:07:04.603 --> 00:07:06.670
مغزم منفجر می‌شود،

00:07:06.670 --> 00:07:09.865
زمانی که فکر می‌کنم که ما می‌توانیم 
چیزی خصوصی مانند احساسات را

00:07:09.865 --> 00:07:12.100
تا این حد، اندازه بگیریم.

00:07:12.100 --> 00:07:14.277
تا به حال چه آموخته‌ایم؟

00:07:15.057 --> 00:07:17.388
جنسیت.

00:07:17.388 --> 00:07:21.034
داده‌های ما، چیز‌هایی که ممکن است
در آن‌ها شک داشته باشید را، تأیید می‌کنند.

00:07:21.034 --> 00:07:22.891
خانم‌ها از آقایان واضح‌تر
ابراز احساسات می‌کنند.

00:07:22.891 --> 00:07:25.574
نه تنها بیشتر لبخند می‌زنند، 
بلکه لبخند‌هایشان با دوام‌تر است.

00:07:25.574 --> 00:07:28.478
و ما می‌توانیم ارزیابی کنیم، ‌
که زنان و مردان به چه چیز‌هایی

00:07:28.478 --> 00:07:30.614
واکنش‌های متفاوتی نشان می‌دهند.

00:07:30.614 --> 00:07:32.904
بیایید فرهنگ را بررسی کنیم:
در ایالات متحده‌،

00:07:32.904 --> 00:07:36.108
زنان ۴۰ درصد بیشتر از مردان
در بیان احساسات خود گویا هستند،

00:07:36.108 --> 00:07:39.753
ولی به شکل عجیبی، هیچ تفاوتی بین زنان و 
مردان در انگلستان، مشاهده نمی‌شود.

00:07:39.753 --> 00:07:42.259
(خنده‌ی حضار)

00:07:43.296 --> 00:07:47.323
سن: کسانی که ۵۰ سال یا بیشتر
سن دارند،

00:07:47.323 --> 00:07:50.759
۲۵ درصد بیشتر از افراد جوان‌تر
احساساتی هستند.

00:07:51.899 --> 00:07:55.751
زنان در دهه‌ی بیست‌سالگیشان، بسیار بیشتر 
از مردان با سن مشابه لبخند می‌زنند.

00:07:55.751 --> 00:07:59.590
شاید این یکی از الزامات معاشرت است.

00:07:59.590 --> 00:08:02.207
اما شاید آن‌چه از بیشتر درباره‌ی این
داده‌ها شگفت‌زده‌مان کرد

00:08:02.207 --> 00:08:05.410
این بود که ما در تمام مدت در حال
ابرازِ احساساتیم،

00:08:05.410 --> 00:08:08.243
حتی زمانی که به تنهایی در مقابل دستگاهمان 
نشسته‌ایم،

00:08:08.243 --> 00:08:11.517
و نه تنها زمانی که داریم ویدیوی یک گربه
را در فیس‌بوک می‌بینیم، بلکه همیشه.

00:08:12.217 --> 00:08:15.227
ما هنگام ای‌میل زدن،پیامک زدن،
خرید آنلاین،

00:08:15.227 --> 00:08:17.527
یا حتی پرداخت مالیات، 
در حال ابراز احساساتیم.

00:08:17.527 --> 00:08:19.919
امروزه، این داده‌ها
در کجا استفاده می‌شود؟

00:08:19.919 --> 00:08:22.682
در فهم این که ما چگونه با رسانه‌ها 
در ارتباطیم،

00:08:22.682 --> 00:08:25.166
در فهم الگو‌های اشتراک‌گذاریِ ویدیو‌ها
و رأی دادن؛

00:08:25.166 --> 00:08:27.906
و همچنین قدرت دادن یا 
احساسی کردن تکنولوژی،

00:08:27.906 --> 00:08:32.527
می‌خواهم چند مثال با شما در میان بگذارم
که قلبم را در‌هم می‌فشارند.

00:08:33.197 --> 00:08:36.265
عینک‌های هوشمند از نظر احساسات
می‌توانند به افرادی که

00:08:36.265 --> 00:08:39.493
از نظر بینایی مشکل دارند، در فهمِ احساساتِ
دیگران، یاری برسانند،

00:08:39.493 --> 00:08:43.680
و به افراد مبتلا به اوتیسم نیز در قالبِ 
مترجم احساسات کمک کنند،

00:08:43.680 --> 00:08:46.458
مشکلی که واقعاً این افراد دارند با آن 
دست و پنجه نرم می‌کنند.

00:08:47.918 --> 00:08:50.777
در آموزش: اگر شما در حال یادگیری هستید،
اپلیکیشن‌ها

00:08:50.777 --> 00:08:53.587
سردرگمی شما را احساس می‌کنند
و سرعت‌شان کم می‌شود.

00:08:53.587 --> 00:08:55.444
یا اگر حوصله‌تان سر رفته
سرعت‌شان بالا می‌رود،

00:08:55.444 --> 00:08:58.413
مانند یک معلم عالی در کلاس درس.

00:08:59.043 --> 00:09:01.644
چه می‌شد اگر ساعت مچی شما 
احساساتتان را درک می‌کرد،

00:09:01.644 --> 00:09:04.337
یا ماشین‌تان می‌فهمید که شما خسته هستید،

00:09:04.337 --> 00:09:06.885
یا یخچال‌تان می‌فهمید که شما مضطرب هستید،

00:09:06.885 --> 00:09:12.951
و به‌طور خودکار بسته می‌شد تا 
از پرخوری شما جلوگیری کند. (خنده‌ی حضار)

00:09:12.951 --> 00:09:15.668
من این را دوست دارم، بله.

00:09:15.668 --> 00:09:17.595
چه می‌شد اگر زمانی که من در کمبریج بودم،

00:09:17.595 --> 00:09:19.908
به رشته‌ی احساسات بی‌درنگم دسترسی داشتم،

00:09:19.908 --> 00:09:23.437
و می‌توانستم آن را با خانواده‌ام در خانه
به صورت طبیعی در میان بگذارم،

00:09:23.437 --> 00:09:27.408
همان‌طور که انگار
با آن‌ها در یک اتاق هستم؟

00:09:27.408 --> 00:09:30.550
فکر می‌کنم که ۵ سال دیگر از الان،

00:09:30.550 --> 00:09:32.887
همه‌ی وسایل ما یک تراشه‌ی احساسات 
خواهند داشت،

00:09:32.887 --> 00:09:36.951
و ما دیگر زمانی را به‌یاد نمی‌آوریم 
که نمی‌توانستیم به وسیله‌مان اخم کنیم،

00:09:36.951 --> 00:09:41.200
و وسیله‌مان به ما می‌گوید: «هممم، 
این را دوست نداشتی، نه؟»

00:09:41.200 --> 00:09:44.961
بزرگ‌ترین چالش ما
کاربرد‌های زیاد این تکنولوژی است.

00:09:44.961 --> 00:09:47.864
من و تیمم به این نتیجه رسیدیم که نمی‌توانیم
همه‌ی اپلیکیشن‌ها را خودمان بسازیم،

00:09:47.864 --> 00:09:51.360
پس این تکنولوژی را در دسترس قرار دادیم 
تا سایر توسعه‌دهندگان

00:09:51.360 --> 00:09:53.474
بتوانند این برنامه‌ها را بسازند
و خلاق باشند.

00:09:53.474 --> 00:09:57.560
ما متوجه شدیم 
که امکان خطر

00:09:57.560 --> 00:09:59.627
و همچنین سؤاستفاده وجود دارد،

00:09:59.627 --> 00:10:02.576
ولی به‌شخصه، بعد از 
چندین سال انجام این کار،

00:10:02.576 --> 00:10:05.548
باور دارم که این تکنولوژی مزایایی برای
انسانیت دارد

00:10:05.548 --> 00:10:07.823
و داشتن تکنولوژی هوشمند احساسی

00:10:07.823 --> 00:10:11.399
ارزشمندتر امکان سؤاستفاده است.

00:10:11.399 --> 00:10:13.930
من شما را دعوت می‌کنم
که بخشی از این گفت‌و‌گو شوید.

00:10:13.930 --> 00:10:16.484
این که افراد بیشتری درباره‌ی
این تکنولوژی بدانند،

00:10:16.484 --> 00:10:19.661
کمک می‌کند تا بیشتر بتوانیم بگوییم که 
چگونه از آن استفاده می‌شود.

00:10:21.081 --> 00:10:25.655
همان‌طور که زندگی‌مان
بیشتر و بیشتر دیجیتالی می‌شود،

00:10:25.655 --> 00:10:29.153
در یک جنگ شکست خورده مبارزه می‌کنیم 
تا از استفاده از وسایل در زندگی‌مان کم کنیم

00:10:29.153 --> 00:10:31.382
به این منظور که احساساتمان را بازگردانیم.

00:10:32.622 --> 00:10:36.536
چیزی که من در عوض برایش تلاش می‌کنم این 
است که احساسات را به درون تکنولوژی بیاورم

00:10:36.536 --> 00:10:38.765
و کاری کنم که تکنولوژی‌هایمان پاسخ‌گوتر باشد.

00:10:38.765 --> 00:10:41.435
پس می‌خواهم وسایلی که ما را 
از هم جدا کرده‌اند،

00:10:41.435 --> 00:10:43.897
دوباره ما را به هم بازگردانند.

00:10:43.897 --> 00:10:48.485
با انسانی کردن تکنولوژی، 
این فرصت طلایی را داریم

00:10:48.485 --> 00:10:51.782
که دوباره درباره‌ی ارتباطمان
با ماشین‌ها فکر کنیم،

00:10:51.782 --> 00:10:56.263
و در نهایت، این که چگونه ما،
به عنوان انسان‌ها،

00:10:56.263 --> 00:10:58.167
با یکدیگر ارتباط برقرار می‌کنیم.

00:10:58.167 --> 00:11:00.327
متشکرم.

00:11:00.327 --> 00:11:03.640
(تشویق حضار)

