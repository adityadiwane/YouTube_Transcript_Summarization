WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Sebastian Betti
Revisor: Denise RQ

00:00:12.542 --> 00:00:16.542
Las emociones influyen en
cada aspecto de nuestras vidas,

00:00:16.573 --> 00:00:20.407
de la salud y el aprendizaje, a la forma
de hacer negocios y tomar decisiones,

00:00:20.408 --> 00:00:21.922
grandes y pequeñas.

00:00:22.667 --> 00:00:26.334
Las emociones influyen en la forma
en la cual interaccionamos entre nosotros.

00:00:27.132 --> 00:00:31.107
Hemos evolucionado para vivir
en un mundo como este,

00:00:31.108 --> 00:00:35.426
pero en cambio, vivimos la vida
cada vez más de esta manera

00:00:35.427 --> 00:00:38.560
--este es el mensaje de texto
que recibí de mi hija anoche--

00:00:38.561 --> 00:00:41.300
en un mundo desprovisto de emoción.

00:00:41.301 --> 00:00:43.251
Mi misión es cambiar esto.

00:00:43.252 --> 00:00:47.343
Quiero devolver las emociones
a nuestra experiencia digital.

00:00:48.223 --> 00:00:51.299
Empecé con esto hace 15 años.

00:00:51.300 --> 00:00:53.365
Era ingeniera informática en Egipto

00:00:53.366 --> 00:00:57.870
y fui aceptada en un programa de doctorado
en la Universidad de Cambridge.

00:00:57.871 --> 00:00:59.983
E hice algo bastante inusual

00:00:59.984 --> 00:01:04.209
para una joven recién casada,
egipcia y musulmana:

00:01:05.599 --> 00:01:08.597
con el apoyo de mi marido,
que debía quedarse en Egipto,

00:01:08.598 --> 00:01:11.615
hice las maletas y me mudé a Inglaterra.

00:01:11.616 --> 00:01:14.833
En Cambridge, a miles
de kilómetros de casa,

00:01:14.834 --> 00:01:18.251
me di cuenta de que estaba
pasando más horas con mi laptop

00:01:18.257 --> 00:01:20.485
que con otros seres humanos.

00:01:20.486 --> 00:01:25.338
Pero a pesar de esta intimidad, mi laptop
no tenía ni idea de mi estado de ánimo.

00:01:25.339 --> 00:01:28.541
No tenía idea de si yo era feliz,

00:01:28.542 --> 00:01:31.541
si tenía un mal día, o estaba
estresada o confundida,

00:01:31.542 --> 00:01:34.460
y eso era frustrante.

00:01:35.600 --> 00:01:40.831
Aun peor, cuando me comunicaba
en línea con mi familia en casa,

00:01:41.421 --> 00:01:44.702
sentía que todas mis emociones
desaparecían en el ciberespacio.

00:01:44.703 --> 00:01:49.857
Sentía nostalgia, estaba sola,
y algunos días lloraba,

00:01:49.858 --> 00:01:54.785
pero todo lo que tenía para
comunicar mis emociones era esto.

00:01:54.786 --> 00:01:56.805
(Risas)

00:01:56.806 --> 00:02:01.779
Hoy la tecnología es
inteligente pero no emocional

00:02:01.780 --> 00:02:04.955
mucha inteligencia cognitiva,
pero nada de inteligencia emocional.

00:02:04.956 --> 00:02:07.152
Eso me hizo pensar,

00:02:07.153 --> 00:02:10.776
¿y si la tecnología pudiera
interpretar nuestras emociones?

00:02:10.777 --> 00:02:14.852
¿Y si nuestros dispositivos pudieran
detectar y reaccionar en consecuencia,

00:02:14.853 --> 00:02:17.866
como lo harían los amigos
con inteligencia emocional?

00:02:18.666 --> 00:02:22.228
Esas preguntas me guiaron
a mí y a mi equipo

00:02:22.229 --> 00:02:26.606
a crear tecnologías capaces
de leer emociones y responder,

00:02:26.607 --> 00:02:29.697
y nuestro punto de partida
fue el rostro humano.

00:02:30.577 --> 00:02:33.749
Nuestro rostro es uno de
los canales más poderosos

00:02:33.750 --> 00:02:37.765
que usamos para comunicar
estados sociales y emocionales,

00:02:37.766 --> 00:02:40.776
todo, del disfrute y la sorpresa,

00:02:40.792 --> 00:02:44.978
a la empatía y la curiosidad.

00:02:44.979 --> 00:02:48.526
En la ciencia de las emociones, cada
movimiento de cada músculo facial,

00:02:48.527 --> 00:02:49.906
es una unidad de acción.

00:02:49.907 --> 00:02:52.831
Por ejemplo, la unidad de acción 12,

00:02:52.832 --> 00:02:54.869
no es una superproducción de Hollywood,

00:02:54.870 --> 00:02:58.311
es el tirón de la comisura labial,
componente principal de una sonrisa.

00:02:58.312 --> 00:03:01.299
Intenten todos. Sonriamos.

00:03:01.300 --> 00:03:03.153
Otro ejemplo es la unidad de acción 4,

00:03:03.154 --> 00:03:06.321
las líneas de expresión en el entrecejo
cuando juntamos las cejas

00:03:06.322 --> 00:03:08.458
y se forman estos pliegues y arrugas.

00:03:08.459 --> 00:03:12.753
No nos gustan, pero es una
fuerte señal de una emoción negativa.

00:03:12.754 --> 00:03:14.959
Hay unas 45 unidades de acción,

00:03:14.960 --> 00:03:18.349
y combinadas expresan
cientos de emociones,

00:03:18.350 --> 00:03:22.250
Enseñarle a una computadora a leer
estas emociones faciales es difícil,

00:03:22.251 --> 00:03:25.222
porque estas unidades de acción
pueden ser rápidas y sutiles,

00:03:25.223 --> 00:03:27.776
y se combinan de muchas formas.

00:03:27.777 --> 00:03:31.514
Tomemos por ejemplo
la sonrisa genuina y la socarrona.

00:03:31.515 --> 00:03:35.267
Se parecen pero expresan cosas diferentes.

00:03:35.268 --> 00:03:36.985
(Risas)

00:03:36.986 --> 00:03:39.529
La sonrisa genuina es positiva,

00:03:39.530 --> 00:03:41.519
la sonrisa socarrona a veces es negativa.

00:03:41.520 --> 00:03:45.135
A veces una mueca puede hacerte célebre.

00:03:45.136 --> 00:03:47.959
Pero en serio, es importante
para una computadora poder

00:03:47.960 --> 00:03:50.814
notar la diferencia entre
las dos expresiones.

00:03:50.815 --> 00:03:52.626
¿Cómo hacemos esto?

00:03:52.627 --> 00:03:54.723
Introducimos en el programa de computación

00:03:54.724 --> 00:03:58.523
decenas de miles de ejemplos
de personas que sonríen

00:03:58.524 --> 00:04:01.588
de distintas etnias, edades, géneros,

00:04:01.589 --> 00:04:04.399
y hacemos lo mismo con
las sonrisas socarronas.

00:04:04.400 --> 00:04:06.783
Luego, los algoritmos
en aprendizaje automático

00:04:06.784 --> 00:04:11.291
buscan estas lineas, pliegues
y cambios musculares faciales

00:04:11.292 --> 00:04:12.426
y básicamente aprenden

00:04:12.426 --> 00:04:15.366
que todas las sonrisas genuinas
tienen características comunes

00:04:15.366 --> 00:04:18.907
mientras que las sonrisas socarronas
tienen otras sensiblemente diferentes.

00:04:18.908 --> 00:04:22.160
Y la próxima vez que vean
un nuevo rostro, sabrán

00:04:22.161 --> 00:04:25.603
que este rostro tiene las mismas
características de una sonrisa genuina,

00:04:25.604 --> 00:04:28.980
y dirán: "Ajá, la reconozco.
Esta es la expresión de una sonrisa".

00:04:30.380 --> 00:04:33.459
Y la mejor manera de demostrar
cómo funciona esta tecnología

00:04:33.459 --> 00:04:35.316
es con una demo en vivo,

00:04:35.317 --> 00:04:39.229
para esto necesito un voluntario,
preferentemente alguien con un rostro.

00:04:39.230 --> 00:04:41.563
(Risas)

00:04:41.564 --> 00:04:44.335
Chloe será nuestra voluntaria de hoy.

00:04:45.334 --> 00:04:49.789
En los últimos 5 años, pasamos de ser
un proyecto de investigación en el MIT

00:04:49.790 --> 00:04:50.938
a ser una empresa,

00:04:50.939 --> 00:04:54.130
donde mi equipo ha trabajado
arduamente en esta tecnología,

00:04:54.131 --> 00:04:56.539
para que funcione fuera del laboratorio.

00:04:56.540 --> 00:04:59.919
Y la hemos compactado tanto como
para que el lector de las emociones

00:04:59.920 --> 00:05:02.980
funcione en un dispositivo móvil
con una cámara, como este iPad.

00:05:02.981 --> 00:05:04.918
Así que probémosla.

00:05:06.756 --> 00:05:10.679
Como pueden ver, el algoritmo
detectó el rostro de Chloe,

00:05:10.680 --> 00:05:12.371
es este cuadro delimitador blanco,

00:05:12.372 --> 00:05:15.282
que detecta los contornos principales
de sus rasgos faciales,

00:05:15.283 --> 00:05:17.798
sus cejas, sus ojos, su boca y nariz.

00:05:17.799 --> 00:05:20.785
La pregunta es:
¿puede reconocer su expresión?

00:05:20.786 --> 00:05:22.457
Vamos a probar la máquina.

00:05:22.459 --> 00:05:26.626
Ante todo, pon cara 
de póquer. Sí, genial. (Risas)

00:05:26.643 --> 00:05:29.885
Y a medida que sonríe --esta es
una sonrisa genuina, es genial--

00:05:29.886 --> 00:05:31.755
pueden ver como aumenta la barra verde.

00:05:31.756 --> 00:05:32.977
Esa fue una gran sonrisa.

00:05:32.978 --> 00:05:36.510
¿Puedes intentar una sonrisa sutil
para ver si la computadora la reconoce?

00:05:36.511 --> 00:05:38.351
También reconoce sonrisas sutiles.

00:05:38.352 --> 00:05:40.646
Hemos trabajado arduamente
para que esto suceda.

00:05:40.647 --> 00:05:43.438
Luego levanta una ceja,
que indica sorpresa.

00:05:43.439 --> 00:05:47.666
Frunce el ceño,
que indica la confusión.

00:05:47.667 --> 00:05:51.667
Enfurruñate. Sí, perfecto.

00:05:51.695 --> 00:05:55.187
Estas son diferentes unidades
de acción. Hay muchas más.

00:05:55.188 --> 00:05:57.219
Esta es solo una demo superficial.

00:05:57.220 --> 00:06:00.367
Llamamos a cada lectura
un dato emocional,

00:06:00.368 --> 00:06:03.646
que luego pueden actuar juntos
para crear distintas emociones.

00:06:03.647 --> 00:06:07.399
A la derecha de la demo,
parece que estás feliz.

00:06:07.400 --> 00:06:09.443
Eso es alegría. Se desata la alegría.

00:06:09.444 --> 00:06:11.371
Ahora pon cara de disgusto.

00:06:11.375 --> 00:06:15.642
Trata de recordar qué sentiste
cuando Zayn dejó One Direction.

00:06:15.643 --> 00:06:17.152
(Risas)

00:06:17.153 --> 00:06:21.495
Sí, arruga la nariz. Genial.

00:06:21.501 --> 00:06:25.225
La valencia es bastante negativa,
por lo que debe haber sido una gran fan.

00:06:25.226 --> 00:06:28.193
La valencia indica cuán positiva
o negativa es una experiencia,

00:06:28.193 --> 00:06:30.711
y la vinculación indica lo
expresiva que es también.

00:06:30.712 --> 00:06:34.335
Imaginen que Chloe tiene acceso a este
contenido emocional en tiempo real,

00:06:34.336 --> 00:06:36.934
y que puede compartir sus
emociones con quien quiere.

00:06:36.935 --> 00:06:38.497
Gracias.

00:06:38.498 --> 00:06:40.169
(Aplausos)

00:06:45.749 --> 00:06:51.018
Hasta ahora contamos con 12 000
millones de estos indicadores emocionales.

00:06:51.019 --> 00:06:53.628
Es la base de datos de emociones
más grande del mundo.

00:06:53.629 --> 00:06:56.835
La hemos recopilado a partir de
2,9 millones de rostros en videos,

00:06:56.842 --> 00:06:59.953
de personas que accedieron a compartir
sus emociones con nosotros,

00:06:59.953 --> 00:07:02.397
de 75 países del mundo.

00:07:02.398 --> 00:07:04.113
Crece cada día.

00:07:04.603 --> 00:07:06.669
Me resulta impactante

00:07:06.670 --> 00:07:09.864
que ahora podamos cuantificar algo
tan personal como las emociones,

00:07:09.865 --> 00:07:12.099
y poder hacerlo a esta escala.

00:07:12.100 --> 00:07:14.277
¿Qué hemos aprendido hasta la fecha?

00:07:15.057 --> 00:07:17.387
Hay diferencias por género.

00:07:17.388 --> 00:07:20.543
Nuestros datos confirman algo
que Uds. ya sospechaban.

00:07:20.544 --> 00:07:22.890
Las mujeres son más
expresivas que los hombres.

00:07:22.891 --> 00:07:25.573
No solo sonríen más,
sus sonrisas duran más,

00:07:25.574 --> 00:07:28.477
y ahora podemos cuantificar
cómo es que hombres y mujeres

00:07:28.478 --> 00:07:30.614
responden de maneras tan diferentes.

00:07:30.626 --> 00:07:32.903
Veamos culturalmente: en EE.UU.,

00:07:32.904 --> 00:07:36.108
las mujeres son un 40 %
más expresivas que los hombres,

00:07:36.125 --> 00:07:39.959
pero curiosamente, no vemos diferencia
entre hombres y mujeres en el R.U.

00:07:39.960 --> 00:07:42.259
(Risas)

00:07:43.296 --> 00:07:47.322
Por edad: las personas de 50 años o más

00:07:47.323 --> 00:07:50.759
son un 25 % más emotivos
que los más jóvenes.

00:07:51.918 --> 00:07:55.752
Las mujeres de veintipico sonríen mucho
más que los hombres de la misma edad,

00:07:55.753 --> 00:07:59.589
quizá es una necesidad para las citas.

00:07:59.590 --> 00:08:02.206
Pero quizá lo que más
nos sorprende de estos datos

00:08:02.207 --> 00:08:05.409
es que solemos ser
expresivos todo el tiempo,

00:08:05.410 --> 00:08:08.752
incluso cuando estamos sentados
solos frente a nuestros dispositivos

00:08:08.753 --> 00:08:11.487
y no solo cuando miramos
videos de gatos en Facebook.

00:08:12.209 --> 00:08:15.918
Somos expresivos cuando mandamos emails,
mensajes, cuando compramos en línea,

00:08:15.919 --> 00:08:17.526
o incluso pagando impuestos.

00:08:17.527 --> 00:08:19.918
¿Para qué se usan estos datos hoy?

00:08:19.919 --> 00:08:22.666
Para entender cómo nos
relacionamos con los medios,

00:08:22.667 --> 00:08:25.376
para entender la viralidad
y el comportamiento del voto;

00:08:25.396 --> 00:08:28.785
y también para dar poder
dotar de emoción a la tecnología,

00:08:28.786 --> 00:08:32.527
y quiero compartir algunos ejemplos
particularmente especiales para mi.

00:08:33.197 --> 00:08:35.904
Las gafas portátiles con lector
emotivo pueden ayudar

00:08:35.905 --> 00:08:39.492
a las personas con discapacidad visual
a leer los rostros de los demás,

00:08:39.493 --> 00:08:43.679
y a las personas del espectro autista
a interpretar pistas emocionales

00:08:43.680 --> 00:08:46.037
algo que les cuesta mucho.

00:08:47.918 --> 00:08:50.785
En educación, imaginen
si sus apps educativas

00:08:50.787 --> 00:08:53.586
detectaran que están confundidos
y bajaran la velocidad,

00:08:53.587 --> 00:08:55.442
o que están aburridos, y aceleraran,

00:08:55.443 --> 00:08:58.413
como haría un buen profesor en el aula.

00:08:59.043 --> 00:09:01.643
Y si una pulsera leyera su estado anímico,

00:09:01.644 --> 00:09:04.333
o el auto detectara que están cansados,

00:09:04.334 --> 00:09:07.252
o quizá si el frigorífico
supiera que están estresados,

00:09:07.292 --> 00:09:12.950
y se autobloqueara para
evitar atracones. (Risas)

00:09:12.951 --> 00:09:15.667
Me gustaría eso, sí.

00:09:15.668 --> 00:09:17.594
¿Y si, cuando estuve en Cambridge,

00:09:17.595 --> 00:09:20.627
hubiera tenido acceso en tiempo
real a mi contenido emocional

00:09:20.628 --> 00:09:24.216
y hubiera podido compartirlo con mi
familia en casa de manera muy natural,

00:09:24.217 --> 00:09:27.407
como si estuviéramos en
la misma habitación juntos?

00:09:27.408 --> 00:09:30.259
Creo que dentro de 5 años,

00:09:30.260 --> 00:09:33.076
todos los dispositivos tendrán
un chip lector de emociones

00:09:33.077 --> 00:09:36.950
y no recordaremos cómo era no poder
fruncir el ceño a nuestro dispositivo

00:09:36.951 --> 00:09:41.079
y que nuestro dispositivo dijera:
"Mmm, no te gusta, ¿no?"

00:09:41.080 --> 00:09:44.960
Nuestro desafío más grande es que hay
tantas aplicaciones para esta tecnología,

00:09:44.961 --> 00:09:48.323
que mi equipo y yo nos dimos cuenta
de que no podemos con todo solos,

00:09:48.324 --> 00:09:50.249
por eso liberamos esta tecnología

00:09:50.250 --> 00:09:53.473
para que otros desarrolladores
puedan desarrollarla y ser creativos.

00:09:53.474 --> 00:09:57.559
Reconocemos que hay riesgos potenciales

00:09:57.560 --> 00:09:59.626
y potencial para el abuso,

00:09:59.627 --> 00:10:02.575
pero en mi opinión, habiendo pasado
muchos años haciendo esto,

00:10:02.576 --> 00:10:05.377
creo que los beneficios para la humanidad

00:10:05.378 --> 00:10:07.892
de contar con tecnología
emocionalmente inteligente

00:10:07.893 --> 00:10:11.398
superan con creces las
desventajas por uso indebido.

00:10:11.399 --> 00:10:13.929
Y los invito a todos
a tomar parte en el debate.

00:10:13.930 --> 00:10:16.483
Cuantas más personas
conozcan esta tecnología,

00:10:16.484 --> 00:10:19.661
más podemos decir
sobre cómo se usa.

00:10:21.081 --> 00:10:25.654
Conforme nuestras vidas
se vuelven cada vez más digitales,

00:10:25.655 --> 00:10:29.152
estamos librando una batalla perdida
tratando de evitar los dispositivos

00:10:29.153 --> 00:10:31.382
para recuperar nuestras emociones.

00:10:32.622 --> 00:10:36.535
Por eso yo propongo, en cambio,
incorporar las emociones a la tecnología

00:10:36.536 --> 00:10:39.034
y hacer que nuestras tecnologías
sean más receptivas.

00:10:39.035 --> 00:10:41.434
Quiero que esos dispositivos
que nos han separado

00:10:41.435 --> 00:10:43.896
nos vuelvan a unir.

00:10:43.897 --> 00:10:48.484
Y humanizando la tecnología,
tenemos esta oportunidad excelente

00:10:48.485 --> 00:10:51.781
de reinventar la manera de
conectarnos con las máquinas,

00:10:51.782 --> 00:10:56.262
y por lo tanto, la manera de como
nosotros, los seres humanos,

00:10:56.263 --> 00:10:58.166
conectamos unos con otros.

00:10:58.167 --> 00:10:59.506
Gracias.

00:10:59.507 --> 00:11:01.190
(Aplausos)

