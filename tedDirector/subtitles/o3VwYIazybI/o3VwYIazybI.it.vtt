WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Letizia Pedicini
Revisore: Elena Montrasio

00:00:12.706 --> 00:00:16.353
Le emozioni influenzano
ogni aspetto delle nostre vite,

00:00:16.523 --> 00:00:19.963
dalla salute, da come impariamo,
al fare affari e a prendere decisioni,

00:00:20.149 --> 00:00:21.442
grandi e piccole.

00:00:22.452 --> 00:00:26.072
Le nostre emozioni influenzano anche
il modo di relazionarci l'un l'altro.

00:00:27.102 --> 00:00:30.418
Ci siamo evoluti per vivere
in un mondo così.

00:00:31.088 --> 00:00:35.317
Ma invece viviamo sempre più
le nostre vite così,

00:00:35.347 --> 00:00:38.571
- questo è il messaggio
di mia figlia la notte scorsa (risate) -

00:00:38.971 --> 00:00:41.141
in un mondo privo di emozioni.

00:00:41.251 --> 00:00:43.202
Perciò la mia missione
è cambiare le cose.

00:00:43.202 --> 00:00:46.933
Voglio riportare le emozioni
nelle nostre esperienze digitali.

00:00:48.223 --> 00:00:50.960
Ho intrapreso questo percorso
15 anni fa.

00:00:50.960 --> 00:00:53.526
Ero un'esperta di informatica in Egitto,

00:00:53.526 --> 00:00:57.661
da poco ammessa a un Dottorato
di Ricerca alla Cambridge University.

00:00:57.871 --> 00:00:59.984
Avevo fatto qualcosa 
di alquanto inusuale

00:00:59.984 --> 00:01:03.779
per una giovane moglie 
Musulmana Egiziana appena sposata.

00:01:03.949 --> 00:01:05.599
(Risate)

00:01:05.599 --> 00:01:08.538
Con il sostegno di mio marito,
che dovette restare in Egitto,

00:01:08.538 --> 00:01:10.986
feci i bagagli e mi trasferii
in Inghilterra.

00:01:11.616 --> 00:01:14.694
A Cambridge,
lontana migliaia di chilometri da casa,

00:01:14.844 --> 00:01:17.937
capii che trascorrevo
molte più ore col mio computer

00:01:17.937 --> 00:01:19.916
che con altri esseri umani.

00:01:20.376 --> 00:01:21.939
Eppure, nonostante l'intimità,

00:01:21.939 --> 00:01:25.209
il mio computer non aveva
assolutamente idea di come mi sentissi.

00:01:25.339 --> 00:01:27.490
Non sapeva se ero felice,

00:01:28.550 --> 00:01:31.628
se passavo una brutta giornata,
o ero stressata, confusa,

00:01:31.628 --> 00:01:33.320
e questo era frustrante.

00:01:35.550 --> 00:01:39.431
Ancora peggio, dato che comunicavo
online con la mia famiglia a casa,

00:01:41.281 --> 00:01:44.303
sentivo le mie emozioni
scomparire nello cyberspazio.

00:01:44.703 --> 00:01:49.498
Mi mancava casa, ero sola,
e alcuni giorni piangevo proprio,

00:01:49.838 --> 00:01:53.076
Ma tutto ciò che avevo per comunicare
queste emozioni

00:01:53.676 --> 00:01:56.596
era questo.
(Risate)

00:01:56.806 --> 00:02:00.990
La tecnologia oggigiorno ha tanto QI
ma non IE.

00:02:00.990 --> 00:02:04.476
Tanta intelligenza cognitiva,
ma nessuna Intelligenza Emotiva.

00:02:04.956 --> 00:02:06.843
E questo mi ha fatto pensare:

00:02:06.853 --> 00:02:11.057
e se la tecnologia potesse sentire
le nostre emozioni?

00:02:11.057 --> 00:02:13.317
Se i dispositivi sapessero
cosa proviamo

00:02:13.317 --> 00:02:14.853
e come reagiamo di conseguenza,

00:02:14.853 --> 00:02:17.776
come solo un amico
emotivamente intelligente farebbe?

00:02:18.666 --> 00:02:21.840
Queste domande
hanno portato me e il mio team

00:02:22.000 --> 00:02:25.897
a creare tecnologie che possono leggere
e reagire alle nostre emozioni.

00:02:26.607 --> 00:02:29.227
E il nostro punto di partenza
è stato il volto umano.

00:02:30.487 --> 00:02:33.840
Il nostro volto pare sia
uno dei più potenti canali

00:02:33.840 --> 00:02:37.496
che usiamo per comunicare
stati sociali ed emotivi.

00:02:37.706 --> 00:02:40.776
Qualsiasi cosa, dal piacere alla sorpresa,

00:02:41.256 --> 00:02:43.879
dall'empatia alla curiosità.

00:02:44.979 --> 00:02:49.637
In scienza delle emozioni ogni movimento muscolare è detto
"unità d'azione".

00:02:49.907 --> 00:02:52.242
Per esempio, l'unità d'azione 12,

00:02:52.272 --> 00:02:54.620
non è un film di successo di Hollywood,

00:02:54.620 --> 00:02:58.022
ma è il tirare l'angolo della bocca,
che è la base per un sorriso.

00:02:58.022 --> 00:03:00.380
Provateci tutti.
Fate partire qualche sorriso.

00:03:00.900 --> 00:03:02.814
Un altro esempio è l'unità d'azione 4,

00:03:02.814 --> 00:03:05.782
è il solco tra le sopracciglia,
quando le ravvicinate

00:03:05.782 --> 00:03:07.809
e create tutte quelle linee
e quelle rughette.

00:03:07.809 --> 00:03:11.664
Non ci piacciono, ma è un forte
segnale di un'emozione negativa.

00:03:11.944 --> 00:03:14.380
Ne abbiamo circa 45,
di queste unità d'azione,

00:03:14.410 --> 00:03:17.510
che si combinano per esprimere
centinaia di emozioni.

00:03:18.340 --> 00:03:21.831
Insegnare a un computer a leggere
queste espressioni facciali è difficile,

00:03:22.211 --> 00:03:25.213
perché le unità d'azione
possono essere veloci, impercettibili,

00:03:25.223 --> 00:03:27.247
e si combinano in tanti modi diversi.

00:03:27.627 --> 00:03:30.305
Prendiamo per esempio
un sorriso e una smorfia.

00:03:31.525 --> 00:03:33.198
Sembrano in qualche modo simili,

00:03:33.498 --> 00:03:36.526
ma hanno significati molto diversi.
(Risate)

00:03:36.986 --> 00:03:38.810
Il sorriso è positivo,

00:03:39.100 --> 00:03:40.920
una smorfia è spesso negativa.

00:03:40.920 --> 00:03:44.456
Qualche volta una smorfia
può farti diventare famoso. (Risate)

00:03:45.136 --> 00:03:47.900
Ma seriamente, è importante
per un computer essere in grado

00:03:47.900 --> 00:03:50.355
di distinguere la differenza
tra le due espressioni.

00:03:50.475 --> 00:03:52.097
Perciò come possiamo farlo?

00:03:52.197 --> 00:03:53.994
Diamo ai nostri algoritmi

00:03:54.044 --> 00:03:57.794
decine di migliaia di esempi
di persone che sappiamo sorridono,

00:03:58.524 --> 00:04:01.339
di diverse etnie, età, genere,

00:04:01.529 --> 00:04:03.460
e facciamo lo stesso per le smorfie.

00:04:04.090 --> 00:04:05.704
E poi, usando il Deep Learning,

00:04:05.894 --> 00:04:08.870
l'algoritmo cerca tutte queste
trame, queste rughe,

00:04:08.870 --> 00:04:11.090
e i mutamenti di forma sul nostro viso,

00:04:11.090 --> 00:04:14.442
e in pratica apprende che tutti i sorrisi
hanno caratteristiche comuni,

00:04:14.592 --> 00:04:17.443
tutte le smorfie hanno caratteristiche
leggermente diverse.

00:04:17.673 --> 00:04:19.781
E la prossima volta
che vede un viso nuovo,

00:04:20.001 --> 00:04:25.020
capisce che quel viso ha le stesse 
caratteristiche di un sorriso,

00:04:25.093 --> 00:04:28.581
e dice: "La riconosco.
È un'espressione sorridente".

00:04:30.271 --> 00:04:33.351
E il miglior modo per dimostrare
come funziona questa tecnologia

00:04:33.351 --> 00:04:35.197
è una dimostrazione dal vivo,

00:04:35.317 --> 00:04:38.820
perciò mi serve un volontario,
possibilmente qualcuno con una faccia.

00:04:38.820 --> 00:04:40.864
(Risate)

00:04:41.564 --> 00:04:43.785
Chloe sarà la nostra volontaria oggi.

00:04:45.325 --> 00:04:49.783
Negli ultimi cinque anni siamo passati
dall'essere un progetto di ricerca al MIT

00:04:49.783 --> 00:04:52.709
ad essere una società,
in cui il mio team ha lavorato sodo

00:04:52.709 --> 00:04:55.801
per far funzionare questa tecnologia,
noi diciamo, come bestie.

00:04:56.120 --> 00:04:59.210
E l'abbiamo anche compressa
così che il sistema emotivo centrale

00:04:59.210 --> 00:05:02.410
funzioni su tutti i dispositivi
con videocamera, come questo Ipad.

00:05:02.530 --> 00:05:04.146
Facciamo una prova.

00:05:06.756 --> 00:05:10.680
Come potete vedere, l'algoritmo
ha praticamente trovato il viso di Chloe,

00:05:10.680 --> 00:05:12.372
è questo riquadro bianco ai bordi,

00:05:12.372 --> 00:05:14.903
e sta tracciando i lineamenti
principali del suo viso,

00:05:14.903 --> 00:05:17.059
cioè sopracciglia, occhi,
bocca e naso.

00:05:17.779 --> 00:05:20.556
La domanda è:
riconosce le sue espressioni?

00:05:20.556 --> 00:05:22.007
Testiamo la macchina.

00:05:22.007 --> 00:05:24.133
Prima di tutto,
fai una faccia impassibile.

00:05:24.133 --> 00:05:26.643
Fantastico. (Risate)

00:05:26.643 --> 00:05:29.576
Poi se lei sorride,
è un sorriso sincero, va benissimo,

00:05:29.576 --> 00:05:31.646
vedete la linea verde salire se sorride.

00:05:31.646 --> 00:05:34.188
Quello era un gran sorriso,
puoi provare un sorrisetto

00:05:34.188 --> 00:05:37.221
per vedere se il computer lo riconosce?
Riconosce anche quelli.

00:05:37.221 --> 00:05:39.267
Abbiamo lavorato duramente
per riuscirci.

00:05:39.607 --> 00:05:43.239
E ora sopracciglia alzate,
indice di sorpresa. (Risate)

00:05:43.439 --> 00:05:47.688
Accigliata, 
che è indice di confusione. (Risate)

00:05:47.688 --> 00:05:51.695
Corrucciata, perfetto.
(Risate)

00:05:51.695 --> 00:05:54.668
Sono tutte unità d'azione
diverse, e ce ne sono tante altre.

00:05:54.668 --> 00:05:56.710
Questa è solo una demo compressa.

00:05:56.910 --> 00:06:00.048
Ma chiamiamo ogni interpretazione
"punto dati dell'emozione",

00:06:00.368 --> 00:06:03.367
e possono accendersi insieme
e descrivere emozioni differenti,

00:06:03.367 --> 00:06:06.910
sul lato destro della demo.
Sembri felice.

00:06:07.220 --> 00:06:09.144
C'è gioia. E "Joy" si accende.

00:06:09.444 --> 00:06:11.241
Poi fai una faccia disgustata.

00:06:11.241 --> 00:06:14.763
Prova a ricordare com'è stato
quando Zayn ha lasciato i One Direction.

00:06:14.763 --> 00:06:16.573
(Risate)

00:06:16.573 --> 00:06:20.035
Arriccia il naso. Fantastico.
(Risate)

00:06:21.495 --> 00:06:25.046
La valenza è abbastanza negativa,
devi essere stata una grande fan.

00:06:25.046 --> 00:06:27.926
"Valence" è quanto positiva
o negativa sia un'esperienza,

00:06:27.926 --> 00:06:30.452
ed "engagement" indica
quanto lei è espressiva.

00:06:30.712 --> 00:06:34.256
Immaginate se Chloe entrasse
in questo flusso emotivo in tempo reale

00:06:34.256 --> 00:06:36.755
e potesse condividerlo
con chiunque volesse.

00:06:36.855 --> 00:06:38.238
Grazie.

00:06:38.268 --> 00:06:42.889
(Applausi)

00:06:45.749 --> 00:06:50.809
Ad oggi abbiamo accumulato 12 miliardi
di questi punti dati dell'emozione.

00:06:50.819 --> 00:06:53.140
È il più vasto database di emozioni
al mondo.

00:06:53.170 --> 00:06:56.383
Lo abbiamo messo insieme
da 2,9 milioni di video facciali,

00:06:56.593 --> 00:06:59.193
persone che hanno condiviso
le loro emozioni con noi,

00:06:59.193 --> 00:07:02.228
e da 75 Paesi di tutto il mondo.

00:07:02.268 --> 00:07:03.783
E si arricchisce ogni giorno.

00:07:04.593 --> 00:07:08.270
Mi sbalordisce che oggi
possiamo misurare qualcosa

00:07:08.270 --> 00:07:09.985
di così personale come le emozioni,

00:07:09.985 --> 00:07:11.850
e possiamo farlo così ampiamente.

00:07:11.970 --> 00:07:14.137
Cosa abbiamo quindi imparato
a determinare?

00:07:15.057 --> 00:07:16.248
Il genere.

00:07:17.328 --> 00:07:20.934
I nostri dati confermano qualcosa
di cui potete sospettare. (Risate)

00:07:20.934 --> 00:07:22.891
Le donne sono più espressive
degli uomini.

00:07:22.891 --> 00:07:25.574
Non solo sorridono di più
ma i loro sorrisi durano di più

00:07:25.574 --> 00:07:28.478
e possiamo davvero determinare
a cosa uomini e donne

00:07:28.478 --> 00:07:30.094
reagiscono in modo differente.

00:07:30.614 --> 00:07:32.904
Vediamo culturalmente.
Negli Stati Uniti

00:07:32.904 --> 00:07:35.828
le donne sono per il 40 %
più espressive degli uomini,

00:07:35.988 --> 00:07:39.753
ma -strano- non c'è alcuna differenza
nel Regno Unito tra uomini e donne.

00:07:39.753 --> 00:07:42.019
(Risate)

00:07:43.296 --> 00:07:47.323
Età: le persone dai 50 anni in su

00:07:47.323 --> 00:07:50.269
sono per il 25 % più emotive
dei più giovani.

00:07:51.519 --> 00:07:55.541
Le donne ventenni sorridono
molto più degli uomini della stessa età,

00:07:55.621 --> 00:07:57.960
forse per necessità relazionali.

00:07:59.510 --> 00:08:02.007
Ma forse ciò che ci ha sorpresi di più
in questi dati

00:08:02.007 --> 00:08:05.260
è che ci ritroviamo a essere
espressivi in ogni momento,

00:08:05.260 --> 00:08:07.973
anche quando siamo seduti
da soli coi nostri dispositivi,

00:08:08.163 --> 00:08:11.307
non solo quando stiamo guardando
video di gatti su Facebook.

00:08:11.987 --> 00:08:15.077
Siamo espressivi quando inviamo email,
messaggi, compriamo online,

00:08:15.077 --> 00:08:16.757
o anche calcolando le tasse.

00:08:17.627 --> 00:08:19.659
Per cosa sono usati questi dati oggi?

00:08:19.919 --> 00:08:22.312
Per capire come ci relazioniamo
coi media,

00:08:22.312 --> 00:08:24.846
cioè comprendere la viralità
e la modalità di scelta;

00:08:25.166 --> 00:08:28.606
e anche per dare potere
o attivare emotivamente la tecnologia.

00:08:28.606 --> 00:08:32.067
Voglio condividere alcuni esempi
particolarmente vicini al mio cuore.

00:08:33.197 --> 00:08:36.265
Occhiali abilitati all'emozione
possono aiutare gli individui

00:08:36.265 --> 00:08:39.263
con problemi di vista
a leggere i volti degli altri,

00:08:39.463 --> 00:08:43.050
e possono aiutare individui con tendenza
autistica a interpretare emozioni

00:08:43.050 --> 00:08:45.148
qualcosa con cui combattono realmente.

00:08:47.508 --> 00:08:50.897
Nell'istruzione, immaginate
se la vostra app per l'apprendimento

00:08:50.897 --> 00:08:53.347
capisse che siete confusi
e rallentasse,

00:08:53.347 --> 00:08:55.444
o che siete annoiati,
così da accelerare,

00:08:55.444 --> 00:08:57.853
proprio come farebbe
un bravo insegnante in classe.

00:08:58.873 --> 00:09:01.644
Se il vostro orologio tracciasse
il vostro umore,

00:09:01.644 --> 00:09:03.947
o se l'auto sentisse che siete stanchi,

00:09:04.257 --> 00:09:06.885
o magari il vostro frigo
sapesse che siete stressati,

00:09:06.885 --> 00:09:11.001
così da bloccarsi automaticamente
per evitarvi un'abbuffata. (Risate)

00:09:11.001 --> 00:09:13.718
A me piacerebbe. (Risate)

00:09:15.668 --> 00:09:17.515
E se, quando ero a Cambridge,

00:09:17.515 --> 00:09:19.908
fossi entrata nel mio flusso
emotivo in tempo reale

00:09:19.908 --> 00:09:23.437
e avessi potuto condividerlo
con la mia famiglia in modo spontaneo,

00:09:23.437 --> 00:09:26.708
come avrei fatto se fossimo stati insieme
nella stessa stanza?

00:09:27.408 --> 00:09:30.140
Credo che nel giro di cinque anni

00:09:30.160 --> 00:09:32.797
tutti i dispositivi avranno
un chip per le emozioni,

00:09:32.887 --> 00:09:35.951
e non ricorderemo com'era quando
non potevamo guardar male

00:09:35.951 --> 00:09:40.120
il nostro dispositivosenza che dicesse:
"Non ti piaceva, vero?

00:09:41.140 --> 00:09:44.751
La grande sfida è che ci sono così tante
applicazioni di questa tecnologia

00:09:44.751 --> 00:09:47.804
che io e il mio team sappiamo
di non poter realizzare da soli.

00:09:47.804 --> 00:09:51.110
Perciò l'abbiamo resa disponibile
così che altri sviluppatori

00:09:51.110 --> 00:09:53.194
possano svilupparla ed essere creativi.

00:09:53.474 --> 00:09:57.560
Ammettiamo che ci sono
rischi potenziali

00:09:57.560 --> 00:09:59.247
e la possibilità di abuso,

00:09:59.627 --> 00:10:02.266
ma personalmente, avendo passato
tanti anni a farlo,

00:10:02.326 --> 00:10:05.078
credo che i benefici per l'uomo

00:10:05.078 --> 00:10:07.463
nell'avere una tecnologia
emotivamente intelligente

00:10:07.573 --> 00:10:10.959
siano di gran lunga maggiori
del potenziale uso improprio.

00:10:11.179 --> 00:10:13.800
E vi invito a essere tutti
parte della conversazione.

00:10:13.800 --> 00:10:16.244
Più persone conoscono
questa tecnologia,

00:10:16.314 --> 00:10:19.351
più possiamo tutti avere voce 
su come va usata.

00:10:21.081 --> 00:10:25.155
Dato che sempre più le nostre vite
diventano digitali,

00:10:25.655 --> 00:10:29.153
combattiamo una battaglia persa
cercando di frenare l'uso dei dispositivi

00:10:29.153 --> 00:10:31.382
per ritrovare le nostre emozioni.

00:10:32.532 --> 00:10:36.566
Quello che invece cerco di fare è portare
le emozioni nella nostra tecnologia

00:10:36.566 --> 00:10:38.585
e renderla più reattiva.

00:10:38.585 --> 00:10:41.195
Voglio che quei dispositivi
che ci hanno divisi

00:10:41.345 --> 00:10:43.047
ci uniscano di nuovo.

00:10:44.207 --> 00:10:48.275
E umanizzando la tecnologia
abbiamo un'opportunità d'oro

00:10:48.485 --> 00:10:51.632
per ripensare a come siamo connessi
con le macchine,

00:10:51.992 --> 00:10:55.943
e quindi a come, in quanto esseri umani,

00:10:56.163 --> 00:10:57.887
siamo connessi agli altri.

00:10:58.037 --> 00:10:59.047
Grazie.

00:10:59.047 --> 00:11:02.750
(Applausi)

