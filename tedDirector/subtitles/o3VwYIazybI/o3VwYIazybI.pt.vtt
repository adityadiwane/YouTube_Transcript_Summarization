WEBVTT
Kind: captions
Language: pt

00:00:00.000 --> 00:00:07.000
Tradutor: Gustavo Rocha
Revisor: Maricene Crus

00:00:12.556 --> 00:00:16.573
Nossos sentimentos influenciam
todos os aspectos de nossas vidas,

00:00:16.573 --> 00:00:20.149
desde nossa saúde e aprendizado
até como fazemos negócios e decisões,

00:00:20.149 --> 00:00:21.922
grandes ou pequenas.

00:00:22.482 --> 00:00:26.162
Nossos sentimentos também influenciam
como nos conectamos.

00:00:26.912 --> 00:00:31.108
Nós evoluímos para viver
num mundo como esse,

00:00:31.108 --> 00:00:35.427
mas em vez disso, cada vez mais
vivemos nossas vidas assim;

00:00:35.427 --> 00:00:38.561
esta mensagem
da minha filha ontem à noite;

00:00:38.561 --> 00:00:41.301
em um mundo desprovido de sentimentos.

00:00:41.301 --> 00:00:43.252
Eu estou numa missão para mudar isso.

00:00:43.252 --> 00:00:47.343
Quero recolocar os sentimentos
em nossas vidas digitais.

00:00:48.223 --> 00:00:51.300
Eu comecei essa jornada há 15 anos.

00:00:51.300 --> 00:00:53.366
Eu era cientista da computação no Egito,

00:00:53.366 --> 00:00:57.871
e tinha acabado de ser aceita
em um Ph.D. na Universidade de Cambridge.

00:00:57.871 --> 00:00:59.984
Então fiz algo bem inusitado

00:00:59.984 --> 00:01:02.599
para uma jovem esposa
egípcia muçulmana recém-casada:

00:01:02.599 --> 00:01:05.599
(Risos)

00:01:05.599 --> 00:01:08.598
Com o apoio de meu marido,
que teve que ficar no Egito,

00:01:08.598 --> 00:01:11.616
eu arrumei minhas malas
e me mudei para a Inglaterra.

00:01:11.616 --> 00:01:14.844
Em Cambridge, milhares
de quilômetros longe de casa,

00:01:14.844 --> 00:01:17.927
eu percebi que passava
mais tempo com meu laptop

00:01:17.927 --> 00:01:20.486
do que com qualquer outro ser humano.

00:01:20.486 --> 00:01:22.099
E apesar desta intimidade,

00:01:22.099 --> 00:01:25.339
meu laptop não tinha a menor ideia
de como eu me sentia.

00:01:25.339 --> 00:01:28.550
Não tinha ideia se eu estava feliz,

00:01:28.550 --> 00:01:31.538
se num dia ruim, estressada, confusa,

00:01:31.538 --> 00:01:34.460
e isso acabou ficando frustrante.

00:01:35.600 --> 00:01:40.831
Pior ainda, enquanto eu me comunicava
online com a minha família em casa,

00:01:41.211 --> 00:01:44.703
eu sentia que todos os meus sentimentos
desapareciam no cyberespaço.

00:01:44.703 --> 00:01:49.858
Eu sentia saudades, estava sozinha,
e alguns até mesmo chorava,

00:01:49.858 --> 00:01:54.786
mas tudo que eu tinha
para expressar esses sentimentos era isto.

00:01:54.786 --> 00:01:56.806
(Risos)

00:01:56.806 --> 00:02:01.780
A tecnologia atual tem muito QI,
mas nenhum QE;

00:02:01.780 --> 00:02:04.956
muita inteligência cognitiva,
mas nenhuma inteligência emocional.

00:02:04.956 --> 00:02:07.153
E isso me fez pensar,

00:02:07.153 --> 00:02:10.777
e se nossa tecnologia pudesse
perceber nossos sentimentos?

00:02:10.777 --> 00:02:12.843
E se nossos dispositivos pudessem perceber

00:02:12.843 --> 00:02:14.853
como nos sentimos e reagissem de acordo,

00:02:14.853 --> 00:02:17.866
como um amigo
emocionalmente inteligente faria?

00:02:18.666 --> 00:02:22.230
Essas questões fizeram
com que eu e minha equipe

00:02:22.230 --> 00:02:26.607
criássemos tecnologias que pudessem
ler e reagir aos nossos sentimentos,

00:02:26.607 --> 00:02:29.697
e nosso ponto de partida
foi o rosto humano.

00:02:30.577 --> 00:02:33.750
Nosso rosto humano
é um dos canais mais poderosos

00:02:33.750 --> 00:02:37.766
que todos nós usamos para comunicar
estados sociais e emocionais,

00:02:37.766 --> 00:02:40.776
tudo desde alegria, surpresa,

00:02:40.776 --> 00:02:44.979
empatia e curiosidade.

00:02:44.979 --> 00:02:46.407
Na ciência dos sentimentos,

00:02:46.407 --> 00:02:49.907
nós chamamos cada movimento
muscular facial de unidade de ação.

00:02:49.907 --> 00:02:52.832
Por exemplo, unidade de ação 12,

00:02:52.832 --> 00:02:54.720
não é um filme de Holywood,

00:02:54.720 --> 00:02:56.610
é sim uma fisgada no canto dos lábios,

00:02:56.610 --> 00:02:58.682
que é o principal
componente de um sorriso.

00:02:58.682 --> 00:03:01.300
Tentem vocês.
Vamos mostrar alguns sorrisos.

00:03:01.300 --> 00:03:04.174
Outro exemplo é a unidade de ação 4.
Que é a testa franzida.

00:03:04.174 --> 00:03:06.192
É quando você junta as sobrancelhas

00:03:06.192 --> 00:03:08.069
e cria todas estas texturas e dobras.

00:03:08.069 --> 00:03:09.374
Não gostamos disso,

00:03:09.374 --> 00:03:11.934
mas é um forte indicador
de um sentimento negativo.

00:03:11.934 --> 00:03:14.680
Temos cerca de 45 dessas unidades de ação,

00:03:14.680 --> 00:03:18.350
e elas se combinam para expressar
centenas de sentimentos.

00:03:18.350 --> 00:03:22.031
Ensinar um computador a ler
essas emoções faciais é difícil,

00:03:22.031 --> 00:03:25.223
porque essas unidades de ação
podem ser rápidas, elas são sutis,

00:03:25.223 --> 00:03:27.777
e se combinam
de várias maneiras diferentes.

00:03:27.777 --> 00:03:31.515
Então peguem, por exemplo,
o sorriso genuíno e o malicioso.

00:03:31.515 --> 00:03:35.268
Eles se parecem de certa maneira,
mas querem dizer coisas bem diferentes.

00:03:35.268 --> 00:03:36.986
(Risos)

00:03:36.986 --> 00:03:40.880
O sorriso genuíno é positivo,
o malicioso normalmente é negativo.

00:03:40.880 --> 00:03:45.226
Às vezes um sorriso malicioso
pode torná-lo famoso.

00:03:45.226 --> 00:03:47.960
Mas falando sério, é importante
que um computador consiga

00:03:47.960 --> 00:03:50.435
diferenciar essas duas expressões.

00:03:50.435 --> 00:03:52.317
Então, como fazemos?

00:03:52.317 --> 00:03:54.414
Nós damos ao nosso algoritmo

00:03:54.414 --> 00:03:56.514
dezenas de milhares de exemplos de pessoas

00:03:56.514 --> 00:03:58.524
que sabemos que estão sorrindo,

00:03:58.524 --> 00:04:01.589
de diferentes etnias, idades e gêneros,

00:04:01.589 --> 00:04:04.230
e fazemos o mesmo
para sorrisos maliciosos.

00:04:04.230 --> 00:04:06.114
E assim, usando aprendizagem profunda,

00:04:06.114 --> 00:04:08.810
o algoritmo busca
todas essas texturas e dobras

00:04:08.810 --> 00:04:11.170
e mudanças de forma em nosso rosto

00:04:11.170 --> 00:04:14.402
e aprende que todos os sorrisos genuínos
têm características em comum,

00:04:14.402 --> 00:04:16.002
todos os sorrisos maliciosos

00:04:16.002 --> 00:04:17.993
têm características
sutilmente diferentes.

00:04:17.993 --> 00:04:20.161
E da próxima vez
que ele vir um novo rosto,

00:04:20.161 --> 00:04:22.440
ele aprende que

00:04:22.440 --> 00:04:25.473
esse rosto tem as mesmas
características de um sorriso genuíno,

00:04:25.473 --> 00:04:29.751
Ele pensa: "Aha, este eu reconheço.
É uma expressão de sorriso genuíno."

00:04:30.381 --> 00:04:33.181
E a melhor maneira de mostrar
que essa tecnologia funciona

00:04:33.181 --> 00:04:35.317
é fazer uma demonstração ao vivo,

00:04:35.317 --> 00:04:39.230
então vou precisar de um voluntário,
de preferência alguém com um rosto.

00:04:39.230 --> 00:04:41.564
(Risos)

00:04:41.564 --> 00:04:44.335
A Cloe vai ser nossa voluntária hoje.

00:04:45.325 --> 00:04:47.003
Durante os últimos cinco anos,

00:04:47.003 --> 00:04:49.653
nós passamos de um projeto
de pesquisa no MIT

00:04:49.653 --> 00:04:50.939
para uma empresa,

00:04:50.939 --> 00:04:52.619
na qual minha equipe trabalhou duro

00:04:52.619 --> 00:04:54.521
para fazer essa tecnologia funcionar,

00:04:54.521 --> 00:04:56.540
como gostamos de dizer, no meio selvagem.

00:04:56.540 --> 00:04:57.800
E nós também a minimizamos

00:04:57.800 --> 00:04:59.870
para que o mecanismo central
de sentimentos

00:04:59.870 --> 00:05:02.530
funcione em qualquer
dispositivo móvel, como este iPad.

00:05:02.530 --> 00:05:04.976
Então vamos testar.

00:05:06.516 --> 00:05:10.380
Como podem ver, o algoritmo essencialmente
encontrou o rosto da Cloe,

00:05:10.380 --> 00:05:12.312
é essa caixa branca delimitadora,

00:05:12.312 --> 00:05:15.122
e está acompanhando 
os pontos característicos em seu rosto,

00:05:15.122 --> 00:05:17.959
as sobrancelhas, olhos, boca, e nariz.

00:05:17.959 --> 00:05:20.586
A questão é: será que consegue
reconhecer sua expressão?

00:05:20.586 --> 00:05:22.387
Vamos testar a máquina.

00:05:22.387 --> 00:05:26.493
Primeiro, faça uma cara de blefe.
Isso, ótimo! (Risos)

00:05:26.493 --> 00:05:29.336
E à medida que ela sorri,
esse sorriso é genuíno, muito bom.

00:05:29.336 --> 00:05:31.856
Podemos ver a barra verde
aumentar enquanto ela sorri.

00:05:31.856 --> 00:05:33.378
Foi um grande sorriso.

00:05:33.378 --> 00:05:36.411
Pode tentar um sorriso sutil
para ver se o computador reconhece?

00:05:36.411 --> 00:05:39.902
Também reconhece sorrisos sutis. 
Trabalhamos muito que isso acontecesse.

00:05:39.902 --> 00:05:43.439
As sobrancelhas levantadas,
o que indica surpresa.

00:05:43.439 --> 00:05:47.688
Testa franzida, o que indica confusão.

00:05:47.688 --> 00:05:51.695
Cara fechada. Isso, perfeito.

00:05:51.695 --> 00:05:55.188
Essas são as diferentes unidades de ação.
Há muitas outras.

00:05:55.188 --> 00:05:57.220
Esta é só uma curta demonstração.

00:05:57.220 --> 00:06:00.258
Mas cada leitura é chamada
de ponto de dados de sentimento,

00:06:00.258 --> 00:06:03.957
e eles podem ser ativados ao mesmo tempo
para retratar diferentes sentimentos.

00:06:03.957 --> 00:06:07.990
Do lado direito da demonstração...
Parece que você está feliz.

00:06:07.990 --> 00:06:09.604
Isto é alegria. A alegria acende.

00:06:09.604 --> 00:06:11.371
E faça uma cara de nojo.

00:06:11.371 --> 00:06:15.643
Tente se lembrar como foi
quando Zayn saiu do One Direction.

00:06:15.643 --> 00:06:17.153
(Risos)

00:06:17.153 --> 00:06:20.545
Isso, torça o nariz. Ótimo.

00:06:21.495 --> 00:06:25.226
E a valência é bastante negativa,
você deve ser uma grande fã.

00:06:25.226 --> 00:06:27.926
Valência é quão positiva
ou negativa é uma sensação,

00:06:27.926 --> 00:06:30.542
e engajamento indica
a expressividade também.

00:06:30.542 --> 00:06:34.206
Imaginem se a Cloe tivesse acesso
a esse fluxo de sentimentos em tempo real,

00:06:34.206 --> 00:06:36.935
e pudesse compartilhar
com quem ela quisesse.

00:06:36.935 --> 00:06:38.858
Obrigada.

00:06:38.858 --> 00:06:41.479
(Aplausos)

00:06:45.749 --> 00:06:51.019
Até agora já acumulamos 12 bilhões
de pontos de dados de sentimentos.

00:06:51.019 --> 00:06:53.630
É o maior banco de dados
de sentimentos do mundo.

00:06:53.630 --> 00:06:56.543
Nós os conseguimos
de 2,9 milhões de vídeos de rostos,

00:06:56.543 --> 00:06:59.693
pessoas que aceitaram compartilhar
seus sentimentos conosco,

00:06:59.693 --> 00:07:02.398
e de 75 países por todo o mundo.

00:07:02.398 --> 00:07:04.113
Está crescendo a cada dia.

00:07:04.603 --> 00:07:06.370
Me deixa sem palavras

00:07:06.370 --> 00:07:09.795
que agora podemos quantificar
algo tão pessoal como nossos sentimentos,

00:07:09.795 --> 00:07:12.100
e podemos fazê-lo nessa escala.

00:07:12.100 --> 00:07:14.277
E o que já aprendemos?

00:07:15.057 --> 00:07:16.788
Gênero.

00:07:17.388 --> 00:07:20.864
Nossos dados confirmam uma coisa
que talvez vocês suspeitem.

00:07:20.864 --> 00:07:22.891
Mulheres são mais expressivas que homens.

00:07:22.891 --> 00:07:25.574
Elas não só sorriem mais,
seus sorrisos duram mais,

00:07:25.574 --> 00:07:28.858
e agora conseguimos quantificar
o que faz com que homens e mulheres

00:07:28.858 --> 00:07:30.614
reajam de maneira diferente.

00:07:30.614 --> 00:07:32.904
Vamos falar de cultura: 
nos Estados Unidos,

00:07:32.904 --> 00:07:36.108
as mulheres são 40%
mais expressivas que os homens,

00:07:36.108 --> 00:07:38.518
mas curiosamente não vemos
nenhuma diferença

00:07:38.518 --> 00:07:40.583
no Reino Unido entre homens e mulheres.

00:07:40.583 --> 00:07:42.259
(Risos)

00:07:43.296 --> 00:07:47.323
Idade: pessoas com 50 anos ou mais

00:07:47.323 --> 00:07:50.759
são 25% mais emotivas
do que os mais jovens.

00:07:51.469 --> 00:07:55.751
Mulheres na casa dos 20 sorriem muito mais
do que homens com a mesma idade,

00:07:55.751 --> 00:07:59.360
talvez uma necessidade para namorar.

00:07:59.360 --> 00:08:02.207
Mas talvez o que mais
nos surpreendeu nesses dados

00:08:02.207 --> 00:08:05.410
é que somos expressivos o tempo todo,

00:08:05.410 --> 00:08:08.243
mesmo quando estamos sozinhos
com nossos dispositivos,

00:08:08.243 --> 00:08:11.517
e não é só quando estamos
assistindo vídeos de gatos no Facebook.

00:08:11.847 --> 00:08:15.417
Somos expressivos quando escrevemos
e-mails, mensagens, fazemos compras,

00:08:15.417 --> 00:08:17.527
ou até mesmo declarando os impostos.

00:08:17.527 --> 00:08:19.919
Onde esses dados são usados hoje?

00:08:19.919 --> 00:08:22.682
Para entender como
interagimos com a mídia,

00:08:22.682 --> 00:08:25.166
entender viralidade
e comportamento de votação;

00:08:25.166 --> 00:08:27.906
e também capacitar e incluir
sentimentos na tecnologia,

00:08:27.906 --> 00:08:32.527
e eu gostaria de mostrar alguns 
dos meus exemplos preferidos.

00:08:33.197 --> 00:08:36.265
Óculos que conseguem ler sentimentos
podem ajudar

00:08:36.265 --> 00:08:39.493
pessoas com deficiência visual
a ler os rostos dos outros

00:08:39.493 --> 00:08:43.680
e pode ajudar pessoas no espectro
do autismo a interpretar sentimentos,

00:08:43.680 --> 00:08:46.458
algo com que têm muita dificuldade.

00:08:47.918 --> 00:08:50.777
Na educação, imagine
se seus aplicativos de ensino

00:08:50.777 --> 00:08:53.587
perceberem que você
está confuso e desacelerarem,

00:08:53.587 --> 00:08:55.444
ou que você está
entediado e acelerarem,

00:08:55.444 --> 00:08:58.413
assim como faria um bom
professor em sala de aula.

00:08:59.043 --> 00:09:01.644
E se seu relógio de pulso
acompanhasse seu humor

00:09:01.644 --> 00:09:04.337
ou seu carro percebesse
que você está cansado,

00:09:04.337 --> 00:09:07.315
ou talvez sua geladeira saiba
que você está estressada,

00:09:07.315 --> 00:09:11.421
e se tranca sozinha 
para que você não coma demais. (Risos)

00:09:11.421 --> 00:09:14.218
Eu gostaria disso, sim.

00:09:15.528 --> 00:09:17.135
E se, quando eu estava em Cambridge,

00:09:17.135 --> 00:09:20.018
eu tivesse acesso ao meu fluxo
de sentimentos em tempo real,

00:09:20.018 --> 00:09:21.358
e pudesse compartilhá-lo

00:09:21.358 --> 00:09:23.757
com a minha família em casa
de maneira natural,

00:09:23.757 --> 00:09:27.408
assim como eu faria se estivéssemos
todos juntos na sala?

00:09:27.408 --> 00:09:30.020
Acredito que daqui a cinco anos,

00:09:30.020 --> 00:09:32.887
todos os nossos dispositivos
vão ter um chip de sentimentos,

00:09:32.887 --> 00:09:34.501
e nem vamos nos lembrar como era

00:09:34.501 --> 00:09:37.411
quando não adiantava fazer cara feia
para o dispositivo

00:09:37.411 --> 00:09:41.200
e ele diria: "Hm, você não
gostou disso, né?"

00:09:41.200 --> 00:09:44.711
Nosso maior desafio é que há tantas
aplicações para essa tecnologia,

00:09:44.711 --> 00:09:48.024
que minha equipe percebeu
que não podemos satisfazê-las sozinhos,

00:09:48.024 --> 00:09:51.360
então nós disponibilizamos essa tecnologia
a outros desenvolvedores

00:09:51.360 --> 00:09:53.474
para que construam e usem a criatividade.

00:09:53.474 --> 00:09:57.560
Nós reconhecemos que há potenciais riscos

00:09:57.560 --> 00:09:59.627
e potencial para abuso,

00:09:59.627 --> 00:10:02.576
mas pessoalmente, 
após muitos anos fazendo isso,

00:10:02.576 --> 00:10:04.978
acredito que os benefícios à humanidade

00:10:04.978 --> 00:10:07.823
de ter tecnologia
emocionalmente inteligente

00:10:07.823 --> 00:10:11.399
superam de longe o potencial de abuso.

00:10:11.399 --> 00:10:13.930
E eu os convido todos
a participarem da conversa.

00:10:13.930 --> 00:10:16.484
Quanto mais pessoas
conhecerem essa tecnologia,

00:10:16.484 --> 00:10:19.661
mais peso terá nossa opinião
sobre como usá-la.

00:10:21.081 --> 00:10:25.655
E à medida que nossas vidas
vão se digitalizando,

00:10:25.655 --> 00:10:29.153
nós lutamos uma batalha perdida
tentando frear nosso uso de dispositivos

00:10:29.153 --> 00:10:31.382
para reivindicar nossos sentimentos.

00:10:32.622 --> 00:10:36.536
Então o que estou tentando fazer
é colocar sentimentos na tecnologia

00:10:36.536 --> 00:10:38.845
e tornar nossa tecnologia mais responsiva.

00:10:38.845 --> 00:10:41.435
Eu quero que esses dispositivos
que nos separaram

00:10:41.435 --> 00:10:43.897
juntem-nos novamente.

00:10:43.897 --> 00:10:48.485
E humanizando a tecnologia,
nós temos essa oportunidade de ouro

00:10:48.485 --> 00:10:51.782
de reimaginar nossa conexão
com as máquinas,

00:10:51.782 --> 00:10:56.263
e assim, como nós, seres humanos,

00:10:56.263 --> 00:10:58.167
nos conectamos uns com os outros.

00:10:58.167 --> 00:11:00.027
Obrigada.

00:11:00.027 --> 00:11:03.640
(Aplausos)

