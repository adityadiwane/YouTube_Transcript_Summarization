WEBVTT
Kind: captions
Language: sv

00:00:00.000 --> 00:00:07.000
Översättare: Annika Bidner
Granskare: Lisbeth Pekkari

00:00:12.556 --> 00:00:16.433
Våra känslor påverkar
varje del av våra liv

00:00:16.433 --> 00:00:20.149
från vår hälsa och hur vi lär oss,
till hur vi gör affärer och fattar beslut,

00:00:20.149 --> 00:00:21.922
stora som små.

00:00:22.672 --> 00:00:26.162
Våra känslor påverkar också
hur vi knyter an till varandra.

00:00:27.132 --> 00:00:31.108
Vi har utvecklats för att leva
i en sån här värld,

00:00:31.108 --> 00:00:35.427
men nu lever vi istället
mer och mer såna här liv -

00:00:35.427 --> 00:00:38.561
det här är ett sms som jag fick
från min dotter igår kväll -

00:00:38.561 --> 00:00:41.151
i en värld som är tömd på känslor.

00:00:41.151 --> 00:00:43.252
Jag ser som mitt uppdrag att förändra det.

00:00:43.252 --> 00:00:47.343
Jag vill föra tillbaka känslorna
i våra digitala upplevelser.

00:00:48.223 --> 00:00:51.070
Jag började med det för 15 år sen.

00:00:51.070 --> 00:00:53.486
Jag var dataingenjör i Egypten

00:00:53.486 --> 00:00:55.011
och hade just blivit antagen

00:00:55.011 --> 00:00:57.541
till en forskarutbildning
vid Cambridge University.

00:00:57.871 --> 00:00:59.984
Jag gjorde något ganska ovanligt

00:00:59.984 --> 00:01:04.209
för att vara en ung nygift
muslimsk egyptisk fru:

00:01:05.599 --> 00:01:08.598
Med stöd från min man
som blev tvungen att stanna i Egypten

00:01:08.598 --> 00:01:11.616
packade jag mina väskor
och flyttade till England.

00:01:11.616 --> 00:01:14.844
I Cambridge, tusentals kilometer hemifrån,

00:01:14.844 --> 00:01:17.847
insåg jag att jag tillbringade
fler timmar med min laptop

00:01:17.847 --> 00:01:20.486
än jag gjorde med någon människa.

00:01:20.486 --> 00:01:25.339
Trots detta nära band visste inte datorn
något om hur jag kände mig.

00:01:25.339 --> 00:01:28.190
Den visste inte om jag var glad,

00:01:28.190 --> 00:01:31.538
om jag hade en dålig dag,
eller var stressad, förvirrad,

00:01:31.538 --> 00:01:34.460
och det blev frustrerande.

00:01:35.600 --> 00:01:41.421
Ännu värre var det när jag kommunicerade
med min familj därhemma, och kände

00:01:41.431 --> 00:01:44.703
att mina känslor försvann i cyberrymden.

00:01:44.703 --> 00:01:49.858
Jag längtade hem, jag kände mig ensam,
och vissa dagar grät jag,

00:01:49.858 --> 00:01:54.786
men allt jag kunde använda
för att kommunicera känslorna var den här.

00:01:54.786 --> 00:01:56.806
(Skratt)

00:01:56.806 --> 00:02:01.780
Dagens teknik har mycket IQ, men ingen EQ;

00:02:01.780 --> 00:02:04.956
hög kognitiv intelligens
men ingen emotionell intelligens.

00:02:04.956 --> 00:02:07.153
Det fick mig att börja fundera på

00:02:07.153 --> 00:02:10.927
hur det skulle bli om vår teknik
skulle kunna känna av våra känslor?

00:02:10.927 --> 00:02:14.853
Om våra maskiner kunde känna av vårt humör
och bete sig i enlighet med det,

00:02:14.853 --> 00:02:17.866
som en emotionellt intelligent vän?

00:02:18.666 --> 00:02:21.970
De här frågorna gjorde
att jag och mitt team

00:02:21.970 --> 00:02:26.607
började skapa teknik som kan läsa av
och reagera på våra känslor,

00:02:26.607 --> 00:02:29.697
och vi började med det mänskliga ansiktet.

00:02:30.577 --> 00:02:33.750
Det mänskliga ansiktet råkar vara
en av de bästa kanaler

00:02:33.750 --> 00:02:37.766
som vi använder för att kommunicera
sociala och känslomässiga tillstånd,

00:02:37.766 --> 00:02:40.776
allt från njutning, överraskning,

00:02:40.776 --> 00:02:44.662
empati och nyfikenhet.

00:02:44.979 --> 00:02:49.907
Inom känslovetenskap kallas en rörelse
hos en ansiktsmuskel för "aktiv enhet".

00:02:49.907 --> 00:02:52.562
Den tolfte aktiva enheten

00:02:52.562 --> 00:02:54.870
är inte en toppfilm från Hollywood

00:02:54.870 --> 00:02:58.312
utan en uppdragen mungipa,
vilket är huvudkomponenten i ett leende.

00:02:58.312 --> 00:03:01.300
Prova det allihop. Nu ler vi lite.

00:03:01.300 --> 00:03:03.334
Ett annat exempel
är fjärde aktiva enheten.

00:03:03.334 --> 00:03:06.192
Det är när man drar ihop ögonbrynen

00:03:06.192 --> 00:03:08.129
och får den här ytan och rynkorna.

00:03:08.129 --> 00:03:12.141
Vi tycker inte om dem, men det är
en stark indikator på en negativ känsla.

00:03:12.164 --> 00:03:14.630
Vi har ungefär 45 aktiva enheter,

00:03:14.630 --> 00:03:18.350
och de kan kombineras
för att uttrycka hundratals känslor.

00:03:18.350 --> 00:03:22.251
Att lära en dator att läsa av
känslouttryck i ansiktet är svårt,

00:03:22.251 --> 00:03:25.223
för de aktiva enheterna
kan vara snabba och subtila

00:03:25.223 --> 00:03:27.487
och de går att kombinera
på många olika sätt.

00:03:27.487 --> 00:03:31.515
Ta till exempel leendet och hånflinet.

00:03:31.515 --> 00:03:35.268
De ser ganska lika ut,
men de betyder helt olika saker.

00:03:35.268 --> 00:03:36.986
(Skratt)

00:03:36.986 --> 00:03:39.430
Ett leende är positivt,

00:03:39.430 --> 00:03:41.260
ett flin är ofta negativt.

00:03:41.260 --> 00:03:45.136
Ibland kan ett flin göra en känd.

00:03:45.136 --> 00:03:47.960
Men trots allt är det viktigt
för en dator att kunna

00:03:47.960 --> 00:03:50.455
se skillnad mellan de här två uttrycken.

00:03:50.455 --> 00:03:52.337
Hur gör vi det?

00:03:52.337 --> 00:03:53.984
Vi ger våra algoritmer

00:03:53.984 --> 00:03:58.524
tiotusentals exempel
av människor som vi vet ler,

00:03:58.524 --> 00:04:01.589
med olika etnisk bakgrund, ålder, kön,

00:04:01.589 --> 00:04:03.631
och vi gör samma sak för flin.

00:04:03.950 --> 00:04:05.954
Och genom maskininlärning

00:04:05.954 --> 00:04:08.810
letar algoritmen
efter såna här ytor och rynkor

00:04:08.810 --> 00:04:11.070
och formändringar i vårt ansikte

00:04:11.070 --> 00:04:14.592
och lär sig helt enkelt att alla leenden
har egenskaper gemensamt,

00:04:14.592 --> 00:04:17.623
medan alla flin har
något annorlunda egenskaper.

00:04:17.623 --> 00:04:20.141
Och nästa gång den ser ett nytt ansikte

00:04:20.141 --> 00:04:22.440
märker den att

00:04:22.440 --> 00:04:25.993
det här ansiktet har samma egenskaper
som ett leende ansikte och den säger:

00:04:25.993 --> 00:04:29.208
"Aha, jag känner igen det här.
Det är ett leende uttryck."

00:04:30.381 --> 00:04:33.181
Det bästa sättet att visa
hur tekniken fungerar

00:04:33.181 --> 00:04:35.317
är genom en livedemo,

00:04:35.317 --> 00:04:39.230
så jag behöver en frivillig,
helst någon med ett ansikte.

00:04:39.230 --> 00:04:41.564
(Skratt)

00:04:41.564 --> 00:04:44.335
Cloe blir vår frivilliga idag.

00:04:45.325 --> 00:04:49.593
De senaste fem åren har vi utvecklats
från att vara ett projekt på MIT

00:04:49.593 --> 00:04:50.849
till att bli ett företag,

00:04:50.849 --> 00:04:54.131
där mitt team har jobbat mycket hårt
för att få tekniken att fungera,

00:04:54.131 --> 00:04:56.540
som vi säger, i naturen.

00:04:56.540 --> 00:04:59.210
Vi har också krympt den
så att känslomotorn

00:04:59.210 --> 00:05:02.530
fungerar i alla mobila enheter
med kamera, som den här iPaden.

00:05:02.530 --> 00:05:05.316
Vi testar.

00:05:06.756 --> 00:05:10.520
Som ni kan se har algoritmen
hittat Cloes ansikte,

00:05:10.520 --> 00:05:12.372
det är den här vita inramande rutan,

00:05:12.372 --> 00:05:14.943
och den spårar
huvudpunkterna i hennes ansikte,

00:05:14.943 --> 00:05:17.799
hennes ögonbryn, ögon, mun och näsa.

00:05:17.799 --> 00:05:20.526
Frågan är, kan den läsa av hennes uttryck?

00:05:20.526 --> 00:05:22.067
Vi ska testa maskinen.

00:05:22.067 --> 00:05:26.252
Först av allt, ge mig ett pokerfejs.
Ja, jättebra. (Skratt)

00:05:26.493 --> 00:05:29.316
Och när hon sen ler
är det ett riktigt leende, det är fint.

00:05:29.316 --> 00:05:31.766
Ni kan se att den gröna stapeln
går upp när hon ler.

00:05:31.766 --> 00:05:32.978
Det var ett stort leende.

00:05:32.978 --> 00:05:36.071
Kan du prova ett litet leende
och se om datorn kan känna igen det?

00:05:36.071 --> 00:05:37.682
Den känner igen småleenden också.

00:05:37.682 --> 00:05:39.968
Vi har jobbat hårt
för att det ska fungera.

00:05:39.968 --> 00:05:43.439
Och sen höjda ögonbryn,
ett tecken på förvåning.

00:05:43.439 --> 00:05:47.098
Rynkade ögonbryn, vilket är
ett tecken på förvirring.

00:05:47.688 --> 00:05:51.695
Rynka pannan. Ja, perfekt.

00:05:51.695 --> 00:05:55.188
Det är de olika aktiva enheterna.
Det finns många fler.

00:05:55.188 --> 00:05:57.220
Det här är bara en förenklad demo.

00:05:57.220 --> 00:06:00.368
Vi kallar varje avläsning
för en emotionell datapunkt,

00:06:00.368 --> 00:06:03.337
och de kan aktiveras tillsammans
för att visa olika känslor.

00:06:03.337 --> 00:06:07.990
Så på högra sidan - se glad ut.

00:06:07.990 --> 00:06:09.444
Det är lycka. Lycka lyser upp.

00:06:09.444 --> 00:06:11.371
Ge mig sen en min av avsmak.

00:06:11.371 --> 00:06:15.643
Försök minnas hur det var
när Zayn lämnade One Direction.

00:06:15.643 --> 00:06:17.153
(Skratt)

00:06:17.153 --> 00:06:21.495
Ja, rynka näsan. Perfekt.

00:06:21.495 --> 00:06:25.226
Och uttrycket är starkt negativt,
så du måste ha varit ett stort fan.

00:06:25.226 --> 00:06:27.926
Värde är hur positiv
eller negativ en upplevelse är,

00:06:27.926 --> 00:06:30.712
och engagemang är hur uttrycksfull hon är.

00:06:30.712 --> 00:06:34.126
Tänk er att Cloe hade tillgång
till den här känsloströmmen i realtid,

00:06:34.126 --> 00:06:36.935
och kunde dela den med vem hon ville.

00:06:36.935 --> 00:06:38.695
Tack.

00:06:38.695 --> 00:06:41.655
(Applåder)

00:06:45.749 --> 00:06:50.809
Så här långt har vi samlat in
12 miljarder såna här datapunkter.

00:06:50.809 --> 00:06:53.360
Det är den största databasen
för känslor i världen.

00:06:53.360 --> 00:06:56.343
Vi har samlat in den
från 2,9 miljoner filmer på ansikten,

00:06:56.343 --> 00:06:59.193
människor som har gått med på
att dela sina känslor med oss,

00:06:59.193 --> 00:07:02.398
från 75 länder i världen.

00:07:02.398 --> 00:07:04.113
Det blir fler och fler varje dag.

00:07:04.603 --> 00:07:06.670
Det känns fantastiskt

00:07:06.670 --> 00:07:09.865
att vi nu kan kvantifiera
något så personligt som våra känslor,

00:07:09.865 --> 00:07:12.100
och vi kan göra det i den här skalan.

00:07:12.100 --> 00:07:14.277
Vad har vi då lärt oss så här långt?

00:07:15.057 --> 00:07:17.388
Kön.

00:07:17.388 --> 00:07:21.034
Vår data bekräftar något
som du kanske misstänker.

00:07:21.034 --> 00:07:22.891
Kvinnor är mer uttrycksfulla än män.

00:07:22.891 --> 00:07:25.574
De inte bara ler mer,
deras leenden pågår längre,

00:07:25.574 --> 00:07:28.478
och vi kan nu verkligen mäta
vad det är som män och kvinnor

00:07:28.478 --> 00:07:30.614
reagerar olika på.

00:07:30.614 --> 00:07:31.794
Om vi tittar på kultur:

00:07:31.794 --> 00:07:35.888
I USA är kvinnor 40 procent
mer uttrycksfulla än män,

00:07:35.888 --> 00:07:39.753
men lustigt nog ser vi ingen skillnad
mellan män och kvinnor i Storbritannien.

00:07:39.753 --> 00:07:42.549
(Skratt)

00:07:43.296 --> 00:07:47.323
Ålder: Människor som är 50 år och äldre

00:07:47.323 --> 00:07:50.759
är 25 procent mer emotionella
än unga människor.

00:07:51.539 --> 00:07:55.751
Kvinnor i 20-årsåldern ler mycket mer
än män i samma ålder,

00:07:55.751 --> 00:07:59.590
kanske är det nödvändigt vid dejter.

00:07:59.590 --> 00:08:02.207
Men det som förvånade oss mest

00:08:02.207 --> 00:08:05.410
är att vi uttrycker oss hela tiden,

00:08:05.410 --> 00:08:08.243
även när vi sitter ensamma
framför våra skärmar,

00:08:08.243 --> 00:08:11.517
och det är inte bara
när vi tittar på kattvideos på Facebook.

00:08:11.757 --> 00:08:15.227
Vi är uttycksfulla när vi skickar e-post,
textmeddelanden, handlar online,

00:08:15.227 --> 00:08:17.527
till och med när vi deklarerar.

00:08:17.527 --> 00:08:19.919
Var används den här informationen idag?

00:08:19.919 --> 00:08:22.892
Genom att förstå hur vi interagerar
med medier kan vi förstå

00:08:22.892 --> 00:08:25.166
viral budskapsspridning och röstbeteenden

00:08:25.166 --> 00:08:28.456
och även föra in möjligheten
till känslouttryck i tekniken,

00:08:28.456 --> 00:08:32.527
och jag vill dela med mig av några exempel
som ligger mig speciellt varmt om hjärtat.

00:08:33.197 --> 00:08:36.265
Känslostyrda glasögon kan hjälpa människor

00:08:36.265 --> 00:08:39.493
med synnedsättning
att läsa av andras ansikten,

00:08:39.493 --> 00:08:43.110
och det kan hjälpa individer
med autism att tolka känslor,

00:08:43.110 --> 00:08:45.825
något som de verkligen kämpar med.

00:08:47.418 --> 00:08:50.777
Inom utbildning,
tänk dig att dina läroappar

00:08:50.777 --> 00:08:53.377
känner av att du är förvirrad
och saktar ner,

00:08:53.377 --> 00:08:55.444
eller om du är uttråkad kan de öka tempot,

00:08:55.444 --> 00:08:58.413
precis som en riktigt bra lärare
skulle göra i klassrummet.

00:08:59.043 --> 00:09:01.644
Tänk om din armbandsklocka
kunde mäta hur du mår,

00:09:01.644 --> 00:09:04.337
eller om din bil kunde veta
att du var trött,

00:09:04.337 --> 00:09:06.885
eller kanske din kyl vet om
att du är stressad,

00:09:06.885 --> 00:09:11.291
så att den låser sig automatiskt
för att undvika att du proppar i dig.

00:09:11.291 --> 00:09:13.158
Det skulle jag vilja ha.

00:09:13.158 --> 00:09:15.223
(Skratt)

00:09:15.668 --> 00:09:17.595
Tänk om jag hade hade haft tillgång

00:09:17.595 --> 00:09:19.908
till mina känslor i realtid i Cambridge,

00:09:19.908 --> 00:09:23.437
och jag hade kunnat dela den
med min familj på ett naturligt sätt,

00:09:23.437 --> 00:09:27.408
på samma sätt som om vi
hade varit i samma rum tillsammans?

00:09:27.408 --> 00:09:30.100
Jag tror att om fem år

00:09:30.100 --> 00:09:32.887
kommer våra enheter att ha ett känslochip

00:09:32.887 --> 00:09:36.951
och vi kommer inte att minnas hur det var
när vi inte kunde rynka pannan åt maskinen

00:09:36.951 --> 00:09:40.529
och den sa "Hmm,
det där gillade du inte va?"

00:09:41.200 --> 00:09:44.791
Vår största utmaning är att det finns
så många tillämpningar för tekniken,

00:09:44.791 --> 00:09:47.864
så jag och mitt team inser
att vi inte kan bygga alla själva,

00:09:47.864 --> 00:09:50.920
så vi har gjort tekniken tillgänglig
så att andra utvecklare

00:09:50.920 --> 00:09:53.474
kan börja skapa på ett kreativt sätt.

00:09:53.474 --> 00:09:57.560
Vi inser att det finns potientiella risker

00:09:57.560 --> 00:09:59.627
och möjligheter till missbruk,

00:09:59.627 --> 00:10:02.576
men jag tror, efter att ha
använt detta i många år,

00:10:02.576 --> 00:10:04.828
att fördelarna för mänskligheten

00:10:04.828 --> 00:10:07.453
av att ha emotionellt intelligent teknik

00:10:07.453 --> 00:10:11.169
mer än väl uppväger konsekvenserna
av felaktig användning.

00:10:11.169 --> 00:10:13.700
Och jag bjuder in er alla
att ta del i diskussionen.

00:10:13.700 --> 00:10:16.154
Ju fler människor
som känner till den här tekniken,

00:10:16.154 --> 00:10:19.661
desto mer kan vi uttrycka åsikter
om hur den ska användas.

00:10:21.081 --> 00:10:25.655
Så när allt fler delar
av våra liv blir digitala

00:10:25.655 --> 00:10:29.323
utkämpar vi en ojämn kamp för att begränsa
användningen av digitala enheter

00:10:29.323 --> 00:10:31.952
och kunna återta våra känslor.

00:10:32.622 --> 00:10:36.536
Vad jag istället försöker göra
är att föra in känslorna i tekniken

00:10:36.536 --> 00:10:38.765
och göra vår teknik mer lyhörd.

00:10:38.765 --> 00:10:41.435
Jag vill att maskinerna
som har separerat oss

00:10:41.435 --> 00:10:44.147
ska föra oss samman igen.

00:10:44.147 --> 00:10:48.485
Och genom att göra tekniken mer human
har vi ett gyllene tillfälle

00:10:48.485 --> 00:10:51.782
att tänka om hur vi umgås med maskiner,

00:10:51.782 --> 00:10:56.263
och därmed hur vi som människor

00:10:56.263 --> 00:10:58.167
umgås med varandra.

00:10:58.167 --> 00:11:00.013
Tack.

00:11:00.013 --> 00:11:03.010
(Applåder)

