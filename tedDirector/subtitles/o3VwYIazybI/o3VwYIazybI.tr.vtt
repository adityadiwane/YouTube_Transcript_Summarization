WEBVTT
Kind: captions
Language: tr

00:00:00.000 --> 00:00:07.000
Çeviri: Eren Gokce
Gözden geçirme: Ramazan Şen

00:00:12.556 --> 00:00:16.573
Duygularımız hayatımızın 
her alanını etkiliyor,

00:00:16.573 --> 00:00:20.149
sağlığımız ve nasıl öğrendiğimizden, 
nasıl iş yaptığımız ve karar aldığımıza kadar,

00:00:20.149 --> 00:00:21.922
büyük olanları ve küçükleri.

00:00:22.672 --> 00:00:27.022
Duygularımız aynı zamanda birbirimizle 
nasıl bağlantı kuracağımızı da etkiliyor.

00:00:27.132 --> 00:00:31.108
Böyle bir dünyada yaşamak 
üzere evrildik,

00:00:31.108 --> 00:00:35.427
ama onun yerine hayatlarımızı giderek 
daha fazla böyle yaşıyoruz --

00:00:35.427 --> 00:00:38.561
bu dün gece kızımdan gelen kısa mesaj --

00:00:38.561 --> 00:00:41.301
duygulardan yoksun bir dünyada.

00:00:41.301 --> 00:00:43.252
Bu durumu değiştirmek üzere görevdeyim.

00:00:43.252 --> 00:00:47.343
Dijital deneyimlerimize duyguları tekrar
getirmek istiyorum.

00:00:48.223 --> 00:00:51.300
Bu yola 15 sene önce koyuldum.

00:00:51.300 --> 00:00:53.366
Mısır'da bilgisayar bilimciydim

00:00:53.366 --> 00:00:57.871
ve Cambridge Üniversitesi'nde doktora 
programına yeni kabul edilmiştim.

00:00:57.871 --> 00:00:59.984
Genç, yeni evli, Müslüman, Mısırlı 

00:00:59.984 --> 00:01:04.209
bir eş için oldukça alışılmadık 
bir şey yaptım:

00:01:05.599 --> 00:01:08.598
Mısır'da kalmak zorunda 
olan eşimin desteğiyle

00:01:08.598 --> 00:01:11.616
bavullarımı toplayıp 
İngiltere'ye taşındım.

00:01:11.616 --> 00:01:14.844
Cambridge'de, evimden binlerce mil uzakta,

00:01:14.844 --> 00:01:18.257
dizüstü bilgisayarımla herhangi 
bir insanla olduğundan

00:01:18.257 --> 00:01:20.486
daha fazla zaman geçirdiğimi fark ettim.

00:01:20.486 --> 00:01:25.339
Bu yakınlığa rağmen, bilgisayarımın ne 
hissettiğime dair kesinlikle en ufak bir fikri yoktu.

00:01:25.339 --> 00:01:28.550
Mutlu mu olduğum, 
kötü bir gün mü geçirdiğim

00:01:28.550 --> 00:01:31.538
veya stresli, şaşkın mı olduğumla ilgili

00:01:31.538 --> 00:01:34.460
bir fikri yoktu ve bu 
sinir bozmaya başladı.

00:01:35.600 --> 00:01:40.831
Daha da kötüsü, ülkemdeki ailemle 
internette iletişim kurduğumda,

00:01:41.421 --> 00:01:44.703
bütün duygularımın sanal gerçeklik içinde 
kaybolduğunu hissettim.

00:01:44.703 --> 00:01:49.858
Evimi özlüyordum, yalnızdım 
ve bazı günler gerçekten ağlıyordum,

00:01:49.858 --> 00:01:54.786
ancak bütün bu duyguları 
iletme şeklim böyleydi.

00:01:54.786 --> 00:01:56.806
(Gülüşmeler)

00:01:56.806 --> 00:02:01.130
Bugünün teknolojisinin çok fazla 
I.Q.'su var, ancak E.Q.'su yok;

00:02:01.130 --> 00:02:04.956
oldukça fazla kavramsal zekâ var, 
ancak duygusal zekâ yok.

00:02:04.956 --> 00:02:07.153
İşte bu beni düşündürdü,

00:02:07.153 --> 00:02:10.777
teknolojimiz duygularımızı 
hissetse ne olurdu?

00:02:10.777 --> 00:02:14.853
Eğer cihazlarımız nasıl hissettiğimizi bilseler 
ve ona göre reaksiyon verseler ne olurdu,

00:02:14.853 --> 00:02:17.866
aynen duygusal zekâya sahip 
bir arkadaşın yapacağı gibi?

00:02:18.666 --> 00:02:22.230
Bu sorular beni ve ekibimi

00:02:22.230 --> 00:02:26.607
duygularımızı okuyup cevap verecek 
teknolojiler yaratmaya götürdü

00:02:26.607 --> 00:02:29.697
ve başlangıç noktamız insan yüzüydü.

00:02:30.577 --> 00:02:33.750
İnsan yüzü, hepimizin sosyal ve 
duygusal durumumuzu iletmek için

00:02:33.750 --> 00:02:37.766
kullandığı en güçlü yollardan biri.

00:02:37.766 --> 00:02:40.776
Hoşlanmadan, sürprize,

00:02:40.776 --> 00:02:44.979
empati ve meraka kadar her şeyi.

00:02:44.979 --> 00:02:49.907
Duygu biliminde, her yüz kası 
hareketine eylem birimi diyoruz.

00:02:49.907 --> 00:02:52.832
Örneğin, eylem birimi 12,

00:02:52.832 --> 00:02:54.870
bir Hollywood kapalı gişesi değil,

00:02:54.870 --> 00:02:58.312
aslında gülüşün ana unsuru olan dudak 
kenarının yukarı doğru çekilmesi.

00:02:58.312 --> 00:03:01.300
Herkes denesin. Hadi biraz gülümseyelim.

00:03:01.300 --> 00:03:03.954
Diğer bir örnek, eylem birimi 4. 
Alnın kırışması.

00:03:03.954 --> 00:03:06.192
Kaşlarınızı birbirine yaklaştırıp,

00:03:06.192 --> 00:03:08.459
bütün o kıvrımları ve kırışıklıkları 
yarattığınız zaman olur.

00:03:08.459 --> 00:03:12.114
Onları sevmeyiz, ama negatif duyguların 
güçlü bir göstergesidir.

00:03:12.114 --> 00:03:14.460
Bu eylem birimlerinden 
45 tane kadarına sahibiz

00:03:14.460 --> 00:03:18.350
ve yüzlerce duyguyu ifade 
etmek için bir araya gelirler.

00:03:18.350 --> 00:03:22.251
Bir bilgisayara yüzdeki bu duyguları 
okumayı öğretmek zordur,

00:03:22.251 --> 00:03:25.223
çünkü bu eylem birimleri 
hızlı olabilir, gizli olabilir

00:03:25.223 --> 00:03:27.777
ve birçok farklı şekilde 
bir araya gelebilirler.

00:03:27.777 --> 00:03:31.515
Örneğin, gülümseme ve 
zoraki tebessümü ele alalım.

00:03:31.515 --> 00:03:35.268
Bir şekilde benzerler, 
ancak çok farklı anlamlara gelirler.

00:03:35.268 --> 00:03:36.986
(Gülüşmeler)

00:03:36.986 --> 00:03:39.210
Gülümseme pozitif,

00:03:39.210 --> 00:03:41.260
zoraki tebessüm ise 
çoğunlukla negatiftir.

00:03:41.260 --> 00:03:45.136
Bazen zoraki tebessüm sizi ünlü yapabilir.

00:03:45.136 --> 00:03:47.960
Ancak sahiden bir bilgisayarın 
iki ifade arasındaki

00:03:47.960 --> 00:03:50.565
farkı bilebilmesi önemlidir.

00:03:50.565 --> 00:03:52.507
Öyleyse bunu nasıl yaparız?

00:03:52.507 --> 00:03:54.414
Algoritmalarımıza farklı 

00:03:54.414 --> 00:03:58.524
etnik gruplardan, yaşlardan, 
cinsiyetlerden gülümsediğini

00:03:58.524 --> 00:04:01.589
bildiğimiz on binlerce örnek veririz

00:04:01.589 --> 00:04:03.980
ve aynısını zoraki 
tebessüm için de yaparız.

00:04:03.980 --> 00:04:05.954
Sonra derin öğrenme yoluyla,

00:04:05.954 --> 00:04:08.810
algoritma yüzümüzdeki bütün bu 
kıvrımlara, kırışıklıklara

00:04:08.810 --> 00:04:11.390
ve şekil değişimlerine bakar,

00:04:11.390 --> 00:04:14.592
kısaca bütün gülümsemelerin ortak 
özellikleri olduğunu öğrenir,

00:04:14.592 --> 00:04:17.773
bütün zoraki tebessümlerin hemen göze
çarpmayan farklı özellikleri var.

00:04:17.773 --> 00:04:20.141
Bir daha yeni bir yüz gördüğünde,

00:04:20.141 --> 00:04:22.440
o yüzün esasen bir gülümsemeye

00:04:22.440 --> 00:04:25.473
özgü karakteristikleri olduğunu öğrenir

00:04:25.473 --> 00:04:29.751
ve şöyle der, "Evet, bunu tanıyorum. 
Bu bir gülümseme ifadesi."

00:04:30.381 --> 00:04:33.181
Bu teknolojinin nasıl çalıştığını 
göstermenin en iyi yolu

00:04:33.181 --> 00:04:35.317
canlı bir demo denemek,

00:04:35.317 --> 00:04:39.230
bu yüzden bir gönüllüye ihtiyacım var, 
tercihen yüzü olan biri.

00:04:39.230 --> 00:04:41.564
(Gülüşmeler)

00:04:41.564 --> 00:04:44.335
Chloe bugün gönüllümüz olacak.

00:04:45.325 --> 00:04:49.783
Geçen beş sene içinde, MIT'de bir 
araştırma projesi olmaktan

00:04:49.783 --> 00:04:50.939
bir şirket olmaya geçtik,

00:04:50.939 --> 00:04:54.131
ekibim bu teknolojinin çalışması 
için gerçekten çok çalıştı,

00:04:54.131 --> 00:04:56.540
şu an piyasada kullanılması 
için diyebiliriz.

00:04:56.540 --> 00:04:59.210
Aynı zamanda onu küçülttük ki, 
çekirdek duygu makinesi,

00:04:59.210 --> 00:05:02.530
bu iPad gibi kameraya sahip herhangi 
bir mobil araçta çalışabilsin.

00:05:02.530 --> 00:05:05.316
Hadi bir deneme yapalım.

00:05:06.756 --> 00:05:10.680
Gördüğünüz gibi, algoritma 
sonuçta Chloe'nin yüzünü buldu,

00:05:10.680 --> 00:05:12.372
işte bu beyaz sınırlı kutu

00:05:12.372 --> 00:05:14.943
ve yüzündeki ana 
hatları takip ediyor,

00:05:14.943 --> 00:05:17.799
işte kaşları, gözleri, ağzı ve burnu.

00:05:17.799 --> 00:05:20.786
Soru şu; ifadesini tanıyabilecek mi?

00:05:20.786 --> 00:05:22.457
Bu yüzden makineyi test edeceğiz.

00:05:22.457 --> 00:05:26.643
İlk önce, bana ifadesiz yüzünü göster. 
Evet, harika. (Gülüşmeler)

00:05:26.643 --> 00:05:29.456
Sonra gülümsedikçe, bu gerçek 
bir gülümseme, harika.

00:05:29.456 --> 00:05:31.756
Evet, gülümsedikçe yeşil çubuğun 
arttığını görebilirsiniz.

00:05:31.756 --> 00:05:32.978
Evet, bu büyük bir gülümsemeydi.

00:05:32.978 --> 00:05:35.771
Bakalım hafif gülümsediğinde
bilgisayarın tanıyabilecek mi?

00:05:35.771 --> 00:05:37.702
Hafif gülümsemeleri de tanıyor.

00:05:37.702 --> 00:05:40.067
Bunu gerçekleştirmek için 
gerçekten çok çalıştık.

00:05:40.067 --> 00:05:43.439
Sonra kaşlar kalkıyor, 
şaşırmanın göstergesi.

00:05:43.439 --> 00:05:47.688
Alnın kırışması, 
kafa karışıklığının göstergesi.

00:05:47.688 --> 00:05:51.695
Somurtma. Evet, mükemmel.

00:05:51.695 --> 00:05:55.188
İşte bunların hepsi farklı eylem 
birimleri. Daha çok var.

00:05:55.188 --> 00:05:57.220
Bu sadece kısaltılmış bir demo.

00:05:57.220 --> 00:06:00.368
Her okumaya, bir duygu veri 
noktası adını veriyoruz.

00:06:00.368 --> 00:06:03.337
Sonra farklı duyguları resmetmek 
için birlikte harekete geçerler.

00:06:03.337 --> 00:06:07.990
Demonun sağ tarafında -- 
mutlu görün.

00:06:07.990 --> 00:06:09.444
İşte bu neşe. 
Neşe harekete geçiyor.

00:06:09.444 --> 00:06:11.371
Şimdi bana iğrenme ifadesi ver.

00:06:11.371 --> 00:06:15.643
Zayn One Direction'ı terk ettiğinde
nasıl olduğunu hatırlamaya çalış.

00:06:15.643 --> 00:06:17.153
(Gülüşmeler)

00:06:17.153 --> 00:06:21.495
Evet, burnunu kırıştır. Harika.

00:06:21.495 --> 00:06:25.226
Değerlik oldukça negatif, herhâlde 
çok büyük bir hayranısın.

00:06:25.226 --> 00:06:27.926
Değerlik, deneyimin ne kadar pozitif 
veya negatif olduğuyla ilgili;

00:06:27.926 --> 00:06:30.712
bağlantı ise, kişinin bunu ne 
kadar ifade edebildiğiyle.

00:06:30.712 --> 00:06:34.126
O zaman Chloe'nin bu gerçek zamanlı 
duygu akışına erişimi olduğunu

00:06:34.126 --> 00:06:36.935
ve istediği kişilerle
paylaşabileceğini hayal edin.

00:06:36.935 --> 00:06:39.858
Teşekkürler.

00:06:39.858 --> 00:06:44.479
(Alkış)

00:06:45.749 --> 00:06:51.019
Şimdiye kadar bu duygu veri noktalarından 
12 milyar adet topladık.

00:06:51.019 --> 00:06:53.630
Dünyadaki en büyük duygu veri tabanı.

00:06:53.630 --> 00:06:56.593
Bunu 2,9 milyon yüz videosundan topladık,

00:06:56.593 --> 00:06:59.193
bizimle duygularını paylaşmaya 
gönüllü insanlardan

00:06:59.193 --> 00:07:02.398
ve dünyadaki 75 ülkeden.

00:07:02.398 --> 00:07:04.113
Her gün büyüyor.

00:07:04.603 --> 00:07:06.670
Duygular kadar kişisel bir şeyi

00:07:06.670 --> 00:07:09.865
artık ölçebiliyor olmamız 
beni çok şaşırtıyor

00:07:09.865 --> 00:07:12.100
ve bunu bu ölçekte yapabiliyoruz.

00:07:12.100 --> 00:07:14.277
Peki şimdiye kadar ne öğrendik?

00:07:15.057 --> 00:07:17.388
Cinsiyet.

00:07:17.388 --> 00:07:21.034
Şüpheleniyor olduğunuz 
bir şeyi verimiz doğruluyor.

00:07:21.034 --> 00:07:22.891
Kadınlar erkeklerden daha 
fazla duygularını ifade ediyor.

00:07:22.891 --> 00:07:25.574
Daha çok gülümsemeleri yanında, 
gülümsemeleri daha uzun sürüyor

00:07:25.574 --> 00:07:28.478
ve erkeklerle kadınların 
gerçekten neye farklı

00:07:28.478 --> 00:07:30.614
yanıt verdiğini artık ölçebiliyoruz.

00:07:30.614 --> 00:07:32.904
Hadi kültüre bakalım: 
Amerika Birleşik Devletleri'nde,

00:07:32.904 --> 00:07:36.108
kadınlar erkeklerden yüzde 40 
daha fazla ifadelerini gösteriyor,

00:07:36.108 --> 00:07:39.753
ancak ilginç biçimde Birleşik Krallık'ta erkekler 
ve kadınlar arasında fark görmüyoruz.

00:07:39.753 --> 00:07:42.259
(Gülüşmeler)

00:07:43.296 --> 00:07:47.323
Yaş: 50 ve üzerindeki yaştaki insanlar

00:07:47.323 --> 00:07:50.759
gençlerden yüzde 25 daha duygusal.

00:07:51.899 --> 00:07:55.751
Yirmilerindeki kadınlar aynı yaştaki 
erkeklerden daha fazla gülümsüyor,

00:07:55.751 --> 00:07:59.590
belki de flört için bir gereklilik.

00:07:59.590 --> 00:08:02.207
Ancak belki de bu veriyle ilgili 
bizi en fazla şaşırtan şey,

00:08:02.207 --> 00:08:05.410
her zaman duygularımızı 
ifade ediyor oluşumuz,

00:08:05.410 --> 00:08:08.243
cihazlarımızın başında tek 
başımıza oturuyor olsak bile

00:08:08.243 --> 00:08:11.517
ve sadece Facebook'ta 
kedi videoları izlerken değil.

00:08:12.217 --> 00:08:15.227
E-posta atarken, mesajlaşırken, internette 
alışveriş yaparken veya vergilerimizi

00:08:15.227 --> 00:08:17.527
hallederken bile duygularımızı 
ifade ediyoruz.

00:08:17.527 --> 00:08:19.919
Bu veri bugün nerede kullanılıyor?

00:08:19.919 --> 00:08:22.682
Medya ile nasıl bağ
kurduğumuzu anlamada,

00:08:22.682 --> 00:08:25.166
yani yayılma ve oy verme 
davranışını anlamada

00:08:25.166 --> 00:08:28.446
ve bunun yanında teknolojik güçlendirme 
veya duygu-etkinleştirmede.

00:08:28.446 --> 00:08:32.527
Özellikle çok sevdiğim bazı örnekleri 
sizinle paylaşmak istiyorum.

00:08:33.197 --> 00:08:36.265
Duygu-etkinleştirilmiş, giyilebilir 
gözlükler, görme engelli olan

00:08:36.265 --> 00:08:39.493
bireylere diğerlerinin yüzlerini 
okumada yardımcı olabilir

00:08:39.493 --> 00:08:43.020
ve otizm spektrumu olan bireylere 
duyguları anlamada yardımcı olabilir,

00:08:43.020 --> 00:08:45.358
bu onların gerçekten çok 
zorluk çektiği bir şey.

00:08:47.668 --> 00:08:50.777
Eğitimde, öğrenme uygulamalarınızın 
kafanızın karıştığını

00:08:50.777 --> 00:08:53.587
hissettiğini ve yavaşladığını veya 
sıkıldığınızı hissettiğini,

00:08:53.587 --> 00:08:55.444
bu yüzden hızlandığını hayal edin,

00:08:55.444 --> 00:08:58.413
aynı iyi bir öğretmenin 
sınıfta yapacağı gibi.

00:08:59.043 --> 00:09:01.644
Eğer kolunuzdaki saatiniz ruh hâlinizi 
takip etseydi ne olurdu

00:09:01.644 --> 00:09:04.337
veya arabanız yorgun 
olduğunuzu hissetseydi

00:09:04.337 --> 00:09:06.885
veya belki de buzdolabınız stresli 
olduğunuzu bilseydi,

00:09:06.885 --> 00:09:11.391
o zaman sizi aşırı yemeden korumak için 
otomatik olarak kilitlenirdi. (Gülüşmeler)

00:09:11.391 --> 00:09:13.388
Bunu isterdim, evet.

00:09:15.668 --> 00:09:17.595
Eğer Cambridge'deyken

00:09:17.595 --> 00:09:19.908
gerçek zamanlı duygu 
akışına erişimim olsaydı

00:09:19.908 --> 00:09:23.437
ve bunu ülkemdeki ailemle çok doğal 
bir şekilde paylaşabilseydim,

00:09:23.437 --> 00:09:27.408
aynı hepimiz aynı odada 
olsaydık yapacağım gibi.

00:09:27.408 --> 00:09:30.550
Bence beş yıl içinde,

00:09:30.550 --> 00:09:32.887
bütün cihazlarımızın duygu çipi olacak,

00:09:32.887 --> 00:09:36.951
yalnızca cihazımıza somurttuğumuzda, 
"Hımm, bunu sevmedin, değil mi?"

00:09:36.951 --> 00:09:41.200
diyecek bir cihazımızın olmamasının 
nasıl bir şey olduğunu hatırlamayacağız.

00:09:41.200 --> 00:09:44.961
En büyük sorunumuz, bu teknolojinin 
pek çok uygulaması olması,

00:09:44.961 --> 00:09:47.864
ekibim ve ben hepsini tek başımıza 
yapamayacağımızın farkındayız,

00:09:47.864 --> 00:09:51.360
o yüzden bu teknolojiyi kullanılabilir hâle 
getirdik, böylece diğer geliştiriciler

00:09:51.360 --> 00:09:53.474
de yapmaya başlayabilir 
ve yaratıcı olabilirler.

00:09:53.474 --> 00:09:57.560
Olası risklerin ve istismar olasılığının

00:09:57.560 --> 00:09:59.627
olduğunun farkındayız,

00:09:59.627 --> 00:10:02.576
ancak şahsen bunu yıllardır 
yapan biri olarak ben,

00:10:02.576 --> 00:10:05.548
duygusal olarak akıllı 
teknolojilere sahip olmanın

00:10:05.548 --> 00:10:07.823
insanlığa getirdiği yararların,
yanlış kullanılma

00:10:07.823 --> 00:10:11.399
olasılığından çok daha 
ağır bastığına inanıyorum.

00:10:11.399 --> 00:10:13.930
Hepinizi bu etkileşimin bir parçası 
olmaya davet ediyorum.

00:10:13.930 --> 00:10:16.484
Bu teknolojiyi bilen daha 
fazla insan oldukça,

00:10:16.484 --> 00:10:19.661
nasıl kullanıldığıyla ilgili daha 
fazla söz hakkımız olur.

00:10:21.081 --> 00:10:25.655
Hayatlarımız daha fazla 
dijital hâle geldikçe,

00:10:25.655 --> 00:10:29.153
duygularımızı geri kazanmak için,
cihazlarımızı kullanmayı frenlemeye

00:10:29.153 --> 00:10:31.382
çalışarak beyhude savaş veriyoruz.

00:10:32.622 --> 00:10:36.536
Bu yüzden bunun yerine yapmaya çalıştığım 
şey, duyguları teknolojimize getirmek

00:10:36.536 --> 00:10:38.765
ve teknolojilerimizi daha cevap
verir hâle getirmek.

00:10:38.765 --> 00:10:41.435
Bu yüzden bizi ayıran bu cihazlarımızın,

00:10:41.435 --> 00:10:43.897
bizi tekrar bir araya 
getirmesini istiyorum.

00:10:43.897 --> 00:10:48.485
Teknolojiyi insanlaştırarak, makinelerle 
nasıl bağlantı kuracağımızı

00:10:48.485 --> 00:10:51.782
ve böylece insanlık olarak birbirimizle 
nasıl bağlantı kuracağımızı

00:10:51.782 --> 00:10:56.263
tekrar düşünmek için 

00:10:56.263 --> 00:10:58.167
bulunmaz bir fırsatımız var.

00:10:58.167 --> 00:11:00.327
Teşekkürler.

00:11:00.327 --> 00:11:03.640
(Alkış)

