WEBVTT
Kind: captions
Language: hu

00:00:00.000 --> 00:00:07.000
Fordító: Peter Balla
Lektor: Maria Ruzsane Cseresnyes

00:00:12.376 --> 00:00:16.393
Az érzelmeink életünk
minden aspektusát befolyásolják,

00:00:16.393 --> 00:00:19.969
az egészségtől kezdve a tanulásig,
az üzleteléstől a döntéshozatalig,

00:00:19.969 --> 00:00:21.742
nagyokat és kicsiket egyaránt.

00:00:22.492 --> 00:00:25.982
Az érzelmeink befolyásolják azt is,
hogyan kötődünk másokhoz.

00:00:26.952 --> 00:00:30.928
Ilyen világra lettünk teremtve,

00:00:30.928 --> 00:00:35.247
de ehelyett egyre inkább
egy másmilyen, --

00:00:35.247 --> 00:00:38.381
ezt az üzenetet a lányomtól
kaptam múlt éjszaka -

00:00:38.381 --> 00:00:41.121
érzelemmentes világban kezdünk élni.

00:00:41.121 --> 00:00:43.072
Az a küldetésem, hogy ezen változtassak.

00:00:43.072 --> 00:00:47.163
Vissza akarom hozni az érzelmeket
digitális élményeinkbe.

00:00:48.043 --> 00:00:51.120
Tizenöt éve indultam el ezen az úton.

00:00:51.120 --> 00:00:53.186
Számítógép-szakértő voltam Egyiptomban,

00:00:53.186 --> 00:00:57.691
és épp akkor vettek fel a Cambridge
Egyetem doktori programjára.

00:00:57.691 --> 00:00:59.804
Tehát valami egészen szokatlant csináltam

00:00:59.804 --> 00:01:04.029
fiatal, frissen házasodott
muszlim egyiptomi feleségként:

00:01:05.419 --> 00:01:08.418
Férjem támogatásával, akinek
Egyiptomban kellett maradnia,

00:01:08.418 --> 00:01:11.436
összecsomagoltam és Angliába költöztem.

00:01:11.436 --> 00:01:14.664
Cambridge-ben, több ezer mérföldre
az otthonomtól,

00:01:14.664 --> 00:01:18.077
rájöttem, hogy több órát töltök
a laptopommal,

00:01:18.077 --> 00:01:20.306
mint bármelyik embertársammal.

00:01:20.306 --> 00:01:25.159
De az intimitás ellenére a laptopomnak
fogalma sem volt az érzéseimről.

00:01:25.159 --> 00:01:28.370
Nem tudta, ha vidám voltam,

00:01:28.370 --> 00:01:31.358
ha rossz napom volt, ha stresszes
vagy zavart voltam,

00:01:31.358 --> 00:01:34.280
és ez frusztrált.

00:01:35.420 --> 00:01:40.651
Még rosszabb: ahogyan online beszélgettem
az otthon maradt családommal,

00:01:41.241 --> 00:01:44.523
úgy éreztem, hogy minden érzelmem
elvész a kibertérben.

00:01:44.523 --> 00:01:49.678
Honvágyam volt, magányos voltam,
és néhanapján igazából is sírtam,

00:01:49.678 --> 00:01:54.606
de ennyi volt mindaz, amivel kifejezhettem
ezeket az érzéseket.

00:01:54.606 --> 00:01:56.626
(Nevetés)

00:01:56.626 --> 00:02:01.600
A mai technológiának magas az IQ-ja,
viszont az EQ-ja nem;

00:02:01.600 --> 00:02:04.776
rengeteg kognitív intelligencia,
de semmi érzelmi intelligencia.

00:02:04.776 --> 00:02:06.973
Ez elgondolkodtatott:

00:02:06.973 --> 00:02:10.597
mi lenne, ha a technológia 
érzékelné érzelmeinket?

00:02:10.597 --> 00:02:14.673
Mi lenne, ha eszközeink érzékelnék, mit
érzünk, és annak megfelelően reagálnának,

00:02:14.673 --> 00:02:17.686
ahogyan azt egy érzelmileg
intelligens barátunk tenné?

00:02:18.486 --> 00:02:22.050
Ezek a kérdések vezettek
engem és a csapatomat

00:02:22.050 --> 00:02:26.427
olyan technológiák megalkotására, amelyek
olvassák az érzéseinket, és válaszolnak.

00:02:26.427 --> 00:02:29.517
Kiindulópontunk az emberi arc volt.

00:02:30.397 --> 00:02:33.570
Emberi arcunk történetesen
az egyik legerősebb csatorna,

00:02:33.570 --> 00:02:37.586
amelynek révén közösségi és érzelmi
állapotainkat közöljük,

00:02:37.586 --> 00:02:40.596
mindent, beleértve az élvezetet,
meglepetést,

00:02:40.596 --> 00:02:44.799
empátiát és kíváncsiságot is.

00:02:44.799 --> 00:02:49.727
Az érzelmek tudományában minden 
arcizom-mozgást egy egységnek nevezünk.

00:02:49.727 --> 00:02:52.652
A 12-es mozgásegység például

00:02:52.652 --> 00:02:54.690
nem egy hollywoodi kasszasiker,

00:02:54.690 --> 00:02:58.132
ez valójában a száj sarkának felhúzása,
ami egy mosoly fő alkotóeleme.

00:02:58.132 --> 00:03:01.120
Mindenki kipróbálhatja.
Lássunk néhány mosolyt.

00:03:01.120 --> 00:03:03.774
Egy másik példa a 4-es egység.
Ez a szemöldök ráncolása.

00:03:03.774 --> 00:03:06.012
Ilyenkor összevonjuk a szemöldökünket,

00:03:06.012 --> 00:03:08.279
és létrehozzuk ezeket a
formákat meg ráncokat.

00:03:08.279 --> 00:03:12.574
Nem szeretjük, de erős 
negatív érzést jelez.

00:03:12.574 --> 00:03:14.780
Van kb. 45 ilyen mozgásegységünk,

00:03:14.780 --> 00:03:18.170
ezek kombinálva több száz
érzelmet fejeznek ki.

00:03:18.170 --> 00:03:22.071
Nehéz megtanítani egy számítógépnek,
hogy ezeket az érzelmeket olvassa,

00:03:22.071 --> 00:03:25.043
mert lehetnek ezek gyorsak, rejtettek,

00:03:25.043 --> 00:03:27.597
és különböző módon keverednek.

00:03:27.597 --> 00:03:31.335
Vegyük például a mosolyt és a grimaszt.

00:03:31.335 --> 00:03:35.088
Valamennyire hasonlónak tűnnek,
ám nagyon különbözik a jelentésük.

00:03:35.088 --> 00:03:36.806
(Nevetés)

00:03:36.806 --> 00:03:39.810
A mosoly pozitív,

00:03:39.810 --> 00:03:41.080
a grimasz gyakran negatív.

00:03:41.080 --> 00:03:44.956
Néha egy grimasz híressé tehet.

00:03:44.956 --> 00:03:47.780
De komolyan, fontos, hogy egy 
számítógép képes legyen

00:03:47.780 --> 00:03:50.635
megkülönböztetni egymástól a két érzelmet.

00:03:50.635 --> 00:03:52.447
Mindezt hogyan csináljuk?

00:03:52.447 --> 00:03:54.234
Adunk az algortimusainknak

00:03:54.234 --> 00:03:58.344
több tízezer példát emberekről,
akikről tudjuk, hogy mosolyognak,

00:03:58.344 --> 00:04:01.409
ezek különböző etnikumúak, korúak, neműek,

00:04:01.409 --> 00:04:04.220
és ugyanígy teszünk a grimasszal is.

00:04:04.220 --> 00:04:05.774
Aztán deep learninget használva

00:04:05.774 --> 00:04:08.630
az algoritmus megkeresi ezeket a
a struktúrákat és ráncokat,

00:04:08.630 --> 00:04:11.210
az arcunk változásait,

00:04:11.210 --> 00:04:14.412
lényegében megtanulja, hogy minden
mosolynak van közös jellemzője,

00:04:14.412 --> 00:04:17.593
és minden grimasznak élesen
különböző jellemzői vannak.

00:04:17.593 --> 00:04:19.961
A következő alkalommal,
mikor meglát egy új arcot,

00:04:19.961 --> 00:04:22.260
lényegében rájön, hogy

00:04:22.260 --> 00:04:25.293
ennek az arcnak ugyanolyan
jellemzői vannak, mint a mosolynak,

00:04:25.293 --> 00:04:29.571
és azt mondja: "Jé, felismerem ezt.
Ez egy mosoly kifejezése."

00:04:30.201 --> 00:04:33.001
A technológia működésének
bizonyítására a legjobb mód

00:04:33.001 --> 00:04:35.137
egy élő demo kipróbálása,

00:04:35.137 --> 00:04:39.050
tehát szükségem van egy önkéntesre,
lehetőleg valakire, akinek van arca.

00:04:39.050 --> 00:04:41.384
(Nevetés)

00:04:41.384 --> 00:04:44.155
Cloe lesz a mai önkéntesünk,

00:04:45.145 --> 00:04:49.603
Az elmúlt öt év során egy MIT-s
kutatási projektből vállalattá

00:04:49.603 --> 00:04:50.759
nőttük ki magunkat,

00:04:50.759 --> 00:04:53.951
és a csapatom igen sokat dolgozott azon,
hogy ez a technológia

00:04:53.951 --> 00:04:56.360
működjön, ahogy mondani szokás,
a vadonban is.

00:04:56.360 --> 00:04:59.030
Úgy összezsugorítottuk, hogy
a fő érzelem-motor

00:04:59.030 --> 00:05:02.350
bármelyik kamerás mobil eszközön
működik, mint ezen az iPad-en is.

00:05:02.350 --> 00:05:05.136
Tehát próbáljuk ki!

00:05:06.576 --> 00:05:10.500
Ahogy láthatják, az algoritmus 
megtalálta Cloe arcát,

00:05:10.500 --> 00:05:12.192
ez az a fehér határolókeret,

00:05:12.192 --> 00:05:14.763
és követi a fő jellemző pontokat az arcán,

00:05:14.763 --> 00:05:17.619
vagyis a szemöldökét, a szemét,
a száját és az orrát.

00:05:17.619 --> 00:05:20.606
Az a kérdés,
hogy fel tudja-e ismerni, mit fejez ki?

00:05:20.606 --> 00:05:22.277
Most leteszteljük a gépet.

00:05:22.277 --> 00:05:26.463
Legelőször mutasd a pókerarcod.
Igen, nagyszerű. (Nevetés)

00:05:26.463 --> 00:05:29.276
Aztán ahogy mosolyog,
ez egy valódi mosoly, nagyszerű.

00:05:29.276 --> 00:05:31.576
A zöld sáv láthatóan növekszik,
mikor mosolyog.

00:05:31.576 --> 00:05:32.798
Ez egy nagy mosoly volt.

00:05:32.798 --> 00:05:35.841
Megpróbálsz egy enyhébb mosolyt,
hogy lássuk, felismeri-e a gép?

00:05:35.841 --> 00:05:38.172
Felismeri az enyhébb mosolyt is.

00:05:38.172 --> 00:05:40.297
Nagyon sokat dolgoztunk,
hogy ez sikerüljön.

00:05:40.297 --> 00:05:43.259
Aztán felemelt szemöldök,
a meglepetés jelzője.

00:05:43.259 --> 00:05:47.508
Szemöldökráncolás,
a zavartság jelzője.

00:05:47.508 --> 00:05:51.515
Homlokráncolás. Tökéletes.

00:05:51.515 --> 00:05:55.008
Ezek mind különböző mozgásegységek.
Sokkal több van belőlük.

00:05:55.008 --> 00:05:57.040
Ez csak egy karcsúsított demo.

00:05:57.040 --> 00:06:00.188
Minden leolvasást
érzelmi adatpontnak nevezünk,

00:06:00.188 --> 00:06:03.157
majd ezek ötvözése ábrázolja
a különböző érzelmeket.

00:06:03.157 --> 00:06:07.810
A demo jobb oldalán -- tégy úgy, 
mintha boldog lennél.

00:06:07.810 --> 00:06:09.264
Ez az öröm. Kigyúl az öröm.

00:06:09.264 --> 00:06:11.191
Most vágj utálkozó arcot.

00:06:11.191 --> 00:06:15.463
Gondolj arra, milyen volt, amikor Zayn
kilépett a One Direction-ből.

00:06:15.463 --> 00:06:16.973
(Nevetés)

00:06:16.973 --> 00:06:21.315
Úgy, ráncold az orrod. Klassz.

00:06:21.315 --> 00:06:25.046
A kötődés eléggé negatív,
biztos nagy rajongója voltál.

00:06:25.046 --> 00:06:27.746
A kötődés a tapasztalat
pozitív vagy negatív jellege,

00:06:27.746 --> 00:06:30.532
az elkötelezettség pedig
azt jelzi, mennyire kifejező.

00:06:30.532 --> 00:06:33.946
Képzeljék el, ha Cloe hozzáférne
egy valós idejű érzelem-csatornához,

00:06:33.946 --> 00:06:36.755
és megoszthatná azt mindenkivel,
akivel csak akarná.

00:06:36.755 --> 00:06:39.678
Köszönöm.

00:06:39.678 --> 00:06:44.299
(Taps)

00:06:45.569 --> 00:06:50.839
Az eddigiekben 12 milliárd ilyen
érzelmi adatpontot gyűjtöttünk.

00:06:50.839 --> 00:06:53.450
Ez a legnagyobb érzelem-adatbázis
a világon.

00:06:53.450 --> 00:06:56.413
2,9 millió arcot ábrázoló
videóról gyűjtöttük ezeket,

00:06:56.413 --> 00:06:59.013
olyanoktól, akik beleegyeztek
érzelmeik megosztásába,

00:06:59.013 --> 00:07:02.218
világszerte, 75 országban.

00:07:02.218 --> 00:07:03.933
Naponta növekszik.

00:07:04.423 --> 00:07:06.490
Lélegzetelállító, hogy tudunk

00:07:06.490 --> 00:07:09.685
számszerűsíteni egy ennyire
személyes dolgot, mint az érzelmeink,

00:07:09.685 --> 00:07:11.920
és ilyen nagyságrendben tudjuk.

00:07:11.920 --> 00:07:14.097
Mit tanultunk tehát eddig?

00:07:14.877 --> 00:07:17.208
A nemek.

00:07:17.208 --> 00:07:20.854
Adataink igazolják,
amit valószínűleg sejtenek.

00:07:20.854 --> 00:07:22.711
A nők kifejezőbbek, mint a férfiak.

00:07:22.711 --> 00:07:25.394
Nemcsak többet mosolyognak,
de a mosolyuk tovább tart,

00:07:25.394 --> 00:07:28.298
és most tényleg számszerűsíteni tudjuk,
mi az, amire

00:07:28.298 --> 00:07:30.434
a nők és a férfiak eltérően válaszolnak.

00:07:30.434 --> 00:07:32.724
Nézzük a kultúrát: az Egyesült Államokban

00:07:32.724 --> 00:07:35.928
a nők 40%-kal kifejezőbbek, 
mint a férfiak,

00:07:35.928 --> 00:07:39.573
de érdekes módon az Egyesült Királyságban
nem látunk közöttük különbséget.

00:07:39.573 --> 00:07:42.079
(Nevetés)

00:07:43.116 --> 00:07:47.143
Életkor: az 50 év felettiek

00:07:47.143 --> 00:07:50.579
25%-kal érzelmesebbek a fiataloknál.

00:07:51.719 --> 00:07:55.571
A huszonéves nők sokkal többet
mosolyognak, mint az azonos korú férfiak,

00:07:55.571 --> 00:07:59.410
lehet, hogy ez szükséges a randizáshoz.

00:07:59.410 --> 00:08:02.027
De az adatokban talán az
lepett meg a legjobban,

00:08:02.027 --> 00:08:05.230
hogy úgy tűnik, mindig kifejezőek vagyunk,

00:08:05.230 --> 00:08:08.063
még akkor is, amikor egyedül ülünk
a készülékeink előtt,

00:08:08.063 --> 00:08:11.337
és nemcsak amikor cicás videókat
nézünk a Facebookon.

00:08:12.037 --> 00:08:15.047
Kifejezőek vagyunk e-mail és SMS írásakor,
online vásárláskor,

00:08:15.047 --> 00:08:17.347
még az adóbevallás kitöltésekor is.

00:08:17.347 --> 00:08:19.739
Hol használják ma ezeket az adatokat?

00:08:19.739 --> 00:08:22.242
Annak megértésére, 
mennyire köt le a média,

00:08:22.242 --> 00:08:24.976
hogy mi és miért terjed a neten, 
hogy hogyan választunk,

00:08:24.976 --> 00:08:28.076
és arra, hogyan építsük be
a gesztus értelmezését a technológiába.

00:08:28.076 --> 00:08:32.347
Bemutatok néhány, a szívemhez 
különösen közel álló példát.

00:08:33.017 --> 00:08:36.085
A gesztus-értelmező szemüvegek segítenek

00:08:36.085 --> 00:08:39.313
a gyengénlátó embereknek
leolvasni mások arcát,

00:08:39.313 --> 00:08:43.500
és segítenek az autista embereknek
az érzelmek értelmezésében,

00:08:43.500 --> 00:08:46.278
ők ezzel nagyon küszködnek.

00:08:47.738 --> 00:08:50.597
Oktatás: képzeljék el,
hogy az online tanulásban az app

00:08:50.597 --> 00:08:53.407
érzékeli, ha összezavarodtunk, 
és lelassít;

00:08:53.407 --> 00:08:55.264
ha unatkozunk, akkor felgyorsít,

00:08:55.264 --> 00:08:58.233
ahogyan egy jó tanár tenné
az osztályteremben.

00:08:58.863 --> 00:09:01.464
Mi lenne, ha a karóránk figyelné
kedélyünket,

00:09:01.464 --> 00:09:04.157
az autónk észlelné, ha fáradtak vagyunk,

00:09:04.157 --> 00:09:06.705
vagy akár: a hűtőnk tudná,
hogy feszültek vagyunk,

00:09:06.705 --> 00:09:12.771
és lezárná magát, hogy megakadályozza,
hogy túlzabáljuk magunkat. (Nevetés)

00:09:12.771 --> 00:09:15.488
Igen, ezt szeretném.

00:09:15.488 --> 00:09:17.415
Mi lett volna, ha a cambridge-i időkben

00:09:17.415 --> 00:09:19.728
hozzáfértem volna az érzelem-csatornámhoz,

00:09:19.728 --> 00:09:23.257
és természetes módon meg tudtam volna
azt osztani otthonmaradt családommal,

00:09:23.257 --> 00:09:27.228
mintha mindannyian együtt 
lennénk, ugyanabban a szobában?

00:09:27.228 --> 00:09:30.370
Azt gondolom, öt év múlva

00:09:30.370 --> 00:09:32.707
minden eszközünkben lesz érzelem-csip,

00:09:32.707 --> 00:09:36.771
és már nem fogunk emlékezni arra, 
amikor hiába néztünk homlokráncolva,

00:09:36.771 --> 00:09:41.020
készülékünk nem mondta: 
"Ez ugye nem tetszett?"

00:09:41.020 --> 00:09:44.781
A nagy kihívás az, hogy a technológiának
olyan sok alkalmazási területe van,

00:09:44.781 --> 00:09:47.684
hogy a csapatommal rájöttünk:
nem tudjuk mindet mi megépíteni,

00:09:47.684 --> 00:09:51.180
ezért közzétettük a technológiát,
hogy más fejlesztők is

00:09:51.180 --> 00:09:53.294
tudjanak építeni rá és alkotni.

00:09:53.294 --> 00:09:57.380
Elismerjük, hogy vannak
potenciális kockázatok,

00:09:57.380 --> 00:09:59.447
és vissza lehet élni ezzel,

00:09:59.447 --> 00:10:02.396
de személy szerint, miután
oly sok éve dolgozom rajta,

00:10:02.396 --> 00:10:05.368
hiszem, hogy az érzelmileg
intelligens technológia léte

00:10:05.368 --> 00:10:07.643
olyan nagy haszon az emberiségnek,

00:10:07.643 --> 00:10:11.219
hogy az jócskán ellensúlyozza
a visszaélés lehetőségét.

00:10:11.219 --> 00:10:13.750
Meghívom Önöket is,
vegyenek részt a beszélgetésben.

00:10:13.750 --> 00:10:16.304
Minél többen tudnak a technológiáról,

00:10:16.304 --> 00:10:19.481
annál többen mondhatnak 
véleményt használatáról.

00:10:20.901 --> 00:10:25.475
Ahogy tehát egyre inkább digitálissá
válik életünk,

00:10:25.475 --> 00:10:28.973
vesztésre állunk a csatában,
amelyben korlátozni próbáljuk eszközeink

00:10:28.973 --> 00:10:31.202
használatát, hogy 
visszakérjük érzelmeinket.

00:10:32.442 --> 00:10:36.356
Ehelyett próbálok érzelmeket
vinni technológiánkba,

00:10:36.356 --> 00:10:38.585
és fogékonyabbá tenni azt.

00:10:38.585 --> 00:10:41.255
Azt akarom, hogy az eszközök,
amelyek elválasztottak,

00:10:41.255 --> 00:10:43.717
újra összekössenek minket.

00:10:43.717 --> 00:10:48.305
A technológia emberiessé tételével
kitűnő lehetőségünk nyílik arra,

00:10:48.305 --> 00:10:51.602
hogy újragondoljuk,
hogyan viszonyulunk a gépekhez,

00:10:51.602 --> 00:10:56.083
és ennek folytán mi, emberi lények,

00:10:56.083 --> 00:10:57.987
hogyan viszonyulunk egymáshoz.

00:10:57.987 --> 00:11:00.147
Köszönöm.

00:11:00.147 --> 00:11:03.460
(Taps)

