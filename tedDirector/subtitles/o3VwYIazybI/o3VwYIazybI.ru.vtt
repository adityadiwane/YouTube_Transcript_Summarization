WEBVTT
Kind: captions
Language: ru

00:00:00.000 --> 00:00:07.000
Переводчик: Alina Siluyanova
Редактор: Volha ( Olya ) Douban

00:00:12.556 --> 00:00:16.343
Наши эмоции оказывают влияние
на все стороны жизни:

00:00:16.343 --> 00:00:20.149
от здоровья и способов получения знаний,
до ведения бизнеса и принятия

00:00:20.149 --> 00:00:21.922
важных либо не очень важных решений.

00:00:22.672 --> 00:00:26.312
Наши эмоции также влияют на то,
как мы взаимодействуем друг с другом.

00:00:27.132 --> 00:00:30.408
Мы созданы для жизни в мире эмоций,

00:00:31.108 --> 00:00:35.427
но вместо этого
всё чаще и чаще мы живём вот так —

00:00:35.427 --> 00:00:38.561
это смс от моей дочери,
которое я получила вчера вечером, —

00:00:38.561 --> 00:00:41.301
в мире, напрочь этих эмоций лишённом.

00:00:41.301 --> 00:00:43.252
Я намерена это изменить.

00:00:43.252 --> 00:00:47.343
Я хочу вернуть эмоции
в наш цифровой мир.

00:00:48.223 --> 00:00:51.300
Этот путь я начала 15 лет назад.

00:00:51.300 --> 00:00:53.366
Я работала программистом в Египте

00:00:53.366 --> 00:00:57.871
и только что поступила в аспирантуру
в Кембридже.

00:00:57.871 --> 00:00:59.984
Я сделала нечто несвойственное

00:00:59.984 --> 00:01:04.209
молодым новобрачным
мусульманкам-египтянкам:

00:01:05.599 --> 00:01:08.598
при поддержке своего мужа,
которому пришлось остаться в Египте,

00:01:08.598 --> 00:01:11.616
я упаковала чемоданы
и переехала в Англию.

00:01:11.616 --> 00:01:14.844
В Кембридже, за тысячи километров от дома,

00:01:14.844 --> 00:01:17.917
я осознала, что провожу
за ноутбуком больше времени,

00:01:17.917 --> 00:01:19.836
чем с людьми.

00:01:20.486 --> 00:01:25.339
Но несмотря на эту близость, мой ноутбук
не имел представления о моих чувствах.

00:01:25.339 --> 00:01:28.050
Он не знал, счастлива ли я,

00:01:28.050 --> 00:01:31.538
был ли у меня тяжёлый день,
напряжена ли я или потеряна,

00:01:31.538 --> 00:01:33.710
и это стало меня расстраивать.

00:01:35.600 --> 00:01:40.031
Даже хуже того:
общаясь с семьёй онлайн,

00:01:41.221 --> 00:01:44.703
я чувствовала, как эмоции
испаряются в киберпространстве.

00:01:44.703 --> 00:01:49.858
Я скучала по дому, мне было одиноко,
иногда я даже плакала,

00:01:49.858 --> 00:01:54.786
и единственным способом
передать все эти чувства было вот это.

00:01:54.786 --> 00:01:56.806
(Смех)

00:01:56.806 --> 00:02:01.070
Технологии сегодняшнего дня
обладают огромным IQ, но не EQ —

00:02:01.070 --> 00:02:04.956
высокий показатель интеллекта,
но никакого эмоционального интеллекта.

00:02:04.956 --> 00:02:07.153
Тогда я задумалась:

00:02:07.153 --> 00:02:10.777
а что, если бы технологии
могли ощущать наши эмоции?

00:02:10.777 --> 00:02:14.853
Что, если бы наши устройства могли ощущать,
как мы себя чувствуем, и реагировать

00:02:14.853 --> 00:02:18.426
в соответствии этому, как сделал бы
эмоционально интеллектуальный друг?

00:02:18.436 --> 00:02:22.230
Эти вопросы подтолкнули меня
и мою команду

00:02:22.230 --> 00:02:26.607
на создание технологий, способных
понимать и отвечать на наши эмоции.

00:02:26.607 --> 00:02:29.307
И начали мы с человеческого лица.

00:02:30.577 --> 00:02:33.750
Человеческое лицо —
один из самых мощных каналов,

00:02:33.750 --> 00:02:37.766
используемых нами для передачи
социальных и эмоциональных состояний:

00:02:37.766 --> 00:02:40.776
наслаждения, удивления,

00:02:40.776 --> 00:02:44.139
сопереживания, любопытства.

00:02:44.979 --> 00:02:49.907
В науке об эмоциях каждое движение
мышцами лица мы называем действием.

00:02:49.907 --> 00:02:52.262
Например, действие 12 —

00:02:52.262 --> 00:02:54.870
это не название голливудского блокбастера,

00:02:54.870 --> 00:02:58.012
а движение уголков губ вверх —
главный компонент улыбки.

00:02:58.012 --> 00:03:00.980
Давайте-ка все попробуем улыбнуться!

00:03:00.980 --> 00:03:03.954
Другой пример — действие 4.
Это нахмуривание бровей.

00:03:03.954 --> 00:03:05.972
Это когда сводишь брови вместе,

00:03:05.972 --> 00:03:07.939
и получаются морщинки.

00:03:07.939 --> 00:03:11.944
Мы их не любим, но они —
явный показатель негативной эмоции.

00:03:11.944 --> 00:03:14.510
У нас 45 таких действий,

00:03:14.510 --> 00:03:17.760
и они комбинируются
для передачи сотен эмоций.

00:03:18.350 --> 00:03:22.251
Научить компьютер
считывать выражения лица трудно,

00:03:22.251 --> 00:03:25.223
потому что такие действия
могут быть быстрыми, нечёткими

00:03:25.223 --> 00:03:27.777
и по-разному комбинироваться.

00:03:27.777 --> 00:03:31.515
Возьмём, к примеру, улыбку и ухмылку.

00:03:31.515 --> 00:03:35.268
Они выглядят похоже,
но значат абсолютно разные вещи.

00:03:35.268 --> 00:03:36.986
(Смех)

00:03:36.986 --> 00:03:38.970
Улыбка позитивна,

00:03:38.970 --> 00:03:40.960
а ухмылка часто негативна.

00:03:40.960 --> 00:03:45.136
Иногда ухмылка
может сделать вас знаменитым.

00:03:45.136 --> 00:03:47.960
Но если серьёзно,
важно, чтобы компьютер

00:03:47.960 --> 00:03:50.505
мог определить разницу
между этими двумя выражениями.

00:03:50.505 --> 00:03:52.257
Как это сделать?

00:03:52.257 --> 00:03:54.034
Мы снабжаем наши алгоритмы

00:03:54.034 --> 00:03:58.524
десятками тысяч примеров
людей, которые точно улыбаются, —

00:03:58.524 --> 00:04:01.589
людей из разных этнических групп,
разных возрастов, разного пола.

00:04:01.589 --> 00:04:03.390
То же самое мы делаем и для ухмылки.

00:04:04.120 --> 00:04:05.954
А затем с помощью глубинного обучения

00:04:05.954 --> 00:04:08.810
алгоритм рассматривает
все эти текстуры, морщинки

00:04:08.810 --> 00:04:11.390
и изменения форм лица

00:04:11.390 --> 00:04:14.592
и запоминает, что у всех улыбок
есть общие характеристики,

00:04:14.592 --> 00:04:17.583
а у ухмылок — слегка иные характеристики.

00:04:17.583 --> 00:04:20.141
В следующий раз,
когда компьютер видит новое лицо,

00:04:20.141 --> 00:04:22.440
он, по сути, узнаёт,

00:04:22.440 --> 00:04:25.473
что у этого лица есть
те же самые характеристики улыбки,

00:04:25.473 --> 00:04:28.551
и восклицает:
«Ага! Узнаю. Это выражение улыбки».

00:04:30.381 --> 00:04:33.181
Лучший способ показать
эту технологию в работе —

00:04:33.181 --> 00:04:35.317
это живая демонстрация,

00:04:35.317 --> 00:04:38.790
так что мне нужен волонтёр,
желательно с лицом.

00:04:38.790 --> 00:04:41.564
(Смех)

00:04:41.564 --> 00:04:43.795
Хлоя будет сегодня нашим волонтёром.

00:04:45.325 --> 00:04:49.783
За последние 5 лет мы превратились
из исследовательского проекта в MIT

00:04:49.783 --> 00:04:50.939
в компанию,

00:04:50.939 --> 00:04:53.951
где моя команда упорно трудилась
над тем, чтобы технология заработала,

00:04:53.951 --> 00:04:56.230
как мы любим говорить,
в естественных условиях.

00:04:56.230 --> 00:04:59.210
Мы также её уменьшили,
и теперь центральное ядро эмоций

00:04:59.210 --> 00:05:02.530
работает на любом мобильном
устройстве с камерой, как вот этот iPad.

00:05:02.530 --> 00:05:04.296
Давайте попробуем.

00:05:06.756 --> 00:05:10.680
Как вы видите,
алгоритм обнаружил лицо Хлои —

00:05:10.680 --> 00:05:12.372
вот эта белая рамка —

00:05:12.372 --> 00:05:14.943
и он отслеживает
основные характерные точки на её лице:

00:05:14.943 --> 00:05:17.799
это её брови, глаза, рот и нос.

00:05:17.799 --> 00:05:20.786
Вопрос в том, может ли он
определить выражение её лица?

00:05:20.786 --> 00:05:22.457
Протестируем механизм.

00:05:22.457 --> 00:05:26.643
Сначала покажи мне каменное лицо.
Да, супер. (Смех)

00:05:26.643 --> 00:05:29.456
А затем, когда она улыбается...
Искренняя улыбка, здорово!

00:05:29.456 --> 00:05:31.946
Видите, зелёная полоска растёт,
когда она улыбается?

00:05:31.946 --> 00:05:33.108
Это была широкая улыбка.

00:05:33.108 --> 00:05:36.311
Можешь слегка улыбнуться,
чтобы посмотреть, распознает ли компьютер?

00:05:36.311 --> 00:05:37.952
Да, распознаёт и неявные улыбки.

00:05:37.952 --> 00:05:39.897
Мы усердно трудились,
чтобы это работало.

00:05:39.897 --> 00:05:43.439
Теперь подними бровь —
индикатор удивления.

00:05:43.439 --> 00:05:47.688
Сдвинь брови —
индикатор замешательства. (Смех)

00:05:47.688 --> 00:05:51.695
Посмотри с неодобрением. Да, отлично.

00:05:51.695 --> 00:05:55.188
Это различного рода действия.
Их гораздо больше.

00:05:55.188 --> 00:05:57.220
Это короткая демонстрация.

00:05:57.220 --> 00:06:00.368
Каждое считывание эмоции
мы называем точкой данных.

00:06:00.368 --> 00:06:03.337
Они подпитывают друг друга
для изображения разных эмоций.

00:06:03.337 --> 00:06:07.260
На правой стороне демо —
смотри, как будто ты счастливая.

00:06:07.260 --> 00:06:09.444
Это радость. Радость усиливается.

00:06:09.444 --> 00:06:11.371
А теперь покажи мне отвращение.

00:06:11.371 --> 00:06:15.643
Вспомни, как Зейн ушёл 
из группы One Direction.

00:06:15.643 --> 00:06:17.153
(Смех)

00:06:17.153 --> 00:06:21.495
Да, сморщи нос. Великолепно.

00:06:21.495 --> 00:06:25.016
Валентность весьма негативная,
то есть ты, пожалуй, была фанатом.

00:06:25.016 --> 00:06:27.926
Валентность — это насколько опыт
положителен или отрицателен.

00:06:27.926 --> 00:06:30.712
А вовлечённость —
насколько она выразительна.

00:06:30.712 --> 00:06:34.496
Представьте, если бы у Хлои был доступ
к этому потоку эмоций в реальном времени

00:06:34.496 --> 00:06:37.025
и она могла бы поделиться этим
с кем угодно.

00:06:37.025 --> 00:06:38.478
Спасибо.

00:06:38.478 --> 00:06:44.479
(Аплодисменты)

00:06:45.749 --> 00:06:51.019
На данный момент мы собрали
12 миллиардов таких вот точек данных.

00:06:51.019 --> 00:06:53.630
Это самая крупная
база данных эмоций в мире.

00:06:53.630 --> 00:06:56.593
Мы собрали её
с 2,9 миллионов видео —

00:06:56.593 --> 00:06:59.433
людей, согласившихся
поделиться с нами своими эмоциями, —

00:06:59.433 --> 00:07:02.398
из 75 стран мира.

00:07:02.398 --> 00:07:04.113
База данных с каждым днём растёт.

00:07:04.603 --> 00:07:07.000
Меня поражает, что теперь мы можем

00:07:07.000 --> 00:07:09.865
измерять нечто настолько личное,
как эмоции,

00:07:09.865 --> 00:07:12.100
причём в таком масштабе.

00:07:12.100 --> 00:07:14.277
Что мы узнали на сегодняшний день?

00:07:15.057 --> 00:07:15.808
Данные о полах.

00:07:17.388 --> 00:07:21.034
Наши данные подтверждают то,
о чём вы, пожалуй, сами догадываетесь:

00:07:21.034 --> 00:07:22.891
женщины более выразительны,
чем мужчины.

00:07:22.891 --> 00:07:25.714
Они не только чаще улыбаются,
но и улыбки их длятся дольше.

00:07:25.714 --> 00:07:27.388
И теперь мы можем измерить,

00:07:27.388 --> 00:07:30.014
на что мужчины и женщины
реагируют по-разному.

00:07:30.614 --> 00:07:31.984
Начнём с культуры:

00:07:31.984 --> 00:07:36.108
в США женщины на 40%
выразительнее мужчин,

00:07:36.108 --> 00:07:39.753
но любопытно, что в Англии
подобного различия не наблюдается.

00:07:39.753 --> 00:07:42.259
(Смех)

00:07:43.296 --> 00:07:47.323
Возраст: люди от 50 лет и старше

00:07:47.323 --> 00:07:50.759
на 25% более эмоциональны,
чем те, кто моложе.

00:07:51.489 --> 00:07:55.751
Женщины после 20 улыбаются
куда чаще мужчин того же возраста,

00:07:55.751 --> 00:07:58.300
может, это необходимо для флирта.

00:07:59.380 --> 00:08:02.207
Но, пожалуй, больше всего нас удивило то,

00:08:02.207 --> 00:08:05.410
что мы постоянно передаём эмоции,

00:08:05.410 --> 00:08:08.243
даже когда в одиночестве
сидим за своими устройствами,

00:08:08.243 --> 00:08:11.517
причём не только когда смотрим видео
о кошках на Facebook.

00:08:12.217 --> 00:08:15.417
Мы выражаем эмоции, когда пишем имейлы,
смс, делаем покупки онлайн

00:08:15.417 --> 00:08:17.527
или даже оформляем налоги.

00:08:17.527 --> 00:08:19.919
Где сейчас используются эти данные?

00:08:19.919 --> 00:08:22.022
Для анализа взаимодействия со СМИ,

00:08:22.022 --> 00:08:24.896
то есть чтобы изучить
виральность и электоральное поведение;

00:08:24.896 --> 00:08:28.746
а также в технологиях, делающих 
возможным проявление эмоций.

00:08:28.746 --> 00:08:32.007
Я хочу поделиться несколькими 
дорогими мне примерами.

00:08:33.197 --> 00:08:36.265
Очки с эмоциональной поддержкой
позволяют пользователю

00:08:36.265 --> 00:08:39.493
со слабым зрением
считывать лица окружающих,

00:08:39.493 --> 00:08:42.980
они могут помочь людям с аутизмом
определять эмоции —

00:08:42.980 --> 00:08:45.188
сложная задача для таких людей.

00:08:47.468 --> 00:08:50.777
В образовании: представьте,
что ваше обучающее приложение

00:08:50.777 --> 00:08:53.357
чувствует, что вы запутались,
и понижает темп,

00:08:53.357 --> 00:08:55.444
или чувствует,
что вам скучно, и ускоряется,

00:08:55.444 --> 00:08:57.923
как бы сделал хороший учитель в классе.

00:08:59.043 --> 00:09:01.644
Что, если бы наручные часы
отслеживали ваше настроение

00:09:01.644 --> 00:09:04.027
или автомобиль ощущал, что вы устали,

00:09:04.027 --> 00:09:07.125
или, может, ваш холодильник
чувствовал, что вы напряжены,

00:09:07.125 --> 00:09:11.451
и запирался, чтобы предотвратить
обжорство. (Смех)

00:09:11.451 --> 00:09:13.528
Мне бы такое понравилось.

00:09:15.668 --> 00:09:17.595
Что, если бы, когда я была в Кембридже,

00:09:17.595 --> 00:09:20.738
у меня был доступ к моему
эмоциональному потоку в реальном времени

00:09:20.738 --> 00:09:23.437
и я могла бы поделиться им
со своей семьёй,

00:09:23.437 --> 00:09:27.408
как если бы они были 
со мной в одной комнате?

00:09:27.408 --> 00:09:30.200
Думаю, через 5 лет

00:09:30.200 --> 00:09:32.887
у всех наших устройств
будет эмоциональный чип,

00:09:32.887 --> 00:09:36.951
и мы забудем о тех временах,
когда мы не могли просто нахмуриться,

00:09:36.951 --> 00:09:40.150
а наше устройство сказало бы:
«Тебе это не понравилось, не так ли?»

00:09:41.200 --> 00:09:42.770
Наша наибольшая трудность в том,

00:09:42.770 --> 00:09:45.201
что у этой технологии
так много областей применения,

00:09:45.201 --> 00:09:47.864
что я и моя команда не можем
всё делать в одиночку.

00:09:47.864 --> 00:09:51.360
Мы сделали эту технологию доступной,
чтобы другие разработчики

00:09:51.360 --> 00:09:53.474
могли начать свои проекты и творить.

00:09:53.474 --> 00:09:57.560
Мы осознаём, что есть риск

00:09:57.560 --> 00:09:59.627
и возможность неправильного обращения,

00:09:59.627 --> 00:10:02.576
но лично мне,
после многих лет за этим делом,

00:10:02.576 --> 00:10:04.818
кажется, что польза для человечества

00:10:04.818 --> 00:10:07.493
от наличия эмоционально
интеллектуальной технологии

00:10:07.493 --> 00:10:11.199
значительно перевешивает
риски злоупотребления.

00:10:11.199 --> 00:10:13.930
Я приглашаю всех принять участие.

00:10:13.930 --> 00:10:16.074
Чем больше людей
знают об этой технологии,

00:10:16.074 --> 00:10:19.901
тем больше возможности для каждого из нас
высказаться о том, как её использовать.

00:10:21.081 --> 00:10:25.335
По мере того, как наша жизнь
всё больше становится цифровой,

00:10:25.335 --> 00:10:29.153
мы ведём безнадёжную борьбу,
пытаясь обуздать применение устройств,

00:10:29.153 --> 00:10:31.382
чтобы вернуть нам наши эмоции.

00:10:32.622 --> 00:10:36.536
Вместо этого я пытаюсь
привнести эмоции в технологии

00:10:36.536 --> 00:10:38.765
и сделать их более чуткими.

00:10:38.765 --> 00:10:41.625
Я хочу, чтобы устройства,
отделившие нас друг от друга,

00:10:41.625 --> 00:10:43.267
снова нас объединили.

00:10:44.217 --> 00:10:48.485
Путём очеловечивания технологий
мы обретаем блестящую возможность

00:10:48.485 --> 00:10:51.782
переосмыслить то, как мы
взаимодействуем с машинами,

00:10:51.782 --> 00:10:56.263
а значит и то, как мы, люди,

00:10:56.263 --> 00:10:58.167
взаимодействуем друг с другом.

00:10:58.167 --> 00:10:59.497
Спасибо.

00:10:59.497 --> 00:11:01.980
(Аплодисменты)

