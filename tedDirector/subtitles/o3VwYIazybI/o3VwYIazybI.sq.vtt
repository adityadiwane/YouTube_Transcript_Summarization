WEBVTT
Kind: captions
Language: sq

00:00:00.000 --> 00:00:07.000
Translator: Rita Selimi
Reviewer: Helena Bedalli

00:00:12.556 --> 00:00:16.573
Emocionet tona e ndikojnë
çdo aspekt të jetës,

00:00:16.573 --> 00:00:20.149
prej shëndetit, nga ajo se si mësojmë,
si bëjmë biznes dhe si marim vendime,

00:00:20.149 --> 00:00:21.922
të mëdha dhe të vogla.

00:00:22.672 --> 00:00:26.162
Emocionet tona gjithashtu 
ndikojnë se si lidhemi me njëri-tjetrin.

00:00:27.132 --> 00:00:31.108
Ne kemi evoluar për të jetuar 
në një botë si kjo,

00:00:31.108 --> 00:00:35.427
por në vend të kësaj, ne po jetojmë
më shumë jetën tonë kështu --

00:00:35.427 --> 00:00:38.561
ky është një mesazh nga 
vajza ime natën e kaluar

00:00:38.561 --> 00:00:41.301
në një botë që i mungojnë emocionet.

00:00:41.301 --> 00:00:43.252
Unë jam në një mision për ta ndryshu këtë

00:00:43.252 --> 00:00:47.343
Unë dua t'i kthej emocionet tona 
prapë në eksperiencën digjitale.

00:00:48.223 --> 00:00:51.300
E fillova këtë rrugë para 15 viteve.

00:00:51.300 --> 00:00:53.366
Isha shkencëtare kompjuterash në Egjipt,

00:00:53.366 --> 00:00:57.871
dhe sapo u pata pranuar në një 
program Ph.D. në Universitetin Cambridge.

00:00:57.871 --> 00:00:59.984
Kështu bëra diçka të pazakonshme

00:00:59.984 --> 00:01:04.209
për një grua 
egjiptiane muslimane të sapomartuar:

00:01:05.599 --> 00:01:08.598
me mbështetjen e burrit tim, 
që duhej të qëndronte në Egjipt

00:01:08.598 --> 00:01:11.616
i bëra gati valixhet dhe 
u zhvendosa në Angli.

00:01:11.616 --> 00:01:14.844
Në Cambridge, 
mijëra kilometra larg shtëpisë,

00:01:14.844 --> 00:01:18.257
e kuptova që po kaloja 
më shumë kohë me laptopin

00:01:18.257 --> 00:01:20.486
se sa me njerëz.

00:01:20.486 --> 00:01:25.339
Pavarësisht këtij intimiteti, 
laptopi nuk kishte ide se si ndihesha.

00:01:25.339 --> 00:01:28.550
Nuk e dinte nëse isha e lumtur,

00:01:28.550 --> 00:01:31.538
nëse kam kaluar ditë të keqe,
jam e stresuar apo konfuze,

00:01:31.538 --> 00:01:34.460
dhe kjo filloi të bëhej frustruese.

00:01:35.600 --> 00:01:40.831
Edhe më keq, derisa 
komunikoja online me familjen në shtëpi,

00:01:41.421 --> 00:01:44.703
e ndjeja se të gjtha 
emocionet e mia u zhdukën në hapësirë.

00:01:44.703 --> 00:01:49.858
Isha përmalluar, isha e vetmuar, 
dhe në disa ditë edhe qaja

00:01:49.858 --> 00:01:54.786
por me çka mund t'i komunikoja 
këto emocione ishte kjo,

00:01:54.786 --> 00:01:56.806
(Te qeshura)

00:01:56.806 --> 00:02:01.780
Teknologjia sot ka shumë I.Q por aspak E.Q

00:02:01.780 --> 00:02:04.956
shumë inteligjencë kognitive,
por jo inteligjencë emocionale.

00:02:04.956 --> 00:02:07.153
Kjo më bëri të mendoj,

00:02:07.153 --> 00:02:10.777
çka nëse teknologjia do të mund 
t'i ndjente emocionet?

00:02:10.777 --> 00:02:14.853
çka nëse pajisjet do të mund ta dinin 
se si ndjehemi dhe reagojmë,

00:02:14.853 --> 00:02:17.866
në të njejtën mënyrë 
sikur një mik inteligjent?

00:02:18.666 --> 00:02:22.230
Këto pyetje na udhëhoqën mua dhe ekipin

00:02:22.230 --> 00:02:26.607
të krijojmë teknologji të cilat mund t'i 
lexojnë dhe t'i përgjigjen emocioneve tona

00:02:26.607 --> 00:02:29.697
dhe pika fillestare ishte fytyra e njeriut.

00:02:30.577 --> 00:02:33.750
Fytyra jonë është një prej 
kanalëve më të fuqishëm

00:02:33.750 --> 00:02:37.766
të cilët ne i përdorim për t'i komunikuar 
gjendjet tona sociale dhe emocionale,

00:02:37.766 --> 00:02:40.776
të gjitha prej kënaqësisë, surprizës,

00:02:40.776 --> 00:02:44.979
empatisë dhe kuriozitetit.

00:02:44.979 --> 00:02:49.907
Në shkencën e emocionëve, ne i quajmë çdo 
lëvizje të muskujve si njësi veprimi.

00:02:49.907 --> 00:02:52.832
Shembull, njësia veprimit 12,

00:02:52.832 --> 00:02:54.870
nuk është hit holliwudian,

00:02:54.870 --> 00:02:58.312
por është tërheqje e buzës, e që
është komponenti kryesor i buzëqeshjes.

00:02:58.312 --> 00:03:01.300
Provoni të gjithë. 
Le t'i shohim ca buzëqeshje.

00:03:01.300 --> 00:03:03.954
Shembull tjetër, njësia 4, 
është rrudhja e vetullave.

00:03:03.954 --> 00:03:06.192
Është kur t'i bashkosh vetullat së bashku

00:03:06.192 --> 00:03:08.459
dhe krijon të gjitha këto rrudha.

00:03:08.459 --> 00:03:12.754
Ne nuk i pëlqejmë , por ato janë 
indikator i fortë i emocionëve negative.

00:03:12.754 --> 00:03:14.960
Ne kemi rreth 45 njësi veprimi,

00:03:14.960 --> 00:03:18.350
dhe ato kombinohen 
për të paraqitur qindra emocione.

00:03:18.350 --> 00:03:22.251
Të mësosh një kompjuter t'i lexojë këto 
emocione të fytyrës është e vështirë,

00:03:22.251 --> 00:03:25.223
sepse këto njësi, 
mund të jenë të shpejta dhe delikate.

00:03:25.223 --> 00:03:27.777
dhe ato kombinohen në mënyra të ndryshme.

00:03:27.777 --> 00:03:31.515
Shembull, 
buzëqeshja dhe buzëqeshja e vetëkënaqur.

00:03:31.515 --> 00:03:35.268
Duken gati se të njejta 
por kanë kuptim të ndryshëm.

00:03:35.268 --> 00:03:36.986
(Te qeshura)

00:03:36.986 --> 00:03:39.990
Buzëqeshja është pozitive,

00:03:39.990 --> 00:03:41.260
tjetra është negative.

00:03:41.260 --> 00:03:45.136
Nganjëherë buzëqeshja e vetëkënaqur
mund t'ju bëjë të famshëm.

00:03:45.136 --> 00:03:47.960
Por seriozisht, është e rëndësishme 
për kompjuterin të mund

00:03:47.960 --> 00:03:50.815
ta tregoje dallimin mes dy shprehjeve.

00:03:50.815 --> 00:03:52.627
Pra si e bëjmë ne këtë?

00:03:52.627 --> 00:03:54.414
Ne i japim algoritmet

00:03:54.414 --> 00:03:58.524
mijëra shembuj të njerëzve 
që i dijmë që janë duke buzëqeshur,

00:03:58.524 --> 00:04:01.589
nga etnitete, mosha, gjini të ndryshme,

00:04:01.589 --> 00:04:04.400
dhe e bëjmë të njejtën 
për buzëqeshjen e vetëkënaqur.

00:04:04.400 --> 00:04:05.954
Pastaj, përdorim mësimin e thellë

00:04:05.954 --> 00:04:08.810
algoritmi shikon të gjitha
modelet dhe rrudhat

00:04:08.810 --> 00:04:11.390
dhe forma ndryshon në fytyrën tonë,

00:04:11.390 --> 00:04:14.592
dhe e mëson se të gjitha buzëqeshjet
kanë karakteristika të ngjashme

00:04:14.592 --> 00:04:17.773
të gjitha buzëqeshjet e vetëkënaqura kanë
karakteristika delikate.

00:04:17.773 --> 00:04:20.141
Dhe kur herën tjetër 
që e sheh një fytyrë të re,

00:04:20.141 --> 00:04:22.440
e mëson që

00:04:22.440 --> 00:04:25.473
kjo fytyrë ka 
karakteristikat e një buzëqeshje,

00:04:25.473 --> 00:04:29.751
dhe thot "Aha, unë e di këte.
Kjo është shprehja për buzëqeshjen."

00:04:30.381 --> 00:04:33.181
Mënyra më e mirë
për ta demonstruar si punon kjo teknologji

00:04:33.181 --> 00:04:35.317
është ta provojmë drejtpërdrejtë,

00:04:35.317 --> 00:04:39.230
më duhet një vullnetar, 
preferohet dikush me fytyrë.

00:04:39.230 --> 00:04:41.564
(Te qeshura)

00:04:41.564 --> 00:04:44.335
Cloe do të jetë vullnetarja jonë sot.

00:04:45.325 --> 00:04:49.783
Këto 5 vitet e fundit, ne kemi kaluar nga 
të qenurit një projekt hulumtues ne MIT

00:04:49.783 --> 00:04:50.939
në një kompani,

00:04:50.939 --> 00:04:54.131
ku ekipi im ka punuar shumë për ta bërë 
këtë teknologji të punojë,

00:04:54.131 --> 00:04:56.540
si na pëlqen të themi, në egërsi.

00:04:56.540 --> 00:04:59.210
Ne edhe e kemi tkurrur 
aq sa motori i emocionëve

00:04:59.210 --> 00:05:02.530
punon në çdo paisje me kamerë, 
sikur ky iPad.

00:05:02.530 --> 00:05:05.316
Pra hajde ta provojmë.

00:05:06.756 --> 00:05:10.680
Pra siq po e shihni, algoritmi
ka gjetur fytyrën e Cloe-it.

00:05:10.680 --> 00:05:12.372
pra është kjo kutia e bardhë,

00:05:12.372 --> 00:05:14.943
është duke i gjetur
tiparet kryesore në fytyrën e saj,

00:05:14.943 --> 00:05:17.799
vetullat e saj, sytë, gojën dhe hundën.

00:05:17.799 --> 00:05:20.786
Pyetja është, 
a mund ta njohe shprehjen e saj?

00:05:20.786 --> 00:05:22.457
Pra, ne do ta provojmë makinën.

00:05:22.457 --> 00:05:26.643
Në fillim, jepma poker face.
Mbresëlënëse. (Qeshin)

00:05:26.643 --> 00:05:29.456
Derisa ajo buzëqesh, 
kjo është buzëqeshje e sinqertë.

00:05:29.456 --> 00:05:31.756
Shiriti i gjelbërt rritet derisa ajo qesh.

00:05:31.756 --> 00:05:32.978
Kjo ishte e madhe.

00:05:32.978 --> 00:05:36.021
A po e provon një më delikate
për ta parë nëse e njeh kompjuteri?

00:05:36.021 --> 00:05:38.352
Po e njeh edhe buzëqeshjen delikate.

00:05:38.352 --> 00:05:40.477
Kemi punuar shumë që kjo të ndodhë.

00:05:40.477 --> 00:05:43.439
Tani, vetulla e ngritur, 
indikator i surprizës.

00:05:43.439 --> 00:05:47.688
Rrudhosja e vetullave, 
indikator i konfuzionit.

00:05:47.688 --> 00:05:51.695
Trego pakënaqësi, perfekt.

00:05:51.695 --> 00:05:55.188
Këto janë disa prej njësive.
Ka shumë më shumë.

00:05:55.188 --> 00:05:57.220
Ky është demo i zvogëluar.

00:05:57.220 --> 00:06:00.368
Ne e quajmë çdo lexim 
si të dhëna,

00:06:00.368 --> 00:06:03.337
që dhezen së bashku 
për të portretizuar emocione të ndryshme.

00:06:03.337 --> 00:06:07.990
Në anën e djathtë-- 
shiko sikur se je e lumtur.

00:06:07.990 --> 00:06:09.444
Pra lumturia dhezet.

00:06:09.444 --> 00:06:11.371
Tani bëje fytyrën sikur neveritesh.

00:06:11.371 --> 00:06:15.643
Provo ta kujtosh si ishte 
kur Zayn la One Direction.

00:06:15.643 --> 00:06:17.153
(Qeshin)

00:06:17.153 --> 00:06:21.495
Po, rrudhe hundën. Mrekullueshëm.

00:06:21.495 --> 00:06:25.226
Valenca është negative, 
sigurisht paske qenë fanse e madhe.

00:06:25.226 --> 00:06:27.926
Valenca tregon a është 
pozitive apo negative eksperienca

00:06:27.926 --> 00:06:30.712
ndërsa angazhimi tregon 
sa ekspresive është ajo.

00:06:30.712 --> 00:06:34.126
Imagjinoi sikur Cloe të kishte
qasje te kjo në kohe reale të emocioneve

00:06:34.126 --> 00:06:36.935
dhe ta ndante me këdo.

00:06:36.935 --> 00:06:39.858
Faleminderit.

00:06:39.858 --> 00:06:44.479
(Duartrokitje)

00:06:45.749 --> 00:06:51.019
Deri tani, ne kemi grumbulluar 12 miliard 
të dhëna të këtyre emocioneve.

00:06:51.019 --> 00:06:53.630
Është databaza më e madhe e emocioneve.

00:06:53.630 --> 00:06:56.593
Ne i kemi mbledhur këto 
nga 2.9 milionë video të fytyrave,

00:06:56.593 --> 00:06:59.193
njerëz që janë pajtuar 
mi nda emocionet e tyre me ne.

00:06:59.193 --> 00:07:02.398
nga 75 vende rreth botës.

00:07:02.398 --> 00:07:04.113
Po rritet çdo ditë.

00:07:04.603 --> 00:07:06.670
Mua më mahnit kjo

00:07:06.670 --> 00:07:09.865
se si mundemi të përcaktojmë diqka 
aq personale sa emocionet tona,

00:07:09.865 --> 00:07:12.100
e ne mund ta bëjmë këtë 
deri në këtë shkallë.

00:07:12.100 --> 00:07:14.277
Pra çka kemi mësuar ne?

00:07:15.057 --> 00:07:17.388
Gjinia.

00:07:17.388 --> 00:07:21.034
Të dhënat tona konfirmojnë diqka 
për të cilën ju mund të keni dyshuar.

00:07:21.034 --> 00:07:22.891
Gratë shprehen më shume se burrat.

00:07:22.891 --> 00:07:25.574
Jo vetëm që buzëqeshin më shumë
por e zgjasin më gjatë

00:07:25.574 --> 00:07:28.478
dhe tani ne mundemi me përcaktu 
se pse burrat dhe gratë

00:07:28.478 --> 00:07:30.614
përgjigjen ndryshe.

00:07:30.614 --> 00:07:32.904
Le ta provojmë kulturën: 
Në Shtetet e bashkuara,

00:07:32.904 --> 00:07:36.108
gratë shprehen 40 përçind 
më shumë se burrat,

00:07:36.108 --> 00:07:39.753
por për kuriozitet, nuk shohim 
ndonjë dallim në U.K mes burrave dhe grave

00:07:39.753 --> 00:07:42.259
(Qeshin)

00:07:43.296 --> 00:07:47.323
Mosha: njerëzit të cilët janë 
50 vjet e më të vjetër

00:07:47.323 --> 00:07:50.759
janë 25 përçind më emotivë se sa të rinjtë

00:07:51.899 --> 00:07:55.751
Gratë në të njëzetat buzëqeshin 
më shumë se burrat në moshën e njejtë.

00:07:55.751 --> 00:07:59.590
ndoshta një domosdoshmëri për takime.

00:07:59.590 --> 00:08:02.207
Por çka na befason neve nga këto të dhëna

00:08:02.207 --> 00:08:05.410
është që ne shprehemi gjatë tërë kohës ,

00:08:05.410 --> 00:08:08.243
edhe kur jemi ulur vetëm 
përballë paisjeve tona,

00:08:08.243 --> 00:08:11.517
e jo vetëm kur jemi duke shikuar 
video të maceve në Facebook.

00:08:12.217 --> 00:08:15.227
Ne shprehemi kur dërgojmë email,
shkruajmë ose kur blejmë online

00:08:15.227 --> 00:08:17.527
ose kur paguajmë taksat.

00:08:17.527 --> 00:08:19.919
Ku përdoren këto të dhëna sot?

00:08:19.919 --> 00:08:22.682
Për të kuptuar si lidhemi ne me mediat,

00:08:22.682 --> 00:08:25.166
për të kuptuar diqka që bëhet virale 
dhe votimin;

00:08:25.166 --> 00:08:27.906
dhe për të fuqizuar 
teknologji të emocionëve,

00:08:27.906 --> 00:08:32.527
dhe dua t'i ndaj disa shembuj që i 
kam shumë për zemër.

00:08:33.197 --> 00:08:36.265
Syzet me mundësi leximi të emocionëve
mund të ndihmojnë individët

00:08:36.265 --> 00:08:39.493
që janë vizualisht të paaftë 
t'i lexojnë fytyrat e tjerëve,

00:08:39.493 --> 00:08:43.680
dhe mund të ndihmojë personat me spektrin
e autizmit t'i interpretojnë emocionet,

00:08:43.680 --> 00:08:46.458
diqka me të cilën ata vërtet luftojnë.

00:08:47.918 --> 00:08:50.777
Në edukim, imagjinoni sikur 
aplikacionet e mësimit

00:08:50.777 --> 00:08:53.587
ta dinin se jeni konfuz dhe ta ngadalësojne

00:08:53.587 --> 00:08:55.444
ose që jeni mërzitur e ta përshpejtojnë

00:08:55.444 --> 00:08:58.413
sikur do ta bënte një mësues i mirë.

00:08:59.043 --> 00:09:01.644
çka nëse ora e dorës 
do të llogariste disponimin,

00:09:01.644 --> 00:09:04.337
ose vetura ta dinte që je i lodhur,

00:09:04.337 --> 00:09:06.885
ose frigoriferi ta dinte se je i stresuar,

00:09:06.885 --> 00:09:12.951
dhe të mbyllej në mënyrë automatike 
për të të parandaluar nga mbingrënia.

00:09:12.951 --> 00:09:15.668
Kjo do të më pëlqente.

00:09:15.668 --> 00:09:17.595
çka nëse kur isha në Cambridge,

00:09:17.595 --> 00:09:19.908
të kisha qasje tek pajisja e emocionëve,

00:09:19.908 --> 00:09:23.437
dhe të mund të ndaja këtë 
me familjen në një mënyrë natyrale,

00:09:23.437 --> 00:09:27.408
sikur do ta bëja nëse do të 
ishim bashkë në një dhomë?

00:09:27.408 --> 00:09:30.550
Mendoj që 5 vjet me vone,

00:09:30.550 --> 00:09:32.887
pajisjet tona do të kenë 
një chip për emocione

00:09:32.887 --> 00:09:36.951
dhe neve nuk do të na kujtohet kur nuk
mundëm me tregu pakënaqësi te pajisja jonë

00:09:36.951 --> 00:09:41.200
pa na thënë, 
"Hmm, kjo nuk të pëlqej, apo jo?"

00:09:41.200 --> 00:09:44.961
Sfida më e madhe është se ka 
shumë aplikacione të kësaj teknologjie,

00:09:44.961 --> 00:09:47.864
ekipi im dhe unë e kuptojmë 
se nuk mundemi t'i ndërtojmë vetë

00:09:47.864 --> 00:09:51.360
dhe e kemi bërë të mundshme 
këtë teknologji që krijuesit e tjerë

00:09:51.360 --> 00:09:53.474
mund të krijojnë dhe të bëhen kreativ.

00:09:53.474 --> 00:09:57.560
Ne dimë se ka rreziqe potenciale

00:09:57.560 --> 00:09:59.627
dhe potencial për abuzim,

00:09:59.627 --> 00:10:02.576
por personalisht, pasi kam kaluar vite 
duke e bërë këtë,

00:10:02.576 --> 00:10:05.548
Besoj që benefitet e njerëzimit

00:10:05.548 --> 00:10:07.823
për të pas
teknologji me inteligjencë emocionale

00:10:07.823 --> 00:10:11.399
e mundin potencialin për shpërdorim.

00:10:11.399 --> 00:10:13.930
Unë ju ftoj të gjithëve 
për të qenë pjesë e bisedës.

00:10:13.930 --> 00:10:16.484
Sa më shumë njerëz 
që dijnë për këtë teknologji,

00:10:16.484 --> 00:10:19.661
aq më shumë do të dijmë se si po përdoret.

00:10:21.081 --> 00:10:25.655
Sa më shumë që jetët tona bëhen digjitale,

00:10:25.655 --> 00:10:29.153
po luftojmë nje betejë të humbur duke 
provuar ta frenojmë përdorimin e paisjeve

00:10:29.153 --> 00:10:31.382
në mënyrë që të rivendosim emocionet tona.

00:10:32.622 --> 00:10:36.536
çka po provoj unë të bëj është që 
t'i sjell emocionet në teknologji

00:10:36.536 --> 00:10:38.765
dhe t'i bëjë teknologjitë tona më reaguese.

00:10:38.765 --> 00:10:41.435
Dua që ato pajisje që na kanë ndarë

00:10:41.435 --> 00:10:43.897
të na bashkojnë përsëri.

00:10:43.897 --> 00:10:48.485
Dhe duke e njerëzuar teknologjinë,
në kemi shansin e artë

00:10:48.485 --> 00:10:51.782
për të riimagjinuar 
si lidhemi ne me makinerinë,

00:10:51.782 --> 00:10:56.263
dhe se si, ne si qenie njerëzore

00:10:56.263 --> 00:10:58.167
lidhemi me njëri tjetrin.

00:10:58.167 --> 00:11:00.327
Faleminderit.

00:11:00.327 --> 00:11:03.640
(Duartrokitje)

