WEBVTT
Kind: captions
Language: zh-TW

00:00:00.000 --> 00:00:07.000
譯者: Regina Chu
審譯者: Marssi Draw

00:00:12.556 --> 00:00:16.573
我們的情緒會影響
日常生活的各個層面，

00:00:16.573 --> 00:00:20.149
從我們的健康到如何學習、
如何做事、做決定，

00:00:20.149 --> 00:00:21.922
無論事情大小都受此影響。

00:00:22.672 --> 00:00:26.162
我們的情緒也會影響
我們如何與他人交流。

00:00:27.132 --> 00:00:31.108
我們已經進化到生活在
一個像這樣的世界，

00:00:31.108 --> 00:00:35.427
然而我們的生活卻愈來愈像這樣──

00:00:35.427 --> 00:00:38.561
這是我女兒昨晚傳來的簡訊──

00:00:38.561 --> 00:00:41.301
一個缺乏情感的世界。

00:00:41.301 --> 00:00:43.252
所以我帶著使命要改變這種狀況。

00:00:43.252 --> 00:00:47.343
我想將情感重新注入數位體驗中。

00:00:48.223 --> 00:00:51.300
我在 15 年前走上這條路。

00:00:51.300 --> 00:00:53.366
當時我在埃及是電腦科學家，

00:00:53.366 --> 00:00:57.871
而且我才拿到劍橋大學
博士班的入學許可。

00:00:57.871 --> 00:01:02.284
所以我做了一件
對身為年輕新婚的埃及回教婦女來說

00:01:02.284 --> 00:01:04.209
相當不尋常的事：

00:01:05.599 --> 00:01:08.598
在我先生的支持下，
他留在埃及，

00:01:08.598 --> 00:01:11.616
我整理行囊搬到英格蘭。

00:01:11.616 --> 00:01:14.844
在劍橋，離家千里遠的地方，

00:01:14.844 --> 00:01:18.257
我發現我與筆電相處的時間，

00:01:18.257 --> 00:01:20.486
遠超過與人交流的時間。

00:01:20.486 --> 00:01:25.339
儘管與筆電相處如此親密，
它卻完全不了解我的感受，

00:01:25.339 --> 00:01:28.550
它不知道我是否開心，

00:01:28.550 --> 00:01:31.538
今天順不順，是否緊張或困惑，

00:01:31.538 --> 00:01:34.460
所以那令我沮喪。

00:01:35.600 --> 00:01:40.831
更糟的是，在我上線
與遠方的家人聯絡時，

00:01:41.421 --> 00:01:44.703
我覺得我的情感
在這虛擬空間裡消失無蹤。

00:01:44.703 --> 00:01:49.858
我好想家，我好孤單，
有些日子我真的哭了，

00:01:49.858 --> 00:01:54.786
但我所能傳達的只有這個。

00:01:54.786 --> 00:01:56.806
（笑聲）

00:01:56.806 --> 00:02:01.780
今天的科技有很多智商，
卻沒有情緒智商；

00:02:01.780 --> 00:02:04.956
有很多認知智商，
卻沒有情緒智商。

00:02:04.956 --> 00:02:07.153
所以這讓我思考，

00:02:07.153 --> 00:02:10.777
如果我們的科技可以
感受我們的情緒會怎樣？

00:02:10.777 --> 00:02:14.853
如果我們的電子裝置可以
感受我們的感覺並做出相對回應，

00:02:14.853 --> 00:02:17.866
就像一位高情商的朋友一樣，
會是怎樣？

00:02:18.666 --> 00:02:22.230
這些問題讓我及我的團隊

00:02:22.230 --> 00:02:26.607
創造出可以讀懂情緒
並做出回應的科技，

00:02:26.607 --> 00:02:29.697
我們的起始點是人的臉。

00:02:30.577 --> 00:02:33.750
人類的臉恰好就是有力的管道，

00:02:33.750 --> 00:02:37.766
能用來傳遞社交及情緒狀態，

00:02:37.766 --> 00:02:40.776
從愉快、驚訝，

00:02:40.776 --> 00:02:44.979
到同情、好奇都可以。

00:02:44.979 --> 00:02:49.907
情緒科學中，我們稱每一種
顏面肌肉運動為一個動作單位。

00:02:49.907 --> 00:02:52.832
舉例來說，動作單位 12，

00:02:52.832 --> 00:02:54.870
這可不是好萊塢的動作巨片，

00:02:54.870 --> 00:02:58.312
這其實是拉嘴角，
這是微笑的主要部分。

00:02:58.312 --> 00:03:01.300
大家都試一下吧！
讓會場有點笑容。

00:03:01.300 --> 00:03:03.954
另一個例子是動作單位 4。
這是蹙額。

00:03:03.954 --> 00:03:06.192
就是你把眉頭皺在一起

00:03:06.192 --> 00:03:08.459
所產生的紋理和皺紋。

00:03:08.459 --> 00:03:12.754
我們都不喜歡皺紋，
但那是負面情緒的重要指標。

00:03:12.754 --> 00:03:14.960
我們有約 45 種動作單位，

00:03:14.960 --> 00:03:18.350
排列組合後可以表現出數百種情緒。

00:03:18.350 --> 00:03:22.251
要教電腦讀懂這些顏面表情很難，

00:03:22.251 --> 00:03:25.223
因為這些動作單位很快、很細微，

00:03:25.223 --> 00:03:27.777
而且還有各種不同的組合法。

00:03:27.777 --> 00:03:31.515
所以再舉個例子，微笑和假笑。

00:03:31.515 --> 00:03:35.268
兩者看起來有點像，
但是意義大不相同。

00:03:35.268 --> 00:03:36.986
（笑聲）

00:03:36.986 --> 00:03:39.990
微笑是正面的，

00:03:39.990 --> 00:03:41.260
假笑往往是負面的。

00:03:41.260 --> 00:03:45.136
有時候一個假笑可以讓你成名。

00:03:45.136 --> 00:03:47.960
但是說真的，要讓電腦能夠

00:03:47.960 --> 00:03:50.815
辨認出這兩種表情的不同很重要。

00:03:50.815 --> 00:03:52.627
所以我們怎麼做呢？

00:03:52.627 --> 00:03:54.414
我們給我們的演算法

00:03:54.414 --> 00:03:58.524
成千上萬筆我們知道在微笑的例子，

00:03:58.524 --> 00:04:01.589
各式人種、年齡、性別都有，

00:04:01.589 --> 00:04:04.400
假笑也如法泡製。

00:04:04.400 --> 00:04:05.954
然後，機器用深度學習法，

00:04:05.954 --> 00:04:08.810
讓演算法找出臉上
所有的紋理、皺紋，

00:04:08.810 --> 00:04:11.390
及臉型的改變，

00:04:11.390 --> 00:04:14.592
基本上學得所有的微笑
都有共同的特點，

00:04:14.592 --> 00:04:17.773
所有的假笑也有
稍稍不同的特點，

00:04:17.773 --> 00:04:20.141
所以下一次電腦看到新的面孔，

00:04:20.141 --> 00:04:22.440
它基本上會得知

00:04:22.440 --> 00:04:25.473
這張臉與微笑有相同的特點，

00:04:25.473 --> 00:04:29.751
然後它會說，「啊哈！
我認得這個，這是微笑的表情。」

00:04:30.381 --> 00:04:33.181
要展示怎麼用
這項科技的最佳方法，

00:04:33.181 --> 00:04:35.317
就是來一個現場示範，

00:04:35.317 --> 00:04:39.230
所以我需要一名志願者，
最好是有臉的。

00:04:39.230 --> 00:04:41.564
（笑聲）

00:04:41.564 --> 00:04:44.335
我們今天的志願者是克蘿伊。

00:04:45.325 --> 00:04:49.783
過去五年，我們從
麻省理工的一項研究計畫

00:04:49.783 --> 00:04:50.939
發展成一家公司，

00:04:50.939 --> 00:04:54.131
我的團隊很努力
讓這項科技能快速傳播，

00:04:54.131 --> 00:04:56.540
好像我們常說的，（病毒）擴散中。

00:04:56.540 --> 00:04:59.210
我們也把它縮小，
讓核心情緒引擎能用在

00:04:59.210 --> 00:05:02.530
任何有照相機的行動裝置上，
像是這台 iPad。

00:05:02.530 --> 00:05:05.316
現在來試一下。

00:05:06.756 --> 00:05:10.680
正如你們所見，基本上
演算法已經找到了克蘿伊的臉，

00:05:10.680 --> 00:05:12.372
就是這個白色的框框，

00:05:12.372 --> 00:05:14.943
它正在找她臉上的
幾個主要特徵點，

00:05:14.943 --> 00:05:17.799
像是她的眉毛、
眼睛、嘴巴和鼻子。

00:05:17.799 --> 00:05:20.786
問題是，它能辨識她的表情嗎？

00:05:20.786 --> 00:05:22.457
我們來考一下機器。

00:05:22.457 --> 00:05:26.643
首先，來一張撲克臉。
對，好極了！（笑聲）

00:05:26.643 --> 00:05:29.456
然後她微笑的時後，
這是真誠的微笑，很棒，

00:05:29.456 --> 00:05:31.756
你們可以看到她微笑的時候，
綠色的信號格增加。

00:05:31.756 --> 00:05:32.978
那可是個好大的微笑。

00:05:32.978 --> 00:05:36.021
你可以試一下淺淺的微笑嗎？
看看電腦能不能辨識？

00:05:36.021 --> 00:05:38.352
它的確也能辨識淺淺的微笑。

00:05:38.352 --> 00:05:40.477
我們真的很努力要做到這一點。

00:05:40.477 --> 00:05:43.439
然後抬眉毛，表示驚訝。

00:05:43.439 --> 00:05:47.688
蹙額，表示困惑。

00:05:47.688 --> 00:05:51.695
皺眉，很好，很完美。

00:05:51.695 --> 00:05:55.188
這些就是不同的動作單位。
還有更多。

00:05:55.188 --> 00:05:57.220
這只是瘦身版示範。

00:05:57.220 --> 00:06:00.368
我們稱每一個讀取
為一個情緒資料點，

00:06:00.368 --> 00:06:03.337
然後它們一起發動
就能描繪出不同的情緒。

00:06:03.337 --> 00:06:07.990
右邊的這張示範──
表現你很開心。

00:06:07.990 --> 00:06:09.444
所以那是高興。高興出現了。

00:06:09.444 --> 00:06:11.371
然後給我一張噁心的臉。

00:06:11.371 --> 00:06:15.643
試著回想贊恩退出
男團一世代的那種感覺。

00:06:15.643 --> 00:06:17.153
（笑聲）

00:06:17.153 --> 00:06:21.495
沒錯，皺鼻子。太棒了！

00:06:21.495 --> 00:06:25.226
效價呈現高負值，
所以你一定是大粉絲。

00:06:25.226 --> 00:06:27.926
效價指的是感受的好壞程度，

00:06:27.926 --> 00:06:30.712
而投入程度指的是
她的表情有多大。

00:06:30.712 --> 00:06:34.126
想像一下如果克羅伊
能使用這套即時情緒串流，

00:06:34.126 --> 00:06:36.935
而且她還可以跟任何人分享。

00:06:36.935 --> 00:06:39.858
謝謝妳！

00:06:39.858 --> 00:06:44.479
（掌聲）

00:06:45.749 --> 00:06:51.019
到目前為止我們已經
累積了 120 億筆情緒數據點。

00:06:51.019 --> 00:06:53.630
這是世界上最大的情緒資料庫。

00:06:53.630 --> 00:06:56.593
我們從 290 萬筆臉孔短片
收集資料，

00:06:56.593 --> 00:06:59.533
由同意與我們分享他們情緒的人提供，

00:06:59.533 --> 00:07:02.398
來源遍及全球 75 個國家。

00:07:02.398 --> 00:07:04.113
資料每天都在增加。

00:07:04.603 --> 00:07:06.670
這真令我驚異萬分，

00:07:06.670 --> 00:07:09.865
我們能量化像情緒
這麼個人的東西，

00:07:09.865 --> 00:07:12.100
還能做到這個地步。

00:07:12.100 --> 00:07:14.277
所以至今我們學到什麼？

00:07:15.057 --> 00:07:17.388
性別。

00:07:17.388 --> 00:07:21.034
我們的數據證實了一些
你們大概已經料到的事。

00:07:21.034 --> 00:07:22.891
女人的表情比男人的更豐富。

00:07:22.891 --> 00:07:25.574
她們不但更常微笑，
微笑的時間還更久，

00:07:25.574 --> 00:07:27.668
而且我們現在真的能量化

00:07:27.668 --> 00:07:30.614
造成男女不同反應的東西。

00:07:30.614 --> 00:07:32.904
來看文化：在美國，

00:07:32.904 --> 00:07:36.108
女性比男性多 40% 
更願意表達情感，

00:07:36.108 --> 00:07:39.753
但奇怪的是，
在英國看不到這樣的差距。

00:07:39.753 --> 00:07:42.259
（笑聲）

00:07:43.296 --> 00:07:47.323
再看年齡：50 歲以上的人

00:07:47.323 --> 00:07:50.759
比年輕人多 25% 更願意表現情感。

00:07:51.899 --> 00:07:55.751
20 多歲的女性
比同年齡的男性更常微笑，

00:07:55.751 --> 00:07:59.590
大概是因為這是約會必殺技。

00:07:59.590 --> 00:08:02.207
但是這筆數據最讓我們訝異的，

00:08:02.207 --> 00:08:05.410
大概是我們隨時都有表情，

00:08:05.410 --> 00:08:08.243
即使我們獨自坐在裝置前也是如此，

00:08:08.243 --> 00:08:11.797
而且不只是在我們看
臉書上貓短片的的時候。

00:08:12.217 --> 00:08:15.227
我們在寫信、傳簡訊、網購，

00:08:15.227 --> 00:08:17.527
甚至在報稅時都表情豐富。

00:08:17.527 --> 00:08:19.919
今天這筆數據用在哪裡呢？

00:08:19.919 --> 00:08:22.682
用在瞭解我們如何與媒體互動，

00:08:22.682 --> 00:08:25.166
所以能瞭解影片爆紅及投票行為，

00:08:25.166 --> 00:08:27.906
也用在情緒辨識科技，

00:08:27.906 --> 00:08:32.527
我想分享幾個
讓我特別感動的例子。

00:08:33.197 --> 00:08:36.265
情緒辨識眼鏡能幫助

00:08:36.265 --> 00:08:39.493
視障者讀取別人臉上的表情，

00:08:39.493 --> 00:08:43.680
也能幫助各種程度的
自閉症患者解讀情緒，

00:08:43.680 --> 00:08:46.458
這是他們的最大難題。

00:08:47.918 --> 00:08:50.777
在教育上，想像一下
如果你的學習應用程式

00:08:50.777 --> 00:08:53.587
感受到你的困惑並放慢速度，

00:08:53.587 --> 00:08:55.444
或是知道你覺得無聊了
所以加快速度，

00:08:55.444 --> 00:08:58.413
就像一位好老師
在課堂上做的一樣。

00:08:59.043 --> 00:09:01.644
如果你的手錶能追蹤你的心情，

00:09:01.644 --> 00:09:04.337
或是你的車能感受到
你現在很疲倦，

00:09:04.337 --> 00:09:06.885
或是你的冰箱能知道
你現在壓力很大，

00:09:06.885 --> 00:09:11.451
所以它會自動鎖住，
你就不能拿東西來吃。（笑聲）

00:09:11.451 --> 00:09:14.488
我會喜歡那個，真的。

00:09:15.668 --> 00:09:17.595
當我在劍橋的時候，

00:09:17.595 --> 00:09:19.908
如果我能用這套
即時情緒串流工具，

00:09:19.908 --> 00:09:23.437
我就能用非常自然的方法
與遠在家鄉的家人分享，

00:09:23.437 --> 00:09:27.408
就好像我們都在
同一間房間一樣，那有多好？

00:09:27.408 --> 00:09:30.550
我想五年後，

00:09:30.550 --> 00:09:32.887
我們所有的裝置
都會有一個情緒晶片，

00:09:32.887 --> 00:09:38.191
我們就會忘記當年
裝置還不會回應我們皺眉的時候說出：

00:09:38.191 --> 00:09:41.200
「嗯，你不喜歡這個，是吧？」
是什麼樣子。

00:09:41.200 --> 00:09:44.961
我們最大的挑戰是
這種科技有許多應用程式，

00:09:44.961 --> 00:09:47.864
我和我的團隊瞭解
我們不可能只靠自己發展全部，

00:09:47.864 --> 00:09:51.360
所以我們開放這項科技
讓其他開發者

00:09:51.360 --> 00:09:53.474
能繼續開發並激發創意。

00:09:53.474 --> 00:09:57.560
我們知道會有潛在風險，

00:09:57.560 --> 00:09:59.627
也可能遭到濫用，

00:09:59.627 --> 00:10:02.576
但是個人認為，
在花了這麼多年做這個之後，

00:10:02.576 --> 00:10:05.548
我相信這對人類的益處，

00:10:05.548 --> 00:10:07.823
就是開發情緒智能科技的益處，

00:10:07.823 --> 00:10:11.399
遠超過誤用的潛在危險。

00:10:11.399 --> 00:10:13.930
我請大家口耳相傳。

00:10:13.930 --> 00:10:16.484
愈多人知道這項科技，

00:10:16.484 --> 00:10:19.661
我們就愈能發聲說明
這該如何使用。

00:10:21.081 --> 00:10:25.655
隨著我們的生活愈來愈數位化，

00:10:25.655 --> 00:10:29.153
試圖以遏止使用裝置來重拾情緒

00:10:29.153 --> 00:10:31.382
是一場必敗的仗。

00:10:32.622 --> 00:10:36.536
與其如此，
我寧可把情感帶進科技，

00:10:36.536 --> 00:10:38.765
讓我們的科技更有回應。

00:10:38.765 --> 00:10:41.435
所以我想用這些
原本使我們疏遠的裝置，

00:10:41.435 --> 00:10:43.897
讓我們重新結合在一起。

00:10:43.897 --> 00:10:48.485
藉著把科技人性化，
我們擁有這個黃金時機

00:10:48.485 --> 00:10:51.782
來重新想像我們如何
與機器連結，

00:10:51.782 --> 00:10:56.263
進而想像我們身為人類

00:10:56.263 --> 00:10:58.167
如何能重新連結彼此。

00:10:58.167 --> 00:11:00.327
謝謝。

00:11:00.327 --> 00:11:03.640
（掌聲）

