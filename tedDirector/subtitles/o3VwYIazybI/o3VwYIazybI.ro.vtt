WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Matei Sterian
Corector: MC M

00:00:12.796 --> 00:00:16.573
Emoțiile influențează fiecare
aspect al vieții noastre,

00:00:16.573 --> 00:00:20.149
de la sănătate și învățătură, 
la cum facem afaceri și cum luăm decizii,

00:00:20.149 --> 00:00:21.922
mari sau mici.

00:00:22.672 --> 00:00:26.162
Emoțiile influențează modul în care 
relaționăm unii cu ceilalți.

00:00:27.132 --> 00:00:30.198
Am evoluat pentru a trăi 
într-o lume ca aceasta.

00:00:30.938 --> 00:00:35.427
Dar în loc viețile noastre
arată tot mai mult așa

00:00:35.427 --> 00:00:39.021
– e un mesaj primit 
de la fiica mea aseară –

00:00:39.021 --> 00:00:41.301
o lume lipsită de emoții.

00:00:41.301 --> 00:00:43.252
Misiunea mea e să schimb asta.

00:00:43.252 --> 00:00:47.863
Vreau să aduc emoțiile înapoi 
în lumea digitală.

00:00:48.483 --> 00:00:50.870
Am început acest drum acum 15 ani.

00:00:50.870 --> 00:00:53.546
Lucram în informatică, în Egipt,

00:00:53.546 --> 00:00:57.871
și tocmai fusesem acceptată la un doctorat
la Universitatea Cambridge.

00:00:57.871 --> 00:00:59.984
Așa că am făcut ceva neobișnuit

00:00:59.984 --> 00:01:04.349
pentru o proaspăt căsătorită
tânără musulmană din Egipt:

00:01:04.349 --> 00:01:05.729
(Râsete)

00:01:05.729 --> 00:01:08.598
cu ajutorul soțului meu, 
care a trebuit să rămână în Egipt,

00:01:08.598 --> 00:01:11.616
mi-am făcut bagajele
și m-am mutat în Anglia.

00:01:11.616 --> 00:01:14.844
La Cambridge, 
mii de kilometri departe de casă,

00:01:14.844 --> 00:01:17.887
am observat că petrec
mai multe ore cu laptopul meu

00:01:17.887 --> 00:01:19.876
decât cu alți oameni.

00:01:20.486 --> 00:01:25.339
Dar în ciuda acestei intimități, 
laptopul n-avea idee cum mă simt.

00:01:25.339 --> 00:01:28.550
Nu știa dacă sunt fericită,

00:01:28.550 --> 00:01:31.628
dacă am o zi proastă, 
dacă sunt stresată sau dezorientată,

00:01:31.628 --> 00:01:34.460
iar asta era enervant.

00:01:35.530 --> 00:01:41.271
Mai rău, când comunicam pe internet
cu familia mea rămasă acasă

00:01:41.271 --> 00:01:44.703
simțeam că toate emoțiile mele
dispar în spațiul virtual.

00:01:44.703 --> 00:01:49.858
Îmi era dor de casă, mă simțeam singură
și în unele zile chiar plângeam,

00:01:49.858 --> 00:01:54.526
dar tot ce puteam folosi pentru a-mi 
comunica emoțiile era... asta.

00:01:55.006 --> 00:01:56.806
(Râsete)

00:01:56.806 --> 00:02:01.030
Tehnologia de azi e foarte inteligentă,
dar nu și emoțională;

00:02:01.030 --> 00:02:05.136
multă inteligență cognitivă,
dar nu și inteligență emoțională.

00:02:05.136 --> 00:02:07.033
Asta m-a pus pe gânduri:

00:02:07.033 --> 00:02:11.107
ce-ar fi dacă tehnologia
ne-ar putea simți emoțiile?

00:02:11.107 --> 00:02:14.853
Ce-ar fi dacă dispozitivele ar ști ce simțim
și ar reacționa în concordanță,

00:02:14.853 --> 00:02:17.866
la fel ca un prieten
cu inteligență emoțională?

00:02:18.666 --> 00:02:22.060
Aceste întrebări ne-au impulsionat
pe mine și echipa mea

00:02:22.060 --> 00:02:26.607
să creăm tehnologii care să citească
și să răspundă la emoțiile noastre.

00:02:26.607 --> 00:02:29.787
Iar punctul nostru de start
a fost chipul uman.

00:02:30.577 --> 00:02:33.900
Chipul nostru e cel mai bun canal

00:02:33.900 --> 00:02:37.766
cu care transmitem
stări sociale și emoționale,

00:02:37.766 --> 00:02:41.196
totul: bucurie, surpriză,

00:02:41.196 --> 00:02:44.979
empatie și curiozitate.

00:02:44.979 --> 00:02:49.957
În știința emoțiilor, fiecare mișcare
a mușchilor feței e o unitate de acțiune.

00:02:49.957 --> 00:02:52.342
De exemplu, unitatea de acțiune 12

00:02:52.342 --> 00:02:54.720
– nu garantează succesul la Hollywood –

00:02:54.720 --> 00:02:57.992
e o ridicare a colțului buzei,
componenta principală a zâmbetului.

00:02:57.992 --> 00:03:00.910
Încercați. Hai să vedem niște zâmbete.

00:03:00.910 --> 00:03:03.954
Un alt exemplu e unitatea 4:
ridurile frunții.

00:03:03.954 --> 00:03:07.742
E atunci când îți apropii sprâncenele
și creezi textura aceea ridată.

00:03:07.742 --> 00:03:11.904
Nu ne place, dar este un indicator
puternic a unei emoții negative.

00:03:11.904 --> 00:03:14.540
Avem vreo 45 de astfel de unități,

00:03:14.540 --> 00:03:18.350
care se combină pentru a exprima
sute de emoții.

00:03:18.350 --> 00:03:22.251
E greu să înveți un calculator
să recunoască emoțiile,

00:03:22.251 --> 00:03:25.223
deoarece aceste unități
pot fi rapide, subtile,

00:03:25.223 --> 00:03:27.617
și se combină în multe moduri.

00:03:27.617 --> 00:03:31.515
Spre exemplu, zâmbetul și strâmbătura.

00:03:31.515 --> 00:03:35.268
Seamănă cumva, dar reprezintă
lucruri foarte diferite.

00:03:35.268 --> 00:03:36.986
(Râsete)

00:03:36.986 --> 00:03:39.210
Zâmbetul e pozitiv,

00:03:39.210 --> 00:03:40.840
strâmbătura e adesea negativă.

00:03:40.840 --> 00:03:44.546
Uneori strâmbătura te poate face celebru.

00:03:45.266 --> 00:03:50.500
Dar e important pentru un calculator
să poată face diferența între cele două.

00:03:50.500 --> 00:03:52.237
Cum facem asta?

00:03:52.237 --> 00:03:54.124
Oferim algoritmilor noștri

00:03:54.124 --> 00:03:58.524
zeci de mii de exemple de oameni
despre care știm că zâmbesc,

00:03:58.524 --> 00:04:01.589
din diferite etnii, vârste, sexe,

00:04:01.589 --> 00:04:04.050
și la fel pentru strâmbături.

00:04:04.050 --> 00:04:05.894
Apoi, folosind învățarea profundă,

00:04:05.894 --> 00:04:08.810
algoritmul caută aceste texturi și riduri

00:04:08.810 --> 00:04:11.220
și schimbările de formă
de pe fața noastră,

00:04:11.220 --> 00:04:14.802
învățând astfel că toate zâmbetele
au caracteristici comune

00:04:14.802 --> 00:04:17.703
și că strâmbăturile
au caracteristici ușor diferite.

00:04:17.703 --> 00:04:20.141
Iar data următoare când vede o față

00:04:20.141 --> 00:04:22.580
învață că

00:04:22.580 --> 00:04:25.473
această față are aceleași
caracteristici ale unui zâmbet

00:04:25.473 --> 00:04:29.051
și spune: „Aha, recunosc asta,
e expresia unui zâmbet.”

00:04:30.561 --> 00:04:35.331
Cel mai bun mod de a ilustra tehnologia
e să încercăm o demonstrație în direct.

00:04:35.331 --> 00:04:39.230
Am nevoie de un voluntar,
preferabil cineva cu o față.

00:04:39.230 --> 00:04:41.564
(Râsete)

00:04:41.564 --> 00:04:44.335
Cloe va fi voluntarul nostru azi.

00:04:45.325 --> 00:04:50.923
În ultimii cinci ani, dintr-un proiect
de cercetare la MIT am devenit o firmă,

00:04:50.923 --> 00:04:54.031
unde echipa mea s-a străduit să facă
tehnologia să meargă,

00:04:54.031 --> 00:04:56.070
cum spunem noi, în „sălbăticie”.

00:04:56.070 --> 00:05:01.130
În plus am comprimat-o încât nucleul ei
să meargă pe orice dispozitiv cu o cameră,

00:05:01.130 --> 00:05:02.650
ca acest iPad.

00:05:02.650 --> 00:05:05.316
Hai să încercăm.

00:05:06.756 --> 00:05:10.680
După cum puteți vedea,
algoritmul a găsit fața lui Cloe,

00:05:10.680 --> 00:05:12.152
acest dreptunghi alb,

00:05:12.152 --> 00:05:14.753
și urmărește punctele
reprezentative ale feței:

00:05:14.753 --> 00:05:17.799
sprâncenele, ochii, gura și nasul.

00:05:17.799 --> 00:05:20.346
Întrebarea este:
îi poate recunoaște expresia?

00:05:20.346 --> 00:05:21.897
Hai să testăm mașina.

00:05:21.897 --> 00:05:23.907
Mai întâi arată-mi o față neutră.

00:05:23.907 --> 00:05:25.323
Da, super.

00:05:25.323 --> 00:05:26.903
(Râsete)

00:05:26.903 --> 00:05:29.726
Pe măsură ce zâmbește
– un zâmbet autentic, super –

00:05:29.726 --> 00:05:31.716
vedeți cum crește bara verde.

00:05:31.716 --> 00:05:34.168
A fost un zâmbet mare,
poți încerca unul subtil

00:05:34.168 --> 00:05:36.051
să vedem dacă îl recunoaște?

00:05:36.051 --> 00:05:39.637
Recunoaște și zâmbete subtile,
ne-am străduit mult să iasă asta.

00:05:39.637 --> 00:05:43.439
Și acum sprâncenele ridicate,
indicatorul surprizei.

00:05:43.439 --> 00:05:47.688
Acum riduri pe frunte,
indicatorul confuziei.

00:05:47.688 --> 00:05:49.695
Încruntă-te.

00:05:49.695 --> 00:05:51.715
Da, perfect.

00:05:51.715 --> 00:05:54.748
Ați văzut diferite unități de acțiune,
mai sunt multe,

00:05:54.748 --> 00:05:56.980
acesta e doar un demo redus.

00:05:56.980 --> 00:06:00.588
Fiecare citire o numim
„valoare măsurată a emoției”;

00:06:00.588 --> 00:06:03.287
ele pot acționa împreună,
creând diferite emoții.

00:06:03.287 --> 00:06:05.420
Pe dreapta...

00:06:05.420 --> 00:06:07.070
Mimează fericirea.

00:06:07.070 --> 00:06:09.444
Asta e bucuria, se aprinde.

00:06:09.444 --> 00:06:11.291
Acum arată-mi o față dezgustată.

00:06:11.291 --> 00:06:15.643
Gândește-te cum a fost
când a plecat Zayn de la One Direction.

00:06:15.643 --> 00:06:17.043
(Râsete)

00:06:17.043 --> 00:06:21.495
Da, încrețește-ți nasul. Super.

00:06:21.495 --> 00:06:24.926
Valența e destul de negativă, 
deci probabil i-ai fost mare fan.

00:06:24.926 --> 00:06:27.926
Valența arată cât de pozitivă
sau negativă e o experiență,

00:06:27.926 --> 00:06:30.712
iar angajamentul arată
cât e de expresivă.

00:06:30.712 --> 00:06:34.126
Imaginați-vă că Cloe ar avea acces 
în timp real la fluxul de emoții

00:06:34.126 --> 00:06:36.935
și că ar putea trimite
emoții oricui.

00:06:36.935 --> 00:06:38.868
Mulțumesc.

00:06:38.868 --> 00:06:41.659
(Aplauze)

00:06:45.819 --> 00:06:50.729
Până acum am strâns 12 miliarde
de valori măsurate ale emoției;

00:06:50.729 --> 00:06:53.190
e cea mai mare bază de date 
de emoții din lume.

00:06:53.190 --> 00:06:56.853
Am colectat-o din 2,9 milioane
de videoclipuri cu fețe,

00:06:56.853 --> 00:06:59.943
oameni care au fost de acord
să ne transmită emoțiile,

00:06:59.943 --> 00:07:02.198
din 75 de țări din toată lumea.

00:07:02.198 --> 00:07:04.113
Și crește în fiecare zi.

00:07:04.603 --> 00:07:10.110
Sunt uimită că am reușit să cuantificăm
ceva atât de personal cum sunt emoțiile,

00:07:10.110 --> 00:07:12.100
la o scară atât de mare.

00:07:12.100 --> 00:07:14.207
Ce am învățat până acum?

00:07:15.057 --> 00:07:16.518
Sexul.

00:07:17.388 --> 00:07:20.834
Datele noastre confirmă ceva 
ce ați putea bănui:

00:07:20.834 --> 00:07:22.881
femeile sunt mai expresive decât bărbații:

00:07:22.881 --> 00:07:25.564
zâmbetele lor sunt mai intense
și durează mai mult,

00:07:25.564 --> 00:07:30.628
iar acum putem cuantifica la ce anume
reacționează diferit bărbații și femeile.

00:07:30.628 --> 00:07:32.904
Să vorbim puțin de cultură: în SUA

00:07:32.904 --> 00:07:35.928
femeile sunt cu 40% mai expresive 
decât bărbații,

00:07:35.928 --> 00:07:39.963
dar, surprinzător,
diferența asta nu există în Regatul Unit.

00:07:39.963 --> 00:07:41.879
(Râsete)

00:07:43.346 --> 00:07:47.323
Vârstă: oamenii peste 50 de ani

00:07:47.323 --> 00:07:50.759
sunt cu 25% mai emotivi
decât cei mai tineri.

00:07:51.439 --> 00:07:55.751
La 20–30 de ani femeile zâmbesc 
mult mai mult decât bărbații,

00:07:55.751 --> 00:07:58.580
poate din nevoia de a-și găsi pe cineva.

00:07:59.500 --> 00:08:03.157
Dar ce ne-a surprins cel mai mult
în aceste date

00:08:03.157 --> 00:08:05.270
e faptul că suntem expresivi mereu,

00:08:05.270 --> 00:08:08.243
chiar și când stăm singuri
în fața dispozitivelor

00:08:08.243 --> 00:08:11.517
și nu doar când ne uităm la 
filmulețe cu pisici pe Facebook.

00:08:12.217 --> 00:08:15.227
Suntem expresivi când scriem 
mesaje, când cumpărăm online,

00:08:15.227 --> 00:08:17.797
chiar și când ne plătim impozitele.

00:08:17.797 --> 00:08:19.919
La ce sunt folosite azi aceste date?

00:08:19.919 --> 00:08:22.166
La a înțelege cum interacționăm cu media,

00:08:22.166 --> 00:08:25.076
cu conținutul viral și
comportamentul votanților,

00:08:25.076 --> 00:08:28.447
dar și la a dezvolta
planul emotiv al tehnologiei.

00:08:28.447 --> 00:08:32.405
Și aș vrea să vă arăt câteva exemple
la care țin foarte mult.

00:08:33.195 --> 00:08:36.303
Ochelarii cu funcții emotive
pot ajuta indivizii

00:08:36.303 --> 00:08:39.470
care au probleme cu vederea 
să citească fețele celorlalți

00:08:39.470 --> 00:08:43.128
și-i poate ajuta pe autiștii
de diverse grade să interpreteze emoția,

00:08:43.128 --> 00:08:45.577
lucru care pentru ei e complicat.

00:08:47.577 --> 00:08:50.767
În educație, imaginați-vă
că aplicațiile de învățare

00:08:50.767 --> 00:08:53.284
vă percep confuzia,
și atunci încetinesc,

00:08:53.284 --> 00:08:55.403
sau plictiseala,
și atunci grăbesc pasul,

00:08:55.403 --> 00:08:58.124
cum ar face un profesor bun în clasă.

00:08:58.834 --> 00:09:01.637
Ce ar fi dacă ceasul v-ar simți starea

00:09:01.637 --> 00:09:04.325
sau dacă mașina ar simți 
că sunteți obosiți,

00:09:04.325 --> 00:09:07.011
sau poate frigiderul simte 
că sunteți stresat

00:09:07.011 --> 00:09:11.058
și se încuie ca să nu mâncați frenetic?
(Râsete)

00:09:11.058 --> 00:09:13.525
Mi-ar plăcea asta, da!

00:09:15.575 --> 00:09:19.598
Cum ar fi fost dacă la Cambridge
aș fi avut acces la acest sistem

00:09:19.598 --> 00:09:23.718
și aș fi putut să le transmit rudelor 
emoțiile, într-un mod natural,

00:09:23.718 --> 00:09:26.910
ca și când aș fi fost în
aceeași cameră cu ei?

00:09:27.450 --> 00:09:30.117
Cred că în viitorii cinci ani

00:09:30.117 --> 00:09:33.011
toate dispozitivele vor avea
un cip al emoțiilor

00:09:33.011 --> 00:09:37.000
și nici nu ne vom aduce aminte cum era
când nu te puteai încrunta la dispozitiv

00:09:37.000 --> 00:09:40.711
ca să-și dea seama dintr-o privire:
„Hmm, nu ți-a plăcut, nu?”

00:09:41.191 --> 00:09:44.724
Cea mai mare dificultate e
că tehnologia are așa multe aplicații

00:09:44.724 --> 00:09:47.840
încât eu și echipa mea înțelegem
că nu putem face noi totul,

00:09:47.840 --> 00:09:49.904
așa că am făcut tehnologia disponibilă,

00:09:49.904 --> 00:09:53.680
pentru ca dezvoltatorii să înceapă
să construiască și să creeze.

00:09:53.680 --> 00:09:57.507
Ne dăm seama că există riscuri

00:09:57.507 --> 00:09:59.596
și potențial pentru abuzuri,

00:09:59.596 --> 00:10:02.378
dar personal, după ce am petrecut
mulți ani făcând asta,

00:10:02.378 --> 00:10:05.123
cred că beneficiile pe care
le poate avea omenirea

00:10:05.123 --> 00:10:07.649
din tehnologiile cu inteligență emoțională

00:10:07.649 --> 00:10:10.730
depășesc cu mult riscurile de abuz.

00:10:11.210 --> 00:10:13.804
Așa că vă invit să participați.

00:10:13.804 --> 00:10:16.381
Cu cât știe mai multă lume 
de această tehnologie,

00:10:16.381 --> 00:10:20.225
cu atât avem un cuvânt mai greu
în cum e ea folosită.

00:10:21.095 --> 00:10:25.603
Pe măsură ce viața noastră
devine digitală

00:10:25.603 --> 00:10:29.342
ne chinuim inutil să ne folosim
mai puțin dispozitivele

00:10:29.342 --> 00:10:31.626
pentru a ne revendica emoțiile.

00:10:32.436 --> 00:10:36.625
Ceea ce încerc eu e să aduc 
emoțiile înapoi în tehnologie,

00:10:36.625 --> 00:10:38.725
să ameliorez reacțiile tehnologiilor.

00:10:38.725 --> 00:10:41.377
Visez ca aceste dispozitive
care ne-au despărțit

00:10:41.377 --> 00:10:43.365
să ne reunească.

00:10:44.205 --> 00:10:48.482
Umanizând tehnologia avem imensa șansă

00:10:48.482 --> 00:10:52.203
de a reimagina modul în care 
ne conectăm cu mașinile,

00:10:52.203 --> 00:10:56.227
și prin asta și modul în care noi,
ca ființe umane,

00:10:56.227 --> 00:10:57.832
ne conectăm între noi.

00:10:58.152 --> 00:10:59.343
Mulțumesc.

00:10:59.343 --> 00:11:02.303
(Aplauze)

