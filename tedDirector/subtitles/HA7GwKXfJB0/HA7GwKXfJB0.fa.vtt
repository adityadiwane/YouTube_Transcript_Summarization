WEBVTT
Kind: captions
Language: fa

00:00:00.000 --> 00:00:07.000
Translator: Amir Saberi
Reviewer: mahmood rokni

00:00:17.260 --> 00:00:20.260
ما در زمانه فوق العاده ای زندگی میکنیم،

00:00:20.260 --> 00:00:23.260
عصر ژنومیکس.

00:00:23.260 --> 00:00:26.260
ژنوم شما تمام توالی دی. ان. ای. شماست.

00:00:26.260 --> 00:00:29.260
توالی شما و توالی من اندکی از هم متفاوت اند.

00:00:29.260 --> 00:00:31.260
برای همین هم هست که من و شما ظاهر متفاوتی داریم.

00:00:31.260 --> 00:00:33.260
من چشمانی قهوه ای دارم.

00:00:33.260 --> 00:00:36.260
چشمان شما ممکن است آبی یا خاکستری باشند.

00:00:36.260 --> 00:00:38.260
اما تمام مساله این اندازه ظاهری هم نیست.

00:00:38.260 --> 00:00:40.260
هر روز از اخبار میشنویم

00:00:40.260 --> 00:00:43.260
که ژن ها میتوانند منجر به بیماری های خطرناکی در ما شوند،

00:00:43.260 --> 00:00:46.260
یا حتی در شکل گیری شخصیت ما نقش داشته باشند،

00:00:46.260 --> 00:00:49.260
یا موجب اختلالات روانی در ما شوند.

00:00:49.260 --> 00:00:52.260
به نظر میرسد ژن های ما

00:00:52.260 --> 00:00:55.260
نقش عمیقی در سرنوشت ما داشته باشند.

00:00:56.260 --> 00:00:59.260
اما همچنان من اصرار دارم که تصور کنم

00:00:59.260 --> 00:01:02.260
من چیزی بیشتر از ژن هایم هستم.

00:01:04.260 --> 00:01:06.260
شما چه فکر میکنید؟

00:01:06.260 --> 00:01:09.260
آیا شما چیزی بیشتر از ژن هایتان هستید؟

00:01:09.260 --> 00:01:11.260
(باشندگان: بله.) بله؟

00:01:13.260 --> 00:01:15.260
فکر میکنم بعضی از شما هم با من هم عقیده اید.

00:01:15.260 --> 00:01:17.260
فکر میکنم ما باید این را با قاطعیت بیان کنیم.

00:01:17.260 --> 00:01:19.260
و فکر میکنم حتی باید این را همه با هم فریاد بزنیم.

00:01:20.260 --> 00:01:23.260
بسیار خوب: "من چیزی بیش از ژن هایم هستم" -- همه باهم.

00:01:23.260 --> 00:01:27.260
همه: من چیزی بیش از ژن هایم هستم.

00:01:27.260 --> 00:01:29.260
(تشویق)

00:01:30.260 --> 00:01:32.260
سباستین سونگ: پس من یعنی چه؟

00:01:32.260 --> 00:01:35.260
(خنده)

00:01:35.260 --> 00:01:38.260
من یعنی کانکتوم من.

00:01:40.260 --> 00:01:42.260
حالا چون شما شنوندگان خیلی خوبی هستید،

00:01:42.260 --> 00:01:44.260
میتوانید من رو خوشحال کنید و این را هم همه با هم بگویید.

00:01:44.260 --> 00:01:46.260
(خنده)

00:01:46.260 --> 00:01:48.260
خوب. حالا همه با هم.

00:01:48.260 --> 00:01:51.260
همه: من یعنی کانکتوم من.

00:01:53.260 --> 00:01:55.260
سباستین سونگ: عالی بود.

00:01:55.260 --> 00:01:57.260
انقدر شما آدم های باحالی هستید که حتی نمیدونید کانکتوم چیست،

00:01:57.260 --> 00:01:59.260
اما حاضرید من رو همراهی کنید.

00:01:59.260 --> 00:02:02.260
فکر میکنم کاری که میخواستم رو کردم و همین حالا میتونم برگردم!

00:02:02.260 --> 00:02:05.260
بسیار خوب، تا این لحظه تنها یک کانکتوم شناخته شده است،

00:02:05.260 --> 00:02:08.260
کانکتوم این کرم کوچک.

00:02:08.260 --> 00:02:10.260
سامانه عصبی جمع و جور این کرم

00:02:10.260 --> 00:02:12.260
تنها از ۳۰۰ نورون ساخته شده است.

00:02:12.260 --> 00:02:14.260
و در دهه های ۱۹۷۰ و ۸۰،

00:02:14.260 --> 00:02:16.260
گروهی از دانشمندان

00:02:16.260 --> 00:02:18.260
تمامی ۷۰۰۰ اتصال میان این نورون ها را

00:02:18.260 --> 00:02:20.260
نقشه برداری کردند.

00:02:21.260 --> 00:02:23.260
در این نمودار، هر گره یک نورون است،

00:02:23.260 --> 00:02:25.260
و هر خط یک اتصال.

00:02:25.260 --> 00:02:27.260
و این کانکتوم این کرم کوچک

00:02:27.260 --> 00:02:31.260
یعنی سی. الگانس است.

00:02:31.260 --> 00:02:34.260
کانکتوم شما بس پیچیده تر از این است،

00:02:34.260 --> 00:02:36.260
چرا که مغز شما

00:02:36.260 --> 00:02:38.260
از ۱۰۰ میلیارد نورون ساخته شده

00:02:38.260 --> 00:02:41.260
و تعداد اتصالات آن ۱۰،۰۰۰ برابر بیشتر است.

00:02:41.260 --> 00:02:43.260
یک نمودار شبیه این برای مغز شما هم وجود دارد،

00:02:43.260 --> 00:02:46.260
اما به هیچ طریقی ممکن نیست در این صفحه بگنجد.

00:02:47.260 --> 00:02:50.260
تعداد اتصالات کانکتوم شما یک میلیون برابر بیشتر است از

00:02:50.260 --> 00:02:53.260
تعداد حروف ژنوم شما.

00:02:53.260 --> 00:02:55.260
و این یعنی انبوهی از اطلاعات.

00:02:55.260 --> 00:02:58.260
در این انبوه اطلاعات چه چیزی نهفته ست؟

00:02:59.260 --> 00:03:02.260
هنوز کسی به طور قطع نمیداند، اما نظریه هایی وجود دارند.

00:03:02.260 --> 00:03:05.260
از قرن نوزدهم، عصب شناسان گمانه زنی هایی در این زمینه کرده اند

00:03:05.260 --> 00:03:07.260
که شاید خاطرات شما --

00:03:07.260 --> 00:03:09.260
اطلاعاتی که باعث شده اند شما، شما باشید --

00:03:09.260 --> 00:03:11.260
شاید خاطرات شما در این اتصالات میان نورون های مغز شما

00:03:11.260 --> 00:03:13.260
نگهداری میشوند.

00:03:15.260 --> 00:03:17.260
و احتمالا جنبه های دیگری از هویت شخصی شما --

00:03:17.260 --> 00:03:20.260
شاید شخصیت و خرد شما --

00:03:20.260 --> 00:03:22.260
شاید آن ها هم در اتصالات میان نورون های شما

00:03:22.260 --> 00:03:25.260
رمز شده باشند.

00:03:26.260 --> 00:03:29.260
حالا متوجه میشوید که چرا این فرضیه را پیشنهاد کردم که:

00:03:29.260 --> 00:03:32.260
من یعنی کانکتوم من.

00:03:32.260 --> 00:03:35.260
از شما نخواستم که فریادش بزنید چون لزوما درست است،

00:03:35.260 --> 00:03:37.260
تنها از شما میخواهم که آن را بخاطر بسپارید.

00:03:37.260 --> 00:03:39.260
در واقع، ما نمیدانیم آیا این فرضیه صحت دارد یا نه،

00:03:39.260 --> 00:03:41.260
چون هرگز فناوری های لازم برای آزمودن آن را

00:03:41.260 --> 00:03:43.260
در اختیار نداشته ایم.

00:03:44.260 --> 00:03:47.260
نقشه برداری کانکتوم آن کرم

00:03:47.260 --> 00:03:50.260
نیازمند بیش از یک دهه کار طاقت فرسا بود.

00:03:50.260 --> 00:03:53.260
و برای یافتن کانکتوم مغزهایی شبیه مغز ما

00:03:53.260 --> 00:03:56.260
نیاز به فناوری هایی بس پیچیده تر داریم، که خودکار هستند،

00:03:56.260 --> 00:03:59.260
و فرآیند نقشه برداری کانکتوم ها را سرعت میبخشند.

00:03:59.260 --> 00:04:02.260
در چند دقیقه آینده در مورد برخی از این فناوری ها صحبت میکنم.

00:04:02.260 --> 00:04:04.260
فناوری هایی که اکنون در آزمایشگاه من و همکارانم

00:04:04.260 --> 00:04:07.260
در حال توسعه هستند.

00:04:08.260 --> 00:04:11.260
احتمالا شما تصویر نورون ها را قبلا دیده اید.

00:04:11.260 --> 00:04:13.260
نورون ها را میتوان به راحتی

00:04:13.260 --> 00:04:16.260
از روی اشکال خارق العاده شان شناخت.

00:04:16.260 --> 00:04:19.260
نورون ها شاخه های بلند و نازکی دارند،

00:04:19.260 --> 00:04:22.260
و شبیه درخت هستند.

00:04:22.260 --> 00:04:25.260
اما این تنها یک نورون است.

00:04:25.260 --> 00:04:27.260
برای یافتن یک کانکتوم،

00:04:27.260 --> 00:04:30.260
بایستی تمام نورون ها را همزمان ببینیم.

00:04:30.260 --> 00:04:32.260
اجازه بدهید بابی کاستوری را به شما معرفی کنم.

00:04:32.260 --> 00:04:34.260
بابی در آزمایشگاه جف لیکمن

00:04:34.260 --> 00:04:36.260
در دانشگاه هاروارد کار میکند.

00:04:36.260 --> 00:04:38.260
چیزی که در دست بابی میبینید برش های بسیار نازکی

00:04:38.260 --> 00:04:40.260
از مغز موش است.

00:04:40.260 --> 00:04:43.260
برای مشاهده همزمان تمام شاخه های نورون ها

00:04:44.260 --> 00:04:46.260
نیاز به قدرت تفکیکی داریم

00:04:46.260 --> 00:04:49.260
که در بزرگنمایی ۱۰۰،۰۰۰ به دست می آید.

00:04:50.260 --> 00:04:53.260
تنها مشکل اینجاست که حتی در این بزرگنمایی ممکن است نتوان آن ها را تشخیص داد،

00:04:53.260 --> 00:04:56.260
و این به این دلیل است که باید با دید سه بعدی به آن ها نگاه کنیم.

00:04:56.260 --> 00:04:58.260
اگر بتوانیم تصاویر بسیاری از تعداد زیادی برش مغز بگیریم

00:04:58.260 --> 00:05:00.260
و آن ها را روی هم پشته کنیم،

00:05:00.260 --> 00:05:02.260
به یک تصویر سه بعدی دست خواهیم یافت.

00:05:02.260 --> 00:05:04.260
اما همچنان نمیتوان شاخه ها را تشخیص داد.

00:05:04.260 --> 00:05:06.260
پس از بالا شروع میکنیم،

00:05:06.260 --> 00:05:09.260
و سطح مقطع یک شاخه را با رنگ قرمز پر میکنیم،

00:05:09.260 --> 00:05:11.260
و این کار را برای برش بعدی هم انجام میدهیم،

00:05:11.260 --> 00:05:13.260
و برش بعدی هم.

00:05:13.260 --> 00:05:15.260
و این کار را تکرار میکنیم،

00:05:15.260 --> 00:05:18.260
برش بعد از برش.

00:05:18.260 --> 00:05:20.260
اگر این کار را برای تمام برش های یک پشته انجام دهیم،

00:05:20.260 --> 00:05:23.260
میتوانیم شکل سه بعدی قطعه کوچکی از

00:05:23.260 --> 00:05:26.260
شاخه ای از یک نورون را بازسازی کنیم.

00:05:26.260 --> 00:05:28.260
و میتوانیم این کار را برای یک نورون دیگر به رنگ سبز انجام دهیم.

00:05:28.260 --> 00:05:30.260
همانطور که میبینید نورون سبز رنگ با نورون قرمز رنگ

00:05:30.260 --> 00:05:32.260
در دو نقطه تماس پیدا میکند

00:05:32.260 --> 00:05:34.260
و این نقاط همان سیناپس ها هستند.

00:05:34.260 --> 00:05:36.260
بد نیست یک سیناپس را در بزرگنمایی بالاتری ببینیم.

00:05:36.260 --> 00:05:39.260
سعی کنید به سطح داخلی نورون سبز دقت کنید.

00:05:39.260 --> 00:05:41.260
احتمالا میتوانید دایره های کوچکی را مشاهده کنید.

00:05:41.260 --> 00:05:44.260
این ها همان کیسه چه ها یا وزیکول ها هستند.

00:05:44.260 --> 00:05:47.260
کیسه چه ها حاوی انتقال دهنده های عصبی هستند.

00:05:47.260 --> 00:05:49.260
هنگامی که نورون سبز رنگ بخواهد پیامی را

00:05:49.260 --> 00:05:51.260
به نورون قرمز مخابره کند،

00:05:51.260 --> 00:05:54.260
مقادیری انتقال دهنده عصبی ترشح میکند.

00:05:54.260 --> 00:05:56.260
اصطلاحا گفته میشود که دو نورون

00:05:56.260 --> 00:05:58.260
با یکدیگر در سیناپس تماس میگیرند،

00:05:58.260 --> 00:06:01.260
مانند دو دوستی که تلفنی با هم حرف میزنند.

00:06:02.260 --> 00:06:04.260
پس یاد گرفتید که سیناپس ها را چگونه ردیابی کنید.

00:06:04.260 --> 00:06:07.260
حال، چطور میتوان تمام یک کانکتوم را پیدا کرد؟

00:06:07.260 --> 00:06:10.260
ساده است، باید این پشته سه بعدی از تصاویر را برداریم

00:06:10.260 --> 00:06:13.260
و با آن به سان یک کتاب رنگ آمیزی غول آسا برخورد کنیم.

00:06:13.260 --> 00:06:16.260
بایستی هر نورون را با رنگ متمایزی رنگ آمیزی کنیم،

00:06:16.260 --> 00:06:18.260
به مجموعه این تصاویر نگاه کنیم،

00:06:18.260 --> 00:06:20.260
سیناپس ها را بیابیم،

00:06:20.260 --> 00:06:23.260
و به رنگ هر دو نورونی که در هر سیناپس شریک اند توجه کنیم.

00:06:23.260 --> 00:06:26.260
اگر این کار را برای تمام این پشته از تصاویر انجام دهیم،

00:06:26.260 --> 00:06:28.260
میتوانیم یک کانکتوم را نقشه برداری کنیم.

00:06:29.260 --> 00:06:31.260
تا اینجا،

00:06:31.260 --> 00:06:33.260
مبانی نورون ها و سیناپس ها را یاد گرفتید.

00:06:33.260 --> 00:06:35.260
گمان میکنم آماده باشیم

00:06:35.260 --> 00:06:38.260
تا با یکی از مهم ترین پرسش ها در نوروساینس برخورد کنیم:

00:06:39.260 --> 00:06:42.260
مغز مردان و زنان چه تفاوت هایی با هم دارند؟

00:06:42.260 --> 00:06:44.260
(خنده)

00:06:44.260 --> 00:06:46.260
به گفته این کتاب رشد شخصیت،

00:06:46.260 --> 00:06:48.260
مغز پسرها شبیه ویفر است؛

00:06:48.260 --> 00:06:51.260
آن ها زندگی شان را در جعبه هایی طبقه بندی میکنند.

00:06:51.260 --> 00:06:54.260
مغز دخترها شبیه ماکارونی است؛

00:06:54.260 --> 00:06:57.260
همه چیز در زندگی آن ها به همه چیز ارتباط دارد!

00:06:57.260 --> 00:06:59.260
(خنده)

00:06:59.260 --> 00:07:01.260
حالا شما به این میخندید،

00:07:01.260 --> 00:07:03.260
اما این کتاب زندگی من را دگرگون کرد!

00:07:03.260 --> 00:07:05.260
(خنده)

00:07:07.260 --> 00:07:10.260
ولی بی شوخی، این توصیف چه ایرادی دارد؟

00:07:10.260 --> 00:07:13.260
شما دیگر الان به اندازه کافی میدانید تا جواب من را بدهید. چه ایرادی دارد؟

00:07:20.260 --> 00:07:23.260
مهم نیست که شما پسر باشید یا دختر،

00:07:23.260 --> 00:07:26.260
مغز همه مثل ماکارونی است.

00:07:26.260 --> 00:07:29.260
یا حتی رشته های ورمیشل خیلی نازک با شاخه های زیاد.

00:07:30.260 --> 00:07:32.260
درست همانطور که یک رشته ماکارونی

00:07:32.260 --> 00:07:35.260
با رشته های زیاد دیگری در بشقاب شما تماس دارد،

00:07:35.260 --> 00:07:37.260
یک نورون هم نورون های بسیار زیاد دیگری را

00:07:37.260 --> 00:07:39.260
از طریق شاخه های در هم پیچیده شان لمس میکند.

00:07:39.260 --> 00:07:42.260
یک نورون میتواند به تعدادی چنان زیاد از نورون های دیگر وصل باشد،

00:07:42.260 --> 00:07:44.260
زیرا در هر یک از نقاط تماس

00:07:44.260 --> 00:07:47.260
میتواند یک سیناپس تشکیل دهد.

00:07:49.260 --> 00:07:52.260
با این همه جزئیات ممکن است چشم انداز کلی را گم کرده باشید.

00:07:52.260 --> 00:07:55.260
تصویر کلی اینکه این مکعب از بافت مغز واقعا چه اندازه است.

00:07:55.260 --> 00:07:58.260
بد نیست چند مقایسه انجام دهیم تا متوجه شوید.

00:07:58.260 --> 00:08:01.260
تاکید میکنم، این مکعب بسیار کوچک است. هر یال تنها ۶ میکرون.

00:08:03.260 --> 00:08:06.260
این همان مکعب است در کنار یک نورون کامل.

00:08:06.260 --> 00:08:09.260
و میبینید که در واقع تنها کوچکترین قطعات هر شاخه

00:08:09.260 --> 00:08:12.260
در درون این مکعب قرار دارند.

00:08:12.260 --> 00:08:15.260
و یک نورون، خوب مسلما کوچکتر از مغز است.

00:08:17.260 --> 00:08:19.260
و این تنها مغز یک موش است.

00:08:21.260 --> 00:08:24.260
که بسیار کوچکتر از مغز انسان است.

00:08:25.260 --> 00:08:27.260
گاهی وقتی این را به دوستانم نشان میدهم،

00:08:27.260 --> 00:08:29.260
به من پیشنهاد میدهند که

00:08:29.260 --> 00:08:32.260
«میدونی سباستین، بد نیست بیخیال شی.

00:08:32.260 --> 00:08:34.260
نوروساینس به جایی نمیرسه!»

00:08:34.260 --> 00:08:36.260
چرا که اگر به مغز با چشم غیرمسلح نگاه کنید،

00:08:36.260 --> 00:08:38.260
هرگز عمق پیچیدگی آن را نمیبینید،

00:08:38.260 --> 00:08:40.260
اما اگر از یک میکروسکوپ استفاده کنید،

00:08:40.260 --> 00:08:43.260
در نهایت، پیچیدگی پنهان آن آشکار میشود.

00:08:45.260 --> 00:08:47.260
در قرن هفدهم،

00:08:47.260 --> 00:08:49.260
فیلسوف و ریاضیدان، بلیز پاسکال،

00:08:49.260 --> 00:08:52.260
از ترس خود از بینهایت نوشت،

00:08:52.260 --> 00:08:54.260
احساسش در مورد بیهودگی اندیشیدن

00:08:54.260 --> 00:08:57.260
به دوردست های فضای بیکران.

00:08:59.260 --> 00:09:01.260
اما به عنوان یک دانشمند،

00:09:01.260 --> 00:09:04.260
من قرار نیست از احساساتم صحبت کنم.

00:09:04.260 --> 00:09:06.260
..استاد خیلی حرف میزنید!

00:09:06.260 --> 00:09:08.260
(خنده)

00:09:08.260 --> 00:09:10.260
ولی آیا اجازه دارم؟

00:09:10.260 --> 00:09:12.260
(خنده)

00:09:12.260 --> 00:09:14.260
(تشویق)

00:09:14.260 --> 00:09:16.260
من بسیار کنجکاوم،

00:09:16.260 --> 00:09:18.260
و در شگفتی غوطه میخورم،

00:09:18.260 --> 00:09:21.260
اما گاهی هم نا امید و درمانده میشوم.

00:09:22.260 --> 00:09:24.260
چرا تصمیم گرفتم این اندام را مطالعه کنم؟

00:09:24.260 --> 00:09:27.260
اندامی که پیچیدگی زیبا و خیره کننده ای دارد

00:09:27.260 --> 00:09:29.260
اما همزمان ممکن است بینهایت باشد.

00:09:29.260 --> 00:09:31.260
احمقانه نیست؟

00:09:31.260 --> 00:09:33.260
ما چطور جرأت میکنیم حتی فکر کنیم

00:09:33.260 --> 00:09:36.260
که روزی ممکن است پیچیدگی اش را درک کنیم؟

00:09:38.260 --> 00:09:41.260
اما من دن کیشوت وار در این تلاش آرمانگرایانه پافشاری میکنم.

00:09:41.260 --> 00:09:44.260
و در واقع، این روزها امید های تازه ای در ذهن میپرورم.

00:09:45.260 --> 00:09:47.260
یک روز،

00:09:47.260 --> 00:09:49.260
یک ناوگان بزرگ از میکروسکوپ ها

00:09:49.260 --> 00:09:51.260
هر نورون و هر سیناپس را

00:09:51.260 --> 00:09:54.260
در دریای عظیمی از عکس ها تصویر میکنند.

00:09:54.260 --> 00:09:57.260
و یک روز، ابررایانه های هوشمند

00:09:57.260 --> 00:10:00.260
این تصاویر را بدون کمک انسان پردازش میکنند

00:10:00.260 --> 00:10:03.260
و آن ها را در یک کانکتوم خلاصه میکنند.

00:10:04.260 --> 00:10:07.260
نمیدانم، ولی امیدوارم زنده باشم تا آن روز را ببینم.

00:10:08.260 --> 00:10:10.260
چرا که یافتن یک کانکتوم کامل انسان

00:10:10.260 --> 00:10:13.260
یکی از بزرگترین چالش های فناوری تاریخ است.

00:10:13.260 --> 00:10:16.260
و برای موفقیت نیاز به تلاش نسل ها دارد.

00:10:17.260 --> 00:10:20.260
در زمان حاضر، آنچه من و همکارانم برایش تلاش میکنیم

00:10:20.260 --> 00:10:22.260
هدفی بسیار فروتنانه تر از این است --

00:10:22.260 --> 00:10:24.260
یافتن کانکتوم های جزئی

00:10:24.260 --> 00:10:27.260
از قطعات کوچکی از مغز موش و انسان.

00:10:27.260 --> 00:10:30.260
و تنها همین برای آزمون های اولیه این فرضیه کافی است

00:10:30.260 --> 00:10:33.260
که من، یعنی کانکتوم من.

00:10:35.260 --> 00:10:38.260
اکنون اجازه دهید شما را متقاعد کنم که این فرضیه ای معقول است،

00:10:38.260 --> 00:10:41.260
و در واقع ارزش دارد جدی گرفته شود.

00:10:42.260 --> 00:10:44.260
هنگامی که شما در کودکی رشد میکنید،

00:10:44.260 --> 00:10:47.260
و در بزرگسالی پا به سن میگذارید،

00:10:47.260 --> 00:10:50.260
هویت شخصی شما به آهستگی دستخوش تغییر میشود.

00:10:50.260 --> 00:10:52.260
به همین صورت، هر کانکتوم نیز

00:10:52.260 --> 00:10:54.260
در طول زمان دگرگون میشود.

00:10:55.260 --> 00:10:57.260
چه دگرگونی هایی رخ میدهند؟

00:10:57.260 --> 00:10:59.260
نورون ها همانند درختانی،

00:10:59.260 --> 00:11:01.260
میتوانند شاخه های جدید بر آورند،

00:11:01.260 --> 00:11:04.260
و شاخه های کهنه را از دست بدهند.

00:11:04.260 --> 00:11:07.260
سیناپس ها میتوانند شکل بگیرند،

00:11:07.260 --> 00:11:10.260
و میتوانند از بین بروند.

00:11:10.260 --> 00:11:12.260
و سیناپس ها میتوانند بزرگتر شوند،

00:11:12.260 --> 00:11:15.260
یا کوچکتر شوند.

00:11:15.260 --> 00:11:17.260
پرسش دوم:

00:11:17.260 --> 00:11:20.260
چه چیزی موجب این دگرگونی ها میشود؟

00:11:20.260 --> 00:11:22.260
خب، درست است.

00:11:22.260 --> 00:11:25.260
این تغییرات تا اندازه ای توسط ژن ها برنامه ریزی میشوند.

00:11:25.260 --> 00:11:27.260
اما این تمام داستان نیست،

00:11:27.260 --> 00:11:29.260
چرا که سیگنال هایی وجود دارند، سیگنال های الکتریکی،

00:11:29.260 --> 00:11:31.260
که شاخه های نورون ها را طی میکنند

00:11:31.260 --> 00:11:33.260
و سیگنال های شیمیایی

00:11:33.260 --> 00:11:35.260
که از شاخه ای به شاخه دیگر میپرند.

00:11:35.260 --> 00:11:38.260
مجموعه این سیگنال ها را فعالیت مغزی مینامند.

00:11:38.260 --> 00:11:40.260
و شواهد بسیاری وجود دارد

00:11:40.260 --> 00:11:43.260
که فعالیت مغزی

00:11:43.260 --> 00:11:46.260
افکار ما، احساسات و ادراک ما

00:11:46.260 --> 00:11:48.260
و تجربیات ذهنی ما را رمز میکند.

00:11:48.260 --> 00:11:51.260
و شواهد بسیاری وجود دارد که فعالیت مغزی

00:11:51.260 --> 00:11:54.260
اتصالات مغز را دگرگون میکند.

00:11:54.260 --> 00:11:57.260
و اگر این دو دانسته را کنار هم بگذاریم،

00:11:57.260 --> 00:11:59.260
نتیجه میشود که تجربیات شما

00:11:59.260 --> 00:12:02.260
میتوانند کانکتوم شما را دگرگون کنند.

00:12:02.260 --> 00:12:04.260
و از این روست که هر کانکتوم یگانه است،

00:12:04.260 --> 00:12:07.260
حتا کانکتوم دوقلوهای همسان.

00:12:08.260 --> 00:12:11.260
کانکتوم جایی ست که «سرشت» و «پرورش» یکدیگر را ملاقات میکنند.

00:12:12.260 --> 00:12:14.260
و ممکن است درست باشد که

00:12:14.260 --> 00:12:16.260
فکر کردن به تنهایی

00:12:16.260 --> 00:12:18.260
میتواند کانکتوم شما را تغییر دهد --

00:12:18.260 --> 00:12:21.260
ایده ای که میتواند انگیزه بخش باشد.

00:12:24.260 --> 00:12:26.260
در این تصویر چه میبینید؟

00:12:28.260 --> 00:12:31.260
ممکن است بگویید جریان خنک و تازه آب.

00:12:32.260 --> 00:12:34.260
دیگر چه میبینید؟

00:12:37.260 --> 00:12:39.260
آن شیار روی زمین را

00:12:39.260 --> 00:12:42.260
که بستر رودخانه نامیده میشود از قلم نیاندازید.

00:12:42.260 --> 00:12:45.260
بدون آن آب نمیداند به کدام جهت جاری شود.

00:12:45.260 --> 00:12:47.260
و من میخوام از مثال جریان آب

00:12:47.260 --> 00:12:49.260
به عنوان یک تشبیه استفاده کنم

00:12:49.260 --> 00:12:51.260
برای ارتباط میان فعالیت عصبی

00:12:51.260 --> 00:12:53.260
و ارتباطات عصبی.

00:12:54.260 --> 00:12:57.260
فعالیت عصبی همواره در حال تغییر است.

00:12:57.260 --> 00:13:00.260
مانند آب رودخانه؛ هرگز از حرکت نمی ایستد.

00:13:00.260 --> 00:13:02.260
ارتباطات شبکه عصبی مغز

00:13:02.260 --> 00:13:04.260
مسیری که فعالیت عصبی

00:13:04.260 --> 00:13:06.260
در آن جریان می یابد را

00:13:06.260 --> 00:13:08.260
تعیین میکند.

00:13:08.260 --> 00:13:11.260
به این طریق، کانکتوم همچون بستر رودخانه است.

00:13:13.260 --> 00:13:16.260
اما این تشبیه از این نیز غنی تر است.

00:13:16.260 --> 00:13:19.260
زیرا جدا از اینکه که بستر رودخانه

00:13:19.260 --> 00:13:21.260
جریان آب را هدایت میکند،

00:13:21.260 --> 00:13:23.260
در دراز مدت،

00:13:23.260 --> 00:13:26.260
آب نیز بستر رودخانه را تغییر شکل میدهد.

00:13:26.260 --> 00:13:28.260
و همانطور که اندکی پیشتر گفتم،

00:13:28.260 --> 00:13:31.260
فعالیت عصبی میتواند کانکتوم را تغییر دهد.

00:13:33.260 --> 00:13:35.260
و اگر اجازه بدهید بار دیگر

00:13:35.260 --> 00:13:38.260
از کلام استعاره کمک بگیرم،

00:13:38.260 --> 00:13:41.260
به یادتان میآورم که فعالیت عصبی

00:13:41.260 --> 00:13:43.260
بنیاد فیزیکی افکار، احساسات و ادراک است --

00:13:43.260 --> 00:13:46.260
یا دستکم عصب شناسان اینگونه گمان میکنند.

00:13:46.260 --> 00:13:48.260
پس بیراه نیست

00:13:48.260 --> 00:13:50.260
اگر از رودخانه هوشیاری صحبت کنیم.

00:13:50.260 --> 00:13:53.260
فعالیت عصبی آب آن است،

00:13:53.260 --> 00:13:56.260
و کانکتوم بستر آن.

00:13:57.260 --> 00:13:59.260
بد نیست از قله های استعاره پایین بیاییم

00:13:59.260 --> 00:14:01.260
و به دانش برگردیم.

00:14:01.260 --> 00:14:03.260
فرض کنید فناوری های ما برای یافتن کانکتوم

00:14:03.260 --> 00:14:05.260
واقعا کار کنند.

00:14:05.260 --> 00:14:07.260
چگونه میتوان این فرضیه را آزمود که

00:14:07.260 --> 00:14:10.260
که «من، یعنی کانکتوم من»؟

00:14:10.260 --> 00:14:13.260
من آزمونی پیشنهاد میکنم که خیلی سر راست است.

00:14:13.260 --> 00:14:15.260
مثلا فرض کنید بخواهیم

00:14:15.260 --> 00:14:18.260
خاطره های یک کانکتوم را بخوانیم.

00:14:18.260 --> 00:14:20.260
حافظه مربوط به یک توالی زمانمند بلند

00:14:20.260 --> 00:14:23.260
از حرکات را تصور کنید،

00:14:23.260 --> 00:14:26.260
مانند یک پیانیست که قطعه سوناتای بتهوون را مینوازد.

00:14:26.260 --> 00:14:29.260
بنا بر نظریه ای که به قرن نوزدهم بر میگردد،

00:14:29.260 --> 00:14:31.260
اینگونه محفوظات به صورت یک زنجیره اتصالات سیناپسی

00:14:31.260 --> 00:14:34.260
درون مغز شما ذخیره شده اند.

00:14:35.260 --> 00:14:38.260
چرا که اگر اولین نورون در این زنجیر فعال شود،

00:14:38.260 --> 00:14:41.260
نورون دوم نیز توسط پیامی که از طریق سیناپس دریافت میکند فعال میشود،

00:14:41.260 --> 00:14:43.260
و همینطور در طول خط،

00:14:43.260 --> 00:14:45.260
مانند زنجیری از مهره های دومینو که می افتند.

00:14:45.260 --> 00:14:47.260
و فرض میشود

00:14:47.260 --> 00:14:50.260
که این توالی فعال سازی های عصبی،

00:14:50.260 --> 00:14:52.260
مبنای توالی آن حرکات است.

00:14:52.260 --> 00:14:54.260
پس یک راه آزمودن آن نظریه این است

00:14:54.260 --> 00:14:56.260
که در درون کانکتوم ها

00:14:56.260 --> 00:14:58.260
در پی چنین زنجیرهایی بگردیم.

00:14:58.260 --> 00:15:01.260
اما این هرگز آسان نخواهد بود زیرا کانکتوم ها به این سادگی نیستند.

00:15:01.260 --> 00:15:03.260
بلکه بسیار پیچیده و در هم تنیده اند.

00:15:03.260 --> 00:15:05.260
پس قطعا به رایانه هایمان نیاز خواهیم داشت

00:15:05.260 --> 00:15:08.260
تا این زنجیرهای در هم و بر هم را باز کنند.

00:15:08.260 --> 00:15:10.260
و اگر موفق شویم،

00:15:10.260 --> 00:15:13.260
توالی نورون هایی که بدست میآوریم

00:15:13.260 --> 00:15:16.260
پیشگویی الگوی فعالیت عصبی خواهد بود

00:15:16.260 --> 00:15:19.260
که در هنگام به یاد آوردن محفوظات بازپخش میشود.

00:15:19.260 --> 00:15:21.260
و باز اگر موفق شویم،

00:15:21.260 --> 00:15:24.260
این نخستین مثال خواندن حافظه از یک کانکتوم خواهد بود.

00:15:28.260 --> 00:15:30.260
(خنده)

00:15:30.260 --> 00:15:32.260
چه شیر تو شیری!

00:15:33.260 --> 00:15:35.260
آیا تا به حال تلاش کرده اید سامانه ای به این پیچیدگی را

00:15:35.260 --> 00:15:37.260
سیم کشی کنید؟

00:15:37.260 --> 00:15:39.260
امیدوارم نکرده باشید!

00:15:39.260 --> 00:15:42.260
اما اگر کرده باشید، میدانید که اشتباه کردن بسیار آسان است.

00:15:45.260 --> 00:15:47.260
شاخه های نورون ها شبیه سیم کشی های مغز اند.

00:15:47.260 --> 00:15:51.260
کسی از شما میداند طول کل سیم های درون مغز شما چقدر است؟

00:15:54.260 --> 00:15:56.260
اجازه بدهید راهنماییتان کنم: خیلی زیاد است!

00:15:56.260 --> 00:15:58.260
(خنده)

00:15:59.260 --> 00:16:02.260
حدس من میلیون ها کیلومتر است.

00:16:02.260 --> 00:16:05.260
این همه در جمجمه شما بسته بندی شده است.

00:16:05.260 --> 00:16:07.260
و اگر به بزرگی این عدد فکر کنید

00:16:07.260 --> 00:16:09.260
میبینید که ظرفیت بسیار بالایی برای بروز خطا

00:16:09.260 --> 00:16:11.260
در سیمکشی مغز وجود دارد.

00:16:11.260 --> 00:16:14.260
و چقدر هم روزنامه ها و مجلات تیترهایی از این قبیل را دوست دارند:

00:16:14.260 --> 00:16:16.260
«سیمکشی متفاوت مغز عامل کم اشتهایی بیمارگونه»

00:16:16.260 --> 00:16:18.260
یا «مغز بیماران اوتیسم سیمکشی متفاوتی دارد.»

00:16:18.260 --> 00:16:20.260
این ها ادعاهای قابل توجهی هستند،

00:16:20.260 --> 00:16:22.260
اما در حقیقت

00:16:22.260 --> 00:16:24.260
ما هنوز نمیتوانیم سیمکشی مغز را به اندازه کافی به روشنی ببینیم

00:16:24.260 --> 00:16:26.260
تا بتوانیم درستی آن ها را آزمایش کنیم.

00:16:26.260 --> 00:16:29.260
بدین سان فناوری های ما برای دیدن کانکتوم ها

00:16:29.260 --> 00:16:31.260
نهایتا ما را قادر میسازند

00:16:31.260 --> 00:16:33.260
سیمکشی های اشتباه مغز را نیز بخوانیم،

00:16:33.260 --> 00:16:36.260
و ناهنجاری های روانی را هم در کانکتوم ها ببینیم.

00:16:40.260 --> 00:16:43.260
گاهی بهترین راه برای آزمودن یک فرضیه

00:16:43.260 --> 00:16:46.260
در نظر گرفتن افراطی ترین نتایج آن است.

00:16:46.260 --> 00:16:49.260
فیلسوفان این بازی را خیلی خوب میدانند.

00:16:50.260 --> 00:16:53.260
اگر باور داشته باشید که من، یعنی کانکتوم من، به همین طریق باید بپذیرید كه مرگ فروپاشی کانکتوم شماست.

00:16:53.260 --> 00:16:56.260
اگر باور داشته باشید که من، یعنی کانکتوم من، به همین طریق باید بپذیرید كه مرگ فروپاشی کانکتوم شماست.

00:16:56.260 --> 00:16:58.260
اگر باور داشته باشید که من، یعنی کانکتوم من، به همین طریق باید بپذیرید كه مرگ فروپاشی کانکتوم شماست.

00:16:58.260 --> 00:17:01.260
اگر باور داشته باشید که من، یعنی کانکتوم من، به همین طریق باید بپذیرید كه مرگ فروپاشی کانکتوم شماست.

00:17:02.260 --> 00:17:05.260
این را مطرح میکنم چرا که امروز پیامبرانی هستند

00:17:05.260 --> 00:17:08.260
که ادعا میکنند

00:17:08.260 --> 00:17:11.260
فناوری شرایط زندگی بشر را به طور بنیادی دگرگون خواهد کرد

00:17:11.260 --> 00:17:14.260
و حتی موجب دگرگونی گونه انسان میشود.

00:17:14.260 --> 00:17:17.260
یکی از پرطرفدارترین رویاهای آن ها این است

00:17:17.260 --> 00:17:19.260
که با استفاده از انجماد اجساد

00:17:19.260 --> 00:17:21.260
مرگ را دور بزنند.

00:17:21.260 --> 00:17:23.260
اگر شما حاضر باشید ۱۰۰٫۰۰۰ دلار پول بدهید،

00:17:23.260 --> 00:17:26.260
میتوانید وصیت کنید که بدنتان را بعد از مرگ

00:17:26.260 --> 00:17:28.260
در یکی از این مخازن در انباری در آریزونا،

00:17:28.260 --> 00:17:30.260
در نیتروژن مایع نگهداری کنند،

00:17:30.260 --> 00:17:32.260
در انتظار تمدنی پیشرفته در آینده

00:17:32.260 --> 00:17:35.260
که بتواند شما را زنده کند.

00:17:36.260 --> 00:17:38.260
آیا جا دارد این جویندگان مدرن بیمرگی را مسخره کنیم و

00:17:38.260 --> 00:17:40.260
آن ها را احمق بنامیم؟

00:17:40.260 --> 00:17:42.260
یا آن ها روزی بالای سر قبر ما

00:17:42.260 --> 00:17:44.260
به ما پوزخند خواهند زد؟؟

00:17:45.260 --> 00:17:47.260
نمیدانم.

00:17:47.260 --> 00:17:50.260
من ترجیح میدهم باورهای آن را به صورت علمی آزمون کنم.

00:17:50.260 --> 00:17:52.260
من پیشنهاد میکنم که تلاش کنیم تا

00:17:52.260 --> 00:17:54.260
کانکتوم یک مغز منجمد را پیدا کنیم.

00:17:54.260 --> 00:17:56.260
میدانیم که پس از مرگ و حتی در حال انجماد

00:17:56.260 --> 00:17:58.260
مغز دچار آسیب خواهد شد.

00:17:58.260 --> 00:18:01.260
حال پرسش این است که آیا این آسیب ها کانکتوم را پاک میکنند؟

00:18:01.260 --> 00:18:04.260
اگر چنین باشد، دیگر هیچ راهی وجود ندارد که تمدنی در آینده

00:18:04.260 --> 00:18:07.260
بتواند حافظه های این مغزهای منجمد را بازخوانی کند.

00:18:07.260 --> 00:18:09.260
ممکن است بتوان بدن ها را زنده کرد،

00:18:09.260 --> 00:18:11.260
اما مغزها را نه.

00:18:11.260 --> 00:18:14.260
اما اگر کانکتوم همچنان دست نخورده مانده باشد،

00:18:14.260 --> 00:18:17.260
نمیتوان به سادگی ادعاهای طرفداران انجماد را به سخره گرفت.

00:18:20.260 --> 00:18:22.260
من در این سخنرانی جویشی را تشریح کردم

00:18:22.260 --> 00:18:25.260
که از دنیای چیزهای بسیار کوچک آغاز میشود،

00:18:25.260 --> 00:18:28.260
و ما را تا دنیای آینده های دور پیش میبرد.

00:18:28.260 --> 00:18:31.260
کانکتوم ها نقطه عطفی را در تاریخ بشر رقم خواهند زد.

00:18:32.260 --> 00:18:34.260
آن زمان که ما از اجداد میمون-مانندمان فرگشت (تکامل) پیدا میکردیم،

00:18:34.260 --> 00:18:36.260
در ساوانای افریقا،

00:18:36.260 --> 00:18:39.260
آنچه ما را متمایز میکرد مغزهای بزرگتر ما بود.

00:18:40.260 --> 00:18:42.260
ما مغزهایمان را بکار بستیم

00:18:42.260 --> 00:18:45.260
تا فناوری های حتی شگفت انگیز تری را شکل دهیم.

00:18:45.260 --> 00:18:48.260
روزی آخر این فناوری ها چنان قدرتمند خواهند شد

00:18:48.260 --> 00:18:51.260
که آن ها را بکار خواهیم بست تا خودمان را بشناسیم،

00:18:51.260 --> 00:18:54.260
با پیاده کردن و بازساختن مغزهای خودمان.

00:18:54.260 --> 00:18:57.260
با پیاده کردن و بازساختن مغزهای خودمان.

00:18:57.260 --> 00:19:00.260
من باور دارم این سفر دراز خودشناسی

00:19:00.260 --> 00:19:03.260
نه فقط برای دانشمندان،

00:19:03.260 --> 00:19:05.260
که برای همه ماست.

00:19:05.260 --> 00:19:08.260
و خوشحالم که امروز شما را در این سفر همراه خودم داشتم.

00:19:08.260 --> 00:19:10.260
سپاسگزارم.

00:19:10.260 --> 00:19:18.260
(برگردان: امیر صابری)

