WEBVTT
Kind: captions
Language: vi

00:00:00.000 --> 00:00:07.000
Translator: Le Huong

00:00:11.820 --> 00:00:16.302
Vì thế, tôi đã có công việc đầu tiên của mình 
là một lập trình viên máy tính

00:00:16.302 --> 00:00:18.415
ngay trong những năm học đại học đầu tiên

00:00:18.415 --> 00:00:20.269
về cơ bản, khi vẫn là một thiếu niên

00:00:20.269 --> 00:00:22.441
Không lâu sau khi tôi bắt đầu công việc,

00:00:22.465 --> 00:00:24.475
trong lúc đang viết phần mềm cho công ty,

00:00:24.619 --> 00:00:28.254
thì người quản lý ở đó tiến đến chỗ tôi

00:00:28.278 --> 00:00:29.546
và thì thầm vào tai tôi

00:00:30.049 --> 00:00:32.910
"Hắn có phát hiện nếu tôi nói dối không?"

00:00:33.626 --> 00:00:35.702
Không có một ai khác trong phòng cả.

00:00:36.601 --> 00:00:41.321
"Ai có thể nhận ra anh đang nói dối?"
"Và tại sao ta phải nói thầm?"

00:00:41.321 --> 00:00:45.416
Ông quản lý chỉ tay vào chiếc máy tính 
trong phòng.

00:00:45.416 --> 00:00:48.313
"Hắn có phát hiện nếu tôi nói dối không?"

00:00:49.433 --> 00:00:53.795
Vâng, ông quản lý này đang ngoại tình
với cô tiếp tân.

00:00:53.819 --> 00:00:54.931
( Cười)

00:00:54.955 --> 00:00:56.721
Và tôi vẫn chỉ là một đứa oắt con.

00:00:57.267 --> 00:00:59.286
nên tôi nói thầm lại với anh ta,

00:00:59.310 --> 00:01:02.934
" Có chứ, nó biết khi nào 
ông nói dối đấy."

00:01:02.958 --> 00:01:04.764
(Cười)

00:01:04.788 --> 00:01:07.711
Vâng, tôi cười nhưng thực ra
là cười bản thân.

00:01:07.735 --> 00:01:11.003
Ngày nay, có những hệ thống máy tính

00:01:11.027 --> 00:01:14.575
có thể nhận diện trạng thái cảm xúc, 
ngay cả việc nói dối

00:01:14.599 --> 00:01:16.643
thông qua phân tích nhân diện.

00:01:17.068 --> 00:01:21.221
Các nhà quảng cáo và thậm chí cả 
chính quyền rất hứng thú với điều này.

00:01:22.139 --> 00:01:24.001
Tôi đã trở thành 1 lập trình viên

00:01:24.025 --> 00:01:27.138
vì tôi từng là đứa trẻ say mê Toán và 
Khoa học.

00:01:27.762 --> 00:01:30.870
Nhưng khoảng thời gian đó, tôi cũng học 
về vũ khí hạt nhân.

00:01:30.894 --> 00:01:33.846
và tôi trở nên rất quan ngại về vấn đề 
đạo đức của khoa học.

00:01:33.870 --> 00:01:35.074
Tôi đã rất bối rối.

00:01:35.098 --> 00:01:37.739
Tuy nhiên, do hoàn cảnh gia đình,

00:01:37.763 --> 00:01:41.061
tôi cần phải bắt đầu làm việc 
càng sớm càng tốt.

00:01:41.085 --> 00:01:44.384
Vì vậy nên tôi nói với bản thân,
này, hãy chọn một ngành kỹ thuật

00:01:44.408 --> 00:01:46.204
giúp tôi có thể dễ dàng kiếm việc

00:01:46.228 --> 00:01:50.246
mà lại không phải quan tâm đến những 
câu hỏi đạo đức phiền phức.

00:01:50.842 --> 00:01:52.371
Vì vậy nên tôi chọn máy tính.

00:01:52.395 --> 00:01:53.499
(Cười lớn)

00:01:53.523 --> 00:01:56.933
Vậy đấy! haha
Tôi cười vì chính mình!

00:01:56.957 --> 00:01:59.711
Ngày nay, các nhà khoa học máy tính
xây dựng hệ điều hành

00:01:59.735 --> 00:02:03.944
có thể điều khiển thứ mà một tỉ người 
xem hằng ngày.

00:02:04.872 --> 00:02:08.694
Họ đang phát triển những chiếc xe có thể 
tự quyết định nó sẽ cán qua ai.

00:02:09.527 --> 00:02:12.740
Họ thậm chí còn đang tạo ra nhiều 
máy móc, vũ khí,

00:02:12.764 --> 00:02:15.049
có thể tiêu diệt loài người 
trong chiến tranh.

00:02:15.073 --> 00:02:17.844
Chung quy lại đều liên quan tới đạo đức

00:02:19.003 --> 00:02:21.061
Trí tuệ nhân tạo là đây.

00:02:21.643 --> 00:02:25.117
Ta không chỉ sử dụng những thuật toán để 
đưa ra mọi quyết định

00:02:25.141 --> 00:02:27.027
mà còn cả những chuyện chưa từng xảy ra

00:02:27.051 --> 00:02:32.223
Ta đưa cho máy móc những câu hỏi không có
một đáp án đúng nào cả,

00:02:32.247 --> 00:02:33.449
những câu hỏi chủ quan

00:02:33.473 --> 00:02:35.798
những câu hỏi mở và mang tính giả định.

00:02:35.822 --> 00:02:37.580
Chúng ta hỏi những câu hỏi như,

00:02:37.604 --> 00:02:39.254
"Công ty nên thuê ai?"

00:02:39.916 --> 00:02:42.675
"Những gì bạn nên được biết từ bạn bè?"

00:02:42.699 --> 00:02:44.965
"Phạm nhân nào có khả năng tái phạm cao?"

00:02:45.334 --> 00:02:48.388
"Dòng tin hay bộ phim nào nên được 
đề xuất cho mọi người?"

00:02:48.412 --> 00:02:51.784
Nhìn xem, đúng, chúng ta đã sử dụng 
máy tính một thời gian dài,

00:02:51.808 --> 00:02:53.325
nhưng lần này thì khác.

00:02:53.349 --> 00:02:55.416
Đây là một bước ngoặt lịch sử,

00:02:55.440 --> 00:03:00.777
vì ta không thể trông cậy vào sự tính 
toán cho các quyết định chủ quan thế này

00:03:00.801 --> 00:03:06.221
như cái cách chúng ta dựa vào nó 
để lái máy bay, xây cầu,

00:03:06.245 --> 00:03:07.504
để đi lên mặt trăng.

00:03:08.269 --> 00:03:11.528
Máy bay liệu có an toàn hơn? 
Cây cầu có lắc lư và sập không?

00:03:11.552 --> 00:03:16.050
Thế đấy, chúng ta đều có một chuẩn mực 
thống nhất và khá rõ ràng,

00:03:16.074 --> 00:03:18.313
và ta có những quy luật của tự nhiên 
hướng dẫn.

00:03:18.337 --> 00:03:21.731
Chúng ta không hề có những điểm tựa hay 
tiêu chuẩn như vậy

00:03:21.755 --> 00:03:25.718
cho các quyết định về những vấn đề 
phức tạp của con người.

00:03:25.742 --> 00:03:29.979
Để làm vấn đề phức tạp hơn, phần mềm 
của ta ngày càng trở nên hùng mạnh,

00:03:30.003 --> 00:03:33.776
nhưng nó đồng thời trở nên khó hiểu
và phức tạp hơn.

00:03:34.362 --> 00:03:36.402
Gần đây, trong thập kỷ gần đây,

00:03:36.426 --> 00:03:39.155
các thuật toán phức tạp đã đạt được 
những bước tiến lớn.

00:03:39.179 --> 00:03:41.169
Chúng có thể nhận diện khuôn mặt người.

00:03:41.805 --> 00:03:43.860
Chúng có thể giải mã được chữ viết tay.

00:03:44.256 --> 00:03:46.322
Chúng có thể nhận biết thẻ tín dụng giả

00:03:46.346 --> 00:03:47.535
và chặn tin rác

00:03:47.559 --> 00:03:49.596
và chúng có thể phiên dịch ngôn ngữ.

00:03:49.620 --> 00:03:52.194
Chúng có thể phát hiện khối u trong 
phim chụp y khoa.

00:03:52.218 --> 00:03:54.423
Chúng đánh bại con người 
trong cờ vua và Go.

00:03:55.084 --> 00:03:59.588
Đa phần những tiến bộ này đến từ 
phương pháp "máy tính tự học"

00:03:59.995 --> 00:04:03.182
Máy tính tự học khác với lập trình 
truyền thống,

00:04:03.206 --> 00:04:06.791
ở chỗ bạn đưa ra những hướng dẫn 
cụ thể, chính xác, kỹ lưỡng cho máy tính.

00:04:07.198 --> 00:04:11.380
Đúng hơn là bạn cho một đống dữ liệu 
vào hệ thống,

00:04:11.404 --> 00:04:13.060
bao gồm dữ liệu chưa được 
sắp xếp,

00:04:13.084 --> 00:04:15.362
như loại chúng ta tạo ra trong thế giới số

00:04:15.386 --> 00:04:18.116
Và hệ thống học bằng cách lướt qua 
các dữ liệu này.

00:04:18.489 --> 00:04:20.015
Và quan trọng hơn,

00:04:20.039 --> 00:04:24.419
những hệ thống này không hoạt động dựa 
trên logic một-câu-trả-lời-duy-nhất.

00:04:24.443 --> 00:04:27.402
Chúng không cho ra câu trả lời đơn giản mà
có tính xác suất hơn

00:04:27.426 --> 00:04:30.909
"Cái này có nhiều khả năng là cái bạn 
đang muốn tìm."

00:04:31.843 --> 00:04:34.913
Lợi thế ở đây là: biện pháp này 
rất hiệu quả.

00:04:34.937 --> 00:04:37.013
Trưởng hệ thống Al của Google gọi nó là,

00:04:37.037 --> 00:04:39.234
"sự hiệu quả bất hợp lý của dữ liệu."

00:04:39.611 --> 00:04:40.964
Bất lợi ở đây là,

00:04:41.558 --> 00:04:44.629
ta không thật sự hiểu cái mà hệ thống 
học được.

00:04:44.653 --> 00:04:46.240
Thực tế, đó là sức mạnh của nó.

00:04:46.766 --> 00:04:50.564
Cái này khác với việc đưa ra hướng dẫn 
cho máy tính;

00:04:51.020 --> 00:04:55.084
Nó giống hơn với việc huấn luyện một loại 
chó cưng bằng máy

00:04:55.108 --> 00:04:57.479
mà chúng ta không thật sự hiểu 
hay kiểm soát.

00:04:58.182 --> 00:04:59.733
Vậy nên đó là vấn đề của ta.

00:05:00.247 --> 00:05:04.509
Nó là vấn đề khi mà hệ thống 
trí tuệ nhân tạo hiểu sai sự việc.

00:05:04.533 --> 00:05:08.073
Nó cũng là vấn đề khi nó hiểu đúng 
sự việc,

00:05:08.097 --> 00:05:11.725
bởi vì chúng ta không thể phân biệt được 
khi nó là một vấn đề chủ quan.

00:05:11.749 --> 00:05:14.088
Chúng ta không biết được vật này 
đang nghĩ gì.

00:05:15.313 --> 00:05:18.996
Thử xem xét một thuật toán thuê --

00:05:19.943 --> 00:05:24.254
một hệ thống dùng để thuê nhân viên, 
dựa vào hệ thống máy móc tự học.

00:05:24.872 --> 00:05:28.451
Một hệ thống như vậy sẽ được đào tạo 
dựa trên dự liệu của nhân viên cũ

00:05:28.475 --> 00:05:31.066
và được hướng dẫn để tìm và thuê

00:05:31.090 --> 00:05:34.128
những người tương tự với nhân viên 
xuất sắc hiện có ở công ty.

00:05:34.634 --> 00:05:35.787
Nghe có vẻ tốt đấy.

00:05:35.811 --> 00:05:37.810
Tôi từng tham dự một hội nghị

00:05:37.834 --> 00:05:40.959
bao gồm quản lý nhân sự và các lãnh đạo,

00:05:40.983 --> 00:05:42.189
những nhân vật cấp cao,

00:05:42.213 --> 00:05:43.772
dùng hệ thống như vậy khi thuê

00:05:43.796 --> 00:05:45.442
Họ cực kỳ phấn khích về việc đó.

00:05:45.466 --> 00:05:50.119
Họ nghĩ rằng hệ thống này sẽ giúp việc 
thuê người khách quan và ít thiên vị hơn,

00:05:50.143 --> 00:05:53.143
và cho phụ nữ và người thiểu số 
một cơ hội tốt hơn

00:05:53.167 --> 00:05:55.355
chống lại những người quản lý thiên vị.

00:05:55.379 --> 00:05:58.222
Đúng là người thuê người thường 
có sự thiên vị.

00:05:58.919 --> 00:06:00.104
Tôi biết vậy.

00:06:00.128 --> 00:06:03.133
Trong những việc đầu tiên của tôi với 
vai trò lập trình viên,

00:06:03.157 --> 00:06:07.025
quản lý trực tiếp của tôi thỉnh thoảng 
sẽ đến chỗ tôi

00:06:07.049 --> 00:06:10.802
rất sớm vào buổi sáng hoặc rất muộn 
vào buổi chiều,

00:06:10.826 --> 00:06:13.888
để nói, "Zeynep, cùng đi ăn trưa nào!"

00:06:14.544 --> 00:06:16.711
Tôi bị bối rối bởi giờ giấc 
thất thường.

00:06:16.735 --> 00:06:18.864
Bây giờ là 4g chiều mà ăn trưa ư?

00:06:18.888 --> 00:06:21.982
Tôi thì thiếu tiền, mà bữa trưa miễn phí. 
Cho nên tôi luôn đi

00:06:22.438 --> 00:06:24.505
Sau đó tôi nhận ra chuyện gì 
đang diễn ra.

00:06:24.529 --> 00:06:29.075
Những quản lý trực tiếp của tôi chưa hề 
thông báo với cấp trên

00:06:29.099 --> 00:06:32.212
rằng lập trình viên họ thuê cho việc 
quan trọng là một thiếu nữ

00:06:32.236 --> 00:06:36.166
mặc quần jeans và đi giày thể thao đi làm.

00:06:36.994 --> 00:06:39.196
Tôi làm tốt việc, chỉ ăn mặc không đúng

00:06:39.220 --> 00:06:40.919
và sai độ tuổi và giới tính.

00:06:40.943 --> 00:06:44.289
Cho nên việc tuyển chọn không dựa theo 
giới tính và sắc tộc

00:06:44.313 --> 00:06:46.178
rõ ràng tốt cho tôi.

00:06:46.851 --> 00:06:50.192
Nhưng với những hệ thống này, nó 
phức tạp hơn, và đây là lý do:

00:06:50.788 --> 00:06:56.579
Bây giờ, hệ thống tính toán có thể đưa ra 
đủ mọi loại kết luận vể bạn

00:06:56.603 --> 00:06:58.475
dựa trên những vết tích số của bạn,

00:06:58.499 --> 00:07:00.832
ngay cả khi bạn không hề tiết lộ 
những việc đó.

00:07:01.326 --> 00:07:04.253
Chúng có thể đưa ra kết luận về xu hướng 
tình dục của bạn,

00:07:04.814 --> 00:07:06.120
tính cách bạn,

00:07:06.679 --> 00:07:08.052
quan điểm chính trị của bạn.

00:07:08.650 --> 00:07:12.335
Chúng có sức mạnh dự đoán với 
sự chuẩn xác cao.

00:07:13.182 --> 00:07:15.760
Nhớ rằng - ngay cả những việc bạn 
không hề tiết lộ.

00:07:15.784 --> 00:07:17.375
Đây chỉ mới là việc suy luận

00:07:17.399 --> 00:07:20.660
Tôi có một người bạn thiết kế những 
hệ thống tính toán như vậy

00:07:20.684 --> 00:07:24.325
để dự đoán khả năng mắc bệnh trầm cảm 
lâm sàng hoặc hậu thai sản

00:07:24.349 --> 00:07:25.765
từ những dự liệu truyền thông xã hội.

00:07:26.496 --> 00:07:27.923
Kết quả thật đáng ấn tượng.

00:07:28.312 --> 00:07:31.669
Hệ thống của cô ấy có thể dự đoán được 
khả năng mắc trầm cảm

00:07:31.693 --> 00:07:35.596
hàng tháng trước khi các triệu chứng 
xuất hiện --

00:07:35.620 --> 00:07:36.993
hàng tháng trước.

00:07:37.017 --> 00:07:39.263
Không hề có triệu chứng, nhưng 
lại có dự đoán.

00:07:39.287 --> 00:07:44.099
Cô mong rằng nó được sử dụng cho việc 
can thiệp sớm. Tuyệt vời!

00:07:44.731 --> 00:07:46.771
Nhưng giờ đặt nó vào viễn cảnh 
tuyển chọn.

00:07:47.847 --> 00:07:50.893
Ở buổi họp quản lý nhân sự này,

00:07:50.917 --> 00:07:55.626
tôi tiếp cận một quản lý cấp cao của 
một công ty lớn,

00:07:55.650 --> 00:08:00.228
và nói rằng, "Này, nếu như, ngoài sự 
hiểu biết của bạn,

00:08:00.252 --> 00:08:06.801
hệ thống của bạn đang gạt bỏ người có thể 
bị trầm cảm cao trong tương lai?

00:08:07.581 --> 00:08:10.957
Hiện tại họ không hề bị trầm cảm, chỉ là 
trong tương lai có khả năng.

00:08:11.743 --> 00:08:15.149
Nếu như hệ thống loại bỏ những phụ nữ 
có khả năng mang thai

00:08:15.173 --> 00:08:17.759
trong một vài năm tới nhưng hiện 
không mang thai?

00:08:18.664 --> 00:08:24.300
Nếu nó chọn những người có tính hung hăng 
vì đó là bản chất làm việc ở đây?"

00:08:24.993 --> 00:08:27.684
Bạn không thể thấy điều này qua việc 
xem tỉ lệ giới tính

00:08:27.708 --> 00:08:29.210
Điều đó có thể được 
cân bằng.

00:08:29.234 --> 00:08:32.791
Và vì đây là máy móc tự học, chứ 
không phải mã hóa truyền thống,

00:08:32.815 --> 00:08:37.722
không hề có một biến số nào có tên 
"có khả năng trầm cảm cao",

00:08:37.746 --> 00:08:39.579
"có khả năng mang thai cao",

00:08:39.603 --> 00:08:41.337
"tính cách hung hăng".

00:08:41.815 --> 00:08:45.494
Bạn không chỉ không biết hệ thống của bạn 
lựa chọn dựa trên tiêu chí gì,

00:08:45.518 --> 00:08:47.841
bạn còn không biết phải bắt đầu 
tìm từ đâu.

00:08:47.865 --> 00:08:49.111
Nó là một hộp đen.

00:08:49.135 --> 00:08:51.942
Nó có khả năng tiên đoán, nhưng bạn 
không hiểu nó.

00:08:52.306 --> 00:08:54.675
Tôi hỏi cô, "Bạn có chốt an toàn nào

00:08:54.699 --> 00:08:58.372
để đảm bảo rằng hộp đen của bạn 
không làm gì mờ ám?"

00:09:00.683 --> 00:09:04.561
Cô ấy nhìn tôi như thể tôi vừa đạp lên 
10 cái đuôi chó.

00:09:04.585 --> 00:09:05.833
(Cười lớn)

00:09:05.857 --> 00:09:07.898
Cô nhìn tôi chằm chằm và nói,

00:09:08.376 --> 00:09:12.709
"Tôi không muốn nghe thêm một từ nào 
về vấn đề này nữa."

00:09:13.278 --> 00:09:15.312
Và cô ấy bỏ đi.

00:09:15.884 --> 00:09:17.370
Cho bạn biết- cô ấy không thô lỗ

00:09:17.394 --> 00:09:23.702
Rõ ràng rằng: điều tôi không biết không phải 
là vấn đề của tôi, đi đi, ánh nhìn chết người.

00:09:23.726 --> 00:09:24.972
(Cười lớn)

00:09:25.682 --> 00:09:29.521
Một hệ thống như vậy có thể ít thiên vị hơn

00:09:29.545 --> 00:09:31.648
những người quản lý theo cách nào đó.

00:09:31.672 --> 00:09:33.818
Và nó có khả năng ra quyết định tài chính.

00:09:34.393 --> 00:09:36.043
Nhưng nó cũng có thể dẫn đến

00:09:36.067 --> 00:09:40.815
một thị trường việc làm ổn định nhưng lén lút cô lập

00:09:40.839 --> 00:09:43.132
những người có khả năng trầm cảm cao.

00:09:43.573 --> 00:09:46.169
Liệu đây có phải là xã hội mà chúng ta muốn gầy dựng,

00:09:46.193 --> 00:09:48.478
khi mà chúng ta còn thậm chí không biết chúng ta làm vậy,

00:09:48.502 --> 00:09:52.466
bởi vì chúng ta phó thác việc ra quyết định cho những cỗ máy mà chính chúng ta cũng không hiểu rõ?

00:09:53.085 --> 00:09:54.543
Một vấn đề khác là:

00:09:55.134 --> 00:09:59.586
những hệ thống này được huấn luyện dựa trên những dữ liệu lấy từ các hành động của chúng ta,

00:09:59.610 --> 00:10:01.426
dấu ấn của con người.

00:10:02.008 --> 00:10:05.816
Chúng có thể phản ánh những thiên vị của chúng ta,

00:10:05.840 --> 00:10:09.433
và những hệ thống này có thể bắt nhịp những thiên vị của chúng ta

00:10:09.457 --> 00:10:10.770
và phóng đại chúng

00:10:10.794 --> 00:10:12.212
và thể hiện chúng lại cho chúng ta,

00:10:12.236 --> 00:10:13.698
trong khi chúng ta lại tự bảo bản thân,

00:10:13.722 --> 00:10:16.839
"Chúng ta đang tính toán một cách trung lập, khách quan."

00:10:18.134 --> 00:10:20.811
Các nhà nghiên cứu tìm ra rằng trên Google,

00:10:21.954 --> 00:10:27.267
phụ nữ ít được cho thấy những thông cáo việc làm lương cao hơn đàn ông.

00:10:28.283 --> 00:10:30.813
Và các tìm kiếm tên của người Mỹ gốc Phi

00:10:30.837 --> 00:10:35.543
sẽ dễ dẫn đến những cảnh báo tiền án tội phạm hơn,

00:10:35.567 --> 00:10:37.134
ngay cả khi người đó không hề phạm tội.

00:10:38.513 --> 00:10:42.062
Những thiên vị tiềm ẩn và những thuật toán hộp-đen như vậy

00:10:42.086 --> 00:10:46.059
được các nhà nghiên cứu thỉnh thoảng tìm ra nhưng thỉnh thoảng chúng ta không hề biết,

00:10:46.083 --> 00:10:48.744
có thể có các hậu quả nặng nề.

00:10:49.778 --> 00:10:53.937
Ở Wisconsin, một bị cáo bị kết án sáu năm tù

00:10:53.961 --> 00:10:55.316
vì trốn tránh cảnh sát.

00:10:56.644 --> 00:10:57.830
Bạn có thể không biết rằng,

00:10:57.854 --> 00:11:01.852
các thuật toán ngày càng được sử dụng trong việc ân xá và kết án nhiều hơn.

00:11:01.876 --> 00:11:04.831
Ông ta muốn biết: Kết quả này được tính toán như thế nào?

00:11:05.615 --> 00:11:07.280
Nó là một hộp đen thương hiệu.

00:11:07.304 --> 00:11:11.509
Công ty từ chối để cho thuật toán của mình bị chất vấn ở các phiên tòa mở.

00:11:12.216 --> 00:11:17.748
Nhưng ProPublica, một tổ chức điều tra phi lợi nhuận, đã kiểm tra chính thuật toán

00:11:17.772 --> 00:11:19.788
họ dùng để tra cứu các dữ liệu công cộng,

00:11:19.812 --> 00:11:22.128
và nhận ra rằng các kết quả của chúng rất thiên vị

00:11:22.152 --> 00:11:25.781
và khả năng dự đoán của nó rất ảm đạm, chẳng hơn đoán mò bao nhiêu,

00:11:25.805 --> 00:11:30.221
và nó kết luận sai các bị cáo da đen có thể thành phạm nhân tương lai

00:11:30.245 --> 00:11:34.140
nhiều gấp đôi bị cáo da trắng.

00:11:35.711 --> 00:11:37.275
Thử nhìn vào vụ án này:

00:11:37.923 --> 00:11:41.775
Người phụ nữ này đón chị đỡ đầu của bà trễ

00:11:41.799 --> 00:11:43.874
từ một trường ở quận Broward, Florida,

00:11:44.577 --> 00:11:46.933
chạy xuống phố với một người bạn của bà.

00:11:46.957 --> 00:11:51.056
Họ nhìn thấy một chiếc xe đạp trẻ em không khóa và một chiếc xe máy trên hiên nhà

00:11:51.080 --> 00:11:52.712
và họ nghịch ngợm nhảy lên nó.

00:11:52.736 --> 00:11:55.335
Trong khi họ đang tăng tốc, một người phụ nữ chạy ra và la lên rằng,

00:11:55.359 --> 00:11:57.564
"Hey, đó là xe đạp của con tôi!"

00:11:57.588 --> 00:12:00.882
Họ quăng chiếc xe lại, chạy đi, nhưng họ bị bắt.

00:12:00.906 --> 00:12:04.543
Cô sai, cô ngu ngốc, nhưng cô vẫn chỉ mới 18 tuổi.

00:12:04.567 --> 00:12:07.111
Cô đã phạm một vài tội vị thành niên.

00:12:07.628 --> 00:12:12.813
Trong khi đó, một người đàn ông bị bắt vì trộm đồ ở Home Depot --

00:12:12.837 --> 00:12:15.761
một mớ đồ trị giá $85, một tội ăn cắp vặt.

00:12:16.586 --> 00:12:21.145
Nhưng ông có hai tiền án cướp có vũ khí.

00:12:21.775 --> 00:12:25.257
Nhưng thuật toán lại chấm điểm cô ấy có khả năng phạm tội cao hơn ông ta.

00:12:26.566 --> 00:12:30.440
Hai năm sau, ProPublica nhận thấy rằng cô ấy không hề tái phạm.

00:12:30.464 --> 00:12:33.014
Nhưng cô ấy chỉ khó kiếm được việc làm với tiền án như v6a5y.

00:12:33.038 --> 00:12:35.114
Ngược lại, ông ta tái phậm

00:12:35.138 --> 00:12:38.974
và hiện đang bị ở tù tám năm cho tội ác sau này.

00:12:39.908 --> 00:12:43.277
Rõ ràng, chúng ta cần kiểm tra các hộp đen của chúng ta

00:12:43.301 --> 00:12:45.916
và không để chúng có những sức mạnh không kiểm soát này.

00:12:45.940 --> 00:12:48.819
(Vỗ tay)

00:12:49.907 --> 00:12:54.149
Kiểm tra rất tuyệt vời và quan trọng, nhưng chúng không giải quyết hết các vấn đề của chúng ta.

00:12:54.173 --> 00:12:56.921
Ví dụ như thuật toán trang chủ hùng mạnh của Facebook --

00:12:56.945 --> 00:13:01.788
bạn biết đấy, cái đánh giá mọi thứ và quyết định sẽ cho bạn xem cái gì

00:13:01.812 --> 00:13:04.096
từ bạn bè và những trang bạn theo dõi.

00:13:04.718 --> 00:13:06.993
Liệu bạn có nên được cho xem thêm một bức ảnh trẻ con nữa?

00:13:07.017 --> 00:13:08.213
(Cười lớn)

00:13:08.237 --> 00:13:10.833
Một thông điệp u tối từ một người quen?

00:13:11.269 --> 00:13:13.125
Một mẩu tin quan trọng nhưng phức tạp?

00:13:13.149 --> 00:13:14.631
Không hề có câu trả lời đúng nào.

00:13:14.655 --> 00:13:17.314
Facebook tối đa hóa các tương tác trên trang chủ:

00:13:17.338 --> 00:13:18.753
thích, chia sẻ, bình luận.

00:13:19.988 --> 00:13:22.684
Vào tháng 8/2014,

00:13:22.708 --> 00:13:25.370
biểu tình diễn ra ở Ferguson, Missouri,

00:13:25.394 --> 00:13:29.811
sau vụ thảm sát một thiếu niên Mỹ Phi bởi một cảnh sát da trắng,

00:13:29.835 --> 00:13:31.405
dưới điều kiện mờ ám.

00:13:31.794 --> 00:13:33.801
Tin tức về các buổi biểu tình tràn ngập

00:13:33.825 --> 00:13:36.510
trên trang chủ Twitter không được thanh lọc bởi thuật toán,

00:13:36.534 --> 00:13:38.484
nhưng không hề hiện ra trên Facebook của tôi.

00:13:39.002 --> 00:13:40.736
Liệu đó có phải do các bạn trên Facebook của tôi?

00:13:40.760 --> 00:13:42.792
Tôi tắt thuật toán của Facebook,

00:13:43.292 --> 00:13:46.140
và rất khó để làm vậy vì Facebook luôn muốn bạn

00:13:46.164 --> 00:13:48.200
ở dưới sự kiểm soát của thuật toán,

00:13:48.224 --> 00:13:50.462
và thấy rằng bạn bè tôi đang nói về vấn đề đó.

00:13:50.486 --> 00:13:52.995
Chỉ là do thuật toán không cho tôi thấy điều đó.

00:13:53.019 --> 00:13:56.061
Tôi đi tìm hiểu và phát hiện ra rằng đây là một vấn đề phổ biến.

00:13:56.085 --> 00:13:59.898
Câu chuyện ở Ferguson không hề thân thiện với thuật toán.

00:13:59.922 --> 00:14:01.093
Nó không được "yêu thích".

00:14:01.117 --> 00:14:02.669
Ai sẽ bấm "thích"?

00:14:03.320 --> 00:14:05.526
Nó không hề đơn giản để bình luận.

00:14:05.550 --> 00:14:06.921
Thiếu các lượt yêu thích và bình luận,

00:14:06.945 --> 00:14:10.237
thuật toán lại hiển thị nó cho càng ít người,

00:14:10.261 --> 00:14:11.803
cho nên chúng ta không hề thấy nó.

00:14:12.766 --> 00:14:13.994
Thay vào đó, trong tuần đó,

00:14:14.018 --> 00:14:16.316
Thuật toán của Facebook lại làm nổi bật mẩu tin

00:14:16.340 --> 00:14:18.566
về ALS Thử Thách Chậu Đá.

00:14:18.590 --> 00:14:22.332
Một động cơ cao cả; đổ chậu nước đá, quyên góp từ thiện, tốt thôi.

00:14:22.356 --> 00:14:24.260
Nhưng nó rất được thuật toán yêu thích.

00:14:25.039 --> 00:14:27.652
Cỗ máy đưa ra quyết định này cho chúng ta.

00:14:27.676 --> 00:14:31.173
Một cuộc hội thoại quan trọng nhưng khó khăn

00:14:31.197 --> 00:14:32.752
có thể vừa bị giết chết,

00:14:32.776 --> 00:14:35.472
nếu như Facebook là cổng thông tin duy nhất.

00:14:35.937 --> 00:14:39.734
Cuối cùng, các hệ thống này có thể phạm lỗi

00:14:39.758 --> 00:14:42.494
theo nhiều cách không giống gì hệ thống con người.

00:14:42.518 --> 00:14:45.440
Quý vị còn nhớ Watson, hệ thống máy móc thông minh của IBM

00:14:45.464 --> 00:14:48.592
quét sạch các người thi con người trong trò Jeopardy?

00:14:48.951 --> 00:14:50.379
Nó là một người chơi tuyệt vời.

00:14:50.403 --> 00:14:53.972
Nhưng ở màn cuối của Jeopardy, khi được hỏi:

00:14:54.479 --> 00:14:57.411
"Sân bay lớn nhất của thành phố này được đặt tên theo một anh hùng Thế Chiến II,

00:14:57.435 --> 00:14:59.687
sân bay lớn nhì được đặt tên theo một trận đánh trong Thế Chiến II."

00:14:59.711 --> 00:15:01.089
(Nhạc nền Jeopardy)

00:15:01.402 --> 00:15:02.584
Chicago.

00:15:02.608 --> 00:15:03.978
Hai người chơi con người đoán đúng.

00:15:04.517 --> 00:15:08.865
Ngược lại, Watson lại trả lời "Toronto" --

00:15:08.889 --> 00:15:10.707
cho một phân mục thành phố Mỹ!

00:15:11.416 --> 00:15:14.317
Một hệ thống ấn tượng phạm một lỗi

00:15:14.341 --> 00:15:17.992
mà không một con người nào sẽ mắc phải, ngay cả một học sinh cấp 2.

00:15:18.643 --> 00:15:21.752
Cỗ máy thông minh của chúng ta đã thất bại

00:15:21.776 --> 00:15:24.876
theo nhiều cách không hề giống con người,

00:15:24.900 --> 00:15:27.850
theo những cách chúng ta không ngờ tới và không chuẩn bị cho.

00:15:27.874 --> 00:15:31.512
Sẽ thật tệ nếu như một người không được nhận vào một công việc mà họ đủ tiêu chuẩn,

00:15:31.536 --> 00:15:35.263
nhưng nó sẽ còn tệ gấp ba lần nếu như lý do là vì sự tắc nghẽn thông tin

00:15:35.287 --> 00:15:36.719
trong một thủ tục phụ nào đó.

00:15:36.743 --> 00:15:38.322
(Cười lớn)

00:15:38.346 --> 00:15:41.132
Vào tháng 5/2010,

00:15:41.156 --> 00:15:45.200
một khủng hoảng nhỏ ở Wall Street xảy ra do hệ thống phản hồi

00:15:45.224 --> 00:15:48.252
trong thuật toán "bán" của Wall Street

00:15:48.276 --> 00:15:52.460
làm bốc hơi một trị giá 1000 tỉ đô trong 36 phút.

00:15:53.542 --> 00:15:55.729
Tôi không hề muốn nghĩ đến "lỗi" đó là gì

00:15:55.753 --> 00:15:59.342
khi nói đến các vũ khí tự phát nguy hiểm.

00:16:01.714 --> 00:16:05.504
Cho nên vâng, con người luôn thiên vị.

00:16:05.528 --> 00:16:07.704
Các người đưa ra quyết định và những người gác cổng,

00:16:07.728 --> 00:16:11.221
trong tòa án, trên báo chí, trong chiến tranh,...

00:16:11.245 --> 00:16:14.283
họ phạm sai lầm; nhưng đó chính xác là điều tôi muốn nói.

00:16:14.307 --> 00:16:17.828
Chúng ta không thể trốn tránh những câu hỏi khó.

00:16:18.416 --> 00:16:21.932
Chúng ta không thể phó thác trách nhiệm của chúng ta cho máy móc.

00:16:22.496 --> 00:16:26.704
(Vỗ tay)

00:16:28.909 --> 00:16:33.356
Trí tuệ nhân tạo không cho chúng ta một thẻ "Trốn tránh đạo đức miễn phí"

00:16:34.562 --> 00:16:37.943
Nhà khoa học dữ liệu Fred Benenson gọi đây là tẩy rửa toán học.

00:16:37.967 --> 00:16:39.356
Chúng ta cần điều ngược lại.

00:16:39.380 --> 00:16:44.768
Chúng ta cần nuôi dưỡng các hoài nghi về các thuật toán, các khó khăn và điều tra.

00:16:45.200 --> 00:16:48.398
Chúng ta cần đảm bảo tính trung thực của các thuật toán,

00:16:48.422 --> 00:16:50.867
sự rõ ràng ý nghĩa và qua kiểm tra.

00:16:51.200 --> 00:16:54.434
Chúng ta cần chấp nhận rằng khi đem toán học và tính toán

00:16:54.458 --> 00:16:57.428
vào các vấn đề phức tạp, nhiều tầng giá trị của con người

00:16:57.452 --> 00:16:59.836
không hề đem đến tính khách quan;

00:16:59.860 --> 00:17:03.493
mà ngược lại, sự phức tạp của các vấn đề của con người xâm lấn các thuật toán.

00:17:03.968 --> 00:17:07.455
Vâng, chúng ta có thể và nên sử dụng tính toán

00:17:07.479 --> 00:17:09.493
để giúp chúng ta đưa ra các quyết định đúng đắn hơn.

00:17:09.517 --> 00:17:14.849
Nhưng chúng ta cần chịu trách nhiệm cho các quyết định mang tính đạo đức của chúng ta,

00:17:14.873 --> 00:17:17.691
và sử dụng thuật toán nội trong khuôn khổ đó,

00:17:17.715 --> 00:17:22.650
chứ không phải như một phương tiện để từ bỏ và phó thác trách nhiệm của chúng ta

00:17:22.674 --> 00:17:25.128
cho người khác giữa người với người.

00:17:25.627 --> 00:17:28.236
Máy móc thông minh tồn tại ở đây.

00:17:28.260 --> 00:17:31.681
Điều đó có nghĩa là chúng ta cần .... hơn

00:17:31.705 --> 00:17:33.852
các giá trị nhân bản và đạo đức nhân văn.

00:17:33.876 --> 00:17:35.030
Xin cám ơn.

00:17:35.054 --> 00:17:40.074
(Vỗ tay)

