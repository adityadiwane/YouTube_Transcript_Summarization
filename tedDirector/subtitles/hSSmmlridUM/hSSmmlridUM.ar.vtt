WEBVTT
Kind: captions
Language: ar

00:00:00.000 --> 00:00:07.000
المترجم: Mutaz Salloum
المدقّق: Ralah Haddad

00:00:12.559 --> 00:00:16.681
لقد بدأت عملي الأول كمبرمجة كمبيوتر

00:00:16.705 --> 00:00:18.661
في أول سنة جامعة لي--

00:00:18.685 --> 00:00:20.192
بشكل أساسي، كمراهقة.

00:00:20.709 --> 00:00:22.441
بعدما بدأت العمل بوقت قصير،

00:00:22.465 --> 00:00:24.075
بكتابة البرمجيات في الشركة،

00:00:24.619 --> 00:00:28.254
آتى مدير في الشركة إلى حيث كنت أعمل،

00:00:28.278 --> 00:00:29.546
و همس لي،

00:00:30.049 --> 00:00:32.910
"هل يستطيع أن يُخبر فيما إذا كنتُ أكذب؟"

00:00:33.626 --> 00:00:35.703
لم يكن هناك أحد آخر في الغرفة.

00:00:36.852 --> 00:00:40.986
"من الذي سيُخبرإذا كنتَ
تكذب؟ ولماذا نحن نهمس؟"

00:00:42.086 --> 00:00:45.193
أشار المدير إلى الكمبيوترالموجود في الغرفة.

00:00:45.217 --> 00:00:48.313
"هل يستطيع أن يُخبر فيما إذا كنتُ أكذب؟"

00:00:49.433 --> 00:00:53.795
حسناً، المدير كان على علاقة
مع موظفة الاستقبال.

00:00:53.819 --> 00:00:54.931
(ضحك)

00:00:54.955 --> 00:00:56.721
وكنت لا أزال مراهقة.

00:00:57.267 --> 00:00:59.286
ولذالك همست له بصوت مرتفع،

00:00:59.310 --> 00:01:02.934
"نعم الكمبيوتر يستطيع أن
يُخبر فيما إذا كنتَ تكذب."

00:01:02.958 --> 00:01:04.764
(ضحك)

00:01:04.788 --> 00:01:07.711
حسنا، لقد ضحكت،
ولكن في الحقيقة ضحكت على نفسي.

00:01:07.735 --> 00:01:11.003
هذه الأيام، يوجد هنالك أنظمة حسابية

00:01:11.027 --> 00:01:14.575
من الممكن أن نعمل عليها
على الحالات العاطفية وحتى الكذب

00:01:14.599 --> 00:01:16.643
من معالجة وجوه الناس.

00:01:17.068 --> 00:01:21.221
العاملون في مجال الإعلان
وحتى الحكومات مهتمون جداً.

00:01:22.139 --> 00:01:24.001
لقد أصبحت مبرمجة كمبيوتر

00:01:24.025 --> 00:01:27.138
لأنني كنت واحدة من أولئك
الأطفال المحبين للرياضيات والعلوم.

00:01:27.762 --> 00:01:30.870
ولكن في مكان ما من هذا
الطريق تعلمت عن الأسلحة النووية،

00:01:30.894 --> 00:01:33.846
وأنا حقاً قلقة حول أخلاقيات العلم.

00:01:33.870 --> 00:01:35.074
كنت مضطربة.

00:01:35.098 --> 00:01:37.739
على أية حال، بسبب ظروف العائلة،

00:01:37.763 --> 00:01:41.061
أنا أيضاً بحاجة أن أبدأ
العمل بأسرع ما يمكن.

00:01:41.085 --> 00:01:44.384
لذلك فكرت بنفسي، مهلاً،
أدخلي في المجال التقني

00:01:44.408 --> 00:01:46.204
حيث أستطيع أن أحصل على عمل بسهولة

00:01:46.228 --> 00:01:50.246
وحيث ليس علي أن أتعامل
مع أسئلة أخلاقية مزعجة.

00:01:50.842 --> 00:01:52.371
لذلك اخترت الحواسيب.

00:01:52.395 --> 00:01:53.499
(ضحك)

00:01:53.523 --> 00:01:56.933
حسناً، ها، ها، ها!
كل الضحك علي.

00:01:56.957 --> 00:01:59.711
هذه الأيام، علماء الحاسوب 
يقومون بصياغة البرامج

00:01:59.735 --> 00:02:03.944
والتي تتحكم بما يستطيع أن
يشاهده مليار شخص كل يوم.

00:02:04.872 --> 00:02:08.694
إنهم يطورون السيارات التي
ممكن أن تقرر مَن تجاوز السرعة.

00:02:09.527 --> 00:02:12.740
إنهم حتى يبنون الألات و الأسلحة،

00:02:12.764 --> 00:02:15.049
التي يُمكن أن تقتل الإنسان في الحرب.

00:02:15.073 --> 00:02:17.844
إنها الأخلاق دائماً في النطاق.

00:02:19.003 --> 00:02:21.061
ذكاء الألة يكون هنا.

00:02:21.603 --> 00:02:25.077
نحن نستخدم الألة لنتخذ كل أنواع القرارات،

00:02:25.141 --> 00:02:27.027
ولكن ايضاً الأنواع الجديدة من القرارات.

00:02:27.051 --> 00:02:32.223
نحن نسأل الحاسب أسئلة 
ليس له إجابات صحيحة منفردة

00:02:32.247 --> 00:02:33.449
والتي تكون غير موضوعية

00:02:33.473 --> 00:02:35.798
مفتوحة وذات قيمة.

00:02:35.822 --> 00:02:37.580
نحن نسأل أسئلة مثل،

00:02:37.604 --> 00:02:39.254
"من الذي يجب على الشركة توظيفه؟"

00:02:39.916 --> 00:02:42.675
"أي تحديث ومن أي صديق 
يجب أن تُشاهد؟"

00:02:42.699 --> 00:02:44.965
"أي إنتهاك من المرجح أن يُعاد إدانته؟"

00:02:45.334 --> 00:02:48.388
"أي الأخبار أو الأفلام يجب
أن يوصى بها إلى الناس؟"

00:02:48.412 --> 00:02:51.784
انظر، نعم، نحن نستخدم الحاسوب منذ فترة،

00:02:51.808 --> 00:02:53.325
ولكن هذا مُختلف.

00:02:53.349 --> 00:02:55.416
هذا تطور تاريخي،

00:02:55.440 --> 00:03:00.777
لأننا لا نستطيع أن نُركّز الحساب
من أجل هكذا قرارات شخصية

00:03:00.801 --> 00:03:06.221
الطريقة التي نستطيع أن نُركّز الحساب
لأجل تحليق الطائرات، بناء الجسور،

00:03:06.245 --> 00:03:07.504
الذهاب إلى القمر

00:03:08.269 --> 00:03:11.528
هل الطائرات أكثر أماناً؟
هل الجسر تأرجح وانهار؟

00:03:11.552 --> 00:03:16.050
هناك، نحن اتفقنا عليه،
معيار واضح ألى حد ما،

00:03:16.074 --> 00:03:18.313
ونحن لدينا قوانين طبيعية لتُرشِدنا.

00:03:18.337 --> 00:03:21.731
ليس لدينا هكذا مرتكز أو معيار

00:03:21.755 --> 00:03:25.718
للقرارات في العلاقات الإنسانية الفوضوية.

00:03:25.742 --> 00:03:29.979
لنجعل الأشياء أكثر تعقيداً،
برمجياتُنا أصبحت أكثر قوة،

00:03:30.003 --> 00:03:33.776
ولكنها أصبحت أيضاً أقل
شفافية وأكثر تعقيداً.

00:03:34.362 --> 00:03:36.402
مؤخراً، في العقد الماضي،

00:03:36.426 --> 00:03:39.155
الخوارزميات المعقدة
صنعت خطوات عظيمة.

00:03:39.179 --> 00:03:41.169
تستطيع أن تُميز الوجوه البشرية.

00:03:41.805 --> 00:03:43.860
تستطيع أن تحل شيفرة خط اليد.

00:03:44.256 --> 00:03:46.322
تستطيع أن تكشف تزوير البطاقة الإتمانية

00:03:46.346 --> 00:03:47.535
وتمنع البريد المزعج

00:03:47.559 --> 00:03:49.596
وتستطيع الترجمة بين اللغات.

00:03:49.620 --> 00:03:52.194
تستطيع أن تكشف الأمراض في التصوير الطبي.

00:03:52.218 --> 00:03:54.423
تستطيع أن تتغلب على الإنسان في الشطرنج.

00:03:55.084 --> 00:03:59.588
معظم هذا التقدم يأتي من اسلوب
يُدعى"تعلم الآلة."

00:03:59.995 --> 00:04:03.182
تعلم الآلة يختلف عن البرمجة التقليدية،

00:04:03.206 --> 00:04:06.791
حيث تُعطي الحاسوب تعليمات
دقيقة ومضبوطة ومُفصلة.

00:04:07.198 --> 00:04:11.380
إنه مثل أن تأخذ النظام
وتُلقمه الكثير من البيانات،

00:04:11.404 --> 00:04:13.060
بما في ذلك البيانات الغير منظمة،

00:04:13.084 --> 00:04:15.362
مثل النوع الذي أنتجناه في حياتنا الرقمية.

00:04:15.386 --> 00:04:18.116
والنظام المتعلم من خلال
الخوض بهذه البيانات.

00:04:18.489 --> 00:04:20.015
و أيضاً، بشكل حاسم،

00:04:20.039 --> 00:04:24.419
هذه الأنظمة لا تعمل تحت
منطق الإجابة الفريدة.

00:04:24.443 --> 00:04:27.402
إنها لا تُنتج إجابة بسيطة؛
إنها أكثر إحتمالية:

00:04:27.426 --> 00:04:30.909
"من المحتمل أن يكون هذا
الشيء هو ما تبحث عنه."

00:04:31.843 --> 00:04:34.913
الآن، الجزء الجيد هو:
هذه الطريقة حقاً قوية.

00:04:34.937 --> 00:04:37.013
رئيس أنظمة غوغل دعاه،

00:04:37.037 --> 00:04:39.234
"الفاعلية الغير منطقية للبيانات."

00:04:39.611 --> 00:04:40.964
الجانب السلبي هو،

00:04:41.558 --> 00:04:44.629
لا نستطيع أن
نفهم ماذا يُعلم النظام تماماً.

00:04:44.653 --> 00:04:46.240
في الحقيقة، تلك قوته.

00:04:46.766 --> 00:04:50.564
هذا بدرجة أقل مثل إعطاء
التعليمات للحاسوب؛

00:04:51.020 --> 00:04:55.084
إنه بالأكثر مثل تدريب
مخلوق آلي مغرور

00:04:55.108 --> 00:04:57.479
لا نستطيع حقاً أن نفهمه أو نتحكم به.

00:04:58.182 --> 00:04:59.733
لذلك هذه هي مُشكلتنا.

00:05:00.247 --> 00:05:04.509
إنها مشكلة عندما يصنع نظام الذكاء
الإصطناعي هذا أشياء خاطئة.

00:05:04.533 --> 00:05:08.073
إنها أيضاً مُشكلة عندما نحصل
على الأشياء الصحيحة،

00:05:08.097 --> 00:05:11.725
لأننا لا نعرف حتى متى
تكون مشكلة غير موضوعية.

00:05:11.749 --> 00:05:14.088
نحن لا نعلم ماذا يُفكر هذه الشيء.

00:05:15.313 --> 00:05:18.996
لذلك، تأمل خوارزمية التوظيف--

00:05:19.943 --> 00:05:24.254
نظام يستعمل لتوظيف الناس،
باستعمال أنظمة تعلّم الآلة.

00:05:24.872 --> 00:05:28.451
هكذا نظام قد تم تمرينه
على بيانات العاملين السابقة

00:05:28.475 --> 00:05:31.066
وأَعطي تعليمات ليجد ويوظف

00:05:31.090 --> 00:05:34.128
الناس مثل الموجودين في الشركة
من ذوي الكفاءات العالية.

00:05:34.634 --> 00:05:35.787
يبدو جيداً.

00:05:35.811 --> 00:05:37.810
حضرت إجتماعاً ذات مرة

00:05:37.834 --> 00:05:40.959
مع مدراء الموارد البشرية
والمدراء التنفيذيين،

00:05:40.983 --> 00:05:42.189
أشخاص على مستوى عال،

00:05:42.213 --> 00:05:43.772
وباستخدام هكذا أنظمة في التوظيف.

00:05:43.796 --> 00:05:45.442
كانوا متحمسين بشكل كبير.

00:05:45.466 --> 00:05:50.119
اعتقدوا أن هذا سيجعل التوظيف
أكثر موضوعية وأقل تحيز،

00:05:50.143 --> 00:05:53.143
وإعطاء النساء والأقليات محاولة أفضل

00:05:53.167 --> 00:05:55.355
ضد تحيز مدراء الموارد البشرية.

00:05:55.379 --> 00:05:58.222
انظر-- التوظيف البشري متحيز.

00:05:58.919 --> 00:06:00.104
أنا أعلم.

00:06:00.128 --> 00:06:03.133
أعني، في أحد أعمالي المبكرة كمبرمجة،

00:06:03.157 --> 00:06:07.025
مديرتي المباشرة كانت تأتي أحياناً إلي
حيث كُنت أعمل

00:06:07.049 --> 00:06:10.802
باكراً في الصباح أو متأخرة بعد الظهر،

00:06:10.826 --> 00:06:13.888
وكانت تقول، "زينب، دعينا نذهب ألى الغداء!"

00:06:14.544 --> 00:06:16.711
وأكون في حيرة من التوقيت الغريب.

00:06:16.735 --> 00:06:18.864
إنه الساعة الرابعة بعد الظهر. الغداء؟

00:06:18.888 --> 00:06:21.982
كُنت مُفلسة، وكذلك الغداء مجاني.
كنت دائماً أذهب.

00:06:22.438 --> 00:06:24.505
فيما بعد أدركت ماذا كان يحدث.

00:06:24.529 --> 00:06:29.075
مُدرائي المباشرين لم يخبروا
المدراء في المستوى الأعلى

00:06:29.099 --> 00:06:32.212
إن المبرمج الذي وظفوه في 
العمل المُهم كانت فتاة شابة

00:06:32.236 --> 00:06:36.166
والتي ترتدي الجنز والأحذية 
الرياضية في العمل.

00:06:36.994 --> 00:06:39.196
كُنت أعمل عملاً جيداً،
فقط مظهري كان خاطئاً

00:06:39.220 --> 00:06:40.919
لقد كان العمر الخطأ والجنس الخطأ.

00:06:40.943 --> 00:06:44.289
لذلك التوظيف بطريقة الجنس والعرق العمياء

00:06:44.313 --> 00:06:46.178
بالتأكيد تبدو جيدة بالنسبة لي.

00:06:46.851 --> 00:06:50.192
ولكن مع هذه الأنظمة،
إنه أكثر تعقيداً، والسبب:

00:06:50.788 --> 00:06:56.579
حالياً، الأنظمة الحسابية تستطيع أن
تستدل على كل الأشياء حولك

00:06:56.603 --> 00:06:58.475
من أجزائك الرقمية الصغيرة،

00:06:58.499 --> 00:07:00.832
حتى لو أنك لم تكشف هذه الأشياء.

00:07:01.326 --> 00:07:04.253
تستطيع أن تكشف توجهك الجنسي،

00:07:04.814 --> 00:07:06.120
ميزاتك الشخصية،

00:07:06.679 --> 00:07:08.052
ميولك السياسية.

00:07:08.650 --> 00:07:12.335
لديها قوة تنبئية بمستوى عالي من الدقة.

00:07:13.182 --> 00:07:15.760
تذّكر- حتى بالنسبة للأشياء التي لم تكشفها.

00:07:15.784 --> 00:07:17.375
هذا هو الاستدلال.

00:07:17.399 --> 00:07:20.660
لدي صديق والذي طور هكذا أنظمة حسابية

00:07:20.684 --> 00:07:24.325
ليتنبأ باحتمالية الإكتئاب المرضي أو
الإكتئاب ما بعد الولادة

00:07:24.349 --> 00:07:25.765
من بيانات وسائل الإعلام.

00:07:26.496 --> 00:07:27.923
النتائج كانت مؤثرة.

00:07:28.312 --> 00:07:31.669
نظامها يستطيع التنبؤ باحتمالية الإكتئاب

00:07:31.693 --> 00:07:35.596
أشهر قبل بداية أي أعراض --

00:07:35.620 --> 00:07:36.993
أشهر قبل.

00:07:37.017 --> 00:07:39.263
لا أعراض، يوجد هنا تنبؤ.

00:07:39.287 --> 00:07:44.099
تأمل أنه سيستعمل للتدخل المُبكر. عظيم!

00:07:44.731 --> 00:07:46.771
لكن الآن ضع هذا في حالة التوظيف.

00:07:47.847 --> 00:07:50.893
لذلك في مؤتمر مدراء الموارد البشرية هذا،

00:07:50.917 --> 00:07:55.626
اقتربت من مدير في المستوى الأعلى
في شركة كبيرة جداً،

00:07:55.650 --> 00:08:00.228
وقُلت لها،" انظري، ماذا لو، غير معروف لك،

00:08:00.252 --> 00:08:06.801
أن نظامك يُزيل الأشخاص ذوي الاحتمالية 
المستقبلية الكبيرة من الإكتئاب؟

00:08:07.581 --> 00:08:10.957
إنهم غير مكتئبين الآن،
ربما فقط في المستقبل، أكثر احتمالية.

00:08:11.743 --> 00:08:15.149
ماذا لو يُزل النساء الأكثر 
احتمالية لأن يكونوا حوامل

00:08:15.173 --> 00:08:17.759
في السنة المقبلة أوالسنتين
ولكن غير حوامل الآن؟

00:08:18.664 --> 00:08:24.300
ماذا لو يوظف الناس العدائيين
لأن ذلك هو ثقافة مكان عملك؟"

00:08:24.993 --> 00:08:27.684
لا تستطيع أن تحكي هذا بالنظر
إلى التقسيم من حيث الجنس.

00:08:27.708 --> 00:08:29.210
هؤلاء ربما يكونوا متوازنيين.

00:08:29.234 --> 00:08:32.791
وبما أن هذا تعّلم الآلة،
وليس تدوين تقليدي،

00:08:32.815 --> 00:08:37.722
لا يوجد هنا متغير يوجد
اسمه "خطر أعلى من الإكتئاب،"

00:08:37.746 --> 00:08:39.579
"خطر أعلى من الحمل،"

00:08:39.603 --> 00:08:41.337
"مقياس شخص عدواني."

00:08:41.815 --> 00:08:45.494
ليس فقط أنك لا تعلم ما يختار نظامك،

00:08:45.518 --> 00:08:47.841
أنت لا تعلم أيضاً أين يجب أن تبدأ النظر.

00:08:47.865 --> 00:08:49.111
إنه صندوق أسود.

00:08:49.135 --> 00:08:51.942
إنه يملك قوة تنبؤية،
لكنك لا تفهمها.

00:08:52.306 --> 00:08:54.675
سألتها "ما إجراءات الوقاية"، ستملكين

00:08:54.699 --> 00:08:58.372
لتتأكد أن صندوقك الأسود
لا يعمل أي شيء مضلل؟"

00:09:00.683 --> 00:09:04.561
نظرت ألي كما لو أنني
ضربتها بعشرة ذيول جِراء.

00:09:04.585 --> 00:09:05.833
(ضحك)

00:09:05.857 --> 00:09:07.898
حدقت إلي وقالت،

00:09:08.376 --> 00:09:12.709
" أنا لا أريد أن أسمع كلمة أخرى حول هذا."

00:09:13.278 --> 00:09:15.312
و دارت نفسها وذهبت بعيداً.

00:09:15.884 --> 00:09:17.370
إنتبهوا-- لم تكن وقحة.

00:09:17.394 --> 00:09:23.702
إنه كان واضحاً: الذي لا أعرفه ليس مشكلتي،
اذهب بعيداً، الموت يُحدق.

00:09:23.726 --> 00:09:24.972
(ضحك)

00:09:25.682 --> 00:09:29.521
انظر، هكذا نظام ربما يكون أقل تحيزاً

00:09:29.545 --> 00:09:31.648
مِن المدراء البشر في بعض الطرق.

00:09:31.672 --> 00:09:33.818
ويمكن أن يصنع إدراك عملي.

00:09:34.393 --> 00:09:36.043
ولكنه ممكن أن يقود أيضاً

00:09:36.067 --> 00:09:40.815
إلى الثبات ولكن إغلاق خفي لسوق العمل

00:09:40.839 --> 00:09:43.132
للناس بمستوى عالي من الإكتئاب.

00:09:43.573 --> 00:09:46.169
هل هذا هو النوع من المجتمع
الذي نريد أن نبنيه،

00:09:46.193 --> 00:09:48.478
بدون حتى أن نعلم أننا فعلنا هذا،

00:09:48.502 --> 00:09:52.466
لأننا حولّنا اتخاذ القرارات
إلى ألات لا نفهمها تماماً؟

00:09:53.085 --> 00:09:54.543
مشكلة أخرى وهي كالتالي:

00:09:55.134 --> 00:09:59.586
هذه الأنظمة غالباً ما تكون دُربت
على البيانات أُنتجت من أعمالنا،

00:09:59.610 --> 00:10:01.426
بصمات الإنسان.

00:10:02.008 --> 00:10:05.816
حسناً، ربما هُن فقط يعكسن تحيزنا،

00:10:05.840 --> 00:10:09.433
وهذه الأنظمة ربما قد تختار تحيزنا

00:10:09.457 --> 00:10:10.770
وتبالغ فيه

00:10:10.794 --> 00:10:12.212
وتعود لترينا اياه

00:10:12.236 --> 00:10:13.698
بينما نحن نُخبر أنفسنا،

00:10:13.722 --> 00:10:16.839
"نحن فقط نفعل الهدف، الحساب الحيادي."

00:10:18.134 --> 00:10:20.811
الباحثون وجدوا ذلك على غوغل،

00:10:21.954 --> 00:10:27.267
النساء أقل احتمالية من الرجال لإعلانات 
العمل بالنسبة للأعمال بالدخل العالي.

00:10:28.283 --> 00:10:30.813
والبحث في الأسماء الأميريكية الإفريقية

00:10:30.837 --> 00:10:35.543
أكثراحتمالية ليجلب إعلانات
مُقترحة تاريخ جنائي،

00:10:35.567 --> 00:10:37.134
حتى عندما لا توجد.

00:10:38.513 --> 00:10:42.062
هكذا تحيز مخفي
وخوارزميات الصندوق الأسود

00:10:42.086 --> 00:10:46.059
والتي لا يُغطيها الباحثون أحياناً
ولكن أحياناً لا نعلم،

00:10:46.083 --> 00:10:48.744
يُمكن أن يكون لديها عواقب
تغيير مدى الحياة.

00:10:49.778 --> 00:10:53.937
في ويسكونسن، حُكم على المدعى عليه 
ست سنوات في السجن

00:10:53.961 --> 00:10:55.316
لأجل تجاهل الشرطة.

00:10:56.644 --> 00:10:57.830
ربما لا تعلم هذا،

00:10:57.854 --> 00:11:01.852
لكن الخوارزميات وبازدياد تُستعمل في
اطلاق السراح وقرارات اصدار الأحكام.

00:11:01.876 --> 00:11:04.831
هو أراد أن يعرف:
كيف تُحسب هذه النتيجة؟

00:11:05.615 --> 00:11:07.280
إنه صندوق أسود تجاري.

00:11:07.304 --> 00:11:11.509
رفضت الشركة لأن تكون خوارزميتها
مُعترض عليها في المحكمة المفتوحة.

00:11:12.216 --> 00:11:17.748
ولكن شركة التحقيق بروبابليكا الغير ربحية،
دققت الخوارزمية

00:11:17.772 --> 00:11:19.788
مع البيانات العامة التي استطاعوا إيجادها،

00:11:19.812 --> 00:11:22.128
ووجدوا أن المُخرجات كانت مُتحيزة

00:11:22.152 --> 00:11:25.781
وقوته التنبؤية كانت مُحزنة،
بالكاد أفضل من الفرصة،

00:11:25.805 --> 00:11:30.221
وكان من الخطأ تصنيف المُدعى عليهم
السود كمجرمي المستقبل

00:11:30.245 --> 00:11:34.140
كضِعف المُدعى عليهم البيض.

00:11:35.711 --> 00:11:37.275
لذا، تأمل هذه الحالة :

00:11:37.923 --> 00:11:41.775
هذه المرأة كانت مُتأخرة لتقل أختها

00:11:41.799 --> 00:11:43.874
من المدرسة في بلدة بروارد، فلوريدا،

00:11:44.577 --> 00:11:46.933
توقفت في الشارع
مع صديقتها.

00:11:46.957 --> 00:11:51.056
واكتشفوا دراجة طفل غير مُقفلة
ودراجة على الرواق

00:11:51.080 --> 00:11:52.712
وبكل حماقة قفزوا عليها.

00:11:52.736 --> 00:11:55.335
بينما كانوا يستعجلون،
ظهرت امرأة وقالت،

00:11:55.359 --> 00:11:57.564
"مرحبا! تلك دراجة طفلي!"

00:11:57.588 --> 00:12:00.882
فقاموا بتركها ومشوا بعيداً،
ولكنهم كانوا قد أُعتقلوا.

00:12:00.906 --> 00:12:04.543
كانت مُخطئة، كانت حمقى، 
ولكنها كانت بعمر 18 سنة أيضاً.

00:12:04.567 --> 00:12:07.111
لديها العديد من المخالفات الصبيانية.

00:12:07.628 --> 00:12:12.813
في الوقت نفسه، ذلك الرجل كان
قد أُعتقل للسرقة مخزن المنزل --

00:12:12.837 --> 00:12:15.761
ما قيمته 85 دولار من الأغراض،
جريمة سخيفة مُشابهة.

00:12:16.586 --> 00:12:21.145
ولكن كان لديه جُرمي سطو مُسلح سابقين.

00:12:21.775 --> 00:12:25.257
ولكن الخوارزمية سجلت المرأة
كخطر كبير ولم تُسجله.

00:12:26.566 --> 00:12:30.440
بعد سنتين، وجدت شركة بروبابليكا
أن المرأة لم تكن قد ارتكبت مُخالفة.

00:12:30.464 --> 00:12:33.014
كان من الصعب عليها فقط أن
تحصل على عمل بسبب سجلها.

00:12:33.038 --> 00:12:35.114
هو، في الجهة المقابلة، ارتكب مخالفة

00:12:35.138 --> 00:12:38.974
وهو يخدم الآن فترة ثماني
سنوات سجن بسبب جريمة لاحقة.

00:12:39.908 --> 00:12:43.277
بكل وضوح، نحن بحاجة 
إلى تدقيق صناديقنا السود

00:12:43.301 --> 00:12:45.916
وأن لا يكون لديها هذا النوع
من القوة الغير مفحوصة.

00:12:45.940 --> 00:12:48.819
(تصفيق)

00:12:49.907 --> 00:12:54.149
تدقيق الحسابات عظيم وهام،
ولكنهن لا يحللن كل مشاكلنا.

00:12:54.173 --> 00:12:56.921
خذ قوة أخبار فيس بوك لُقمت بالخوارزمية --

00:12:56.945 --> 00:13:01.788
أنت تعلم، الشخص الذي صنف كل شيء
ويقرر ما يُظهر لك

00:13:01.812 --> 00:13:04.096
من كل الأصدقاء والصفحات التي تُتابعها.

00:13:04.718 --> 00:13:06.993
هل يجب أن ترى صورة طفل آخر؟

00:13:07.017 --> 00:13:08.213
(ضحك)

00:13:08.237 --> 00:13:10.833
ملاحظة مُتجهمة من شخص معروف؟

00:13:11.269 --> 00:13:13.125
الأخبار المُهمة ولكنها عويصة؟

00:13:13.149 --> 00:13:14.631
لا يوجد هنا أي اجابة صحيحة.

00:13:14.655 --> 00:13:17.314
يبحث فيس بوك عن أفضل الحلول
للتشابك على الموقع:

00:13:17.338 --> 00:13:18.753
اعجابات، مشاركات، تعليقات.

00:13:19.988 --> 00:13:22.684
في شهرآب من 2014،

00:13:22.708 --> 00:13:25.370
اندلعت الاحتجاجات في فيرغوسن، 
مُقاطعة ميسوري،

00:13:25.394 --> 00:13:29.811
بعد مقتل مراهق أميريكي-افريقي
من قبل ضابط شرطة أبيض،

00:13:29.835 --> 00:13:31.405
في ظروف غامضة.

00:13:31.794 --> 00:13:33.801
الأخبار عن الاحتجاجات كانت قد انتهت

00:13:33.825 --> 00:13:36.510
خوارزميتي الحسابية لم تُصفي تلقيم تويتر،

00:13:36.534 --> 00:13:38.484
ولكن هنا على الفيس بوك خاصتي.

00:13:39.002 --> 00:13:40.736
هل كانوا أصدقاء حسابي الفيس بوك؟

00:13:40.760 --> 00:13:42.792
عَطلتُ خوارزمية فيس بوك الحسابية،

00:13:43.292 --> 00:13:46.140
حيث إنه صعب، لأن فيس بوك
دائماً يُريد أن يجعلك

00:13:46.164 --> 00:13:48.200
تبقى تحت سيطرة الخوارزمية،

00:13:48.224 --> 00:13:50.462
وشاهدت أصدقائي كانوا يتكلمون عنه.

00:13:50.486 --> 00:13:52.995
أنه فقط أن الخوارزمية
لم تكن تُظهره لي.

00:13:53.019 --> 00:13:56.061
بحثت حول هذا ووجدت
أن هذا كان مُشكلة واسعة الانتشار.

00:13:56.085 --> 00:13:59.898
قصة فيرغوسن لم تكن
ضمن نظام الخوارزمية بشكل ودّي.

00:13:59.922 --> 00:14:01.093
إنه ليس"جدير بالمحبة."

00:14:01.117 --> 00:14:02.669
مَن سيضغط على "اعجاب؟"

00:14:03.320 --> 00:14:05.526
إنه حتى ليس من السهل أن 
تُعلق عليه.

00:14:05.550 --> 00:14:06.921
من دون الاعجابات والتعليقات،

00:14:06.945 --> 00:14:10.237
الخوارزمية كانت من المحتمل
أن تظهره لعدد أقل من الناس،

00:14:10.261 --> 00:14:11.803
لذلك نحن لا نُريد أن نرى هذا.

00:14:12.766 --> 00:14:13.994
بدلاً من، ذلك الاسبوع،

00:14:14.018 --> 00:14:16.316
خوارزمية فيس بوك ألقت الضوء على هذا،

00:14:16.340 --> 00:14:18.566
حيث إنه تحدي الدلو الجليدي ALS.

00:14:18.590 --> 00:14:22.332
سبب قيّم؛ الماء الجليدي المفرغ،
صُنع المعروف، جميل.

00:14:22.356 --> 00:14:24.260
ولكنها كانت خوارزمية
صديقة بامتياز.

00:14:25.039 --> 00:14:27.652
الآلة صنعت هذا القرار من أجلنا.

00:14:27.676 --> 00:14:31.173
محادثة مهمة جداً ولكنها صعبة

00:14:31.197 --> 00:14:32.752
ربما تكون قد غُطت بكثافة،

00:14:32.776 --> 00:14:35.472
ربما كان فيس بوك القناة الوحيدة.

00:14:35.937 --> 00:14:39.734
الآن،وأخيراً، هذه الأنظمة
يمكن أيضاً أن تكون مخطئة

00:14:39.758 --> 00:14:42.494
في الطُرق التي لا تُماثل الأنظمة الانسانية.

00:14:42.518 --> 00:14:45.440
هل تتذكرون واتسون،
نظام الذكاء الآلي لشركة IBM

00:14:45.464 --> 00:14:48.592
والذي أزال الإرباك مع
المتنافسين البشر على لعبة Jeopardy؟

00:14:48.951 --> 00:14:50.379
كان لاعب عظيم.

00:14:50.403 --> 00:14:53.972
ولكن فيما بعد، بالنسبة للعبة الأخيرة،
سُأل واتسون هذا السؤال:

00:14:54.479 --> 00:14:57.411
"مطاره الأكبر سُمي لبطل
الحرب العالمية الثانية،

00:14:57.435 --> 00:14:59.687
ثاني أكبر مطار لمعركة 
الحرب العالمية الثانية."

00:14:59.711 --> 00:15:01.089
(دندنة لموسيقا اللعبة الأخيرة)

00:15:01.402 --> 00:15:02.584
شيكاغو.

00:15:02.608 --> 00:15:03.978
الشخصين أجابوا بشكل صحيح.

00:15:04.517 --> 00:15:08.865
واتسون، على الجهة المقابلة،
أجاب "تورونتو"--

00:15:08.889 --> 00:15:10.707
عوضاً عن تصنيف مدينة أمريكية!

00:15:11.416 --> 00:15:14.317
النظام المُثير للاعجاب أيضاً يصنع أخطاء

00:15:14.341 --> 00:15:17.992
التي لا يُمكن أن يصنعها الإنسان،
الصنف الثاني سوف لن يصنعها.

00:15:18.643 --> 00:15:21.752
ذكاء ألتُنا الصناعي يُمكن أن يفشل

00:15:21.776 --> 00:15:24.876
في الطرق التي لا تناسب نماذج خطأ الانسان

00:15:24.900 --> 00:15:27.850
في الطرق التي لا نتوقعها
ونكون مُحضرين لها.

00:15:27.874 --> 00:15:31.512
سيكون من الحقارة أن لا يحصل
الشخص على عمل يكون مؤهل له،

00:15:31.536 --> 00:15:35.263
لكن سيكون استيعاب ثلاثي
إذا كان بسبب فائض مُكدس

00:15:35.287 --> 00:15:36.719
في بعض الروتين الفعلي.

00:15:36.743 --> 00:15:38.322
(ضحك)

00:15:38.346 --> 00:15:41.132
في شهر شهر مايو/أيارعام 2010،

00:15:41.156 --> 00:15:45.200
الإنهيار السريع في وول ستريت
المُغذى بحلقة ردود الفعل

00:15:45.224 --> 00:15:48.252
في خوارزمية "البيع" الحسابية
في وول ستريت

00:15:48.276 --> 00:15:52.460
أزال ما قيمته ترليليون دولار 
في 36 دقيقة.

00:15:53.542 --> 00:15:55.729
أنا لا أريد حتى أن أعتقد
ما يعني"الخطأ"

00:15:55.753 --> 00:15:59.342
في سياق الأسلحة المستقلة المُهلكة.

00:16:01.714 --> 00:16:05.504
لذا نعم، الناس دائماً يصنعون التحيز.

00:16:05.528 --> 00:16:07.704
صانعوا القرارات و حارسوا البوابات،

00:16:07.728 --> 00:16:11.221
في المحاكم، في الأخبار، في الحرب...

00:16:11.245 --> 00:16:14.283
هم يصنعون الأخطاء؛
ولكن تلك فكرتي بالضبط.

00:16:14.307 --> 00:16:17.828
نحن لا نستطيع الهرب من
هذه الأسئلة الصعبة.

00:16:18.416 --> 00:16:21.932
نحن لا نستطيع التعهد
بمسؤلياتنا إلى الآلات.

00:16:22.496 --> 00:16:26.704
(تصفيق)

00:16:28.909 --> 00:16:33.356
الذكاء الاصطناعي لا يعطينا
بطاقة "الخروج من الأخلاق بحرية".

00:16:34.562 --> 00:16:37.943
عالم البيانات فريد بيننسون
يدعو هذا غسيل الرياضيات.

00:16:37.967 --> 00:16:39.356
نحن نحتاج العكس.

00:16:39.380 --> 00:16:44.768
نريد أن نصقل التشكيك حول الخوارزمية،
الفحص الدقيق و الاستقصاء.

00:16:45.200 --> 00:16:48.398
نريد أن نتأكد أنه لدينا مسؤلية
حول ما يتعلق بالخوارزمية.

00:16:48.422 --> 00:16:50.867
التدقيق، الشفافية ذات المعنى.

00:16:51.200 --> 00:16:54.434
نريد أن نقبل أن نجلب
الرياضيات والحساب

00:16:54.458 --> 00:16:57.428
للأشياء الفوضوية،
العلاقات الانسانية المحملة بالقيمة

00:16:57.452 --> 00:16:59.836
لا تجلب الموضوعية؛

00:16:59.860 --> 00:17:03.493
بالأحرى، العلاقات الانسانية المعقدة
تنتهك الخوارزميات.

00:17:03.968 --> 00:17:07.455
نعم، نحن نستطيع ويجب علينا
أن نستخدم الحساب

00:17:07.479 --> 00:17:09.493
ليساعدنا على اتخاذ قرارات أفضل.

00:17:09.517 --> 00:17:14.849
ولكن يجب علينا أن نعترف
بمسؤليتنا الاخلاقية في الحكم،

00:17:14.873 --> 00:17:17.691
وأن نستخدم الخوارزميات
ضمن اطار العمل ذلك،

00:17:17.715 --> 00:17:22.650
ليس بمعنى أن نتنازل و نتعهد
بمسؤلياتنا

00:17:22.674 --> 00:17:25.128
لشخص آخر مثلاً
إنسان لإنسان.

00:17:25.627 --> 00:17:28.236
الذكاء الآلي هنا.

00:17:28.260 --> 00:17:31.681
والذي يعني أنه يجب علينا
ننتظر بشكل محكم أكثر من أي وقت مضى

00:17:31.705 --> 00:17:33.852
للقيم الانسانية والأخلاق الانسانية.

00:17:33.876 --> 00:17:35.030
شكراً لكم.

00:17:35.054 --> 00:17:40.074
(تصفيق)

