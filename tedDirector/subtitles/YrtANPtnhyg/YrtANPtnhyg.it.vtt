WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: P F
Revisore: Roberto Zanchi

00:00:15.260 --> 00:00:17.260
Siamo cresciuti

00:00:17.260 --> 00:00:20.260
interagendo con gli oggetti fisici intorno a noi.

00:00:20.260 --> 00:00:22.260
Ce ne sono un'infinità

00:00:22.260 --> 00:00:24.260
che usiamo ogni giorno.

00:00:24.260 --> 00:00:27.260
A differenza dei nostri dispositivi computerizzati,

00:00:27.260 --> 00:00:30.260
questi oggetti sono più semplici da usare.

00:00:30.260 --> 00:00:33.260
Quando parliamo di oggetti,

00:00:33.260 --> 00:00:36.260
tendiamo ad associare altre cose ad essi

00:00:36.260 --> 00:00:38.260
e cioè i gesti:

00:00:38.260 --> 00:00:40.260
come manipoliamo questi oggetti,

00:00:40.260 --> 00:00:43.260
come li usiamo nella vita quotidiana.

00:00:43.260 --> 00:00:46.260
Usiamo gesti non solo quando interagiamo con questi oggetti,

00:00:46.260 --> 00:00:48.260
ma anche quando interagiamo tra di noi.

00:00:48.260 --> 00:00:51.260
Il gesto del "Namasté", per esempio, come segno di rispetto

00:00:51.260 --> 00:00:52.260
o anche –

00:00:52.260 --> 00:00:54.260
in India non c'è bisogno di insegnare ai bimbi

00:00:54.260 --> 00:00:56.260
che questo significa "quattro" nel cricket.

00:00:56.260 --> 00:00:59.260
Lo si impara con il vivere quotidiano.

00:00:59.260 --> 00:01:01.260
Quindi, mi interessa molto

00:01:01.260 --> 00:01:03.260
come possiamo

00:01:03.260 --> 00:01:05.260
sfruttare quel che sappiamo

00:01:05.260 --> 00:01:07.260
degli oggetti quotidiani

00:01:07.260 --> 00:01:09.260
e dei gesti a loro associati,

00:01:09.260 --> 00:01:12.260
per interagire con il mondo digitale.

00:01:12.260 --> 00:01:15.260
Piuttosto che usare la tastiera e il mouse,

00:01:15.260 --> 00:01:18.260
perché non posso usare il mio computer

00:01:18.260 --> 00:01:21.260
così come faccio con gli altri oggetti nel mondo fisico?

00:01:21.260 --> 00:01:24.260
Così, otto anni fa ho cominciato la mia esplorazione,

00:01:24.260 --> 00:01:27.260
partendo proprio dal mouse sulla mia scrivania.

00:01:27.260 --> 00:01:30.260
Anziché usarlo per il computer,

00:01:30.260 --> 00:01:33.260
l'ho aperto.

00:01:33.260 --> 00:01:35.260
La maggior parte di voi saprà che a quei tempi

00:01:35.260 --> 00:01:37.260
il mouse conteneva una pallina al suo interno

00:01:37.260 --> 00:01:39.260
e c'erano due piccoli rulli che

00:01:39.260 --> 00:01:42.260
indicavano al computer come si muoveva la pallina

00:01:42.260 --> 00:01:44.260
e, di conseguenza, dove andava il mouse.

00:01:44.260 --> 00:01:47.260
Mi interessavano questi due rulli e ne volevo

00:01:47.260 --> 00:01:50.260
degli altri, così presi in prestito il mouse di un amico –

00:01:50.260 --> 00:01:52.260
mai più restituito –

00:01:52.260 --> 00:01:54.260
e così adesso avevo quattro rulli.

00:01:54.260 --> 00:01:57.260
Ho poi tolto i rulli dai mouse,

00:01:57.260 --> 00:02:00.260
li ho messi in fila

00:02:00.260 --> 00:02:02.260
e ho aggiunto anche

00:02:02.260 --> 00:02:05.260
alcuni tiranti, pulegge e molle.

00:02:05.260 --> 00:02:08.260
Ne è venuto fuori un dispositivo di interfaccia gestuale

00:02:08.260 --> 00:02:12.260
che agisce come un rilevatore di movimento,

00:02:12.260 --> 00:02:14.260
fatto con due dollari.

00:02:14.260 --> 00:02:17.260
Quindi, qualsiasi movimento che io faccia nel mondo fisico

00:02:17.260 --> 00:02:20.260
viene replicato nel mondo digitale, semplicemente

00:02:20.260 --> 00:02:23.260
usando questo piccolo dispositivo costruito otto anni fa,

00:02:23.260 --> 00:02:25.260
nel 2000.

00:02:25.260 --> 00:02:27.260
Siccome ero interessato ad integrare questi due mondi,

00:02:27.260 --> 00:02:29.260
ho pensato ai foglietti adesivi.

00:02:29.260 --> 00:02:32.260
Mi sono chiesto: "Perché non si può collegare

00:02:32.260 --> 00:02:34.260
un semplice foglietto di carta

00:02:34.260 --> 00:02:36.260
al mondo digitale?"

00:02:36.260 --> 00:02:38.260
Un messaggio scritto su un foglietto,

00:02:38.260 --> 00:02:39.260
su carta,

00:02:39.260 --> 00:02:41.260
può diventare un SMS

00:02:41.260 --> 00:02:43.260
o un promemoria di un appuntamento

00:02:43.260 --> 00:02:45.260
che automaticamente si sincronizza con il mio calendario digitale

00:02:45.260 --> 00:02:48.260
o con una lista delle cose-da-fare.

00:02:48.260 --> 00:02:51.260
Ma si può anche cercare nel mondo digitale,

00:02:51.260 --> 00:02:53.260
o magari scrivere qualcosa come:

00:02:53.260 --> 00:02:55.260
"Qual'è l'indirizzo del Dott. Smith?"

00:02:55.260 --> 00:02:57.260
e il sistema lo trova e lo stampa –

00:02:57.260 --> 00:02:59.260
funziona cioè come un di sistema di input-output,

00:02:59.260 --> 00:03:02.260
fatto con la carta.

00:03:05.260 --> 00:03:07.260
In un'altra esplorazione,

00:03:07.260 --> 00:03:10.260
ho pensato di costruire una penna per disegnare in tre dimensioni.

00:03:10.260 --> 00:03:12.260
L'ho implementata per

00:03:12.260 --> 00:03:14.260
aiutare designer e architetti

00:03:14.260 --> 00:03:16.260
non solo a pensare in tre dimensioni,

00:03:16.260 --> 00:03:18.260
ma anche a disegnarci,

00:03:18.260 --> 00:03:20.260
in modo più intuitivo.

00:03:20.260 --> 00:03:22.260
Poi ho pensato: "Perché non costruire una Google Map,

00:03:22.260 --> 00:03:24.260
ma nel mondo fisico?"

00:03:24.260 --> 00:03:27.260
Piuttosto che digitare una parola chiave per trovare qualcosa,

00:03:27.260 --> 00:03:29.260
ci metto sopra gli oggetti direttamente.

00:03:29.260 --> 00:03:32.260
Se metto una carta d'imbarco, mi indicherà dove si trova il cancello d'imbarco.

00:03:32.260 --> 00:03:35.260
Una tazza di caffè e mi mostrerà dove posso trovarne dell'altro,

00:03:35.260 --> 00:03:37.260
o dove posso buttare via il contenitore.

00:03:37.260 --> 00:03:40.260
Queste sono alcune delle mie prime esplorazioni,

00:03:40.260 --> 00:03:43.260
l'obiettivo era quello di collegare facilmente questi due mondi.

00:03:44.260 --> 00:03:46.260
Tutti questi esperimenti

00:03:46.260 --> 00:03:48.260
avevano una cosa in comune:

00:03:48.260 --> 00:03:52.260
in tutti cercavo di portare parte del mondo fisico in quello digitale.

00:03:52.260 --> 00:03:55.260
Prendevo certi aspetti degli oggetti,

00:03:55.260 --> 00:03:58.260
o del loro uso nella vita quotidiana,

00:03:58.260 --> 00:04:01.260
e li portavo nel mondo digitale,

00:04:01.260 --> 00:04:04.260
perché l'obiettivo era di rendere le interfacce con i computer più intuitive.

00:04:04.260 --> 00:04:06.260
Ma poi mi sono accorto che noi umani

00:04:06.260 --> 00:04:09.260
non siamo interessati ai computer di per sé.

00:04:09.260 --> 00:04:12.260
Ci interessa l'informazione che veicolano.

00:04:12.260 --> 00:04:14.260
Vogliamo conoscere cose, fatti.

00:04:14.260 --> 00:04:16.260
Vogliamo conoscere quel che succede.

00:04:16.260 --> 00:04:21.260
Così l'anno scorso – all'inizio dell'anno – ho cominciato a pensare:

00:04:21.260 --> 00:04:24.260
"Perché non affrontare la questione al contrario?"

00:04:24.260 --> 00:04:27.260
Mi son detto: "E se prendessi il mio mondo digitale

00:04:27.260 --> 00:04:32.260
e 'dipingessi' il mondo fisico con queste informazioni digitali?"

00:04:32.260 --> 00:04:36.260
Perché i pixel, al momento, sono confinati dentro questi dispositivi rettangolari

00:04:36.260 --> 00:04:38.260
che ci stanno nelle tasche.

00:04:38.260 --> 00:04:41.260
Perché non rimuovere questo limite

00:04:41.260 --> 00:04:44.260
e portarli sugli oggetti di ogni giorno, nella vita reale,

00:04:44.260 --> 00:04:46.260
così che non ci sia bisogno di imparare

00:04:46.260 --> 00:04:49.260
un nuovo linguaggio per interagire con questi pixel?

00:04:50.260 --> 00:04:52.260
Così, per realizzare questo sogno,

00:04:52.260 --> 00:04:55.260
ho pensato di mettermi un grande proiettore in testa.

00:04:55.260 --> 00:04:58.260
Sarà per questo che si chiama proiettore a montaggio in testa, no?

00:04:58.260 --> 00:05:00.260
Ho preso l'idea molto alla lettera e

00:05:00.260 --> 00:05:02.260
ho usato il mio casco da ciclista,

00:05:02.260 --> 00:05:05.260
creando un alloggiamento per fissare meglio il proiettore.

00:05:05.260 --> 00:05:07.260
Quindi adesso posso aggiungere

00:05:07.260 --> 00:05:11.260
al mondo intorno a me informazioni digitali.

00:05:11.260 --> 00:05:13.260
Ma poi mi sono accorto

00:05:13.260 --> 00:05:16.260
che volevo anche interagire con questi pixel.

00:05:16.260 --> 00:05:18.260
Così ho messo anche una piccola telecamera,

00:05:18.260 --> 00:05:20.260
che fa da occhio digitale.

00:05:20.260 --> 00:05:22.260
In seguito abbiamo realizzato una versione

00:05:22.260 --> 00:05:24.260
molto migliore, più orientata all’utilizzatore,

00:05:24.260 --> 00:05:27.260
che molti di voi conoscono come il dispositivo SixthSense.

00:05:27.260 --> 00:05:30.260
Ma la cosa più interessante di questa tecnologia

00:05:30.260 --> 00:05:34.260
è che si può portare il proprio mondo digitale con sé,

00:05:34.260 --> 00:05:36.260
ovunque si vada.

00:05:36.260 --> 00:05:39.260
Si può usare qualsiasi superficie, qualsiasi muro,

00:05:39.260 --> 00:05:41.260
come una interfaccia.

00:05:41.260 --> 00:05:44.260
La telecamera rileva tutti i gesti.

00:05:44.260 --> 00:05:46.260
Qualsiasi sia il gesto che le mani fanno,

00:05:46.260 --> 00:05:48.260
il sistema lo riconosce.

00:05:48.260 --> 00:05:50.260
E ci sono anche dei marcatori colorati

00:05:50.260 --> 00:05:53.260
che usiamo nella versione iniziale.

00:05:53.260 --> 00:05:55.260
Si può dipingere su qualsiasi muro.

00:05:55.260 --> 00:05:58.260
Basta fermarsi davanti a un muro e iniziare.

00:05:58.260 --> 00:06:00.260
Ma qui non stiamo rilevando un dito solo.

00:06:00.260 --> 00:06:04.260
Qui abbiamo la libertà di usare entrambe le mani e possiamo usarle

00:06:04.260 --> 00:06:07.260
per lo zoom, per ingrandire o rimpicciolire una mappa,

00:06:07.260 --> 00:06:09.260
semplicemente unendo le dita.

00:06:09.260 --> 00:06:12.260
Il ruolo della telecamera qui è semplicemente di

00:06:12.260 --> 00:06:13.260
acquisire le immagini –

00:06:13.260 --> 00:06:16.260
che poi saranno processate per il riconoscimento dei bordi

00:06:16.260 --> 00:06:19.260
e dei colori, in aggiunta a molti altri piccoli algoritmi.

00:06:19.260 --> 00:06:21.260
Tecnicamente è un po' complesso, ma il risultato

00:06:21.260 --> 00:06:24.260
è qualcosa di più intuitivo da usare, per certi aspetti.

00:06:24.260 --> 00:06:27.260
Ma mi entusiasma di più quello che si può fare all'esterno.

00:06:27.260 --> 00:06:30.260
Piuttosto che tirare fuori la macchina fotografica dalla tasca,

00:06:30.260 --> 00:06:33.260
si può semplicemente fare il gesto di fare una foto

00:06:33.260 --> 00:06:35.260
e la foto viene scattata.

00:06:35.260 --> 00:06:39.260
(Applausi)

00:06:39.260 --> 00:06:40.260
Grazie.

00:06:41.260 --> 00:06:43.260
E magari dopo posso trovare un muro

00:06:43.260 --> 00:06:45.260
e cominciare a selezionare le foto

00:06:45.260 --> 00:06:47.260
e dire: "OK, adesso voglio aggiustare un po' questa

00:06:47.260 --> 00:06:49.260
e spedirla via email ad un amico."

00:06:49.260 --> 00:06:52.260
Ciò che abbiamo in mente è un’era nella quale

00:06:52.260 --> 00:06:55.260
l'elaborazione di informazioni sarà inglobata nel mondo fisico.

00:06:55.260 --> 00:06:58.260
E, naturalmente, in mancanza di una superficie sottomano

00:06:58.260 --> 00:07:01.260
si potrà usare la mano stessa per le operazioni più semplici.

00:07:01.260 --> 00:07:03.260
Qui sto componendo un numero di telefono.

00:07:07.260 --> 00:07:10.260
La telecamera riconosce non solo i movimenti della mano,

00:07:10.260 --> 00:07:11.260
ma anche

00:07:11.260 --> 00:07:14.260
gli oggetti che si tengono in mano.

00:07:14.260 --> 00:07:17.260
Per esempio, in questo caso

00:07:17.260 --> 00:07:19.260
la copertina del libro

00:07:19.260 --> 00:07:21.260
è messa a confronto

00:07:21.260 --> 00:07:24.260
con migliaia o forse milioni di libri online,

00:07:24.260 --> 00:07:26.260
per verificare di che libro si tratta.

00:07:26.260 --> 00:07:27.260
Una volta trovato,

00:07:27.260 --> 00:07:29.260
va a cercare le recensioni del libro

00:07:29.260 --> 00:07:32.260
o magari il New York Times ha una recensione audio,

00:07:32.260 --> 00:07:34.260
così si può ascoltare, sul libro,

00:07:34.260 --> 00:07:36.260
l'audio della recensione.

00:07:36.260 --> 00:07:38.260
("il famoso discorso alla Harvard University...")

00:07:38.260 --> 00:07:41.260
Questa è la visita di Obama al MIT, la scorsa settimana.

00:07:42.260 --> 00:07:46.260
("...e vorrei ringraziare particolarmente due brillanti...")

00:07:46.260 --> 00:07:51.260
Qui ero fuori e stavo guardando il video in diretta, sul giornale.

00:07:51.260 --> 00:07:54.260
Il giornale mostrerà le previsioni meteo in tempo reale,

00:07:54.260 --> 00:07:57.260
piuttosto che di volta in volta – adesso dobbiamo usare

00:07:57.260 --> 00:07:59.260
il computer per ricevere l'ultimo aggiornamento, no?

00:07:59.260 --> 00:08:04.260
(Applausi)

00:08:04.260 --> 00:08:07.260
Quando rientro posso usare il mio biglietto aereo

00:08:07.260 --> 00:08:09.260
per verificare di quanto il mio volo è stato ritardato,

00:08:09.260 --> 00:08:11.260
perché in quel momento

00:08:11.260 --> 00:08:13.260
non mi va di tirare fuori l'iPhone

00:08:13.260 --> 00:08:15.260
e cercare tra le icone.

00:08:15.260 --> 00:08:18.260
E credo che questa tecnologia cambierà non solo il modo –

00:08:18.260 --> 00:08:19.260
Sì. (Risate)

00:08:20.260 --> 00:08:22.260
Cambierà il modo in cui interagiamo anche con le persone,

00:08:22.260 --> 00:08:24.260
non solo con il mondo fisico.

00:08:24.260 --> 00:08:27.260
La parte divertente è quando vado nella

00:08:27.260 --> 00:08:30.260
metro di Boston e gioco a "Pong"

00:08:30.260 --> 00:08:32.260
sul pavimento del treno, no?

00:08:32.260 --> 00:08:33.260
(Risate)

00:08:33.260 --> 00:08:35.260
E credo che l'immaginazione sia il solo limite

00:08:35.260 --> 00:08:37.260
di quello che si può concepire

00:08:37.260 --> 00:08:39.260
quando questa tecnologia entra nella vita reale.

00:08:39.260 --> 00:08:41.260
Molti obietteranno che non tutto

00:08:41.260 --> 00:08:44.260
il nostro lavoro ha a che fare con oggetti fisici.

00:08:44.260 --> 00:08:47.260
Lavoriamo molto con i dati e con l'editing di testi

00:08:47.260 --> 00:08:49.260
e come facciamo con tutte queste cose?

00:08:49.260 --> 00:08:53.260
Molti si entusiasmano per la prossima generazione di "tablet computer"

00:08:53.260 --> 00:08:55.260
che arriveranno sul mercato.

00:08:55.260 --> 00:08:57.260
Piuttosto che aspettare che arrivino

00:08:57.260 --> 00:09:00.260
ho pensato di farne uno, semplicemente con un foglio di carta.

00:09:00.260 --> 00:09:02.260
Ho smontato la telecamera –

00:09:02.260 --> 00:09:06.260
tutte le webcam hanno un microfono al loro interno –

00:09:06.260 --> 00:09:09.260
ho rimosso il microfono

00:09:09.260 --> 00:09:11.260
e l'ho semplicemente pinzato –

00:09:11.260 --> 00:09:14.260
attaccandoci prima una graffetta –

00:09:14.260 --> 00:09:18.260
su un foglio di carta, uno qualsiasi.

00:09:18.260 --> 00:09:21.260
Adesso, il rumore del dito che tocca la carta

00:09:21.260 --> 00:09:24.260
mi segnala esattamente quando tocco il foglio.

00:09:24.260 --> 00:09:28.260
La telecamera invece rileva dove si muovono le dita.

00:09:28.260 --> 00:09:31.260
Naturalmente è possibile vedere dei film.

00:09:31.260 --> 00:09:34.260
("Buon pomeriggio, mi chiamo Russell...")

00:09:34.260 --> 00:09:37.260
("...e sono un Esploratore della Foresta della Tribù 54.")

00:09:37.260 --> 00:09:40.260
Ed è anche possibile giocare ad un videogioco.

00:09:40.260 --> 00:09:43.260
(Motore d'automobile)

00:09:43.260 --> 00:09:46.260
Qui la telecamera riconosce come il foglio è tenuto in mano

00:09:46.260 --> 00:09:48.260
e controlla il videogioco.

00:09:48.260 --> 00:09:51.260
(Applausi)

00:09:52.260 --> 00:09:54.260
Molti avranno pensato, OK, si potrà anche usare il browser.

00:09:54.260 --> 00:09:57.260
Sì. Naturalmente si può visitare qualsiasi sito web

00:09:57.260 --> 00:10:00.260
e lanciare applicazioni varie, su un pezzo di carta,

00:10:00.260 --> 00:10:01.260
ovunque ce ne sia bisogno.

00:10:01.260 --> 00:10:04.260
Ma mi interessa di più come possiamo

00:10:04.260 --> 00:10:07.260
utilizzarlo in modo più dinamico.

00:10:07.260 --> 00:10:10.260
Quando ritorno alla mia scrivania posso afferrare queste informazioni

00:10:10.260 --> 00:10:12.260
e portarle sul mio computer,

00:10:12.260 --> 00:10:15.260
così che poi posso usare il mio computer normale.

00:10:15.260 --> 00:10:17.260
(Applausi)

00:10:17.260 --> 00:10:20.260
E perché solo con i computer? Magari anche con la carta.

00:10:20.260 --> 00:10:23.260
Il mondo della carta è anche interessante per queste cose.

00:10:23.260 --> 00:10:25.260
Qui sto prendendo parte di un documento

00:10:25.260 --> 00:10:29.260
e ci metto sopra quest'altro, preso da un'altra parte –

00:10:29.260 --> 00:10:32.260
modifico queste informazioni

00:10:32.260 --> 00:10:34.260
che ho qui sul foglio.

00:10:34.260 --> 00:10:37.260
E dico: "OK, mi sembra vada bene,

00:10:37.260 --> 00:10:39.260
adesso lo stampo".

00:10:39.260 --> 00:10:41.260
Così adesso ho la stampa e

00:10:41.260 --> 00:10:44.260
alla fine tutto il processo è più intuitivo

00:10:44.260 --> 00:10:47.260
rispetto a 20 anni fa,

00:10:47.260 --> 00:10:50.260
piuttosto che saltare in continuazione tra questi due mondi.

00:10:50.260 --> 00:10:53.260
Quindi, come ultima riflessione, credo che

00:10:53.260 --> 00:10:56.260
l'integrazione delle informazioni negli oggetti quotidiani

00:10:56.260 --> 00:11:01.260
ci aiuterà non solo a superare il "digital divide",

00:11:01.260 --> 00:11:03.260
la separazione tra questi due mondi,

00:11:03.260 --> 00:11:05.260
ma ci aiuterà anche, in qualche modo,

00:11:05.260 --> 00:11:07.260
a rimanere umani,

00:11:07.260 --> 00:11:10.260
a rimanere più connessi con il mondo fisico.

00:11:13.260 --> 00:11:16.260
E ci aiuterà a non diventare delle macchine

00:11:16.260 --> 00:11:18.260
sedute di fronte ad altre macchine.

00:11:18.260 --> 00:11:21.260
Tutto qui. Grazie.

00:11:21.260 --> 00:11:35.260
(Applausi)

00:11:35.260 --> 00:11:36.260
Grazie.

00:11:36.260 --> 00:11:39.260
(Applausi)

00:11:39.260 --> 00:11:40.260
Chris Anderson: Allora, Pranav,

00:11:40.260 --> 00:11:43.260
prima di tutto, sei un genio.

00:11:43.260 --> 00:11:46.260
È incredibile, davvero.

00:11:46.260 --> 00:11:49.260
Che cosa pensi di fare con questo? Un'azienda nei tuoi piani?

00:11:49.260 --> 00:11:51.260
O farai ricerca per sempre, o cosa?

00:11:51.260 --> 00:11:53.260
Pranav Mistry: Ci sono molte aziende –

00:11:53.260 --> 00:11:54.260
praticamente gli sponsor del Media Lab –

00:11:54.260 --> 00:11:57.260
che sono interessate a portare avanti il progetto in vari modi.

00:11:57.260 --> 00:11:59.260
Aziende come operatori di telefonia mobile che

00:11:59.260 --> 00:12:02.260
vogliono svilupparlo in una direzione diversa dalle ONG in India,

00:12:02.260 --> 00:12:05.260
che pensano: "Perché dobbiamo avere solo 'Sesto Senso'?

00:12:05.260 --> 00:12:07.260
Dovremmo avere un 'Quinto Senso' per quelli ai quali manca uno,

00:12:07.260 --> 00:12:08.260
quelli che non possono parlare.

00:12:08.260 --> 00:12:11.260
Questa tecnologia può essere usata per parlare in altro modo,

00:12:11.260 --> 00:12:12.260
per esempio con degli altoparlanti."

00:12:12.260 --> 00:12:15.260
CA: Quali sono i tuoi piani? Rimani al MIT,

00:12:15.260 --> 00:12:16.260
o vuoi fare qualcosa con tutto questo?

00:12:16.260 --> 00:12:18.260
PM: Sto cercando di rendere il tutto più accessibile

00:12:18.260 --> 00:12:21.260
alle persone così che chiunque possa sviluppare il proprio "SixthSense"

00:12:21.260 --> 00:12:26.260
perché l'hardware non è così difficile da produrre,

00:12:26.260 --> 00:12:28.260
o da assemblare da soli.

00:12:28.260 --> 00:12:30.260
Noi forniremo tutto il software open source

00:12:30.260 --> 00:12:32.260
forse già a partire dal prossimo mese.

00:12:32.260 --> 00:12:34.260
CA: Open source? Uao!

00:12:34.260 --> 00:12:39.260
(Applausi)

00:12:39.260 --> 00:12:42.260
CA: Ritornerai in India con qualcosa, prima o poi?

00:12:42.260 --> 00:12:44.260
PM: Sì, sì, naturalmente.

00:12:44.260 --> 00:12:46.260
CA: Che cosa pensi di fare? MIT?

00:12:46.260 --> 00:12:48.260
India? Come pensi di ripartire il tempo in futuro?

00:12:48.260 --> 00:12:51.260
PM: C'è molta energia qui. Si sta imparando molto.

00:12:51.260 --> 00:12:53.260
Tutto il lavoro che avete visto qui è nato

00:12:53.260 --> 00:12:55.260
da quello che ho imparato in India.

00:12:55.260 --> 00:12:58.260
E adesso, se guardiamo al lato costi-benefici:

00:12:58.260 --> 00:13:00.260
questo sistema costa 300 dollari

00:13:00.260 --> 00:13:03.260
in confronto al sistema "surface table" che ne costa 20.000.

00:13:03.260 --> 00:13:06.260
O anche il sistema gestuale da due dollari

00:13:06.260 --> 00:13:09.260
che allora costava circa 5000 dollari?

00:13:09.260 --> 00:13:13.260
A quel tempo avevo fatto vedere queste cose, ad una conferenza,

00:13:13.260 --> 00:13:15.260
al presidente Abdul Kalam,

00:13:15.260 --> 00:13:18.260
e lui disse: "OK, lo dovremmo portare al Bhabha Atomic Research Centre

00:13:18.260 --> 00:13:20.260
per usarlo in qualche modo".

00:13:20.260 --> 00:13:23.260
Per cui, mi entusiasma l'idea di portare questa tecnologia

00:13:23.260 --> 00:13:26.260
alle masse, piuttosto che tenerla in laboratorio.

00:13:26.260 --> 00:13:30.260
(Applausi)

00:13:30.260 --> 00:13:33.260
CA: Per quel che abbiamo visto qui a TED, posso dire che

00:13:33.260 --> 00:13:34.260
tu sei uno dei due o tre

00:13:34.260 --> 00:13:36.260
migliori inventori al mondo al momento.

00:13:36.260 --> 00:13:38.260
È un onore averti qui a TED.

00:13:38.260 --> 00:13:40.260
Grazie molte.

00:13:40.260 --> 00:13:41.260
È fantastico.

00:13:41.260 --> 00:13:45.260
(Applausi)

