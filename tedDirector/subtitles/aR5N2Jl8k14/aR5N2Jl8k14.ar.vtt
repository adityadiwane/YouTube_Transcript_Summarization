WEBVTT
Kind: captions
Language: ar

00:00:00.000 --> 00:00:07.000
المترجم: Eman Shahen
المدقّق: Sarah Shahid

00:00:12.555 --> 00:00:14.844
كم مبدع بينكم،

00:00:14.868 --> 00:00:16.507
كم مهندس، مصمم، رجل أعمال، فنان،

00:00:16.507 --> 00:00:20.903
أو قد يكون لديكم مخيلة عظيمة بحق؟

00:00:20.927 --> 00:00:22.775
هل ترفعون أيديكم؟ (هتاف)

00:00:22.799 --> 00:00:23.980
أغلبكم.

00:00:25.154 --> 00:00:27.448
عندي بعض الأخبار 
لنا كمبدعين.

00:00:28.534 --> 00:00:31.107
على مدى 20 عامًا القادمة،

00:00:33.291 --> 00:00:36.264
سيتغيرالكثير في ما يخُص
الطريقة التي نقوم بها بعملنا

00:00:37.202 --> 00:00:39.359
خلافًا لما حدث في 2000 عام الأخيرة.

00:00:40.331 --> 00:00:44.959
في الحقيقة، أعتقد أننا في فجر
عصر جديد من تاريخ البشرية.

00:00:45.465 --> 00:00:50.226
حاليًا، هناك أربعة عصور رئيسية تاريخية 
تمّ تصنيفها وفقًا لطريقة عملنا.

00:00:51.224 --> 00:00:54.499
استمر عصر الصيد وجمع الثمار 
لملايين السنين.

00:00:54.983 --> 00:00:58.559
ثم دام العصر الزراعي 
لآلاف السنين.

00:00:59.015 --> 00:01:02.505
ودام العصر الصناعي 
لبضع قرون.

00:01:02.529 --> 00:01:06.816
وحاليًا لقد دام عصر المعلومات 
لبضع عقود.

00:01:06.840 --> 00:01:12.060
واليوم نحن على أعتاب
عصرنا العظيم القادم كأجناس بشرية.

00:01:13.116 --> 00:01:15.796
أهلًا بكم في عصرالتطور.

00:01:15.820 --> 00:01:19.513
في هذا العصرالجديد، ستتطور
قدراتكم البشرية

00:01:19.537 --> 00:01:22.605
بفضل الأنظمة الحاسوبية
التي تساعدكم على التفكير،

00:01:22.629 --> 00:01:24.815
والأنظمة الآلية التي تساعدكم على التنفيذ،

00:01:24.839 --> 00:01:26.487
وجهاز عصبي رقمي

00:01:26.511 --> 00:01:30.201
يربطك بالعالم أبعد من حواسك الطبيعية.

00:01:31.257 --> 00:01:33.199
لنبدأ بالتطور المعرفي.

00:01:33.223 --> 00:01:35.423
من بينكم انسان آلي
ذو قدرات قابلة للتطور؟

00:01:35.953 --> 00:01:38.603
(ضحك)

00:01:38.627 --> 00:01:41.448
سأقيم الحجة بأننا بالفعل قابلون للتطور.

00:01:42.108 --> 00:01:43.612
تخيل أنك في حفلة،

00:01:43.636 --> 00:01:47.156
ويسألك أحدهم سؤالًا لا تعرف إجابته.

00:01:47.180 --> 00:01:50.940
إذا كان لديك إحدى هذه، 
خلال ثوانِ، يمكنك معرفة الإجابة.

00:01:51.689 --> 00:01:53.988
ولكن هذه مجرد بداية أولية.

00:01:54.683 --> 00:01:58.014
حتى سيري مجرد آلة غير واعية.

00:01:58.480 --> 00:02:01.861
في الواقع، لمدة الثلاث ونصف
مليون سنة الأخيرة،

00:02:01.885 --> 00:02:04.994
كانت الأدوات التي لدينا 
غير واعية تمامًا.

00:02:06.023 --> 00:02:09.678
كانت تقوم بما نخبرها به ولا شيء أكثر.

00:02:09.702 --> 00:02:12.803
كانت أداتُنا الأولى تقطع حيثما نضربها

00:02:13.642 --> 00:02:16.682
يقطع المِنْقاش حيثما يصوبه الفنان.

00:02:17.163 --> 00:02:22.804
وحتى أدواتنا الأكثرتقدمًا، 
لا تقوم بشيء من دون توجيهنا المحدد.

00:02:22.828 --> 00:02:26.009
في الحقيقة، حتى هذا التاريخ، 
وهذا شئ يُحبطني،

00:02:26.033 --> 00:02:27.481
لقد كنا دائمًا مقيدين

00:02:27.505 --> 00:02:31.006
بالحاجة إلى الدفع يدويًا 
بإرادتنا إلى أداوتنا

00:02:31.030 --> 00:02:33.327
مثل، يدويًا، استعمال أيدينا حرفيًا،

00:02:33.351 --> 00:02:34.779
حتى مع الحواسيب.

00:02:35.892 --> 00:02:38.355
ولكني أشبه كثيرًا سكوتي 
في "ستار تريك."

00:02:38.379 --> 00:02:40.229
(ضحك)

00:02:40.253 --> 00:02:42.399
أريد إجراء محادثة 
مع حاسوب.

00:02:42.423 --> 00:02:45.393
أريد أن أقول، "أيها الحاسوب، 
لنصمم سيارة،"

00:02:45.417 --> 00:02:46.956
ويظهر الحاسوب لي سيارة.

00:02:46.980 --> 00:02:49.588
وأقول، "لا، ذات مظهر سريع أكثر،
وغير ألمانية.

00:02:49.612 --> 00:02:51.775
فرقعة، ويقدم لي الحاسوب خيارًا.

00:02:51.799 --> 00:02:53.664
(ضحك)

00:02:54.028 --> 00:02:56.334
قد تكون تلك محادثة
غير ممكنة بعض الشيء،

00:02:56.358 --> 00:02:59.023
ربما أقل مما يعتقد
الكثير منا،

00:02:59.047 --> 00:03:00.810
لكن الآن،

00:03:00.834 --> 00:03:01.985
نحن نعمل على ذلك.

00:03:02.009 --> 00:03:06.042
تقوم الأدوات بهذه القفزة من كونها 
غير واعية إلى كونها منتجة.

00:03:06.651 --> 00:03:09.959
تستخدم أدوات التصميم المُنتجة
حاسوب وخوارزميات

00:03:09.983 --> 00:03:12.591
لتشكيل هندسة

00:03:12.615 --> 00:03:15.369
تأتي بتصاميم ذاتية جديدة.

00:03:15.816 --> 00:03:18.564
كل ما تحتاجه هو أهدافك وتعليماتك.

00:03:18.588 --> 00:03:19.996
سأعطيكم مثالًا.

00:03:20.020 --> 00:03:22.808
في حالة هيكل الطائرة بدون طيار هذه،

00:03:22.832 --> 00:03:25.458
كل ما عليك فعله هو أن تخبره شيئًا مثل،

00:03:25.482 --> 00:03:26.755
أن لديه أربع أعمدة،

00:03:26.779 --> 00:03:28.910
تريدها أن تكون 
خفيفة الوزن قدر الإمكان،

00:03:28.934 --> 00:03:31.204
وتريدها أن تكون ذات 
فاعلية ديناميكية هوائية.

00:03:31.228 --> 00:03:36.142
ما يقوم به الحاسوب هو
استكشاف نطاق الحل كاملًا:

00:03:36.166 --> 00:03:40.093
كل إمكانية ستحل وتلبي معاييرك --

00:03:40.117 --> 00:03:41.559
الملايين منهم.

00:03:41.583 --> 00:03:43.558
يتطلب هذا حواسيب كبيرة.

00:03:43.582 --> 00:03:45.537
لكن الأمر يعود إلينا بالنسبة للتصاميم

00:03:45.561 --> 00:03:48.704
التي لم نكن، بأنفسنا، نتخيلها.

00:03:49.146 --> 00:03:52.058
وتقوم الحواسيب بذلك الأمر 
بذاتها بشكل كامل --

00:03:52.082 --> 00:03:53.760
لم يرسم أحد أي شيء.

00:03:53.784 --> 00:03:55.870
وبدأت تمامًا من الصفر.

00:03:56.858 --> 00:03:59.245
وبالمناسبة، ليست صدفة

00:03:59.269 --> 00:04:02.750
أن يشبه هيكل الطائرة بدون طيار
حوض السنجاب الطائر.

00:04:03.107 --> 00:04:05.114
(ضحك)

00:04:05.860 --> 00:04:08.162
ذلك لأن الخوارزميات صُمّمت للعمل

00:04:08.186 --> 00:04:09.823
بنفس طريقة التطور.

00:04:10.535 --> 00:04:13.195
المثير أننا بدأنا نرى هذه التكنولوجيا

00:04:13.219 --> 00:04:14.378
جَلية في العالم الواقعي.

00:04:14.402 --> 00:04:16.854
لقد عملنا مع أيرباص
لعدة سنوات

00:04:16.878 --> 00:04:18.787
على مفهوم الطائرة هذا للمستقبل.

00:04:18.811 --> 00:04:20.881
لم ترَ النور بعد.

00:04:20.905 --> 00:04:24.685
لكن مؤخرًا، استخدمنا تصميم ذو
ذكاء اصطناعي مُنتج.

00:04:24.709 --> 00:04:26.516
ليأتي بهذا.

00:04:27.429 --> 00:04:32.582
هذا قسم مقصورة ذات صورة
ثلاثية أبعاد صممها حاسوب.

00:04:32.606 --> 00:04:35.430
إنها أقوى من الحقيقية
و تزن نصف الوزن الحقيقي،

00:04:35.454 --> 00:04:38.600
وستطير في إيرباص A320 لاحقًا هذا العام.

00:04:39.225 --> 00:04:40.784
لذا يمكن للحواسيب أن تنتج الآن؛

00:04:40.808 --> 00:04:45.403
يمكنها تقديم حلولها الخاصة
لمشاكلنا المحددة.

00:04:46.497 --> 00:04:47.807
ولكنها ليست بديهية.

00:04:47.831 --> 00:04:50.917
فلا يزال عليها البدء من الصفر كل مرّة،

00:04:50.941 --> 00:04:53.506
ذلك لأنها لا تتعلم أبدًا.

00:04:54.188 --> 00:04:55.954
على عكس ماجي.

00:04:55.978 --> 00:04:57.559
(ضحك)

00:04:57.583 --> 00:05:00.880
ماجي في الحقيقة أذكى من
أدواتنا التصمّيمة الأكثر تقدمًا.

00:05:01.287 --> 00:05:02.727
ما الذي أعنيه بذلك؟

00:05:02.751 --> 00:05:04.341
إذا التقط صاحبها الرسن،

00:05:04.365 --> 00:05:06.433
تعرف ماجي بدرجة كبيرة من التأكد

00:05:06.457 --> 00:05:07.861
أنه حان وقت الذهاب للتنزه.

00:05:07.885 --> 00:05:09.070
وكيف تعلمت ذلك؟

00:05:09.094 --> 00:05:12.418
حسنًا، كلما يلتقط صاحبها الرسن،
يذهبان للتنزه.

00:05:12.442 --> 00:05:14.320
وقامت ماجي بثلاثة أشياء:

00:05:14.344 --> 00:05:16.213
كانت لابد أن تنتبه،

00:05:16.237 --> 00:05:18.319
وكانت لابد أن تتذكر ما حدث

00:05:18.343 --> 00:05:22.360
وكان عليها أن تحفظ مسارًا
في رأسها وتحدده.

00:05:23.249 --> 00:05:25.344
والمثير للاهتمام، هذا هو بالضبط

00:05:25.368 --> 00:05:27.891
يحاول علماء الحاسوب جَعل
الذكاء الإصطناعي يقوم بذلك

00:05:27.915 --> 00:05:29.774
لمدة 60 سنة الأخيرة أو ما يُقارب ذلك.

00:05:30.503 --> 00:05:31.852
بالعودة لعام 1952،

00:05:31.876 --> 00:05:35.677
صنعوا هذا الحاسوب الذي 
يصدر صوت تيك-تاك-تو

00:05:36.901 --> 00:05:38.061
أمر عظيم.

00:05:38.849 --> 00:05:41.849
ثم بعد 45 سنة، في عام 1997،

00:05:41.873 --> 00:05:44.345
هزم ديب بلو كاسباروف 
في لعبة الشطرنج.

00:05:45.866 --> 00:05:50.834
في 2011، هزم واتسون هذان
البشريان في جاباردي،

00:05:50.858 --> 00:05:53.786
وهو شيء أصعب للحاسوب
في اللعب من الشطرنج.

00:05:53.810 --> 00:05:57.622
في الحقيقة،

00:05:57.646 --> 00:06:00.969
احتاج وتسون لاستخدام المنطق حتى
يتغلب على خصومه البشريين.

00:06:02.213 --> 00:06:04.652
ومن ثم منذ بضعة أسابيع،

00:06:04.676 --> 00:06:08.938
هزم ديب ميند التابع لألفاجو
أفضل بشري في جو،

00:06:08.962 --> 00:06:11.174
والتى تعد أصعب لعبة لدينا.

00:06:11.198 --> 00:06:14.094
في الحقيقة، في جو، هناك المزيد
من التغيرات الممكنة

00:06:14.118 --> 00:06:16.142
أكثر من الذرات الموجودة في الكون.

00:06:18.030 --> 00:06:19.856
لذا للفوز،

00:06:19.880 --> 00:06:22.498
يجب على الفاجو أن يقوم بتطوير البديهة.

00:06:22.918 --> 00:06:27.028
وفي الواقع، في بعض النقاط،
لم يفهم مبرمجو الفاجو

00:06:27.052 --> 00:06:29.338
لما كان يقوم ألفاجو بما قام به.

00:06:31.271 --> 00:06:32.931
وتمضي الأشياء بسرعة كبيرة.

00:06:32.955 --> 00:06:36.182
أعني، فكروا في -- في نطاق العمر البشري،

00:06:36.206 --> 00:06:38.439
فقد انتقلت الحواسيب من كونها لعبة أطفال

00:06:39.740 --> 00:06:42.788
إلى كونها رأس التفكير الاستراتيجي.

00:06:43.819 --> 00:06:46.236
ما يحدث أساسيًا

00:06:46.260 --> 00:06:49.570
هو أن الحواسيب تنتقل من كونها شبه سبوك

00:06:49.594 --> 00:06:51.543
إلى كونها أكثر شبهًا بكيرك.

00:06:51.567 --> 00:06:55.185
(ضحك)

00:06:55.209 --> 00:06:58.633
صحيح؟ من المنطق البحت إلى البديهة.

00:07:00.004 --> 00:07:01.747
هل ستعبرون هذا الجسر؟

00:07:02.429 --> 00:07:04.752
يقول معظمكم، "اوه، لا بحق الجحيم!"

00:07:04.776 --> 00:07:06.084
(ضحك)

00:07:06.108 --> 00:07:08.765
وقد قررتم ذلك في جزء أقل من الثانية.

00:07:08.789 --> 00:07:11.217
تعرفون نوعًا ما بأن هذا الجسر غير آمن.

00:07:11.241 --> 00:07:13.230
وهذا بالتحديد هو البديهة

00:07:13.254 --> 00:07:16.822
التي بدأت أنظمتنا المعرفيّة 
المعقدة بتطويرها الآن.

00:07:17.542 --> 00:07:19.249
قريبًا، ستكونون حرفيًا قادرين على

00:07:19.273 --> 00:07:21.479
أن تظهروا شيء قد صنعتموه، أو صممتموه،

00:07:21.503 --> 00:07:22.656
إلى حاسوب،

00:07:22.680 --> 00:07:24.169
وسينظر إليه ويقول،

00:07:24.193 --> 00:07:27.016
"آسف، يا صاح، لن يصلح هذا أبدًا.
لابد أن تحاول مجددًا.

00:07:27.674 --> 00:07:30.744
أو قد تساله إذا ما كان الناس
سيحبون أُغنيتك التالية،

00:07:31.593 --> 00:07:33.656
او نكهتك التالية من الآيس كريم.

00:07:35.369 --> 00:07:37.948
أو ما هو أكثر أهميةً من ذلك،

00:07:37.972 --> 00:07:40.336
هو العمل مع حاسوب لحل مشكلة

00:07:40.360 --> 00:07:41.997
لم نواجهها من قبل.

00:07:42.021 --> 00:07:43.422
على سبيل المثال، تغير المناخ.

00:07:43.446 --> 00:07:45.466
نحن لا نقوم بعمل جيد بمفردنا،

00:07:45.490 --> 00:07:47.735
يمكننا بالتاكيد استخدام المساعدة 
التي يمكن أن نحصل عليها.

00:07:47.759 --> 00:07:49.217
هذا ما أتحدث عنه،

00:07:49.241 --> 00:07:51.796
تقوي التكنولوجيا قدراتنا الإدراكية

00:07:51.820 --> 00:07:55.372
بذلك يمكننا تخيل وتصميم أشياء
لم تكن في متناولنا

00:07:55.396 --> 00:07:57.955
كبشر غير متطورين وبسطاء.

00:07:59.804 --> 00:08:02.745
إذاً ماذا عن هذا
الشيء المجنون الجديد

00:08:02.769 --> 00:08:05.210
الذي سنخترعه وسنصممه؟

00:08:05.772 --> 00:08:09.865
أعتقد أن عصر التطور البشري
بقدر ما هو حول العالم المادي

00:08:09.889 --> 00:08:12.954
بقدر ما هو حول العالم الإفتراضي الفكري.

00:08:13.653 --> 00:08:15.574
إذًا كيف ستتطورنا التكنولوجيا؟

00:08:16.081 --> 00:08:18.554
في العالم المادي، الأنظمة الآلية.

00:08:19.440 --> 00:08:21.176
حسنًا، هناك بالتأكيد خوف من

00:08:21.200 --> 00:08:23.688
أن الأنظمة الحاسوبية ستأخذ وظائف البشر،

00:08:23.712 --> 00:08:25.542
وهذا حقيقي في بعض القطاعات.

00:08:25.994 --> 00:08:28.872
ولكني مهتم أكثر بهذه الفكرة

00:08:28.896 --> 00:08:33.906
أن عمل البشر والأنسان الآلي معًا
سيطور من بعضهم البعض،

00:08:33.930 --> 00:08:35.988
ويبدأون بشغل مجال جديد.

00:08:36.012 --> 00:08:38.374
هذا معملنا للبحث التطبيقي
في سان فرانسيسكو،

00:08:38.398 --> 00:08:41.540
حيث أحدى مجالات اهتماماتنا
هو علم الإنسان الآلي المتقدم،

00:08:41.564 --> 00:08:44.075
وبالأخص، التعاون البشري الآلي.

00:08:44.854 --> 00:08:47.613
وهذا بيشوب، إنسان آلي لدينا.

00:08:47.637 --> 00:08:49.426
كتجربة، أعددناه

00:08:49.450 --> 00:08:52.910
لمساعدة شخص يعمل في البناء
يقوم بمهام متكررة --

00:08:53.804 --> 00:08:57.998
مهام مثل حفر ثقوب مأخذ التيار 
أو مفاتيح الإضاءة في حائط الجبس.

00:08:58.022 --> 00:09:00.488
(ضحك)

00:09:01.697 --> 00:09:04.808
فالشريك البشري لبيشوب بإمكانه إخباره
بما يجب فعله بإنجليزية بسيطة

00:09:04.832 --> 00:09:06.137
وبإشارات بسيطة،

00:09:06.161 --> 00:09:07.608
نوعًا ما مثل التحدث إلى كلب،

00:09:07.632 --> 00:09:09.775
وبعدها ينفذ بيشوب وفقًا لتلك التعليمات

00:09:09.799 --> 00:09:11.691
بإحكام تام.

00:09:11.715 --> 00:09:14.704
نحن نستخدم البشر فيما هم جيدون فيه:

00:09:14.728 --> 00:09:17.061
الوعي و الإدراك واتخاذ القررات،

00:09:17.085 --> 00:09:19.325
ونستخدم الإنسان الآلي فيما هو جيد فيه:

00:09:19.349 --> 00:09:21.097
الانضباط والتكرار.

00:09:22.072 --> 00:09:24.439
وهنا مشروع ممتاز آخر يعمل به بيشوب.

00:09:24.463 --> 00:09:27.538
إن هدف هذا المشروع، الذي نسميه ال "هايف"،

00:09:27.562 --> 00:09:31.413
هو وضع تصميم أولي لتجربة
البشر والحواسيب والإنسان الآلي

00:09:31.437 --> 00:09:34.657
لعملهم معًا جميعًا لحل مشكلة
تصميم معقدة جدًا.

00:09:35.613 --> 00:09:37.064
يمثل البشر العمالة.

00:09:37.088 --> 00:09:40.561
هم يتجولون حول موقع البناء،
ويشكلون الخيزران --

00:09:40.585 --> 00:09:43.341
والذي بسبب كونه مادة غير تَشاكُلية،

00:09:43.365 --> 00:09:45.239
صعب جدًا على الإنسان
الآلي التعامل معها.

00:09:45.263 --> 00:09:47.285
من ثم يقوم الإنسان
الآلي بلف الألياف هذه،

00:09:47.309 --> 00:09:49.760
والذي كان مستحيل تقريبًا علي البشر فعله.

00:09:49.784 --> 00:09:53.405
ومن ثم كان لدينا الذكاء الصنعي
الذي يتحكم في كل شيء.

00:09:53.429 --> 00:09:56.719
كان يُملي على البشرما يجب عليهم فعله، 
والإنسان الآلي كذلك

00:09:56.743 --> 00:09:59.658
ويتتبع مسار آلاف المكونات الفردية.

00:09:59.682 --> 00:10:00.862
المثير للاهتمام أن،

00:10:00.886 --> 00:10:04.027
بناء هذا الجناح لم يكن ممكنًا

00:10:04.051 --> 00:10:08.575
بدون البشر والإنسان الآلي و الذكاء 
الصنعي بتطويرهم لبعضهم البعض.

00:10:09.710 --> 00:10:13.030
حسنًا، سأشارككم مشروع آخر.
و هو مجنون قليلًا.

00:10:13.054 --> 00:10:17.522
إننا نعمل مع فنان مقيم في أمستردام جوريس 
لارمان وفريقه في أم أكس ثري دي

00:10:17.546 --> 00:10:20.424
وذلك للتصميم بشكل إنتاجي والطباعة آليًا

00:10:20.448 --> 00:10:23.443
أول جسر في العالم مصنع بشكل استقلالي.

00:10:24.135 --> 00:10:27.820
وبذلك، يصمم جوريس و الذكاء
الصنعي هذا الشيء الآن، ونحن نتكلم،

00:10:27.844 --> 00:10:29.016
في أمستردام.

00:10:29.040 --> 00:10:31.361
وعندما ينتهون، سنعطي "إشارة البدء"

00:10:31.385 --> 00:10:34.696
وسيبدأ الإنسان الآلي برسم رسومات
ثلاثية الأبعاد على فولاذ مقاوم للصدأ.

00:10:34.720 --> 00:10:38.003
وبعدها سيواصلون الرسم من دون تدخل البشر،

00:10:38.027 --> 00:10:39.585
حتي ينتهي الجسر.

00:10:40.919 --> 00:10:43.847
لذا إن كانت الحواسيب ستطور من قدرتنا

00:10:43.871 --> 00:10:46.021
على تخيل وتصمم أشياء جديدة،

00:10:46.045 --> 00:10:48.940
فستساعدنا النُظم الآلية على بناء 
وتصنيع أشياء جديدة

00:10:48.964 --> 00:10:51.048
لم نكن قادرين على القيام بها من قبل.

00:10:52.167 --> 00:10:56.327
ولكن ماذا عن قدرتنا على الإدراك 
والتحكم في هذه الأشياء؟

00:10:56.351 --> 00:11:00.382
ماذا عن جهاز عصبي للأشياء التى نصنعها؟

00:11:00.406 --> 00:11:02.918
جهازنا العصبي، الجهازي العصبي البشري،

00:11:02.942 --> 00:11:05.253
يخبرنا بالأشياء التى تجري من حولنا.

00:11:06.006 --> 00:11:09.690
لكن الجهاز العصبي للأشياء التي
نصنعها بدائي في أحسن حالاته.

00:11:09.714 --> 00:11:13.277
مثلًا، السيارة لا تُخبر دائرة 
الأشغال العامة بالمدينة

00:11:13.301 --> 00:11:16.431
أنها قد اصطدمت في حفرة عند زاوية
برودواي و إيمرسون.

00:11:16.455 --> 00:11:18.487
وأن البناء لا يخبر مصمميه

00:11:18.511 --> 00:11:21.195
إن ما كان الناس بداخله
يحبون التواجد فيه أم لا،

00:11:21.219 --> 00:11:24.229
ولايعرف مصمم لعُبة

00:11:24.253 --> 00:11:26.260
إن كان يُلعب بها --

00:11:26.284 --> 00:11:28.823
كيف وأين وإذا ما كانت ممتعة أو لا.

00:11:29.440 --> 00:11:33.254
انظروا، أنا متأكد أن المصممين
تخيلوا نظام الحياة هذا لباربي

00:11:33.278 --> 00:11:34.502
وهم يصممونها.

00:11:34.526 --> 00:11:35.973
(ضحك)

00:11:35.997 --> 00:11:38.903
لكن ماذا لو بدا أن باربي في الواقع وحيدة؟

00:11:38.927 --> 00:11:42.074
(ضحك)

00:11:43.086 --> 00:11:44.374
لو كان يعلم المصممون

00:11:44.398 --> 00:11:46.505
ما كان يحدث في العالم الواقعي

00:11:46.529 --> 00:11:49.112
مع تصميماتهم -- الطريق، البناء، باربي --

00:11:49.136 --> 00:11:51.830
لكانوا استخدموا هذه المعرفة لخلق تجربة

00:11:51.854 --> 00:11:53.254
أفضل للمستخدم.

00:11:53.278 --> 00:11:55.069
ما ينقص هو جهاز عصبي

00:11:55.093 --> 00:11:58.802
يربطنا بجميع الأشياء التي
نُصممها ونصنعها ونستخدمها.

00:11:59.735 --> 00:12:03.290
ماذا لو كان لديكم هذا النوع 
من المعلومات التي تأتي اليكم

00:12:03.314 --> 00:12:05.497
من الأشياء التي تصنعونها
في العالم الواقعي.

00:12:07.252 --> 00:12:08.703
مع كل هذه الأشياء التي نصنعها،

00:12:08.727 --> 00:12:11.162
قد أنفقنا كم هائل من المال والطاقة --

00:12:11.186 --> 00:12:13.562
فى الواقع، العام الماضي،
حوالي 2 تريليون دولارًا --

00:12:13.586 --> 00:12:16.440
لإقناع الناس بشراء الأشياء التي صنعناها .

00:12:16.464 --> 00:12:19.852
لكن إن كان لديكم هذه العلاقة بين
الأشياء التي تصممونها وتصنعونها

00:12:19.876 --> 00:12:21.603
بعدما كانوا في العالم الخارجي،

00:12:21.627 --> 00:12:25.241
بعد بيعهم أو اطلاقهم أو أيًا كان،

00:12:25.265 --> 00:12:26.885
بإمكاننا فعليًا تغيير ذلك،

00:12:26.909 --> 00:12:29.956
ونتحول من جذب الناس لشراء أشياءنا،

00:12:29.980 --> 00:12:33.414
إلى تصنيع الأشياء التي يريدها
الناس في المقام الأول.

00:12:33.438 --> 00:12:36.225
الأخبار الجيدة هى أننا نعمل على
جهاز عصبي رقمي

00:12:36.249 --> 00:12:39.050
يربطنا بالأشياء التي نصممها.

00:12:40.185 --> 00:12:41.812
نعمل على مشروع

00:12:41.836 --> 00:12:45.548
مع بعض الرفاق في لوس أنجلوس
يسمون "بانديتو برازرز"

00:12:45.572 --> 00:12:46.979
وفريقهم.

00:12:47.003 --> 00:12:50.436
وأحد الأشياء التي يقوم بها هؤلاء
الرفاق هو تصميم سيارات مجنونة

00:12:50.460 --> 00:12:53.333
والتي تقوم بالطبع بأشياء مجنونة.

00:12:54.725 --> 00:12:56.175
هؤلاء الرفاق مجانين--

00:12:56.199 --> 00:12:57.235
(ضحك)

00:12:57.259 --> 00:12:58.662
بأفضل حال.

00:13:00.813 --> 00:13:02.576
وما نفعله معهم

00:13:02.600 --> 00:13:05.040
هو أخد هيكل سيارة سباق تقليدية

00:13:05.064 --> 00:13:06.649
وإعطاءه جهاز عصبي.

00:13:06.673 --> 00:13:09.731
وعليه فقد جهزها بعشرات
من أجهزة الاستشعار،

00:13:09.755 --> 00:13:12.390
وجعلنا سائق ذو تصنيف عالمي يقودها،

00:13:12.414 --> 00:13:15.771
وأخذها خارجًا الى الصحراء
وقادها لمدة أسبوع.

00:13:15.795 --> 00:13:18.286
والتقط الجهاز العصبي للسيارة كل شيء

00:13:18.310 --> 00:13:19.792
كان يحدث للسيارة.

00:13:19.816 --> 00:13:22.437
لقد جمعنا 4 بليون نقطة معلومات؛

00:13:22.461 --> 00:13:24.771
جميعها من القوى التي خضعت لها.

00:13:24.795 --> 00:13:26.454
وبعدها قمنا بشيء مجنون.

00:13:27.088 --> 00:13:28.588
أخذنا كل تلك المعلومات،

00:13:28.612 --> 00:13:32.348
ووصلناها الى تصميم إنتاجي للذكاء الصنعي
أسميناه " دريمكاتشر."

00:13:33.090 --> 00:13:37.054
إذًأ ماذا يحدث عندما تعطي 
جهاز عصبي لآلة تصميم،

00:13:37.078 --> 00:13:39.960
وطلبت منها أن تصمم لك هيكل سيارة نهائي؟

00:13:40.543 --> 00:13:42.516
ستحصل على هذا.

00:13:44.113 --> 00:13:47.826
هذا شيء لم يمكن لإنسان أن يصممه أبدًا.

00:13:48.527 --> 00:13:50.415
باستثناء إنسان واحد قام بتصميمه،

00:13:50.439 --> 00:13:54.748
لكنه كان إنسان قد تطورعن طريق
تصميم إنتاجي للذكاء الصنعي،

00:13:54.772 --> 00:13:56.003
و نظام عصبي رقمي

00:13:56.027 --> 00:13:59.032
و إنسان آلي بإمكانه أن يصنع شيء مثل هذا.

00:13:59.500 --> 00:14:03.095
لذا، إذا كان هذا هو المستقبل،
والعصر المتطور

00:14:03.119 --> 00:14:07.380
وسنتطور معرفيًا وماديًا وإدراكيًا،

00:14:07.404 --> 00:14:08.812
كيف سيبدوا هذا؟

00:14:09.396 --> 00:14:12.717
كيف ستبدو أرض العجائب هذه؟

00:14:12.741 --> 00:14:14.450
أعتقد أننا سنرى عالم

00:14:14.474 --> 00:14:17.542
حيث سننتقل من الأشياء المصنعة

00:14:17.566 --> 00:14:19.011
الى الأشياء المزروعة.

00:14:19.979 --> 00:14:23.432
وحيث سننتقل من الأشياء المبنية

00:14:23.456 --> 00:14:25.160
إلى تلك النامية.

00:14:25.954 --> 00:14:28.142
سنتحول من كوننا منعزلين

00:14:28.166 --> 00:14:29.776
إلى كوننا متواصلين.

00:14:30.454 --> 00:14:32.865
وسنبتعد عن الاستخراج

00:14:32.889 --> 00:14:34.762
إلى قبول التجميع.

00:14:35.787 --> 00:14:39.554
أعتقد أيضًا أننا سنغير من
الرغبة في انقياد الأشياء لنا

00:14:39.578 --> 00:14:41.219
إلى تقدير التحكم الذاتي.

00:14:42.330 --> 00:14:44.235
بفضل قدراتنا المطورة،

00:14:44.259 --> 00:14:46.636
سيتغيرعالمنا بشكل كبير.

00:14:47.396 --> 00:14:50.642
سيكون لدينا عالم ذو تنوع أكثر،
وذو اتصال أكبر،

00:14:50.666 --> 00:14:52.953
وذو دينامكية أكثر، وتعقيد أكبر،

00:14:52.977 --> 00:14:55.295
وأكثر تكيفًا، وبالطبع،

00:14:55.319 --> 00:14:56.536
أكثر جمالًا.

00:14:57.051 --> 00:14:58.615
شكل الأشياء المستقبلية

00:14:58.639 --> 00:15:00.929
سيكون مختلف عن الأشياء
التي رأيناها من قبل.

00:15:00.953 --> 00:15:02.112
لماذا؟

00:15:02.136 --> 00:15:05.891
لأن من سيشكل تلك الأشياء
هي تلك الشراكة الجديدة

00:15:05.915 --> 00:15:09.585
بين التكنولوجيا والطبيعة والإنسانية.

00:15:11.099 --> 00:15:14.903
ذلك، بالنسبة لي،
مستقبل جدير بأن يُتطلع إليه.

00:15:14.927 --> 00:15:16.198
الشكر لكم جميعًا.

00:15:16.222 --> 00:15:21.891
(تصفيق)

