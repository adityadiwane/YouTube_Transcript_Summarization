WEBVTT
Kind: captions
Language: tr

00:00:00.000 --> 00:00:07.000
Çeviri: Cihan Ekmekçi
Gözden geçirme: Selda Yener

00:00:12.555 --> 00:00:14.844
Aramızda kaçınız yaratıcı?

00:00:14.868 --> 00:00:18.492
Kaçınız tasarımcı, mühendis,
girişimci, aktör

00:00:18.516 --> 00:00:20.903
veya sadece büyük bir
hayal gücünüz var?

00:00:20.927 --> 00:00:22.775
Elleri göreyim?

00:00:22.799 --> 00:00:23.980
Demek ki çoğunuz.

00:00:25.154 --> 00:00:27.448
Biz yaratıcılar için haberlerim var.

00:00:28.534 --> 00:00:31.107
Önümüzdeki 20 yıl içinde,

00:00:33.291 --> 00:00:36.264
geçtiğimiz son 2000 yıla kıyasla
çalışma şeklimiz

00:00:37.202 --> 00:00:39.359
çok daha fazla değişecek.

00:00:40.331 --> 00:00:44.959
Hatta bence insanlık tarihinde
yeni bir çağın eşiğindeyiz.

00:00:45.465 --> 00:00:50.226
Çalışma şeklimize göre
dört temel tarihi çağ geçirdik.

00:00:51.224 --> 00:00:54.499
Avcı-Toplayıcı Çağı 
birkaç milyon yıl sürdü.

00:00:54.983 --> 00:00:58.559
Sonra birkaç bin yıl süren
Tarım Çağı.

00:00:59.015 --> 00:01:02.505
Ardından birkaç yüzyıl süren
Sanayi Çağı.

00:01:02.529 --> 00:01:06.816
Şimdi ise henüz onlarca yıldır
süregelen Bilgi Çağı'ndayız.

00:01:06.840 --> 00:01:12.060
Bugün insan türü olarak yeni bir
büyük çağın kıyısındayız.

00:01:13.116 --> 00:01:15.796
Artırılmış Çağ'a hoş geldiniz.

00:01:15.820 --> 00:01:19.513
Bu yeni çağda doğal insani yetileriniz

00:01:19.537 --> 00:01:22.605
düşünmenize yardım eden
bilgisayar sistemleri,

00:01:22.629 --> 00:01:24.815
üretmenize yardım eden
robotik sistemler

00:01:24.839 --> 00:01:26.487
ve doğal duyularınızın ötesinde

00:01:26.511 --> 00:01:30.201
sizi dünyaya bağlayan dijital 
bir sinir sistemi ile güçlendirilecek.

00:01:31.257 --> 00:01:32.999
Bilişsel artırma ile başlayalım.

00:01:33.246 --> 00:01:34.739
Kaçınız güçlendirilmiş sayborg?

00:01:35.953 --> 00:01:38.603
(Kahkahalar)

00:01:38.627 --> 00:01:41.448
Ben de zaten artırılmış
olduğumuzu iddia ediyordum.

00:01:42.108 --> 00:01:43.612
Bir partide olduğunuzu

00:01:43.636 --> 00:01:47.156
ve birinin size cevabını bilmediğiniz
bir soru sorduğunu düşünün.

00:01:47.180 --> 00:01:50.940
Eğer elinizde bunlardan bir tane varsa,
birkaç saniyede cevabı bulursunuz.

00:01:51.689 --> 00:01:53.988
Fakat bu sadece ilkel bir başlangıç.

00:01:54.683 --> 00:01:58.014
Siri bile sadece pasif bir araç.

00:01:58.480 --> 00:02:01.861
Aslına bakarsanız
son üç buçuk milyon yıldır

00:02:01.885 --> 00:02:04.994
kullandığımız tüm araçlar
tamamen pasifti.

00:02:06.023 --> 00:02:09.678
Yalnızca söylediğimizi yapıyorlar,
başka bir şey değil.

00:02:09.702 --> 00:02:12.803
Kullandığımız ilk araç yalnızca
onu sapladığımız yeri kesiyordu.

00:02:13.642 --> 00:02:16.682
Matkap yalnızca kullananın
işaretlediği noktayı deliyor.

00:02:17.163 --> 00:02:22.804
Hatta en gelişmiş araçlarımız bile biz 
yönlendirmeden hiçbir şey yapmıyorlar.

00:02:22.828 --> 00:02:26.009
Aslında beni hayal kırıklığına
uğratan şey şu;

00:02:26.033 --> 00:02:27.481
biz her zaman irademizi

00:02:27.505 --> 00:02:31.006
fiziksel yollarla araçlara 
yönlendirerek kısıtladık;

00:02:31.030 --> 00:02:33.327
fiziksel derken gerçekten
ellerimizi kullanarak,

00:02:33.351 --> 00:02:34.779
bilgisayarda bile.

00:02:35.892 --> 00:02:38.355
Ama ben ''Uzay Yolu''ndaki Scotty gibiyim.

00:02:38.379 --> 00:02:40.229
(Kahkahalar)

00:02:40.253 --> 00:02:42.399
Bir bigisayarla sohbet etmek istiyorum.

00:02:42.423 --> 00:02:45.393
''Hey bilgisayar, hadi bir araba
tasarlayalım.'' demek,

00:02:45.417 --> 00:02:47.386
bilgisayar da bana
araba çizsin istiyorum.

00:02:47.386 --> 00:02:50.678
Sonra ''hayır, daha sağlam
ve Alman işi gibi olmasın'' desem

00:02:50.678 --> 00:02:52.595
ve bilgisayar bir seçenek gösterse.

00:02:52.595 --> 00:02:53.664
(Kahkahalar)

00:02:54.028 --> 00:02:56.334
Bu sohbet biraz uçarı olabilir,

00:02:56.358 --> 00:02:59.023
muhtemelen çoğumuzun 
düşündüğünden az,

00:02:59.047 --> 00:03:00.810
ama şu an

00:03:00.834 --> 00:03:02.085
bunun üzerine çalışıyoruz.

00:03:02.085 --> 00:03:06.042
Araçlar pasif olmaktan
üretken olmaya doğru çığır atlıyor.

00:03:06.651 --> 00:03:09.959
Üretken tasarımlı araçlar
bilgisayar ve algoritma kullanarak

00:03:09.983 --> 00:03:12.591
geometri sentezi yapıp

00:03:12.615 --> 00:03:15.369
tamamen kendi başlarına
yeni tasarımlar ortaya atıyorlar.

00:03:15.816 --> 00:03:18.564
Tek ihtiyacı olan şey sizin
hedef ve filtreleriniz.

00:03:18.588 --> 00:03:19.996
Bir örnek vereyim:

00:03:20.020 --> 00:03:22.808
Bu insansız hava aracı şasesinde

00:03:22.832 --> 00:03:25.458
tek yapmanız gereken 
ona bir şey söylemek.

00:03:25.482 --> 00:03:26.755
Aracın dört pervanesi var,

00:03:26.779 --> 00:03:28.910
mümkün olduğu kadar
hafif olsun istiyorsunuz

00:03:28.934 --> 00:03:31.204
ve aerodinamik olarak
çalışması gerek.

00:03:31.228 --> 00:03:36.142
İşte bu noktada bilgisayar 
tüm çözümleri tarıyor:

00:03:36.166 --> 00:03:40.093
Kriterlerinize uygun her bir 
olasılığı çözüp karşılayan --

00:03:40.117 --> 00:03:41.559
milyonlarca olasılığı.

00:03:41.583 --> 00:03:43.558
Bunun için büyük bilgisayarlar gerek.

00:03:43.582 --> 00:03:45.537
Fakat konu bizi

00:03:45.561 --> 00:03:48.704
hayal dahi edemeyeceğimiz 
tasarımlara getirir.

00:03:49.146 --> 00:03:52.058
Bilgisayar bütün bunları
tek başına yapıyor-

00:03:52.082 --> 00:03:53.760
hiç kimse bir çizim yapmadı

00:03:53.784 --> 00:03:55.870
ve tamamen sıfırdan başladı.

00:03:56.858 --> 00:03:59.245
Bu arada hava aracının

00:03:59.269 --> 00:04:02.750
uçan bir sincabın iç kısmına
benzemesi de tesadüf değil.

00:04:03.107 --> 00:04:05.114
(Kahkahalar)

00:04:05.860 --> 00:04:08.162
Bunun sebebi algoritmaların
evrim mantığıyla

00:04:08.186 --> 00:04:09.823
çalışacak şekilde tasarlanması.

00:04:10.535 --> 00:04:13.195
İşin heyecan verici kısmıysa
bu teknolojiyi

00:04:13.219 --> 00:04:14.838
gerçek hayatta görmeye başlamamız.

00:04:14.838 --> 00:04:16.854
Birkaç yıldır Airbus'la birlikte

00:04:16.878 --> 00:04:18.787
geleceğin uçakları üzerine çalışıyoruz.

00:04:18.811 --> 00:04:20.881
Henüz olması mümkün değil.

00:04:20.905 --> 00:04:24.685
Fakat kısa süre önce
bunu başarmak için üretken tasarımlı

00:04:24.709 --> 00:04:26.516
yapay zekâ kullandık.

00:04:27.429 --> 00:04:32.582
Bu, bilgisayar tarafından tasarlanmış
bir kabin bölmesinin 3B gösterimi.

00:04:32.606 --> 00:04:35.430
Orijinalinden daha güçlü
ama yarısı ağırlığında

00:04:35.454 --> 00:04:38.600
ve bu yıl Airbus A320 ile
uçuyor olacak.

00:04:39.225 --> 00:04:41.064
Yani bilgisayarlar artık üretebiliyor;

00:04:41.064 --> 00:04:45.403
bizim iyi tanımladığımız sorunlara
kendi çözümlerini bulabiliyorlar.

00:04:46.497 --> 00:04:47.807
Ama sezgisel değiller.

00:04:47.831 --> 00:04:50.917
Her seferinde sıfırdan
başlamaları gerek,

00:04:50.941 --> 00:04:53.506
çünkü hiçbir zaman öğrenmiyorlar.

00:04:54.188 --> 00:04:55.954
Maggie öyle değil ama.

00:04:55.978 --> 00:04:57.559
(Kahkahalar)

00:04:57.583 --> 00:05:00.880
Maggie aslında çoğu ileri tasarım
araçlarımızdan daha akıllı.

00:05:01.287 --> 00:05:02.727
Peki ben ne demek istiyorum?

00:05:02.751 --> 00:05:04.341
Sahibi tasmayı eline aldığında

00:05:04.365 --> 00:05:06.433
Maggie neredeyse kendinden
emin bir şekilde

00:05:06.457 --> 00:05:07.951
yürüyüşe çıkacaklarını biliyor.

00:05:07.951 --> 00:05:09.070
Nasıl öğrendi peki?

00:05:09.094 --> 00:05:12.418
Çünkü sahibi tasmayı her aldığında
yürüyüşe çıktılar.

00:05:12.442 --> 00:05:14.320
Maggie üç şey yaptı:

00:05:14.344 --> 00:05:16.213
Dikkat verdi,

00:05:16.237 --> 00:05:18.319
ne olduğunu hatırladı

00:05:18.343 --> 00:05:22.360
ve bunu aklında tutup
kafasında bir şablon oluşturdu.

00:05:23.249 --> 00:05:25.344
İşin ilginç yanı, bu tam da

00:05:25.368 --> 00:05:27.891
son 60 yıldır bilgisayar
bilimcilerin Yapay Zekâ

00:05:27.915 --> 00:05:29.774
üzerinde yapmak istedikleri şey.

00:05:30.503 --> 00:05:31.852
1952 yılında,

00:05:31.876 --> 00:05:35.677
XOXO oynayabilen bu
bilgisayarı geliştirdiler.

00:05:36.901 --> 00:05:38.061
Büyük başarı.

00:05:38.849 --> 00:05:41.849
45 yıl sonra 1997 yılında,

00:05:41.873 --> 00:05:44.345
Deep Blue satrançta Kasparov'u yendi.

00:05:45.866 --> 00:05:50.834
2011'de Watson bu iki kişiyi
bilgi yarışmasında yendi,

00:05:50.858 --> 00:05:53.786
ki bu satranç oynamaktan 
daha zordur bilgisayar için.

00:05:53.810 --> 00:05:57.622
Gerçek şu ki, önceden belirtilmiş
talimatlarla çalışmak yerine

00:05:57.646 --> 00:06:00.969
Watson bu insan rakiplerini 
yenmek için mantık kullandı.

00:06:02.213 --> 00:06:04.652
Yine birkaç hafta önce,

00:06:04.676 --> 00:06:08.938
DeepMind'ın AlphaGo robotu
Go oyununda dünya birincisini yendi,

00:06:08.962 --> 00:06:11.174
bu sahip olduğumuz en zor oyun.

00:06:11.198 --> 00:06:14.094
Go oyununda, evrendeki atom
sayısından çok

00:06:14.118 --> 00:06:16.142
hamle olasılığı var.

00:06:18.030 --> 00:06:19.856
Yani kazanmak için

00:06:19.880 --> 00:06:22.498
AlphaGo'nın sezgi geliştirmesi gerekliydi.

00:06:22.918 --> 00:06:27.028
Yine bazı noktalarda,
AlphaGo'nun programcıları

00:06:27.052 --> 00:06:29.338
onun neyi niçin yaptığını anlayamadılar.

00:06:31.271 --> 00:06:32.991
İşler çok hızlı bir şekilde işliyor.

00:06:32.991 --> 00:06:36.182
Bir düşünün,
insan hayatı boyunca

00:06:36.206 --> 00:06:38.439
bilgisayarlar bir çocuk oyunundan

00:06:39.740 --> 00:06:42.788
stratejik düşüncenin zirvesi 
kabul edilen bir oyuna yöneldi.

00:06:43.819 --> 00:06:46.236
Burada olan şey şu;

00:06:46.260 --> 00:06:49.570
bilgisayarlar Spock olmaktan çıkıp

00:06:49.594 --> 00:06:51.543
Kirk olmaya başlıyorlar.

00:06:51.567 --> 00:06:55.185
(Kahkahalar)

00:06:55.209 --> 00:06:58.633
Basit mantıktan sezgiye.

00:07:00.004 --> 00:07:01.747
Bu köprüden geçer miydiniz?

00:07:02.429 --> 00:07:04.752
Çoğunuz ''hayatta olmaz!'' diyor

00:07:04.776 --> 00:07:06.084
(Kahkahalar)

00:07:06.108 --> 00:07:08.765
Bu kararı vermeniz 
saniyeden kısa sürdü.

00:07:08.789 --> 00:07:11.217
Köprünün güvenli 
olmadığını biliyordunuz.

00:07:11.241 --> 00:07:13.230
İşte bu tam da derin öğrenme

00:07:13.254 --> 00:07:16.822
sistemlerimizin geliştirmeye 
çalıştıkları türden bir sezgi.

00:07:17.542 --> 00:07:19.249
Çok yakında, yaptığınız,

00:07:19.273 --> 00:07:21.479
tasarladığınız bir şeyi
bir bilgisayara

00:07:21.503 --> 00:07:22.656
gösterebileceksiniz.

00:07:22.680 --> 00:07:24.169
O da bakıp şöyle diyecek,

00:07:24.193 --> 00:07:27.016
''Olmaz, kanka, işe yaramaz,
baştan yapman lazım.''

00:07:27.674 --> 00:07:30.744
İnsanlar yeni şarkınızı beğenecek mi 
veya hangi dondurmayı

00:07:31.593 --> 00:07:33.656
alacağınızı da sorabilirsiniz.

00:07:35.369 --> 00:07:37.948
Veya daha da önemlisi

00:07:37.972 --> 00:07:40.336
daha önce hiç karşılaşmadığımız
bir sorunla ilgili

00:07:40.360 --> 00:07:41.997
bilgisayarla çalışabilirsiniz.

00:07:42.021 --> 00:07:43.422
Örneğin iklim değişikliği.

00:07:43.446 --> 00:07:45.466
Kendi başımıza 
pek bir iş başaramıyoruz.

00:07:45.490 --> 00:07:47.735
Alabileceğimiz her yardıma
ihtiyacımız var.

00:07:47.759 --> 00:07:49.217
İşte söylemek istediğim bu;

00:07:49.241 --> 00:07:51.796
teknolojinin bilişsel 
yetilerimizi kuvvetlendirmesi,

00:07:51.820 --> 00:07:55.372
böylelikle artırılmamış insan olarak
erişemeyeceğimiz şeyleri

00:07:55.396 --> 00:07:57.955
hayal edip tasarlamak.

00:07:59.804 --> 00:08:02.745
Gelelim icat edip

00:08:02.769 --> 00:08:05.210
tasarlayacağımız onca çılgınca şeye.

00:08:05.772 --> 00:08:09.865
Sanırım insan artırma çağı,
sanal ve düşünsel olduğu kadar

00:08:09.889 --> 00:08:12.954
fiziksel dünyayla da alakalı.

00:08:13.653 --> 00:08:15.574
Teknoloji bizi nasıl güçlendirecek?

00:08:16.081 --> 00:08:18.554
Fiziksel dünyada; robotlar.

00:08:19.440 --> 00:08:21.176
Robotların insanların işine

00:08:21.200 --> 00:08:23.688
mal olacağı konusunda
ciddi bir korku var,

00:08:23.712 --> 00:08:25.542
bazı sektörler için bu doğru.

00:08:25.994 --> 00:08:28.872
Ama benim ilgimi çeken, 
insan ve robotların

00:08:28.896 --> 00:08:33.906
birlikte çalışarak 
birbirlerini güçlendirecek olması

00:08:33.930 --> 00:08:35.988
ve yeni bir alanda yaşamaya başlamaları.

00:08:36.012 --> 00:08:38.824
Bu San Francisco'daki uygulamalı 
araştırma laboratuvarımız.

00:08:38.824 --> 00:08:41.540
Buradaki çalışmalarımızdan 
biri ileri robotlar,

00:08:41.564 --> 00:08:44.075
özellikle de insan-robot işbirliği.

00:08:44.854 --> 00:08:47.613
Bu Bishop, robotlarımızdan biri.

00:08:47.637 --> 00:08:49.426
Deney amaçlı, sürekli aynı

00:08:49.450 --> 00:08:52.910
hareketleri yapan bir inşaat işçisine
yardım etmesi için ayarladık,

00:08:53.804 --> 00:08:57.998
kuru duvarda priz veya lambalar 
için delik açma gibi görevler.

00:08:58.022 --> 00:09:00.488
(Kahkahalar)

00:09:01.697 --> 00:09:04.808
Bishop'ın insan ortağı
basit bir dil ve jestlerle

00:09:04.832 --> 00:09:06.137
ne yapacağını söylüyor;

00:09:06.161 --> 00:09:07.608
bir köpekle konuşmak gibi,

00:09:07.632 --> 00:09:09.775
sonra Bishop
mükemmel bir dikkatle

00:09:09.799 --> 00:09:11.691
bu talimatları uyguluyor.

00:09:11.715 --> 00:09:14.704
İnsanı iyi olduğu şey için kullanıyoruz:

00:09:14.728 --> 00:09:17.061
Farkındalık, algı ve karar verme.

00:09:17.085 --> 00:09:19.325
Robotu da iyi olduğu alanda:

00:09:19.349 --> 00:09:21.097
Dikkat ve tekrar etme.

00:09:22.072 --> 00:09:24.439
Bishop'ın iyi olduğu
güzel bir proje daha var.

00:09:24.463 --> 00:09:27.538
HIVE diye adlandırdığımız
bu projenin amacı,

00:09:27.562 --> 00:09:31.413
aşırı karmaşık bir tasarım
sorununu çözmek için insan,

00:09:31.437 --> 00:09:34.657
bilgisayar ve robotların ortak 
çalışma tecrübesini örnek almak.

00:09:35.613 --> 00:09:37.064
İnsanlar iş gücü oldular.

00:09:37.088 --> 00:09:40.561
İnşaat alanında gezdiler,
bambuyu sürekli değiştirdiler,

00:09:40.585 --> 00:09:43.341
ki bambu eşbiçimli bir 
materyal olmadığı için

00:09:43.365 --> 00:09:45.239
robotların çalışması çok zordur.

00:09:45.263 --> 00:09:47.505
Sonra robotlar bu fiber
bağlamayı gerçekleştirdi,

00:09:47.505 --> 00:09:49.760
insanın bunu yapması 
neredeyse imkânsızdı.

00:09:49.784 --> 00:09:53.405
Bir de her şeyi kontrol eden
bir Yapay Zekâmız vardı.

00:09:53.429 --> 00:09:56.719
İnsanlara ve robotlara
yapması gerekenleri söyleyip

00:09:56.743 --> 00:09:59.658
binlerce bireysel bileşenin
kaydını tutuyordu.

00:09:59.682 --> 00:10:00.862
İlginç olan şeyse,

00:10:00.886 --> 00:10:04.027
insan, robot ve yapay zekânın
birbirini güçlendirmeden

00:10:04.051 --> 00:10:08.575
bu terası inşa etmesinin
kesinlikle mümkün olmamasıydı.

00:10:09.710 --> 00:10:13.030
Bir proje daha göstereceğim.
Bu biraz çılgınca.

00:10:13.054 --> 00:10:17.522
Amsterdamlı ressam Joris Laarman ve
MX3D'deki takımı ile çalışıyoruz,

00:10:17.546 --> 00:10:20.424
amacımız üretken tasarım ve
robotik yazdırma ile

00:10:20.448 --> 00:10:23.443
dünyanın ilk özerk inşa
edilmiş köprüsünü yapmak.

00:10:24.135 --> 00:10:27.820
Şu anda Joris ve Yapay Zekâ
Amsterdam'da bunun

00:10:27.844 --> 00:10:29.016
üzerine çalışıyorlar.

00:10:29.040 --> 00:10:31.361
İşleri bitince sadece
bir tuşa basacağız

00:10:31.385 --> 00:10:34.696
ve robotlar paslanmaz çelik üzerine
3B çıkışlar alacak,

00:10:34.720 --> 00:10:38.003
sonra insan olmadan buna
devam edecekler,

00:10:38.027 --> 00:10:39.585
ta ki köprü tamamlanana kadar.

00:10:40.919 --> 00:10:43.847
Bilgisayarlar yeni şeyler
hayal etme ve tasarlama

00:10:43.871 --> 00:10:46.021
yetilerimizi güçlendirirken

00:10:46.045 --> 00:10:48.940
robotik sistemler daha önce
hiç yapamadğımız

00:10:48.964 --> 00:10:51.048
şeyler yapmamıza yardım edecekler.

00:10:52.167 --> 00:10:56.327
Peki ya bunları hissetme ve
kontrol etme yetimiz?

00:10:56.351 --> 00:11:00.382
Yaptığımız şeyler için bir 
sinir sistemi olmayacak mı?

00:11:00.406 --> 00:11:02.918
İnsanın sinir sistemi

00:11:02.942 --> 00:11:05.253
çevremizde olan her şeyi bize bildirir.

00:11:06.006 --> 00:11:09.690
Ama kendi yaptığımız şeylerin
sinir sistemi gelişmemiş.

00:11:09.714 --> 00:11:13.277
Örneğin, bir araba gidip belediyeye 
Broadway ve Morrison'ın köşe başında

00:11:13.301 --> 00:11:16.431
bir çukur olduğunu ve 
üstünden geçtiğini söylemez.

00:11:16.455 --> 00:11:18.547
Bir bina, tasarımcılarına
içindeki insanların

00:11:18.547 --> 00:11:21.195
orada olmaktan memnun olup
olmadıklarını söylemez,

00:11:21.219 --> 00:11:24.229
oyuncak üreticisi o oyuncakla

00:11:24.253 --> 00:11:26.260
gerçekten oynandığını bilemez,

00:11:26.284 --> 00:11:28.823
şu an nerede veya 
oynaması zevkli mi bilemez.

00:11:29.440 --> 00:11:33.254
Ama şuna eminim ki tasarımcılar
Barbie'yi yaptıklarında,

00:11:33.278 --> 00:11:34.972
ona bu hayat tarzını yakıştırdılar.

00:11:34.972 --> 00:11:35.973
(Kahkahalar)

00:11:35.997 --> 00:11:38.903
Barbie kendini yalnız
hissederse ne olur peki?

00:11:38.927 --> 00:11:42.074
(Kahkahalar)

00:11:43.086 --> 00:11:44.374
Tasarımcılar gerçek dünyada

00:11:44.398 --> 00:11:46.505
neler olduğunu bilseler

00:11:46.529 --> 00:11:49.112
yol, bina veya Barbie fark etmez,

00:11:49.136 --> 00:11:51.830
bu bilgiyi kullanıcı için

00:11:51.854 --> 00:11:53.254
daha iyi hâle getirebilirler.

00:11:53.278 --> 00:11:55.069
Burada eksik olan şey tasarladığımız,

00:11:55.093 --> 00:11:58.802
yapıp kullandığımız şeylere
ilişkin bir sinir sistemi.

00:11:59.735 --> 00:12:03.290
Gerçek hayatta yarattığınız
şeylerden bu tür bir

00:12:03.314 --> 00:12:05.497
geri bildirim alsanız nasıl olurdu?

00:12:07.252 --> 00:12:08.743
Yaptığımız onca şeyi düşününce-

00:12:08.743 --> 00:12:11.162
inanılmaz para ve enerji harcıyoruz-

00:12:11.186 --> 00:12:13.562
geçen yıl insanları 
yaptığımız şeyleri almaya

00:12:13.586 --> 00:12:16.440
ikna etmek için
2 trilyon dolar harcanmış.

00:12:16.464 --> 00:12:19.852
Satılmış veya kullanıma sunulmuş,
tasarladığınız ve yarattığınız

00:12:19.876 --> 00:12:21.603
tüm bu şeylere ilişkin

00:12:21.627 --> 00:12:25.241
böyle bir bağlantıya sahip olsaydınız

00:12:25.265 --> 00:12:26.885
bunu değiştirebilirdiniz;

00:12:26.909 --> 00:12:29.956
insanlara icatlarımızı aldırmak yerine

00:12:29.980 --> 00:12:33.414
sadece istedikleri şeyleri yapabiliriz.

00:12:33.438 --> 00:12:36.225
İyi haber şu ki, bizi 
tasarımlarımıza bağlayacak

00:12:36.249 --> 00:12:39.050
dijital sinir sistemi 
üzerinde çalışıyoruz.

00:12:40.185 --> 00:12:41.812
Bir proje üzerinde çalışıyoruz,

00:12:41.836 --> 00:12:45.548
Los Angeles'ta Bandito Kardeşler

00:12:45.572 --> 00:12:46.979
ve takımı ile birlikte.

00:12:47.003 --> 00:12:50.436
Bu ekibin yaptığı şeylerden biri
sıradışı şeyler yapan

00:12:50.460 --> 00:12:53.333
sıradışı arabalar üretmek.

00:12:54.725 --> 00:12:56.175
Bunlar çıldırmış.

00:12:56.199 --> 00:12:57.235
(Kahkahalar)

00:12:57.259 --> 00:12:58.662
Ama iyi anlamda.

00:13:00.813 --> 00:13:02.576
Bizim birlikte yaptığımız şey ise

00:13:02.600 --> 00:13:05.040
geleneksel yarış arabası şasesini alıp

00:13:05.064 --> 00:13:06.649
ona bir sinir sistemi yüklemek.

00:13:06.673 --> 00:13:09.731
Yani onlarca sensör taktık ve

00:13:09.755 --> 00:13:12.390
direksiyona birinci sınıf
bir sürücü koyduk,

00:13:12.414 --> 00:13:15.771
arabayı çöle götürdük ve
bir hafta boyunca kullandık.

00:13:15.795 --> 00:13:18.286
Arabanın sinir sistemi
arabanın başına gelen

00:13:18.310 --> 00:13:19.792
her şeyi yakaladı.

00:13:19.816 --> 00:13:22.437
4 milyar veri noktası elde ettik;

00:13:22.461 --> 00:13:24.771
sorumlu olduğu tüm güçlerden.

00:13:24.795 --> 00:13:26.454
Sonra çılgınca bir şey yaptık.

00:13:27.088 --> 00:13:28.588
Tüm veriyi aldık

00:13:28.612 --> 00:13:32.348
''Dreamcatcher'' dediğimiz üretken
tasarımlı bir yapay zekâya taktık.

00:13:33.090 --> 00:13:37.054
Bir tasarıma dijital 
bir sinir sistemi yükleyip

00:13:37.078 --> 00:13:39.960
size son model bir şase 
yapmasını isterseniz ne olur?

00:13:40.543 --> 00:13:42.516
İşte bu.

00:13:44.113 --> 00:13:47.826
Bu bir insanın asla
tasarlayamayacağı bir şey.

00:13:48.527 --> 00:13:50.415
Ancak bunu bir insan tasarladı,

00:13:50.439 --> 00:13:54.748
ama üretken tasarımlı yapay zekâ,

00:13:54.772 --> 00:13:56.003
dijital bir sinir sistemi

00:13:56.027 --> 00:13:59.032
ve imal yetisi olan robotlar ile
güçlendirilmiş bir insan.

00:13:59.500 --> 00:14:03.095
Eğer gelecek, 
Artırılmış Çağ bu ise

00:14:03.119 --> 00:14:07.380
bilişsel, fiziksel ve algısal
olarak güçlendirileceksek,

00:14:07.404 --> 00:14:08.812
bu neye benzeyecek?

00:14:09.396 --> 00:14:12.717
Bu harikalar diyarı nasıl görünecek?

00:14:12.741 --> 00:14:14.450
Sanırım imal etmekten ziyade

00:14:14.474 --> 00:14:17.542
yetiştirme yapılan bir dünyaya doğru

00:14:17.566 --> 00:14:19.011
yol alıyoruz.

00:14:19.979 --> 00:14:23.432
Nesnelerin inşa edilmek yerine

00:14:23.456 --> 00:14:25.160
yetiştirildiği bir dünya.

00:14:25.954 --> 00:14:28.142
İzole olmaktan çıkıp

00:14:28.166 --> 00:14:29.776
iletişim hâlinde olacağız.

00:14:30.454 --> 00:14:32.865
Ayrılmayı bir yana bırakıp

00:14:32.889 --> 00:14:34.762
birleşmeye kucak açacağız.

00:14:35.787 --> 00:14:39.554
Yine sanıyorum ki itaat
etmek yerine

00:14:39.578 --> 00:14:41.219
özerkliğin değerini anlayacağız.

00:14:42.330 --> 00:14:44.235
Artırılmış yetilerimiz sayesinde,

00:14:44.259 --> 00:14:46.636
dünya ciddi bir değişim geçirecek.

00:14:47.396 --> 00:14:50.642
Bu dünyada daha fazla 
çeşitlilik, iletişim,

00:14:50.666 --> 00:14:52.953
dinamizm ve karmaşıklık,

00:14:52.977 --> 00:14:55.295
daha çok uyum sağlama ve

00:14:55.319 --> 00:14:56.536
daha çok güzellik olacak.

00:14:57.051 --> 00:14:58.615
Gelecek şeylerin biçimi

00:14:58.639 --> 00:15:00.929
daha önce hiç 
görmediğimiz türden olacak.

00:15:00.953 --> 00:15:02.112
Neden mi?

00:15:02.136 --> 00:15:05.891
Çünkü onlara bu biçimi verecek şey

00:15:05.915 --> 00:15:09.585
teknoloji, doğa ve insan ortaklığı olacak.

00:15:11.099 --> 00:15:14.903
Bu bana göre 
dört gözle beklenecek bir gelecek.

00:15:14.927 --> 00:15:16.198
Çok teşekkür ederim.

00:15:16.222 --> 00:15:21.891
(Alkışlar)

