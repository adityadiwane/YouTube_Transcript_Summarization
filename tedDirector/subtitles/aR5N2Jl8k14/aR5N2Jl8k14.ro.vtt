WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Ioana Miruna
Corector: Lorena Ciutacu

00:00:12.555 --> 00:00:14.844
Câți dintre voi sunteți creatori,

00:00:14.868 --> 00:00:18.492
designeri, ingineri, 
antrepenori, artiști

00:00:18.516 --> 00:00:20.903
sau poate doar aveți
o imaginație debordantă?

00:00:20.927 --> 00:00:22.775
Ridicați mâna.
(Aclamații)

00:00:22.799 --> 00:00:23.980
Majoritatea.

00:00:25.154 --> 00:00:27.448
Am vești pentru noi, cei creativi.

00:00:28.534 --> 00:00:31.107
În următorii 20 de ani,

00:00:33.291 --> 00:00:36.264
se vor schimba mai multe lucruri
în felul în care lucrăm

00:00:37.202 --> 00:00:39.359
decât în ultimii 2000 de ani.

00:00:40.331 --> 00:00:44.959
De fapt, cred că suntem la răsăritul
unei noi ere a istoriei umane.

00:00:45.465 --> 00:00:50.226
Până acum au fost 4 mari ere
istorice definite de felul în care lucrăm.

00:00:51.224 --> 00:00:54.499
Era vânătorilor-culegători
a durat câteva milioane de ani.

00:00:54.983 --> 00:00:58.559
Apoi Era agricultorilor
a durat câteva mii de ani.

00:00:59.015 --> 00:01:02.505
Era industrială
a durat câteva secole.

00:01:02.529 --> 00:01:06.816
Acum, Era informației
durează doar de câteva decenii.

00:01:06.840 --> 00:01:12.060
În prezent, suntem la apogeul
următoarei mari ere ca specie.

00:01:13.116 --> 00:01:15.796
Bun venit în Era augmentării.

00:01:15.820 --> 00:01:19.513
În această nouă eră, capacitățile
naturale de om urmează să fie depășite

00:01:19.537 --> 00:01:22.605
de sisteme computaționale
care vă ajută să gândiți,

00:01:22.629 --> 00:01:24.815
de sisteme robotizate
care vă ajută să creați

00:01:24.839 --> 00:01:26.487
și de un sistem nervos digital

00:01:26.511 --> 00:01:30.201
care vă conectează la lume
dincolo de simțurile naturale.

00:01:31.257 --> 00:01:33.199
Să începem cu augmentarea cognitivă.

00:01:33.223 --> 00:01:35.423
Câți dintre voi sunteți cyborgi evoluați?

00:01:35.953 --> 00:01:38.603
(Râsete)

00:01:38.627 --> 00:01:41.448
De fapt aș susține faptul
că suntem deja evoluați.

00:01:42.108 --> 00:01:44.002
Imaginați-vă că sunteți 
la o petrecere

00:01:44.002 --> 00:01:47.156
și cineva vă pune o întrebare
la care nu știți răspunsul.

00:01:47.180 --> 00:01:50.940
Dacă aveți așa ceva, în câteva
secunde ați ști răspunsul.

00:01:51.689 --> 00:01:53.988
Acesta este doar un început primitiv.

00:01:54.683 --> 00:01:58.014
Chiar și Siri e doar un instrument pasiv.

00:01:58.480 --> 00:02:01.861
De fapt, în ultimii 3 milioane
și jumătate de ani,

00:02:01.885 --> 00:02:04.994
instrumentele pe care le-am avut
au fost total pasive.

00:02:06.023 --> 00:02:09.678
Fac doar ce le spunem noi
și nimic mai mult.

00:02:09.702 --> 00:02:12.803
Prima noastră unealtă adevărată 
tăia doar unde loveam cu ea.

00:02:13.642 --> 00:02:16.682
Dalta cioplește doar unde
o îndreaptă artistul.

00:02:17.163 --> 00:02:22.804
Chiar și cele mai avansate unelte
nu fac nimic fără instrucțiuni explicite.

00:02:22.828 --> 00:02:26.009
În realitate, și asta este frustrant,

00:02:26.033 --> 00:02:27.481
mereu am fost limitați

00:02:27.505 --> 00:02:31.006
de nevoia de a ne transpune manual
dorințele în unelte,

00:02:31.030 --> 00:02:35.557
folosindu-ne efectiv de mâini,
chiar și în cazul calculatoarelor.

00:02:35.892 --> 00:02:38.355
Eu semăn mai mult cu Scotty
din Star Trek.

00:02:38.379 --> 00:02:40.229
(Râsete)

00:02:40.253 --> 00:02:42.399
Vreau să am o conversație cu un computer.

00:02:42.423 --> 00:02:45.393
Vreau să spun: „Calculatorule,
hai să proiectăm o mașină”,

00:02:45.417 --> 00:02:47.216
iar calculatorul să-mi arate mașina.

00:02:47.216 --> 00:02:49.738
Și eu spun: „Să fie mai rapidă,
și mai puțin germană.”

00:02:49.748 --> 00:02:51.895
și bang, calculatorul
să-mi arate o variantă.

00:02:51.895 --> 00:02:53.664
(Râsete)

00:02:54.028 --> 00:02:56.334
Această conversație poate fi
prea avansată,

00:02:56.358 --> 00:02:59.023
probabil mai puțin decât credem mulți,

00:02:59.047 --> 00:03:00.810
dar chiar acum

00:03:00.834 --> 00:03:01.985
lucrăm la asta.

00:03:02.009 --> 00:03:06.042
Instrumentele fac acest salt
de la a fi pasiv la a fi generativ.

00:03:06.651 --> 00:03:09.959
Crearea instrumentelor generative
folosește un computer și algoritmi

00:03:09.983 --> 00:03:12.591
care să sintetizeze geometria

00:03:12.615 --> 00:03:15.369
să vină singură cu noi modele.

00:03:15.816 --> 00:03:18.564
Tot ce trebuie sunt obiectivele
și restrângerile tale.

00:03:18.588 --> 00:03:19.996
Să vă dau un exemplu.

00:03:20.020 --> 00:03:22.808
În cazul acesui șasiu de dronă aeriană,

00:03:22.832 --> 00:03:25.458
tot ce trebuie să faci
e să îi spui ceva ca:

00:03:25.482 --> 00:03:26.755
are 4 elice,

00:03:26.779 --> 00:03:28.910
o greutate cât mai mică

00:03:28.934 --> 00:03:31.204
și să fie eficientă aerodinamic.

00:03:31.228 --> 00:03:36.142
Apoi computerul examinează
întregul interval de soluții:

00:03:36.166 --> 00:03:40.093
fiecare posibilitate care 
se potrivește criteriilor tale;

00:03:40.117 --> 00:03:41.559
sunt milioane.

00:03:41.583 --> 00:03:43.558
E nevoie de un computer enorm
pentru asta.

00:03:43.582 --> 00:03:45.537
Apoi ne arată modele

00:03:45.561 --> 00:03:48.704
pe care noi, fără ajutor,
nu ni le-am fi putut imagina.

00:03:49.146 --> 00:03:52.058
Calculatorul inventează asta singur,

00:03:52.082 --> 00:03:53.760
nimeni nu desenează nimic

00:03:53.784 --> 00:03:55.870
și începe de la zero.

00:03:56.858 --> 00:03:59.245
Apropo, nu accidental

00:03:59.269 --> 00:04:02.750
drona arată ca bazinul
unei veverițe zburătoare.

00:04:03.107 --> 00:04:05.114
(Râsete)

00:04:05.860 --> 00:04:08.162
Algoritmii sunt făcuți să funcționeze

00:04:08.186 --> 00:04:09.823
la fel ca evoluția.

00:04:10.535 --> 00:04:13.195
Interesant e că începem 
să vedem această tehnologie

00:04:13.219 --> 00:04:14.378
în lumea reală.

00:04:14.402 --> 00:04:16.854
Am lucrat cu Airbus câțiva ani

00:04:16.878 --> 00:04:18.787
la un concept de avion al viitorului.

00:04:18.811 --> 00:04:20.881
Încă e un proiect.

00:04:20.905 --> 00:04:24.685
Chiar recent am folosit
un model generativ de IA

00:04:24.709 --> 00:04:26.516
care a venit cu asta.

00:04:27.429 --> 00:04:32.582
Aceasta este o cabină printată 3D 
proiectată de un computer.

00:04:32.606 --> 00:04:35.430
E mai bună decât originalul,
și cântărește jumătate din el,

00:04:35.454 --> 00:04:38.600
și va zbura în Airbus
A320 la sfârșitul anului.

00:04:39.225 --> 00:04:40.784
Deci computerele pot crea acum.

00:04:40.808 --> 00:04:45.403
Pot veni cu propriile soluții
la problemele noastre bine definite.

00:04:46.497 --> 00:04:47.807
Însă nu au intuiție.

00:04:47.831 --> 00:04:50.917
Trebuie să o ia de la început 
de fiecare dată

00:04:50.941 --> 00:04:53.506
pentru că nu învață niciodată,

00:04:54.188 --> 00:04:55.954
spre deosebire de Maggie.

00:04:55.978 --> 00:04:57.559
(Râsete)

00:04:57.583 --> 00:05:00.880
Maggie e chiar mai inteligentă
decât cele mai avansate instrumente.

00:05:01.287 --> 00:05:02.727
Ce vreau să spun prin asta?

00:05:02.751 --> 00:05:04.341
Dacă stăpânul îi ridică lesa,

00:05:04.365 --> 00:05:06.433
Maggie știe destul de cert

00:05:06.457 --> 00:05:07.861
că e timpul pentru plimbare.

00:05:07.885 --> 00:05:09.070
Cum a învățat?

00:05:09.094 --> 00:05:12.418
De fiecare dată când stăpânul a luat lesa
au mers la plimbare.

00:05:12.442 --> 00:05:14.320
Maggie a făcut 3 lucruri:

00:05:14.344 --> 00:05:16.213
a trebuit să fie atentă,

00:05:16.237 --> 00:05:18.319
să își amintească ce s-a întâmplat

00:05:18.343 --> 00:05:22.360
și să rețină și să recreeze
un model în minte.

00:05:23.249 --> 00:05:26.924
Interesant e că exact asta
au încercat cercetătorii

00:05:26.924 --> 00:05:29.791
să facă cu IA în ultimii 60 de ani.

00:05:30.503 --> 00:05:31.852
În 1952,

00:05:31.876 --> 00:05:35.677
au construit acest computer
care putea să joace X și 0.

00:05:36.901 --> 00:05:38.061
Mare lucru.

00:05:38.849 --> 00:05:41.849
După 45 de ani, în 1997,

00:05:41.873 --> 00:05:44.345
Deep Blue îl bate pe Kasparov la șah.

00:05:45.866 --> 00:05:50.834
În 2011, Watson îi bate pe acești
doi oameni la Jeopardy,

00:05:50.858 --> 00:05:53.786
care e mai greu de jucat decât șahul 
pentru un computer.

00:05:53.810 --> 00:05:57.622
De fapt, în loc să folosească 
algoritmi predefiniți,

00:05:57.646 --> 00:06:00.969
Watson a trebuit să gândească 
pentru a-și bate adversarii umani.

00:06:02.213 --> 00:06:04.652
Acum câteva săptămâni,

00:06:04.676 --> 00:06:08.938
AlphaGo din Deep Mind l-a bătut 
pe cel mai bun jucător uman la Go,

00:06:08.962 --> 00:06:11.174
care e cel mai greu joc
pe care îl avem.

00:06:11.198 --> 00:06:14.094
În Go sunt mai multe mutări posibile

00:06:14.118 --> 00:06:16.142
decât atomi în univers.

00:06:18.030 --> 00:06:19.856
Ca să câștige,

00:06:19.880 --> 00:06:22.498
AlphaGo a trebuit
să își dezvolte intuiție.

00:06:22.918 --> 00:06:24.412
În realitate,

00:06:24.412 --> 00:06:29.338
programatorii AlphaGo nu au înțeles
de ce AlphaGo făcea ce făcea.

00:06:31.271 --> 00:06:32.931
Lucrurile se mișcă foarte repede.

00:06:32.955 --> 00:06:36.182
Gândiți-vă:
în contextul unei vieți umane,

00:06:36.206 --> 00:06:38.439
computerele au ajuns
de la mintea unui copil

00:06:39.740 --> 00:06:42.788
la ceea ce numim
apogeul gândirii strategice.

00:06:43.819 --> 00:06:46.236
Practic,

00:06:46.260 --> 00:06:49.570
computerele evoluează de la Spock

00:06:49.594 --> 00:06:51.543
la a fi ca Kirk.

00:06:51.567 --> 00:06:55.185
(Râsete)

00:06:55.209 --> 00:06:58.633
Nu? De la logică pură la intuiție.

00:07:00.004 --> 00:07:01.747
Ați trece acest pod?

00:07:02.429 --> 00:07:04.752
Mulți dintre dumneavoastră
ar spune „Oh nu!”

00:07:04.776 --> 00:07:06.084
(Râsete)

00:07:06.108 --> 00:07:08.765
Ați ajuns la această
decizie într-un moment.

00:07:08.789 --> 00:07:11.217
Cumva ați știut că podul este nesigur.

00:07:11.241 --> 00:07:13.230
E exact genul de intuiție

00:07:13.254 --> 00:07:16.822
pe care sistemele noastre
de învățare încep să îl folosească.

00:07:17.542 --> 00:07:19.249
Foarte curând, veți fi capabili

00:07:19.273 --> 00:07:22.619
să îi arătați unui computer
ceva ce ați creat

00:07:22.680 --> 00:07:24.169
și el să vă răspundă

00:07:24.193 --> 00:07:27.016
„Îmi pare rău, omule, nu va funcționa.
Mai încearcă.”

00:07:27.674 --> 00:07:31.084
Sau l-ați putea întreba dacă oamenilor
le va plăcea următorul tău cântec

00:07:31.593 --> 00:07:33.656
sau următoarea ta aromă
de înghețată.

00:07:35.369 --> 00:07:37.948
Sau, mult mai important,

00:07:37.972 --> 00:07:40.426
ați putea lucra cu un calculator
la o problemă

00:07:40.426 --> 00:07:41.997
care încă nu are soluție.

00:07:42.021 --> 00:07:43.422
Ca încălzirea globală.

00:07:43.446 --> 00:07:45.466
Nu facem o treabă prea bună singuri.

00:07:45.490 --> 00:07:47.735
Am putea folosi orice ajutor am primi.

00:07:47.759 --> 00:07:49.217
Despre asta vorbesc,

00:07:49.241 --> 00:07:51.796
tehnologia ne mărește
abilitățile cognitive

00:07:51.820 --> 00:07:55.372
ca să putem imagina și crea 
lucruri care nu ne sunt la îndemână

00:07:55.396 --> 00:07:57.955
ca simpli oameni vechi și neevoluați.

00:07:59.804 --> 00:08:02.745
Cum ar fi să facem
toate aceste lucruri noi

00:08:02.769 --> 00:08:05.210
pe care le vom inventa și proiecta?

00:08:05.772 --> 00:08:09.865
Cred că era dezvoltării umane e la fel
de mult despre lumea fizică

00:08:09.889 --> 00:08:12.954
cât despre cea virtuală,
domeniul intelectual.

00:08:13.653 --> 00:08:15.574
Cum ne va dezvolta tehnologia?

00:08:16.081 --> 00:08:18.554
În lumea fizică,
sistemele robotizate.

00:08:19.440 --> 00:08:21.176
Cu siguranță există o teamă

00:08:21.200 --> 00:08:23.688
că roboții le vor lua joburile oamenilor,

00:08:23.712 --> 00:08:25.762
ceea ce e adevărat în anumite domenii.

00:08:25.994 --> 00:08:28.872
Dar sunt mult mai interesat de ideea

00:08:28.896 --> 00:08:33.906
ca oamenii și roboții lucrând împreună
să se augmenteze reciproc

00:08:33.930 --> 00:08:35.988
și să locuiască într-un nou spațiu.

00:08:36.012 --> 00:08:38.944
În laboratorul nostru de cercetare aplicată
din San Francisco,

00:08:38.944 --> 00:08:41.540
unul din domeniile pe care ne axăm
e robotica avansată,

00:08:41.564 --> 00:08:44.075
în special colaborarea om-robot.

00:08:44.854 --> 00:08:47.613
Acesta e Bishop,
unul dintre roboții noștri.

00:08:47.637 --> 00:08:49.426
Experimental, l-am setat

00:08:49.450 --> 00:08:52.910
să ajute un lucrător în construcții
să facă sarcini repetitive,

00:08:53.804 --> 00:08:57.998
ca făcutul găurilor pentru scurgeri
sau întrerupătoarelor în pereți.

00:08:58.022 --> 00:09:00.488
(Râsete)

00:09:01.697 --> 00:09:04.808
Partenerul uman al lui Bishop
îi spune ce să facă în engleză

00:09:04.832 --> 00:09:06.137
folosind gesturi simple,

00:09:06.161 --> 00:09:07.608
cum ar vorbi cu un câine,

00:09:07.632 --> 00:09:09.775
iar Bishop execută
acele instrucțiuni

00:09:09.799 --> 00:09:11.691
cu precizie perfectă.

00:09:11.715 --> 00:09:14.704
Folosim omul la ce e el bun:

00:09:14.728 --> 00:09:17.061
avertizare, percepție
și luarea deciziilor.

00:09:17.085 --> 00:09:19.325
Și folosim robotul
la ce e el bun:

00:09:19.349 --> 00:09:21.097
precizie și repetiție.

00:09:22.072 --> 00:09:24.439
Iată alt proiect 
la care Bishop a contribuit.

00:09:24.463 --> 00:09:27.538
Scopul acestui proiect,
pe care l-am numit HIVE,

00:09:27.562 --> 00:09:31.413
a fost să imagineze experiența oamenilor, 
computerelor și roboților

00:09:31.437 --> 00:09:34.657
toți lucrând împreună să rezolve
o problemă complexă de design.

00:09:35.613 --> 00:09:37.254
Oamenii au acționat ca lucrători.

00:09:37.254 --> 00:09:40.561
Au navigat pe un site de construcții,
au lucrat cu bambusul,

00:09:40.585 --> 00:09:43.341
care fiind un material non-izomorf,

00:09:43.365 --> 00:09:45.239
e greu de manipulat de către roboți.

00:09:45.263 --> 00:09:47.285
Dar apoi roboții au înfășurat firele,

00:09:47.309 --> 00:09:49.760
lucru aproapre imposibl pentru oameni.

00:09:49.784 --> 00:09:53.405
Apoi am avut IA care a controlat totul.

00:09:53.429 --> 00:09:56.719
Le spunea oamenilor și roboților
ce să facă

00:09:56.743 --> 00:09:59.658
și ținea evidența miilor de componente.

00:09:59.682 --> 00:10:00.862
Interesant e că,

00:10:00.886 --> 00:10:04.027
construirea acestui pavilion
era pur și simplu imposibil

00:10:04.051 --> 00:10:08.575
fără om, robot și IA,
ajutându-se reciproc.

00:10:09.710 --> 00:10:13.030
Vă mai împărtășesc un proiect.
Ăsta e puțin nebunesc.

00:10:13.054 --> 00:10:17.522
Lucrăm cu artistul din Amsterdam,
Joris Laarman și cu echipa lui la MX3D

00:10:17.546 --> 00:10:20.424
să creăm și să printăm robotizat

00:10:20.448 --> 00:10:23.443
primul pod din lume făcut autonom.

00:10:24.135 --> 00:10:27.820
Joris și un IA creează acest lucru acum,
în timp ce vorbim,

00:10:27.844 --> 00:10:29.016
în Amsterdam.

00:10:29.040 --> 00:10:31.361
Când vor termina, vom apăsa GO

00:10:31.385 --> 00:10:34.696
și roboții vor printa 3D
în oțel inoxidabil,

00:10:34.720 --> 00:10:38.003
fără ajutor omenesc,

00:10:38.027 --> 00:10:39.585
până ce podul e gata.

00:10:40.919 --> 00:10:43.847
În timp ce computerele 
ne vor crește abilitatea

00:10:43.871 --> 00:10:46.021
de a ne imagina și de a crea
noi lucruri,

00:10:46.045 --> 00:10:48.940
sistemele robotizate ne vor ajuta
să construim

00:10:48.964 --> 00:10:51.048
lucruri pe care înainte nu le puteam face.

00:10:52.167 --> 00:10:56.327
Dar abilitatea noastră 
de a simți și controla aceste lucruri?

00:10:56.351 --> 00:11:00.382
Dar un sistem nervos
pentru lucrurile pe care le facem?

00:11:00.406 --> 00:11:02.918
Sistemul nostru nervos,
sistemul nervos uman,

00:11:02.942 --> 00:11:05.253
ne spune tot ce se întâmplă în jur.

00:11:06.006 --> 00:11:09.690
Dar sistemul nervos al lucrurilor
pe care le facem e rudimentar.

00:11:09.714 --> 00:11:13.277
De exemplu, o mașină nu îi spune
departamentului de lucrări publice

00:11:13.301 --> 00:11:16.431
că a luat o groapă la colțul
dintre Broadway și Morrison.

00:11:16.455 --> 00:11:18.487
O clădire nu le spune proiectanților

00:11:18.511 --> 00:11:21.195
dacă oamenilor dinăuntru le place acolo

00:11:21.219 --> 00:11:24.229
și producătorul unei jucării nu știe

00:11:24.253 --> 00:11:26.260
dacă cineva se joacă cu ea,

00:11:26.284 --> 00:11:28.823
cum și unde sau dacă
e distractivă sau nu.

00:11:29.440 --> 00:11:33.254
Sunt sigur că designerii și-au imaginat
acest stil de viață pentru Barbie

00:11:33.278 --> 00:11:34.502
când au gândit-o.

00:11:34.526 --> 00:11:35.973
(Râsete)

00:11:35.997 --> 00:11:38.903
Dar dacă de fapt Barbie 
e foarte singură?

00:11:38.927 --> 00:11:42.074
(Râsete)

00:11:43.086 --> 00:11:44.374
Dacă designerii ar fi știut

00:11:44.398 --> 00:11:47.075
ce se întâmplă cu adevărat
în lumea reală cu ce au creat

00:11:47.075 --> 00:11:49.112
– drumul, clădirea, Barbie –

00:11:49.136 --> 00:11:51.824
ar fi putut folosi informația
pentru a crea o experiență

00:11:51.824 --> 00:11:53.464
mai bună pentru utilizator.

00:11:53.464 --> 00:11:55.629
Lipsește un sistem nervos
să ne conecteze

00:11:55.629 --> 00:11:58.952
cu lucrurile pe care le proiectăm,
construim și folosim.

00:11:59.735 --> 00:12:03.290
Dacă toți ați avea acel gen 
de informație venind la voi

00:12:03.314 --> 00:12:05.647
de la lucrurile pe care le creați
în lumea reală?

00:12:07.252 --> 00:12:08.703
Pentru tot ce facem,

00:12:08.727 --> 00:12:11.162
folosim o cantitate enormă 
de bani și energie

00:12:11.186 --> 00:12:13.622
– anul trecut,
cam două trilioane de dolari –

00:12:13.622 --> 00:12:16.440
convingând oameni
să cumpere ce am făcut.

00:12:16.464 --> 00:12:19.852
Dar dacă ați avea această conexiune
cu ce proiectați și creați

00:12:19.876 --> 00:12:21.603
după ce ies în lumea reală,

00:12:21.627 --> 00:12:25.241
după ce sunt vândute sau lansate,

00:12:25.265 --> 00:12:26.885
am putea schimba acest lucru,

00:12:26.909 --> 00:12:29.956
pentru a merge de la ideea
ca oamenii să ne vrea lucrurile

00:12:29.980 --> 00:12:33.414
la a face lucruri
pe care oamenii să le vrea.

00:12:33.438 --> 00:12:36.225
Vestea bună e că lucrăm
la un sistem nervos digital

00:12:36.249 --> 00:12:39.050
care să ne conecteze cu lucrurile
pe care le creăm.

00:12:40.185 --> 00:12:41.812
Lucrăm la un proiect

00:12:41.836 --> 00:12:45.548
cu niște băieți din LA
numiți Bandito Brothers

00:12:45.572 --> 00:12:46.979
și cu echipa lor.

00:12:47.003 --> 00:12:50.436
Unul din lucrurile pe care le fac ei
este să facă mașini uluitoare

00:12:50.460 --> 00:12:53.333
care fac lucruri uluitoare.

00:12:54.725 --> 00:12:56.175
Băieții ăștia sunt nebuni.

00:12:56.199 --> 00:12:57.235
(Râsete)

00:12:57.259 --> 00:12:58.662
În sensul bun.

00:13:00.813 --> 00:13:02.576
Împreună cu ei,

00:13:02.600 --> 00:13:05.200
luăm un șasiu de la o mașină 
de curse tradițională

00:13:05.200 --> 00:13:06.799
și să îi oferim un sistem nervos.

00:13:06.799 --> 00:13:09.731
Așa că am echipat-o cu zeci de senzori,

00:13:09.755 --> 00:13:12.390
i-am pus un șofer
de clasă mondială la volan

00:13:12.414 --> 00:13:15.771
am scos-o în deșert
și am condus-o nebunește o săptămână.

00:13:15.795 --> 00:13:18.286
Și sistemul nervos al mașinii 
a înregistrat tot

00:13:18.310 --> 00:13:19.792
ce se întâmpla cu mașina.

00:13:19.816 --> 00:13:22.437
Am înregistrat 4 miliarde de măsurători,

00:13:22.461 --> 00:13:24.771
toate forțele la care a fost supusă.

00:13:24.795 --> 00:13:26.454
Apoi am făcut ceva nebunesc.

00:13:27.088 --> 00:13:28.588
Am luat toate datele

00:13:28.612 --> 00:13:32.348
și le-am introdus într-un sistem
de design generativ IA numit Dreamcatcher.

00:13:33.090 --> 00:13:37.054
Ce obții când îi dai unui instrument
de design un sistem nervos

00:13:37.078 --> 00:13:39.960
și îi ceri să îți construiască
cel mai modern model de șasiu?

00:13:40.543 --> 00:13:42.516
Asta.

00:13:44.113 --> 00:13:47.826
E ceva ce un om n-ar fi putut
niciodată proiecta.

00:13:48.527 --> 00:13:50.415
Doar că un om a făcut asta,

00:13:50.439 --> 00:13:54.662
dar ajutat de o IA generatoare de design,

00:13:54.662 --> 00:13:56.003
de un sistem nervos digital

00:13:56.027 --> 00:13:59.032
și de roboți care
chiar pot fabrica așa ceva.

00:13:59.500 --> 00:14:03.095
Dacă ăsta e viitorul, Era augmentării,

00:14:03.119 --> 00:14:07.380
și vom fi augmentați cognitiv,
fizic și perceptiv,

00:14:07.404 --> 00:14:08.812
cum va arăta?

00:14:09.396 --> 00:14:12.717
Cum va fi acest tărâm al minunilor?

00:14:12.741 --> 00:14:14.450
Cred că vom vedea o lume

00:14:14.474 --> 00:14:17.542
unde vom trece de la lucruri fabricate

00:14:17.566 --> 00:14:19.011
la unele crescute.

00:14:19.979 --> 00:14:23.432
Unde vom trece de la lucruri construite

00:14:23.456 --> 00:14:25.160
la cele crescute.

00:14:25.954 --> 00:14:28.142
Vom trece de la a fi izolați

00:14:28.166 --> 00:14:29.776
la a fi conectați.

00:14:30.454 --> 00:14:32.865
Și ne vom îndepărta de origini

00:14:32.889 --> 00:14:34.762
pentru a îmbrățișa agregarea.

00:14:35.787 --> 00:14:39.554
De asemenea cred că ne vom schimba
de la a râvni supunerea lucrurilor

00:14:39.578 --> 00:14:41.219
la a le aprecia autonomia.

00:14:42.330 --> 00:14:44.405
Grație posibilităților noastre augmentate,

00:14:44.405 --> 00:14:46.636
lumea se va schimba dramatic.

00:14:47.396 --> 00:14:50.642
Vom avea o lume cu mai multă
varietate, conexiune,

00:14:50.666 --> 00:14:52.953
dinamism, complexitate,

00:14:52.977 --> 00:14:55.295
adaptabilitate și desigur

00:14:55.319 --> 00:14:56.536
frumusețe.

00:14:57.051 --> 00:14:58.615
Forma lucrurilor viitoare

00:14:58.639 --> 00:15:00.929
nu va semăna cu ce am văzut înainte.

00:15:00.953 --> 00:15:02.112
De ce?

00:15:02.136 --> 00:15:05.891
Pentru că ce va modela acele lucruri 
este noul parteneriat

00:15:05.915 --> 00:15:09.585
dintre tehnologie, natură și umanitate.

00:15:11.099 --> 00:15:14.903
Asta, pentru mine, este un viitor
spre care merită să privim.

00:15:14.927 --> 00:15:16.198
Vă mulțumesc tuturor.

00:15:16.222 --> 00:15:21.891
(Aplauze)

