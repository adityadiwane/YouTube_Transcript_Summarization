WEBVTT
Kind: captions
Language: sr

00:00:00.000 --> 00:00:07.000
Prevodilac: Milenka Okuka
Lektor: Mile Živković

00:00:12.555 --> 00:00:14.844
Koliko vas su kreativci,

00:00:14.868 --> 00:00:18.492
dizajneri, inženjeri,
preduzetnici, umetnici

00:00:18.516 --> 00:00:20.903
ili možda prosto imate
veoma bujnu maštu?

00:00:20.927 --> 00:00:22.775
Pokažite ruke? (Klicanje)

00:00:22.799 --> 00:00:23.980
To je većina vas.

00:00:25.154 --> 00:00:27.448
Imam novosti za nas kreativce.

00:00:28.534 --> 00:00:31.107
U narednih 20 godina,

00:00:33.291 --> 00:00:36.264
više će se promeniti
način na koji obavljamo naše poslove

00:00:37.202 --> 00:00:39.359
nego u poslednjih 2000 godina.

00:00:40.331 --> 00:00:44.959
Zapravo, mislim da smo u praskozorju
novog doba u ljudskoj istoriji.

00:00:45.465 --> 00:00:50.226
Sad, imali smo četiri značajne istorijske
ere, definisane načinom našeg rada.

00:00:51.224 --> 00:00:54.499
Doba lovaca i sakupljača
koje je trajalo nekoliko miliona godina.

00:00:54.983 --> 00:00:58.559
A potom zemljoradničko doba
koje je trajalo nekoliko hiljada godina.

00:00:59.015 --> 00:01:02.505
Industrijsko doba
je trajalo nekoliko vekova.

00:01:02.529 --> 00:01:06.816
A sadašnje informaciono doba
je trajalo svega nekoliko decenija.

00:01:06.840 --> 00:01:12.060
Trenutno smo kao vrsta na samom početku
naše nove značajne ere.

00:01:13.116 --> 00:01:15.796
Dobro došli u prošireno doba.

00:01:15.820 --> 00:01:19.513
U ovoj novoj eri, vaše prirodne ljudske
sposobnosti će da budu proširene

00:01:19.537 --> 00:01:22.605
uz pomoć računarskih sistema
koji vam pomažu da razmišljate,

00:01:22.629 --> 00:01:24.815
robotskih sistema
koji vam pomažu da stvarate

00:01:24.839 --> 00:01:26.487
i digitalnih nervnih sistema

00:01:26.511 --> 00:01:30.201
koji vas povezuju sa svetom
daleko izvan vaših prirodnih čula.

00:01:31.257 --> 00:01:33.199
Započnimo kognitivnim proširenjem.

00:01:33.223 --> 00:01:35.423
Koliko vas su prošireni kiborzi?

00:01:35.953 --> 00:01:38.603
(Smeh)

00:01:38.627 --> 00:01:41.448
Ja bih zapravo rekao
da smo svi mi prošireni.

00:01:42.108 --> 00:01:43.612
Zamislite da ste na zabavi

00:01:43.636 --> 00:01:47.156
i neko vam postavi pitanje
na koje ne znate odgovor.

00:01:47.180 --> 00:01:50.940
Ako imate nešto slično ovome,
za nekoliko sekundi možete znati odgovor.

00:01:51.689 --> 00:01:53.988
Ali ovo je tek primitivni početak.

00:01:54.683 --> 00:01:58.014
Čak je i Siri tek pasivno oruđe.

00:01:58.480 --> 00:02:01.861
Zapravo, u poslednjih
tri i po miliona godina,

00:02:01.885 --> 00:02:04.994
oruđa koja smo imali
su bila potpuno pasivna.

00:02:06.023 --> 00:02:09.678
Ona rade tačno ono što im kažemo
i ništa više.

00:02:09.702 --> 00:02:12.803
Naše prvo oruđe je jedino seklo
onde gde bismo udarili njime.

00:02:13.642 --> 00:02:16.682
Dleto rezbari samo onde
gde ga umetnik usmeri.

00:02:17.163 --> 00:02:22.804
Čak i naša najnaprednija oruđa ne rade
bilo šta bez naših eksplicitnih naredbi.

00:02:22.828 --> 00:02:26.009
Zapravo, do danas,
a to je nešto što me nervira,

00:02:26.033 --> 00:02:27.481
oduvek smo bili ograničeni

00:02:27.505 --> 00:02:31.006
potrebom da ručno
uteramo našu volju u naše alate -

00:02:31.030 --> 00:02:33.327
ručno, bukvalno koristeći naše ruke,

00:02:33.351 --> 00:02:34.779
čak i sa kompjuterima.

00:02:35.892 --> 00:02:38.355
No ja sam više nalik Skotiju
iz "Zvezdanih staza".

00:02:38.379 --> 00:02:40.229
(Smeh)

00:02:40.253 --> 00:02:42.399
Želim da razgovaram s kompjuterom.

00:02:42.423 --> 00:02:45.393
Želim da kažem: "Kompjuteru,
hajde da dizajniramo automobil",

00:02:45.417 --> 00:02:46.956
i kompjuter mi pokaže automobil.

00:02:46.980 --> 00:02:49.588
A ja kažem: "Ne, da izgleda brže
i manje nemački",

00:02:49.612 --> 00:02:51.775
i, bum, kompjuter mi pokaže opciju.

00:02:51.799 --> 00:02:53.664
(Smeh)

00:02:54.028 --> 00:02:56.334
Taj razgovor je možda malčice daleko,

00:02:56.358 --> 00:02:59.023
verovatno manje nego što većina nas misli,

00:02:59.047 --> 00:03:00.810
ali trenutno

00:03:00.834 --> 00:03:01.985
radimo na tome.

00:03:02.009 --> 00:03:06.042
Oruđa prave ovaj skok
od pasivnih do stvaralačkih.

00:03:06.651 --> 00:03:09.959
Stvaralačka dizajnerska oruđa
koriste kompjutere i algoritme,

00:03:09.983 --> 00:03:12.591
da bi tim spojem stvorila geometriju

00:03:12.615 --> 00:03:15.369
i potpuno sama došla do novih dizajna.

00:03:15.816 --> 00:03:18.564
Sve što im je potrebno
su vaši ciljevi i vaša ograničenja.

00:03:18.588 --> 00:03:19.996
Daću vam jedan primer.

00:03:20.020 --> 00:03:22.808
U slučaju ove vazdušne šasije drona,

00:03:22.832 --> 00:03:25.458
sve što bi trebalo da uradite
je da tražite sledeće:

00:03:25.482 --> 00:03:26.755
da ima četiri propelera,

00:03:26.779 --> 00:03:28.910
želite da bude što lakša

00:03:28.934 --> 00:03:31.204
i želite da ima aerodinamičnu efikasnost.

00:03:31.228 --> 00:03:36.142
Potom kompjuter istražuje
celokupan prostor rešenja:

00:03:36.166 --> 00:03:40.093
baš svaku mogućnost
koja rešava i ispunjava vaše kriterijume -

00:03:40.117 --> 00:03:41.559
milione njih.

00:03:41.563 --> 00:03:43.578
Potrebni su veliki kompjuteri da to obave.

00:03:43.582 --> 00:03:45.537
Ali su nam uzvratili dizajnima

00:03:45.561 --> 00:03:48.704
koje mi sami ne bismo
nikad mogli da zamislimo.

00:03:49.146 --> 00:03:52.058
A kompjuter je sam došao do ovoga -

00:03:52.082 --> 00:03:53.760
niko nikad nije nacrtao bilo šta -

00:03:53.784 --> 00:03:55.870
i započeo je potpuno od nule.

00:03:56.858 --> 00:03:59.245
I, usput, nije slučajno

00:03:59.269 --> 00:04:02.750
da telo drona izgleda
baš kao karlica leteće veverice.

00:04:03.107 --> 00:04:05.114
(Smeh)

00:04:05.860 --> 00:04:08.162
To je tako jer su algoritmi
dizajnirani da deluju

00:04:08.186 --> 00:04:09.823
na isti način kao evolucija.

00:04:10.535 --> 00:04:13.195
Uzbudljivo je što počinjemo
da gledamo ovu tehnologiju

00:04:13.219 --> 00:04:14.378
u stvarnom svetu.

00:04:14.402 --> 00:04:16.854
Nekoliko godina smo radili sa Erbasom

00:04:16.878 --> 00:04:18.787
na konceptu aviona iz budućnosti.

00:04:18.811 --> 00:04:20.881
I dalje je ispred svog vremena.

00:04:20.905 --> 00:04:24.685
Ali baš nedavno smo koristili
generativni dizajn veštačke inteligencije

00:04:24.709 --> 00:04:26.516
da bismo smislili ovo.

00:04:27.429 --> 00:04:32.582
Ovo je pregrada odštampana 3D štampačem,
koju je dizajnirao kompjuter.

00:04:32.606 --> 00:04:35.430
Jača je od prvobitne,
a ipak je upola lakša

00:04:35.454 --> 00:04:38.600
i leteće u erbasu A320 kasnije ove godine.

00:04:39.225 --> 00:04:40.784
Kompjuteri sad mogu da stvaraju;

00:04:40.808 --> 00:04:45.403
mogu da osmisle sopstvena rešenja
za naše dobro definisane probleme.

00:04:46.497 --> 00:04:47.807
Ali nisu intuitivni.

00:04:47.831 --> 00:04:50.917
I dalje moraju da počnu od nule,
baš svaki put,

00:04:50.941 --> 00:04:53.506
a to je zato što nikad ne nauče.

00:04:54.188 --> 00:04:55.954
Za razliku od Megi.

00:04:55.978 --> 00:04:57.559
(Smeh)

00:04:57.583 --> 00:05:00.880
Megi je zapravo pametnija od naših
najnaprednijih dizajnerskih oruđa.

00:05:01.287 --> 00:05:02.727
Šta podrazumevam time?

00:05:02.751 --> 00:05:04.341
Ako njen vlasnik uzme povodac,

00:05:04.365 --> 00:05:06.433
Megi zna s porpiličnim stepenom izvesnosti

00:05:06.457 --> 00:05:07.861
da je vreme za šetnju.

00:05:07.885 --> 00:05:09.070
A kako je naučila?

00:05:09.094 --> 00:05:12.418
Pa, svaki put kad je vlasnik
uzeo povodac, išli su u šetnju.

00:05:12.442 --> 00:05:14.320
I Megi je obavila tri stvari:

00:05:14.344 --> 00:05:16.213
morala je da obrati pažnju,

00:05:16.237 --> 00:05:18.319
morala je da se priseti šta se desilo

00:05:18.343 --> 00:05:22.360
i morala je da zadrži i stvori
obrazac u svom umu.

00:05:23.229 --> 00:05:25.374
Zanimljivo je da je upravo to ono što

00:05:25.374 --> 00:05:27.951
naučnici za kompjutere pokušavaju
da navedu VI da uradi

00:05:27.951 --> 00:05:29.774
u poslednjih oko 60 godina.

00:05:30.503 --> 00:05:31.852
Te 1952.

00:05:31.876 --> 00:05:35.677
su sagradili ovaj kompjuter
koji je mogao da igra iks-oks.

00:05:36.901 --> 00:05:38.061
Velika stvar.

00:05:38.849 --> 00:05:41.849
Potom, 45 godina kasnije, 1997.

00:05:41.873 --> 00:05:44.345
Deep Blue je pobedio Kasparova u šahu.

00:05:45.866 --> 00:05:50.834
Godine 2011, Watson je pobedio
ova dva čoveka u kvizu,

00:05:50.858 --> 00:05:53.786
što je daleko teže za kompjuter
da iga od šaha.

00:05:53.810 --> 00:05:57.622
Zapravo, umesto da radi
na osnovu već definisanih recepata,

00:05:57.646 --> 00:06:01.209
Votson je morao da koristi rasuđivanje
da bi prevazišao ljudske protivnike.

00:06:02.213 --> 00:06:04.652
A onda, pre nekoliko nedelja,

00:06:04.676 --> 00:06:08.938
AlphaGo iz DeepMind-a je pobedio
ljudsko biće koje je najbolje u gou,

00:06:08.962 --> 00:06:11.174
a to je najkomplikovanija igra koju imamo.

00:06:11.198 --> 00:06:14.094
Zapravo, ima više mogućih poteza u gou

00:06:14.118 --> 00:06:16.142
nego što ima atoma u univerzumu.

00:06:18.030 --> 00:06:19.856
Pa, kako bi pobedio,

00:06:19.880 --> 00:06:22.498
AlphaGo je morao da razvije intuiciju.

00:06:22.918 --> 00:06:27.028
I zapravo, u nekim momentima
programeri AlphaGo-a nisu razumeli

00:06:27.052 --> 00:06:29.338
zašto je AlphaGo radio to što radi.

00:06:31.271 --> 00:06:32.931
A stvari se odvijaju zaista brzo.

00:06:32.955 --> 00:06:36.182
Mislim, razmotrite -
u okviru ljudskog životnog veka,

00:06:36.206 --> 00:06:38.439
kompjuteri su prešli od dečje igre

00:06:39.740 --> 00:06:42.788
do onoga što se smatra vrhuncem
strateškog mišljenja.

00:06:43.819 --> 00:06:46.236
U suštini se dešava to

00:06:46.260 --> 00:06:49.570
da kompjuteri prestaju da budu poput Spoka

00:06:49.594 --> 00:06:51.543
i postaju mnogo više nalik Kirku.

00:06:51.567 --> 00:06:55.185
(Smeh)

00:06:55.209 --> 00:06:58.633
Je li tako? Od čiste logike do intuicije.

00:07:00.004 --> 00:07:01.747
Da li biste prešli ovaj most?

00:07:02.429 --> 00:07:04.752
Većina vas govori: "Uh, nema šanse!"

00:07:04.776 --> 00:07:06.084
(Smeh)

00:07:06.108 --> 00:07:08.765
A stigli ste do te odluke
u deliću sekunde.

00:07:08.789 --> 00:07:11.217
Prosto ste nekako znali
da taj most nije bezbedan.

00:07:11.241 --> 00:07:13.230
A upravo je to tip intuicije

00:07:13.254 --> 00:07:16.822
koju naši sistemi dubinskog učenja
trenutno počinju da razvijaju.

00:07:17.542 --> 00:07:19.249
Veoma brzo ćete bukvalno moći

00:07:19.273 --> 00:07:21.479
da pokažete kompjuteru
nešto što ste napravili,

00:07:21.503 --> 00:07:22.656
što ste dizajnirali

00:07:22.680 --> 00:07:24.169
i on će to da pogleda i kaže:

00:07:24.193 --> 00:07:27.016
"Izvini, druže, to neće proći.
Moraš opet da pokušaš."

00:07:27.674 --> 00:07:30.954
Ili ćete moći da ga pitate da li će se
ljudima sviđati vaša nova pesma

00:07:31.593 --> 00:07:33.656
ili vaš novi ukus sladoleda.

00:07:35.369 --> 00:07:37.842
Ili, što je još važnije,

00:07:37.842 --> 00:07:40.416
moći ćete raditi sa kompjuterom
da biste rešili problem

00:07:40.416 --> 00:07:41.997
s kojim se pre nismo suočili.

00:07:42.021 --> 00:07:43.422
Na primer, klimatske promene.

00:07:43.446 --> 00:07:45.466
Sami ne obavljamo posao naročito dobro,

00:07:45.490 --> 00:07:47.735
svakako da bi nam koristila
sva moguća pomoć.

00:07:47.759 --> 00:07:49.211
O tome govorim,

00:07:49.211 --> 00:07:51.826
o tehnologiji koja naglašava
naše kognitivne sposobnosti

00:07:51.826 --> 00:07:55.372
kako bismo mogli da zamislimo
i dizajniramo stvari koje nisu dostupne

00:07:55.396 --> 00:07:57.955
nama, prostim starim neproširenim ljudima.

00:07:59.784 --> 00:08:02.745
Pa, o čemu se radi kod stvaranja
svih tih blesavih novih stvari

00:08:02.769 --> 00:08:05.210
koje ćemo izumeti i dizajnirati?

00:08:05.772 --> 00:08:09.865
Mislim da se u eri ljudskog proširivanja
podjednako radi o fizičkom svetu

00:08:09.889 --> 00:08:12.954
kao i o virtuelnoj, intelektualnoj sferi.

00:08:13.653 --> 00:08:15.574
Kako će nas tehnologija proširiti?

00:08:16.081 --> 00:08:18.554
U fizičkom svetu,
biće to robotski sistemi.

00:08:19.440 --> 00:08:21.176
U redu, svakako da postoji strah

00:08:21.200 --> 00:08:23.688
da će roboti da oduzmu poslove ljudima,

00:08:23.712 --> 00:08:25.542
to je tačno za određene sektore.

00:08:25.994 --> 00:08:28.872
No, mene više zanima zamisao

00:08:28.896 --> 00:08:33.906
da će ljudi i roboti radeći zajedno
proširiti jedni druge,

00:08:33.930 --> 00:08:35.902
i počeće da naseljavaju nove prostore.

00:08:35.902 --> 00:08:38.734
Ovo je primenjena istraživačka
laboratorija u San Francisku,

00:08:38.734 --> 00:08:41.740
gde je napredna robotika
jedna od oblasti na koje se fokusiramo,

00:08:41.740 --> 00:08:44.075
naročito saradnja između ljudi i robota.

00:08:44.854 --> 00:08:47.613
A ovo je Bišop, jedan od naših robota.

00:08:47.637 --> 00:08:49.426
Kao eksperiment, podesili smo ga

00:08:49.450 --> 00:08:52.910
da pomaže osobi koja na građevini
obavlja repetitivne poslove -

00:08:53.804 --> 00:08:57.998
poslove poput bušenja rupa u gips-kartonu
za utičnice ili prekidače za svetla.

00:08:58.022 --> 00:09:00.488
(Smeh)

00:09:01.697 --> 00:09:04.792
Dakle, Bišopov ljudski partner
može da mu objasni na engleskom

00:09:04.792 --> 00:09:06.237
i jednostavnom gestikulacijom,

00:09:06.237 --> 00:09:07.608
poput razgovaranja sa psom,

00:09:07.632 --> 00:09:09.775
a potom Bišop, izvodi ta uputstva

00:09:09.799 --> 00:09:11.691
savršenom preciznošću.

00:09:11.715 --> 00:09:14.704
Koristimo ljude za ono u čemu su dobri:

00:09:14.728 --> 00:09:17.061
svesnost, percepcija i donošenje odluka.

00:09:17.085 --> 00:09:19.325
A koristimo robota za ono u čemu je dobar:

00:09:19.349 --> 00:09:21.097
preciznost i ponavljanje.

00:09:22.072 --> 00:09:24.439
Još jedan sjajan projekat
na kom je radio Bišop.

00:09:24.463 --> 00:09:27.538
Cilj ovog projekta, koga smo nazvali HIVE,

00:09:27.562 --> 00:09:31.413
bio je da testira iskustvo
ljudi, kompjutera i robota

00:09:31.437 --> 00:09:34.777
gde svi rade zajedno kako bi rešili
veoma složene dizajnerske probleme.

00:09:35.553 --> 00:09:37.144
Ljudi su služili kao radna snaga.

00:09:37.144 --> 00:09:40.561
Kružili su po gradilištu,
rukovali bambusom -

00:09:40.585 --> 00:09:43.341
koji je, usput, stoga
što je neizomorfan materijal,

00:09:43.365 --> 00:09:45.239
veoma težak robotima za rukovanje.

00:09:45.263 --> 00:09:47.285
No, potom su roboti namotavali ovo vlakno,

00:09:47.309 --> 00:09:49.760
a to je skoro nemoguće za ljude da urade.

00:09:49.784 --> 00:09:53.405
A potom smo imali VI
koja je sve kontrolisala.

00:09:53.429 --> 00:09:56.719
Govorila je ljudima šta da rade,
govorila je robotima šta da rade

00:09:56.743 --> 00:09:59.658
i nadgledala hiljade
pojedinačnih komponenti.

00:09:59.682 --> 00:10:00.862
Zanimljivo je

00:10:00.886 --> 00:10:04.027
da je izgradnja ovog paviljona
prosto bila nemoguća

00:10:04.051 --> 00:10:08.575
bez ljudi, robota i VI
koji proširuju jedni druge.

00:10:09.710 --> 00:10:13.030
Podeliću sa vama još jedan projekat.
Ovaj je malčice blesav.

00:10:13.054 --> 00:10:17.522
Radimo sa umetnicima iz Amsterdama,
Jorisom Larmanom i njegovom ekipom iz MX3D

00:10:17.546 --> 00:10:20.424
da bismo generativno dizajnirali
i robotski odštampali

00:10:20.448 --> 00:10:23.443
prvi u svetu autonomno proizveden most.

00:10:24.135 --> 00:10:27.820
Dakle, Joris i VI baš dok govorimo
dizajniraju taj objekat

00:10:27.844 --> 00:10:29.016
u Amsterdamu.

00:10:29.040 --> 00:10:31.361
A kad završe, pritisnućemo "Kreni"

00:10:31.385 --> 00:10:34.696
i roboti će početi 3D tehnologijom
da štampaju nerđajući čelik

00:10:34.720 --> 00:10:38.003
i nastaviće da štampaju
bez ljudskog uplitanja,

00:10:38.027 --> 00:10:39.585
sve dok završe most.

00:10:40.919 --> 00:10:43.847
Pa, kako će roboti
da prošire našu sposobnost

00:10:43.871 --> 00:10:45.995
zamišljanja i dizajniranja novih stvari,

00:10:45.995 --> 00:10:48.940
robotski sistemi će da nam pomognu
da gradimo i pravimo stvari

00:10:48.964 --> 00:10:51.048
koje nismo mogli da pravimo pre.

00:10:52.167 --> 00:10:56.327
No, šta je s našom sposobnošću
da osetimo i kontrolišemo ove stvari?

00:10:56.351 --> 00:11:00.382
Kako bi bilo da imamo nervni sistem
kod stvari koje pravimo?

00:11:00.406 --> 00:11:02.918
Naš nervni sistem, ljudski nervni sistem,

00:11:02.942 --> 00:11:05.253
saopštava nam o svemu
što se dešava oko nas.

00:11:06.006 --> 00:11:09.690
Međutim, nervni sitem stvari
koje pravimo je u najboljem slučaju prost.

00:11:09.714 --> 00:11:13.277
Na primer, automobil ne saopštava
gradskom odseku za javne delatnosti

00:11:13.301 --> 00:11:16.431
da je upravo udario u rupu
na uglu ulice Brodvej i Morison.

00:11:16.455 --> 00:11:18.487
Građevina ne sopštava njenim dizajnerima

00:11:18.511 --> 00:11:21.195
da li ljudi unutar nje vole da budu tu,

00:11:21.219 --> 00:11:24.229
a proizvođač lutaka ne zna

00:11:24.253 --> 00:11:26.260
da li se zaista igraju
njihovim igračkama -

00:11:26.284 --> 00:11:28.823
kako, gde i da li su ili nisu zabavne.

00:11:29.440 --> 00:11:33.254
Vidite, siguran sam da su dizajneri
zamislili ovakav stil života za barbiku

00:11:33.278 --> 00:11:34.502
kada su je dizajnirali.

00:11:34.526 --> 00:11:35.973
(Smeh)

00:11:35.997 --> 00:11:38.903
Ali šta ako se ispostavi
da je barbi zapravo veoma usamljena?

00:11:38.927 --> 00:11:42.074
(Smeh)

00:11:43.086 --> 00:11:44.374
Kad bi dizajneri znali

00:11:44.378 --> 00:11:46.149
šta se zaista dešava u stvarnom svetu

00:11:46.149 --> 00:11:48.716
njihovim dizajnima - putevima,
građevinama, barbikama -

00:11:48.716 --> 00:11:50.204
mogli bi da koriste to znanje

00:11:50.204 --> 00:11:52.598
da stvore bolja iskustva za korisnike.

00:11:52.598 --> 00:11:55.069
Nedostaje nervni sistem

00:11:55.093 --> 00:11:58.802
koji bi nas povezao sa svim stvarima
koje dizajniramo, pravimo i koristimo.

00:11:59.735 --> 00:12:03.290
Šta kad biste svi vi imali
dotok takvog oblika informacija

00:12:03.314 --> 00:12:05.497
od stvari koje stvarate u stvarnom svetu?

00:12:07.252 --> 00:12:08.703
Uz sve što pravimo,

00:12:08.727 --> 00:12:11.162
trošimo ogromne količine
novca i energije -

00:12:11.186 --> 00:12:13.562
zapravo, prošle godine,
skoro dva biliona dolara -

00:12:13.586 --> 00:12:16.440
ubeđujući ljude da kupe
stvari koje pravimo.

00:12:16.464 --> 00:12:19.852
Ali kad biste imali ovakvu vezu
sa stvarima koje dizajnirate i stvarate

00:12:19.876 --> 00:12:21.603
kada se one nađu u stvarnom svetu,

00:12:21.627 --> 00:12:25.215
nakon što ih prodaju
ili lansiraju ili šta god,

00:12:25.215 --> 00:12:26.915
zapravo bismo mogli to da promenimo

00:12:26.915 --> 00:12:29.956
i da se pomerimo
od ubeđivanja ljudi da vole naše stvari

00:12:29.980 --> 00:12:33.414
do prosto pravljenja stvari
koje su ljudima prvenstveno potrebne.

00:12:33.438 --> 00:12:36.225
Dobre vesti su da radimo
na digitalnom nervnom sistemu

00:12:36.249 --> 00:12:39.050
koji bi nas povezao
sa stvarima koje dizajniramo.

00:12:40.185 --> 00:12:41.812
Radimo na jednom projektu

00:12:41.836 --> 00:12:45.548
sa nekoliko momaka iz Los Anđelesa,
koji sebe nazivaju Bandito Bradersima,

00:12:45.572 --> 00:12:46.979
i njihovom ekipom.

00:12:47.003 --> 00:12:50.436
A jedna od stvari koju ovi momci rade
je izgradnja ludih automobila

00:12:50.460 --> 00:12:53.333
koji rade potpuno lude stvari.

00:12:54.725 --> 00:12:56.175
Ovi momci su sumanuti -

00:12:56.199 --> 00:12:57.235
(Smeh)

00:12:57.259 --> 00:12:58.662
na najbolji način.

00:13:00.813 --> 00:13:02.576
A mi s njima radimo

00:13:02.600 --> 00:13:05.040
tako što uzmemo tradicionalnu
šasiju za trkačka auta

00:13:05.064 --> 00:13:06.649
i ugrađujemo nervni sistem u nju.

00:13:06.673 --> 00:13:09.731
Dakle, opskrbili smo je
desetinama senzora,

00:13:09.755 --> 00:13:12.390
stavili smo iza volana
vozača svetske klase,

00:13:12.414 --> 00:13:15.771
odvezli auto u pustinju
vozali ga do besvesti sedam dana.

00:13:15.795 --> 00:13:18.286
A nervni sistem automobila je zabeležio

00:13:18.310 --> 00:13:19.792
sve što se dešavalo automobilu.

00:13:19.816 --> 00:13:22.437
Zabeležili smo četiri milijarde
jedinica podataka;

00:13:22.461 --> 00:13:24.771
sve sile kojima je bilo izloženo.

00:13:24.795 --> 00:13:26.454
A potom smo uradili nešto ludo.

00:13:27.088 --> 00:13:28.588
Uzeli smo sve podatke

00:13:28.612 --> 00:13:32.348
i priključili ih na VI genrativnog dizajna
koju nazivamo "Dreamcatcher".

00:13:33.090 --> 00:13:37.054
Pa, šta dobijate kada dizajnerskom oruđu
date nervni sistem

00:13:37.078 --> 00:13:39.960
i zatražite od njega da vam sagradi
najbolju šasiju za auto?

00:13:40.543 --> 00:13:42.516
Dobijate ovo.

00:13:44.113 --> 00:13:47.826
Ovo je nešto što ljudi
nikad ne bi mogli da dizajniraju.

00:13:48.527 --> 00:13:50.415
Samo što ljudi ovo jesu dizajnirali,

00:13:50.439 --> 00:13:54.732
ali to su bili ljudi prošireni
VI generativnog dizajna,

00:13:54.732 --> 00:13:56.043
digitalnim nervnim sistemom

00:13:56.043 --> 00:13:59.032
i robotima koji zapravo mogu
da proizvedu nešto ovakvo.

00:13:59.500 --> 00:14:03.095
Pa, ako je ovo budućnost, prošireno doba,

00:14:03.119 --> 00:14:07.380
a mi ćemo da budemo prošireni
kognitivno, fizički i čulno,

00:14:07.404 --> 00:14:08.812
kako će to da izgleda?

00:14:09.396 --> 00:14:12.717
Kako će da izgleda ova zemlja čuda?

00:14:12.741 --> 00:14:14.450
Mislim da ćemo da vidimo svet

00:14:14.474 --> 00:14:17.542
u kom se udaljavamo
od stvari koje se proizvode

00:14:17.566 --> 00:14:19.011
do stvari koje se obrađuju.

00:14:19.979 --> 00:14:23.432
U kom se udaljavamo od stvari
koje se konstruišu

00:14:23.456 --> 00:14:25.160
do onih koje se gaje.

00:14:25.954 --> 00:14:28.142
Udaljićemo se od izolacije

00:14:28.166 --> 00:14:29.776
ka povezanosti.

00:14:30.454 --> 00:14:32.865
I udaljićemo se od kopanja

00:14:32.889 --> 00:14:34.762
ka sakupljanju.

00:14:35.787 --> 00:14:39.554
Mislim i da ćemo se pomeriti
od žudnje da nam stvari budu poslušne

00:14:39.578 --> 00:14:41.219
ka cenjenju autonomije.

00:14:42.330 --> 00:14:44.345
Zahvaljujući našim
proširenim mogućnostima,

00:14:44.345 --> 00:14:46.636
naš svet će da se drastično izmeni.

00:14:47.396 --> 00:14:50.642
Imaćemo svet s više izbora,
više povezanosti,

00:14:50.666 --> 00:14:52.953
dinamičniji, složeniji

00:14:52.977 --> 00:14:55.295
prilagodljiviji i, naravno,

00:14:55.319 --> 00:14:56.536
lepši.

00:14:57.051 --> 00:14:58.615
Obrisi budućnosti

00:14:58.639 --> 00:15:00.929
neće da liče na bilo šta
što smo videli do sad.

00:15:00.953 --> 00:15:02.112
Zašto?

00:15:02.136 --> 00:15:05.891
Jer će sve ovo da oblikuje
novo partnerstvo

00:15:05.915 --> 00:15:09.585
između tehnologije, prirode i čovečanstva.

00:15:11.099 --> 00:15:14.903
Za mene, to je budućnost
koju vredi iščekivati.

00:15:14.927 --> 00:15:16.198
Mnogo vam hvala.

00:15:16.222 --> 00:15:21.891
(Aplauz)

