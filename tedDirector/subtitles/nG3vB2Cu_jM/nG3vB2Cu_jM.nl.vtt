WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Kyon Adriaans
Nagekeken door: Els De Keyser

00:00:15.260 --> 00:00:17.260
Macht.

00:00:17.260 --> 00:00:19.260
Dat is het woord waaraan ik moet denken.

00:00:19.260 --> 00:00:21.260
We zijn de nieuwe technologen.

00:00:21.260 --> 00:00:24.260
We hebben een heleboel data, dus we hebben een heleboel macht.

00:00:24.260 --> 00:00:26.260
Hoeveel macht hebben we?

00:00:26.260 --> 00:00:29.260
Scène uit een film: "Apocalypse Now" -- geweldige film.

00:00:29.260 --> 00:00:32.260
We moeten onze held, Kap. Willard, bij de monding van de Nung rivier krijgen

00:00:32.260 --> 00:00:34.260
zodat hij achter Kol. Kurtz aan kan gaan.

00:00:34.260 --> 00:00:36.260
We gaan dat doen door hem er naartoe te vliegen en af te zetten.

00:00:36.260 --> 00:00:38.260
Dus de scène:

00:00:38.260 --> 00:00:41.260
de horizon is gevuld met een vloot helikopters die hem brengt.

00:00:41.260 --> 00:00:43.260
Er is luide, spannende muziek op de achtergrond,

00:00:43.260 --> 00:00:45.260
ruige muziek.

00:00:45.260 --> 00:00:47.260
♫ Dum da ta da dum ♫

00:00:47.260 --> 00:00:49.260
♫ Dum da ta da dum ♫

00:00:49.260 --> 00:00:52.260
♫ Da ta da da ♫

00:00:52.260 --> 00:00:54.260
Dat is een heleboel macht.

00:00:54.260 --> 00:00:56.260
Dat is het soort macht dat ik in deze ruimte voel.

00:00:56.260 --> 00:00:58.260
Dat is het soort macht dat wij hebben

00:00:58.260 --> 00:01:00.260
door alle data die we hebben.

00:01:00.260 --> 00:01:02.260
Laten we een voorbeeld nemen.

00:01:02.260 --> 00:01:04.260
Wat kunnen we doen

00:01:04.260 --> 00:01:07.260
met de data van maar één persoon?

00:01:07.260 --> 00:01:09.260
Wat kunnen we doen

00:01:09.260 --> 00:01:11.260
met de data van die kerel?

00:01:11.260 --> 00:01:13.260
Ik kan je financiële gegevens bekijken.

00:01:13.260 --> 00:01:15.260
Ik kan zeggen of jij je rekeningen op tijd betaalt.

00:01:15.260 --> 00:01:17.260
Ik weet of je kredietwaardig bent.

00:01:17.260 --> 00:01:20.260
Ik kan je medische gegevens bekijken, ik kan zien of je rikketik nog tikt --

00:01:20.260 --> 00:01:23.260
zien of je we je een verzekering kunnen aanbieden.

00:01:23.260 --> 00:01:25.260
Ik kan je klikpatronen bekijken.

00:01:25.260 --> 00:01:28.260
Wanneer je op mijn website komt, weet ik eigenlijk al wat je gaat doen,

00:01:28.260 --> 00:01:30.260
want hiervoor heb ik je miljoenen websites zien bezoeken.

00:01:30.260 --> 00:01:32.260
En het spijt me dat ik het je zeg,

00:01:32.260 --> 00:01:34.260
je bent als een pokerspeler, je hebt een "tell".

00:01:34.260 --> 00:01:36.260
Ik kan door middel van data-analyse zeggen wat je gaat doen

00:01:36.260 --> 00:01:38.260
zelfs voordat je het doet.

00:01:38.260 --> 00:01:41.260
Ik weet wat je leuk vindt. Ik weet wie je bent.

00:01:41.260 --> 00:01:43.260
En dat is nog voordat ik naar je post kijk

00:01:43.260 --> 00:01:45.260
of naar je telefoon.

00:01:45.260 --> 00:01:47.260
Dat is het soort dingen dat we kunnen doen

00:01:47.260 --> 00:01:50.260
met de data die we hebben.

00:01:50.260 --> 00:01:53.260
Maar ik ben eigenlijk niet hier om te praten over wat we kúnnen doen.

00:01:56.260 --> 00:01:59.260
Ik ben hier om te praten over wat we zouden moeten doen.

00:02:00.260 --> 00:02:03.260
Wat is het juiste om te doen?

00:02:04.260 --> 00:02:06.260
Nu zie ik wat verbaasde blikken:

00:02:06.260 --> 00:02:09.260
"Waarom vraag je ons wat het juiste is om te doen?

00:02:09.260 --> 00:02:12.260
We bouwen dit spul alleen. Iemand anders gebruikt het."

00:02:12.260 --> 00:02:15.260
Niets mis mee.

00:02:15.260 --> 00:02:17.260
Maar het laat me terugdenken.

00:02:17.260 --> 00:02:19.260
Ik denk aan de Tweede Wereldoorlog --

00:02:19.260 --> 00:02:21.260
sommige van onze grootse technologen toen,

00:02:21.260 --> 00:02:23.260
sommige van onze grootse natuurkundigen

00:02:23.260 --> 00:02:25.260
die kernsplijting en kernfusie bestudeerden --

00:02:25.260 --> 00:02:27.260
nucleaire dingen.

00:02:27.260 --> 00:02:30.260
We brengen deze natuurkundigen bijeen in Los Alamos

00:02:30.260 --> 00:02:33.260
om te zien wat zij gaan maken.

00:02:33.260 --> 00:02:36.260
We willen dat de mensen die de technologie ontwikkelen,

00:02:36.260 --> 00:02:39.260
nadenken over wat we zouden moeten doen met de technologie.

00:02:41.260 --> 00:02:44.260
Dus wat zouden we moeten doen met de data van die kerel?

00:02:44.260 --> 00:02:47.260
Moeten we ze inzamelen, verzamelen,

00:02:47.260 --> 00:02:49.260
zodat we zijn online belevenis beter kunnen maken?

00:02:49.260 --> 00:02:51.260
Zodat we geld kunnen verdienen?

00:02:51.260 --> 00:02:53.260
Zodat we onszelf kunnen beschermen

00:02:53.260 --> 00:02:55.260
wanneer hij iets slechts van plan zou zijn?

00:02:55.260 --> 00:02:58.260
Of moeten we zijn privacy respecteren,

00:02:58.260 --> 00:03:01.260
zijn waardigheid beschermen en hem met rust laten?

00:03:02.260 --> 00:03:05.260
Welke van de twee is het?

00:03:05.260 --> 00:03:07.260
Hoe zouden we daar achter kunnen komen?

00:03:07.260 --> 00:03:10.260
Ik weet het: "crowdsourcen". Laten we dit "crowdsourcen".

00:03:11.260 --> 00:03:14.260
Laten we, om op te warmen,

00:03:14.260 --> 00:03:16.260
beginnen met een makkelijke vraag --

00:03:16.260 --> 00:03:19.260
iets waar iedereen hier wel een mening over heeft:

00:03:19.260 --> 00:03:21.260
iPhone versus Android.

00:03:21.260 --> 00:03:24.260
Laten we handen tellen -- iPhone.

00:03:24.260 --> 00:03:26.260
Uh huh.

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
Je zou denken dat met een groep slimme mensen

00:03:31.260 --> 00:03:33.260
we niet zo'n zwakte zouden hebben voor de mooie telefoons.

00:03:33.260 --> 00:03:35.260
(Gelach)

00:03:35.260 --> 00:03:37.260
Volgende vraag,

00:03:37.260 --> 00:03:39.260
een beetje moeilijker.

00:03:39.260 --> 00:03:41.260
Zouden we de data van die kerel moeten inzamelen

00:03:41.260 --> 00:03:43.260
om zijn belevenissen te verbeteren

00:03:43.260 --> 00:03:46.260
en onszelf te beschermen wanneer hij iets slechts van plan is?

00:03:46.260 --> 00:03:48.260
Of moeten we hem met rust laten?

00:03:48.260 --> 00:03:51.260
Verzamel zijn data.

00:03:53.260 --> 00:03:56.260
Laat hem met rust.

00:03:56.260 --> 00:03:58.260
Je zit veilig. Het is al goed.

00:03:58.260 --> 00:04:00.260
(Gelach)

00:04:00.260 --> 00:04:02.260
Oké, laatste vraag --

00:04:02.260 --> 00:04:04.260
moeilijkere vraag --

00:04:04.260 --> 00:04:07.260
wanneer we proberen te beoordelen

00:04:07.260 --> 00:04:10.260
wat we zouden moeten doen in dit geval,

00:04:10.260 --> 00:04:14.260
moeten we dan een kantiaans, deontologisch ethisch kader gebruiken,

00:04:14.260 --> 00:04:17.260
of een milliaans, consequentialistisch kader?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
Niet zoveel stemmen als net.

00:04:27.260 --> 00:04:30.260
(Gelach)

00:04:30.260 --> 00:04:33.260
Ja, dat is een verschikkelijk resultaat.

00:04:34.260 --> 00:04:38.260
Verschrikkelijk, omdat we een sterkere mening hebben

00:04:38.260 --> 00:04:40.260
over onze mobiele apparaten

00:04:40.260 --> 00:04:42.260
dan over het ethisch kader

00:04:42.260 --> 00:04:44.260
dat we zouden moeten gebruiken om richting te geven aan onze beslissingen.

00:04:44.260 --> 00:04:47.260
Hoe weten we wat we moeten doen met al de macht die we hebben

00:04:47.260 --> 00:04:50.260
als we geen ethish kader hebben?

00:04:50.260 --> 00:04:53.260
We weten meer over mobiele besturingssystemen,

00:04:53.260 --> 00:04:56.260
maar wat we echt nodig hebben is een ethisch besturingssysteem.

00:04:58.260 --> 00:05:00.260
Wat is een ethisch besturingssysteem?

00:05:00.260 --> 00:05:02.260
We weten allemaal wat goed of fout is.

00:05:02.260 --> 00:05:04.260
Je voelt je goed wanneer je iets goed doet,

00:05:04.260 --> 00:05:06.260
je voelt je slecht wanneer je iets fout doet.

00:05:06.260 --> 00:05:09.260
Onze ouders leren ons dat: wie zoet is krijgt lekkers, wie stout is de roe.

00:05:09.260 --> 00:05:12.260
Maar hoe kunnen we bepalen wat goed en fout is?

00:05:12.260 --> 00:05:15.260
In onze dagelijkse routine gebruiken we daar bepaalde technieken voor.

00:05:15.260 --> 00:05:18.260
Misschien gaan we op ons gevoel af.

00:05:18.260 --> 00:05:21.260
Misschien houden we een stemming -- we "crowdsourcen".

00:05:21.260 --> 00:05:23.260
Of misschien geven we het op --

00:05:23.260 --> 00:05:26.260
vraag het de juridische afdeling, kijk wat zij zeggen.

00:05:26.260 --> 00:05:28.260
Met andere woorden, het is wat willekeurig,

00:05:28.260 --> 00:05:30.260
nogal ad hoc,

00:05:30.260 --> 00:05:33.260
hoe we bepalen wat we zouden moeten doen.

00:05:33.260 --> 00:05:36.260
Als we meer houvast willen,

00:05:36.260 --> 00:05:39.260
is onze echte nood misschien een ethisch kader dat ons kan leiden,

00:05:39.260 --> 00:05:42.260
dat ons zegt welke soort dingen goed en fout zijn op de eerste plaats,

00:05:42.260 --> 00:05:46.260
en hoe we in een bepaalde situatie kunnen weten wat te doen.

00:05:46.260 --> 00:05:48.260
Dus laten we een ethisch kader verkrijgen.

00:05:48.260 --> 00:05:51.260
We zijn cijfermensen, we leven met cijfers.

00:05:51.260 --> 00:05:53.260
Hoe kunnen we cijfers gebruiken

00:05:53.260 --> 00:05:56.260
als basis voor een ethisch kader?

00:05:56.260 --> 00:05:59.260
Ik ken een man die precies dat heeft gedaan,

00:05:59.260 --> 00:06:02.260
Een briljante kerel --

00:06:02.260 --> 00:06:05.260
hij is al 2.500 jaar dood.

00:06:05.260 --> 00:06:07.260
Plato, juist.

00:06:07.260 --> 00:06:09.260
Herinner je hem -- oude filosoof?

00:06:09.260 --> 00:06:12.260
Je lag te slapen tijdens die les.

00:06:12.260 --> 00:06:14.260
Plato was bezorgd over veelal dezelfde dingen zoals wij.

00:06:14.260 --> 00:06:16.260
Hij bekommerde zich over goed en slecht.

00:06:16.260 --> 00:06:18.260
Hij wilde weten wat juist is.

00:06:18.260 --> 00:06:20.260
Maar het verontrustte hem dat het enige wat we lijken te doen,

00:06:20.260 --> 00:06:22.260
het uitwisselen van meningen is.

00:06:22.260 --> 00:06:25.260
Hij zegt iets wat juist is. Zij zegt iets anders wat juist is.

00:06:25.260 --> 00:06:27.260
Wat hij zegt klinkt overtuigend en wat zij zegt ook.

00:06:27.260 --> 00:06:29.260
Ik ga alleen heen en weer; zo kom ik nergens.

00:06:29.260 --> 00:06:32.260
Ik wil geen meningen, ik wil kennis.

00:06:32.260 --> 00:06:35.260
Ik wil de waarheid weten over rechtvaardigheid --

00:06:35.260 --> 00:06:38.260
zoals we waarheden kennen in de wiskunde.

00:06:38.260 --> 00:06:41.260
In de wiskunde kennen we de objectieve feiten.

00:06:41.260 --> 00:06:43.260
Neem een getal, welk getal dan ook -- twee.

00:06:43.260 --> 00:06:45.260
Favoriete getal. Ik hou van dat getal.

00:06:45.260 --> 00:06:47.260
Er zijn waarheden over twee.

00:06:47.260 --> 00:06:49.260
Als je twee van iets hebt,

00:06:49.260 --> 00:06:51.260
en je doet er twee bij, dan krijg je vier.

00:06:51.260 --> 00:06:53.260
Dat is waar ongeacht het ding waarover je het hebt.

00:06:53.260 --> 00:06:55.260
Het is een objectieve waarheid over de Idee van twee,

00:06:55.260 --> 00:06:57.260
de abstracte vorm.

00:06:57.260 --> 00:06:59.260
Wanneer je twee dingen hebt van iets -- twee ogen, twee oren, twee neuzen,

00:06:59.260 --> 00:07:01.260
gewoon twee uitsteeksels --

00:07:01.260 --> 00:07:04.260
dan hebben die alle deel aan de Idee van twee.

00:07:04.260 --> 00:07:08.260
Ze nemen alle deel aan de waarheden die twee heeft.

00:07:08.260 --> 00:07:10.260
Ze hebben alle tweeheid in zich.

00:07:10.260 --> 00:07:13.260
En daarom is het geen kwestie van mening.

00:07:13.260 --> 00:07:15.260
Wat als, dacht Plato,

00:07:15.260 --> 00:07:17.260
ethiek zou zijn zoals wiskunde?

00:07:17.260 --> 00:07:20.260
Wat als er een zuivere Idee van rechtvaardigheid zou zijn?

00:07:20.260 --> 00:07:22.260
Wat als er waarheden zijn over rechtvaardigheid,

00:07:22.260 --> 00:07:24.260
en je gewoon zou kunnen rondkijken in deze wereld

00:07:24.260 --> 00:07:26.260
en zien welke dingen,

00:07:26.260 --> 00:07:29.260
deel hebben aan die Idee van rechtvaardigheid?

00:07:29.260 --> 00:07:32.260
Dan zou je weten wat echt juist is en wat niet.

00:07:32.260 --> 00:07:34.260
Het zou geen zaak zijn

00:07:34.260 --> 00:07:37.260
van gewoon een mening of gewoon schijn.

00:07:37.260 --> 00:07:39.260
Dat is een sensationele visie.

00:07:39.260 --> 00:07:42.260
Ik bedoel, stel je eens voor. Hoe groots. Hoe ambitieus.

00:07:42.260 --> 00:07:44.260
Dat is zo ambitieus als wij zijn.

00:07:44.260 --> 00:07:46.260
Hij wil ethiek oplossen.

00:07:46.260 --> 00:07:48.260
Hij wil objectieve waarheden.

00:07:48.260 --> 00:07:51.260
Als je zo denkt,

00:07:51.260 --> 00:07:54.260
heb je een platonisch ethisch kader.

00:07:54.260 --> 00:07:56.260
Als je niet zo denkt,

00:07:56.260 --> 00:07:58.260
nou, dan heb je veel gezelschap in de geschiedenis van de westerse filosofie,

00:07:58.260 --> 00:08:01.260
omdat er veel kritiek kwam op het aardige idee.

00:08:01.260 --> 00:08:04.260
Aristoteles in het bijzonder, werd er niet vrolijk van.

00:08:04.260 --> 00:08:07.260
Hij vond het onpraktisch.

00:08:07.260 --> 00:08:11.260
Aristoteles zei: "We moeten voor elk onderwerp maar zoveel precisie nastreven

00:08:11.260 --> 00:08:13.260
als het onderwerp toelaat."

00:08:13.260 --> 00:08:16.260
Aristoteles vond niet dat ethiek vergelijkbaar was met wiskunde.

00:08:16.260 --> 00:08:19.260
Hij dacht dat ethiek een zaak was van beslissingen nemen in het hier en nu

00:08:19.260 --> 00:08:21.260
zo goed mogelijk oordelen

00:08:21.260 --> 00:08:23.260
om het juiste pad te vinden.

00:08:23.260 --> 00:08:25.260
Als je dat denkt, dan is Plato niet jouw man.

00:08:25.260 --> 00:08:27.260
Maar geef niet op.

00:08:27.260 --> 00:08:29.260
Misschien is er een andere manier

00:08:29.260 --> 00:08:32.260
om getallen te gebruiken als de basis voor ons ethisch kader.

00:08:33.260 --> 00:08:35.260
Stel je voor:

00:08:35.260 --> 00:08:38.260
wat als, in welke situatie ook, je gewoon zou kunnen berekenen,

00:08:38.260 --> 00:08:40.260
de keuzes bekijken,

00:08:40.260 --> 00:08:43.260
afwegen welke beter is en weten wat te doen?

00:08:43.260 --> 00:08:45.260
Dat klinkt bekend?

00:08:45.260 --> 00:08:48.260
Dat is een utilitaristisch ethisch kader.

00:08:48.260 --> 00:08:50.260
John Stuart Mill was hier een pleitbezorger van --

00:08:50.260 --> 00:08:52.260
aardige kerel trouwens --

00:08:52.260 --> 00:08:54.260
en pas 200 jaar dood.

00:08:54.260 --> 00:08:56.260
Dus de basis van utilitarisme --

00:08:56.260 --> 00:08:58.260
Ik weet zeker dat je er minstens bekend mee bent.

00:08:58.260 --> 00:09:00.260
De drie mensen die eerder voor Mill stemden zijn hier bekend mee.

00:09:00.260 --> 00:09:02.260
Het werkt zo.

00:09:02.260 --> 00:09:05.260
Wat als fatsoen, wat als dat wat iets zedelijk maakt,

00:09:05.260 --> 00:09:07.260
slechts een kwestie is van of het plezier maximaliseert

00:09:07.260 --> 00:09:09.260
en pijn minimaliseert?

00:09:09.260 --> 00:09:12.260
Het heeft een intrinsiek effect op de handeling.

00:09:12.260 --> 00:09:14.260
Het is niet zoals haar relatie tot een abstracte vorm.

00:09:14.260 --> 00:09:16.260
Het is enkel een zaak van de consequenties.

00:09:16.260 --> 00:09:18.260
Je kijkt simpelweg naar de consequenties

00:09:18.260 --> 00:09:20.260
en ziet of het, in totaliteit, ten goede of ten kwade is.

00:09:20.260 --> 00:09:22.260
Dat zou simpel zijn. Dan weten we wat te doen.

00:09:22.260 --> 00:09:24.260
Laten we een voorbeeld nemen.

00:09:24.260 --> 00:09:26.260
Stel dat ik een stap verder ga

00:09:26.260 --> 00:09:28.260
en ik zeg: "Ik ga jouw telefoon afnemen."

00:09:28.260 --> 00:09:30.260
Niet enkel omdat deze daarnet overging,

00:09:30.260 --> 00:09:33.260
maar ik ga hem afnemen omdat ik een kleine berekening heb gemaakt.

00:09:33.260 --> 00:09:36.260
Ik dacht: die kerel ziet verdacht uit.

00:09:36.260 --> 00:09:39.260
Wat als hij berichtjes aan het sturen is naar Bin Ladens schuilplaats --

00:09:39.260 --> 00:09:41.260
of wie het ook overgenomen heeft na Bin Laden --

00:09:41.260 --> 00:09:44.260
en hij is eigenlijk een terrorist, een "sleeper cell".

00:09:44.260 --> 00:09:47.260
Ik ga daar achter komen, en wanneer ik daar achter kom,

00:09:47.260 --> 00:09:50.260
ga ik een enorme hoeveelheid schade voorkomen die hij zou kunnen veroorzaken.

00:09:50.260 --> 00:09:53.260
Dat heeft erg veel nut om die schade te voorkomen.

00:09:53.260 --> 00:09:55.260
Vergeleken met de geringe pijn die het gaat aanrichten --

00:09:55.260 --> 00:09:57.260
want het zal gênant zijn wanneer ik zijn telefoon bekijk

00:09:57.260 --> 00:10:00.260
en zie dat hij een "Farmville" probleem heeft en de hele mikmak --

00:10:00.260 --> 00:10:03.260
dat is niets vergeleken

00:10:03.260 --> 00:10:05.260
met de waarde van het bekijken van de telefoon.

00:10:05.260 --> 00:10:07.260
Als je het daar mee eens bent,

00:10:07.260 --> 00:10:10.260
dan is dat een utilitaristische keuze.

00:10:10.260 --> 00:10:13.260
Maar misschien ben je het daar ook niet mee eens.

00:10:13.260 --> 00:10:15.260
Misschien denk je: het is zijn telefoon.

00:10:15.260 --> 00:10:17.260
Het is verkeerd om zijn telefoon te pakken,

00:10:17.260 --> 00:10:19.260
want hij is een persoon

00:10:19.260 --> 00:10:21.260
en hij heeft rechten en hij heeft waardigheid,

00:10:21.260 --> 00:10:23.260
en we kunnen daar niet zomaar inbreuk op maken.

00:10:23.260 --> 00:10:25.260
Hij heeft autonomie.

00:10:25.260 --> 00:10:27.260
Het maakt niet uit wat de berekeningen zijn.

00:10:27.260 --> 00:10:30.260
Er zijn dingen die intrinsiek verkeerd zijn --

00:10:30.260 --> 00:10:32.260
zoals liegen verkeerd is,

00:10:32.260 --> 00:10:35.260
zoals het martelen van onschuldige kinderen verkeerd is.

00:10:35.260 --> 00:10:38.260
Kant was erg sterk op dit punt,

00:10:38.260 --> 00:10:40.260
en hij zei het iets beter dan hoe ik het zeg.

00:10:40.260 --> 00:10:42.260
Hij zei dat we onze rede moeten gebruiken

00:10:42.260 --> 00:10:45.260
om tot de regels te komen waarmee we ons gedrag dienen te sturen.

00:10:45.260 --> 00:10:48.260
En dan is het onze plicht

00:10:48.260 --> 00:10:51.260
om die regels te volgen. Het is geen zaak van berekening.

00:10:51.260 --> 00:10:53.260
Dus laten we stoppen.

00:10:53.260 --> 00:10:56.260
We zitten er midden in, in deze filosofische wirwar.

00:10:56.260 --> 00:10:59.260
En dit gaat zo duizenden jaren door,

00:10:59.260 --> 00:11:01.260
want dit zijn lastige vragen,

00:11:01.260 --> 00:11:03.260
en ik heb maar 15 minuten.

00:11:03.260 --> 00:11:05.260
Laten we ons beperken tot de hoofdvraag.

00:11:05.260 --> 00:11:09.260
Hoe moeten we onze beslissingen nemen?

00:11:09.260 --> 00:11:12.260
Is het Plato, is het Aristoteles, is het Kant, is het Mill?

00:11:12.260 --> 00:11:14.260
Wat moeten we doen? Wat is het antwoord?

00:11:14.260 --> 00:11:17.260
Wat is de formule die we kunnen gebruiken

00:11:17.260 --> 00:11:19.260
in elke situatie om te bepalen wat we moeten doen,

00:11:19.260 --> 00:11:21.260
of we die kerel zijn data moeten gebruiken of niet?

00:11:21.260 --> 00:11:24.260
Wat is de formule?

00:11:25.260 --> 00:11:27.260
Er is geen formule.

00:11:29.260 --> 00:11:31.260
Er is geen simpel antwoord.

00:11:31.260 --> 00:11:34.260
Ethiek is moeilijk.

00:11:34.260 --> 00:11:37.260
Ethiek vereist denkwerk.

00:11:38.260 --> 00:11:40.260
En dat is ongemakkelijk.

00:11:40.260 --> 00:11:42.260
Ik weet het. Tijdens mijn carrière heb ik me veel beziggehouden

00:11:42.260 --> 00:11:44.260
met kunstmatige intelligentie,

00:11:44.260 --> 00:11:47.260
geprobeerd om machines te bouwen die wat van dit denken voor ons kunnen doen,

00:11:47.260 --> 00:11:49.260
die ons antwoorden kunnen geven.

00:11:49.260 --> 00:11:51.260
Maar ze kunnen het niet.

00:11:51.260 --> 00:11:53.260
Je kunt niet zomaar menselijk denken nemen

00:11:53.260 --> 00:11:55.260
en het in een machine stoppen.

00:11:55.260 --> 00:11:58.260
Wij zijn degenen die het moeten doen.

00:11:58.260 --> 00:12:01.260
Gelukkig zijn wij geen machines en kunnen we het doen.

00:12:01.260 --> 00:12:03.260
Niet alleen kunnen we denken,

00:12:03.260 --> 00:12:05.260
we moeten.

00:12:05.260 --> 00:12:07.260
Hannah Arendt zei:

00:12:07.260 --> 00:12:09.260
"De trieste waarheid

00:12:09.260 --> 00:12:11.260
is dat het meeste kwaad in deze wereld

00:12:11.260 --> 00:12:13.260
niet is gedaan door mensen

00:12:13.260 --> 00:12:15.260
die kiezen om slecht te zijn.

00:12:15.260 --> 00:12:18.260
Het komt voort uit niet denken."

00:12:18.260 --> 00:12:22.260
Dat is wat zij noemde "de banaliteit van het kwaad".

00:12:22.260 --> 00:12:24.260
De reactie daarop

00:12:24.260 --> 00:12:26.260
is dat we elk weldenkend persoon

00:12:26.260 --> 00:12:29.260
verzoeken om na te denken.

00:12:29.260 --> 00:12:31.260
Dus laten we dat doen. Laten we nadenken.

00:12:31.260 --> 00:12:34.260
Sterker nog, laten we nu meteen beginnen.

00:12:34.260 --> 00:12:37.260
Iedereen in deze ruimte, doe dit:

00:12:37.260 --> 00:12:40.260
denk aan de laatste keer dat je een beslissing moest nemen

00:12:40.260 --> 00:12:42.260
waarbij je bezorgd was om het juiste te doen,

00:12:42.260 --> 00:12:44.260
waarbij je jezelf afvroeg: "Wat zou ik moeten doen?"

00:12:44.260 --> 00:12:46.260
Neem dat in gedachten.

00:12:46.260 --> 00:12:48.260
Reflecteer daar nu over

00:12:48.260 --> 00:12:51.260
en zeg: "Hoe kwam ik tot die beslissing?

00:12:51.260 --> 00:12:54.260
Wat heb ik gedaan? Volgde ik mijn intuïtie?

00:12:54.260 --> 00:12:56.260
Liet ik erover stemmen? Of schoof ik het af naar juridisch?"

00:12:56.260 --> 00:12:59.260
We hebben nu een paar keuzes extra.

00:12:59.260 --> 00:13:01.260
"Heb ik beoordeeld wat

00:13:01.260 --> 00:13:03.260
het meeste plezier zou opleveren zoals Mill zou doen?

00:13:03.260 --> 00:13:06.260
Of heb ik, zoals Kant, de rede gebruikt om erachter te komen wat intrinsiek goed was?"

00:13:06.260 --> 00:13:09.260
Denk erover. Hou het goed in gedachten. Dit is belangrijk.

00:13:09.260 --> 00:13:11.260
Het is zo belangrijk

00:13:11.260 --> 00:13:13.260
dat we 30 seconden waardevolle TEDTalk tijd gaan besteden

00:13:13.260 --> 00:13:15.260
aan niets anders dan hierover denken.

00:13:15.260 --> 00:13:17.260
Ben je er klaar voor? Start.

00:13:33.260 --> 00:13:36.260
Stop. Goed werk.

00:13:36.260 --> 00:13:38.260
Wat je zojuist deed,

00:13:38.260 --> 00:13:40.260
dat is de eerste stap richting het nemen van verantwoordelijkheid

00:13:40.260 --> 00:13:43.260
voor wat we moeten doen met al onze macht.

00:13:45.260 --> 00:13:48.260
Nu de volgende stap -- probeer dit.

00:13:49.260 --> 00:13:51.260
Ga naar een vriend en leg hem uit

00:13:51.260 --> 00:13:53.260
hoe je die beslissing genomen hebt.

00:13:53.260 --> 00:13:55.260
Niet nu meteen. Wacht tot ik klaar ben met praten.

00:13:55.260 --> 00:13:57.260
Doe het tijdens de lunch.

00:13:57.260 --> 00:14:00.260
En ga niet weer naar een vriend-technoloog;

00:14:00.260 --> 00:14:02.260
zoek iemand, anders dan jezelf.

00:14:02.260 --> 00:14:04.260
Zoek een artiest of een schrijver --

00:14:04.260 --> 00:14:07.260
of, god verhoede, ga naar een filosoof en praat met hem.

00:14:07.260 --> 00:14:09.260
Ga naar iemand van de geesteswetenschappen.

00:14:09.260 --> 00:14:11.260
Waarom? Omdat zij anders over problemen nadenken

00:14:11.260 --> 00:14:13.260
dan dat wij doen als technologen.

00:14:13.260 --> 00:14:16.260
Pas een paar dagen geleden zijn hier aan de overkant van de straat,

00:14:16.260 --> 00:14:18.260
honderden mensen samengekomen.

00:14:18.260 --> 00:14:20.260
Het waren technologen en humanisten

00:14:20.260 --> 00:14:22.260
bij die grote BiblioTech-conferentie.

00:14:22.260 --> 00:14:24.260
Zij kwamen samen

00:14:24.260 --> 00:14:26.260
omdat de technologen wilden leren

00:14:26.260 --> 00:14:29.260
hoe het zou zijn om te denken vanuit een geesteswetenschappelijk perspectief.

00:14:29.260 --> 00:14:31.260
Je hebt iemand van Google

00:14:31.260 --> 00:14:33.260
die praat met iemand die bezig is met vergelijkende literatuurwetenschap.

00:14:33.260 --> 00:14:36.260
Je denkt over de relevantie van 17e-eeuws Frans theater --

00:14:36.260 --> 00:14:38.260
wat heeft dat te maken met durfkapitaal?

00:14:38.260 --> 00:14:41.260
Dat is interessant. Dat is een andere manier van denken.

00:14:41.260 --> 00:14:43.260
En als je op die manier denkt,

00:14:43.260 --> 00:14:46.260
dan word je gevoeliger voor de menselijke overwegingen,

00:14:46.260 --> 00:14:49.260
die cruciaal zijn voor het maken van ethische beslissingen.

00:14:49.260 --> 00:14:51.260
Stel je dus voor dat je op dit moment

00:14:51.260 --> 00:14:53.260
je vriend-muzikant was gaan opzoeken.

00:14:53.260 --> 00:14:56.260
Je vertelt hem waar wij het over hebben,

00:14:56.260 --> 00:14:58.260
over onze hele datarevolutie en alles --

00:14:58.260 --> 00:15:00.260
misschien neurie je zelf een paar maten van onze herkenningsmelodie.

00:15:00.260 --> 00:15:03.260
♫ Dum ta da da dum dum ta da da dum ♫

00:15:03.260 --> 00:15:05.260
Je vriend-muzikant

00:15:05.260 --> 00:15:07.260
zal je onderbreken en zeggen: "Weet je,

00:15:07.260 --> 00:15:09.260
de herkenningsmelodie voor jouw datarevolutie,

00:15:09.260 --> 00:15:11.260
dat is een opera,

00:15:11.260 --> 00:15:13.260
dat is Wagner. Het is gebaseerd op een Noordse mythe.

00:15:13.260 --> 00:15:15.260
Het zijn goden en mythische wezens

00:15:15.260 --> 00:15:18.260
die strijden om magische juwelen."

00:15:19.260 --> 00:15:22.260
Dat is interessant.

00:15:22.260 --> 00:15:25.260
Het is ook een mooie opera.

00:15:25.260 --> 00:15:28.260
En we zijn ontroerd door die opera.

00:15:28.260 --> 00:15:30.260
We zijn ontroerd omdat het over een strijd gaat

00:15:30.260 --> 00:15:32.260
tussen goed en kwaad,

00:15:32.260 --> 00:15:34.260
over juist en fout.

00:15:34.260 --> 00:15:36.260
En we geven om juist en fout.

00:15:36.260 --> 00:15:39.260
We geven om wat er gebeurt in die opera.

00:15:39.260 --> 00:15:42.260
We geven om wat er gebeurt in "Apocalypse Now."

00:15:42.260 --> 00:15:44.260
En we geven zeker om

00:15:44.260 --> 00:15:46.260
wat er gebeurt met onze technologieën.

00:15:46.260 --> 00:15:48.260
We hebben zo veel macht vandaag.

00:15:48.260 --> 00:15:51.260
Het is aan ons om uit te zoeken wat te doen.

00:15:51.260 --> 00:15:53.260
En dat is het goede nieuws.

00:15:53.260 --> 00:15:56.260
Wij zijn degenen die deze opera schrijven.

00:15:56.260 --> 00:15:58.260
Dit is onze film.

00:15:58.260 --> 00:16:01.260
Wij maken uit wat er zal gebeuren met deze technologie.

00:16:01.260 --> 00:16:04.260
Wij bepalen hoe dit alles gaat aflopen.

00:16:04.260 --> 00:16:06.260
Dank u.

00:16:06.260 --> 00:16:11.260
(Applaus)

