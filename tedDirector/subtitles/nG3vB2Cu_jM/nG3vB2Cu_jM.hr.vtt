WEBVTT
Kind: captions
Language: hr

00:00:00.000 --> 00:00:07.000
Prevoditelj: Dijana Ivezic
Recezent: Tilen Pigac - EFZG

00:00:15.260 --> 00:00:17.260
Moć.

00:00:17.260 --> 00:00:19.260
To je riječ koja nam pada na pamet.

00:00:19.260 --> 00:00:21.260
Mi smo novi tehnolozi.

00:00:21.260 --> 00:00:24.260
Imamo puno podataka, stoga imamo puno moći.

00:00:24.260 --> 00:00:26.260
Koliko moći imamo?

00:00:26.260 --> 00:00:29.260
Scena iz filma "Apokalipsa danas" -- sjajnog filma.

00:00:29.260 --> 00:00:32.260
Moramo dovesti našeg junaka, kapetana Willarda, do ušća rijeke Nung

00:00:32.260 --> 00:00:34.260
kako bi mogao krenuti za pukovnikom Kurtzom.

00:00:34.260 --> 00:00:36.260
To ćemo postići tako da ga ukrcamo u avion i ostavimo tamo.

00:00:36.260 --> 00:00:38.260
Ovako ide scena:

00:00:38.260 --> 00:00:41.260
nebo je prepuno helikoptera koji ga prevoze

00:00:41.260 --> 00:00:43.260
u pozadini je glasna, uzbudljiva,

00:00:43.260 --> 00:00:45.260
divlja glazba.

00:00:45.260 --> 00:00:47.260
♫ Dum da ta da dum ♫

00:00:47.260 --> 00:00:49.260
♫ Dum da ta da dum ♫

00:00:49.260 --> 00:00:52.260
♫ Da ta da da ♫

00:00:52.260 --> 00:00:54.260
To je puno moći.

00:00:54.260 --> 00:00:56.260
Takvu vrstu moći osjećam u ovoj prostoriji.

00:00:56.260 --> 00:00:58.260
Mi imamo tu vrstu moći

00:00:58.260 --> 00:01:00.260
zbog svih tih podataka koje imamo.

00:01:00.260 --> 00:01:02.260
Na primjer,

00:01:02.260 --> 00:01:04.260
što možemo učiniti

00:01:04.260 --> 00:01:07.260
s podacima jedne jedine osobe?

00:01:07.260 --> 00:01:09.260
Što možemo

00:01:09.260 --> 00:01:11.260
s podacima ovog tipa?

00:01:11.260 --> 00:01:13.260
Mogu pogledati vaše financijsko stanje.

00:01:13.260 --> 00:01:15.260
Mogu reći plaćate li račune na vrijeme.

00:01:15.260 --> 00:01:17.260
Znam jeste li kreditno sposobni.

00:01:17.260 --> 00:01:20.260
Mogu pogledati vaše zdravstveno stanje, vidjeti radi li vam još srce,

00:01:20.260 --> 00:01:23.260
jeste li pogodni za osiguranje.

00:01:23.260 --> 00:01:25.260
Mogu pogledati uzorak vaših klikova.

00:01:25.260 --> 00:01:28.260
Kada dođete na moju web stranicu, već znam što ćete učiniti,

00:01:28.260 --> 00:01:30.260
jer sam već vidio kako posjećujete milijune web stranica.

00:01:30.260 --> 00:01:32.260
Žao mi je što vam to moram reći,

00:01:32.260 --> 00:01:34.260
ali vi ste kao igrač pokera, imate tik.

00:01:34.260 --> 00:01:36.260
Analizom podataka mogu reći što namjeravate učiniti

00:01:36.260 --> 00:01:38.260
prije nego što to učinite.

00:01:38.260 --> 00:01:41.260
Znam što volite. Znam tko ste.

00:01:41.260 --> 00:01:43.260
I sve to prije nego što sam pogledao vašu poštu

00:01:43.260 --> 00:01:45.260
ili vaš telefon.

00:01:45.260 --> 00:01:47.260
To su stvari koje možemo učiniti

00:01:47.260 --> 00:01:50.260
s podacima koje imamo.

00:01:50.260 --> 00:01:53.260
No, zapravo nisam ovdje da bih govorio o stvarima koje možemo učiniti.

00:01:56.260 --> 00:01:59.260
Ovdje sam kako bih govorio o onome što bismo trebali učiniti.

00:02:00.260 --> 00:02:03.260
Što je ispravno?

00:02:04.260 --> 00:02:06.260
Vidim neke začuđene poglede, u stilu

00:02:06.260 --> 00:02:09.260
"Zašto nas pitaš što je ispravno?

00:02:09.260 --> 00:02:12.260
Mi samo stvaramo te stvari. Netko drugi ih koristi".

00:02:12.260 --> 00:02:15.260
Pošteno.

00:02:15.260 --> 00:02:17.260
To me vraća unatrag.

00:02:17.260 --> 00:02:19.260
Razmišljam o 2. svjetskom ratu --

00:02:19.260 --> 00:02:21.260
nekima od ondašnjih velikih tehnologa,

00:02:21.260 --> 00:02:23.260
nekim velikim fizičarima,

00:02:23.260 --> 00:02:25.260
koji su studirali fisiju i fuziju,

00:02:25.260 --> 00:02:27.260
nuklearne stvari.

00:02:27.260 --> 00:02:30.260
Okupimo te fizičare u Los Alamosu

00:02:30.260 --> 00:02:33.260
da vidimo što će stvoriti.

00:02:33.260 --> 00:02:36.260
Želimo da ljudi stvaraju tehnologiju

00:02:36.260 --> 00:02:39.260
razmišljajući o tome što bismo pomoću nje trebali činiti.

00:02:41.260 --> 00:02:44.260
Onda, što bismo trebali učiniti s podacima tog tipa?

00:02:44.260 --> 00:02:47.260
Bismo li ih trebali skupljati, grupirati,

00:02:47.260 --> 00:02:49.260
kako bismo unaprijedili njegovo online iskustvo?

00:02:49.260 --> 00:02:51.260
Kako bismo zaradili?

00:02:51.260 --> 00:02:53.260
Kako bismo zaštitili sebe

00:02:53.260 --> 00:02:55.260
ako bi on imao loše namjere?

00:02:55.260 --> 00:02:58.260
Ili bismo trebali poštovati njegovu privatnost,

00:02:58.260 --> 00:03:01.260
zaštititi njegovo dostojanstvo i pustiti ga na miru?

00:03:02.260 --> 00:03:05.260
Što je ispravno?

00:03:05.260 --> 00:03:07.260
Kako ćemo to doznati?

00:03:07.260 --> 00:03:10.260
Znam: crowd source. Idemo ovo "crowdsourceati".

00:03:11.260 --> 00:03:14.260
Za zagrijavanje,

00:03:14.260 --> 00:03:16.260
krenimo s laganim pitanjem --

00:03:16.260 --> 00:03:19.260
s nečim o čemu sigurno svi prisutni imaju mišljenje:

00:03:19.260 --> 00:03:21.260
iPhone ili Android.

00:03:21.260 --> 00:03:24.260
Dignimo ruke -- iPhone.

00:03:24.260 --> 00:03:26.260
Opa.

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
Čovjek bi pomislio da ovoliko pametnih ljudi

00:03:31.260 --> 00:03:33.260
ne bi tako lako palo samo na lijepe telefone.

00:03:33.260 --> 00:03:35.260
(Smijeh)

00:03:35.260 --> 00:03:37.260
Sljedeće pitanje,

00:03:37.260 --> 00:03:39.260
malo teže.

00:03:39.260 --> 00:03:41.260
Bismo li trebali prikupljati sve podatke tog tipa

00:03:41.260 --> 00:03:43.260
kako bismo poboljšali njegova iskustva

00:03:43.260 --> 00:03:46.260
i zaštitili se u slučaju njegovih loših namjera --

00:03:46.260 --> 00:03:48.260
ili bismo ga trebali pustiti na miru?

00:03:48.260 --> 00:03:51.260
Prikupi podatke.

00:03:53.260 --> 00:03:56.260
Ostavi ga na miru.

00:03:56.260 --> 00:03:58.260
U redu je, sigurni ste.

00:03:58.260 --> 00:04:00.260
(Smijeh)

00:04:00.260 --> 00:04:02.260
U redu, zadnje pitanje --

00:04:02.260 --> 00:04:04.260
teže pitanje --

00:04:04.260 --> 00:04:07.260
u procesu procjene

00:04:07.260 --> 00:04:10.260
što bismo trebali učiniti u ovom slučaju,

00:04:10.260 --> 00:04:14.260
trebamo li koristiti Kantov deontološki moralni okvir

00:04:14.260 --> 00:04:17.260
ili Millov posljedični?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
Nema baš puno glasova.

00:04:27.260 --> 00:04:30.260
(Smijeh)

00:04:30.260 --> 00:04:33.260
Da, to je zastrašujuć rezultat.

00:04:34.260 --> 00:04:38.260
Zastrašujuće je to da imamo snažnija mišljenja

00:04:38.260 --> 00:04:40.260
o svojim mobilnim uređajima

00:04:40.260 --> 00:04:42.260
nego o moralnom okviru

00:04:42.260 --> 00:04:44.260
koji bi nas trebao voditi pri odlučivanju.

00:04:44.260 --> 00:04:47.260
Kako možemo znati što činiti sa svom tom moći koju imamo

00:04:47.260 --> 00:04:50.260
ako nemamo moralni okvir?

00:04:50.260 --> 00:04:53.260
Više znamo o mobilnim operativnim sustavima,

00:04:53.260 --> 00:04:56.260
ali ono što nam zaista treba je moralni operativni sustav.

00:04:58.260 --> 00:05:00.260
Što je moralni operativni sustav?

00:05:00.260 --> 00:05:02.260
Svi znamo da postoji ispravno i pogrešno, zar ne?

00:05:02.260 --> 00:05:04.260
Osjećate se dobro kada učinite nešto ispravno,

00:05:04.260 --> 00:05:06.260
a loše kada učinite nešto pogrešno.

00:05:06.260 --> 00:05:09.260
Roditelji nas uče: dobro treba hvaliti, loše grditi.

00:05:09.260 --> 00:05:12.260
No, kako razlikovati ispravno od pogrešnog?

00:05:12.260 --> 00:05:15.260
Iz dana u dan, koristimo razne tehnike.

00:05:15.260 --> 00:05:18.260
Možda samo slijedimo vlastiti predosjećaj.

00:05:18.260 --> 00:05:21.260
Možda glasujemo -- koristimo crowd source,

00:05:21.260 --> 00:05:23.260
a možda odustanemo --

00:05:23.260 --> 00:05:26.260
pitamo pravnike da vidimo što će oni reći.

00:05:26.260 --> 00:05:28.260
Drugim riječima, to je nasumično,

00:05:28.260 --> 00:05:30.260
zapravo ad hoc,

00:05:30.260 --> 00:05:33.260
kako zaključujemo što bismo trebali učiniti.

00:05:33.260 --> 00:05:36.260
Možda je, ako želimo biti sigurniji,

00:05:36.260 --> 00:05:39.260
ono što zbilja želimo moralni okvir koji će nam biti nit vodilja,

00:05:39.260 --> 00:05:42.260
koji će nam reći koje su stvari ispravne, a koje pogrešne

00:05:42.260 --> 00:05:46.260
i kako bismo u nekoj situaciji znali što učiniti.

00:05:46.260 --> 00:05:48.260
Stoga stvorimo moralni okvir.

00:05:48.260 --> 00:05:51.260
Mi smo ljudi od brojki, živimo od brojeva.

00:05:51.260 --> 00:05:53.260
Kako možemo iskoristiti brojeve

00:05:53.260 --> 00:05:56.260
kao temelj moralnog okvira?

00:05:56.260 --> 00:05:59.260
Znam tipa koji je učinio upravo to,

00:05:59.260 --> 00:06:02.260
briljantan tip --

00:06:02.260 --> 00:06:05.260
mrtav je već 2.500 godina.

00:06:05.260 --> 00:06:07.260
Platon, tako je.

00:06:07.260 --> 00:06:09.260
Sjećate se tog starog filozofa?

00:06:09.260 --> 00:06:12.260
Spavali ste na tom satu.

00:06:12.260 --> 00:06:14.260
Platona su brinule iste stvari kao nas sada.

00:06:14.260 --> 00:06:16.260
Brinuo je oko ispravnog i pogrešnog.

00:06:16.260 --> 00:06:18.260
Želio je znati što je pravedno,

00:06:18.260 --> 00:06:20.260
ali je brinuo da je sve što činimo

00:06:20.260 --> 00:06:22.260
samo razmjena mišljenja o tome.

00:06:22.260 --> 00:06:25.260
On kaže da je nešto pravedno. Ona kaže da je nešto drugo pravedno.

00:06:25.260 --> 00:06:27.260
Dok govore, prilično su uvjerljivi i jedan i drugi.

00:06:27.260 --> 00:06:29.260
Idem naprijed-natrag; nikamo ne stižem.

00:06:29.260 --> 00:06:32.260
Ne želim mišljenja, želim znanje.

00:06:32.260 --> 00:06:35.260
Želim znati istinu o pravdi --

00:06:35.260 --> 00:06:38.260
baš kao što imamo istine u matematici.

00:06:38.260 --> 00:06:41.260
U matematici znamo objektivne činjenice.

00:06:41.260 --> 00:06:43.260
Uzmimo neki, bilo koji broj -- dva.

00:06:43.260 --> 00:06:45.260
Omiljeni broj, volim taj broj.

00:06:45.260 --> 00:06:47.260
Postoje istine o dva.

00:06:47.260 --> 00:06:49.260
Ako imate dva nečega,

00:06:49.260 --> 00:06:51.260
i dodate još dva, dobivate četiri.

00:06:51.260 --> 00:06:53.260
To je istina, bez obzira o čemu govorili.

00:06:53.260 --> 00:06:55.260
To je objektivna istina o obliku dva,

00:06:55.260 --> 00:06:57.260
apstraktnom obliku.

00:06:57.260 --> 00:06:59.260
Kada imate bilo što dva -- dva oka, dva uha, dva nosa,

00:06:59.260 --> 00:07:01.260
samo dvije izbočine --

00:07:01.260 --> 00:07:04.260
sve to sačinjava oblik dva.

00:07:04.260 --> 00:07:08.260
Sve to sudjeluje u istinama koje posjeduje dva.

00:07:08.260 --> 00:07:10.260
Svi oni imaju dva-nost u sebi.

00:07:10.260 --> 00:07:13.260
Stoga, to nije stvar mišljenja.

00:07:13.260 --> 00:07:15.260
Što ako je, mislio je Platon,

00:07:15.260 --> 00:07:17.260
etika poput matematike?

00:07:17.260 --> 00:07:20.260
Što ako postoji čisti oblik pravde?

00:07:20.260 --> 00:07:22.260
Što ako postoje istine o pravdi

00:07:22.260 --> 00:07:24.260
i možete samo pogledati ovaj svijet oko sebe,

00:07:24.260 --> 00:07:26.260
vidjeti koje stvari sudjeluju,

00:07:26.260 --> 00:07:29.260
sačinjavaju taj oblik pravde?

00:07:29.260 --> 00:07:32.260
Tada biste znali što je zaista pravedno, a što nije.

00:07:32.260 --> 00:07:34.260
To ne bi bio predmet

00:07:34.260 --> 00:07:37.260
mišljenja ili predodžbi.

00:07:37.260 --> 00:07:39.260
To je zapanjujuća vizija.

00:07:39.260 --> 00:07:42.260
Promislite o tome -- kako veliko, kako ambiciozno.

00:07:42.260 --> 00:07:44.260
Ambiciozno baš poput nas.

00:07:44.260 --> 00:07:46.260
On želi riješiti etiku.

00:07:46.260 --> 00:07:48.260
On želi objektivne istine.

00:07:48.260 --> 00:07:51.260
Ako razmišljate na taj način,

00:07:51.260 --> 00:07:54.260
imate platonistički moralni okvir.

00:07:54.260 --> 00:07:56.260
Ako ne razmišljate tako,

00:07:56.260 --> 00:07:58.260
u tome imate puno istomišljenika u povijesti zapadne filozofije,

00:07:58.260 --> 00:08:01.260
zbog čistoće ideje -- znate, ljudi su ju kritizirali.

00:08:01.260 --> 00:08:04.260
Aristotela, na primjer, to nije zabavljalo.

00:08:04.260 --> 00:08:07.260
Mislio je da je nepraktična.

00:08:07.260 --> 00:08:11.260
Aristotel je rekao: "Trebali bismo tražiti onoliko preciznosti u svakom predmetu

00:08:11.260 --> 00:08:13.260
koliko taj predmet dopušta".

00:08:13.260 --> 00:08:16.260
Aristotel nije mislio da je etika slična matematici.

00:08:16.260 --> 00:08:19.260
Mislio je da je etika predmet donošenja odluka "ovdje i sada"

00:08:19.260 --> 00:08:21.260
pomoću naše najbolje procjene

00:08:21.260 --> 00:08:23.260
u pronalasku pravog puta.

00:08:23.260 --> 00:08:25.260
Ako tako razmišljate, Platon nije vaš tip,

00:08:25.260 --> 00:08:27.260
ali ne dajte se,

00:08:27.260 --> 00:08:29.260
možda postoji drugi način

00:08:29.260 --> 00:08:32.260
na koji možemo iskoristiti brojeve za temelj našeg moralnog okvira.

00:08:33.260 --> 00:08:35.260
Što kažete na ovo:

00:08:35.260 --> 00:08:38.260
Što ako bi u bilo kojoj situaciji mogli samo izračunati,

00:08:38.260 --> 00:08:40.260
pogledati što se nudi,

00:08:40.260 --> 00:08:43.260
izmjeriti što je bolje i znati što učiniti?

00:08:43.260 --> 00:08:45.260
Zvuči poznato?

00:08:45.260 --> 00:08:48.260
To je utilitaristički moralni okvir.

00:08:48.260 --> 00:08:50.260
John Stuart Mill je bio veliki zagovornik ovoga --

00:08:50.260 --> 00:08:52.260
osim toga, bio je dobar tip --

00:08:52.260 --> 00:08:54.260
a mrtav je samo 200 godina.

00:08:54.260 --> 00:08:56.260
Dakle, temelji utilitarizma --

00:08:56.260 --> 00:08:58.260
siguran sam da su vam poznati.

00:08:58.260 --> 00:09:00.260
Troje ljudi koji su glasovali za Milla ranije su upoznati s ovim.

00:09:00.260 --> 00:09:02.260
No, evo kako to funkcionira.

00:09:02.260 --> 00:09:05.260
Što ako je moral, odnosno ono što nešto čini moralnim

00:09:05.260 --> 00:09:07.260
samo pitanje povećavanja užitka

00:09:07.260 --> 00:09:09.260
i smanjivanja boli?

00:09:09.260 --> 00:09:12.260
Radi nešto svojstveno tom činu,

00:09:12.260 --> 00:09:14.260
a ne odnosi se na neki apstraktni oblik.

00:09:14.260 --> 00:09:16.260
Samo je pitanje posljedica.

00:09:16.260 --> 00:09:18.260
Gledate samo posljedice

00:09:18.260 --> 00:09:20.260
i vidite je li, u cjelini, to nešto za dobru ili lošu svrhu.

00:09:20.260 --> 00:09:22.260
To bi bilo jednostavno i tada bismo znali što učiniti.

00:09:22.260 --> 00:09:24.260
Pogledajmo primjer.

00:09:24.260 --> 00:09:26.260
Recimo da odem gore

00:09:26.260 --> 00:09:28.260
i kažem: "Uzet ću ti mobitel".

00:09:28.260 --> 00:09:30.260
Ne zato što je ranije zazvonio,

00:09:30.260 --> 00:09:33.260
već zato što sam napravio jedan mali izračun.

00:09:33.260 --> 00:09:36.260
Pomislio sam, ovaj tip izgleda sumnjivo.

00:09:36.260 --> 00:09:39.260
Što ako šalje porukice u Bin Ladenovo skrovište --

00:09:39.260 --> 00:09:41.260
ili nekome tko je naslijedio Bin Ladena --

00:09:41.260 --> 00:09:44.260
i zapravo je poput terorista, krtica.

00:09:44.260 --> 00:09:47.260
Saznat ću što se događa i kad saznam,

00:09:47.260 --> 00:09:50.260
spriječit ću ogromnu štetu koju je mogao izazvati.

00:09:50.260 --> 00:09:53.260
Od sprječavanja te štete imamo veliku korist,

00:09:53.260 --> 00:09:55.260
u usporedbi s malom boli koju ćemo izazvati

00:09:55.260 --> 00:09:57.260
jer će biti osramoćen kada mu pregledam mobitel

00:09:57.260 --> 00:10:00.260
i vidim da ima problem u Farmvilleu, jer sve je to

00:10:00.260 --> 00:10:03.260
nadvladala

00:10:03.260 --> 00:10:05.260
vrijednost pregledavanja njegovog mobitela.

00:10:05.260 --> 00:10:07.260
Ako se ovako osjećate,

00:10:07.260 --> 00:10:10.260
to je utilitaristički izbor.

00:10:10.260 --> 00:10:13.260
No, možda se ne osjećate ni ovako,

00:10:13.260 --> 00:10:15.260
možda mislite: "To je njegov mobitel,

00:10:15.260 --> 00:10:17.260
pogrešno je uzeti njegov mobitel

00:10:17.260 --> 00:10:19.260
jer je on osoba

00:10:19.260 --> 00:10:21.260
koja ima prava i dostojanstvo

00:10:21.260 --> 00:10:23.260
i ne možemo se u to uplitati".

00:10:23.260 --> 00:10:25.260
On ima autonomiju,

00:10:25.260 --> 00:10:27.260
neovisno o izračunima,

00:10:27.260 --> 00:10:30.260
postoje stvari koje su same po sebi pogrešne --

00:10:30.260 --> 00:10:32.260
kao što je laganje pogrešno,

00:10:32.260 --> 00:10:35.260
kao što je mučenje nevine djece pogrešno.

00:10:35.260 --> 00:10:38.260
Kant je u ovome bio jako dobar

00:10:38.260 --> 00:10:40.260
i rekao je to malo bolje nego što ću ja reći.

00:10:40.260 --> 00:10:42.260
Rekao je da bismo trebali upotrijebiti naš razum

00:10:42.260 --> 00:10:45.260
kako bismo otkrili pravila po kojima ćemo voditi svoje ponašanje.

00:10:45.260 --> 00:10:48.260
Naša je dužnost slijediti ta pravila.

00:10:48.260 --> 00:10:51.260
To nije stvar izračuna.

00:10:51.260 --> 00:10:53.260
Stoga, prestanimo.

00:10:53.260 --> 00:10:56.260
Upravo smo u srži ove filozofske zavrzlame

00:10:56.260 --> 00:10:59.260
koja se nastavlja tisućama godina,

00:10:59.260 --> 00:11:01.260
jer se radi o teškim pitanjima,

00:11:01.260 --> 00:11:03.260
a ja imam samo 15 minuta.

00:11:03.260 --> 00:11:05.260
Zato prijeđimo na stvar.

00:11:05.260 --> 00:11:09.260
Kako bismo trebali donositi naše odluke?

00:11:09.260 --> 00:11:12.260
Kao Platon, Aristotel, Kant ili Mill?

00:11:12.260 --> 00:11:14.260
Što bismo trebali činiti, što je odgovor?

00:11:14.260 --> 00:11:17.260
Koja je formula koju možemo upotrijebiti u bilo kojoj situaciji

00:11:17.260 --> 00:11:19.260
kako bismo odlučili što trebamo napraviti,

00:11:19.260 --> 00:11:21.260
hoćemo li upotrijebiti podatke tog tipa ili ne?

00:11:21.260 --> 00:11:24.260
Koja je formula?

00:11:25.260 --> 00:11:27.260
Nema formule.

00:11:29.260 --> 00:11:31.260
Nema jednostavnog odgovora.

00:11:31.260 --> 00:11:34.260
Etika je teška.

00:11:34.260 --> 00:11:37.260
Etika zahtijeva razmišljanje,

00:11:38.260 --> 00:11:40.260
a to je neugodno.

00:11:40.260 --> 00:11:42.260
To znam jer sam potrošio dobar dio karijere

00:11:42.260 --> 00:11:44.260
na umjetnu inteligenciju,

00:11:44.260 --> 00:11:47.260
pokušavajući napraviti strojeve koji bi mogli malo razmišljati umjesto nas,

00:11:47.260 --> 00:11:49.260
dati nam odgovore --

00:11:49.260 --> 00:11:51.260
ali oni to ne mogu.

00:11:51.260 --> 00:11:53.260
Naprosto ne možeš uzeti ljudsko razmišljanje

00:11:53.260 --> 00:11:55.260
i staviti ga u stroj.

00:11:55.260 --> 00:11:58.260
To moramo učiniti sami.

00:11:58.260 --> 00:12:01.260
Srećom, nismo strojevi pa možemo.

00:12:01.260 --> 00:12:03.260
Ne samo da možemo razmišljati,

00:12:03.260 --> 00:12:05.260
već moramo.

00:12:05.260 --> 00:12:07.260
Hannah Arendt je rekla:

00:12:07.260 --> 00:12:09.260
"Tužna istina je

00:12:09.260 --> 00:12:11.260
da najveća zla na ovome svijetu

00:12:11.260 --> 00:12:13.260
nisu počinili ljudi

00:12:13.260 --> 00:12:15.260
zato što su odabrali biti zli

00:12:15.260 --> 00:12:18.260
nego zato što nisu razmišljali".

00:12:18.260 --> 00:12:22.260
Ona to naziva "banalnošću zla".

00:12:22.260 --> 00:12:24.260
Kao odgovor na to,

00:12:24.260 --> 00:12:26.260
zahtijevamo vježbu razmišljanja

00:12:26.260 --> 00:12:29.260
od svake zdrave osobe.

00:12:29.260 --> 00:12:31.260
Stoga, učinimo to. Razmišljajmo.

00:12:31.260 --> 00:12:34.260
Zapravo, krenimo odmah.

00:12:34.260 --> 00:12:37.260
Neka svaka osoba u ovoj prostoriji učini ovo:

00:12:37.260 --> 00:12:40.260
prisjetite se kada ste zadnji put morali donijeti odluku

00:12:40.260 --> 00:12:42.260
i bili ste zabrinuti činite li ispravnu stvar,

00:12:42.260 --> 00:12:44.260
pitali ste se: "Što bih trebao učiniti?"

00:12:44.260 --> 00:12:46.260
Prisjetite se toga

00:12:46.260 --> 00:12:48.260
i sada promislite o tome

00:12:48.260 --> 00:12:51.260
pa recite: "Kako sam došao do te odluke?

00:12:51.260 --> 00:12:54.260
Što sam učinio? Jesam li slijedio svoj predosjećaj?

00:12:54.260 --> 00:12:56.260
Jesam li izglasavao ili pitao pravnike?"

00:12:56.260 --> 00:12:59.260
Sada ipak imamo nešto više izbora.

00:12:59.260 --> 00:13:01.260
"Jesam li procjenjivao što bi bio najveći užitak,

00:13:01.260 --> 00:13:03.260
poput Milla?

00:13:03.260 --> 00:13:06.260
Ili sam, poput Kanta, koristio razum kako bih otkrio što je dobro samo po sebi?"

00:13:06.260 --> 00:13:09.260
Razmislite o tome. Stvarno se prisjetite, ovo je važno.

00:13:09.260 --> 00:13:11.260
Toliko je važno

00:13:11.260 --> 00:13:13.260
da ćemo potrošiti 30 sekundi vrijednog TEDTalk vremena

00:13:13.260 --> 00:13:15.260
ne radeći ništa osim razmišljanja o ovome.

00:13:15.260 --> 00:13:17.260
Jeste li spremni? Krenite.

00:13:33.260 --> 00:13:36.260
Stanite. Dobar posao.

00:13:36.260 --> 00:13:38.260
Ovo što ste upravo učinili

00:13:38.260 --> 00:13:40.260
prvi je korak prema preuzimanju odgovornosti

00:13:40.260 --> 00:13:43.260
za ono što trebamo učiniti sa svom svojom moći.

00:13:45.260 --> 00:13:48.260
Na redu je sljedeći korak -- probajte ovo.

00:13:49.260 --> 00:13:51.260
Nađite prijatelja i objasnite mu

00:13:51.260 --> 00:13:53.260
kako ste došli do te odluke.

00:13:53.260 --> 00:13:55.260
Ne sada, čekajte dok završim s govorom.

00:13:55.260 --> 00:13:57.260
Za vrijeme ručka.

00:13:57.260 --> 00:14:00.260
Nemojte naći još jednog prijatelja-tehnologa,

00:14:00.260 --> 00:14:02.260
nego nekoga drukčijeg od vas.

00:14:02.260 --> 00:14:04.260
Pronađite umjetnika ili pisca --

00:14:04.260 --> 00:14:07.260
ili, ne daj Bože, filozofa -- i popričajte s njim.

00:14:07.260 --> 00:14:09.260
Zapravo, pronađite nekoga iz humanistike.

00:14:09.260 --> 00:14:11.260
Zašto? Zato što oni razmišljaju o problemima

00:14:11.260 --> 00:14:13.260
drukčije nego mi, tehnolozi.

00:14:13.260 --> 00:14:16.260
Prije par dana, na ulici točno preko puta odavde,

00:14:16.260 --> 00:14:18.260
skupilo se na stotine ljudi.

00:14:18.260 --> 00:14:20.260
Bili su to tehnolozi i humanisti

00:14:20.260 --> 00:14:22.260
u sklopu velike BiblioTech konferencije.

00:14:22.260 --> 00:14:24.260
Okupili su se

00:14:24.260 --> 00:14:26.260
jer su tehnolozi željeli naučiti

00:14:26.260 --> 00:14:29.260
kako bi bilo razmišljati iz humanističke perspektive.

00:14:29.260 --> 00:14:31.260
Dakle, netko iz Googlea

00:14:31.260 --> 00:14:33.260
razgovrara s nekim tko se bavi komparativnom književnošću.

00:14:33.260 --> 00:14:36.260
Vi razmišljate o tome kakve veze ima francusko kazalište iz 17. stoljeća

00:14:36.260 --> 00:14:38.260
s rizičnim kapitalom?

00:14:38.260 --> 00:14:41.260
To je zanimljivo. To je drukčiji način razmišljanja.

00:14:41.260 --> 00:14:43.260
Kada razmišljate na taj način,

00:14:43.260 --> 00:14:46.260
postajete osjetljiviji prema pitanju ljudi,

00:14:46.260 --> 00:14:49.260
što je ključno kod donošenja etičkih odluka.

00:14:49.260 --> 00:14:51.260
Zamislite da ste sada

00:14:51.260 --> 00:14:53.260
otišli i sreli svog prijatelja glazbenika

00:14:53.260 --> 00:14:56.260
i da mu pričate o ovome o čemu smo sada govorili,

00:14:56.260 --> 00:14:58.260
o cijeloj revoluciji podataka i svemu tome --

00:14:58.260 --> 00:15:00.260
možda čak zapjevate pokoji takt glazbene teme.

00:15:00.260 --> 00:15:03.260
♫ Dum ta da da dum dum ta da da dum ♫

00:15:03.260 --> 00:15:05.260
Vaš prijatelj glazbenik bi vas zaustavio i rekao:

00:15:05.260 --> 00:15:07.260
"Znaš, ta glazbena tema

00:15:07.260 --> 00:15:09.260
iz tvoje revolucije podataka

00:15:09.260 --> 00:15:11.260
je opera. To je Wagner.

00:15:11.260 --> 00:15:13.260
Utemeljena je na nordijskoj legendi

00:15:13.260 --> 00:15:15.260
prema kojoj se bogovi i mitska bića

00:15:15.260 --> 00:15:18.260
bore za čarobni nakit".

00:15:19.260 --> 00:15:22.260
To je zanimljivo.

00:15:22.260 --> 00:15:25.260
To je predivna opera

00:15:25.260 --> 00:15:28.260
i ganuti smo njome.

00:15:28.260 --> 00:15:30.260
Ganuti smo jer se radi o borbi

00:15:30.260 --> 00:15:32.260
između dobra i zla,

00:15:32.260 --> 00:15:34.260
između ispravnog i pogrešnog,

00:15:34.260 --> 00:15:36.260
a nama je stalo do ispravnog i pogrešnog.

00:15:36.260 --> 00:15:39.260
Stalo nam je do toga što će se dogoditi u toj operi.

00:15:39.260 --> 00:15:42.260
Stalo nam je do toga što će se dogoditi u "Apokalipsi danas"

00:15:42.260 --> 00:15:44.260
i svakako nam je stalo

00:15:44.260 --> 00:15:46.260
što će se dogoditi s našim tehnologijama.

00:15:46.260 --> 00:15:48.260
Danas imamo toliko moći

00:15:48.260 --> 00:15:51.260
i sami moramo odlučiti što ćemo učiniti.

00:15:51.260 --> 00:15:53.260
To su dobre vijesti.

00:15:53.260 --> 00:15:56.260
Mi smo skladatelji ove opere.

00:15:56.260 --> 00:15:58.260
Ovo je naš film.

00:15:58.260 --> 00:16:01.260
Mi otkrivamo što će se dogoditi s ovom tehnologijom.

00:16:01.260 --> 00:16:04.260
Mi odlučujemo kako će sve ovo završiti.

00:16:04.260 --> 00:16:06.260
Hvala vam.

00:16:06.260 --> 00:16:11.260
(Pljesak)

