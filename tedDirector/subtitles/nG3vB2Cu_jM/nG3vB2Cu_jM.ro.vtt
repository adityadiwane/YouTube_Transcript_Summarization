WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: preda silvana
Corector: Maria Tancu

00:00:15.260 --> 00:00:17.260
Putere.

00:00:17.260 --> 00:00:19.260
Acesta este cuvântul care îmi vine în minte.

00:00:19.260 --> 00:00:21.260
Suntem noii tehnologi.

00:00:21.260 --> 00:00:24.260
Avem multă informație, așadar avem multă putere.

00:00:24.260 --> 00:00:26.260
Cât de multă putere avem?

00:00:26.260 --> 00:00:29.260
Scenă dintr-un film: ”Apocalipsa acum” -- grozav film.

00:00:29.260 --> 00:00:32.260
Trebuie să îl aducem pe eroul nostru, căpitanul Willard, la gura râului Nung

00:00:32.260 --> 00:00:34.260
pentru a-l putea urmări pe col. Kurtz..

00:00:34.260 --> 00:00:36.260
Modul în care vom face acest lucru este să-l aducem în zbor și să-l aducem acolo.

00:00:36.260 --> 00:00:38.260
Așadar scena:

00:00:38.260 --> 00:00:41.260
cerul este acoperit de o flotă de elicoptere ce îl transportă.

00:00:41.260 --> 00:00:43.260
Și este această muzică zgomotoasă, captivantă pe fundal,

00:00:43.260 --> 00:00:45.260
o muzică sălbatică.

00:00:45.260 --> 00:00:47.260
♫ Dum da ta da dum ♫

00:00:47.260 --> 00:00:49.260
♫ Dum da ta da dum ♫

00:00:49.260 --> 00:00:52.260
♫ Da ta da da ♫

00:00:52.260 --> 00:00:54.260
Asta înseamnă multă putere.

00:00:54.260 --> 00:00:56.260
Acesta este tipul de putere pe care îl simt în această încăpere.

00:00:56.260 --> 00:00:58.260
Acesta este tipul de putere pe care îl avem

00:00:58.260 --> 00:01:00.260
datorită tuturor informațiilor pe care le avem.

00:01:00.260 --> 00:01:02.260
Să luăm un exemplu.

00:01:02.260 --> 00:01:04.260
Ce putem face

00:01:04.260 --> 00:01:07.260
cu datele unei singure persoane?

00:01:07.260 --> 00:01:09.260
Ce putem facem

00:01:09.260 --> 00:01:11.260
cu datele acelui tip?

00:01:11.260 --> 00:01:13.260
Pot să vă cercetez trecutul financiar.

00:01:13.260 --> 00:01:15.260
Pot să vă spun dacă plătiți facturile la timp.

00:01:15.260 --> 00:01:17.260
Știu dacă vă calificați pentru un împrumut .

00:01:17.260 --> 00:01:20.260
Pot să vă analizez istoria medicală, pot să aflu în ce stare vă este inima --

00:01:20.260 --> 00:01:23.260
pentru a decide dacă merită să vă ofer asigurare.

00:01:23.260 --> 00:01:25.260
Pot să analizez modelul clicurilor.

00:01:25.260 --> 00:01:28.260
Când îmi vizitaţi website-ul, chiar ştiu deja ce o să faceţi,

00:01:28.260 --> 00:01:30.260
pentru că v-am mai văzut vizitând milioane de website-uri.

00:01:30.260 --> 00:01:32.260
Şi regret să vă spun,

00:01:32.260 --> 00:01:34.260
sunteţi ca un jucător de pocher, sunteţi transparent.

00:01:34.260 --> 00:01:36.260
Analizând informaţiile, vă pot spune ce urmează să faceţi

00:01:36.260 --> 00:01:38.260
înainte chiar de a acţiona.

00:01:38.260 --> 00:01:41.260
Ştiu ce vă place. Ştiu cine sunteţi.

00:01:41.260 --> 00:01:43.260
Şi asta chiar înainte de a vă vedea mail-ul

00:01:43.260 --> 00:01:45.260
sau telefonul.

00:01:45.260 --> 00:01:47.260
Astfel de lucruri putem face

00:01:47.260 --> 00:01:50.260
cu informaţiile pe care le avem.

00:01:50.260 --> 00:01:53.260
Dar nu sunt aici pentru a vă vorbi despre ce putem face.

00:01:56.260 --> 00:01:59.260
Sunt aici pentru a vorbi despre ce ar trebui să facem.

00:02:00.260 --> 00:02:03.260
Ce e bine să facem?

00:02:04.260 --> 00:02:06.260
Acum văd unele priviri nedumerite

00:02:06.260 --> 00:02:09.260
de genul, "De ce ne întrebi ce e bine să facem?

00:02:09.260 --> 00:02:12.260
Noi doar fabricăm aceste lucruri. Alţii le folosesc."

00:02:12.260 --> 00:02:15.260
Corect.

00:02:15.260 --> 00:02:17.260
Dar, îmi provoacă amintiri.

00:02:17.260 --> 00:02:19.260
Mă gândesc la al Doilea Război Mondial -

00:02:19.260 --> 00:02:21.260
atunci, unii dintre cei mai buni tehnologi de-ai noștri,

00:02:21.260 --> 00:02:23.260
unii dintre cei mai buni fizicieni de-ai noştri,

00:02:23.260 --> 00:02:25.260
au studiat fisiunea şi fuziunea nucleară--

00:02:25.260 --> 00:02:27.260
doar chestii nucleare.

00:02:27.260 --> 00:02:30.260
Îi reunim pe aceşti fizicieni în Los Alamos

00:02:30.260 --> 00:02:33.260
pentru a vedea ce au construit.

00:02:33.260 --> 00:02:36.260
Dorim ca persoanele care construiesc tehnologia

00:02:36.260 --> 00:02:39.260
să se gândească la ce ar trebui să facem cu tehnologia.

00:02:41.260 --> 00:02:44.260
Deci ce ar trebui să facem cu informaţiile acelui tip?

00:02:44.260 --> 00:02:47.260
Ar trebui să le preluăm, să le adunăm,

00:02:47.260 --> 00:02:49.260
pentru a-i înbunătăţi experienţa online?

00:02:49.260 --> 00:02:51.260
Pentru ca să câştigăm bani?

00:02:51.260 --> 00:02:53.260
Pentru a ne putea apăra

00:02:53.260 --> 00:02:55.260
dacă se dovedeşte că nu are intenţii bune?

00:02:55.260 --> 00:02:58.260
Sau trebuie să-i respectăm intimitatea,

00:02:58.260 --> 00:03:01.260
să-i protejăm demnitatea şi să-l lăsăm în pace?

00:03:02.260 --> 00:03:05.260
Ce variantă să alegem?

00:03:05.260 --> 00:03:07.260
Cum ne dăm seama ce să facem?

00:03:07.260 --> 00:03:10.260
Ştiu: sondajul de opinie. Haideţi să-l aplicăm asupra acestui lucru.

00:03:11.260 --> 00:03:14.260
Ca să-i pregătim pe oameni,

00:03:14.260 --> 00:03:16.260
să începem cu o întrebare simplă--

00:03:16.260 --> 00:03:19.260
despre un lucru asupra căruia sunt sigur că toată lumea are o opinie:

00:03:19.260 --> 00:03:21.260
IPhone versus Android.

00:03:21.260 --> 00:03:24.260
Să votăm -- pentru iPhone.

00:03:24.260 --> 00:03:26.260
Uh huh.

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
V-aţi gândi că un grup de oameni inteligenţi ca acesta

00:03:31.260 --> 00:03:33.260
nu ar fi interesat de asemenea aiureli folositoare telefoanelor frumoase.

00:03:33.260 --> 00:03:35.260
(Râsete)

00:03:35.260 --> 00:03:37.260
Următoarea întrebare,

00:03:37.260 --> 00:03:39.260
un pic mai dificilă.

00:03:39.260 --> 00:03:41.260
Trebuie să adunăm toate datele despre acel tip

00:03:41.260 --> 00:03:43.260
pentru a-i îmbunătăţi experienţa

00:03:43.260 --> 00:03:46.260
şi a ne proteja dacă se dovedeşte că nu are intenţii bune?

00:03:46.260 --> 00:03:48.260
Sau ar trebui să -l lăsăm în pace?

00:03:48.260 --> 00:03:51.260
Să-i adunăm datele.

00:03:53.260 --> 00:03:56.260
Să-l lăsăm în pace.

00:03:56.260 --> 00:03:58.260
Eşti în siguranţă. E în regulă.

00:03:58.260 --> 00:04:00.260
(Râsete)

00:04:00.260 --> 00:04:02.260
Ok, ultima întrebare --

00:04:02.260 --> 00:04:04.260
întrebarea cea mai dificilă--

00:04:04.260 --> 00:04:07.260
când încercăm să evaluăm

00:04:07.260 --> 00:04:10.260
ceea ce ar trebui să facem în acest caz,

00:04:10.260 --> 00:04:14.260
ar trebui să utilizăm un model moral deontologic kantian,

00:04:14.260 --> 00:04:17.260
sau ar trebui să utilizăm o teorie subsecventă milliană?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
Nu chiar atât de multe voturi.

00:04:27.260 --> 00:04:30.260
(Râsete)

00:04:30.260 --> 00:04:33.260
Da, e un rezultat terifiant.

00:04:34.260 --> 00:04:38.260
Terifiant, pentru că avem păreri mai puternice

00:04:38.260 --> 00:04:40.260
despre dispozitivele noastre manuale

00:04:40.260 --> 00:04:42.260
decât despre cadrul moral

00:04:42.260 --> 00:04:44.260
pe care ar trebui să-l folosim în luarea deciziilor.

00:04:44.260 --> 00:04:47.260
Cum ştim să ne folosim de toată puterea pe care o avem

00:04:47.260 --> 00:04:50.260
dacă nu avem un cadru moral?

00:04:50.260 --> 00:04:53.260
Ştim mai mult despre sistemele de operare ale telefoanelor mobile,

00:04:53.260 --> 00:04:56.260
dar avem de fapt nevoie de un sistem de operare moral.

00:04:58.260 --> 00:05:00.260
Ce este un sistem de operare moral?

00:05:00.260 --> 00:05:02.260
Cu toţii cunoaştem binele şi răul .

00:05:02.260 --> 00:05:04.260
Vă simţiţi bine când faceţi un lucru bun

00:05:04.260 --> 00:05:06.260
vă simţiţi rău când faceţi un lucru rău.

00:05:06.260 --> 00:05:09.260
Părinţii nostri ne învaţă că lauda este pentru bine, mustrarea pentru rău.

00:05:09.260 --> 00:05:12.260
Dar cum distingem binele de rău?

00:05:12.260 --> 00:05:15.260
Pe zi ce trece, avem tehnici pe care le folosim.

00:05:15.260 --> 00:05:18.260
Poate ne urmăm instinctul.

00:05:18.260 --> 00:05:21.260
Poate votăm- facem un sondaj de opinie.

00:05:21.260 --> 00:05:23.260
Sau poate pariem-

00:05:23.260 --> 00:05:26.260
întrebaţi departamentul juridic, vedeţi ce spun ei.

00:05:26.260 --> 00:05:28.260
Cu alte cuvinte e aleatoriu,

00:05:28.260 --> 00:05:30.260
cam ad hoc,

00:05:30.260 --> 00:05:33.260
felul în care ne dăm seama ce ar trebui să facem.

00:05:33.260 --> 00:05:36.260
Şi poate, dacă vrem să fim mai siguri,

00:05:36.260 --> 00:05:39.260
ceea ce realmente vrem este un cadru moral care ne va ajuta să ajungem acolo,

00:05:39.260 --> 00:05:42.260
care ne va spune din start ce fel de lucruri sunt bune şi rele

00:05:42.260 --> 00:05:46.260
şi cum vom şti ce să facem într-o anumită situaţie.

00:05:46.260 --> 00:05:48.260
Aşa că, haideţi să dobândim un cadru moral.

00:05:48.260 --> 00:05:51.260
Suntem un număr de oameni care se ghidează după numere.

00:05:51.260 --> 00:05:53.260
Cum putem folosi numerele

00:05:53.260 --> 00:05:56.260
ca bază pentru un cadru moral?

00:05:56.260 --> 00:05:59.260
Cunosc un tip care tocmai asta a făcut.

00:05:59.260 --> 00:06:02.260
Un tip extraordinar-

00:06:02.260 --> 00:06:05.260
care e mort de 2500 de ani.

00:06:05.260 --> 00:06:07.260
Platon, corect.

00:06:07.260 --> 00:06:09.260
Vi-l amintiţi - bătrânul filosof?

00:06:09.260 --> 00:06:12.260
Aţi dormit la acel curs.

00:06:12.260 --> 00:06:14.260
Şi Platon, a avut aceleaşi preocupări ca şi noi.

00:06:14.260 --> 00:06:16.260
S-a preocupat de ceea ce e bine şi rău.

00:06:16.260 --> 00:06:18.260
A vrut să ştie ce este corect.

00:06:18.260 --> 00:06:20.260
Dar a fost îngrijorat că tot ceea ce facem de fapt

00:06:20.260 --> 00:06:22.260
este să schimbăm opinii despre asta.

00:06:22.260 --> 00:06:25.260
El spune că ceva este corect. Ea spune că altceva este corect.

00:06:25.260 --> 00:06:27.260
E cam convingător ceea ce spune el şi, la fel, ceea ce spune ea.

00:06:27.260 --> 00:06:29.260
Merg înainte şi înapoi.

00:06:29.260 --> 00:06:32.260
Nu vreau păreri, vreau cunoaştere.

00:06:32.260 --> 00:06:35.260
Vreau să aflu adevărul despre dreptate -

00:06:35.260 --> 00:06:38.260
asemănător adevărului matematic.

00:06:38.260 --> 00:06:41.260
În matematică cunoaştem datele obiective.

00:06:41.260 --> 00:06:43.260
Luaţi un număr, orice număr - doi.

00:06:43.260 --> 00:06:45.260
Numărul favorit. Iubesc acest număr.

00:06:45.260 --> 00:06:47.260
Există adevăruri despre doi.

00:06:47.260 --> 00:06:49.260
Dacă aveţi două lucruri,

00:06:49.260 --> 00:06:51.260
mai adăugaţi două, aveţi patru.

00:06:51.260 --> 00:06:53.260
E adevărat indiferent despre ce lucru este vorba

00:06:53.260 --> 00:06:55.260
Este un adevăr obiectiv despre forma lui doi,

00:06:55.260 --> 00:06:57.260
forma abstractă.

00:06:57.260 --> 00:06:59.260
Când aveţi oricare două lucruri - doi ochi, două urechi, două nasuri,

00:06:59.260 --> 00:07:01.260
doar două proeminenţe -

00:07:01.260 --> 00:07:04.260
acestea toate fac parte din forma lui doi.

00:07:04.260 --> 00:07:08.260
Toate fac parte din adevărul lui doi.

00:07:08.260 --> 00:07:10.260
Toate au doi-ul în ele.

00:07:10.260 --> 00:07:13.260
De aceea nu este o chestiune de opinie.

00:07:13.260 --> 00:07:15.260
Ce ar fi, dacă Platon ar fi crezut

00:07:15.260 --> 00:07:17.260
că etica este ca matematica?

00:07:17.260 --> 00:07:20.260
Ce ar fi dacă ar exista o formă pură de dreptate?

00:07:20.260 --> 00:07:22.260
Ce ar fi dacă există adevăruri despre dreptate,

00:07:22.260 --> 00:07:24.260
şi puteţi arunca o privire acestei lumi

00:07:24.260 --> 00:07:26.260
şi să vedeţi care lucruri au participat,

00:07:26.260 --> 00:07:29.260
au împărtăşit acea formă de dreptate?

00:07:29.260 --> 00:07:32.260
Atunci aţi şti ce era cu adevărat corect şi ce nu.

00:07:32.260 --> 00:07:34.260
Nu ar fi doar o chestiune

00:07:34.260 --> 00:07:37.260
de opinie sau imagine.

00:07:37.260 --> 00:07:39.260
Este o viziune uluitoare.

00:07:39.260 --> 00:07:42.260
Vrea să spun, gândiţi-vă la asta. Ce măreţ. Ce ambiţios.

00:07:42.260 --> 00:07:44.260
Atât de ambiţioşi suntem.

00:07:44.260 --> 00:07:46.260
El vrea să rezolve probleme etice.

00:07:46.260 --> 00:07:48.260
El vrea adevăruri obiective.

00:07:48.260 --> 00:07:51.260
Dacă gândiţi astfel,

00:07:51.260 --> 00:07:54.260
aveţi un cadru moral platonician.

00:07:54.260 --> 00:07:56.260
Dacă nu gândiţi astfel,

00:07:56.260 --> 00:07:58.260
ei bine, aveţi mulţi colegi în istoria filosofiei occidentale,

00:07:58.260 --> 00:08:01.260
pentru că cea mai curată idee - ştiţi, este criticată de oameni.

00:08:01.260 --> 00:08:04.260
Aristotel, mai ales, nu a fost amuzat.

00:08:04.260 --> 00:08:07.260
A considerat că nu este practică.

00:08:07.260 --> 00:08:11.260
Aristotel a spus, "Ar trebui să căutăm numai atâta precizie în fiecare subiect

00:08:11.260 --> 00:08:13.260
câtă acel subiect ne permite."

00:08:13.260 --> 00:08:16.260
Aristotel credea că etica nu prea semăna cu matematica.

00:08:16.260 --> 00:08:19.260
Credea că etica ţine de luarea deciziilor aici şi acum

00:08:19.260 --> 00:08:21.260
folosindu-ne de raţionamentul cel mai bun

00:08:21.260 --> 00:08:23.260
pentru găsirea căii corecte.

00:08:23.260 --> 00:08:25.260
Dacă gândiţi aşa, Platon nu este omul vostru.

00:08:25.260 --> 00:08:27.260
Dar nu renunţaţi.

00:08:27.260 --> 00:08:29.260
Poate există o altă cale

00:08:29.260 --> 00:08:32.260
prin care putem folosi numerele ca bază a cadrului nostru moral.

00:08:33.260 --> 00:08:35.260
Ce ziceţi de asta:

00:08:35.260 --> 00:08:38.260
Ce ar fi ca în orice situaţie să puteţi calcula,

00:08:38.260 --> 00:08:40.260
analiza opţiunile,

00:08:40.260 --> 00:08:43.260
cântări care este cea mai bună şi să ştiţi ce să faceţi?

00:08:43.260 --> 00:08:45.260
Vă sună cunoscut?

00:08:45.260 --> 00:08:48.260
Este un cadru moral utilitarist.

00:08:48.260 --> 00:08:50.260
John Stuart Mill era un susţinător înfocat al acestuia -

00:08:50.260 --> 00:08:52.260
un tip de treabă de altfel -

00:08:52.260 --> 00:08:54.260
şi mort de 200 de ani.

00:08:54.260 --> 00:08:56.260
Deci bazele utilitarismului -

00:08:56.260 --> 00:08:58.260
sunt sigur că sunteţi cel puţin familiarizaţi.

00:08:58.260 --> 00:09:00.260
Cele trei persoane care au votat cu Mill înainte să se familiarizeze cu acesta.

00:09:00.260 --> 00:09:02.260
Dar iată cum funcţionează.

00:09:02.260 --> 00:09:05.260
Ce ar fi dacă morala, ce ar fi dacă ceea ce face un lucru moral

00:09:05.260 --> 00:09:07.260
este doar o chestiune de a-i maximiza plăcerea

00:09:07.260 --> 00:09:09.260
şi a minimiza durerea?

00:09:09.260 --> 00:09:12.260
Face ceva intrinsec actului.

00:09:12.260 --> 00:09:14.260
Nu se aseamănă cu relaţia sa cu o formă abstractă.

00:09:14.260 --> 00:09:16.260
E o chestiune legată de consecinţe.

00:09:16.260 --> 00:09:18.260
Vă uitaţi la consecinţe

00:09:18.260 --> 00:09:20.260
şi vedeţi dacă, în mare, este înspre bine sau înspre rău.

00:09:20.260 --> 00:09:22.260
Asta ar fi simplu. Atunci ştim ce să facem.

00:09:22.260 --> 00:09:24.260
Haideţi să luăm un exemplu.

00:09:24.260 --> 00:09:26.260
Să presupunem că mă trezesc

00:09:26.260 --> 00:09:28.260
şi vă spun, "Vă voi lua telefonul."

00:09:28.260 --> 00:09:30.260
Nu doar pentru că a sunat mai devreme,

00:09:30.260 --> 00:09:33.260
dar îl voi lua pentru că am calculat puţin.

00:09:33.260 --> 00:09:36.260
Mi s-a părut că acel tip arată suspect.

00:09:36.260 --> 00:09:39.260
Şi dacă transmite mesaje scurte ascunzătorii lui Bin Laden -

00:09:39.260 --> 00:09:41.260
sau celui care a preluat conducerea după Bin Laden -

00:09:41.260 --> 00:09:44.260
şi este de fapt un fel de terorist, o celulă.

00:09:44.260 --> 00:09:47.260
Voi afla acel lucru, şi când îl voi afla,

00:09:47.260 --> 00:09:50.260
voi preveni un număr mare de distrugeri pe care le-ar putea cauza.

00:09:50.260 --> 00:09:53.260
Aceasta are o utilitate crescută în prevenirea distrugerilor.

00:09:53.260 --> 00:09:55.260
Şi în comparaţie cu puţina durere pe care o va cauza -

00:09:55.260 --> 00:09:57.260
pentru că va fi jenant când mă voi uita în telefonul lui

00:09:57.260 --> 00:10:00.260
şi voi vedea că are o problemă legată de Farmville -

00:10:00.260 --> 00:10:03.260
este copleşitor

00:10:03.260 --> 00:10:05.260
din perspectiva valorii de a te uita la un telefon.

00:10:05.260 --> 00:10:07.260
Dacă asta simţiţi,

00:10:07.260 --> 00:10:10.260
aceasta este o alegere utilitaristă.

00:10:10.260 --> 00:10:13.260
Dar poate că nu sunteţi de acord nici cu asta.

00:10:13.260 --> 00:10:15.260
Poate vă gândiţi, este telefonul lui.

00:10:15.260 --> 00:10:17.260
E greşit să-i iau telefonul,

00:10:17.260 --> 00:10:19.260
pentru că e o persoană

00:10:19.260 --> 00:10:21.260
şi are drepturi şi demnitate,

00:10:21.260 --> 00:10:23.260
şi nu putem să ne amestecăm în asta.

00:10:23.260 --> 00:10:25.260
Are autonomie.

00:10:25.260 --> 00:10:27.260
Nu contează care sunt calculele.

00:10:27.260 --> 00:10:30.260
Există lucruri care sunt intrinsec greşite -

00:10:30.260 --> 00:10:32.260
cum ar fi minciuna care este rea,

00:10:32.260 --> 00:10:35.260
cum ar fi torturarea copiilor nevinovaţi, care este un lucru rău.

00:10:35.260 --> 00:10:38.260
Kant era foarte bun în această privinţă,

00:10:38.260 --> 00:10:40.260
iar el a spus-o puţin mai bine decât o voi spune eu.

00:10:40.260 --> 00:10:42.260
A spus că ar trebui să ne folosim raţiunea

00:10:42.260 --> 00:10:45.260
pentru a găsi regulile după care să ne ghidăm conduita.

00:10:45.260 --> 00:10:48.260
Şi apoi este datoria noastră să respectăm acele reguli.

00:10:48.260 --> 00:10:51.260
Nu este o chestiune de calcul.

00:10:51.260 --> 00:10:53.260
Deci, să ne oprim.

00:10:53.260 --> 00:10:56.260
Avem dreptate în profunzime, această profunzime filosofică.

00:10:56.260 --> 00:10:59.260
Şi acest lucru se repetă de o mie de ani,

00:10:59.260 --> 00:11:01.260
pentru că acestea sunt întrebări dificile,

00:11:01.260 --> 00:11:03.260
şi eu am la dispoziţie doar 15 minute.

00:11:03.260 --> 00:11:05.260
Deci să trecem la subiect.

00:11:05.260 --> 00:11:09.260
Cum ar trebui să luăm deciziile?

00:11:09.260 --> 00:11:12.260
Ca Platon, Aristotel, Kant sau Mill?

00:11:12.260 --> 00:11:14.260
Ce ar trebui să facem? Care este răspunsul?

00:11:14.260 --> 00:11:17.260
Care este formula pe care o putem folosi în orice situaţie

00:11:17.260 --> 00:11:19.260
pentru a determina ceea ce trebuie să facem,

00:11:19.260 --> 00:11:21.260
ar trebui să folosim informaţiile acelui tip sau nu?

00:11:21.260 --> 00:11:24.260
Care este formula?

00:11:25.260 --> 00:11:27.260
Nu există formulă.

00:11:29.260 --> 00:11:31.260
Nu există un răspuns simplu.

00:11:31.260 --> 00:11:34.260
Etica este grea.

00:11:34.260 --> 00:11:37.260
Etica presupune gândire.

00:11:38.260 --> 00:11:40.260
Şi acesta nu este un lucru confortabil.

00:11:40.260 --> 00:11:42.260
Ştiu, mi-am petrecut mult timp din carieră

00:11:42.260 --> 00:11:44.260
în inteligenţa artificială,

00:11:44.260 --> 00:11:47.260
încercând să construiesc maşini care ar putea să gândească pentru noi,

00:11:47.260 --> 00:11:49.260
care ar putea să ne ofere răspunsuri.

00:11:49.260 --> 00:11:51.260
Dar nu pot.

00:11:51.260 --> 00:11:53.260
Nu puteţi doar să luați gândirea umană

00:11:53.260 --> 00:11:55.260
şi să o puneți într-o maşină.

00:11:55.260 --> 00:11:58.260
Noi suntem cei care trebuie s-o facem.

00:11:58.260 --> 00:12:01.260
Din fericire, nu suntem maşini, şi putem s-o facem.

00:12:01.260 --> 00:12:03.260
Nu numai că putem raționa,

00:12:03.260 --> 00:12:05.260
dar trebuie să raționăm.

00:12:05.260 --> 00:12:07.260
Hannah Arendt a spus,

00:12:07.260 --> 00:12:09.260
"Tristul adevăr

00:12:09.260 --> 00:12:11.260
este că cea mai mare parte a răului făcut în această lume

00:12:11.260 --> 00:12:13.260
nu este făcut de oameni

00:12:13.260 --> 00:12:15.260
care aleg să fie răi.

00:12:15.260 --> 00:12:18.260
Provine din faptul că nu gândim."

00:12:18.260 --> 00:12:22.260
Asta numeşte ea "banalitatea răului."

00:12:22.260 --> 00:12:24.260
Şi răspunsul la asta

00:12:24.260 --> 00:12:26.260
este că cerem exercițiul gândirii

00:12:26.260 --> 00:12:29.260
fiecărei persoane normale.

00:12:29.260 --> 00:12:31.260
Deci, haideți să facem asta. Haideți să gândim.

00:12:31.260 --> 00:12:34.260
De fapt, haideți să începem chiar acum.

00:12:34.260 --> 00:12:37.260
Fiecare persoană din această încăpere să facă asta:

00:12:37.260 --> 00:12:40.260
gândiți-vă la ultima dată când a trebuit să luați o decizie

00:12:40.260 --> 00:12:42.260
când a face lucru corect vă îngrijora,

00:12:42.260 --> 00:12:44.260
când v-ați întrebat, "Ce ar trebui să fac?"

00:12:44.260 --> 00:12:46.260
Aduceți-vă aminte.

00:12:46.260 --> 00:12:48.260
Şi acum reflectați la acel lucru

00:12:48.260 --> 00:12:51.260
şi spuneți, "Cum am ajuns la această decizie?

00:12:51.260 --> 00:12:54.260
Ce am făcut? Mi-am urmat instinctul?

00:12:54.260 --> 00:12:56.260
Am pus pe cineva să voteze decizia? Sau am mizat pe drept?"

00:12:56.260 --> 00:12:59.260
Acum avem puțin mai multe alegeri.

00:12:59.260 --> 00:13:01.260
"Am evaluat care ar fi cea mai mare plăcere

00:13:01.260 --> 00:13:03.260
cum ar fi făcut Mill?

00:13:03.260 --> 00:13:06.260
Sau asemenea lui Kant, am folosit rațiunea pentru a afla ceea ce intrinsec este bine?

00:13:06.260 --> 00:13:09.260
Gândiți-vă. Chiar amintiți-vă. Este important.

00:13:09.260 --> 00:13:11.260
Este atât de important

00:13:11.260 --> 00:13:13.260
încât vom folosi 30 de secunde prețioase din timpul TEDTalks

00:13:13.260 --> 00:13:15.260
nefăcând altceva decât gândindu-ne la asta.

00:13:15.260 --> 00:13:17.260
Sunteți pregătiți? Începeți.

00:13:33.260 --> 00:13:36.260
Opriți-vă. Foarte bine.

00:13:36.260 --> 00:13:38.260
Ceea ce tocmai ați făcut

00:13:38.260 --> 00:13:40.260
este primul pas în asumarea responsabilității

00:13:40.260 --> 00:13:43.260
pentru ceea ce ar trebui să facem cu toată puterea noastră.

00:13:45.260 --> 00:13:48.260
Acum următorul pas - încercați asta.

00:13:49.260 --> 00:13:51.260
Găsiți-vă un prieten şi explicați-i

00:13:51.260 --> 00:13:53.260
cum ați luat decizia.

00:13:53.260 --> 00:13:55.260
Nu chiar acum. Aşteptați până termin conferința.

00:13:55.260 --> 00:13:57.260
Faceți-o la prânz.

00:13:57.260 --> 00:14:00.260
Şi nu vă găsiți un alt prieten tehnolog;

00:14:00.260 --> 00:14:02.260
găsiți pe cineva diferit de voi.

00:14:02.260 --> 00:14:04.260
Găsiți-vă un artist sau un scriitor -

00:14:04.260 --> 00:14:07.260
sau, pentru Dumnezeu, găsiți-vă un filosof şi vorbiți cu el.

00:14:07.260 --> 00:14:09.260
De fapt, găsiți pe cineva din ştiințele umane.

00:14:09.260 --> 00:14:11.260
De ce? Pentru că ei se gândesc la probleme

00:14:11.260 --> 00:14:13.260
diferit de noi tehnologii.

00:14:13.260 --> 00:14:16.260
Acum câteva zile, peste drum de noi,

00:14:16.260 --> 00:14:18.260
erau sute de oameni adunați.

00:14:18.260 --> 00:14:20.260
Erau tehnologi şi umanişti

00:14:20.260 --> 00:14:22.260
la acea mare Conferință BiblioTech.

00:14:22.260 --> 00:14:24.260
Şi s-au reunit

00:14:24.260 --> 00:14:26.260
pentru că tehnologii doreau să afle

00:14:26.260 --> 00:14:29.260
cum ar fi să gândeşti din perspectiva ştiințelor umaniste.

00:14:29.260 --> 00:14:31.260
Aveți pe cineva de pe Google

00:14:31.260 --> 00:14:33.260
care vorbeşte cu cineva care se ocupă cu literatura comparată.

00:14:33.260 --> 00:14:36.260
Vă gândiți la relevanța teatrului francez din secolul al-XVII-lea -

00:14:36.260 --> 00:14:38.260
cum afectează asta capitalul de risc?

00:14:38.260 --> 00:14:41.260
Ei bine, e interesant. E o altfel de gândire.

00:14:41.260 --> 00:14:43.260
Şi când gândeşti în acest fel

00:14:43.260 --> 00:14:46.260
devii mai sensibil la părerile oamenilor,

00:14:46.260 --> 00:14:49.260
care sunt cruciale în luarea deciziilor etice.

00:14:49.260 --> 00:14:51.260
Deci, imaginaţi-vă că în acest moment

00:14:51.260 --> 00:14:53.260
aţi plecat şi v-aţi găsit prietenul muzician.

00:14:53.260 --> 00:14:56.260
Şi îi povestiţi discuţia noastră

00:14:56.260 --> 00:14:58.260
despre întreaga revoluţie a informaţiilor şi toate acestea -

00:14:58.260 --> 00:15:00.260
poate chiar îi fredonaţi câteva note ale temei noastre muzicale.

00:15:00.260 --> 00:15:03.260
♫ Dum ta da da dum dum ta da da dum♫

00:15:03.260 --> 00:15:05.260
Ei bine, prietenul vostru muzician o să vă oprească şi va spune,

00:15:05.260 --> 00:15:07.260
"Ştii, tema muzicală

00:15:07.260 --> 00:15:09.260
pentru revoluţia informaţiilor,

00:15:09.260 --> 00:15:11.260
e o operă, e Wagner.

00:15:11.260 --> 00:15:13.260
E bazată pe legenda lui Norse.

00:15:13.260 --> 00:15:15.260
E vorba de zei şi creaturi mitice

00:15:15.260 --> 00:15:18.260
care se luptă pentru bijuterii magice.

00:15:19.260 --> 00:15:22.260
Interesant.

00:15:22.260 --> 00:15:25.260
Este şi o operă frumoasă.

00:15:25.260 --> 00:15:28.260
Suntem mişcaţi de acea operă.

00:15:28.260 --> 00:15:30.260
Suntem mişcaţi pentru că are ca subiect lupta

00:15:30.260 --> 00:15:32.260
dintre bine şi rău,

00:15:32.260 --> 00:15:34.260
dreptatea şi nedreptatea.

00:15:34.260 --> 00:15:36.260
Şi suntem preocupaţi de dreptate şi nedreptate.

00:15:36.260 --> 00:15:39.260
Ne pasă de ceea ce se petrece în această operă.

00:15:39.260 --> 00:15:42.260
Ne pasă de ce se petrece în "Apocalipsa prezentului."

00:15:42.260 --> 00:15:44.260
Şi, cu siguranţă, ne pasă

00:15:44.260 --> 00:15:46.260
de ceea ce se întâmplă cu tehnologia noastră.

00:15:46.260 --> 00:15:48.260
Avem atât de multă putere astăzi,

00:15:48.260 --> 00:15:51.260
depinde de noi să descoperim ce să facem.

00:15:51.260 --> 00:15:53.260
Şi aceasta este vestea bună.

00:15:53.260 --> 00:15:56.260
Noi suntem cei care scriu această operă.

00:15:56.260 --> 00:15:58.260
Acesta este filmul nostru.

00:15:58.260 --> 00:16:01.260
Noi descoperim ce se va întâmpla cu această tehnologie.

00:16:01.260 --> 00:16:04.260
Noi determinăm cum se vor termina toate acestea.

00:16:04.260 --> 00:16:06.260
Mulţumesc.

00:16:06.260 --> 00:16:11.260
(Aplauze)

