WEBVTT
Kind: captions
Language: no

00:00:00.000 --> 00:00:07.000
Translator: Anna Karina Carlsson
Reviewer: Martin Hassel

00:00:15.260 --> 00:00:17.260
Makt.

00:00:17.260 --> 00:00:19.260
Det er ordet jeg kommer å tenke på.

00:00:19.260 --> 00:00:21.260
Vi er de nye teknologene.

00:00:21.260 --> 00:00:24.260
Vi har mye data, så vi har mye makt.

00:00:24.260 --> 00:00:26.260
Hvor mye makt har vi?

00:00:26.260 --> 00:00:29.260
Scene fra en film: "Apocalypse Now" -- storartet film.

00:00:29.260 --> 00:00:32.260
Vi må sende vår helt, Kapt. Willard, til munningen av Nung-floden

00:00:32.260 --> 00:00:34.260
slik at han kan forfølge Oberst Kurtz.

00:00:34.260 --> 00:00:36.260
Måten vi skal gjøre det på er å fly ham inn og slippe ham ut.

00:00:36.260 --> 00:00:38.260
Så, scenen:

00:00:38.260 --> 00:00:41.260
himmelen er fylt med denne flåten av helikoptre som tar ham inn.

00:00:41.260 --> 00:00:43.260
Og det er den der høye, spennende musikken i bakgrunnen,

00:00:43.260 --> 00:00:45.260
vill musikk.

00:00:45.260 --> 00:00:47.260
♫ Dum da ta da dum ♫

00:00:47.260 --> 00:00:49.260
♫ Dum da ta da dum ♫

00:00:49.260 --> 00:00:52.260
♫ Da ta da da ♫

00:00:52.260 --> 00:00:54.260
Det er mye makt.

00:00:54.260 --> 00:00:56.260
Det er den typen makt jeg kjenner i dette rommet.

00:00:56.260 --> 00:00:58.260
Det er den typen makt vi har

00:00:58.260 --> 00:01:00.260
gjennom all den data som vi har.

00:01:00.260 --> 00:01:02.260
La oss ta et eksempel.

00:01:02.260 --> 00:01:04.260
Hva vi kan gjøre

00:01:04.260 --> 00:01:07.260
med kun en persons data?

00:01:07.260 --> 00:01:09.260
Hva kan vi gjøre

00:01:09.260 --> 00:01:11.260
med den fyrens data?

00:01:11.260 --> 00:01:13.260
Jeg kan se på dine finanser.

00:01:13.260 --> 00:01:15.260
Jeg kan si om du betaler dine regninger i tide.

00:01:15.260 --> 00:01:17.260
Jeg vet om du er verdt å innvilge lån til.

00:01:17.260 --> 00:01:20.260
Jeg kan se på din medisinske journal, jeg kan se om pumpen din fortsatt pumper --

00:01:20.260 --> 00:01:23.260
se om du er verdt å tilby forsikring til.

00:01:23.260 --> 00:01:25.260
Jeg kan se på ditt klikkemønster.

00:01:25.260 --> 00:01:28.260
Når du kommer inn på min webside, kan jeg faktisk vite hva du har tenkt å gjøre allerede,

00:01:28.260 --> 00:01:30.260
for jeg har sett deg besøke milliontalls websider tidligere.

00:01:30.260 --> 00:01:32.260
Og jeg beklager å si det,

00:01:32.260 --> 00:01:34.260
du er som en pokerspiller, du avslører deg.

00:01:34.260 --> 00:01:36.260
Jeg kan med dataanalyse si hva du kommer til å gjøre

00:01:36.260 --> 00:01:38.260
før du faktisk gjør det.

00:01:38.260 --> 00:01:41.260
Jeg vet hva du liker. Jeg vet hvem du er.

00:01:41.260 --> 00:01:43.260
Og det er til og med før jeg kikker på dine e-poster

00:01:43.260 --> 00:01:45.260
eller din telefon.

00:01:45.260 --> 00:01:47.260
Det er slike ting vi kan gjøre

00:01:47.260 --> 00:01:50.260
med det datamateriell vi har.

00:01:50.260 --> 00:01:53.260
Men, jeg er egentlig ikke her for å prate om hva vi kan gjøre.

00:01:56.260 --> 00:01:59.260
Jeg er her for å prate om hva vi burde gjøre.

00:02:00.260 --> 00:02:03.260
Hva er det riktige å gjøre?

00:02:04.260 --> 00:02:06.260
Nå ser jeg noen rådville uttrykk

00:02:06.260 --> 00:02:09.260
som, "Hvorfor spør du oss om hva som er det riktige å gjøre?

00:02:09.260 --> 00:02:12.260
Vi bygger jo bare tingene. Noen andre bruker dem.

00:02:12.260 --> 00:02:15.260
Sant nok.

00:02:15.260 --> 00:02:17.260
Men det bringer meg tilbake.

00:02:17.260 --> 00:02:19.260
Jeg tenker på andre verdenskrigen --

00:02:19.260 --> 00:02:21.260
noen av våre fantastiske teknologer da,

00:02:21.260 --> 00:02:23.260
noen av våre fantastiske fysikere,

00:02:23.260 --> 00:02:25.260
som studerte kjernefysisk fisjon og fusjon --

00:02:25.260 --> 00:02:27.260
bare kjernefysiske ting.

00:02:27.260 --> 00:02:30.260
Vi samler sammen disse fysikerne i Los Alamos

00:02:30.260 --> 00:02:33.260
for å se hva de kan bygge.

00:02:33.260 --> 00:02:36.260
Vi vil at menneskene som bygger teknologien

00:02:36.260 --> 00:02:39.260
skal tenke på hva vi burde gjøre med teknologien.

00:02:41.260 --> 00:02:44.260
Så hva burde vi gjøre med den fyrens data?

00:02:44.260 --> 00:02:47.260
Burde vi samle det inn, registrere det,

00:02:47.260 --> 00:02:49.260
slik at vi kan gjøre hans opplevelse online bedre.

00:02:49.260 --> 00:02:51.260
Slik at vi kan tjene penger?

00:02:51.260 --> 00:02:53.260
Slik at vi kan beskytte oss selv

00:02:53.260 --> 00:02:55.260
hvis han var ute etter å gjøre ugagn.

00:02:55.260 --> 00:02:58.260
Eller, burde vi respektere hans privatliv,

00:02:58.260 --> 00:03:01.260
beskytte hans verdighet og la ham være i fred?

00:03:02.260 --> 00:03:05.260
Hvilken er det?

00:03:05.260 --> 00:03:07.260
Hvordan finner vi det ut?

00:03:07.260 --> 00:03:10.260
Jeg vet: avstemning. La oss stemme på dette.

00:03:11.260 --> 00:03:14.260
Så, som oppvarming,

00:03:14.260 --> 00:03:16.260
la oss starte med et lett spørsmål --

00:03:16.260 --> 00:03:19.260
noe jeg er sikker på at alle her har en mening om:

00:03:19.260 --> 00:03:21.260
iPhone versus Android.

00:03:21.260 --> 00:03:24.260
Strekk opp handa -- iPhone.

00:03:24.260 --> 00:03:26.260
Aha.

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
Man skulle tro, med en masse smarte mennesker,

00:03:31.260 --> 00:03:33.260
at vi ikke bare var svake for de fineste telefonene.

00:03:33.260 --> 00:03:35.260
(Latter)

00:03:35.260 --> 00:03:37.260
Neste spørsmål,

00:03:37.260 --> 00:03:39.260
littegrann vanskeligere.

00:03:39.260 --> 00:03:41.260
Burde vi samle inn alt av den fyrens data

00:03:41.260 --> 00:03:43.260
for å gjøre hans opplevelse bedre

00:03:43.260 --> 00:03:46.260
og for å beskytte oss selv hvis han er uærlig?

00:03:46.260 --> 00:03:48.260
Eller burde vi la ham være i fred?

00:03:48.260 --> 00:03:51.260
Samle inn data.

00:03:53.260 --> 00:03:56.260
La ham være i fred.

00:03:56.260 --> 00:03:58.260
Dere er sikker. Det går bra.

00:03:58.260 --> 00:04:00.260
(Latter)

00:04:00.260 --> 00:04:02.260
Ok, siste spørsmål --

00:04:02.260 --> 00:04:04.260
vanskeligere spørsmål --

00:04:04.260 --> 00:04:07.260
når man skal evaluere

00:04:07.260 --> 00:04:10.260
hva man burde gjøre i dette tilfellet,

00:04:10.260 --> 00:04:14.260
burde vi bruke et Kantiansk deontologisk moralsk rammeverk,

00:04:14.260 --> 00:04:17.260
eller burde vi bruke et Mill-konsekvensialistisk?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
Ikke like mange stemmer.

00:04:27.260 --> 00:04:30.260
(Latter)

00:04:30.260 --> 00:04:33.260
Ja, det er et skremmende resultat.

00:04:34.260 --> 00:04:38.260
Skremmende fordi vi har sterkere meninger

00:04:38.260 --> 00:04:40.260
om våre håndholdte enheter

00:04:40.260 --> 00:04:42.260
enn om vårt moralske rammeverk

00:04:42.260 --> 00:04:44.260
vi burde bruke for å veilede våre beslutninger.

00:04:44.260 --> 00:04:47.260
Hvordan vet vi hva vi skal gjøre med all den makt vi har

00:04:47.260 --> 00:04:50.260
hvis vi ikke har et moralsk rammeverk?

00:04:50.260 --> 00:04:53.260
Vi vet mer om mobile operativsystem,

00:04:53.260 --> 00:04:56.260
men hva vi egentlig trenger er et moralsk operativsystem.

00:04:58.260 --> 00:05:00.260
Hva er et moralsk operativsystem?

00:05:00.260 --> 00:05:02.260
Vi kjenner alle riktig og galt, ikke sant.

00:05:02.260 --> 00:05:04.260
Det føles bra når du gjør noe riktig,

00:05:04.260 --> 00:05:06.260
det føles dårlig når du gjør noe galt.

00:05:06.260 --> 00:05:09.260
Våre foreldre lær oss: ros med det gode, ris med det gale.

00:05:09.260 --> 00:05:12.260
Men hvordan finner vi ut hva som er rett og galt?

00:05:12.260 --> 00:05:15.260
Og fra dag til dag, vi har teknikkene vi bruker.

00:05:15.260 --> 00:05:18.260
Kanskje vi bare følger magefølelsen.

00:05:18.260 --> 00:05:21.260
Kanskje vi stemmer -- vi tar en avstemning.

00:05:21.260 --> 00:05:23.260
Eller vi tar sjansen --

00:05:23.260 --> 00:05:26.260
spør jussavdelingen, ser hva de sier.

00:05:26.260 --> 00:05:28.260
Med andre ord, det er ganske tilfeldig,

00:05:28.260 --> 00:05:30.260
ganske ad hoc,

00:05:30.260 --> 00:05:33.260
hvordan vi finner ut hva vi burde gjøre.

00:05:33.260 --> 00:05:36.260
Og kanskje, hvis vi vil være på sikrere grunn,

00:05:36.260 --> 00:05:39.260
hva vi egentlig vil ha er et moralsk rammeverk som kan guide oss dit,

00:05:39.260 --> 00:05:42.260
som forteller oss hvilke ting som er rette og gale i utgangspunktet,

00:05:42.260 --> 00:05:46.260
og hvordan vi skal kunne vite i enhver situasjon hva vi skal gjøre.

00:05:46.260 --> 00:05:48.260
Så la oss skaffe oss et moralsk rammeverk.

00:05:48.260 --> 00:05:51.260
Vi er siffer-mennesker, vi lever av tall.

00:05:51.260 --> 00:05:53.260
Hvordan kan vi bruke tall

00:05:53.260 --> 00:05:56.260
som basis for et moralsk rammeverk?

00:05:56.260 --> 00:05:59.260
Jeg kjenner en fyr som gjorde nøyaktig det,

00:05:59.260 --> 00:06:02.260
En genial fyr --

00:06:02.260 --> 00:06:05.260
han har vært død i 2500 år.

00:06:05.260 --> 00:06:07.260
Platon, det stemmer.

00:06:07.260 --> 00:06:09.260
Husker dere ham -- gammel filosof?

00:06:09.260 --> 00:06:12.260
Dere sov i den timen.

00:06:12.260 --> 00:06:14.260
Og Platon, han hadde mange av de samme bekymringene som vi hadde.

00:06:14.260 --> 00:06:16.260
Han var bekymret over rett og galt.

00:06:16.260 --> 00:06:18.260
Han ville vite hva som er rettferdig.

00:06:18.260 --> 00:06:20.260
Men han var bekymret over at alt vi så ut til å gjøre

00:06:20.260 --> 00:06:22.260
var å utbytte synspunkter om dette.

00:06:22.260 --> 00:06:25.260
Han sier at noe er rettferdig. Hun sier at noe annet er rettferdig.

00:06:25.260 --> 00:06:27.260
Det er ganske overbevisende når han snakker og når hun snakker også.

00:06:27.260 --> 00:06:29.260
Jeg går bare frem og tilbake; jeg kommer ingen vei.

00:06:29.260 --> 00:06:32.260
Jeg vil ikke ha synspunkter, jeg vil ha kunnskap.

00:06:32.260 --> 00:06:35.260
Jeg vil ha sannheten om rettferdighet --

00:06:35.260 --> 00:06:38.260
som vi har sannheter i matematikk.

00:06:38.260 --> 00:06:41.260
Innenfor matematikk vet vi objektive fakta.

00:06:41.260 --> 00:06:43.260
Ta et tall, hvilket som helst -- to.

00:06:43.260 --> 00:06:45.260
Favorittall. Jeg elsker det tallet.

00:06:45.260 --> 00:06:47.260
Det finnes sannheter om to.

00:06:47.260 --> 00:06:49.260
Hvis du har to av noe,

00:06:49.260 --> 00:06:51.260
du legger til to til, så får du fire.

00:06:51.260 --> 00:06:53.260
Det er sant uansett hva slags ting du snakker om.

00:06:53.260 --> 00:06:55.260
Det er en objektiv sannhet om formen av to,

00:06:55.260 --> 00:06:57.260
den abstrakte formen.

00:06:57.260 --> 00:06:59.260
Når du har to av noe -- to øyer, to ører, to neser,

00:06:59.260 --> 00:07:01.260
bare to utspring --

00:07:01.260 --> 00:07:04.260
de tar alle formen av to.

00:07:04.260 --> 00:07:08.260
De er alle med i sannheten som to har.

00:07:08.260 --> 00:07:10.260
De har alle en to-het i seg.

00:07:10.260 --> 00:07:13.260
Og derfor er det ikke et spørsmål om synspunkter.

00:07:13.260 --> 00:07:15.260
Enn hvis, tenkte Platon,

00:07:15.260 --> 00:07:17.260
etikk var som matematikk?

00:07:17.260 --> 00:07:20.260
Enn hvis det fantes en ren form for rettferdighet?

00:07:20.260 --> 00:07:22.260
Enn hvis det finnes sannheter om rettferdighet,

00:07:22.260 --> 00:07:24.260
og du bare kan se deg rundt i verden

00:07:24.260 --> 00:07:26.260
og se hvilke ting som tilhørte,

00:07:26.260 --> 00:07:29.260
var en del av den formen for rettferdighet?

00:07:29.260 --> 00:07:32.260
Da hadde du visst hva som virkelig var rettferdig og hva som ikke var det.

00:07:32.260 --> 00:07:34.260
Det hadde ikke blitt et spørsmål

00:07:34.260 --> 00:07:37.260
om bare synspunkter eller fremtreden.

00:07:37.260 --> 00:07:39.260
Det er en oppsiktsvekkende visjon.

00:07:39.260 --> 00:07:42.260
Jeg mener, tenk på det. Så flott. Så ambisiøst.

00:07:42.260 --> 00:07:44.260
Det er så ambisiøse vi er.

00:07:44.260 --> 00:07:46.260
Han vil løse etikken.

00:07:46.260 --> 00:07:48.260
Han ønsker objektiv sannhet.

00:07:48.260 --> 00:07:51.260
Hvis du tenker på den måten.

00:07:51.260 --> 00:07:54.260
har du et platonsk moralsk rammeverk.

00:07:54.260 --> 00:07:56.260
Hvis du ikke tenker på den måten,

00:07:56.260 --> 00:07:58.260
vel, da har du mye selskap fra vestens historiske filosofi,

00:07:58.260 --> 00:08:01.260
siden en så ryddig idé -- du vet, folk kritiserte den.

00:08:01.260 --> 00:08:04.260
Aristoteles, spesielt, han var ikke fornøyd.

00:08:04.260 --> 00:08:07.260
Han mente det var upraktisk.

00:08:07.260 --> 00:08:11.260
Aristoteles sa, "Vi burde søke kun så mye presisjon i ethvert emne,

00:08:11.260 --> 00:08:13.260
som det emnet tillater."

00:08:13.260 --> 00:08:16.260
Aristoteles mente etikk ikke var som matematikk.

00:08:16.260 --> 00:08:19.260
Han mente etikk var et spørsmål om å ta beslutning i øyeblikket

00:08:19.260 --> 00:08:21.260
gjennom å bruke vårt beste skjønn

00:08:21.260 --> 00:08:23.260
for å finne den rette veien.

00:08:23.260 --> 00:08:25.260
Hvis du tenker sånn er ikke Platon din type.

00:08:25.260 --> 00:08:27.260
Men ikke gi opp.

00:08:27.260 --> 00:08:29.260
Kanskje finnes det en annen måte

00:08:29.260 --> 00:08:32.260
vi kan bruke tall på som en basis for vårt moralske rammeverk.

00:08:33.260 --> 00:08:35.260
Hva med dette:

00:08:35.260 --> 00:08:38.260
Enn hvis du, i enhver situasjon, kunne beregne,

00:08:38.260 --> 00:08:40.260
se på valgmulighetene,

00:08:40.260 --> 00:08:43.260
måle opp hvilken som er bedre og vite hva man skal gjøre?

00:08:43.260 --> 00:08:45.260
Høres dette kjent ut?

00:08:45.260 --> 00:08:48.260
Det er et utilitaristisk moralsk rammeverk.

00:08:48.260 --> 00:08:50.260
John Stuart Mill var en stor advokat for dette --

00:08:50.260 --> 00:08:52.260
hyggelig fyr foresten --

00:08:52.260 --> 00:08:54.260
og har kun vær død i 200 år.

00:08:54.260 --> 00:08:56.260
Så grunnleggende utilitarisme --

00:08:56.260 --> 00:08:58.260
det er sikkert litt kjent.

00:08:58.260 --> 00:09:00.260
De tre personene som stemte for Mill tidligere kjenner til dette.

00:09:00.260 --> 00:09:02.260
Men her er måten det fungerer på.

00:09:02.260 --> 00:09:05.260
Enn hvis moral, enn hvis det som gjør noe moralsk,

00:09:05.260 --> 00:09:07.260
bare er et spørsmål om hvorvidt det maksimerer nytelse

00:09:07.260 --> 00:09:09.260
og minimerer smerte?

00:09:09.260 --> 00:09:12.260
Det tilfører noe inneboende til handlingen.

00:09:12.260 --> 00:09:14.260
Det er ikke dens relasjon til noen abstrakt form.

00:09:14.260 --> 00:09:16.260
Det er bare et spørsmål om konsekvenser.

00:09:16.260 --> 00:09:18.260
Du ser på konsekvensene

00:09:18.260 --> 00:09:20.260
og ser om de, overordnet, gjør det bedre eller verre.

00:09:20.260 --> 00:09:22.260
Det hadde vært enkelt. Da vet vi hva vi skal gjøre.

00:09:22.260 --> 00:09:24.260
La oss ta et eksempel.

00:09:24.260 --> 00:09:26.260
La oss si at jeg går opp

00:09:26.260 --> 00:09:28.260
og sier, "Jeg tenker å ta din telefon."

00:09:28.260 --> 00:09:30.260
Ikke bare fordi den ringte tidligere,

00:09:30.260 --> 00:09:33.260
men jeg tenker ta den fordi jeg har gjort et lite regnestykke.

00:09:33.260 --> 00:09:36.260
Jeg tenkte, den fyren ser mistenkelig ut.

00:09:36.260 --> 00:09:39.260
Og hva om han har sendt noen små meldinger til Bin Ladens gjemmested --

00:09:39.260 --> 00:09:41.260
eller hvem som nå tok over etter Bin Laden --

00:09:41.260 --> 00:09:44.260
og han er faktisk som en terrorist, en 'hvilende'.

00:09:44.260 --> 00:09:47.260
Jeg skal finne det ut, og når jeg har funnet det ut,

00:09:47.260 --> 00:09:50.260
så skal jeg forhindre en enorm mengde skader som han kunne ha skapt.

00:09:50.260 --> 00:09:53.260
Det har en veldig høy nytteverdi å forhindre den skaden.

00:09:53.260 --> 00:09:55.260
Og sammenlignet med den lille smerten det kommer å forårsake --

00:09:55.260 --> 00:09:57.260
fordi det kommer til å bli pinlig når jeg ser på telefonen hans

00:09:57.260 --> 00:10:00.260
og ser at han har et Farmville-problem og alt det der --

00:10:00.260 --> 00:10:03.260
det blir overgått

00:10:03.260 --> 00:10:05.260
av verdien av å se på den telefonen.

00:10:05.260 --> 00:10:07.260
Hvis du føler det på den måten,

00:10:07.260 --> 00:10:10.260
så er det et utilitaristisk valg

00:10:10.260 --> 00:10:13.260
Men kanskje føler du det ikke på den måten heller.

00:10:13.260 --> 00:10:15.260
Kanskje tenker du, det er hans telefon.

00:10:15.260 --> 00:10:17.260
Det er galt å ta hans telefon,

00:10:17.260 --> 00:10:19.260
fordi han er en person

00:10:19.260 --> 00:10:21.260
og han har rettigheter og han har verdighet,

00:10:21.260 --> 00:10:23.260
og vi kan ikke bare forstyrre det.

00:10:23.260 --> 00:10:25.260
Han har autonomi.

00:10:25.260 --> 00:10:27.260
Det spiller ingen rolle hva regnestykket er.

00:10:27.260 --> 00:10:30.260
Det finnes ting som er grunnlegende galt --

00:10:30.260 --> 00:10:32.260
slik som å lyve er galt,

00:10:32.260 --> 00:10:35.260
som å torturere uskyldige barn er galt.

00:10:35.260 --> 00:10:38.260
Kant var veldig bra på det punktet,

00:10:38.260 --> 00:10:40.260
og han sa det litt bedre enn jeg sier det.

00:10:40.260 --> 00:10:42.260
Han sa at vi skulle bruke vårt fornuft

00:10:42.260 --> 00:10:45.260
til å finne ut de reglene som skal styre vår adferd.

00:10:45.260 --> 00:10:48.260
Og da er det vår plikt å følge disse reglene.

00:10:48.260 --> 00:10:51.260
Det er ikke et spørsmål om beregning.

00:10:51.260 --> 00:10:53.260
Så la oss stoppe.

00:10:53.260 --> 00:10:56.260
Vi er midt i smørøyet her, i dette filosofiske kaoset.

00:10:56.260 --> 00:10:59.260
Og dette fortsetter i tusenvis av år,

00:10:59.260 --> 00:11:01.260
fordi dette er vanskelige spørsmål,

00:11:01.260 --> 00:11:03.260
og jeg har bare 15 minutter.

00:11:03.260 --> 00:11:05.260
Så la oss komme til saken.

00:11:05.260 --> 00:11:09.260
Hvordan burde vi ta våre beslutninger?

00:11:09.260 --> 00:11:12.260
Er det Platon, er det Aristoteles, er det Kant, er det Mill?

00:11:12.260 --> 00:11:14.260
Hva burde vi gjøre? Hva er svaret?

00:11:14.260 --> 00:11:17.260
Hva er formelen som vi kan bruke i enhver situasjon

00:11:17.260 --> 00:11:19.260
for å avgjøre hva vi burde gjøre,

00:11:19.260 --> 00:11:21.260
hvis vi burde bruke denne fyrens data eller ikke?

00:11:21.260 --> 00:11:24.260
Hva er formelen?

00:11:25.260 --> 00:11:27.260
Det finnes ingen formel.

00:11:29.260 --> 00:11:31.260
Det finnes ikke et enkelt svar.

00:11:31.260 --> 00:11:34.260
Etikk er vanskelig.

00:11:34.260 --> 00:11:37.260
Etikk krever tenkning.

00:11:38.260 --> 00:11:40.260
Og det er ukomfortabelt.

00:11:40.260 --> 00:11:42.260
Jeg vet; Jeg tilbragte mye av min karriere

00:11:42.260 --> 00:11:44.260
innenfor kunstig intelligens,

00:11:44.260 --> 00:11:47.260
og forsøkte bygge maskiner som kunne gjøre noe av denne tenkningen for oss,

00:11:47.260 --> 00:11:49.260
som kunne gi oss svar.

00:11:49.260 --> 00:11:51.260
Men det kan de ikke.

00:11:51.260 --> 00:11:53.260
Du kan ikke bare ta menneskelig tenkning

00:11:53.260 --> 00:11:55.260
og putte den inn i en maskin.

00:11:55.260 --> 00:11:58.260
Det er vi som må gjøre det.

00:11:58.260 --> 00:12:01.260
Heldigvis, vi er ikke maskiner, og vi kan gjøre det.

00:12:01.260 --> 00:12:03.260
Ikke bare kan vi tenke,

00:12:03.260 --> 00:12:05.260
vi må.

00:12:05.260 --> 00:12:07.260
Hannah Arendt sa,

00:12:07.260 --> 00:12:09.260
"Den triste sannheten

00:12:09.260 --> 00:12:11.260
er at den verste ondskapen i denne verden

00:12:11.260 --> 00:12:13.260
ikke kommer fra mennesker

00:12:13.260 --> 00:12:15.260
som velger å være onde.

00:12:15.260 --> 00:12:18.260
Den kommer fra å ikke tenke."

00:12:18.260 --> 00:12:22.260
Det er hva hun kaller "ondskapens banalitet."

00:12:22.260 --> 00:12:24.260
Og responsen på det

00:12:24.260 --> 00:12:26.260
er at vi krever øvelse i å tenke

00:12:26.260 --> 00:12:29.260
fra enhver fornuftig person.

00:12:29.260 --> 00:12:31.260
Så la oss gjøre det. La oss tenke.

00:12:31.260 --> 00:12:34.260
Faktisk, la oss starte akkurat nå.

00:12:34.260 --> 00:12:37.260
Alle personer i dette rommet gjør følgende:

00:12:37.260 --> 00:12:40.260
tenk på den siste gangen dere skulle ta en beslutning

00:12:40.260 --> 00:12:42.260
hvor dere var bekymret over å gjøre det riktige,

00:12:42.260 --> 00:12:44.260
hvor dere lurte på, "Hva burde jeg gjøre?"

00:12:44.260 --> 00:12:46.260
Ha det i tankene.

00:12:46.260 --> 00:12:48.260
Og nå reflekter rundt det

00:12:48.260 --> 00:12:51.260
og si, "Hvordan kom jeg frem til den beslutningen?

00:12:51.260 --> 00:12:54.260
Hva gjorde jeg? Fulgte jeg magefølelsen?

00:12:54.260 --> 00:12:56.260
Fikk jeg noen til å stemme om det? Eller tok jeg sjansen på rettssystemet?

00:12:56.260 --> 00:12:59.260
Eller nå har vi noen fler muligheter.

00:12:59.260 --> 00:13:01.260
"Vurderte jeg hva som hadde gitt den høyeste nytelsen

00:13:01.260 --> 00:13:03.260
som Mill hadde gjort?

00:13:03.260 --> 00:13:06.260
Eller som Kant, brukte jeg fornuftet for å finne ut hva som var grunnleggende riktig?"

00:13:06.260 --> 00:13:09.260
Tenk på det. Virkelig ha det i tankene. Dette er viktig.

00:13:09.260 --> 00:13:11.260
Det er så viktig

00:13:11.260 --> 00:13:13.260
at vi skal bruke 30 sekunder av verdifull TEDTalk-tid

00:13:13.260 --> 00:13:15.260
og ikke gjøre noe annet enn å tenke på det.

00:13:15.260 --> 00:13:17.260
Er dere klare? Nå.

00:13:33.260 --> 00:13:36.260
Stopp. Bra jobba.

00:13:36.260 --> 00:13:38.260
Hva dere nettopp gjorde,

00:13:38.260 --> 00:13:40.260
er det første trinnet mot å ta ansvar

00:13:40.260 --> 00:13:43.260
for hva vi burde gjøre med all vår makt.

00:13:45.260 --> 00:13:48.260
Nå til neste trinn -- prøv dette.

00:13:49.260 --> 00:13:51.260
Let opp en venn og forklar for dem

00:13:51.260 --> 00:13:53.260
hvordan du tok den beslutningen.

00:13:53.260 --> 00:13:55.260
Ikke akkurat nå. Vent til jeg har snakket ferdig.

00:13:55.260 --> 00:13:57.260
Gjør det i lunsjen.

00:13:57.260 --> 00:14:00.260
Og finn ikke bare en annen teknologvenn;

00:14:00.260 --> 00:14:02.260
finn noen som er annerledes enn du.

00:14:02.260 --> 00:14:04.260
Finn en artist eller en forfatter --

00:14:04.260 --> 00:14:07.260
eller, Gud forby, finn en filosof og snakk med dem.

00:14:07.260 --> 00:14:09.260
Forresten, finn noen fra humaniora.

00:14:09.260 --> 00:14:11.260
Hvorfor? Fordi de tenker på problem

00:14:11.260 --> 00:14:13.260
annerledes enn vi gjør som teknologer.

00:14:13.260 --> 00:14:16.260
For bare et par dager siden, rett over gaten herfra,

00:14:16.260 --> 00:14:18.260
var det hundrevis av mennesker sammen.

00:14:18.260 --> 00:14:20.260
Det var teknologer og humanister

00:14:20.260 --> 00:14:22.260
på den der BiblioTech-konferansen.

00:14:22.260 --> 00:14:24.260
Og de samlet seg sammen

00:14:24.260 --> 00:14:26.260
fordi teknologene ville lære seg

00:14:26.260 --> 00:14:29.260
hvordan det ville være å tenke fra et humanistisk perspektiv.

00:14:29.260 --> 00:14:31.260
Du har noen fra Google

00:14:31.260 --> 00:14:33.260
som snakker med noen som gjør komparativ litteratur.

00:14:33.260 --> 00:14:36.260
Du tenker på relevansen av fransk teater fra 1600-tallet --

00:14:36.260 --> 00:14:38.260
hvordan innvirker det på risikokapital?

00:14:38.260 --> 00:14:41.260
Vel, det er interessant. Det er en annen måte å tenke på.

00:14:41.260 --> 00:14:43.260
Og når du tenker på den måten,

00:14:43.260 --> 00:14:46.260
blir du mer følsom for menneskelige hensyn,

00:14:46.260 --> 00:14:49.260
som er avgjørende for å ta etiske beslutninger.

00:14:49.260 --> 00:14:51.260
Så forestill deg akkurat nå

00:14:51.260 --> 00:14:53.260
du gikk og du fant en musikkvenn.

00:14:53.260 --> 00:14:56.260
Og du forteller ham hva vi snakker om,

00:14:56.260 --> 00:14:58.260
om hele vår datarevolusjon og alt dette --

00:14:58.260 --> 00:15:00.260
kanskje til og med nynner noen strofer fra vår temasang.

00:15:00.260 --> 00:15:03.260
♫ Dum ta da da dum dum ta da da dum ♫

00:15:03.260 --> 00:15:05.260
Vel, din musikkvenn vill stoppe deg og si,

00:15:05.260 --> 00:15:07.260
"Du vet, den temasangen

00:15:07.260 --> 00:15:09.260
for din datarevolusjon,

00:15:09.260 --> 00:15:11.260
det er en opera, det er Wagner.

00:15:11.260 --> 00:15:13.260
Den er basert på Norrøn legende.

00:15:13.260 --> 00:15:15.260
Det er guder og mytiske skapninger

00:15:15.260 --> 00:15:18.260
som sloss over magiske smykker."

00:15:19.260 --> 00:15:22.260
Det er interessant.

00:15:22.260 --> 00:15:25.260
Nå er det også en vakker opera.

00:15:25.260 --> 00:15:28.260
Og vi blir rørt av den operaen

00:15:28.260 --> 00:15:30.260
Vi blir rørt fordi det handler om kampen

00:15:30.260 --> 00:15:32.260
mellom godt og ondt,

00:15:32.260 --> 00:15:34.260
om rett og galt.

00:15:34.260 --> 00:15:36.260
Og vi bryr oss om rett og galt.

00:15:36.260 --> 00:15:39.260
Vi bryr oss om hva som skjer i den operaen.

00:15:39.260 --> 00:15:42.260
Vi bryr oss om hva som skjer i "Apocalypse Now."

00:15:42.260 --> 00:15:44.260
Og vi bryr oss virkelig om

00:15:44.260 --> 00:15:46.260
hva som skjer med vår teknologi.

00:15:46.260 --> 00:15:48.260
Vi har så mye makt i dag,

00:15:48.260 --> 00:15:51.260
at det er opp til oss å finne ut hva vi skal gjøre.

00:15:51.260 --> 00:15:53.260
Og det er de gode nyhetene.

00:15:53.260 --> 00:15:56.260
Vi er de som skriver den her operaen.

00:15:56.260 --> 00:15:58.260
Dette er vår film.

00:15:58.260 --> 00:16:01.260
Vi finner ut hva som skal skje med denne teknologien.

00:16:01.260 --> 00:16:04.260
Vi bestemmer hvordan dette vil ende.

00:16:04.260 --> 00:16:06.260
Tusen takk.

00:16:06.260 --> 00:16:11.260
(Applaus)

