WEBVTT
Kind: captions
Language: tr

00:00:00.000 --> 00:00:07.000
Çeviri: Kutay Erbayat
Gözden geçirme: Çağrı Mert Bakırcı

00:00:15.260 --> 00:00:17.260
Güç

00:00:17.260 --> 00:00:19.260
Akla gelen kelime bu.

00:00:19.260 --> 00:00:21.260
Biz yeni teknoloji uzmanlarıyız.

00:00:21.260 --> 00:00:24.260
Çok fazla verimiz var, bu yüzden de çok fazla güce sahibiz.

00:00:24.260 --> 00:00:26.260
Peki, ne kadar gücümüz var?

00:00:26.260 --> 00:00:29.260
Bir filmden sahne, "Apocalypse Now (Kıyamet)" -- harika bir film.

00:00:29.260 --> 00:00:32.260
Kahramanımızı yani Kaptan Willard'ı Nung Nehri'nin ağzına götürmemiz gerek

00:00:32.260 --> 00:00:34.260
o da böylece Albay Kurtz'u takip edebilecek.

00:00:34.260 --> 00:00:36.260
Bunu yapmak için de, onu oraya uçurup iniş yaptıracağız.

00:00:36.260 --> 00:00:38.260
Ve sahne:

00:00:38.260 --> 00:00:41.260
gökyüzü onu oraya taşıyan helikopter filosuyla doludur.

00:00:41.260 --> 00:00:43.260
Ve arkada şu yüksek sesli, heyecanlı müzik çalar.

00:00:43.260 --> 00:00:45.260
Şu çılgınca parça.

00:00:45.260 --> 00:00:47.260
♫ Dum da ta da dum ♫

00:00:47.260 --> 00:00:49.260
♫ Dum da ta da dum ♫

00:00:49.260 --> 00:00:52.260
♫ Da ta da da ♫

00:00:52.260 --> 00:00:54.260
İşte bu büyük bir güç.

00:00:54.260 --> 00:00:56.260
Benim bu salonda hissettiğim türden güç.

00:00:56.260 --> 00:00:58.260
Bu, elimizdeki tüm o veriler sayesinde

00:00:58.260 --> 00:01:00.260
bizde olan türden bir güç.

00:01:00.260 --> 00:01:02.260
Bir örnek ele alalım.

00:01:02.260 --> 00:01:04.260
Sadece bir kişinin verileriyle

00:01:04.260 --> 00:01:07.260
ne yapabiliriz?

00:01:07.260 --> 00:01:09.260
Mesela şuradaki adamın

00:01:09.260 --> 00:01:11.260
verileriyle ne yapabiliriz?

00:01:11.260 --> 00:01:13.260
Finansal kayıtlarına bakabilirim.

00:01:13.260 --> 00:01:15.260
Faturalarını zamanında ödeyip ödemediğini söyleyebilirim.

00:01:15.260 --> 00:01:17.260
Borç vermeye uygun olup olmadığını öğrenebilirim.

00:01:17.260 --> 00:01:20.260
Tıbbi kayıtlarına bakıp, kalbinin sağlam olup olmadığını görebilir --

00:01:20.260 --> 00:01:23.260
böylece sigorta teklif etmeye uygun mu görebilirim.

00:01:23.260 --> 00:01:25.260
İnternet eğilimlerine bakabilirim.

00:01:25.260 --> 00:01:28.260
İnternet sayfama geldiğinde, aslında ne yapacağını önceden biliyorum.

00:01:28.260 --> 00:01:30.260
çünkü milyonlarca internet sayfasını ziyaret edişini gördüm

00:01:30.260 --> 00:01:32.260
Ve üzgünüm ama,

00:01:32.260 --> 00:01:34.260
tıpkı bir poker oyuncusu gibisin, bunu söylemek zorundayım.

00:01:34.260 --> 00:01:36.260
Veri analizleri ile ne yapacağını sana

00:01:36.260 --> 00:01:38.260
sen daha yapmadan söyleyebilirim.

00:01:38.260 --> 00:01:41.260
Nelerden hoşlandığını, kim olduğunu biliyorum.

00:01:41.260 --> 00:01:43.260
Hem de daha e-postana bakmadan önce bile

00:01:43.260 --> 00:01:45.260
ya da telefonuna.

00:01:45.260 --> 00:01:47.260
İşte bunlar elimizdeki verilerle

00:01:47.260 --> 00:01:50.260
yapabileceğimiz türden şeyler.

00:01:50.260 --> 00:01:53.260
Ama aslında neler yapabileceğimiz hakkında konuşmak için burada değilim.

00:01:56.260 --> 00:01:59.260
Neler yapmamız gerektiği hakkında konuşmak için buradayım.

00:02:00.260 --> 00:02:03.260
Yapılacak doğru şey ne?

00:02:04.260 --> 00:02:06.260
Şaşkın bakışlar görüyorum

00:02:06.260 --> 00:02:09.260
sanki, "Bize doğru olanın ne olduğunu neden soruyorsun?

00:02:09.260 --> 00:02:12.260
Bu zımbırtıyı biz sadece geliştiriyoruz. Onu başkaları kullanıyor.” dercesine

00:02:12.260 --> 00:02:15.260
Peki, öyle olsun.

00:02:15.260 --> 00:02:17.260
Ama bu beni geçmişe götürüyor.

00:02:17.260 --> 00:02:19.260
II. Dünya Savaşını düşünüyorum da --

00:02:19.260 --> 00:02:21.260
büyük teknoloji uzmanlarımızın bazıları,

00:02:21.260 --> 00:02:23.260
büyük fizikçilerimizin bazıları,

00:02:23.260 --> 00:02:25.260
nükleer fisyon ve füzyon üzerine çalışıyorlar --

00:02:25.260 --> 00:02:27.260
sadece nükleer şeyler üzerine.

00:02:27.260 --> 00:02:30.260
Ne üreteceklerini görmek için tüm bu fizikçileri Los Alamos'ta

00:02:30.260 --> 00:02:33.260
bir araya getiriyoruz.

00:02:33.260 --> 00:02:36.260
Teknolojiyi üreten insanlar

00:02:36.260 --> 00:02:39.260
teknolojiyle ne yapmamız gerektiğini düşünen insanlar olsun istiyoruz.

00:02:41.260 --> 00:02:44.260
Peki şu adamın verileriyle bizim ne yapmamız gerekiyor?

00:02:44.260 --> 00:02:47.260
Onları toplamalı, derlemeli miyiz,

00:02:47.260 --> 00:02:49.260
ki böylece onun internet deneyimini iyileştirebilelim?

00:02:49.260 --> 00:02:51.260
Böylece para kazanabilelim?

00:02:51.260 --> 00:02:53.260
Böylece eğer iyi biri değilse

00:02:53.260 --> 00:02:55.260
kendimizi koruyabilelim?

00:02:55.260 --> 00:02:58.260
Yoksa mahremiyetine saygı duymalı,

00:02:58.260 --> 00:03:01.260
itibarını korumalı ve onu rahat mı bırakmalıyız?

00:03:02.260 --> 00:03:05.260
Hangisi?

00:03:05.260 --> 00:03:07.260
Bunu nasıl anlayabiliriz?

00:03:07.260 --> 00:03:10.260
Ben biliyorum: Kitle kaynak. Bunu kitle kaynakla çözelim.

00:03:11.260 --> 00:03:14.260
Öyleyse biraz ısınmak üzere,

00:03:14.260 --> 00:03:16.260
kolay bir soru ile başlayalım --

00:03:16.260 --> 00:03:19.260
buradaki herkesin bir fikri olduğuna emin olduğum bir şeyle:

00:03:19.260 --> 00:03:21.260
iPhone’a karşı Android.

00:03:21.260 --> 00:03:24.260
Haydi el kaldırarak gösterelim – iPhone diyenler.

00:03:24.260 --> 00:03:26.260
A-ha

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
Bir grup zeki insan olarak bizim

00:03:31.260 --> 00:03:33.260
o kadar da güzel telefon budalası olmayacağımızı düşünebilirsiniz.

00:03:33.260 --> 00:03:35.260
(Gülüşmeler)

00:03:35.260 --> 00:03:37.260
Sıradaki soru,

00:03:37.260 --> 00:03:39.260
birazcık daha zor

00:03:39.260 --> 00:03:41.260
Oradaki adamın deneyimlerini iyileştirmek için

00:03:41.260 --> 00:03:43.260
ve eğer o iyi biri değilse kendimizi korumak için

00:03:43.260 --> 00:03:46.260
onun tüm verilerini toplamalı mıyız?

00:03:46.260 --> 00:03:48.260
Yoksa onu rahat mı bırakmalıyız?

00:03:48.260 --> 00:03:51.260
Verileri toplayalım diyenler.

00:03:53.260 --> 00:03:56.260
Rahat bırakalım.

00:03:56.260 --> 00:03:58.260
Güvendesiniz. Sorun yok.

00:03:58.260 --> 00:04:00.260
(Gülüşmeler)

00:04:00.260 --> 00:04:02.260
Tamam, son soru --

00:04:02.260 --> 00:04:04.260
daha zor bir soru --

00:04:04.260 --> 00:04:07.260
böyle durumları değerlendirmeye çalışırken

00:04:07.260 --> 00:04:10.260
sizce ne yapmalıyız,

00:04:10.260 --> 00:04:14.260
Kantçı deontolojik bir ahlak çerçevesi mi kullanmalıyız,

00:04:14.260 --> 00:04:17.260
yoksa Mill tarzı bir sonuççuluk mu kullanmalıyız?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
Pek fazla oy yok.

00:04:27.260 --> 00:04:30.260
(Gülüşmeler)

00:04:30.260 --> 00:04:33.260
Evet, bu endişe verici bir sonuç.

00:04:34.260 --> 00:04:38.260
Endişe verici, çünkü taşınabilir cihazlarımız hakkında,

00:04:38.260 --> 00:04:40.260
kararlarımızı yönlendirirken kullanmamız gereken

00:04:40.260 --> 00:04:42.260
ahlaki çerçeve hakkında olduğundan

00:04:42.260 --> 00:04:44.260
daha güçlü fikirlerimiz var.

00:04:44.260 --> 00:04:47.260
Elimizdeki tüm bu güç ile ne yapacağımızı,

00:04:47.260 --> 00:04:50.260
eğer bir ahlaki çerçevemiz yoksa nasıl bilebiliriz ki?

00:04:50.260 --> 00:04:53.260
Taşınabilir işletim sistemleri hakkında çok şey bilirken,

00:04:53.260 --> 00:04:56.260
aslında gerçek ihtiyacımız olan şey bir ahlaki işletim sistemi.

00:04:58.260 --> 00:05:00.260
Nedir ahlaki işletim sistemi?

00:05:00.260 --> 00:05:02.260
Doğru ve yanlışın ne olduğunu biliyoruz, değil mi?

00:05:02.260 --> 00:05:04.260
Doğru bir şey yaptığında kendini iyi hissedersin,

00:05:04.260 --> 00:05:06.260
Yanlış bir şey yaptığında kendini kötü hissedersin.

00:05:06.260 --> 00:05:09.260
Ebeveynlerimiz bize şunu öğretir: iyiyi yücelt, kötünün dersini ver.

00:05:09.260 --> 00:05:12.260
Ama neyin doğru neyin yanlış olduğunu nasıl anlayacağız?

00:05:12.260 --> 00:05:15.260
Günbegün kullandığımız tekniklerimiz var.

00:05:15.260 --> 00:05:18.260
Belki sadece kalbimizin sesini dinliyoruz.

00:05:18.260 --> 00:05:21.260
Belki oylama yapıyoruz – kitle kaynak kullanıyoruz

00:05:21.260 --> 00:05:23.260
Belki kumar oynuyoruz --

00:05:23.260 --> 00:05:26.260
Hukukçulara sorup, ne dediklerine bakıyoruz.

00:05:26.260 --> 00:05:28.260
Bir başka deyişle, ne yapmamız gerektiğini nasıl bulduğumuz,

00:05:28.260 --> 00:05:30.260
bir bakıma rastlantısal,

00:05:30.260 --> 00:05:33.260
bir bakıma da “ad hoc” (niyete mahsus)

00:05:33.260 --> 00:05:36.260
Ve belki de, daha güvenilir bir temelde olmak istiyorsak

00:05:36.260 --> 00:05:39.260
gerçekte istediğimiz, bizi orada yönlendirmede yardım edecek,

00:05:39.260 --> 00:05:42.260
ilk etapta bize neyin doğru neyin yanlış olduğunu söyleyecek,

00:05:42.260 --> 00:05:46.260
ve belli bir durumda ne yapacağımızı nasıl bileceğimize yardım edecek ahlaki bir çerçevedir.

00:05:46.260 --> 00:05:48.260
Öyleyse bir ahlaki çerçeve edinelim.

00:05:48.260 --> 00:05:51.260
Biz sayılarla yaşayan, çok sayıda kişiyiz.

00:05:51.260 --> 00:05:53.260
Ahlaki bir çerçeveye temel olacak şekilde,

00:05:53.260 --> 00:05:56.260
sayıları nasıl kullanabiliriz?

00:05:56.260 --> 00:05:59.260
Ben tam olarak bunu yapan birini tanıyorum,

00:05:59.260 --> 00:06:02.260
Parlak zekâlı bir adam --

00:06:02.260 --> 00:06:05.260
2.500 yıl önce öldü.

00:06:05.260 --> 00:06:07.260
Platon, evet doğru.

00:06:07.260 --> 00:06:09.260
Hatırladınız mı – hani şu eski filozof?

00:06:09.260 --> 00:06:12.260
O sırada derste uyuyordunuz.

00:06:12.260 --> 00:06:14.260
Ve Platon, bizim sahip olduğumuz aynı kaygılara çokça sahipti.

00:06:14.260 --> 00:06:16.260
Doğru ve yanlış hakkında meraklıydı.

00:06:16.260 --> 00:06:18.260
Neyin adil olduğunu bilmek istiyordu.

00:06:18.260 --> 00:06:20.260
Ama bu konuda tüm yaptığımızın bu konuda fikir alışverişi

00:06:20.260 --> 00:06:22.260
yapıyormuşuz gibi göründüğünden endişeliydi.

00:06:22.260 --> 00:06:25.260
Birine göre bir şey adilken, diğerine göre başka bir şey adil.

00:06:25.260 --> 00:06:27.260
Onun anlattığı da bunun anlattığı da bir bakıma ikna edici.

00:06:27.260 --> 00:06:29.260
Bir ileri bir geri gidiyorum bu şekilde, bir yere vardığım yok.

00:06:29.260 --> 00:06:32.260
Artık fikir istemiyorum, bilgi birikimi istiyorum.

00:06:32.260 --> 00:06:35.260
Adalet hakkındaki gerçeği bilmek istiyorum --

00:06:35.260 --> 00:06:38.260
tıpkı matematikte gerçekliklerimizin olduğu gibi.

00:06:38.260 --> 00:06:41.260
Matematikte tarafsız olguları bilebiliriz.

00:06:41.260 --> 00:06:43.260
Bir sayı al, herhangi bir sayı -- iki

00:06:43.260 --> 00:06:45.260
En sevdiğim sayıdır. Bayılırım bu sayıya.

00:06:45.260 --> 00:06:47.260
İki hakkında gerçekler vardır.

00:06:47.260 --> 00:06:49.260
Herhangi bir şeyden iki tanesine sahipseniz,

00:06:49.260 --> 00:06:51.260
buna iki tane daha eklediğinizde, dört elde edersiniz.

00:06:51.260 --> 00:06:53.260
Neden bahsettiğiniz fark etmez, her şey için doğrudur.

00:06:53.260 --> 00:06:55.260
Bu iki olma biçimi hakkında, bu soyut biçim hakkında

00:06:55.260 --> 00:06:57.260
tarafsız bir olgudur.

00:06:57.260 --> 00:06:59.260
Herhangi bir şeyden iki tanesine sahipsen – iki göz, iki kulak, burun delikleri

00:06:59.260 --> 00:07:01.260
sadece iki çıkıntı --

00:07:01.260 --> 00:07:04.260
tüm bunlar iki biçiminde yerini alır.

00:07:04.260 --> 00:07:08.260
İkinin sahip olduğu tüm gerçeklere ortak olur.

00:07:08.260 --> 00:07:10.260
Hepsinde sahip oldukları bir "ikilik" vardır.

00:07:10.260 --> 00:07:13.260
Ve dolayısıyla, bu bir kanaat meselesi değildir.

00:07:13.260 --> 00:07:15.260
Peki ya Platon, etiğin

00:07:15.260 --> 00:07:17.260
matematik gibi olduğunu düşünseydi?

00:07:17.260 --> 00:07:20.260
Ya adaletin saf bir biçimi varsa?

00:07:20.260 --> 00:07:22.260
Ya adalet hakkında gerçeklikler varsa,

00:07:22.260 --> 00:07:24.260
ve yalnızca dünyaya şöyle bir bakınarak

00:07:24.260 --> 00:07:26.260
nelerin bu gerçeğe ortak olup,

00:07:26.260 --> 00:07:29.260
bu adalet biçiminde yerini aldığını görebilseydik?

00:07:29.260 --> 00:07:32.260
Böylece gerçekte neyin adil olup neyin olmadığını bilebilirdik.

00:07:32.260 --> 00:07:34.260
Sadece kanaat veya sadece

00:07:34.260 --> 00:07:37.260
kalıplardan ibaret olmazdı.

00:07:37.260 --> 00:07:39.260
Bu çarpıcı bir görüş.

00:07:39.260 --> 00:07:42.260
Yani, bir düşünsenize. Ne kadar muazzam. Ne kadar hırslı.

00:07:42.260 --> 00:07:44.260
Tıpkı bizim kadar hırslı.

00:07:44.260 --> 00:07:46.260
Etiği çözmek istiyor.

00:07:46.260 --> 00:07:48.260
Tarafsız gerçeklikler istiyor.

00:07:48.260 --> 00:07:51.260
Eğer bu şekilde düşünüyorsanız,

00:07:51.260 --> 00:07:54.260
Platonist bir ahlaki çerçeveniz var demektir.

00:07:54.260 --> 00:07:56.260
Eğer böyle düşünmüyorsanız,

00:07:56.260 --> 00:07:58.260
öyleyse, batı felsefesinde pek çok fikir ortağınız var demektir,

00:07:58.260 --> 00:08:01.260
çünkü bu hatrı sayılır fikri – bilirsiniz, insanlar bunu eleştirdi.

00:08:01.260 --> 00:08:04.260
Aristo, bundan özellikle memnun kalmadı.

00:08:04.260 --> 00:08:07.260
O bunun kullanışsız olduğunu düşünüyordu.

00:08:07.260 --> 00:08:11.260
Aristo şöyle dedi, “Bizler herhangi bir konuda, ancak o konunun bize izin verdiği miktarda

00:08:11.260 --> 00:08:13.260
kesinlik arayabiliriz”

00:08:13.260 --> 00:08:16.260
Aristo etiğin matematiğe pek benzemediğini düşünüyordu.

00:08:16.260 --> 00:08:19.260
Etiğin, anlık bir karar verirken doğru yolu bulmak üzere, en iyi şekilde

00:08:19.260 --> 00:08:21.260
hüküm verme yetimizi kullanma meselesi

00:08:21.260 --> 00:08:23.260
olduğunu düşünüyordu.

00:08:23.260 --> 00:08:25.260
Eğer, Platon sizin adamınız değilse,

00:08:25.260 --> 00:08:27.260
yine de pes etmeyin.

00:08:27.260 --> 00:08:29.260
Belki, ahlaki çerçevemizde

00:08:29.260 --> 00:08:32.260
sayıları temel alarak kullanabileceğimiz başka bir yol vardır.

00:08:33.260 --> 00:08:35.260
Şuna ne dersiniz:

00:08:35.260 --> 00:08:38.260
Ya herhangi bir durumda hesaplamalar yapıp,

00:08:38.260 --> 00:08:40.260
seçeneklere bakıp,

00:08:40.260 --> 00:08:43.260
hangisinin daha iyi olduğunu ölçerek ne yapacağınızı bilebilirseniz?

00:08:43.260 --> 00:08:45.260
Bu tanıdık geliyor mu?

00:08:45.260 --> 00:08:48.260
İşte bu faydacı ahlak çerçevesi.

00:08:48.260 --> 00:08:50.260
John Stuart Mill bunun en büyük savunucusuydu --

00:08:50.260 --> 00:08:52.260
ayrıca iyi bir adamdı --

00:08:52.260 --> 00:08:54.260
ve sadece 200 yıl önce öldü.

00:08:54.260 --> 00:08:56.260
Dolayısıyla faydacılığın temeli --

00:08:56.260 --> 00:08:58.260
En azından aşina olduğunuza eminim.

00:08:58.260 --> 00:09:00.260
Başlarda Mill için el kaldırmış üç kişi için bunlar tanıdıktır.

00:09:00.260 --> 00:09:02.260
Ama işte bu şekilde çalışır.

00:09:02.260 --> 00:09:05.260
Ya ahlak kuralları, yani bir şeyin ahlaklı olmasını sağlayanlar,

00:09:05.260 --> 00:09:07.260
onların sadece hazzı çoğaltması ve acıyı azaltması

00:09:07.260 --> 00:09:09.260
ile ilgiliyse?

00:09:09.260 --> 00:09:12.260
Eyleme içkin bir şey.

00:09:12.260 --> 00:09:14.260
Soyut bir biçim ile olan ilişkisi gibi değil.

00:09:14.260 --> 00:09:16.260
Ortaya çıkan sonuçlarla ilgili bir şey.

00:09:16.260 --> 00:09:18.260
Sadece sonuçlara bakıyorsunuz

00:09:18.260 --> 00:09:20.260
ve eylemin iyi veya kötü olduğunu görüyorsunuz.

00:09:20.260 --> 00:09:22.260
Böylesi basit olurdu. Böylece ne yapacağımızı bilebiliriz.

00:09:22.260 --> 00:09:24.260
Bir örnek ele alalım.

00:09:24.260 --> 00:09:26.260
İyice ileri gittiğimi varsayalım

00:09:26.260 --> 00:09:28.260
diyorum ki, “Telefonunu alacağım”

00:09:28.260 --> 00:09:30.260
Zamansız çaldığı için değil ama,

00:09:30.260 --> 00:09:33.260
onu alacağım çünkü küçük bir hesaplama yaptım.

00:09:33.260 --> 00:09:36.260
Bu adamın şüpheli göründüğünü düşündüm.

00:09:36.260 --> 00:09:39.260
Ya Bin Ladin’in saklandığı yere küçük mesajlar gönderip duruyorsa --

00:09:39.260 --> 00:09:41.260
veya Bin Ladin’den sonra yerine geçen her kimse --

00:09:41.260 --> 00:09:44.260
ve bu adam aslında bir terörist, emir bekleyen bir saldırgan.

00:09:44.260 --> 00:09:47.260
Ben bunu ortaya çıkartacağım, ve bunu yaptığımda,

00:09:47.260 --> 00:09:50.260
sebep olabileceği muazzam boyuttaki zararı önlemiş olacağım.

00:09:50.260 --> 00:09:53.260
Hasar önleme konusunda çok büyük faydası var bunun.

00:09:53.260 --> 00:09:55.260
Ve sebep olacağı azıcık ıstırabı, kıyasladığımda --

00:09:55.260 --> 00:09:57.260
çünkü telefonuna bakıp aslında Farmville’de küçük bir problemi olduğunu

00:09:57.260 --> 00:10:00.260
gördüğümde bu biraz utanç verici olacak --

00:10:00.260 --> 00:10:03.260
bu benim telefona

00:10:03.260 --> 00:10:05.260
bakmamın değeri karşısında hiçbir şey olmayacak.

00:10:05.260 --> 00:10:07.260
Eğer bu şekilde düşünüyorsanız,

00:10:07.260 --> 00:10:10.260
bu faydacı bir seçimdir.

00:10:10.260 --> 00:10:13.260
Ama belki, bu şekilde de düşünmüyorsunuz.

00:10:13.260 --> 00:10:15.260
Belki de sizce, bu onun telefonu.

00:10:15.260 --> 00:10:17.260
Bu adamın telefonunu almamız yanlış bir şey,

00:10:17.260 --> 00:10:19.260
çünkü o bir birey,

00:10:19.260 --> 00:10:21.260
onun kişisel hakları ve bir itibarı var,

00:10:21.260 --> 00:10:23.260
ve biz bunlara öylece müdahale edemeyiz.

00:10:23.260 --> 00:10:25.260
Onun bir özyönetimi var.

00:10:25.260 --> 00:10:27.260
Hesaplamaların ne olduğu mühim değil.

00:10:27.260 --> 00:10:30.260
İçkin olarak yanlış olan şeyler vardır --

00:10:30.260 --> 00:10:32.260
mesela yalan söylemek yanlıştır,

00:10:32.260 --> 00:10:35.260
mesela masum çocuklara işkence etmek yanlıştır.

00:10:35.260 --> 00:10:38.260
Kant bu noktada çok iyidi,

00:10:38.260 --> 00:10:40.260
ve benim ifade edeceğimden biraz daha iyisini söyledi.

00:10:40.260 --> 00:10:42.260
O, davranışlarımızı yönlendirmemiz gereken kuralları belirlemek için

00:10:42.260 --> 00:10:45.260
idrakımızı kullanmamız gerektiğini söyledi.

00:10:45.260 --> 00:10:48.260
Sonrasında bu kuralları takip etmek bizim görevimiz.

00:10:48.260 --> 00:10:51.260
Bu hesaplanacak bir şey değil.

00:10:51.260 --> 00:10:53.260
Öyleyse şimdi duralım.

00:10:53.260 --> 00:10:56.260
Bu meselenin felsefi çalılıklarında dolaşmakta haklıyız.

00:10:56.260 --> 00:10:59.260
Ve bu binlerce yıldır sürüyor,

00:10:59.260 --> 00:11:01.260
çünkü bunlar zor sorular,

00:11:01.260 --> 00:11:03.260
ve benim yalnızca 15 dakikam var.

00:11:03.260 --> 00:11:05.260
Öyleyse sadede gelelim.

00:11:05.260 --> 00:11:09.260
Kararlarımızı nasıl vermeliyiz?

00:11:09.260 --> 00:11:12.260
Platon mu, Aristo mu, Kant mı, yoksa Mill mi?

00:11:12.260 --> 00:11:14.260
Ne yapmalıyız? Cevap ne?

00:11:14.260 --> 00:11:17.260
O adamın verilerini kullanıp kullanmama konusunda

00:11:17.260 --> 00:11:19.260
ne yapmamız gerektiğini belirlemek için,

00:11:19.260 --> 00:11:21.260
Her durumda kullanabileceğimiz türden formül ne?

00:11:21.260 --> 00:11:24.260
Nedir bunun formülü?

00:11:25.260 --> 00:11:27.260
Böyle bir formül yok.

00:11:29.260 --> 00:11:31.260
Basit bir cevap yok.

00:11:31.260 --> 00:11:34.260
Etik zordur.

00:11:34.260 --> 00:11:37.260
Etik düşünmeyi gerektirir.

00:11:38.260 --> 00:11:40.260
Ve bu tatsız bir durum.

00:11:40.260 --> 00:11:42.260
Biliyorum, kariyerimin çoğunu

00:11:42.260 --> 00:11:44.260
yapay zeka için kullandım,

00:11:44.260 --> 00:11:47.260
bizim için düşünme işinin bir kısmını yapabilecek, bize cevaplar verebilecek

00:11:47.260 --> 00:11:49.260
makineler üretmeye çalışmakta.

00:11:49.260 --> 00:11:51.260
Ama yapamıyorlar.

00:11:51.260 --> 00:11:53.260
Gidip insan düşüncesini alıp

00:11:53.260 --> 00:11:55.260
aynen bir makineye yerleştiremiyorsunuz.

00:11:55.260 --> 00:11:58.260
Bu işi yapması gereken bizleriz.

00:11:58.260 --> 00:12:01.260
Şükür ki biz makine değiliz ve biz bunu yapabiliyoruz.

00:12:01.260 --> 00:12:03.260
Sadece düşünmeyi becermekle kalmıyoruz,

00:12:03.260 --> 00:12:05.260
buna mecburuz.

00:12:05.260 --> 00:12:07.260
Hannah Arendt şöyle söylüyor,

00:12:07.260 --> 00:12:09.260
“Acı gerçek şu ki

00:12:09.260 --> 00:12:11.260
dünyadaki kötülüklerin çoğu

00:12:11.260 --> 00:12:13.260
kötü olmayı seçen kişiler

00:12:13.260 --> 00:12:15.260
tarafından yapılmıyor.

00:12:15.260 --> 00:12:18.260
Düşünmemekten kaynaklanıyor.”

00:12:18.260 --> 00:12:22.260
Bu, onun “kötülüğün bayağılığı” dediği şey.

00:12:22.260 --> 00:12:24.260
Ve buna verilecek karşılık,

00:12:24.260 --> 00:12:26.260
aklı başında her insan tarafından düşünme tatbikine

00:12:26.260 --> 00:12:29.260
gereksinim duymamız.

00:12:29.260 --> 00:12:31.260
Öyleyse yapalım. Haydi düşünelim.

00:12:31.260 --> 00:12:34.260
Gerçekten, şimdi başlayalım.

00:12:34.260 --> 00:12:37.260
Bu salondaki herkes şunu yapsın:

00:12:37.260 --> 00:12:40.260
karar vermenizi gerektiren son zamanı düşünün

00:12:40.260 --> 00:12:42.260
doğru olanı yapmak için kaygılandığınız,

00:12:42.260 --> 00:12:44.260
Ne yapmalıyım acaba?” diye merak ettiğiniz.

00:12:44.260 --> 00:12:46.260
Aklınıza getirin.

00:12:46.260 --> 00:12:48.260
Ve şimdi üzerine kafa yorun

00:12:48.260 --> 00:12:51.260
deyin ki, “Bu karara nasıl vardım?”

00:12:51.260 --> 00:12:54.260
Ne yaptım? Kalbimin sesini mi dinledim?

00:12:54.260 --> 00:12:56.260
Birilerinin kanaatine mi sundum? Bir hukukçuya mı danıştım?

00:12:56.260 --> 00:12:59.260
Veya artık birkaç tercihimiz daha var.

00:12:59.260 --> 00:13:01.260
“En çok hazzı verecek şeye göre mi değerlendirme yaptım,

00:13:01.260 --> 00:13:03.260
Mill’in yapacağı gibi?”

00:13:03.260 --> 00:13:06.260
Yoksa Kant gibi, içkin doğruyu bulmak için sağduyumu mu kullandım?

00:13:06.260 --> 00:13:09.260
Bunu bir düşünün. Gerçekten aklınızda canlandırın. Bu önemli.

00:13:09.260 --> 00:13:11.260
Bu öylesine önemli ki

00:13:11.260 --> 00:13:13.260
değerli TEDTalk zamanımızın 30 saniyesini buna harcayacağız

00:13:13.260 --> 00:13:15.260
hiçbir şey yapmayıp, sadece bunun hakkında düşüneceğiz.

00:13:15.260 --> 00:13:17.260
Hazır mısınız? Başla.

00:13:33.260 --> 00:13:36.260
Tamam dur. Güzel.

00:13:36.260 --> 00:13:38.260
Az önce yaptığınız,

00:13:38.260 --> 00:13:40.260
gücümüzle ne yapmamız gerektiği konusunda

00:13:40.260 --> 00:13:43.260
sorumluluk alma yolunda ilk adımdı.

00:13:45.260 --> 00:13:48.260
Şimdi bir sonraki adım – şunu deneyin.

00:13:49.260 --> 00:13:51.260
Gidip bir arkadaşınızı bulun ve ona

00:13:51.260 --> 00:13:53.260
bu kararı nasıl aldığınızı anlatın.

00:13:53.260 --> 00:13:55.260
Şimdi değil. Konuşmamızı bitirene kadar bekleyin.

00:13:55.260 --> 00:13:57.260
Öğle yemeğinden sonra yapın.

00:13:57.260 --> 00:14:00.260
Ve gidip yine bir teknoloji uzmanı bulmayın;

00:14:00.260 --> 00:14:02.260
sizden farklı olan birini bulun.

00:14:02.260 --> 00:14:04.260
Bir sanatçı veya yazar bulun --

00:14:04.260 --> 00:14:07.260
veya tanrı göstermesin, bir felsefeci bulup onunla konuşun.

00:14:07.260 --> 00:14:09.260
Hakikaten, beşeri bilimlerden birini bulun.

00:14:09.260 --> 00:14:11.260
Niye? Çünkü onlar sorunlar hakkında

00:14:11.260 --> 00:14:13.260
biz teknoloji uzmanlarından farklı düşünür.

00:14:13.260 --> 00:14:16.260
Birkaç gün önce, buranın karşı sokağında,

00:14:16.260 --> 00:14:18.260
yüzlerce insan toplanmıştı.

00:14:18.260 --> 00:14:20.260
Teknoloji uzmanları ve hümanistler,

00:14:20.260 --> 00:14:22.260
şu büyük BiblioTech konferansındaydı.

00:14:22.260 --> 00:14:24.260
Bir araya geldiler

00:14:24.260 --> 00:14:26.260
çünkü teknoloji uzmanları, beşeri bilimler perspektifiyle

00:14:26.260 --> 00:14:29.260
düşünmenin nasıl bir şey olduğunu öğrenmek istiyordu.

00:14:29.260 --> 00:14:31.260
Google'da çalışan birini

00:14:31.260 --> 00:14:33.260
karşılaştırmalı edebiyat üzerine çalışan biri ile konuşurken buluyordunuz.

00:14:33.260 --> 00:14:36.260
Şimdi 17inci yüzyıl Fransız tiyatrosunu düşünüyorsunuz --

00:14:36.260 --> 00:14:38.260
bunun risk sermayesi ile nasıl bir ilgisi olabilir?

00:14:38.260 --> 00:14:41.260
Evet ilginç. Bu farklı bir düşünme şekli.

00:14:41.260 --> 00:14:43.260
Ve bu şekilde düşündüğünüzde,

00:14:43.260 --> 00:14:46.260
insani hususlara karşı daha duyarlı hale geliyorsunuz,

00:14:46.260 --> 00:14:49.260
ki bunlar etik kararlar alırken oldukça can alıcı.

00:14:49.260 --> 00:14:51.260
Öylese şimdi şunu hayal edin

00:14:51.260 --> 00:14:53.260
gittiniz ve müzisyen bir arkadaşınızı buldunuz.

00:14:53.260 --> 00:14:56.260
Ona hakkında konuştuğumuz şeyi anlatıyorsunuz,

00:14:56.260 --> 00:14:58.260
tüm bu veri devrimini ve tüm bunları --

00:14:58.260 --> 00:15:00.260
hatta belki şu parçamızdan birkaç ölçü mırıldanıyorsunuz.

00:15:00.260 --> 00:15:03.260
♫ Dum ta da da dum dum ta da da dum ♫

00:15:03.260 --> 00:15:05.260
Müzisyen arkadaşınız sizi durdurup şunu söyleyecek,

00:15:05.260 --> 00:15:07.260
“Hani şu müzik parçası var ya

00:15:07.260 --> 00:15:09.260
şu veri devrimi için,

00:15:09.260 --> 00:15:11.260
işte o bir opera, bir Wagner eseri.

00:15:11.260 --> 00:15:13.260
İskandinav efsaneleri üzerine.

00:15:13.260 --> 00:15:15.260
Tanrılar ve mitsel yaratıklar

00:15:15.260 --> 00:15:18.260
sihirli mücevherler için savaşıyorlar.”

00:15:19.260 --> 00:15:22.260
Bu enteresan.

00:15:22.260 --> 00:15:25.260
Ayrıca güzel de bir opera.

00:15:25.260 --> 00:15:28.260
Biz bu opera ile duygulanıyoruz.

00:15:28.260 --> 00:15:30.260
Duygulanıyoruz, çünkü bu opera iyi ile kötü arasında

00:15:30.260 --> 00:15:32.260
doğru ile yanlış arasında

00:15:32.260 --> 00:15:34.260
geçen bir savaş hakkında yazılmış.

00:15:34.260 --> 00:15:36.260
Ve biz doğru ile yanlışı önemsiyoruz.

00:15:36.260 --> 00:15:39.260
Biz o operada ne olduğunu önemsiyoruz.

00:15:39.260 --> 00:15:42.260
Biz “Kıyamet” filminde ne olduğunu önemsiyoruz.

00:15:42.260 --> 00:15:44.260
Ve biz kesinlikle teknolojimizle

00:15:44.260 --> 00:15:46.260
neler olduğunu önemsiyoruz.

00:15:46.260 --> 00:15:48.260
Bugün çok fazla gücümüz var,

00:15:48.260 --> 00:15:51.260
ne yapacağımızı belirlemek bizim elimizde.

00:15:51.260 --> 00:15:53.260
Ve işte iyi haber de bu.

00:15:53.260 --> 00:15:56.260
Burada bu operayı yazanlar bizleriz.

00:15:56.260 --> 00:15:58.260
Bu bizim filmimiz.

00:15:58.260 --> 00:16:01.260
Bu teknoloji ile neler olacağını biz belirliyoruz.

00:16:01.260 --> 00:16:04.260
Nasıl biteceğini biz belirliyoruz.

00:16:04.260 --> 00:16:06.260
Teşekkür ederim.

00:16:06.260 --> 00:16:11.260
(Alkışlar)

