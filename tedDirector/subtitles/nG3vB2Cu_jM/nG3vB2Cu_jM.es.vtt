WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Veronica Vera
Revisor: Sebastian Betti

00:00:15.260 --> 00:00:17.260
Poder.

00:00:17.260 --> 00:00:19.260
Esa es la palabra que viene a la mente.

00:00:19.260 --> 00:00:21.260
Somos los nuevos tecnólogos.

00:00:21.260 --> 00:00:24.260
Tenemos gran cantidad de información, así que tenemos mucho poder.

00:00:24.260 --> 00:00:26.260
¿Cuánto poder tenemos?

00:00:26.260 --> 00:00:29.260
Escena de la película: "Apocalipsis Now" -- excelente película.

00:00:29.260 --> 00:00:32.260
Tenemos que llevar a nuestro héroe, el capitán Willard, a la desembocadura del río Nung

00:00:32.260 --> 00:00:34.260
para que pueda perseguir al coronel Kurtz.

00:00:34.260 --> 00:00:36.260
Para esto, lo vamos a transportar volando y lo dejamos en el lugar.

00:00:36.260 --> 00:00:38.260
En esta escena

00:00:38.260 --> 00:00:41.260
el cielo está repleto de helicópteros que lo llevan.

00:00:41.260 --> 00:00:43.260
Hay de fondo una música fuerte y emocionante,

00:00:43.260 --> 00:00:45.260
una música desenfrenada.

00:00:45.260 --> 00:00:47.260
♫ Dum da ta da dum ♫

00:00:47.260 --> 00:00:49.260
♫ Dum da ta da dum ♫

00:00:49.260 --> 00:00:52.260
♫ Da ta da da ♫

00:00:52.260 --> 00:00:54.260
Hay mucha potencia.

00:00:54.260 --> 00:00:56.260
La clase de potencia que siento en esta sala.

00:00:56.260 --> 00:00:58.260
Es el poder que nos da

00:00:58.260 --> 00:01:00.260
toda la información que tenemos.

00:01:00.260 --> 00:01:02.260
Pongamos un ejemplo:

00:01:02.260 --> 00:01:04.260
¿Qué podemos hacer

00:01:04.260 --> 00:01:07.260
con la información de una sola persona?

00:01:07.260 --> 00:01:09.260
¿Qué podemos hacer

00:01:09.260 --> 00:01:11.260
con la información de ese señor?

00:01:11.260 --> 00:01:13.260
Puedo mirar sus registros financieros.

00:01:13.260 --> 00:01:15.260
Puedo decir si paga sus cuentas puntualmente.

00:01:15.260 --> 00:01:17.260
Sé si reúne las condiciones para que le den un préstamo.

00:01:17.260 --> 00:01:20.260
Puedo ver su historia clínica, puedo ver si aún late su corazón;

00:01:20.260 --> 00:01:23.260
ver si está bien para que le ofrezcan un seguro.

00:01:23.260 --> 00:01:25.260
Puedo observar sus hábitos en Internet.

00:01:25.260 --> 00:01:28.260
Cuando viene a mi sitio web, en realidad ya sé lo que va a hacer,

00:01:28.260 --> 00:01:30.260
porque lo he visto visitar millones de sitios web antes.

00:01:30.260 --> 00:01:32.260
Y lamento decirlo,

00:01:32.260 --> 00:01:34.260
eres como un jugador de póquer, tienes esa manía.

00:01:34.260 --> 00:01:36.260
Analizando datos puedo decir lo que vas a hacer

00:01:36.260 --> 00:01:38.260
aún antes que lo hagas.

00:01:38.260 --> 00:01:41.260
Sé lo que te gusta. Sé quién eres.

00:01:41.260 --> 00:01:43.260
Incluso antes de mirar tu correo

00:01:43.260 --> 00:01:45.260
o tu teléfono.

00:01:45.260 --> 00:01:47.260
Ese es el tipo de cosas que podemos hacer

00:01:47.260 --> 00:01:50.260
con los datos que tenemos.

00:01:50.260 --> 00:01:53.260
Pero en realidad no estoy aquí para hablar de lo que podemos hacer.

00:01:56.260 --> 00:01:59.260
Estoy aquí para hablar de lo que debemos hacer.

00:02:00.260 --> 00:02:03.260
¿Cuál es la acción correcta?

00:02:04.260 --> 00:02:06.260
Veo algunas miradas desconcertadas

00:02:06.260 --> 00:02:09.260
como diciendo, "¿Por qué nos preguntas qué es lo correcto?

00:02:09.260 --> 00:02:12.260
Nosotros hacemos. Son otros los que la usan".

00:02:12.260 --> 00:02:15.260
Es cierto.

00:02:15.260 --> 00:02:17.260
Pero esto me lleva al pasado.

00:02:17.260 --> 00:02:19.260
Pienso en la Segunda Guerra Mundial --

00:02:19.260 --> 00:02:21.260
algunos de nuestros grandes tecnólogos de entonces,

00:02:21.260 --> 00:02:23.260
algunos de los grandes físicos,

00:02:23.260 --> 00:02:25.260
estudiaban la fisión y la fusión nuclear --

00:02:25.260 --> 00:02:27.260
cuestiones nucleares.

00:02:27.260 --> 00:02:30.260
Reunimos a estos físicos en Los Álamos

00:02:30.260 --> 00:02:33.260
para ver que construían.

00:02:33.260 --> 00:02:36.260
Queremos que la gente que desarrolla tecnología

00:02:36.260 --> 00:02:39.260
piense qué deberíamos hacer nosotros con ella.

00:02:41.260 --> 00:02:44.260
Entonces, ¿qué deberíamos hacer con los datos de ese señor?

00:02:44.260 --> 00:02:47.260
¿Deberíamos recolectar, reunir los datos,

00:02:47.260 --> 00:02:49.260
para mejorar su experiencia en línea?

00:02:49.260 --> 00:02:51.260
¿Para ganar dinero?

00:02:51.260 --> 00:02:53.260
¿Para protegernos nosotros mismos

00:02:53.260 --> 00:02:55.260
si no se comporta bien?

00:02:55.260 --> 00:02:58.260
¿O deberíamos respetar su privacidad,

00:02:58.260 --> 00:03:01.260
proteger su dignidad y dejarlo en paz?

00:03:02.260 --> 00:03:05.260
¿Qué hacemos?

00:03:05.260 --> 00:03:07.260
¿Cómo debemos decidir?

00:03:07.260 --> 00:03:10.260
Ya sé: colaboración pública. Vamos a resolver esto juntos.

00:03:11.260 --> 00:03:14.260
Para entrar en calor,

00:03:14.260 --> 00:03:16.260
comencemos con una pregunta fácil --

00:03:16.260 --> 00:03:19.260
algo sobre lo que estoy seguro que todos aquí tienen una opinión:

00:03:19.260 --> 00:03:21.260
iPhone versus Android.

00:03:21.260 --> 00:03:24.260
Levanten las manos por el iPhone.

00:03:24.260 --> 00:03:26.260
Ajá.

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
Uno pensaría que un grupo de gente inteligente

00:03:31.260 --> 00:03:33.260
o sucumbiría tan fácil ante unos lindos teléfonos.

00:03:33.260 --> 00:03:35.260
(Risas)

00:03:35.260 --> 00:03:37.260
Siguiente pregunta,

00:03:37.260 --> 00:03:39.260
un poco más difícil.

00:03:39.260 --> 00:03:41.260
¿Deberíamos recolectar toda los datos de ese hombre

00:03:41.260 --> 00:03:43.260
para ofrecerle una mejor experiencia

00:03:43.260 --> 00:03:46.260
y para protegernos en caso de que trame algo malo?

00:03:46.260 --> 00:03:48.260
¿O deberíamos dejarlo en paz?

00:03:48.260 --> 00:03:51.260
Recolectar sus datos.

00:03:53.260 --> 00:03:56.260
Dejarlo en paz.

00:03:56.260 --> 00:03:58.260
Estás a salvo. Está bien.

00:03:58.260 --> 00:04:00.260
(Risas)

00:04:00.260 --> 00:04:02.260
Bien, última pregunta --

00:04:02.260 --> 00:04:04.260
más difícil --

00:04:04.260 --> 00:04:07.260
Al tratar de evaluar

00:04:07.260 --> 00:04:10.260
lo que deberíamos hacer en este caso,

00:04:10.260 --> 00:04:14.260
¿deberíamos usar un sistema moral deontológico kantiano,

00:04:14.260 --> 00:04:17.260
o un sistema consecuencionalista milliano?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
No hay tantos votos.

00:04:27.260 --> 00:04:30.260
(Risas)

00:04:30.260 --> 00:04:33.260
Sí, ese es un resultado aterrador.

00:04:34.260 --> 00:04:38.260
Es aterrador porque tenemos opiniones más firmes

00:04:38.260 --> 00:04:40.260
sobre nuestros aparatos portátiles

00:04:40.260 --> 00:04:42.260
que sobre el sistema moral

00:04:42.260 --> 00:04:44.260
que debería guiar nuestras decisiones.

00:04:44.260 --> 00:04:47.260
¿Cómo sabemos qué hacer con todo el poder que tenemos

00:04:47.260 --> 00:04:50.260
si no tenemos un sistema moral?

00:04:50.260 --> 00:04:53.260
Sabemos más sobre los sistemas operativos móviles,

00:04:53.260 --> 00:04:56.260
pero lo que realmente necesitamos es un sistema operativo moral.

00:04:58.260 --> 00:05:00.260
¿Qué es un sistema operativo moral?

00:05:00.260 --> 00:05:02.260
Todos sabemos lo que es correcto e incorrecto.

00:05:02.260 --> 00:05:04.260
Te sientes bien cuando haces algo correcto,

00:05:04.260 --> 00:05:06.260
te sientes mal cuando haces algo incorrecto.

00:05:06.260 --> 00:05:09.260
Nuestros padres nos enseñan que se alaba lo bueno y se regaña lo malo.

00:05:09.260 --> 00:05:12.260
Pero, ¿cómo podemos averiguar qué es lo correcto y lo incorrecto?

00:05:12.260 --> 00:05:15.260
Y, día a día, tenemos las técnicas que utilizamos.

00:05:15.260 --> 00:05:18.260
Tal vez solo seguimos nuestro instinto.

00:05:18.260 --> 00:05:21.260
Tal vez votamos --consultamos la opinión pública.

00:05:21.260 --> 00:05:23.260
O tal vez apostamos --

00:05:23.260 --> 00:05:26.260
preguntamos al departamento legal, vemos lo que dicen.

00:05:26.260 --> 00:05:28.260
En otras palabras, es un poco aleatorio,

00:05:28.260 --> 00:05:30.260
improvisamos,

00:05:30.260 --> 00:05:33.260
la forma de averiguar lo que debemos hacer.

00:05:33.260 --> 00:05:36.260
Y, tal vez, si queremos sentirnos más seguros,

00:05:36.260 --> 00:05:39.260
lo que realmente queremos es un sistema moral que nos oriente,

00:05:39.260 --> 00:05:42.260
que nos diga en primer lugar que tipo de cosas están bien y mal,

00:05:42.260 --> 00:05:46.260
y cómo sabemos qué hacer en una situación dada.

00:05:46.260 --> 00:05:48.260
Entonces tengamos un sistema moral.

00:05:48.260 --> 00:05:51.260
Somos seres que trabajamos con números, vivimos por los números.

00:05:51.260 --> 00:05:53.260
¿Cómo podemos usar los números

00:05:53.260 --> 00:05:56.260
como base para un sistema moral?

00:05:56.260 --> 00:05:59.260
Conozco a un hombre que hizo exactamente eso,

00:05:59.260 --> 00:06:02.260
Un hombre brillante --

00:06:02.260 --> 00:06:05.260
murió hace 2500 años.

00:06:05.260 --> 00:06:07.260
Platón, exacto.

00:06:07.260 --> 00:06:09.260
¿Lo recuerdan? ¿un viejo filósofo?

00:06:09.260 --> 00:06:12.260
Se durmieron durante esa clase.

00:06:12.260 --> 00:06:14.260
Y Platón se planteó muchas de estas preocupaciones que tenemos.

00:06:14.260 --> 00:06:16.260
Se preocupaba por lo correcto y lo incorrecto.

00:06:16.260 --> 00:06:18.260
Quería saber qué era lo justo.

00:06:18.260 --> 00:06:20.260
Pero le preocupaba que todo lo que parecíamos hacer

00:06:20.260 --> 00:06:22.260
era intercambiar opiniones sobre el tema.

00:06:22.260 --> 00:06:25.260
Él dice que algo es lo justo. Ella dice que otra cosa es lo justo.

00:06:25.260 --> 00:06:27.260
Ambos suenan convincentes.

00:06:27.260 --> 00:06:29.260
Vamos y volvemos sin llegar a ningún lado.

00:06:29.260 --> 00:06:32.260
No quiero opiniones, quiero conocimiento.

00:06:32.260 --> 00:06:35.260
Quiero saber la verdad sobre la justicia --

00:06:35.260 --> 00:06:38.260
tal como tenemos verdades en matemáticas.

00:06:38.260 --> 00:06:41.260
En matemáticas conocemos los hechos objetivos.

00:06:41.260 --> 00:06:43.260
Tomen un número, cualquier número -- el 2.

00:06:43.260 --> 00:06:45.260
Mi número favorito. Me encanta ese número.

00:06:45.260 --> 00:06:47.260
Hay verdades sobre el 2.

00:06:47.260 --> 00:06:49.260
Si tienen 2 de algo,

00:06:49.260 --> 00:06:51.260
y agregan 2 más, tienen 4.

00:06:51.260 --> 00:06:53.260
Eso es verdad sin importar qué estén hablando.

00:06:53.260 --> 00:06:55.260
Es una verdad objetiva sobre la forma del 2,

00:06:55.260 --> 00:06:57.260
la forma abstracta.

00:06:57.260 --> 00:06:59.260
Cuando se tiene 2 de cualquier cosa - 2 ojos, 2 oídos, 2 narices,

00:06:59.260 --> 00:07:01.260
2 protuberancias --

00:07:01.260 --> 00:07:04.260
todos ellos participan de la forma del 2.

00:07:04.260 --> 00:07:08.260
Todos participan de las verdades del 2.

00:07:08.260 --> 00:07:10.260
Todos tienen la dualidad.

00:07:10.260 --> 00:07:13.260
Y por lo tanto, no es una cuestión de opinión.

00:07:13.260 --> 00:07:15.260
Platón pensaba: ¿y si

00:07:15.260 --> 00:07:17.260
la ética fuese como la matemática?

00:07:17.260 --> 00:07:20.260
¿Y si hubiera una forma pura de justicia?

00:07:20.260 --> 00:07:22.260
¿Y si hay verdades acerca de la justicia,

00:07:22.260 --> 00:07:24.260
y si pudiéramos mirar el mundo

00:07:24.260 --> 00:07:26.260
y ver las cosas que la componen,

00:07:26.260 --> 00:07:29.260
que forman parte de la justicia?

00:07:29.260 --> 00:07:32.260
Entonces podría saberse lo que realmente es justo y lo que no.

00:07:32.260 --> 00:07:34.260
No sería una cuestión

00:07:34.260 --> 00:07:37.260
de simple opinión o apariencias.

00:07:37.260 --> 00:07:39.260
Esa es una visión asombrosa.

00:07:39.260 --> 00:07:42.260
Quiero decir, piénsenlo. Es magnífico y ambicioso.

00:07:42.260 --> 00:07:44.260
Tan ambicioso como nosotros.

00:07:44.260 --> 00:07:46.260
Él quiere resolver la ética.

00:07:46.260 --> 00:07:48.260
Quiere verdades objetivas.

00:07:48.260 --> 00:07:51.260
Si piensas de esa forma,

00:07:51.260 --> 00:07:54.260
tienes un sistema moral platónico.

00:07:54.260 --> 00:07:56.260
Si no piensas de esa forma,

00:07:56.260 --> 00:07:58.260
bien, tienes mucha compañía en la historia de la filosofía occidental,

00:07:58.260 --> 00:08:01.260
porque, ya saben, esta linda idea fue criticada.

00:08:01.260 --> 00:08:04.260
Aristóteles, en particular, no la compartía.

00:08:04.260 --> 00:08:07.260
Le resultaba poco práctico.

00:08:07.260 --> 00:08:11.260
Aristóteles dijo: "En cada asunto solo debemos buscar el nivel de precisión

00:08:11.260 --> 00:08:13.260
que ese asunto permite".

00:08:13.260 --> 00:08:16.260
Aristóteles pensaba que la ética no era como la matemática.

00:08:16.260 --> 00:08:19.260
Él pensaba que la ética es una cuestión de tomar decisiones aquí y ahora

00:08:19.260 --> 00:08:21.260
usando nuestro mejor juicio

00:08:21.260 --> 00:08:23.260
para encontrar el camino correcto.

00:08:23.260 --> 00:08:25.260
Si piensan eso, Platón no es la persona a seguir.

00:08:25.260 --> 00:08:27.260
Pero no se rindan.

00:08:27.260 --> 00:08:29.260
Tal vez hay otra manera

00:08:29.260 --> 00:08:32.260
de usar los números como base de nuestro sistema moral.

00:08:33.260 --> 00:08:35.260
¿Qué tal si

00:08:35.260 --> 00:08:38.260
ante cada situación simplemente pudieran calcular,

00:08:38.260 --> 00:08:40.260
mirar las opciones,

00:08:40.260 --> 00:08:43.260
medir cuál es mejor y saber qué hacer?

00:08:43.260 --> 00:08:45.260
¿Les suena familiar?

00:08:45.260 --> 00:08:48.260
Ese es un sistema moral utilitarista.

00:08:48.260 --> 00:08:50.260
John Stuart Mill fue un gran defensor de esto --

00:08:50.260 --> 00:08:52.260
además de un tipo genial --

00:08:52.260 --> 00:08:54.260
y murió hace solo 200 años.

00:08:54.260 --> 00:08:56.260
Así, la base del utilitarismo --

00:08:56.260 --> 00:08:58.260
Seguro que al menos están familiarizados.

00:08:58.260 --> 00:09:00.260
Las 3 personas que votaron por Mill antes están familiarizados con esto.

00:09:00.260 --> 00:09:02.260
Esto es así:

00:09:02.260 --> 00:09:05.260
¿Qué pasa si la moral, lo que hace que algo sea moral,

00:09:05.260 --> 00:09:07.260
es solo una cuestión de maximizar el placer

00:09:07.260 --> 00:09:09.260
y minimizar el dolor?

00:09:09.260 --> 00:09:12.260
Se trata de algo intrínseco al acto.

00:09:12.260 --> 00:09:14.260
No se trata de una relación con alguna forma abstracta.

00:09:14.260 --> 00:09:16.260
Es sólo una cuestión de consecuencias.

00:09:16.260 --> 00:09:18.260
Buscamos sólo en las consecuencias

00:09:18.260 --> 00:09:20.260
y vemos si en el todo, son positivas o negativas.

00:09:20.260 --> 00:09:22.260
Eso sería simple. Entonces sabríamos que hacer.

00:09:22.260 --> 00:09:24.260
Pongamos un ejemplo.

00:09:24.260 --> 00:09:26.260
Supongamos que voy

00:09:26.260 --> 00:09:28.260
y digo, "Voy a tomar tu teléfono".

00:09:28.260 --> 00:09:30.260
No sólo porque sonó antes,

00:09:30.260 --> 00:09:33.260
sino que lo voy a tomar porque hice un pequeño cálculo.

00:09:33.260 --> 00:09:36.260
Pensé, ese tipo parece sospechoso.

00:09:36.260 --> 00:09:39.260
Y qué tal si ha estado enviando mensajes a la guarida de Bin Laden --

00:09:39.260 --> 00:09:41.260
o quien haya reemplazado a Bin Laden -

00:09:41.260 --> 00:09:44.260
Y en realidad es un terrorista, una célula latente.

00:09:44.260 --> 00:09:47.260
Voy a averiguarlo, y cuando lo descubra,

00:09:47.260 --> 00:09:50.260
voy a evitar el enorme daño que podría causar.

00:09:50.260 --> 00:09:53.260
Eso va a ser muy útil para evitar ese daño.

00:09:53.260 --> 00:09:55.260
Y comparado con el pequeño dolor que va a causar --

00:09:55.260 --> 00:09:57.260
porque va a ser vergonzoso cuando vea su teléfono móvil

00:09:57.260 --> 00:10:00.260
y vea que tiene un problema con Farmville y todo lo demás -

00:10:00.260 --> 00:10:03.260
eso es minimizado

00:10:03.260 --> 00:10:05.260
por el valor de mirar su teléfono.

00:10:05.260 --> 00:10:07.260
Si consideran ese camino,

00:10:07.260 --> 00:10:10.260
esa es una opción utilitarista.

00:10:10.260 --> 00:10:13.260
Pero tal vez tampoco consideren esa opción.

00:10:13.260 --> 00:10:15.260
Tal vez piensen, es su teléfono.

00:10:15.260 --> 00:10:17.260
No está bien tomar su teléfono,

00:10:17.260 --> 00:10:19.260
porque él es una persona

00:10:19.260 --> 00:10:21.260
y tiene derechos y dignidad,

00:10:21.260 --> 00:10:23.260
y simplemente no podemos interferir en eso.

00:10:23.260 --> 00:10:25.260
Él tiene autonomía.

00:10:25.260 --> 00:10:27.260
No importa cuáles sean los cálculos.

00:10:27.260 --> 00:10:30.260
Hay cosas que intrínsecamente están mal --

00:10:30.260 --> 00:10:32.260
como mentir está mal.

00:10:32.260 --> 00:10:35.260
torturar a niños inocentes está mal.

00:10:35.260 --> 00:10:38.260
Kant era muy bueno en este punto,

00:10:38.260 --> 00:10:40.260
y planteaba esto un poco mejor de lo que yo lo haré.

00:10:40.260 --> 00:10:42.260
Decía que deberíamos usar nuestro razonamiento

00:10:42.260 --> 00:10:45.260
para decidir las reglas que deberían guiar nuestra conducta.

00:10:45.260 --> 00:10:48.260
Y luego es nuestro deber seguir esas reglas.

00:10:48.260 --> 00:10:51.260
No es una cuestión de cálculos.

00:10:51.260 --> 00:10:53.260
Así que detengámonos.

00:10:53.260 --> 00:10:56.260
Estamos justo en el centro de esta maraña filosófica.

00:10:56.260 --> 00:10:59.260
Esto continuó durante miles de años,

00:10:59.260 --> 00:11:01.260
porque son preguntas difíciles,

00:11:01.260 --> 00:11:03.260
y solo tengo 15 minutos.

00:11:03.260 --> 00:11:05.260
Por lo tanto, vamos directo al grano.

00:11:05.260 --> 00:11:09.260
¿Cómo debemos tomar nuestras decisiones?

00:11:09.260 --> 00:11:12.260
¿De acuerdo a Platón, a Aristóteles, a Kant, a Mill?

00:11:12.260 --> 00:11:14.260
¿Qué debemos hacer? ¿Cuál es la respuesta?

00:11:14.260 --> 00:11:17.260
¿Cuál es la fórmula que podemos usar en cualquier situación

00:11:17.260 --> 00:11:19.260
para determinar qué debemos hacer,

00:11:19.260 --> 00:11:21.260
sea que debamos o no usar la información de ese hombre?

00:11:21.260 --> 00:11:24.260
¿Cuál es la fórmula?

00:11:25.260 --> 00:11:27.260
No hay fórmula.

00:11:29.260 --> 00:11:31.260
No hay una respuesta simple.

00:11:31.260 --> 00:11:34.260
La ética es algo difícil.

00:11:34.260 --> 00:11:37.260
Requiere reflexión.

00:11:38.260 --> 00:11:40.260
Y eso es incómodo.

00:11:40.260 --> 00:11:42.260
Lo sé; pasé gran parte de mi carrera

00:11:42.260 --> 00:11:44.260
en inteligencia artificial,

00:11:44.260 --> 00:11:47.260
tratando de construir máquinas que pudiesen pensar algunas de estas cuestiones por nosotros,

00:11:47.260 --> 00:11:49.260
que pudiesen darnos respuestas.

00:11:49.260 --> 00:11:51.260
Pero ellas no pueden.

00:11:51.260 --> 00:11:53.260
No se puede tomar el pensamiento humano

00:11:53.260 --> 00:11:55.260
y ponerlo dentro de una máquina.

00:11:55.260 --> 00:11:58.260
Somos nosotros quienes debemos hacerlo.

00:11:58.260 --> 00:12:01.260
Felizmente, no somos máquinas y podemos hacerlo.

00:12:01.260 --> 00:12:03.260
Y no sólo podemos pensar,

00:12:03.260 --> 00:12:05.260
debemos hacerlo.

00:12:05.260 --> 00:12:07.260
Hannah Arendt dijo:

00:12:07.260 --> 00:12:09.260
"La triste verdad

00:12:09.260 --> 00:12:11.260
es que el mayor daño hecho en este mundo

00:12:11.260 --> 00:12:13.260
no lo causan las personas

00:12:13.260 --> 00:12:15.260
que eligen ser malas.

00:12:15.260 --> 00:12:18.260
Surge de la falta de pensamiento".

00:12:18.260 --> 00:12:22.260
Es lo que ella llamaba la "banalidad del mal".

00:12:22.260 --> 00:12:24.260
Y la respuesta a eso

00:12:24.260 --> 00:12:26.260
es que demandamos el ejercicio del pensamiento

00:12:26.260 --> 00:12:29.260
de cada persona sana.

00:12:29.260 --> 00:12:31.260
Así que hagámoslo. Pensemos.

00:12:31.260 --> 00:12:34.260
De hecho, empecemos ahora mismo.

00:12:34.260 --> 00:12:37.260
Cada persona de esta sala haga esto:

00:12:37.260 --> 00:12:40.260
piensen en la última vez que tuvieron que tomar una decisión

00:12:40.260 --> 00:12:42.260
donde estuvieron preocupados por hacer lo correcto,

00:12:42.260 --> 00:12:44.260
donde se preguntaron, "¿Qué debo hacer?"

00:12:44.260 --> 00:12:46.260
Recuerden ese momento.

00:12:46.260 --> 00:12:48.260
Y ahora reflexionen en eso

00:12:48.260 --> 00:12:51.260
y digan: "¿Cómo llegué a esa decisión?

00:12:51.260 --> 00:12:54.260
¿Qué hice? ¿Seguí mi intuición?

00:12:54.260 --> 00:12:56.260
¿Pedí la votación de alguien? ¿Pedí opinión legal?"

00:12:56.260 --> 00:12:59.260
O, ahora, tenemos algunas opciones más.

00:12:59.260 --> 00:13:01.260
"¿Evalué cuál sería el mayor de los placeres

00:13:01.260 --> 00:13:03.260
como lo haría Mill?

00:13:03.260 --> 00:13:06.260
O al igual que Kant, ¿usé la razón para decidir qué era intrínsecamente correcto?"

00:13:06.260 --> 00:13:09.260
Piensen en esto. Recuerden. Esto es importante.

00:13:09.260 --> 00:13:11.260
Es tan importante

00:13:11.260 --> 00:13:13.260
que vamos a usar 30 segundos del valioso tiempo de TED

00:13:13.260 --> 00:13:15.260
nada más que para pensar en esto.

00:13:15.260 --> 00:13:17.260
¿Están listos? Vamos.

00:13:33.260 --> 00:13:36.260
Paren. Buen trabajo.

00:13:36.260 --> 00:13:38.260
Lo que acaban de hacer,

00:13:38.260 --> 00:13:40.260
es el primer paso en el sentido de asumir responsabilidad

00:13:40.260 --> 00:13:43.260
por lo que debemos hacer con todo nuestro poder.

00:13:45.260 --> 00:13:48.260
Ahora el siguiente paso -- prueben esto.

00:13:49.260 --> 00:13:51.260
Busquen un amigo y explíquenle

00:13:51.260 --> 00:13:53.260
cómo tomaron esa decisión.

00:13:53.260 --> 00:13:55.260
Ahora no. Esperen el final de la charla.

00:13:55.260 --> 00:13:57.260
Durante el almuerzo.

00:13:57.260 --> 00:14:00.260
Y no lo hagan con otro amigo tecnólogo;

00:14:00.260 --> 00:14:02.260
encuentren alguien diferente a ustedes.

00:14:02.260 --> 00:14:04.260
Encuentren un artista o un escritor --

00:14:04.260 --> 00:14:07.260
o, Dios nos libre, encuentren un filósofo y hablen con ellos.

00:14:07.260 --> 00:14:09.260
De hecho, encuentren alguien de las humanidades.

00:14:09.260 --> 00:14:11.260
¿Por qué? Porque ellos piensan en los problemas

00:14:11.260 --> 00:14:13.260
de forma diferente a como lo hacemos los tecnólogos.

00:14:13.260 --> 00:14:16.260
Hace unos días, aquí en frente, al otro lado de la calle,

00:14:16.260 --> 00:14:18.260
había cientos de personas reunidas.

00:14:18.260 --> 00:14:20.260
Eran tecnólogos y humanistas

00:14:20.260 --> 00:14:22.260
en una conferencias sobre Bibliotecas Tecnológicas.

00:14:22.260 --> 00:14:24.260
Y ellos se reunieron

00:14:24.260 --> 00:14:26.260
porque los tecnólogos querían aprender

00:14:26.260 --> 00:14:29.260
cómo era pensar desde una perspectiva humanista.

00:14:29.260 --> 00:14:31.260
Hay alguien de Google

00:14:31.260 --> 00:14:33.260
hablando con alguien que hace literatura comparada.

00:14:33.260 --> 00:14:36.260
Están pensando sobre la relevancia del teatro francés del siglo XVII --

00:14:36.260 --> 00:14:38.260
¿cómo se relaciona eso con el capital de riesgo?

00:14:38.260 --> 00:14:41.260
Bien eso es interesante. Es una forma de pensar diferente.

00:14:41.260 --> 00:14:43.260
Y cuando piensan de esa forma,

00:14:43.260 --> 00:14:46.260
se vuelven más sensibles a las cuestionas humanas,

00:14:46.260 --> 00:14:49.260
lo cual es crucial para tomar decisiones éticas.

00:14:49.260 --> 00:14:51.260
Entonces, imaginen que ahora mismo

00:14:51.260 --> 00:14:53.260
van y encuentran a su amigo músico.

00:14:53.260 --> 00:14:56.260
Y le cuentan lo que estuvimos hablando,

00:14:56.260 --> 00:14:58.260
sobre la revolución de la información y todo eso --

00:14:58.260 --> 00:15:00.260
incluso tarareando algunas partes de nuestro tema:

00:15:00.260 --> 00:15:03.260
♫ Dum ta da da dum dum ta da da dum ♫

00:15:03.260 --> 00:15:05.260
Bueno, su amigo músico los detendrá y dirá:

00:15:05.260 --> 00:15:07.260
"Sabes, la música de fondo

00:15:07.260 --> 00:15:09.260
para tu revolución de la información,

00:15:09.260 --> 00:15:11.260
es una ópera, es Wagner.

00:15:11.260 --> 00:15:13.260
Se basa en la mitología nórdica.

00:15:13.260 --> 00:15:15.260
Son dioses y criaturas míticas

00:15:15.260 --> 00:15:18.260
luchando por joyas mágicas".

00:15:19.260 --> 00:15:22.260
Eso es interesante.

00:15:22.260 --> 00:15:25.260
También es una ópera hermosa.

00:15:25.260 --> 00:15:28.260
Y esa ópera nos emociona.

00:15:28.260 --> 00:15:30.260
Nos emociona porque es sobre la lucha

00:15:30.260 --> 00:15:32.260
entre el bien y el mal,

00:15:32.260 --> 00:15:34.260
sobre lo correcto y lo incorrecto.

00:15:34.260 --> 00:15:36.260
Y nos importa lo que lo correcto y lo incorrecto.

00:15:36.260 --> 00:15:39.260
Nos importa lo que pasa en la ópera.

00:15:39.260 --> 00:15:42.260
Nos importa lo que pasa en "Apocalipsis Now".

00:15:42.260 --> 00:15:44.260
Y sin duda que nos importa

00:15:44.260 --> 00:15:46.260
lo que pasa con nuestras tecnologías.

00:15:46.260 --> 00:15:48.260
Hoy tenemos mucho poder,

00:15:48.260 --> 00:15:51.260
depende de nosotros decidir qué hacer.

00:15:51.260 --> 00:15:53.260
Y esa es la buena noticia.

00:15:53.260 --> 00:15:56.260
Somos nosotros los que escribimos esta ópera.

00:15:56.260 --> 00:15:58.260
Es nuestra película.

00:15:58.260 --> 00:16:01.260
Nosotros decidimos lo que pasará con esta tecnología.

00:16:01.260 --> 00:16:04.260
Nosotros determinamos cómo terminará todo esto.

00:16:04.260 --> 00:16:06.260
Gracias.

00:16:06.260 --> 00:16:11.260
(Aplausos)

