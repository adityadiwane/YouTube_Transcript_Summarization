WEBVTT
Kind: captions
Language: ko

00:00:00.000 --> 00:00:07.000
번역: Jeong-Lan Kinser
검토: Jimin Lee

00:00:15.260 --> 00:00:17.260
권력

00:00:17.260 --> 00:00:19.260
그 말이 제 마음으로 들어서는군요.

00:00:19.260 --> 00:00:21.260
우리는 신세대 테크놀로지스트들입니다.

00:00:21.260 --> 00:00:24.260
우리에게는 많은 양의 데이터가 있어서, 우리에겐 많은 권력이 있지요.

00:00:24.260 --> 00:00:26.260
얼마나 많은 권력을 우리가 가지고 있나요?

00:00:26.260 --> 00:00:29.260
영화의 한장면: "아포칼립스 나우"--굉장한 영화지요.

00:00:29.260 --> 00:00:32.260
우리는 우리의 영웅, 윌라드 대장을, 넝 강(Nung River) 의 입구로 가서 체포해야 해요.

00:00:32.260 --> 00:00:34.260
그래서 그는 커츠 대령을 쫒을 수 있지요.

00:00:34.260 --> 00:00:36.260
우리가 이걸 하려는 방식은 그를 비행기로 태워다가 떨구어 놓는 겁니다.

00:00:36.260 --> 00:00:38.260
그래서 그 장면은:

00:00:38.260 --> 00:00:41.260
하늘은 그를 운반해 들여오는 이 헬리콥터의 무리로 가득차 있죠.

00:00:41.260 --> 00:00:43.260
또 거기에는 이 요란한, 스릴있는 음악이 배경에 깔려있습니다,

00:00:43.260 --> 00:00:45.260
이 야생적인 음악.

00:00:45.260 --> 00:00:47.260
♫덤 다 타 다 덤♫

00:00:47.260 --> 00:00:49.260
♫덤 다 타 다 덤♫

00:00:49.260 --> 00:00:52.260
♫다 타 다 다♫

00:00:52.260 --> 00:00:54.260
그것은 대단한 권력입니다.

00:00:54.260 --> 00:00:56.260
그건 제가 이 장소에서 느끼는 것과 같은 종류의 권력입니다.

00:00:56.260 --> 00:00:58.260
그건 우리가 가지고 있는 종류의 권력입니다

00:00:58.260 --> 00:01:00.260
왜냐하면 우리가 가지고 있는 데이터의 전부이기 때문이지요.

00:01:00.260 --> 00:01:02.260
예를 들어봅시다.

00:01:02.260 --> 00:01:04.260
우리가 뭘 할수 있을까요

00:01:04.260 --> 00:01:07.260
한사람의 데이터를 가지구요?

00:01:07.260 --> 00:01:09.260
우리가 뭘 할 수 있을까요

00:01:09.260 --> 00:01:11.260
저 남자의 데이터를 가지고 말이죠?

00:01:11.260 --> 00:01:13.260
저는 여러분의 재정 기록상황을 볼 수 있습니다.

00:01:13.260 --> 00:01:15.260
저는 여러분이 제때에 요금을 지불하는지 말할 수 있습니다.

00:01:15.260 --> 00:01:17.260
저는 여러분이 융자를 얻을만큼 신용이 있는지 알 수 있지요.

00:01:17.260 --> 00:01:20.260
저는 여러분의 의료 기록을 볼 수 있고, 여러분의 심장이 제대로 작동하는 지 볼 수 있지요--

00:01:20.260 --> 00:01:23.260
여러분이 보험을 제공받을 만큼 신용이 있는 지 볼 수 있고.

00:01:23.260 --> 00:01:25.260
여러분이 클릭하는 패턴을 볼 수 있습니다.

00:01:25.260 --> 00:01:28.260
여러분이 제 웹사이트로 갔을 때, 저는 실제로 여러분이 뭘 할 것인지를 알고 있습니다,

00:01:28.260 --> 00:01:30.260
왜냐하면 저는 여러분이 전에 그 웹사이트를 방문한 것을 보았기 때문이지요.

00:01:30.260 --> 00:01:32.260
그리고 저는 여러분에게 말하는것을 죄송하게 생각합니다,

00:01:32.260 --> 00:01:34.260
여러분이 포커 플레이어같아서, 할말이 있다는 것을요.

00:01:34.260 --> 00:01:36.260
저는 그 데이터 분석으로 여러분이 무엇을 할 것인지를 압니다

00:01:36.260 --> 00:01:38.260
여러분이 그것을 시작하기도 전에 말이죠.

00:01:38.260 --> 00:01:41.260
저는 여러분이 좋아하는것을 압니다. 저는 여러분이 누구인지를 압니다.

00:01:41.260 --> 00:01:43.260
그것은 심지어 제가 여러분의 메일이나

00:01:43.260 --> 00:01:45.260
여러분의 전화를 보기도 이전입니다.

00:01:45.260 --> 00:01:47.260
그런것들이 우리가 할 수 있는 종류의 것들입니다

00:01:47.260 --> 00:01:50.260
우리가 가진 데이터를 가지고 말이죠.

00:01:50.260 --> 00:01:53.260
하지만 저는 실제로 여기에서 우리가 할 수 있는것에 관해서 이야기하려고 온것이 아닙니다.

00:01:56.260 --> 00:01:59.260
저는 우리가 해야만 하는 것들에 대해서 말하려고 왔어요.

00:02:00.260 --> 00:02:03.260
무엇이 해야만 하는 정당한 것일까요?

00:02:04.260 --> 00:02:06.260
자 몇몇의 혼란해하는 표정이 보이는군요.

00:02:06.260 --> 00:02:09.260
"왜 당신이 우리에게 무엇이 해야만 하는 정당한 일인지를 묻는거야?

00:02:09.260 --> 00:02:12.260
우리는 이것을 만들고 있을 뿐이야. 다른 누군가가 그것을 이용하고 있어."

00:02:12.260 --> 00:02:15.260
충분히 정당하죠.

00:02:15.260 --> 00:02:17.260
하지만 그것은 저를 다시 되돌려 옵니다.

00:02:17.260 --> 00:02:19.260
저는 제 2차 세계대전에 대해 생각해 봅니다.

00:02:19.260 --> 00:02:21.260
그당시 우리의 대단한 테그놀로지스트들 몇명과,

00:02:21.260 --> 00:02:23.260
우리의 대단한 물리학자들 몇명이,

00:02:23.260 --> 00:02:25.260
핵 분열과 퓨전에 대해 공부하고 있었습니다--

00:02:25.260 --> 00:02:27.260
단지 핵의 물건일 뿐이었습니다.

00:02:27.260 --> 00:02:30.260
우리는 로스 알라모스에서 이 물리학자들과 함께 모였습니다

00:02:30.260 --> 00:02:33.260
그들이 지을 것이 무엇인지를 보려구요.

00:02:33.260 --> 00:02:36.260
우리는 사람들이 그 테크놀로지를 건축하는것을 바랍니다

00:02:36.260 --> 00:02:39.260
우리가 테크놀로지로 무엇을 해야만 할 것인지를 생각하면서 말이지요.

00:02:41.260 --> 00:02:44.260
자 저 남자의 데이터를 가지고 우리는 무엇을 해야만 할 까요?

00:02:44.260 --> 00:02:47.260
우리가 그걸 모으고, 집합시켜야 할까요,

00:02:47.260 --> 00:02:49.260
그래서 우리가 그의 온라인 경험을 더 낫게 하기 위해서?

00:02:49.260 --> 00:02:51.260
그래서 우리가 돈을 벌수 있도록?

00:02:51.260 --> 00:02:53.260
그래서 우리가 우리 자신을 보호할 수 있도록

00:02:53.260 --> 00:02:55.260
만약 그가 신용이 없어질 때까지?

00:02:55.260 --> 00:02:58.260
또는 우리가 그의 개인 정보를 존중해야 할까요,

00:02:58.260 --> 00:03:01.260
그의 존엄을 보호하고 그를 혼자서 내버려 두어야 할까요?

00:03:02.260 --> 00:03:05.260
어떤것이어야 할까요?

00:03:05.260 --> 00:03:07.260
우리가 어떻게 알아내야 할까요?

00:03:07.260 --> 00:03:10.260
저는 압니다: 크라우드 소스. 이것을 크라우드 소스시킵시다.

00:03:11.260 --> 00:03:14.260
그래서 사람들에게 준비를 시키기 위해서,

00:03:14.260 --> 00:03:16.260
쉬운 질문으로 시작합시다--

00:03:16.260 --> 00:03:19.260
제가 확신하기로 여기 있는 모든 사람들이 의견을 가지고 있는 무엇으로:

00:03:19.260 --> 00:03:21.260
아이폰 대 안드로이드.

00:03:21.260 --> 00:03:24.260
손을 보여봅시다--아이폰

00:03:24.260 --> 00:03:26.260
좋아요.

00:03:26.260 --> 00:03:29.260
안드로이드.

00:03:29.260 --> 00:03:31.260
여러분이 영리한 많은 사람들이 생각하기를

00:03:31.260 --> 00:03:33.260
"우리는 단지 예쁜 전화만을 원하는 바보는 안될거야." 라고 하시겠죠.

00:03:33.260 --> 00:03:35.260
(웃음)

00:03:35.260 --> 00:03:37.260
다음 질문,

00:03:37.260 --> 00:03:39.260
약간 더 어려운것.

00:03:39.260 --> 00:03:41.260
우리가 그 남자의 데이터를 모두 수집해서

00:03:41.260 --> 00:03:43.260
그의 경험의 질을 높이기 위해

00:03:43.260 --> 00:03:46.260
또 그가 신용이 없어질 경우에 우리를 지킬 수 있도록 해야 할까요?

00:03:46.260 --> 00:03:48.260
또는 그를 혼자 내버려 두어야 할까요?

00:03:48.260 --> 00:03:51.260
그의 데이터를 수집해라.

00:03:53.260 --> 00:03:56.260
그를 혼자 내버려 두어라.

00:03:56.260 --> 00:03:58.260
여러분은 안전합니다. 좋아요.

00:03:58.260 --> 00:04:00.260
(웃음)

00:04:00.260 --> 00:04:02.260
좋아요, 마지막 질문--

00:04:02.260 --> 00:04:04.260
어려운 질문--

00:04:04.260 --> 00:04:07.260
우리가 이 사례에서 무엇을 해야만 할 지

00:04:07.260 --> 00:04:10.260
평가하려는 노력을 할때,

00:04:10.260 --> 00:04:14.260
우리는 칸트방식의 의미론전 도덕 체계를 이용해야 할까요

00:04:14.260 --> 00:04:17.260
또는 우리가 밀방식의 결과론적인 것을 이용해야 할까요?

00:04:19.260 --> 00:04:22.260
칸트.

00:04:22.260 --> 00:04:25.260
밀.

00:04:25.260 --> 00:04:27.260
투표가 많이 없군요.

00:04:27.260 --> 00:04:30.260
(웃음)

00:04:30.260 --> 00:04:33.260
맞아요, 그건 끔찍한 결과입니다.

00:04:34.260 --> 00:04:38.260
끔찍합니다, 왜냐하면 우리는 우리가 우리의 결정을 하는데 도움을 주는

00:04:38.260 --> 00:04:40.260
도덕적인 체계에 대한 것보다

00:04:40.260 --> 00:04:42.260
우리의 소형기기 장치에 대해서

00:04:42.260 --> 00:04:44.260
보다 강한 의견을 가지고 있기 때문이죠

00:04:44.260 --> 00:04:47.260
만일 우리가 도덕적인 체계를 가지지 않았다면

00:04:47.260 --> 00:04:50.260
우리가 가진 모든 권력을 가지고 무엇을 해야할지 어떻게 알겠습니까?

00:04:50.260 --> 00:04:53.260
우리는 모빌 운영 시스템에 관해 보다 더 많이 알고 있지만,

00:04:53.260 --> 00:04:56.260
우리에게 정말 필요한 것은 도덕적인 운영 시스템입니다.

00:04:58.260 --> 00:05:00.260
무엇이 도덕적인 운영 시스템일까요?

00:05:00.260 --> 00:05:02.260
우리모두는 옳고 그름을 압니다, 맞지요?

00:05:02.260 --> 00:05:04.260
여러분이 뭔가 바른 일을 했을때 여러분은 기분이 좋음을 느낍니다,

00:05:04.260 --> 00:05:06.260
여러분이 뭔가 나쁜 일을 했을때 여러분은 기분이 좋지 않음을 느낍니다.

00:05:06.260 --> 00:05:09.260
우리의 부모들이 그걸 가르쳤지요; 좋은것은 칭찬하고, 나쁜것은 꾸짖어라.

00:05:09.260 --> 00:05:12.260
하지만 어떤것이 옳고 그른지 어떻게 알 수 있을까요?

00:05:12.260 --> 00:05:15.260
하지만 매일 매일, 우리에게는 우리가 이용하는 기술을 갖고 있습니다.

00:05:15.260 --> 00:05:18.260
우리는 어쩌면 우리의 본능을 그저 따라갑니다.

00:05:18.260 --> 00:05:21.260
우리는 어쩌면 투표를 합니다--우리는 크라우드 소스를 합니다.

00:05:21.260 --> 00:05:23.260
또는 어쩌면 우리는 펀트(손에서 떨어뜨린 공이 땅에 닿기 전에 차기)를 하겠죠--

00:05:23.260 --> 00:05:26.260
법률부서에 물어봐, 그들이 뭐라고 하는지 보자.

00:05:26.260 --> 00:05:28.260
달리 말하면, 그건 무작위적이죠,

00:05:28.260 --> 00:05:30.260
일종의 임시 응변적이죠,

00:05:30.260 --> 00:05:33.260
우리가 무엇을 해야할 지 알아내는것은요.

00:05:33.260 --> 00:05:36.260
그리고 어쩌면, 만약 우리가 보다 확실한 거점을 확보하고 싶다면,

00:05:36.260 --> 00:05:39.260
우리가 정말 원하는 것은 우리를 저 곳으로,

00:05:39.260 --> 00:05:42.260
우리에게 처음부터 어떤 것들이 옳고 그른것인지 알려주고

00:05:42.260 --> 00:05:46.260
우리가 주어진 상황에서 무엇을 할 지 우리가 어떻게 아는 장소로 데려갈 도덕적인 체계입니다.

00:05:46.260 --> 00:05:48.260
그러니 도덕적인 체계를 마련합시다.

00:05:48.260 --> 00:05:51.260
우리는 숫자에 따라 사는 숫자의 사람들입니다.

00:05:51.260 --> 00:05:53.260
도덕적인 체계를 위한 토대로서

00:05:53.260 --> 00:05:56.260
우리가 어떻게 숫자를 이용할까요?

00:05:56.260 --> 00:05:59.260
저는 바로 그렇게 한 남자를 알고 있습니다.

00:05:59.260 --> 00:06:02.260
굉장히 영리한 남자죠--

00:06:02.260 --> 00:06:05.260
그는 2,500 년전에 죽었습니다.

00:06:05.260 --> 00:06:07.260
플라토, 맞아요.

00:06:07.260 --> 00:06:09.260
그를 기억하시나요--늙은 철학자를?

00:06:09.260 --> 00:06:12.260
여러분은 그 수업에 잠을 자고 있었죠.

00:06:12.260 --> 00:06:14.260
자 플라토, 그는 우리가 가진것과 같은 근심을 많이 가지고 있었습니다.

00:06:14.260 --> 00:06:16.260
그는 옳고 그름에 관해 걱정을 했습니다.

00:06:16.260 --> 00:06:18.260
그는 무엇이 정의인지에 대해서 알고 싶어했지요.

00:06:18.260 --> 00:06:20.260
하지만 그는 우리 모두가 하고 있는것과 같은

00:06:20.260 --> 00:06:22.260
이것에 관한 의견을 교환하는것에 대해 걱정했습니다.

00:06:22.260 --> 00:06:25.260
"그는 무엇인가가 정의라고 말해. 그녀는 다른 어떤것이 정의라고 말해," 라고 하는 것을요.

00:06:25.260 --> 00:06:27.260
그가 말할때 그것은 신뢰할만 하고, 그녀가 말할때도 신뢰할만 하죠.

00:06:27.260 --> 00:06:29.260
저는 단지 왔다 갔다 할 뿐이죠; 어떤 곳에도 도달하지 않아요.

00:06:29.260 --> 00:06:32.260
저는 의견을 원하는 것이 아닙니다, 저는 지식을 원해요.

00:06:32.260 --> 00:06:35.260
저는 정의에 관한 진리를 알고 싶어요--

00:06:35.260 --> 00:06:38.260
우리가 수학에서 진리를 가지고 있는것처럼.

00:06:38.260 --> 00:06:41.260
수학에서, 우리는 객관적인 사실을 압니다.

00:06:41.260 --> 00:06:43.260
숫자를 택하세요, 임의의 숫자--2.

00:06:43.260 --> 00:06:45.260
가장 좋아하는 숫자. 저는 그 숫자를 사랑합니다.

00:06:45.260 --> 00:06:47.260
2에 관한 진실이 있어요.

00:06:47.260 --> 00:06:49.260
여러분이 두개의 뭔가를 가졌다며,

00:06:49.260 --> 00:06:51.260
두개를 더하면, 4를 얻게 됩니다.

00:06:51.260 --> 00:06:53.260
그건 여러분이 어떤것에 이야기 하는지 상관없이 사실입니다.

00:06:53.260 --> 00:06:55.260
그건 2의 추상적인 형태에 관한

00:06:55.260 --> 00:06:57.260
객관적인 진실입니다,

00:06:57.260 --> 00:06:59.260
여러분이 어떤것 2개를 가졌을때 --2개의 눈, 2개의 귀, 코에

00:06:59.260 --> 00:07:01.260
단지 2개의 돌출부--

00:07:01.260 --> 00:07:04.260
그것들은 모두 2개 형태에 한몫으로 낍니다.

00:07:04.260 --> 00:07:08.260
그들은 모두 2가 가지는 진실에 가담합니다.

00:07:08.260 --> 00:07:10.260
그들에게는 모두 2 형태를 가지고 있어요.

00:07:10.260 --> 00:07:13.260
그러므로, 그것은 의견의 문제가 아닙니다.

00:07:13.260 --> 00:07:15.260
만약 플라토가 생각하기를,

00:07:15.260 --> 00:07:17.260
윤리가 수학과 같은거라고 생각했다면 어떨까요?

00:07:17.260 --> 00:07:20.260
만약 정의에 순수한 형태가 존재한다면요?

00:07:20.260 --> 00:07:22.260
만약 정의에 관한 진실이 있고,

00:07:22.260 --> 00:07:24.260
여러분은 이 세상을 돌아보아

00:07:24.260 --> 00:07:26.260
어떤것들이 참여되어서,

00:07:26.260 --> 00:07:29.260
정의의 형태에 참가했다면은요?

00:07:29.260 --> 00:07:32.260
그러면 여러분은 무엇이 진실이고 무엇이 진실이 아니었는지 알 수 있을겁니다.

00:07:32.260 --> 00:07:34.260
단지 의견이나 단지 외양은

00:07:34.260 --> 00:07:37.260
문제가 되지 않을것입니다.

00:07:37.260 --> 00:07:39.260
그것은 굉장한 통찰력입니다.

00:07:39.260 --> 00:07:42.260
생각해 보세요. 얼마나 거대합니까. 얼마나 야심적인 것인가요.

00:07:42.260 --> 00:07:44.260
그건 우리가 야심찬 정도와 같지요.

00:07:44.260 --> 00:07:46.260
우리는 윤리학을 풀고 싶어합니다.

00:07:46.260 --> 00:07:48.260
그는 객관적인 진실을 바랍니다.

00:07:48.260 --> 00:07:51.260
만일 여러분이 그런 방식으로 생각한다면,

00:07:51.260 --> 00:07:54.260
여러분은 플라톤식의 윤리체계를 가지고 있습니다.

00:07:54.260 --> 00:07:56.260
만일 여러분이 그런식으로 생각하지 않는다면,

00:07:56.260 --> 00:07:58.260
글쎄요, 여러분은 서부 철학의 역사에서 많은 동료를 공유합니다,

00:07:58.260 --> 00:08:01.260
왜냐하면 그 정돈된 생각은--아시죠, 사람들이 그걸 비판합니다.

00:08:01.260 --> 00:08:04.260
특히, 아리스토텔레스는 그것을 즐겨하지 않았지요.

00:08:04.260 --> 00:08:07.260
그는 그게 비실용적이라고 생각했습니다.

00:08:07.260 --> 00:08:11.260
아리스토텔레스가 말하길, "우리는 각 주제에 그 주제가 허락하는

00:08:11.260 --> 00:08:13.260
그 정도만의 정확성을 추구해야만 합니다."

00:08:13.260 --> 00:08:16.260
아리스토텔레스는 윤리가 수학과 같지 않다고 생각했어요.

00:08:16.260 --> 00:08:19.260
그는 윤리가 즉결을 요구하는 의사결정의,

00:08:19.260 --> 00:08:21.260
바른 행로를 찾기위해

00:08:21.260 --> 00:08:23.260
우리의 가장 훌륭한 판단을 이용하는 문제라고 생각했어요.

00:08:23.260 --> 00:08:25.260
만약 여러분이 그렇게 생각했다면, 플라톤은 여러분의 사람이 아닙니다.

00:08:25.260 --> 00:08:27.260
하지만 포기하지는 마세요.

00:08:27.260 --> 00:08:29.260
어쩌면 다른 방법이 있을수도 있습니다.

00:08:29.260 --> 00:08:32.260
우리의 윤리 체계의 기반으로서 숫자를 이용하는 것입니다.

00:08:33.260 --> 00:08:35.260
이건 어떨까요:

00:08:35.260 --> 00:08:38.260
만약 여러분이 단지 계산할 수 있는 임의의 상황이 있다면,

00:08:38.260 --> 00:08:40.260
그 선택사항들을 보세요,

00:08:40.260 --> 00:08:43.260
어떤것이 더 나은지 또 무엇을 해야할 지 아는지를 측정하세요?

00:08:43.260 --> 00:08:45.260
그게 친숙하게 들리나요?

00:08:45.260 --> 00:08:48.260
그것은 공리주의 도덕 체계입니다.£

00:08:48.260 --> 00:08:50.260
존 스튜어트 밀이

00:08:50.260 --> 00:08:52.260
좋은 사람이었던고

00:08:52.260 --> 00:08:54.260
200년 전에 타계했던것 이외에도 이 공리주의의 굉장한 주창자였지요.

00:08:54.260 --> 00:08:56.260
그래서 공리주의의 기반은--

00:08:56.260 --> 00:08:58.260
적어도 여러분이 친숙할 거라고 확신합니다.

00:08:58.260 --> 00:09:00.260
이전에 밀을 위해 투표했던 세사람은 이 실용주의에 대해 친숙합니다.

00:09:00.260 --> 00:09:02.260
하지만 여기 그게 운영되는 방식이 있습니다.

00:09:02.260 --> 00:09:05.260
만약 윤리가, 만약 뭔가 도덕적인것을 만드는 무엇인가가

00:09:05.260 --> 00:09:07.260
쾌락을 극대화하고 고통을 극소화시키는 것에 대한

00:09:07.260 --> 00:09:09.260
문제라면 어떨까요?

00:09:09.260 --> 00:09:12.260
그건 그 행위에 본능적인 뭔가를 합니다.

00:09:12.260 --> 00:09:14.260
그건 추상적인 형태로의 관계와 같은 게 아닙니다.

00:09:14.260 --> 00:09:16.260
그건 단지 결과의 문제입니다.

00:09:16.260 --> 00:09:18.260
여러분은 단지 결과를 보고

00:09:18.260 --> 00:09:20.260
만약, 그게 선을 위한것인지 또는 악을 위한것인지를 전체적으로 보지요.

00:09:20.260 --> 00:09:22.260
그건 간단한 것일 겁니다. 그러면 우리는 무엇을 할 지 알지요.

00:09:22.260 --> 00:09:24.260
예를 들어봅시다.

00:09:24.260 --> 00:09:26.260
제가 올라가서 말하기를

00:09:26.260 --> 00:09:28.260
"나는 너의 전화를 압수하겠어," 라고 했다고 가정해 봅시다.

00:09:28.260 --> 00:09:30.260
그게 전에 울렸기 때문이 아니라,

00:09:30.260 --> 00:09:33.260
내가 작은 계산을 했기 때문에 그것을 가질거라고.

00:09:33.260 --> 00:09:36.260
저는, 저 남자가 수상하게 보인다고 생각했습니다.

00:09:36.260 --> 00:09:39.260
만일 그가 작은 메세지를 빈 라든의 은거장소로

00:09:39.260 --> 00:09:41.260
또는 빈 라든의 이후 세력을 물려받은 그 누구에게라도 보내왔고

00:09:41.260 --> 00:09:44.260
그는 실제로 테러리스트와 같은, 슬리퍼 핸드폰같다구요.

00:09:44.260 --> 00:09:47.260
저는 그것을 알아낼거고, 제가 그것을 알아냈을때는,

00:09:47.260 --> 00:09:50.260
그가 유발할 수도 있는 거대한 양의 손상을 방지할것입니다.

00:09:50.260 --> 00:09:53.260
그 손상을 방지하는 것은 굉장히 높은 실용성이 있습니다.

00:09:53.260 --> 00:09:55.260
그리고 그것은 그것이 유발할 작은 고통으로 비교됩니다.

00:09:55.260 --> 00:09:57.260
왜냐하면 제가 그의 전화기를 보면서

00:09:57.260 --> 00:10:00.260
그 전화기를 바라보며 압도적으로 전체가

00:10:00.260 --> 00:10:03.260
팜빌 (Farmville) 문제가 있다는 것을 보는것은

00:10:03.260 --> 00:10:05.260
창피하게 느껴질 것이기 때문입니다.

00:10:05.260 --> 00:10:07.260
만일 여러분이 그런식으로 느낀다면,

00:10:07.260 --> 00:10:10.260
그것은 실용주의자적인 선택입니다.

00:10:10.260 --> 00:10:13.260
하지만 여러분은 그런 방식으로 느끼지 않을지도 모릅니다.

00:10:13.260 --> 00:10:15.260
어쩌면은 여러분은, "그건 그의 전화야" 라고 생각할 지도 모릅니다.

00:10:15.260 --> 00:10:17.260
"그의 전화를 압수하는 것은 옳지않아,

00:10:17.260 --> 00:10:19.260
왜냐하면 그는 사람이고

00:10:19.260 --> 00:10:21.260
그에게는 권리가 있고 존엄성이 있고,

00:10:21.260 --> 00:10:23.260
우리는 그것을 그냥 그렇게 방해할 수는 없어.

00:10:23.260 --> 00:10:25.260
그는 자율성을 가졌어.

00:10:25.260 --> 00:10:27.260
계산이 어떤것인지는 문제가 되지않아.

00:10:27.260 --> 00:10:30.260
본능적으로 그른것들이 있습니다--

00:10:30.260 --> 00:10:32.260
거짓말이 그른것과 같이요.

00:10:32.260 --> 00:10:35.260
순진한 어린이들을 괴롭히는것이 그른것과 같이요.

00:10:35.260 --> 00:10:38.260
칸트는 이 요점에 관해 아주 탁월했고,

00:10:38.260 --> 00:10:40.260
그는 제가 말할 것보다 조금 더 잘 말했죠.

00:10:40.260 --> 00:10:42.260
그가 말하길 우리는 우리의 이성을 이용하여

00:10:42.260 --> 00:10:45.260
우리의 행실을 안내해야만하는 규칙들을 알아내야만 한다고 말했습니다.

00:10:45.260 --> 00:10:48.260
그리고 그 규칙들을 따르는 것은 우리의 의무라고요.

00:10:48.260 --> 00:10:51.260
그것은 계산의 문제가 아닙니다.

00:10:51.260 --> 00:10:53.260
그러니 멈추도록 합시다.

00:10:53.260 --> 00:10:56.260
우리는 그것의 밀집의 중심에 있습니다, 이것은 철학적인 착잡함이죠.

00:10:56.260 --> 00:10:59.260
이것은 수천년동안 지속됩니다,

00:10:59.260 --> 00:11:01.260
왜냐하면 이것들은 어려운 질문들이기 때문이고

00:11:01.260 --> 00:11:03.260
저는 단지 15분만을 가지고 있습니다.

00:11:03.260 --> 00:11:05.260
그러니 단도 직입적으로 말합시다.

00:11:05.260 --> 00:11:09.260
우리가 어떻게 우리의 의사결정을 해야만 할까요?

00:11:09.260 --> 00:11:12.260
플라토인가요, 아리스토텔레스인가요, 칸트인가요, 밀인가요?

00:11:12.260 --> 00:11:14.260
우리가 무엇을 해야만 할까요? 무엇이 대답인가요?

00:11:14.260 --> 00:11:17.260
우리가 그 남자의 데이타를 이용해야만 할 지 아닌지

00:11:17.260 --> 00:11:19.260
우리가 어떤 상황에나 이용할 수 있는

00:11:19.260 --> 00:11:21.260
우리가 무엇을 해야만 할 지를 결정하는 공식은 무엇일까요?

00:11:21.260 --> 00:11:24.260
그 공식은 무엇일까요?

00:11:25.260 --> 00:11:27.260
공식은 없습니다.

00:11:29.260 --> 00:11:31.260
단순한 대답이 있는것은 아닙니다.

00:11:31.260 --> 00:11:34.260
윤리학은 어렵습니다.

00:11:34.260 --> 00:11:37.260
윤리학은 생각을 요구합니다.

00:11:38.260 --> 00:11:40.260
그리고 그것은 편안하지 않지요.

00:11:40.260 --> 00:11:42.260
알아요; 저는 제 직업의 많은 부분을

00:11:42.260 --> 00:11:44.260
인공지능에 소비했습니다,

00:11:44.260 --> 00:11:47.260
우리릉 위해 이러한 생각을 조금할 수 있는,

00:11:47.260 --> 00:11:49.260
우리에게 대답을 줄 수 있는 기계를 설립하려고 시도하면서 말이죠.

00:11:49.260 --> 00:11:51.260
그러나 기계들은 할 수 없습니다.

00:11:51.260 --> 00:11:53.260
단지 인간의 생각을 택해서

00:11:53.260 --> 00:11:55.260
기계에 집어넣을 수는 없어요.

00:11:55.260 --> 00:11:58.260
그것을 해야만 하는 사람은 우리입니다.

00:11:58.260 --> 00:12:01.260
행복하게도, 우리는 기계가 아니어서 우리는 그것을 할 수 있지요.

00:12:01.260 --> 00:12:03.260
우리는 생각할 수 있을 뿐만이 아니라,

00:12:03.260 --> 00:12:05.260
우리는 생각해야만 합니다.

00:12:05.260 --> 00:12:07.260
하나 아렌드트가 말하길,

00:12:07.260 --> 00:12:09.260
"슬픈 진실은

00:12:09.260 --> 00:12:11.260
이 세상에 치루어진 악의 대부분은

00:12:11.260 --> 00:12:13.260
악인이 되기로 선택한 사람들에

00:12:13.260 --> 00:12:15.260
의해서 그렇게 된것이 아니다.

00:12:15.260 --> 00:12:18.260
악은 생각을 안하는 것으로부터 제기된다."

00:12:18.260 --> 00:12:22.260
그것이 그녀가 "악의 진부," 라고 부르는 것입니다.

00:12:22.260 --> 00:12:24.260
그리고 그에 대한 반응은

00:12:24.260 --> 00:12:26.260
우리가 모든 정신을 제대로 가진 사람에게서

00:12:26.260 --> 00:12:29.260
생각의 연습을 요구하는 것입니다.

00:12:29.260 --> 00:12:31.260
그러니 그렇게 하도록 합시다. 생각하도록 합시다.

00:12:31.260 --> 00:12:34.260
사실, 지금 그것을 바로 시작합시다.

00:12:34.260 --> 00:12:37.260
이 장소에 있는 모든사람이 이렇게 하세요:

00:12:37.260 --> 00:12:40.260
여러분이 맨 마직막으로 의사결정을 했어야 할때를 생각하세요

00:12:40.260 --> 00:12:42.260
바른일을 하는것에 대해 걱정했던것

00:12:42.260 --> 00:12:44.260
"내가 뭘해야만 하나?" 라고 의심쩍어 하던것

00:12:44.260 --> 00:12:46.260
그걸 마음속으로 데려오세요.

00:12:46.260 --> 00:12:48.260
이제 그걸 회상해서

00:12:48.260 --> 00:12:51.260
말하길, "어떻게 내가 그 결정에 도달했지?

00:12:51.260 --> 00:12:54.260
내가 뭘 했지? 내가 본능을 따랐나?

00:12:54.260 --> 00:12:56.260
그걸 가지고 사람들이 투표를 하게 했나? 또는 내가 법률 전문가에게 펀트를 했나?"

00:12:56.260 --> 00:12:59.260
또는 이제 우리는 몇가지 더 많은 선택사항들이 있습니다.

00:12:59.260 --> 00:13:01.260
"밀이 할것과 같이 가장 최상의 쾌락상태가

00:13:01.260 --> 00:13:03.260
되도록 평가했나?

00:13:03.260 --> 00:13:06.260
또는 칸트와 같이, 이성을 이용하여 본능적으로 무엇이 옳은지 알아내도록 했나?"

00:13:06.260 --> 00:13:09.260
그것에 대해 생각해 보세요. 그것을 정말로 마음속으로 들여오세요. 이것은 중요합니다.

00:13:09.260 --> 00:13:11.260
그것은 아주 중요합니다

00:13:11.260 --> 00:13:13.260
우리는 귀중한 TEDTalk 시간의 30초를

00:13:13.260 --> 00:13:15.260
이것에 관해서만 생각해 보는데 소비할 것입니다.

00:13:15.260 --> 00:13:17.260
준비 되셨나요? 하세요.

00:13:33.260 --> 00:13:36.260
멈추세요. 좋은 작업입니다.

00:13:36.260 --> 00:13:38.260
여러분이 방금하신것은,

00:13:38.260 --> 00:13:40.260
우리가 가진 권력의 전부를 가지고 우리가 무엇을 해야할

00:13:40.260 --> 00:13:43.260
책임감을 취하는 방향으로 가는 첫번째의 단계입니다

00:13:45.260 --> 00:13:48.260
자 이제 다음 단계--이걸 시도해 보세요.

00:13:49.260 --> 00:13:51.260
친구하나를 찾아서 설명하세요

00:13:51.260 --> 00:13:53.260
여러분이 그 결정을 어떻게 내렸는지 말이죠.

00:13:53.260 --> 00:13:55.260
지금말구요. 제가 이야기를 끝낼때까지 기다리세요.

00:13:55.260 --> 00:13:57.260
점심시간동안 그것을 하세요.

00:13:57.260 --> 00:14:00.260
또 다른 테크놀로지스트 친구를 찾지 마시고;

00:14:00.260 --> 00:14:02.260
여러분과 다른 어떤 다른 사람을 찾으세요.

00:14:02.260 --> 00:14:04.260
예술가나 작가를 찾으세요--

00:14:04.260 --> 00:14:07.260
또는 천국이 금지한, 철학자를 찾아서 그에게 이야기 하세요.

00:14:07.260 --> 00:14:09.260
사실, 인문학에서의 사람을 찾으세요.

00:14:09.260 --> 00:14:11.260
왜냐구요? 왜냐하면 그들은 문제들에 관해서

00:14:11.260 --> 00:14:13.260
우리 테크놀로지스트들이 생각하는 것과는 다르게 생각하기 때문이죠.

00:14:13.260 --> 00:14:16.260
단지 몇일전에, 여기서 바로 맞은편 거리에,

00:14:16.260 --> 00:14:18.260
수백명의 사람들이 모여있었습니다.

00:14:18.260 --> 00:14:20.260
테크놀로지스트들과 인문학자들이

00:14:20.260 --> 00:14:22.260
거대한 비블리오 테크 컨퍼런스에서 있었지요.

00:14:22.260 --> 00:14:24.260
그들이 함께 모였습니다

00:14:24.260 --> 00:14:26.260
왜냐하면 그들은 인문학자적인 관점에서

00:14:26.260 --> 00:14:29.260
생각하는것은 어떤지를 배우고 싶어서였기 때문입니다.

00:14:29.260 --> 00:14:31.260
구글회사에서 일하는 어떤사람이

00:14:31.260 --> 00:14:33.260
비교 문학을 하는 누군가에게 이야기를 합니다.

00:14:33.260 --> 00:14:36.260
17세기의 불란서 연극과의 관련성에 대해 이야기 합니다.

00:14:36.260 --> 00:14:38.260
그것이 어떻게 벤처 캐피털에 이익을 산출할까요?

00:14:38.260 --> 00:14:41.260
글쎄 그게 재미있는것입니다. 그것은 다른 방식의 생각입니다.

00:14:41.260 --> 00:14:43.260
여러분이 그런 방식으로 생각할 때,

00:14:43.260 --> 00:14:46.260
여러분은 인간 고려점들에 대해 보다 민감하게 되지요.

00:14:46.260 --> 00:14:49.260
그건 윤리적인 의사결정을 하는데 필수적인 것입니다.

00:14:49.260 --> 00:14:51.260
그러니 바로 여기서 상상해 보세요.

00:14:51.260 --> 00:14:53.260
여러분이 가서 음악가 친구를 찾았습니다.

00:14:53.260 --> 00:14:56.260
우리가 여기서 이야기 하는것에 대해서 그에게 이야기 합니다.

00:14:56.260 --> 00:14:58.260
우리의 전체적인 데이터 혁명과 이러한 모든것에 관해서--

00:14:58.260 --> 00:15:00.260
어쩌면 우리 테마 음악의 몇소절을 허밍할 수 도 있죠.

00:15:00.260 --> 00:15:03.260
♫ 덤 타 다 다 덤 덤 타 다 다 덤 ♫

00:15:03.260 --> 00:15:05.260
글쎄요, 여러분의 음악가 친구는 여러분에게 멈추어서 말하길,

00:15:05.260 --> 00:15:07.260
"있잖아, 그 테마 음악은

00:15:07.260 --> 00:15:09.260
너의 데이터의 혁명을 위한 거야

00:15:09.260 --> 00:15:11.260
저건 오페라야, 저건 바그너야

00:15:11.260 --> 00:15:13.260
그건 고대 스칸디나비아의 전설에 근거한 거야.

00:15:13.260 --> 00:15:15.260
그건 신들과 신화적인 생명체들이

00:15:15.260 --> 00:15:18.260
마력의 보석을 놓고 싸우는것에 관한거야."

00:15:19.260 --> 00:15:22.260
그건 흥미롭습니다.

00:15:22.260 --> 00:15:25.260
자 그것은 또한 아름다운 오페라입니다.

00:15:25.260 --> 00:15:28.260
또 우리는 그 오페라에 의해서 감동을 받죠.

00:15:28.260 --> 00:15:30.260
우리는 감동을 받습니다 왜냐하면 그것은

00:15:30.260 --> 00:15:32.260
선과 악사이의 전쟁,

00:15:32.260 --> 00:15:34.260
옳고 그름에 관한 것이기 때문입니다.

00:15:34.260 --> 00:15:36.260
우리는 옳고 그름에 대해 우려합니다.

00:15:36.260 --> 00:15:39.260
우리는 그 오페라에서 무슨 일이 일어나는지 우려합니다.

00:15:39.260 --> 00:15:42.260
우리는 "아포칼립소 나우"에서 무슨일이 일어나는지 염려합니다.

00:15:42.260 --> 00:15:44.260
또 우리는 확실히 염려합니다.

00:15:44.260 --> 00:15:46.260
우리의 테크놀로지에 무슨일이 일어나느지를.

00:15:46.260 --> 00:15:48.260
우리는 오늘날 대단히 많은 권력을 가지고 있습니다,

00:15:48.260 --> 00:15:51.260
그것을 가지고 무엇을 할지 그것은 우리에게 달려있습니다.

00:15:51.260 --> 00:15:53.260
그것은 좋은 뉴스입니다.

00:15:53.260 --> 00:15:56.260
우리가 이 오페라를 쓰는 사람들입니다.

00:15:56.260 --> 00:15:58.260
이것은 우리의 영화입니다.

00:15:58.260 --> 00:16:01.260
우리는 이 테크놀로지에 무슨일이 일어날지 알아냅니다.

00:16:01.260 --> 00:16:04.260
이것이 어떻게 종결이 될지는 우리가 결정합니다.

00:16:04.260 --> 00:16:06.260
감사합니다.

00:16:06.260 --> 00:16:11.260
(박수)

