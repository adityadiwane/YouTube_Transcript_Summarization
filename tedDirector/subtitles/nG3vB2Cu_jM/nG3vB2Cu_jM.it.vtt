WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Laura 劳拉 Leotta
Revisore: Alice de Carli Enrico

00:00:15.260 --> 00:00:17.260
Potere.

00:00:17.260 --> 00:00:19.260
Questa è la parola che viene in mente.

00:00:19.260 --> 00:00:21.260
Noi siamo i nuovi tecnologi.

00:00:21.260 --> 00:00:24.260
Abbiamo molti dati, quindi abbiamo molto potere.

00:00:24.260 --> 00:00:26.260
Quanto potere abbiamo?

00:00:26.260 --> 00:00:29.260
Scena di un film: "Apocalypse Now" - gran bel film.

00:00:29.260 --> 00:00:32.260
Dobbiamo portare il nostro eroe, il Capitan Willard, alla foce del fiume Nung

00:00:32.260 --> 00:00:34.260
così che possa seguire le tracce del Colonnello Kurtz.

00:00:34.260 --> 00:00:36.260
Riusciremo a farlo trasportandolo in volo e facendolo scendere.

00:00:36.260 --> 00:00:38.260
Eccoci alla scena:

00:00:38.260 --> 00:00:41.260
il cielo è gremito dalla flotta di elicotteri incaricati di trasportarlo.

00:00:41.260 --> 00:00:43.260
C'è questa musica ad alto volume ed avvincente di sottofondo,

00:00:43.260 --> 00:00:45.260
questa musica selvaggia.

00:00:45.260 --> 00:00:47.260
♫ Dum da ta da dum ♫

00:00:47.260 --> 00:00:49.260
♫ Dum da ta da dum ♫

00:00:49.260 --> 00:00:52.260
♫ Da ta da da ♫

00:00:52.260 --> 00:00:54.260
Molto potente.

00:00:54.260 --> 00:00:56.260
Questo è il tipo di potenza che percepisco in questa sala.

00:00:56.260 --> 00:00:58.260
Questo è il tipo di potere che abbiamo

00:00:58.260 --> 00:01:00.260
grazie a tutti i dati di cui disponiamo.

00:01:00.260 --> 00:01:02.260
Facciamo un esempio.

00:01:02.260 --> 00:01:04.260
Cosa possiamo fare

00:01:04.260 --> 00:01:07.260
con i dati di una sola persona?

00:01:07.260 --> 00:01:09.260
Cosa possiamo fare

00:01:09.260 --> 00:01:11.260
con i dati di quel ragazzo?

00:01:11.260 --> 00:01:13.260
Posso guardare i tuoi estratti conto.

00:01:13.260 --> 00:01:15.260
Posso dirti se paghi le bollette in tempo.

00:01:15.260 --> 00:01:17.260
So se posso concederti un prestito.

00:01:17.260 --> 00:01:20.260
Posso dare un'occhiata ai tuoi referti medici, vedere se il tuo cuore batte ancora -

00:01:20.260 --> 00:01:23.260
vedere se è conveniente assicurarti.

00:01:23.260 --> 00:01:25.260
Posso vedere come visiti i siti Internet.

00:01:25.260 --> 00:01:28.260
Quando visiti il mio sito, so già esattamente cosa farai,

00:01:28.260 --> 00:01:30.260
perché ti ho visto visitare altri milioni di siti prima del mio.

00:01:30.260 --> 00:01:32.260
E mi dispiace dirtelo,

00:01:32.260 --> 00:01:34.260
sei come un giocatore di poker, lanci dei segnali.

00:01:34.260 --> 00:01:36.260
Grazie all'analisi dei dati posso predire cosa farai

00:01:36.260 --> 00:01:38.260
prima ancora che tu lo faccia.

00:01:38.260 --> 00:01:41.260
So cosa ti piace. So chi sei.

00:01:41.260 --> 00:01:43.260
E questo anche prima che io dia un'occhiata alla tua posta

00:01:43.260 --> 00:01:45.260
o al tuo telefono.

00:01:45.260 --> 00:01:47.260
Quelle sono le cose che siamo in grado di fare

00:01:47.260 --> 00:01:50.260
con i dati a nostra disposizione.

00:01:50.260 --> 00:01:53.260
Ma in realtà non sono qui per parlarvi di ciò che possiamo fare.

00:01:56.260 --> 00:01:59.260
Sono qui per parlarvi di ciò che dovremmo fare.

00:02:00.260 --> 00:02:03.260
Qual è la cosa giusta da fare?

00:02:04.260 --> 00:02:06.260
Ora vedo degli sguardi interrogativi

00:02:06.260 --> 00:02:09.260
tipo: "Perchè chiedi a noi quale sia la cosa giusta da fare?

00:02:09.260 --> 00:02:12.260
Noi mettiamo solo insieme questa roba. Qualcun altro la sta usando."

00:02:12.260 --> 00:02:15.260
Mi sembra giusto.

00:02:15.260 --> 00:02:17.260
Ma questo mi fa ricordare...

00:02:17.260 --> 00:02:19.260
Penso alla Seconda Guerra Mondiale -

00:02:19.260 --> 00:02:21.260
alcuni dei nostri più grandi tecnologi di allora,

00:02:21.260 --> 00:02:23.260
alcuni dei nostri più grandi fisici,

00:02:23.260 --> 00:02:25.260
che studiavano la fissione e fusione nucleare -

00:02:25.260 --> 00:02:27.260
solo roba nucleare.

00:02:27.260 --> 00:02:30.260
Noi riuniamo insieme questi fisici a Los Alamos

00:02:30.260 --> 00:02:33.260
per vedere cosa costruiranno.

00:02:33.260 --> 00:02:36.260
Vogliamo che le persone che creano la tecnologia

00:02:36.260 --> 00:02:39.260
pensino anche a come dovremmo utilizzarla.

00:02:41.260 --> 00:02:44.260
Per cui cosa dovremmo farci con i dati di quel ragazzo?

00:02:44.260 --> 00:02:47.260
Dovremmo raccoglierli, metterli insieme,

00:02:47.260 --> 00:02:49.260
così da migliorare il tempo che passa su Internet?

00:02:49.260 --> 00:02:51.260
Così poterci guadagnare?

00:02:51.260 --> 00:02:53.260
Così da poterci proteggere

00:02:53.260 --> 00:02:55.260
nel caso facesse qualcosa di male?

00:02:55.260 --> 00:02:58.260
O dovremmo rispettare la sua privacy,

00:02:58.260 --> 00:03:01.260
proteggere la sua dignità e lasciarlo in pace?

00:03:02.260 --> 00:03:05.260
Quale dovremmo scegliere?

00:03:05.260 --> 00:03:07.260
Come facciamo a deciderlo?

00:03:07.260 --> 00:03:10.260
Lo so: sentiamo il pubblico. Sentiamo il pubblico a riguardo.

00:03:11.260 --> 00:03:14.260
Perciò per mettervi a vostro agio,

00:03:14.260 --> 00:03:16.260
cominciamo con una domanda semplice -

00:03:16.260 --> 00:03:19.260
qualcosa su cui tutti qui hanno di certo un'opinione:

00:03:19.260 --> 00:03:21.260
iPhone oppure Android.

00:03:21.260 --> 00:03:24.260
Alzate le mani - iPhone.

00:03:24.260 --> 00:03:26.260
Uh uh.

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
Penserete che con delle persone intelligenti

00:03:31.260 --> 00:03:33.260
non ci faremmo trarre in inganno solo dai cellulari belli all'apparenza.

00:03:33.260 --> 00:03:35.260
(Risate)

00:03:35.260 --> 00:03:37.260
Ok, prossima domanda,

00:03:37.260 --> 00:03:39.260
un po' più difficile.

00:03:39.260 --> 00:03:41.260
Dovremmo raccogliere tutti i dati di quel ragazzo

00:03:41.260 --> 00:03:43.260
per migliorare il tempo che trascorre su Internet

00:03:43.260 --> 00:03:46.260
e proteggerci nel caso in cui avesse cattive intenzioni?

00:03:46.260 --> 00:03:48.260
O dovremmo lasciarlo in pace?

00:03:48.260 --> 00:03:51.260
Raccogliere i suoi dati.

00:03:53.260 --> 00:03:56.260
Lasciarlo in pace.

00:03:56.260 --> 00:03:58.260
Sei fuori pericolo. Va tutto bene.

00:03:58.260 --> 00:04:00.260
(Risate)

00:04:00.260 --> 00:04:02.260
Ok, ultima domanda -

00:04:02.260 --> 00:04:04.260
più difficile -

00:04:04.260 --> 00:04:07.260
quando proviamo a valutare

00:04:07.260 --> 00:04:10.260
cosa dovremmo fare in questo caso,

00:04:10.260 --> 00:04:14.260
dovremmo utilizzare una struttura morale ispirata alla deontologia kantiana,

00:04:14.260 --> 00:04:17.260
o dovremmo usarne una consequenzialistica milliana?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
Non altrettanti voti.

00:04:27.260 --> 00:04:30.260
(Risate)

00:04:30.260 --> 00:04:33.260
Sì, è un risultato spaventoso.

00:04:34.260 --> 00:04:38.260
Spaventoso perché abbiamo opinioni più chiare

00:04:38.260 --> 00:04:40.260
rispetto ai nostri cellulari

00:04:40.260 --> 00:04:42.260
che non per la struttura morale di riferimento

00:04:42.260 --> 00:04:44.260
che dovremmo utilizzare per guidare le nostre decisioni.

00:04:44.260 --> 00:04:47.260
Come possiamo sapere che farne di tutto il potere che abbiamo

00:04:47.260 --> 00:04:50.260
se non abbiamo una struttura morale?

00:04:50.260 --> 00:04:53.260
Ne sappiamo di più dei sistemi operativi dei cellulari,

00:04:53.260 --> 00:04:56.260
ma ciò che davvero ci occorre è un sistema operativo morale.

00:04:58.260 --> 00:05:00.260
Che cos'è un sistema operativo morale?

00:05:00.260 --> 00:05:02.260
Tutti sappiamo cosa è giusto e cosa è sbagliato, vero?

00:05:02.260 --> 00:05:04.260
Ci si sente bene quando si fa qualcosa di buono,

00:05:04.260 --> 00:05:06.260
ci si sente in colpa quando si fa qualcosa di sbagliato.

00:05:06.260 --> 00:05:09.260
I nostri genitori ci insegnano a: lodare il giusto, rimproverare l'errore.

00:05:09.260 --> 00:05:12.260
Ma come facciamo a distinguere tra giusto e sbagliato?

00:05:12.260 --> 00:05:15.260
Di giorno in giorno, abbiamo delle tecniche che utilizziamo.

00:05:15.260 --> 00:05:18.260
Forse usiamo semplicemente il nostro intuito.

00:05:18.260 --> 00:05:21.260
Forse la mettiamo ai voti - l'opinione della maggioranza.

00:05:21.260 --> 00:05:23.260
O forse ci affidiamo alla legge -

00:05:23.260 --> 00:05:26.260
chiediamo all'ufficio legale e vediamo che ne pensano.

00:05:26.260 --> 00:05:28.260
In altre parole, è un po' casuale,

00:05:28.260 --> 00:05:30.260
un po' improvvisato,

00:05:30.260 --> 00:05:33.260
il modo in cui decidiamo cosa sia meglio fare.

00:05:33.260 --> 00:05:36.260
E forse, se vogliamo avere basi per agire più solide,

00:05:36.260 --> 00:05:39.260
ciò che davvero vogliamo è una struttura morale che ci aiuti e ci indirizzi,

00:05:39.260 --> 00:05:42.260
che per prima cosa ci dica cosa è giusto e cosa è sbagliato,

00:05:42.260 --> 00:05:46.260
e come fare a sapere come comportarci in una determinata situazione.

00:05:46.260 --> 00:05:48.260
Allora troviamo una struttura morale di riferimento.

00:05:48.260 --> 00:05:51.260
Siamo persone che usano i numeri, che vivono con i numeri.

00:05:51.260 --> 00:05:53.260
Come possiamo usare i numeri

00:05:53.260 --> 00:05:56.260
come base per una struttura morale di riferimento?

00:05:56.260 --> 00:05:59.260
Conosco un ragazzo che ha fatto esattamente questo.

00:05:59.260 --> 00:06:02.260
Un ragazzo brillante -

00:06:02.260 --> 00:06:05.260
è morto da 2.500 anni.

00:06:05.260 --> 00:06:07.260
Platone, esatto.

00:06:07.260 --> 00:06:09.260
Ve lo ricordate - il vecchio filosofo?

00:06:09.260 --> 00:06:12.260
Stavate dormendo in quella lezione?

00:06:12.260 --> 00:06:14.260
Platone, anche lui si è interrogato su molte delle domande che ci siamo posti noi.

00:06:14.260 --> 00:06:16.260
Anche lui meditava su cosa è giusto e cosa è sbagliato.

00:06:16.260 --> 00:06:18.260
Voleva sapere cosa fosse giusto.

00:06:18.260 --> 00:06:20.260
Ma temeva che tutto ciò che facciamo

00:06:20.260 --> 00:06:22.260
non fosse altro che scambiarci opinioni a riguardo.

00:06:22.260 --> 00:06:25.260
Secondo lui questo è giusto. Secondo lei è giusta un'altra cosa.

00:06:25.260 --> 00:06:27.260
Lui è piuttosto convincente quando parla...

00:06:27.260 --> 00:06:29.260
..ma anche lei! Vado avanti e indietro; non sto andando da nessuna parte.

00:06:29.260 --> 00:06:32.260
Non voglio opinioni, voglio conoscenza.

00:06:32.260 --> 00:06:35.260
Voglio sapere la verità riguardo alla giustizia -

00:06:35.260 --> 00:06:38.260
come le verità che abbiamo in matematica.

00:06:38.260 --> 00:06:41.260
In matematica, abbiamo i fatti oggettivi.

00:06:41.260 --> 00:06:43.260
Prendete un numero, un numero qualsiasi - 2.

00:06:43.260 --> 00:06:45.260
Il mio numero preferito. Amo quel numero.

00:06:45.260 --> 00:06:47.260
Ci sono delle verità sul 2.

00:06:47.260 --> 00:06:49.260
Se avete 2 unità di qualcosa,

00:06:49.260 --> 00:06:51.260
e gliene aggiungete altre 2, ottenete 4.

00:06:51.260 --> 00:06:53.260
È vero a prescindere da qualsiasi sia l'ambito di discussione.

00:06:53.260 --> 00:06:55.260
È una verità oggettiva sulla forma del 2,

00:06:55.260 --> 00:06:57.260
la forma astratta.

00:06:57.260 --> 00:06:59.260
Quando avete 2 unità di qualsiasi cosa -- 2 occhi, 2 orecchie, 2 nasi,

00:06:59.260 --> 00:07:01.260
solo 2 protuberanze -

00:07:01.260 --> 00:07:04.260
tutte prendono parte alla forma del 2.

00:07:04.260 --> 00:07:08.260
Tutte condividono le verità che ha il 2.

00:07:08.260 --> 00:07:10.260
Hanno la du-alità in loro.

00:07:10.260 --> 00:07:13.260
E quindi, non si tratta di opinioni.

00:07:13.260 --> 00:07:15.260
Platone pensò: e se

00:07:15.260 --> 00:07:17.260
l'etica fosse come la matematica?

00:07:17.260 --> 00:07:20.260
E se ci fosse una forma pura di giustizia?

00:07:20.260 --> 00:07:22.260
E se ci fossero delle verità sulla giustizia,

00:07:22.260 --> 00:07:24.260
e ci si potesse semplicemente guardare attorno in questo mondo

00:07:24.260 --> 00:07:26.260
per vedere quali cose hanno preso parte a tali verità,

00:07:26.260 --> 00:07:29.260
hanno condiviso quella forma di giustizia?

00:07:29.260 --> 00:07:32.260
A quel punto si saprebbe cosa era realmente giusto e cosa non lo era.

00:07:32.260 --> 00:07:34.260
Non sarebbe un problema

00:07:34.260 --> 00:07:37.260
di opinioni o di impressioni su ciò che è giusto.

00:07:37.260 --> 00:07:39.260
È una visione che lascia di stucco.

00:07:39.260 --> 00:07:42.260
Voglio dire, pensateci. Quant'è grandioso, ambizioso.

00:07:42.260 --> 00:07:44.260
Tanto ambizioso quanto lo siamo noi.

00:07:44.260 --> 00:07:46.260
Vuole risolvere l'etica.

00:07:46.260 --> 00:07:48.260
Vuole verità oggettive.

00:07:48.260 --> 00:07:51.260
Se la pensate in quel modo,

00:07:51.260 --> 00:07:54.260
avete una struttura morale platonica.

00:07:54.260 --> 00:07:56.260
Se non la pensate in quel modo,

00:07:56.260 --> 00:07:58.260
beh, avete molta compagnia nella storia della filosofia occidentale,

00:07:58.260 --> 00:08:01.260
perché questa notevole idea - sapete, la gente l'ha criticata.

00:08:01.260 --> 00:08:04.260
Aristotele, in particolare, non ne era entusiasta.

00:08:04.260 --> 00:08:07.260
La riteneva poco pratica.

00:08:07.260 --> 00:08:11.260
Aristotele diceva, "Dovremmo richiedere in ciascun campo tanta precisione

00:08:11.260 --> 00:08:13.260
quanta ne permette la natura dell'oggetto".

00:08:13.260 --> 00:08:16.260
Aristotele pensava che l'etica non fosse come la matematica.

00:08:16.260 --> 00:08:19.260
Pensava che l'etica fosse più una questione legata al prendere decisioni al momento,

00:08:19.260 --> 00:08:21.260
usando il nostro giudizio

00:08:21.260 --> 00:08:23.260
per capire la giusta direzione da prendere.

00:08:23.260 --> 00:08:25.260
Se la pensate così, Platone non fa per voi.

00:08:25.260 --> 00:08:27.260
Ma non arrendetevi.

00:08:27.260 --> 00:08:29.260
Forse esiste un altro modo grazie a cui

00:08:29.260 --> 00:08:32.260
possiamo usare i numeri come base per il nostro sistema di riferimento morale.

00:08:33.260 --> 00:08:35.260
Cosa ne dite di questo:

00:08:35.260 --> 00:08:38.260
come sarebbe se in ogni situazione poteste semplicemente prevedere,

00:08:38.260 --> 00:08:40.260
vagliare le possibilità,

00:08:40.260 --> 00:08:43.260
giudicare quale sia la migliore e sapere cosa fare?

00:08:43.260 --> 00:08:45.260
Vi suona familiare?

00:08:45.260 --> 00:08:48.260
Questo è un sistema di riferimento utilitaristico.

00:08:48.260 --> 00:08:50.260
John Stuart Mill ne è stato un gran difensore -

00:08:50.260 --> 00:08:52.260
oltre ad essere un bravo ragazzo -

00:08:52.260 --> 00:08:54.260
ed è morto solo 200 anni fa.

00:08:54.260 --> 00:08:56.260
Almeno con le basi dell'utilitarismo

00:08:56.260 --> 00:08:58.260
sono sicuro che abbiate familiarità:

00:08:58.260 --> 00:09:00.260
le tre persone che prima hanno votato per Mill ne hanno familiarità.

00:09:00.260 --> 00:09:02.260
Ma ecco come funziona.

00:09:02.260 --> 00:09:05.260
Come sarebbe se la moralità, ciò che rende qualcosa morale,

00:09:05.260 --> 00:09:07.260
fosse solo una questione di massimizzazione del piacere

00:09:07.260 --> 00:09:09.260
e minimizzazione del dolore?

00:09:09.260 --> 00:09:12.260
È qualcosa di intrinseco all'azione.

00:09:12.260 --> 00:09:14.260
Non è come la relazione che intrattiene con qualche forma astratta.

00:09:14.260 --> 00:09:16.260
È solo una questione di conseguenze.

00:09:16.260 --> 00:09:18.260
Vagliate solo le conseguenze

00:09:18.260 --> 00:09:20.260
e giudicate se, in generale, propende per il meglio o il peggio.

00:09:20.260 --> 00:09:22.260
Sarebbe semplice. A quel punto sappiamo cosa fare.

00:09:22.260 --> 00:09:24.260
Facciamo un esempio.

00:09:24.260 --> 00:09:26.260
Supponiamo che io me ne esca

00:09:26.260 --> 00:09:28.260
dicendo "Prenderò il tuo telefono."

00:09:28.260 --> 00:09:30.260
Non perché prima abbia squillato,

00:09:30.260 --> 00:09:33.260
ma lo prenderò perché ho fatto qualche piccola previsione.

00:09:33.260 --> 00:09:36.260
Ho pensato: "quel ragazzo ha un'aria sospetta.

00:09:36.260 --> 00:09:39.260
E se avesse mandato dei messaggini al nascondiglio di Bin Landen? -

00:09:39.260 --> 00:09:41.260
o chiunque abbia preso il posto di Bin Landen -

00:09:41.260 --> 00:09:44.260
e fosse davvero un terrorista, una cellula dormiente?

00:09:44.260 --> 00:09:47.260
Lo scoprirò, e quando l'avrò scoperto,

00:09:47.260 --> 00:09:50.260
impedirò il danno enorme che potrebbe causare".

00:09:50.260 --> 00:09:53.260
È davvero un gran vantaggio prevenire quel danno.

00:09:53.260 --> 00:09:55.260
E a paragone del piccolo dolore che la mia azione causerà -

00:09:55.260 --> 00:09:57.260
perché sarà imbarazzante quando andrò a sbirciare sul suo cellulare

00:09:57.260 --> 00:10:00.260
e vedrò che ha solo un problema con Farmville e altre cose del genere -

00:10:00.260 --> 00:10:03.260
quest'imbarazzo sarà superato

00:10:03.260 --> 00:10:05.260
dal valore che avrà avuto l'aver controllato il suo cellulare.

00:10:05.260 --> 00:10:07.260
Se la pensate in questo modo

00:10:07.260 --> 00:10:10.260
avete fatto una scelta utilitaristica.

00:10:10.260 --> 00:10:13.260
Ma forse non la pensate neanche in quel modo.

00:10:13.260 --> 00:10:15.260
Forse pensate: "è il suo cellulare.

00:10:15.260 --> 00:10:17.260
È sbagliato prendere il suo cellulare,

00:10:17.260 --> 00:10:19.260
perché è una persona

00:10:19.260 --> 00:10:21.260
e come tale ha i suoi diritti e la sua dignità,

00:10:21.260 --> 00:10:23.260
e noi semplicemente non possiamo interferire.

00:10:23.260 --> 00:10:25.260
Ha la propria autonomia.

00:10:25.260 --> 00:10:27.260
Non importa quali siano le previsioni:

00:10:27.260 --> 00:10:30.260
ci sono cose intrinsecamente sbagliate -

00:10:30.260 --> 00:10:32.260
così com'è sbagliato mentire,

00:10:32.260 --> 00:10:35.260
così com'è sbagliato torturare bambini innocenti".

00:10:35.260 --> 00:10:38.260
Kant era molto ferrato su questo punto

00:10:38.260 --> 00:10:40.260
e si è espresso un po' meglio di quanto lo farò io.

00:10:40.260 --> 00:10:42.260
Lui diceva che dovremmo usare la ragione

00:10:42.260 --> 00:10:45.260
per capire le regole su cui basare il nostro comportamento.

00:10:45.260 --> 00:10:48.260
E a quel punto è nostro obbligo morale attenerci a quelle regole.

00:10:48.260 --> 00:10:51.260
Non è una questione di previsione.

00:10:51.260 --> 00:10:53.260
Fermiamoci un attimo.

00:10:53.260 --> 00:10:56.260
Siamo nel bel mezzo di questa coltre filosofica.

00:10:56.260 --> 00:10:59.260
E questo va avanti ormai da migliaia di anni,

00:10:59.260 --> 00:11:01.260
perché queste sono domande difficili,

00:11:01.260 --> 00:11:03.260
e io ho solo 15 minuti a disposizione.

00:11:03.260 --> 00:11:05.260
Andiamo dritti al dunque.

00:11:05.260 --> 00:11:09.260
In che modo dovremmo prendere le nostre decisioni?

00:11:09.260 --> 00:11:12.260
Dovremmo ragionare come Platone, Aristotele, Kant o Mill?

00:11:12.260 --> 00:11:14.260
Cosa dovremmo fare? Qual è la risposta?

00:11:14.260 --> 00:11:17.260
Qual è la formula che possiamo utilizzare in qualsiasi situazione

00:11:17.260 --> 00:11:19.260
per determinare cosa dovremmo fare,

00:11:19.260 --> 00:11:21.260
se è giusto utilizzare i dati di quel ragazzo o no?

00:11:21.260 --> 00:11:24.260
Qual è la formula?

00:11:25.260 --> 00:11:27.260
Non esiste una formula.

00:11:29.260 --> 00:11:31.260
Non esiste una risposta semplice.

00:11:31.260 --> 00:11:34.260
L'etica è difficile.

00:11:34.260 --> 00:11:37.260
L'etica richiede riflessione.

00:11:38.260 --> 00:11:40.260
E ciò crea disagio.

00:11:40.260 --> 00:11:42.260
Lo so: ho passato gran parte della mia carriera

00:11:42.260 --> 00:11:44.260
occupandomi di intelligenza artificiale,

00:11:44.260 --> 00:11:47.260
provando a costruire macchine in grado di fare un po' di queste riflessioni per noi,

00:11:47.260 --> 00:11:49.260
in grado di darci delle risposte.

00:11:49.260 --> 00:11:51.260
Ma non possono.

00:11:51.260 --> 00:11:53.260
Semplicemente non si può prendere il pensiero umano

00:11:53.260 --> 00:11:55.260
e metterlo in una macchina.

00:11:55.260 --> 00:11:58.260
Siamo noi che dobbiamo pensare.

00:11:58.260 --> 00:12:01.260
La buona notizia è che non siamo macchine e possiamo farlo.

00:12:01.260 --> 00:12:03.260
Non solo possiamo pensare,

00:12:03.260 --> 00:12:05.260
ma dobbiamo.

00:12:05.260 --> 00:12:07.260
Hannah Arendt diceva,

00:12:07.260 --> 00:12:09.260
"La triste verità

00:12:09.260 --> 00:12:11.260
è che la maggior parte del male in questo mondo

00:12:11.260 --> 00:12:13.260
non è causato da persone

00:12:13.260 --> 00:12:15.260
che vogliono essere deliberatamente cattive.

00:12:15.260 --> 00:12:18.260
Nasce dal non pensare affatto".

00:12:18.260 --> 00:12:22.260
Questo è ciò che lei ha chiamato "la banalità del male".

00:12:22.260 --> 00:12:24.260
E in risposta a ciò

00:12:24.260 --> 00:12:26.260
pretendiamo che qualsiasi persona sana

00:12:26.260 --> 00:12:29.260
sfrutti la propria capacità di riflettere.

00:12:29.260 --> 00:12:31.260
E allora facciamolo. Pensiamo.

00:12:31.260 --> 00:12:34.260
Anzi, iniziamo proprio adesso.

00:12:34.260 --> 00:12:37.260
Ognuno di voi qui presente faccia questo:

00:12:37.260 --> 00:12:40.260
pensate all'ultima volta che avete dovuto prendere una decisione

00:12:40.260 --> 00:12:42.260
per cui vi siete preoccupati di quale fosse la cosa giusta,

00:12:42.260 --> 00:12:44.260
e vi siete chiesti, "Cosa dovrei fare?"

00:12:44.260 --> 00:12:46.260
Fate riaffiorare questo ricordo.

00:12:46.260 --> 00:12:48.260
Adesso rifletteteci

00:12:48.260 --> 00:12:51.260
e rispondete, "Come sono giunto alla mia decisione?

00:12:51.260 --> 00:12:54.260
Cosa ho fatto? Ho seguito l'istinto?

00:12:54.260 --> 00:12:56.260
Ho fatto votare qualcuno? O mi sono attenuto alla legge?"

00:12:56.260 --> 00:12:59.260
Adesso abbiamo un po' più di scelta.

00:12:59.260 --> 00:13:01.260
"Ho valutato quale sarebbe stato il piacere maggiore

00:13:01.260 --> 00:13:03.260
come avrebbe fatto Mill?

00:13:03.260 --> 00:13:06.260
O come Kant, ho utilizzato la ragione per capire cosa fosse intrinsecamente giusto?"

00:13:06.260 --> 00:13:09.260
Pensateci. Davvero, fate uno sforzo di memoria. È importante.

00:13:09.260 --> 00:13:11.260
È così importante

00:13:11.260 --> 00:13:13.260
che perderemo ben 30 preziosi secondi del mio tempo qui a TEDTalk

00:13:13.260 --> 00:13:15.260
facendo nulla, se non pensare a questo.

00:13:15.260 --> 00:13:17.260
Siete pronti? Via.

00:13:33.260 --> 00:13:36.260
Stop. Ottimo lavoro.

00:13:36.260 --> 00:13:38.260
Quello che avete appena fatto

00:13:38.260 --> 00:13:40.260
è il primo passo verso l'assunzione di responsabilità

00:13:40.260 --> 00:13:43.260
per ciò che dovremmo fare con tutto il nostro potere.

00:13:45.260 --> 00:13:48.260
Ecco il prossimo passo - provate a far questo.

00:13:49.260 --> 00:13:51.260
Andate da un amico e spiegategli

00:13:51.260 --> 00:13:53.260
come avete preso la vostra decisione.

00:13:53.260 --> 00:13:55.260
Non adesso. Aspettate la fine di questo intervento.

00:13:55.260 --> 00:13:57.260
Fatelo a pranzo.

00:13:57.260 --> 00:14:00.260
E non andate a parlare con qualche altro amico tecnologo;

00:14:00.260 --> 00:14:02.260
trovate qualcuno diverso da voi.

00:14:02.260 --> 00:14:04.260
Cercate un arista o uno scrittore -

00:14:04.260 --> 00:14:07.260
oppure, Dio ce ne scampi, trovate un filosofo e parlategli.

00:14:07.260 --> 00:14:09.260
Insomma, trovate qualcuno del settore umanistico.

00:14:09.260 --> 00:14:11.260
Perché? Perché il loro approccio ai problemi

00:14:11.260 --> 00:14:13.260
è diverso rispetto a quello di noi tecnologi.

00:14:13.260 --> 00:14:16.260
Proprio qualche giorno fa, proprio qui davanti,

00:14:16.260 --> 00:14:18.260
c'erano centinaia di persone radunate.

00:14:18.260 --> 00:14:20.260
Erano tecnologi e umanisti

00:14:20.260 --> 00:14:22.260
che partecipavano alla grande conferenza BiblioTech.

00:14:22.260 --> 00:14:24.260
E si sono riuniti tutti insieme

00:14:24.260 --> 00:14:26.260
perché i tecnologi volevano capire

00:14:26.260 --> 00:14:29.260
come sarebbe stato pensare da un punto di vista umanistico.

00:14:29.260 --> 00:14:31.260
Qualcuno che lavorava per Google

00:14:31.260 --> 00:14:33.260
parlava con qualcuno che studiava letteratura comparata.

00:14:33.260 --> 00:14:36.260
Pensate alla rilevanza del teatro francese del 17esimo secolo -

00:14:36.260 --> 00:14:38.260
come influisce sul capitale di rischio?

00:14:38.260 --> 00:14:41.260
Beh, è interessante. È un modo diverso di pensare.

00:14:41.260 --> 00:14:43.260
E quando ragionate in quel modo,

00:14:43.260 --> 00:14:46.260
diventate più sensibili alle considerazioni umane,

00:14:46.260 --> 00:14:49.260
che sono indispensabili per prendere decisioni etiche.

00:14:49.260 --> 00:14:51.260
Immaginate che proprio questo momento

00:14:51.260 --> 00:14:53.260
voi uscite e trovate il vostro amico musicista.

00:14:53.260 --> 00:14:56.260
E mentre gli raccontate di cosa stiamo parlando,

00:14:56.260 --> 00:14:58.260
di tutta la nostra rivoluzione dei dati e via di seguito -

00:14:58.260 --> 00:15:00.260
potreste anche accennargli un paio di battute della nostra musica di sottofondo.

00:15:00.260 --> 00:15:03.260
♫ Dum ta da da dum dum ta da da dum ♫

00:15:03.260 --> 00:15:05.260
Beh, il vostro amico musicista vi interrompe e vi dice,

00:15:05.260 --> 00:15:07.260
"Sai, la musica

00:15:07.260 --> 00:15:09.260
per la vostra rivoluzione dei dati,

00:15:09.260 --> 00:15:11.260
è un'opera, è Wagner.

00:15:11.260 --> 00:15:13.260
È basata su una leggenda norrena.

00:15:13.260 --> 00:15:15.260
Parla di dei e creature mitiche

00:15:15.260 --> 00:15:18.260
che si battono per dei gioielli magici".

00:15:19.260 --> 00:15:22.260
Interessante.

00:15:22.260 --> 00:15:25.260
Adesso è anche una bella opera.

00:15:25.260 --> 00:15:28.260
E ci sentiamo commossi da quest'opera.

00:15:28.260 --> 00:15:30.260
Ci sentiamo commossi perché si tratta di una lotta

00:15:30.260 --> 00:15:32.260
tra il bene e il male,

00:15:32.260 --> 00:15:34.260
tra ciò che è giusto e ciò che è sbagliato.

00:15:34.260 --> 00:15:36.260
E a noi importa di ciò è giusto e ciò che è sbagliato.

00:15:36.260 --> 00:15:39.260
Ci importa di ciò che accade in quell'opera.

00:15:39.260 --> 00:15:42.260
Ci importa di ciò che accade in "Apocalypse Now".

00:15:42.260 --> 00:15:44.260
E sicuramente ci importa

00:15:44.260 --> 00:15:46.260
di ciò che accade con le tecnologie che usiamo.

00:15:46.260 --> 00:15:48.260
Abbiamo così tanto potere al giorno d'oggi,

00:15:48.260 --> 00:15:51.260
dipende esclusivamente da noi capire cosa farne.

00:15:51.260 --> 00:15:53.260
E qui arriva la buona notizia.

00:15:53.260 --> 00:15:56.260
Siamo noi a scrivere quest'opera.

00:15:56.260 --> 00:15:58.260
Questo è il nostro film.

00:15:58.260 --> 00:16:01.260
Siamo noi a decidere cosa ne sarà di questa tecnologia.

00:16:01.260 --> 00:16:04.260
Saremo noi a determinare il finale di tutto questo.

00:16:04.260 --> 00:16:06.260
Grazie.

00:16:06.260 --> 00:16:11.260
(Applausi)

