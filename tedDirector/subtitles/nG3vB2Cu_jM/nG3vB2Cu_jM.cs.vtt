WEBVTT
Kind: captions
Language: cs

00:00:00.000 --> 00:00:07.000
Překladatel: Tomáš Křehlík
Korektor: Jan Kadlec

00:00:15.260 --> 00:00:17.260
Moc.

00:00:17.260 --> 00:00:19.260
To je to slovo, které se nám vybaví.

00:00:19.260 --> 00:00:21.260
My jsme noví technologové.

00:00:21.260 --> 00:00:24.260
Máme spoustu dat, takže máme velkou moc.

00:00:24.260 --> 00:00:26.260
Jak velkou moc máme?

00:00:26.260 --> 00:00:29.260
Scéna z filmu: "Apokalypsa" -- super film.

00:00:29.260 --> 00:00:32.260
Musíme dostat našeho hrdinu, kapitána Willarda, k ústí řeky Nung,

00:00:32.260 --> 00:00:34.260
aby mohl pronásledovat plukovníka Kurtze.

00:00:34.260 --> 00:00:36.260
Uděláme to tak, že tam s ním doletíme a vysadíme ho tam.

00:00:36.260 --> 00:00:38.260
Takže ta scéna:

00:00:38.260 --> 00:00:41.260
obloha je plná helikoptér, které nesou kapitána Willarda.

00:00:41.260 --> 00:00:43.260
A na pozadí hraje ta hlasitá, vzrušující hudba.

00:00:43.260 --> 00:00:45.260
tahle nespoutaná hudba.

00:00:45.260 --> 00:00:47.260
♫ Tam ta da ta tam ♫

00:00:47.260 --> 00:00:49.260
♫ Tam ta da ta tam ♫

00:00:49.260 --> 00:00:52.260
♫ Ta da ta tá ♫

00:00:52.260 --> 00:00:54.260
To je velká moc.

00:00:54.260 --> 00:00:56.260
To je ten druh moci, který cítím v téhle místnosti.

00:00:56.260 --> 00:00:58.260
To je ten druh moci, který máme,

00:00:58.260 --> 00:01:00.260
kvůli datům, které máme k dispozici.

00:01:00.260 --> 00:01:02.260
Nějaký příklad.

00:01:02.260 --> 00:01:04.260
Co můžeme udělat

00:01:04.260 --> 00:01:07.260
s údaji jediného člověka?

00:01:07.260 --> 00:01:09.260
Co můžeme udělat

00:01:09.260 --> 00:01:11.260
s údaji o tom člověku?

00:01:11.260 --> 00:01:13.260
Můžu se podívat na jeho finanční záznamy.

00:01:13.260 --> 00:01:15.260
Můžu říct, jestli platí na čas svoje složenky.

00:01:15.260 --> 00:01:17.260
Vím, jestli je dost spolehlivý, abych mu dal půjčku.

00:01:17.260 --> 00:01:20.260
Můžu se podívat na jeho zdravotní záznamy, jestli mu ještě pumpuje pumpa...

00:01:20.260 --> 00:01:23.260
podívat se, jestli ho mám pojistit.

00:01:23.260 --> 00:01:25.260
Můžu se podívat, kde kliká na monitoru.

00:01:25.260 --> 00:01:28.260
Když přijde na mou stránku, já vlastně už dopředu vím, co bude dělat,

00:01:28.260 --> 00:01:30.260
protože jsem ho už viděl na miliónech jiných stránek.

00:01:30.260 --> 00:01:32.260
A, nerad to říkám,

00:01:32.260 --> 00:01:34.260
on je jako hráč pokeru, má zvláštní tik, který ho odhalí.

00:01:34.260 --> 00:01:36.260
S pomocí datové analýzy dokážu říct, co bude dělat

00:01:36.260 --> 00:01:38.260
před tím, než to udělá.

00:01:38.260 --> 00:01:41.260
Vím, co má rád. Vím, kdo je.

00:01:41.260 --> 00:01:43.260
A to dokonce před tím, než se podívám na jeho mail

00:01:43.260 --> 00:01:45.260
nebo telefon.

00:01:45.260 --> 00:01:47.260
To je ten druh věcí, co můžeme dělat

00:01:47.260 --> 00:01:50.260
s daty, která máme.

00:01:50.260 --> 00:01:53.260
Ale já tu nejsem kvůli tomu, abych mluvil o tom, co můžeme dělat.

00:01:56.260 --> 00:01:59.260
Jsem tu kvůli tomu, abych mluvil o tom, co bychom měli dělat.

00:02:00.260 --> 00:02:03.260
Co bychom měli dělat?

00:02:04.260 --> 00:02:06.260
Teď vidím nějaké zmatené obličeje,

00:02:06.260 --> 00:02:09.260
které říkají: "Proč se nás ptáš, co bychom měli dělat?

00:02:09.260 --> 00:02:12.260
My to jenom vyvíjíme. Používá to někdo jiný."

00:02:12.260 --> 00:02:15.260
Dobře.

00:02:15.260 --> 00:02:17.260
Ale přenáší mě to zpátky.

00:02:17.260 --> 00:02:19.260
Přemýšlím o druhé světové válce.

00:02:19.260 --> 00:02:21.260
Někteří výborní technologové,

00:02:21.260 --> 00:02:23.260
někteří naši nejlepší fyzikové

00:02:23.260 --> 00:02:25.260
studovali jadernou fúzi a štěpnou reakci.

00:02:25.260 --> 00:02:27.260
Jenom jaderné věci.

00:02:27.260 --> 00:02:30.260
Shromáždili jsme ty fyziky v Los Alamos,

00:02:30.260 --> 00:02:33.260
abychom zjistili, co vyrobí.

00:02:33.260 --> 00:02:36.260
Chceme po lidech, kteří vytváří technologie,

00:02:36.260 --> 00:02:39.260
aby přemýšleli o tom, co bychom s nimi měli dělat.

00:02:41.260 --> 00:02:44.260
Tak co bychom měli dělat s daty toho člověka?

00:02:44.260 --> 00:02:47.260
Měli bychom je shromažďovat, schraňovat,

00:02:47.260 --> 00:02:49.260
abychom zlepšili jeho online prostředí?

00:02:49.260 --> 00:02:51.260
Takže můžeme vydělat peníze?

00:02:51.260 --> 00:02:53.260
Můžeme ochraňovat sami sebe,

00:02:53.260 --> 00:02:55.260
pokud by neměl dobré úmysly?

00:02:55.260 --> 00:02:58.260
Nebo bychom měli respektovat jeho soukromí,

00:02:58.260 --> 00:03:01.260
ochraňovat jeho důstojnost a nechat ho napokoji?

00:03:02.260 --> 00:03:05.260
Co bychom měli dělat?

00:03:05.260 --> 00:03:07.260
A jak bychom měli přijít na to, co dělat?

00:03:07.260 --> 00:03:10.260
Vím: podle davu. Zjistíme to v davu.

00:03:11.260 --> 00:03:14.260
Takže něco na zahřátí,

00:03:14.260 --> 00:03:16.260
začneme s jednoduchou otázkou,

00:03:16.260 --> 00:03:19.260
něco o čem si jsem jistý, že na to tady každý bude mít názor:

00:03:19.260 --> 00:03:21.260
iPhone nebo Android.

00:03:21.260 --> 00:03:24.260
Ruce nahoru pro iPhone.

00:03:24.260 --> 00:03:26.260
Oh ho.

00:03:26.260 --> 00:03:29.260
Android.

00:03:29.260 --> 00:03:31.260
Člověk by si myslel, že taková parta chytrých lidí

00:03:31.260 --> 00:03:33.260
nebudou blázni jen kvůli hezkým telefonům.

00:03:33.260 --> 00:03:35.260
(Smích)

00:03:35.260 --> 00:03:37.260
Další otázka,

00:03:37.260 --> 00:03:39.260
trošku těžší.

00:03:39.260 --> 00:03:41.260
Měli bychom shromažďovat data toho člověka,

00:03:41.260 --> 00:03:43.260
abychom mu zlepšili jeho online prostředí

00:03:43.260 --> 00:03:46.260
a ochraňovali sami sebe, pokud by měl špatné úmysly?

00:03:46.260 --> 00:03:48.260
Nebo bychom ho měli nechat napokoji?

00:03:48.260 --> 00:03:51.260
Shromažďovat data.

00:03:53.260 --> 00:03:56.260
Nechat ho napokoji.

00:03:56.260 --> 00:03:58.260
Je v bezpečí, je to v pohodě.

00:03:58.260 --> 00:04:00.260
(Smích)

00:04:00.260 --> 00:04:02.260
Dobrá, poslední otázka,

00:04:02.260 --> 00:04:04.260
těžší,

00:04:04.260 --> 00:04:07.260
když zkoušíme zjistit,

00:04:07.260 --> 00:04:10.260
co bychom měli dělat v tomhle případu,

00:04:10.260 --> 00:04:14.260
měli bychom použít Kantův deontologický morální rámec,

00:04:14.260 --> 00:04:17.260
nebo bychom měli použít Millův konsekvenciální?

00:04:19.260 --> 00:04:22.260
Kant.

00:04:22.260 --> 00:04:25.260
Mill.

00:04:25.260 --> 00:04:27.260
Docela málo hlasů.

00:04:27.260 --> 00:04:30.260
(Smích)

00:04:30.260 --> 00:04:33.260
Jo, to je strašný výsledek.

00:04:34.260 --> 00:04:38.260
Strašidelný, protože máme vyhraněnější názory

00:04:38.260 --> 00:04:40.260
na naše smartphony

00:04:40.260 --> 00:04:42.260
než na morální rámec,

00:04:42.260 --> 00:04:44.260
který bychom měli používat při rozhodování.

00:04:44.260 --> 00:04:47.260
Jak máme vědět, co dělat se vší mocí, kterou máme,

00:04:47.260 --> 00:04:50.260
pokud nemáme morální rámec?

00:04:50.260 --> 00:04:53.260
Víme víc o mobilních operačních systémech,

00:04:53.260 --> 00:04:56.260
ale opravdu bychom potřebovali morální operační systém.

00:04:58.260 --> 00:05:00.260
Co je to morální operační systém?

00:05:00.260 --> 00:05:02.260
Všichni víme, co je dobré a co je špatné, že.

00:05:02.260 --> 00:05:04.260
Cítíme se dobře, pokud něco uděláme dobře,

00:05:04.260 --> 00:05:06.260
cítíme se špatně, pokud uděláme něco špatně.

00:05:06.260 --> 00:05:09.260
Naši rodiče nás učí, že se správným rozhodnutím přichází odměna a se špatným trest.

00:05:09.260 --> 00:05:12.260
Ale jak víme, co je správné a co není?

00:05:12.260 --> 00:05:15.260
A ze dne na den máme technologie, které používáme.

00:05:15.260 --> 00:05:18.260
Možná následujeme nějaký vnitřní instinkt.

00:05:18.260 --> 00:05:21.260
Možná hlasujeme.

00:05:21.260 --> 00:05:23.260
Nebo se na to vykašlem,

00:05:23.260 --> 00:05:26.260
zeptáme se právního oddělení, co si o tom myslí.

00:05:26.260 --> 00:05:28.260
Jinak řečeno, je to takové náhodné,

00:05:28.260 --> 00:05:30.260
trochu ad hoc,

00:05:30.260 --> 00:05:33.260
jak přicházíme na to, co bychom měli dělat.

00:05:33.260 --> 00:05:36.260
A možná, pokud bychom chtěli stát oběma nohama na zemi,

00:05:36.260 --> 00:05:39.260
to co opravdu chceme je morální rámec, který nás bude vést,

00:05:39.260 --> 00:05:42.260
který nám řekne, které věci jsou správné a které špatné

00:05:42.260 --> 00:05:46.260
a co bychom měli v dané situaci dělat.

00:05:46.260 --> 00:05:48.260
Sežeňme si tedy morální rámec.

00:05:48.260 --> 00:05:51.260
Jsme číslíčkáři, žijeme čísly.

00:05:51.260 --> 00:05:53.260
Jak můžeme použít čísla

00:05:53.260 --> 00:05:56.260
jako základ pro náš morální rámec?

00:05:56.260 --> 00:05:59.260
Znám člověka, který přesně toto udělal.

00:05:59.260 --> 00:06:02.260
Výbornej chlap,

00:06:02.260 --> 00:06:05.260
už je 2500 let mrtvý.

00:06:05.260 --> 00:06:07.260
Platón, je to tak.

00:06:07.260 --> 00:06:09.260
Znáte ho? Starý filozof?

00:06:09.260 --> 00:06:12.260
Vy jste při těch hodinách spali.

00:06:12.260 --> 00:06:14.260
A Platón měl s námi hodně společných problémů.

00:06:14.260 --> 00:06:16.260
Přemýšlel o správných a špatných věcech.

00:06:16.260 --> 00:06:18.260
Chtěl vědět, co je spravedlivé.

00:06:18.260 --> 00:06:20.260
Ale bál se, že jediné, co děláme je,

00:06:20.260 --> 00:06:22.260
že si vyměňujeme názory.

00:06:22.260 --> 00:06:25.260
On říká, že něco je spravedlivé, ona říká, že něco jiného je spravedlivé.

00:06:25.260 --> 00:06:27.260
Oba jsou docela přesvědčiví, když mluví.

00:06:27.260 --> 00:06:29.260
Jde to od desíti k pěti, nikam se nedostáváme.

00:06:29.260 --> 00:06:32.260
Nechci názory, chci poznání.

00:06:32.260 --> 00:06:35.260
Chci znát pravdu o spravedlnosti,

00:06:35.260 --> 00:06:38.260
tak jako máme pravdy v matematice.

00:06:38.260 --> 00:06:41.260
V matematice máme objektivní fakta.

00:06:41.260 --> 00:06:43.260
Vezměte si číslo, jakékoliv číslo, třeba dvojku.

00:06:43.260 --> 00:06:45.260
Je to moje oblíbené číslo, miluju ho.

00:06:45.260 --> 00:06:47.260
Máme pravdivé výroky o dvojce.

00:06:47.260 --> 00:06:49.260
Pokud máte dva něčeho

00:06:49.260 --> 00:06:51.260
a přidáte další dva, máte čtyři.

00:06:51.260 --> 00:06:53.260
Je to pravda vždycky, nehledě na to o čem mluvíte.

00:06:53.260 --> 00:06:55.260
Je to objektivní pravda o dvojce,

00:06:55.260 --> 00:06:57.260
o abstraktní formě.

00:06:57.260 --> 00:06:59.260
Pokud máte dva čehokoliv: dvě oči, dvě uši, dva nosy,

00:06:59.260 --> 00:07:01.260
dva výčnělky,

00:07:01.260 --> 00:07:04.260
ty všechny na sebe berou formu dvou.

00:07:04.260 --> 00:07:08.260
O všech platí pravdy, které platí o dvojce.

00:07:08.260 --> 00:07:10.260
Všechny mají v sobě vlastnosti dvojky.

00:07:10.260 --> 00:07:13.260
A proto to není věc názoru.

00:07:13.260 --> 00:07:15.260
Co kdyby, myslel si Platón,

00:07:15.260 --> 00:07:17.260
byla etika jako matematika?

00:07:17.260 --> 00:07:20.260
Co kdybychom měli čistou formu spravedlnosti?

00:07:20.260 --> 00:07:22.260
Co když existují pravdy o spravedlnosti,

00:07:22.260 --> 00:07:24.260
kdy bychom se mohli jenom rozhlédnout po světě

00:07:24.260 --> 00:07:26.260
a zjistit, kterých věcí jsou součástí,

00:07:26.260 --> 00:07:29.260
které na sebe berou podobu té formy spravedlnosti?

00:07:29.260 --> 00:07:32.260
Potom bychom věděli, co je opravdu spravedlivé a co není.

00:07:32.260 --> 00:07:34.260
Nebyla by to jenom záležitost

00:07:34.260 --> 00:07:37.260
názoru nebo pohledu.

00:07:37.260 --> 00:07:39.260
To je ohromující představa.

00:07:39.260 --> 00:07:42.260
Vezměte si to. Tak vznešená, tak ambiciózní.

00:07:42.260 --> 00:07:44.260
Tak ambiciózní, jako jsme my sami.

00:07:44.260 --> 00:07:46.260
On chce přijít na kloub etice.

00:07:46.260 --> 00:07:48.260
Chce objektivní pravdy.

00:07:48.260 --> 00:07:51.260
Pokud uvažujete tímto způsobem,

00:07:51.260 --> 00:07:54.260
máte Platónský morální rámec.

00:07:54.260 --> 00:07:56.260
Pokud tak neuvažujete,

00:07:56.260 --> 00:07:58.260
tak máte spousty přátel v historii západní filozofie,

00:07:58.260 --> 00:08:01.260
protože tu krásnou myšlenku lidé kritizovali.

00:08:01.260 --> 00:08:04.260
Hlavně Aristoteles z ní nebyl moc nadšený.

00:08:04.260 --> 00:08:07.260
Připadala mu nepraktická.

00:08:07.260 --> 00:08:11.260
Řekl: "V každé disciplíně bychom měli hledat jen tolik přesnosti,

00:08:11.260 --> 00:08:13.260
kolik nám disciplína dovoluje."

00:08:13.260 --> 00:08:16.260
Aristoteles si nemyslel, že etika je podobná matice.

00:08:16.260 --> 00:08:19.260
Věřil, že etika je záležitost rozhodování se tady a teď,

00:08:19.260 --> 00:08:21.260
používání našeho nejlepšího úsudku,

00:08:21.260 --> 00:08:23.260
abychom našli správnou cestu.

00:08:23.260 --> 00:08:25.260
Pokud tomu věříte, tak Platón není váš člověk.

00:08:25.260 --> 00:08:27.260
Ale nevzdávejte to.

00:08:27.260 --> 00:08:29.260
Možná je tu i jiná cesta,

00:08:29.260 --> 00:08:32.260
ve které bychom mohli použít čísla jako základ našeho morálního rámce.

00:08:33.260 --> 00:08:35.260
Co třeba tohle.

00:08:35.260 --> 00:08:38.260
Co kdybychom mohli v každé situaci počítat,

00:08:38.260 --> 00:08:40.260
podívat se na možnosti,

00:08:40.260 --> 00:08:43.260
a změřit, která je lepší a co dělat?

00:08:43.260 --> 00:08:45.260
Zní to povědomě?

00:08:45.260 --> 00:08:48.260
Je to utilitární morální rámec.

00:08:48.260 --> 00:08:50.260
Velkým obhájcem tohohle přístupu byl John Stuart Mill,

00:08:50.260 --> 00:08:52.260
dobrej chlap, mimochodem,

00:08:52.260 --> 00:08:54.260
a je mrtvej jen 200 let.

00:08:54.260 --> 00:08:56.260
Takže základ utilitarismu,

00:08:56.260 --> 00:08:58.260
určitě to znáte.

00:08:58.260 --> 00:09:00.260
Ti tři, kteří předtím hlasovali pro Milla, to určitě znají.

00:09:00.260 --> 00:09:02.260
Ale funguje to asi takhle.

00:09:02.260 --> 00:09:05.260
Co kdyby morálka, něco co moralizuje věc,

00:09:05.260 --> 00:09:07.260
byla jenom otázka maximalizace požitku

00:09:07.260 --> 00:09:09.260
a minimalizace utrpení?

00:09:09.260 --> 00:09:12.260
Vytváří to něco zvláštního v jednání.

00:09:12.260 --> 00:09:14.260
Není to jako vztah k nějaké abstraktní formě.

00:09:14.260 --> 00:09:16.260
Je to jen záležitost následků.

00:09:16.260 --> 00:09:18.260
Jen se podíváme na následky

00:09:18.260 --> 00:09:20.260
a zjistíme, jestli jsou v součtu dobré nebo špatné.

00:09:20.260 --> 00:09:22.260
To by bylo jednoduché. Takže víme, co dělat.

00:09:22.260 --> 00:09:24.260
Vezmeme si příklad.

00:09:24.260 --> 00:09:26.260
Třeba řekněme, že přijdu

00:09:26.260 --> 00:09:28.260
a řeknu: "Vezmu ti telefon."

00:09:28.260 --> 00:09:30.260
Ne jenom kvůli tomu, že ti před chvílí zvonil,

00:09:30.260 --> 00:09:33.260
ale vezmu ti ho, protože jsem si to trochu spočítal.

00:09:33.260 --> 00:09:36.260
Řekl jsem si, ten chlap vypadá podezřele.

00:09:36.260 --> 00:09:39.260
A co kdyby posílal zprávy Bin Ládinovi do úkrytu,

00:09:39.260 --> 00:09:41.260
nebo teda komukoliv, kdo to po Bin Ládinovi převzal,

00:09:41.260 --> 00:09:44.260
a je vlastně terorista v utajení.

00:09:44.260 --> 00:09:47.260
Zjistím to a až to zjistím,

00:09:47.260 --> 00:09:50.260
zabráním spoustě škod, které mohl způsobit.

00:09:50.260 --> 00:09:53.260
Předcházet škodám má velký užitek.

00:09:53.260 --> 00:09:55.260
A ve srovnání s malým utrpením, které mu tím způsobím,

00:09:55.260 --> 00:09:57.260
protože to bude trapné, až mu budu koukat do telefonu

00:09:57.260 --> 00:10:00.260
a uvidím, že má problémy s Farmvillem a vším tím okolo,

00:10:00.260 --> 00:10:03.260
to bude všechno překonáno

00:10:03.260 --> 00:10:05.260
hodnotou, která vzejde z koukání na jeho telefon.

00:10:05.260 --> 00:10:07.260
Pokud přemýšlíte takhle,

00:10:07.260 --> 00:10:10.260
tak jste utilitariáni.

00:10:10.260 --> 00:10:13.260
Ale možná nepřemýšlíte ani takhle.

00:10:13.260 --> 00:10:15.260
Možná si říkáte, že je to jeho telefon.

00:10:15.260 --> 00:10:17.260
A je špatné vzít mu ho,

00:10:17.260 --> 00:10:19.260
protože je člověk

00:10:19.260 --> 00:10:21.260
a má svá práva a důstojnost

00:10:21.260 --> 00:10:23.260
a do toho my nesmíme zasahovat.

00:10:23.260 --> 00:10:25.260
Má autonomii.

00:10:25.260 --> 00:10:27.260
Všechny kalkulace nemají význam.

00:10:27.260 --> 00:10:30.260
Jsou věci, které jsou z podstaty špatné,

00:10:30.260 --> 00:10:32.260
třeba lhaní

00:10:32.260 --> 00:10:35.260
nebo mučení nevinného dítěte.

00:10:35.260 --> 00:10:38.260
Kant to říká jasně

00:10:38.260 --> 00:10:40.260
a taky trochu líp, než to řeknu já.

00:10:40.260 --> 00:10:42.260
Řekl, že bychom měli používat svůj rozum,

00:10:42.260 --> 00:10:45.260
abychom zjistili, podle jakých pravidel se máme chovat.

00:10:45.260 --> 00:10:48.260
A potom je naší povinností se podle těchto pravidel řídit.

00:10:48.260 --> 00:10:51.260
Není to záležitost počtů.

00:10:51.260 --> 00:10:53.260
Takže přestaňme.

00:10:53.260 --> 00:10:56.260
A teď jsme v tom až po uši, v té filozofické kaši.

00:10:56.260 --> 00:10:59.260
A takhle to jde po tisíce let,

00:10:59.260 --> 00:11:01.260
protože to jsou těžké otázky

00:11:01.260 --> 00:11:03.260
a já mám jen patnáct minut.

00:11:03.260 --> 00:11:05.260
Takže pojďme k věci.

00:11:05.260 --> 00:11:09.260
Jak bychom se měli rozhodovat?

00:11:09.260 --> 00:11:12.260
Je to Platón, Aristoteles, Kant nebo Mill?

00:11:12.260 --> 00:11:14.260
Co bychom měli dělat? Jaká je odpověď?

00:11:14.260 --> 00:11:17.260
Jaký je vzorec, který můžeme použít pokaždé,

00:11:17.260 --> 00:11:19.260
když budeme chtít zjistit, co dělat,

00:11:19.260 --> 00:11:21.260
jestli bychom měli používat data toho člověka?

00:11:21.260 --> 00:11:24.260
Jaký je ten vzorec?

00:11:25.260 --> 00:11:27.260
Žádný není.

00:11:29.260 --> 00:11:31.260
Není žádná jednoduchá odpověď.

00:11:31.260 --> 00:11:34.260
Etika je těžká.

00:11:34.260 --> 00:11:37.260
Etika vyžaduje přemýšlení.

00:11:38.260 --> 00:11:40.260
A to není příjemné.

00:11:40.260 --> 00:11:42.260
Znám to, strávil jsem velkou část své kariéry

00:11:42.260 --> 00:11:44.260
umělou inteligencí,

00:11:44.260 --> 00:11:47.260
zkoušel jsem postavit stroje, které budou moci vymyslet tyhle věci za nás,

00:11:47.260 --> 00:11:49.260
které nám dají odpovědi.

00:11:49.260 --> 00:11:51.260
Ale oni nemůžou.

00:11:51.260 --> 00:11:53.260
Nemůžete vzít lidské přemýšlení

00:11:53.260 --> 00:11:55.260
a vložit ho do stroje.

00:11:55.260 --> 00:11:58.260
Musíme to udělat my sami.

00:11:58.260 --> 00:12:01.260
Naštěstí nejsme stroje a můžeme to udělat.

00:12:01.260 --> 00:12:03.260
Nejenom že umíme přemýšlet,

00:12:03.260 --> 00:12:05.260
my musíme.

00:12:05.260 --> 00:12:07.260
Hannah Arendtová řekla:

00:12:07.260 --> 00:12:09.260
"Smutná pravda je,

00:12:09.260 --> 00:12:11.260
že nejvíce zla v tomto světě

00:12:11.260 --> 00:12:13.260
není způsobeno lidmi,

00:12:13.260 --> 00:12:15.260
kteří se rozhodnou být zlí.

00:12:15.260 --> 00:12:18.260
Nejvíc ho vzniká z nepřemýšlení."

00:12:18.260 --> 00:12:22.260
To je to, čemu říkala "banalita zla."

00:12:22.260 --> 00:12:24.260
A odpověď na to je,

00:12:24.260 --> 00:12:26.260
že budeme požadovat přemýšlení

00:12:26.260 --> 00:12:29.260
od každého normálního člověka.

00:12:29.260 --> 00:12:31.260
Udělejme to tedy. Přemýšlejme.

00:12:31.260 --> 00:12:34.260
Vlastně můžeme začít hned teď.

00:12:34.260 --> 00:12:37.260
Každý v téhle místnosti,

00:12:37.260 --> 00:12:40.260
vzpomeňte si, kdy naposled jste museli udělat rozhodnutí,

00:12:40.260 --> 00:12:42.260
kdy jste měli strach, že neuděláte dobře,

00:12:42.260 --> 00:12:44.260
kdy jste si říkali: "Co bych měl udělat?"

00:12:44.260 --> 00:12:46.260
Vzpomeňte si na to.

00:12:46.260 --> 00:12:48.260
A teď přemýšlejte

00:12:48.260 --> 00:12:51.260
a řekněte "Jak jsem přišel na to, co mám udělat?

00:12:51.260 --> 00:12:54.260
Co jsem udělal? Jednal jsem instinktivně?

00:12:54.260 --> 00:12:56.260
Nechal jsem o tom hlasovat? Nebo jsem se na to vykašlal a zavolal na právní?"

00:12:56.260 --> 00:12:59.260
Anebo teď máme několik dalších možností.

00:12:59.260 --> 00:13:01.260
"Vymyslel jsem, co vytvoří největší potěšení,

00:13:01.260 --> 00:13:03.260
jako by to udělal Mill?

00:13:03.260 --> 00:13:06.260
Nebo jako Kant, použil jsem rozum, abych přišel na to, co je správné?"

00:13:06.260 --> 00:13:09.260
Přemýšlejte o tom. Opravdu vzpomínejte. Je to důležité.

00:13:09.260 --> 00:13:11.260
Je to tak důležité,

00:13:11.260 --> 00:13:13.260
že strávíme 30 sekund našeho TED času

00:13:13.260 --> 00:13:15.260
nicneděláním a přemýšlením.

00:13:15.260 --> 00:13:17.260
Jste připravení? Jdem na to!

00:13:33.260 --> 00:13:36.260
Konec. Dobrá práce!

00:13:36.260 --> 00:13:38.260
To co jste právě udělali,

00:13:38.260 --> 00:13:40.260
je první krok k tomu, abychom přijali zodpovědnost

00:13:40.260 --> 00:13:43.260
za to, co bychom měli dělat ze všech sil.

00:13:45.260 --> 00:13:48.260
Jako další krok vyzkoušíme tohle.

00:13:49.260 --> 00:13:51.260
Jděte a najděte známého a vysvětlete mu,

00:13:51.260 --> 00:13:53.260
jak jste k tomu rozhodnutí došli.

00:13:53.260 --> 00:13:55.260
Ne teď. Počkejte až domluvím.

00:13:55.260 --> 00:13:57.260
Udělejte to třeba při obědě.

00:13:57.260 --> 00:14:00.260
A najděte někoho jiného než dalšího technologa,

00:14:00.260 --> 00:14:02.260
najděte někoho, kdo je jiný než vy.

00:14:02.260 --> 00:14:04.260
Najděte umělce nebo spisovatele

00:14:04.260 --> 00:14:07.260
nebo, možná radši ne, najděte filozofa a mluvte s ním.

00:14:07.260 --> 00:14:09.260
Vlastně najděte někoho, kdo studuje humanitní vědy.

00:14:09.260 --> 00:14:11.260
Proč? Protože oni o problémech přemýšlejí

00:14:11.260 --> 00:14:13.260
jinak než my technologové.

00:14:13.260 --> 00:14:16.260
Před několika dny, přímo přes ulici,

00:14:16.260 --> 00:14:18.260
se shromáždily stovky lidí.

00:14:18.260 --> 00:14:20.260
Byli to technologové a lidé, kteří studují humanitní vědy,

00:14:20.260 --> 00:14:22.260
kteří přišli na BiblioTech Conference.

00:14:22.260 --> 00:14:24.260
A sešli se tam,

00:14:24.260 --> 00:14:26.260
protože technologové chtěli zjistit,

00:14:26.260 --> 00:14:29.260
jaké by to bylo přemýšlet z perspektivy humanitních věd.

00:14:29.260 --> 00:14:31.260
Máte třeba někoho z Googlu,

00:14:31.260 --> 00:14:33.260
kdo mluví s někým zaobírajícím se komparativní literaturou.

00:14:33.260 --> 00:14:36.260
Přemýšlíte o významu francouzského divadla sedmnáctého století

00:14:36.260 --> 00:14:38.260
a co má společného s rizikovým kapitálem?

00:14:38.260 --> 00:14:41.260
Hmm, to je zajímavé. To je jiný způsob myšlení.

00:14:41.260 --> 00:14:43.260
A když takhle začnete přemýšlet,

00:14:43.260 --> 00:14:46.260
začnete být citlivější na lidská kritéria,

00:14:46.260 --> 00:14:49.260
která jsou zásadní v etickém rozhodování.

00:14:49.260 --> 00:14:51.260
Tak si to teď představme,

00:14:51.260 --> 00:14:53.260
šli jste a našli jste nějakého muzikanta.

00:14:53.260 --> 00:14:56.260
A říkáte mu, o čem jsme tady mluvili,

00:14:56.260 --> 00:14:58.260
o té datové revoluci a tak,

00:14:58.260 --> 00:15:00.260
možná i pár taktů naší úvodní hudby.

00:15:00.260 --> 00:15:03.260
♫ Tam ta da da tam tam ta da da tam ♫

00:15:03.260 --> 00:15:05.260
Muzikant vás zastaví a řekne:

00:15:05.260 --> 00:15:07.260
"Víš, že ta vaše úvodní hudba

00:15:07.260 --> 00:15:09.260
k té datové revoluci,

00:15:09.260 --> 00:15:11.260
to je opera, to je Wagner.

00:15:11.260 --> 00:15:13.260
Je založená na norské legendě.

00:15:13.260 --> 00:15:15.260
Jsou tam bohové a mytická stvoření,

00:15:15.260 --> 00:15:18.260
kteří bojují o magický prsten."

00:15:19.260 --> 00:15:22.260
To je zajímavé.

00:15:22.260 --> 00:15:25.260
Takže teď je to i krásná opera.

00:15:25.260 --> 00:15:28.260
A jsme dojatí z té opery.

00:15:28.260 --> 00:15:30.260
Jsme dojatí, protože je to o boji

00:15:30.260 --> 00:15:32.260
mezi dobrem a zlem,

00:15:32.260 --> 00:15:34.260
o správném a špatném.

00:15:34.260 --> 00:15:36.260
A nás zajímá, co je dobře a co špatně.

00:15:36.260 --> 00:15:39.260
Nás zajímá, co se stane v té opeře.

00:15:39.260 --> 00:15:42.260
Zajímá nás, co se stane v "Apokalypse."

00:15:42.260 --> 00:15:44.260
A zcela jistě nás zajímá,

00:15:44.260 --> 00:15:46.260
co se stane s našimi technologiemi.

00:15:46.260 --> 00:15:48.260
Máme dnes tolik moci,

00:15:48.260 --> 00:15:51.260
že je na nás, abychom přišli na to, co dělat.

00:15:51.260 --> 00:15:53.260
A to je dobrá zpráva.

00:15:53.260 --> 00:15:56.260
My jsme ti, kteří píší tuhle operu.

00:15:56.260 --> 00:15:58.260
Tohle je náš film.

00:15:58.260 --> 00:16:01.260
My přijdeme na to, co se má stát s touhle technologií.

00:16:01.260 --> 00:16:04.260
My určíme, jak to skončí!

00:16:04.260 --> 00:16:06.260
Děkuji.

00:16:06.260 --> 00:16:11.260
(Potlesk)

