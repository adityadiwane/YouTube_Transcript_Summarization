WEBVTT
Kind: captions
Language: zh-TW

00:00:00.000 --> 00:00:07.000
譯者: Wang Qian
審譯者: Bill Hsiung

00:00:25.000 --> 00:00:27.000
首先，我要用最快的速度為大家示範

00:00:27.000 --> 00:00:31.000
一些新技術的基礎研究成果。

00:00:31.000 --> 00:00:34.000
正好是一年前， 微軟收購了我們公司，

00:00:34.000 --> 00:00:37.000
而我們為微軟帶來了這項技術，它就是「海龍」(Seadragon)。

00:00:37.000 --> 00:00:40.000
「海龍」是一個軟體環境，你可以通過它以近景或遠景的方式

00:00:40.000 --> 00:00:43.000
流覽浩瀚的視覺化資料。

00:00:43.000 --> 00:00:46.000
我們在這裏看到的是，非常多千兆位元組的數位像片，

00:00:46.000 --> 00:00:49.000
我們可以對它們可以進行持續並且平滑的放大，

00:00:50.000 --> 00:00:52.000
可以通過全景的方式流覽它們，還可以對它們進行重新排列。

00:00:52.000 --> 00:00:56.000
不管所見到的資料有多少、

00:00:56.000 --> 00:00:59.000
圖像集有多大或是圖像本身有多大。

00:00:59.000 --> 00:01:01.000
以上展示的圖片，大部分是來自一般數位相機的照片，

00:01:01.000 --> 00:01:04.000
但這個例子不同，它是一張來自國會圖書館的掃描圖片，

00:01:05.000 --> 00:01:07.000
擁有3億個像素。

00:01:08.000 --> 00:01:09.000
然而，這沒有造成任何不同，

00:01:09.000 --> 00:01:12.000
因為能夠限制像這樣的系統效能的唯一因素，

00:01:12.000 --> 00:01:15.000
是你所使用的螢幕所正在顯示的像素數量。

00:01:15.000 --> 00:01:18.000
「海龍」同時也是一個非常靈活的架構。

00:01:18.000 --> 00:01:21.000
這是一本完整的書，是非圖形式資料的一個例子。

00:01:22.000 --> 00:01:27.000
這是狄更斯所著的《荒涼山莊》，每一欄就是一個章節。

00:01:27.000 --> 00:01:31.000
為了向你們證明這真的是文字而非圖片，

00:01:31.000 --> 00:01:33.000
我們可以這樣操作，

00:01:33.000 --> 00:01:36.000
大家可以看得出來這真的是文字，而不是一張圖片。

00:01:37.000 --> 00:01:39.000
也許這會是一種閱讀電子書的方式，

00:01:39.000 --> 00:01:40.000
但是我個人不會推薦這麼做。

00:01:40.000 --> 00:01:43.000
接下來是一個更加實際的例子，這是一期《衛報》。

00:01:43.000 --> 00:01:45.000
你所看到的每一張大圖片，就是各版頭條，

00:01:45.000 --> 00:01:48.000
而報紙或雜誌的紙本，本身就包含了各種比例的媒材，

00:01:48.000 --> 00:01:53.000
因此這樣閱讀的時候，讀者會得到更好的閱讀體驗，

00:01:54.000 --> 00:01:55.000
從而享受閱讀的樂趣。

00:01:56.000 --> 00:01:57.000
我們在這裏做了點小小的更動，

00:01:57.000 --> 00:02:00.000
在這一期《衛報》的一角。

00:02:00.000 --> 00:02:03.000
我們刊登了一個非常高解析度的虛構廣告 —

00:02:03.000 --> 00:02:05.000
比你平常看到的普通廣告的解析度要高很多，

00:02:05.000 --> 00:02:07.000
我們並在圖片中嵌入了額外的內容。

00:02:07.000 --> 00:02:09.000
如果你希望看到這輛車的特性，你可以看這裏，

00:02:10.000 --> 00:02:14.000
你還能看到其他的型號，甚至技術規格。

00:02:15.000 --> 00:02:17.000
這種方式在一定程度上，

00:02:18.000 --> 00:02:22.000
避開了螢幕面積的限制。

00:02:22.000 --> 00:02:24.000
我們希望這個技術能夠減少不必要的彈出視窗，

00:02:24.000 --> 00:02:26.000
及其他類似的，不必要的垃圾。

00:02:27.000 --> 00:02:29.000
當然，對於像這樣的技術，

00:02:29.000 --> 00:02:31.000
數位地圖也是顯而易見的應用之一。

00:02:31.000 --> 00:02:33.000
對此，我真的不想花費太多的時間進行介紹，

00:02:33.000 --> 00:02:35.000
我只想告訴大家，我們對這個領域也貢獻了一己之力。

00:02:37.000 --> 00:02:39.000
這些是將美國的所有道路，

00:02:39.000 --> 00:02:43.000
疊加在太空總署的地理空間影像上。

00:02:44.000 --> 00:02:46.000
現在，我們先放下這些，看看其他的。

00:02:46.000 --> 00:02:49.000
實際上，這項技術已經放到網路上了，大家可以自己去體驗一下。

00:02:49.000 --> 00:02:50.000
這個計畫名叫「相片合成」 (Photosynth)，

00:02:51.000 --> 00:02:52.000
它實際上融合了兩個不同的技術：

00:02:52.000 --> 00:02:53.000
一個是「海龍」，

00:02:54.000 --> 00:02:56.000
而另一個則是源自華盛頓大學的研究生 Noah Snavely，

00:02:57.000 --> 00:02:59.000
所進行的電腦視覺化研究的美麗成果。

00:03:00.000 --> 00:03:02.000
這項研究還得到了華盛頓大學 Steve Seitz

00:03:02.000 --> 00:03:06.000
和微軟研究中心 Rick Szeliski 的共同指導。這是一個非常漂亮的合作成果。

00:03:07.000 --> 00:03:09.000
現在各位看到的是我們連上網路的即時示範，它是根基於「海龍」技術。

00:03:09.000 --> 00:03:11.000
你可以看到，我們輕鬆地對圖片進行多種方式的查看，

00:03:12.000 --> 00:03:13.000
就好像潛入這些影像一般，

00:03:14.000 --> 00:03:15.000
擁有了這種多解析度的瀏覽體驗。

00:03:16.000 --> 00:03:20.000
不過，在這邊，這些圖片空間上的關係事實上是有意義的。

00:03:20.000 --> 00:03:23.000
電腦視覺演算法將這些圖片聯繫到一起，

00:03:23.000 --> 00:03:27.000
那麼這些圖片就能將真實空間給呈現出來了，

00:03:27.000 --> 00:03:29.000
而我們正是在這個地方拍了上述的照片 — 這些照片都是在

00:03:31.000 --> 00:03:33.000
加拿大洛磯山脈的格拉西湖附近拍下的 — 所有照片都是在這裏拍下的。

00:03:33.000 --> 00:03:37.000
因此，這邊你可以看到穩定幻燈片播放的元素或者環景影像，

00:03:40.000 --> 00:03:42.000
而這些內容在空間上都是互相關聯的。

00:03:42.000 --> 00:03:45.000
我不確定我是否有時間為你們示範其他環境的例子。

00:03:45.000 --> 00:03:46.000
有些其他例子比這個的空間感還要強。

00:03:47.000 --> 00:03:50.000
下面讓我們來看一下去年夏天，

00:03:50.000 --> 00:03:52.000
Noah 早期所建立的資料集之一，

00:03:52.000 --> 00:03:54.000
這是來自於「相片合成」技術早期的原型階段。

00:03:54.000 --> 00:03:55.000
我認為，

00:03:55.000 --> 00:03:58.000
這是我們這項技術最搶眼之處。

00:03:59.000 --> 00:04:01.000
「相片合成」技術不單單像我們剛剛在

00:04:01.000 --> 00:04:04.000
網站上所示範的環境般，那麼的簡單明瞭。

00:04:04.000 --> 00:04:06.000
主要因為我們製作網站時，要顧慮很多法律問題。

00:04:07.000 --> 00:04:08.000
這裡是利用 Flickr 網站上

00:04:09.000 --> 00:04:11.000
的照片，並完全以電腦重建的巴黎聖母院。

00:04:11.000 --> 00:04:14.000
你所要做的只是在 Flickr 網站上輸入「巴黎聖母院」，

00:04:14.000 --> 00:04:17.000
然後便能看到很多照片，包括在那邊留影的遊客等等。

00:04:17.000 --> 00:04:21.000
每一個橘色的錐形都代表了一張

00:04:22.000 --> 00:04:24.000
用來建立模型的照片。

00:04:26.000 --> 00:04:28.000
這些全部是來自 Flickr 的圖片，

00:04:28.000 --> 00:04:31.000
被這樣在空間裡被串聯起來。

00:04:31.000 --> 00:04:33.000
接著，我們便可如此自然的進行瀏覽。

00:04:35.000 --> 00:04:44.000
（掌聲）

00:04:44.000 --> 00:04:46.000
說實話，我從來沒想過我會為微軟工作，

00:04:46.000 --> 00:04:50.000
這樣受到歡迎，真挺令人高興的。

00:04:50.000 --> 00:04:53.000
（笑聲）

00:04:53.000 --> 00:04:56.000
我想你們可以看出，

00:04:56.000 --> 00:04:58.000
這些照片來自很多不同的相機：

00:04:58.000 --> 00:05:01.000
從手機鏡頭到專業的單眼相機。

00:05:02.000 --> 00:05:03.000
如此大量的不同品質的照片，全被在這個環境下

00:05:03.000 --> 00:05:04.000
拼湊在一 起。

00:05:04.000 --> 00:05:06.000
讓我來找些比較詭異的照片。

00:05:08.000 --> 00:05:11.000
看，不少照片包含了遊客的大頭照等等。

00:05:13.000 --> 00:05:14.000
我記得這裡應該有

00:05:15.000 --> 00:05:16.000
一系列的照片 — 啊，在這兒。

00:05:17.000 --> 00:05:20.000
這實際上是一張有巴黎聖母院照片的海報，

00:05:21.000 --> 00:05:23.000
我們可以鑽到海報裡，

00:05:24.000 --> 00:05:27.000
去看整個重建的環境。

00:05:31.000 --> 00:05:34.000
這裏的重點呢？便是我們可以

00:05:34.000 --> 00:05:39.000
有效地利用網路社群。我們可以從每個人那裡得到資料，

00:05:39.000 --> 00:05:40.000
將每個人對不同環境

00:05:40.000 --> 00:05:42.000
的視覺記憶蒐集在一起，

00:05:43.000 --> 00:05:44.000
並將它們連結起來。

00:05:44.000 --> 00:05:46.000
當所有這些圖片交織在一起時，

00:05:46.000 --> 00:05:47.000
所衍生出的東西，

00:05:47.000 --> 00:05:49.000
要遠遠超過各部件的總和，

00:05:49.000 --> 00:05:51.000
這個模型所衍生出的，是整個地球。

00:05:51.000 --> 00:05:56.000
將之想像是 Stephen Lawler《虛擬地球》的長尾市場。（Stephen Lawler 是微軟「虛擬地球」專案主管）

00:05:56.000 --> 00:05:58.000
這類模型， 會隨著人們的

00:05:58.000 --> 00:06:01.000
使用而不斷變得更複雜，

00:06:01.000 --> 00:06:03.000
變得更加有價值。

00:06:03.000 --> 00:06:05.000
用戶的照片，會被其他人

00:06:05.000 --> 00:06:06.000
輸入標注資料。

00:06:07.000 --> 00:06:10.000
如果有人願意，為聖母院裡的所有聖賢輸入標注，

00:06:10.000 --> 00:06:13.000
表明他們是誰，那我們聖母院的照片便會

00:06:13.000 --> 00:06:15.000
一下子增加了許多資訊，

00:06:15.000 --> 00:06:18.000
然後呢，我們便能以這張照片為起點，進入這個空間，

00:06:18.000 --> 00:06:20.000
這個由很多人的照片所搭建的虛擬世界，

00:06:21.000 --> 00:06:23.000
從而得到一種跨越模型，

00:06:25.000 --> 00:06:28.000
跨越用戶的社交體驗。

00:06:28.000 --> 00:06:29.000
當然了，這一切所帶來另外一個寶貴產物便是，

00:06:30.000 --> 00:06:32.000
我們擁有地球上每一個有趣的地方，

00:06:32.000 --> 00:06:34.000
非常豐富的模型。

00:06:35.000 --> 00:06:38.000
這些模型的資料來源，不再僅限於空拍或衛星照片等等，

00:06:38.000 --> 00:06:40.000
而是來自全人類的集合記憶。

00:06:40.000 --> 00:06:42.000
非常感謝！

00:06:42.000 --> 00:06:53.000
（掌聲）

00:06:53.000 --> 00:06:57.000
Chris Anderson: 如果我理解正確的話，你們的這個軟體將能夠

00:06:58.000 --> 00:07:00.000
在未來的幾年內，

00:07:01.000 --> 00:07:05.000
將來自全球網路使用者所共享的照片

00:07:05.000 --> 00:07:07.000
結合在一起？

00:07:07.000 --> 00:07:09.000
BAA:是的。這個軟體的真正意義便是去探索，

00:07:09.000 --> 00:07:12.000
它在照片間建立超鏈結。

00:07:12.000 --> 00:07:13.000
這個結合的過程，

00:07:13.000 --> 00:07:14.000
完全是基於照片的內容。

00:07:14.000 --> 00:07:17.000
更令人興奮的

00:07:17.000 --> 00:07:19.000
在於照片所包含的大量文字語義資訊。

00:07:19.000 --> 00:07:21.000
譬如，你在網路上搜尋一張照片，

00:07:22.000 --> 00:07:24.000
鍵入關鍵字後，網頁上的文字內容

00:07:24.000 --> 00:07:27.000
將包含大量與這個照片相關的資訊。

00:07:27.000 --> 00:07:29.000
現在，假設這些照片，全部都與你的照片互相連結，那將會怎樣？

00:07:29.000 --> 00:07:31.000
那時，所有這些語義資訊相互連結的

00:07:31.000 --> 00:07:32.000
資訊量將是

00:07:32.000 --> 00:07:35.000
非常巨大的。這是非常典型的網路效應。

00:07:35.000 --> 00:07:37.000
CA:Blaise， 太難以置信了。祝賀你們！

00:07:37.000 --> 00:07:38.000
BAA: 非常感謝各位！

