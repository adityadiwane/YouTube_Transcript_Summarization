WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Juliette Hettema
Nagekeken door: Els De Keyser

00:00:15.260 --> 00:00:18.260
Al sinds ik een klein meisje was

00:00:18.260 --> 00:00:20.260
en Star Wars voor het eerst zag,

00:00:20.260 --> 00:00:22.260
ben ik gefascineerd geraakt door het idee

00:00:22.260 --> 00:00:24.260
van huishoudelijke robots.

00:00:24.260 --> 00:00:26.260
Als klein meisje

00:00:26.260 --> 00:00:28.260
hield ik van het idee van een robot die communiceert met ons

00:00:28.260 --> 00:00:31.260
als een behulpzame en vertrouwde 'sidekick'

00:00:31.260 --> 00:00:33.260
iets dat ons pleziert en onze leven verrijkt

00:00:33.260 --> 00:00:36.260
en ons helpt een melkweg of twee te redden.

00:00:37.260 --> 00:00:40.260
Ik wist dat zulk soort robots niet echt bestaan,

00:00:40.260 --> 00:00:42.260
maar ik wist dat ik ze wilde bouwen.

00:00:42.260 --> 00:00:44.260
Dus 20 jaren gaan voorbij --

00:00:44.260 --> 00:00:46.260
Nu ben ik Mastersstudent aan het MIT

00:00:46.260 --> 00:00:48.260
waar ik kunstmatige intelligentie studeer.

00:00:48.260 --> 00:00:50.260
Het is 1997,

00:00:50.260 --> 00:00:53.260
en NASA heeft zojuist de eerste robot op Mars doen landen.

00:00:53.260 --> 00:00:56.260
Maar wij hebben nog geen robots in huis, gek genoeg.

00:00:56.260 --> 00:00:58.260
Ik weet nog dat ik dacht

00:00:58.260 --> 00:01:00.260
aan alle redenen waarom dat het geval zou kunnen zijn.

00:01:00.260 --> 00:01:02.260
Maar eentje bleef me het meeste bij.

00:01:02.260 --> 00:01:05.260
Robotica ging vooral over het communiceren met dingen,

00:01:05.260 --> 00:01:07.260
niet met mensen --

00:01:07.260 --> 00:01:09.260
zeker niet op een sociale manier die natuurlijk is voor ons

00:01:09.260 --> 00:01:11.260
en mensen zou helpen met het accepteren van robots

00:01:11.260 --> 00:01:13.260
in ons dagelijks leven.

00:01:13.260 --> 00:01:16.260
Voor mij was dat het ontbrekende deel, wat robots nog niet kunnen doen.

00:01:16.260 --> 00:01:19.260
Dus dat jaar begon ik met het bouwen van een robot, Kismet,

00:01:19.260 --> 00:01:22.260
's werelds eerste sociale robot.

00:01:22.260 --> 00:01:24.260
Drie jaar later --

00:01:24.260 --> 00:01:26.260
na veel programmeren,

00:01:26.260 --> 00:01:28.260
werken met andere studenten in het lab --

00:01:28.260 --> 00:01:30.260
was Kismet klaar om met mensen te communiceren.

00:01:30.260 --> 00:01:32.260
(Video) Wetenschapper: Ik wil je wat laten zien.

00:01:32.260 --> 00:01:34.260
Kismet: (Onzin).

00:01:34.260 --> 00:01:37.260
Wetenschapper: Dit is een horloge dat mijn vriendin me gaf.

00:01:37.260 --> 00:01:39.260
Kismet: (Onzin).

00:01:39.260 --> 00:01:41.260
Wetenschapper: Ja, kijk, er zit ook een klein blauw lichtje in.

00:01:41.260 --> 00:01:44.260
Ik was het bijna kwijtgeraakt deze week.

00:01:44.260 --> 00:01:47.260
Cynthia Breazeal: Dus Kismet communiceert met mensen

00:01:47.260 --> 00:01:50.260
zoals een non-verbaal kind of een pre-verbaal kind,

00:01:50.260 --> 00:01:53.260
wat eigenlijk best goed past aangezien hij de eerste van zijn soort is.

00:01:53.260 --> 00:01:55.260
Hij sprak geen taal, maar dat maakte niet uit.

00:01:55.260 --> 00:01:57.260
Deze kleine robot kon op een of andere manier

00:01:57.260 --> 00:02:00.260
op een diepere sociale manier met ons omgaan.

00:02:00.260 --> 00:02:02.260
En daarmee kwam een belofte van een geheel nieuwe manier

00:02:02.260 --> 00:02:04.260
waarop we kunnen omgaan met robots.

00:02:04.260 --> 00:02:06.260
Dus de laatste paar jaren

00:02:06.260 --> 00:02:08.260
ben ik me verder gaan verdiepen in deze interpersoonlijke dimensie van robots,

00:02:08.260 --> 00:02:10.260
nu in het media lab

00:02:10.260 --> 00:02:12.260
samen met mijn team van ongelofelijk getalenteerde studenten.

00:02:12.260 --> 00:02:15.260
Een van mijn favoriete robots is Leonardo.

00:02:15.260 --> 00:02:18.260
We hebben Leonardo ontwikkeld in samenwerking met Stan Winston Studio.

00:02:18.260 --> 00:02:21.260
Ik toon jullie graag één van Leo's momenten die me nauw aan het hart liggen.

00:02:21.260 --> 00:02:23.260
Dit is Matt Berlin terwijl hij communiceert met Leo/

00:02:23.260 --> 00:02:25.260
Hij stelt hem voor aan een nieuw voorwerp.

00:02:25.260 --> 00:02:28.260
En omdat het nieuw is, weet Leo niet wat hij er van moet vinden.

00:02:28.260 --> 00:02:30.260
Maar zoals wij dat kunnen, kan hij er toch wat van leren,

00:02:30.260 --> 00:02:33.260
door de reacties van Matt te observeren.

00:02:33.260 --> 00:02:35.260
(Video) Matt Berlin: Hallo, Leo.

00:02:38.260 --> 00:02:41.260
Leo, dit is Koekjesmonster.

00:02:44.260 --> 00:02:47.260
Kun je Koekjesmonster vinden?

00:02:52.260 --> 00:02:55.260
Leo, Koekjesmonster is erg stout.

00:02:56.260 --> 00:02:58.260
Hij is heel stout, Leo.

00:03:00.260 --> 00:03:03.260
Koekjesmonster is heel, heel stout.

00:03:07.260 --> 00:03:09.260
Hij is een eng monster.

00:03:09.260 --> 00:03:11.260
Hij wil je koekjes hebben.

00:03:12.260 --> 00:03:14.260
(Gelach)

00:03:14.260 --> 00:03:17.260
CB: Ok, dus Leo en Koekjesmonster

00:03:17.260 --> 00:03:19.260
hebben misschien niet de beste introductie gehad,

00:03:19.260 --> 00:03:22.260
maar ze kunnen het nu goed met elkaar vinden.

00:03:22.260 --> 00:03:24.260
Dus wat ik geleerd heb

00:03:24.260 --> 00:03:26.260
door het bouwen van deze systemen,

00:03:26.260 --> 00:03:28.260
is dat robots eigenlijk

00:03:28.260 --> 00:03:30.260
een hele fascinerende sociale technologie zijn.

00:03:30.260 --> 00:03:32.260
Vooral hun vermogen om

00:03:32.260 --> 00:03:34.260
sociaal op ons in te spelen

00:03:34.260 --> 00:03:36.260
en met ons te communiceren als een gelijke,

00:03:36.260 --> 00:03:39.260
dat is de kern van hun functionaliteit.

00:03:39.260 --> 00:03:41.260
Met die verandering van denken kunnen we ons nu

00:03:41.260 --> 00:03:44.260
nieuwe vragen en nieuwe mogelijkheden voor robots voorstellen

00:03:44.260 --> 00:03:47.260
waar we eerder misschien nooit aan gedacht zouden hebben.

00:03:47.260 --> 00:03:49.260
Maar wat bedoel ik als ik zeg 'sociaal op ons inspelen'?

00:03:49.260 --> 00:03:51.260
Eén van de dingen die we geleerd hebben,

00:03:51.260 --> 00:03:53.260
is dit: als we robots ontwerpen om met ons te communiceren

00:03:53.260 --> 00:03:55.260
met dezelfde lichaamstaal,

00:03:55.260 --> 00:03:57.260
en dezelfde soort non-verbale reacties die mensen gebruiken --

00:03:57.260 --> 00:04:00.260
zoals Nexi, onze humanistiche robot hier doet --

00:04:00.260 --> 00:04:02.260
dan zien we mensen vaak reageren op robots

00:04:02.260 --> 00:04:04.260
zoals ze op mensen reageren.

00:04:04.260 --> 00:04:07.260
Mensen gebruiken deze indicaties om te bepalen hoe overtuigend iemand is,

00:04:07.260 --> 00:04:09.260
hoe leuk, hoe sympathiek,

00:04:09.260 --> 00:04:11.260
en hoe betrouwbaar.

00:04:11.260 --> 00:04:13.260
Het blijkt dat hetzelfde geldt voor robots.

00:04:13.260 --> 00:04:15.260
Het blijkt nu dat

00:04:15.260 --> 00:04:18.260
robots een heel interessant wetenschappelijk werktuig zijn

00:04:18.260 --> 00:04:20.260
om menselijk gedrag te begrijpen.

00:04:20.260 --> 00:04:23.260
Om vragen te beantwoorden zoals: hoe komt het dat we, door een korte ontmoeting,

00:04:23.260 --> 00:04:26.260
kunnen inschatten hoe betrouwbaar de andere persoon is?

00:04:26.260 --> 00:04:29.260
Imitatie schijnt een rol te spelen, maar hoe?

00:04:29.260 --> 00:04:32.260
Gaat het om het nadoen van bepaalde gebaren?

00:04:32.260 --> 00:04:34.260
Het blijkt heel moeilijk te zijn

00:04:34.260 --> 00:04:36.260
om dit te leren of te begrijpen door naar mensen te kijken

00:04:36.260 --> 00:04:39.260
omdat we dit automatisch doen als we communiceren.

00:04:39.260 --> 00:04:41.260
We controleren dit niet voorzichtig, omdat het onbewust is voor ons.

00:04:41.260 --> 00:04:43.260
Maar met een robot kan dit wel.

00:04:43.260 --> 00:04:45.260
Zoals in deze video hier--

00:04:45.260 --> 00:04:48.260
dit is een video uit David DeSteno's lab in Northeastern University.

00:04:48.260 --> 00:04:50.260
Hij is een psycholoog met wie we samenwerken.

00:04:50.260 --> 00:04:53.260
Er is eigenlijk een wetenschapper die zorgvuldig de indicaties van Nexi beheert

00:04:53.260 --> 00:04:56.260
om deze vraag te kunnen bestuderen.

00:04:56.260 --> 00:04:58.260
Het komt erop neer -- dit werkt

00:04:58.260 --> 00:05:00.260
omdat mensen zich gewoon als mensen gedragen

00:05:00.260 --> 00:05:03.260
zelfs wanneer ze met een robot communiceren.

00:05:03.260 --> 00:05:05.260
Dus met die gedachte

00:05:05.260 --> 00:05:07.260
kunnen we ons indenken

00:05:07.260 --> 00:05:10.260
waarvoor we robots kunnen gebruiken.

00:05:10.260 --> 00:05:13.260
Bijvoorbeeld, als robots reageren op non-verbale indicaties,

00:05:13.260 --> 00:05:17.260
dan worden ze misschien een nieuwe coole communicatietechnologie.

00:05:17.260 --> 00:05:19.260
Stel je dit voor:

00:05:19.260 --> 00:05:21.260
Wat dacht je van een robotaccessoire voor je mobiele telefoon?

00:05:21.260 --> 00:05:23.260
Je belt een vriendin, ze zet haar mobiel in een robot,

00:05:23.260 --> 00:05:25.260
en, bam! je bent een IkBot --

00:05:25.260 --> 00:05:28.260
je kunt oogcontact maken, je kunt met je vrienden praten,

00:05:28.260 --> 00:05:30.260
je kan rondbewegen, gebaren maken --

00:05:30.260 --> 00:05:33.260
misschien het beste na echt ergens zijn, of niet?

00:05:33.260 --> 00:05:35.260
Om deze vraag te beantwoorden

00:05:35.260 --> 00:05:38.260
heeft mijn student, Siggy Adalgeirsson, een studie gedaan

00:05:38.260 --> 00:05:41.260
waarbij we menselijke deelnemers in ons lab brachten

00:05:41.260 --> 00:05:43.260
om een collaboratieve taak te doen

00:05:43.260 --> 00:05:45.260
met een medewerker op afstand.

00:05:45.260 --> 00:05:47.260
De taak bevatte dingen zoals

00:05:47.260 --> 00:05:49.260
naar een set objecten kijken op tafel,

00:05:49.260 --> 00:05:52.260
en hun belang bespreken, en hun vermogen om een bepaalde taak te kunnen uitvoeren --

00:05:52.260 --> 00:05:54.260
dit werd uiteindelijk een survivaltaak --

00:05:54.260 --> 00:05:56.260
en ze dan beoordelen op

00:05:56.260 --> 00:05:58.260
hoe waardevol en belangrijk ze dachten dat ze waren.

00:05:58.260 --> 00:06:01.260
De medewerker op afstand was een veldonderzoeker van onze groep.

00:06:01.260 --> 00:06:03.260
Ze gebruikten één van de volgende drie verschillende technologieën

00:06:03.260 --> 00:06:05.260
om met de deelnemers te communiceren.

00:06:05.260 --> 00:06:07.260
De eerste was alleen het scherm.

00:06:07.260 --> 00:06:10.260
Dus dat is net zoals videoconferenties vandaag de dag.

00:06:10.260 --> 00:06:13.260
De tweede was mobiliteit, dus het scherm had een verplaatsbare basis.

00:06:13.260 --> 00:06:16.260
Dit is zoals -- als je bekend bent met telepresence robots --

00:06:16.260 --> 00:06:19.260
dit is een soortgelijke situatie.

00:06:19.260 --> 00:06:21.260
En toen de volledig expressieve IkBot.

00:06:21.260 --> 00:06:23.260
Na de interactie

00:06:23.260 --> 00:06:26.260
vroegen we de deelnemers om de kwaliteit van hun gesprekken te beoordelen

00:06:26.260 --> 00:06:28.260
met de technologie, met een medewerker op afstand,

00:06:28.260 --> 00:06:31.260
doormiddel van deze technologie, op verschillende manieren.

00:06:31.260 --> 00:06:33.260
We keken naar psychologische betrokkenheid --

00:06:33.260 --> 00:06:35.260
hoeveel medeleven voelde je voor de andere persoon?

00:06:35.260 --> 00:06:37.260
We keken naar de gehele betrokkenheid.

00:06:37.260 --> 00:06:39.260
We keken naar hun wil om mee te werken.

00:06:39.260 --> 00:06:42.260
En dit is wat we zien als je alleen een scherm gebruikt.

00:06:42.260 --> 00:06:45.260
Het blijkt dat als je mobiliteit toevoegt -- rond de tafel kunnen rijden --

00:06:45.260 --> 00:06:47.260
je iets meer stimulatie krijgt.

00:06:47.260 --> 00:06:50.260
En dat krijg je nog meer als je volledige uitdrukkingen toevoegt.

00:06:50.260 --> 00:06:52.260
Dus het ziet er naar uit dat een fysieke sociale aanwezigheid

00:06:52.260 --> 00:06:54.260
echt een groot verschil maakt.

00:06:54.260 --> 00:06:57.260
Laten we dit nu in wat meer context plaatsen.

00:06:57.260 --> 00:07:00.260
We weten dat families steeds verder bij elkaar vandaan wonen,

00:07:00.260 --> 00:07:02.260
en dat dit vaak een tol eist voor de onderlinge relaties

00:07:02.260 --> 00:07:04.260
en familiebanden over deze afstand.

00:07:04.260 --> 00:07:06.260
Ikzelf heb drie jonge zonen,

00:07:06.260 --> 00:07:08.260
en ik wil dat ze een hele goede relatie hebben

00:07:08.260 --> 00:07:10.260
met hun grootouders.

00:07:10.260 --> 00:07:12.260
Maar mijn ouders wonen op duizenden kilometer afstand van ons,

00:07:12.260 --> 00:07:14.260
dus ze zien elkaar gewoon niet zo vaak.

00:07:14.260 --> 00:07:16.260
We proberen Skype, we proberen telefoongesprekken,

00:07:16.260 --> 00:07:18.260
maar de jongens zijn klein -- ze houden niet zo van praten,

00:07:18.260 --> 00:07:20.260
ze willen spelen.

00:07:20.260 --> 00:07:22.260
Ze vinden het idee van robots

00:07:22.260 --> 00:07:25.260
als een nieuwe speel-op-afstand-technologie geweldig.

00:07:25.260 --> 00:07:28.260
Dus ik stel me voor dat in de nabije toekomst --

00:07:28.260 --> 00:07:30.260
mijn moeder op haar computer

00:07:30.260 --> 00:07:32.260
een browser kan openen en een kleine robot kan inpluggen.

00:07:32.260 --> 00:07:35.260
Als oma-bot

00:07:35.260 --> 00:07:37.260
kan ze nu spelen, echt spelen,

00:07:37.260 --> 00:07:39.260
met mijn zonen, met haar kleinzoons,

00:07:39.260 --> 00:07:42.260
in de echte wereld met zijn echte speelgoed.

00:07:42.260 --> 00:07:44.260
Ik kan me voorstellen dat grootmoeders sociale spelletjes doen

00:07:44.260 --> 00:07:46.260
met hun kleindochters, met hun vrienden,

00:07:46.260 --> 00:07:48.260
en zo allerlei activiteiten in en rond het huis kunnen doen,

00:07:48.260 --> 00:07:50.260
zoals een verhaaltje lezen voor het slapen gaan.

00:07:50.260 --> 00:07:52.260
Door middel van deze technologie

00:07:52.260 --> 00:07:54.260
hebben ze de mogelijkheid actief mee te doen

00:07:54.260 --> 00:07:56.260
in het leven van hun kleinkinderen

00:07:56.260 --> 00:07:58.260
op een manier die vandaag de dag nog niet mogelijk is.

00:07:58.260 --> 00:08:00.260
Denk eens aan andere terreinen,

00:08:00.260 --> 00:08:02.260
zoals gezondheid.

00:08:02.260 --> 00:08:04.260
In de huidige Verenigde Staten

00:08:04.260 --> 00:08:07.260
heeft 65 procent van de mensen overgewicht of zwaarlijvigheid,

00:08:07.260 --> 00:08:09.260
en nu is het ook een groot probleem voor onze kinderen.

00:08:09.260 --> 00:08:11.260
We weten dat naarmate je ouder wordt,

00:08:11.260 --> 00:08:14.260
overgewicht tijdens de jeugd tot chronische ziektes kan leiden

00:08:14.260 --> 00:08:16.260
die niet alleen de kwaliteit van je leven verminderen,

00:08:16.260 --> 00:08:19.260
maar een enorme economische last voor ons gezondheidssysteem betekenen.

00:08:19.260 --> 00:08:21.260
Maar als robots sympathiek kunnen zijn,

00:08:21.260 --> 00:08:23.260
als we het leuk vinden om met robots samen te werken,

00:08:23.260 --> 00:08:25.260
als robots overtuigend zijn,

00:08:25.260 --> 00:08:27.260
kan een robot je misschien helpen

00:08:27.260 --> 00:08:29.260
om een dieet- en trainingsprogramma vol te houden.

00:08:29.260 --> 00:08:32.260
Misschien kunnen ze je helpen om je gewicht te onderhouden.

00:08:32.260 --> 00:08:34.260
Een soort digitale Jiminy (de krekel) --

00:08:34.260 --> 00:08:36.260
zoals in het welbekende sprookje --

00:08:36.260 --> 00:08:38.260
een vriendelijke en steunende aanwezigheid die er altijd is

00:08:38.260 --> 00:08:40.260
om je te helpen de juiste keuzes te maken,

00:08:40.260 --> 00:08:42.260
op de goede manier en op de juiste tijd,

00:08:42.260 --> 00:08:44.260
om gezonde gewoontes aan te nemen.

00:08:44.260 --> 00:08:46.260
Dus we hebben dit idee onderzocht in ons lab.

00:08:46.260 --> 00:08:48.260
Dit is een robot, Autom.

00:08:48.260 --> 00:08:51.260
Cory Kidd heeft deze robot ontworpen voor zijn doctoraal werk.

00:08:51.260 --> 00:08:54.260
Hij was ontworpen als dieet- en bewegingscoach.

00:08:54.260 --> 00:08:56.260
Hij heeft een paar simpele non-verbale vaardigheden.

00:08:56.260 --> 00:08:58.260
Hij kan oogcontact met je maken.

00:08:58.260 --> 00:09:00.260
Hij kan informatie delen op een scherm.

00:09:00.260 --> 00:09:02.260
Je gebruikt een scherm om informatie in te voeren,

00:09:02.260 --> 00:09:04.260
zoals hoeveel calorieën je die dag hebt gegeten,

00:09:04.260 --> 00:09:06.260
hoeveel lichaamsbeweging je hebt gehad.

00:09:06.260 --> 00:09:08.260
Hij kan dit bijhouden voor je.

00:09:08.260 --> 00:09:10.260
De robot sprak met een synthetische stem

00:09:10.260 --> 00:09:12.260
om je te laten deelnemen aan een coachingsgesprek,

00:09:12.260 --> 00:09:14.260
zoals echte trainers zouden doen

00:09:14.260 --> 00:09:16.260
en patiënten en zo voort.

00:09:16.260 --> 00:09:18.260
Hij zou een werkrelatie met je opbouwen

00:09:18.260 --> 00:09:20.260
door middel van die dialogen.

00:09:20.260 --> 00:09:22.260
Hij kan je helpen doelen te stellen en je voortgang bij te houden,

00:09:22.260 --> 00:09:24.260
en hij zal je motiveren.

00:09:24.260 --> 00:09:26.260
Een interessante vraag is:

00:09:26.260 --> 00:09:29.260
is de personificatie echt van belang? Maakt het uit dat het een robot is?

00:09:29.260 --> 00:09:32.260
Is het echt alleen de kwaliteit van het advies en de informatie die telt?

00:09:32.260 --> 00:09:34.260
Om die vraag op te lossen,

00:09:34.260 --> 00:09:36.260
hebben we een onderzoek gedaan in de omgeving van Boston

00:09:36.260 --> 00:09:39.260
waar we één van onze drie uitvindingen in de huizen van mensen plaatsten

00:09:39.260 --> 00:09:41.260
voor een aantal weken.

00:09:41.260 --> 00:09:44.260
Eén geval was de robot die je net zag, Autom.

00:09:44.260 --> 00:09:47.260
Een ander was een computer met dezelfde touch-screen interface,

00:09:47.260 --> 00:09:49.260
met precies dezelfde dialogen.

00:09:49.260 --> 00:09:51.260
De kwaliteit van het advies was identiek.

00:09:51.260 --> 00:09:53.260
De derde was gewoon een logboek met pen en papier,

00:09:53.260 --> 00:09:55.260
want dat is de standaard-ingreep die je vaak ziet

00:09:55.260 --> 00:09:58.260
wanneer je een dieet of lichaamsbewegingsprogramma start.

00:09:58.260 --> 00:10:01.260
Dus een van de dingen waar we echt naar wilde kijken,

00:10:01.260 --> 00:10:04.260
was niet hoeveel gewicht mensen verloren,

00:10:04.260 --> 00:10:07.260
maar hoe lang ze communiceerden met de robot.

00:10:07.260 --> 00:10:10.260
Want de uitdaging is niet gewicht verliezen, maar niet aankomen.

00:10:10.260 --> 00:10:13.260
Als je langer kan communiceren met een van deze interventies,

00:10:13.260 --> 00:10:16.260
dan kan dat, potentieel, succes op de lange termijn aangeven.

00:10:16.260 --> 00:10:18.260
Dus het eerste waar ik naar wil kijken, is hoe lang

00:10:18.260 --> 00:10:20.260
mensen communiceerden met deze systemen.

00:10:20.260 --> 00:10:22.260
Het bleek dat de mensen meer met de robot communiceerden,

00:10:22.260 --> 00:10:24.260
beduidend meer,

00:10:24.260 --> 00:10:27.260
ookal was de kwaliteit van het advies identiek aan dat van de computer.

00:10:28.260 --> 00:10:31.260
Toen hij de mensen vroeg hem een cijfer te geven voor de kwaliteit van de samenwerking,

00:10:31.260 --> 00:10:33.260
gaven de mensen de robot een hoger cijfer

00:10:33.260 --> 00:10:35.260
en vertrouwden ze de robot meer.

00:10:35.260 --> 00:10:37.260
(Gelach)

00:10:37.260 --> 00:10:39.260
Als je naar emotionele band kijkt,

00:10:39.260 --> 00:10:41.260
dan was deze compleet anders.

00:10:41.260 --> 00:10:43.260
Mensen gaven de robots een naam.

00:10:43.260 --> 00:10:45.260
Ze kleedden de robots aan .

00:10:45.260 --> 00:10:47.260
(Gelach)

00:10:47.260 --> 00:10:50.260
Toen we ze op kwamen halen aan het einde van het onderzoek,

00:10:50.260 --> 00:10:52.260
kwamen ze zelfs naar de auto om gedag te zeggen tegen de robots.

00:10:52.260 --> 00:10:54.260
Dit deden ze niet met een computer.

00:10:54.260 --> 00:10:56.260
Het laatste waar ik het over wil hebben vandaag,

00:10:56.260 --> 00:10:58.260
is de toekomst van media voor kinderen.

00:10:58.260 --> 00:11:01.260
We weten dat kinderen tegenwoordig veel tijd achter een scherm doorbrengen,

00:11:01.260 --> 00:11:04.260
of dat nu televisie of computerspellen of iets anders is.

00:11:04.260 --> 00:11:07.260
Mijn zoons zijn dol op het beeldscherm. Ze houden van het scherm.

00:11:07.260 --> 00:11:10.260
Maar ik wil dat ze spelen, als moeder wil ik dat ze spelen

00:11:10.260 --> 00:11:12.260
zoals in de echte wereld.

00:11:12.260 --> 00:11:15.260
Dus heb ik een nieuw project in mijn groep dat ik aan jullie wil presenteren vandaag.

00:11:15.260 --> 00:11:17.260
Het heet Playtime Computing.

00:11:17.260 --> 00:11:19.260
Het denkt echt na over

00:11:19.260 --> 00:11:21.260
wat digitale media zo boeiend maakt.

00:11:21.260 --> 00:11:23.260
Het brengt ze letterlijk van het scherm af

00:11:23.260 --> 00:11:25.260
naar de echte wereld van het kind toe.

00:11:25.260 --> 00:11:28.260
Daar kan het de vele vormen van echt spel aannemen.

00:11:29.260 --> 00:11:33.260
Dus hier is een eerste verkenning van dit idee,

00:11:33.260 --> 00:11:36.260
waar personages fysiek of virtueel kunnen zijn,

00:11:36.260 --> 00:11:38.260
en waar de digitale inhoud

00:11:38.260 --> 00:11:40.260
letterlijk van het scherm af kan komen,

00:11:40.260 --> 00:11:42.260
naar de echte wereld en ook terug.

00:11:42.260 --> 00:11:44.260
Ik zie het graag

00:11:44.260 --> 00:11:46.260
als de Atari Pong

00:11:46.260 --> 00:11:48.260
van dit gemengde realiteitsspel.

00:11:48.260 --> 00:11:50.260
Maar we kunnen dit idee verder uitwerken.

00:11:50.260 --> 00:11:52.260
Wat als --

00:11:52.260 --> 00:11:55.260
(Spel) Nathan: Hier komt het. Yay!

00:11:55.260 --> 00:11:58.260
CB: -- het personage in jouw wereld kan komen?

00:11:58.260 --> 00:12:00.260
Het blijkt dat kinderen dat geweldig vinden

00:12:00.260 --> 00:12:03.260
wanneer de personages echt worden en in hun wereld binnenkomen.

00:12:03.260 --> 00:12:05.260
Als het in hun wereld is,

00:12:05.260 --> 00:12:07.260
kunnen ze er een band mee scheppen en ermee spelen op een manier

00:12:07.260 --> 00:12:09.260
die fundamenteel anders is van wanneer ze spelen op een beeldscherm.

00:12:09.260 --> 00:12:11.260
Een ander belangrijk idee is de notie

00:12:11.260 --> 00:12:14.260
van standvastigheid van het personage in alle realiteiten.

00:12:14.260 --> 00:12:16.260
Aanpassingen die kinderen doen in de echte wereld,

00:12:16.260 --> 00:12:18.260
moeten worden vertaald naar de virtuele wereld.

00:12:18.260 --> 00:12:21.260
Hier heeft Nathan de letter A veranderd in het nummer 2.

00:12:21.260 --> 00:12:23.260
Je kunt je misschien voorstellen dat deze symbolen

00:12:23.260 --> 00:12:26.260
het personage speciale krachten geven als het de virtuele wereld in gaat.

00:12:26.260 --> 00:12:29.260
Dus ze sturen nu het personage terug naar die wereld.

00:12:29.260 --> 00:12:32.260
En nu heeft het 'nummerkracht'.

00:12:32.260 --> 00:12:34.260
Tot slot: wat ik heb geprobeerd te doen,

00:12:34.260 --> 00:12:37.260
is het creeëren van een verdiepende ervaring voor kinderen,

00:12:37.260 --> 00:12:40.260
waarin ze echt voelen dat ze deel uit maken van het verhaal,

00:12:40.260 --> 00:12:42.260
en deel uitmaken van de ervaring.

00:12:42.260 --> 00:12:44.260
Ik wil echt hun fantasie laten spreken

00:12:44.260 --> 00:12:47.260
zoals ik dat ervaarde toen ik 'Star Wars' zag als klein meisje.

00:12:47.260 --> 00:12:49.260
Maar ik wil meer dan alleen dat doen.

00:12:49.260 --> 00:12:52.260
Ik wil dat ze die ervaringen zelf maken.

00:12:52.260 --> 00:12:54.260
Ik wil dat ze letterlijk hun fantasie kunnen bouwen

00:12:54.260 --> 00:12:56.260
in deze ervaringen en deze persoonlijk maken.

00:12:56.260 --> 00:12:58.260
Dus we hebben heel veel ideeën bekeken

00:12:58.260 --> 00:13:00.260
in tele-aanwezigheid en gemengde realiteit

00:13:00.260 --> 00:13:03.260
om letterlijk kinderen hun ideeën te laten projecteren in deze ruimte

00:13:03.260 --> 00:13:05.260
waar andere kinderen mee kunnen doen

00:13:05.260 --> 00:13:07.260
en er verder aan kunnen werken.

00:13:07.260 --> 00:13:10.260
Ik wil echt nieuwe manieren voor media voor kinderen uitvinden,

00:13:10.260 --> 00:13:13.260
die creativiteit, innovatie en leren cultiveren.

00:13:13.260 --> 00:13:16.260
Ik denk dat dat erg, erg belangrijk is.

00:13:16.260 --> 00:13:18.260
Dus dit is een nieuw project.

00:13:18.260 --> 00:13:20.260
We hebben heel veel kinderen uitgenodigd in deze ruimte,

00:13:20.260 --> 00:13:23.260
en ze vinden het best wel cool.

00:13:23.260 --> 00:13:25.260
Maar ik kan je vertellen, wat ze het leukste vinden

00:13:25.260 --> 00:13:27.260
is de robot.

00:13:27.260 --> 00:13:30.260
Waar ze om geven is de robot.

00:13:30.260 --> 00:13:33.260
Robots raken iets menselijks in ons.

00:13:33.260 --> 00:13:35.260
Dus of ze ons nu helpen

00:13:35.260 --> 00:13:37.260
om creatief en innovatief te worden,

00:13:37.260 --> 00:13:39.260
of dat ze ons helpen

00:13:39.260 --> 00:13:41.260
om meer contact te ervaren ondanks grote afstanden,

00:13:41.260 --> 00:13:43.260
of dat ze onze betrouwbaar hulpje zijn

00:13:43.260 --> 00:13:45.260
dat ons helpt onze persoonlijke doelen te bereiken

00:13:45.260 --> 00:13:47.260
en om het beste uit onszelf te halen,

00:13:47.260 --> 00:13:50.260
voor mij draaien robots helemaal om mensen.

00:13:50.260 --> 00:13:52.260
Dankuwel.

00:13:52.260 --> 00:13:57.260
(Applaus)

