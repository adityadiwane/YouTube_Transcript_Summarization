WEBVTT
Kind: captions
Language: de

00:00:00.000 --> 00:00:07.000
Übersetzung: Simone Lackerbauer
Lektorat: Alex Boos

00:00:15.260 --> 00:00:18.260
Schon als ich noch ein kleines Mädchen war

00:00:18.260 --> 00:00:20.260
und zum ersten Mal „Star Wars“ sah,

00:00:20.260 --> 00:00:22.260
war ich von einer Idee fasziniert,

00:00:22.260 --> 00:00:24.260
nämlich von den persönlichen Robotern.

00:00:24.260 --> 00:00:26.260
Und als ein kleines Mädchen

00:00:26.260 --> 00:00:28.260
gefiel mir die Idee eines Roboters, der mit uns interagieren würde,

00:00:28.260 --> 00:00:31.260
vielmehr wie ein hilfreicher, vertrauter Kumpel –

00:00:31.260 --> 00:00:33.260
etwas, das uns entzücken würde, unser Leben bereichern würde

00:00:33.260 --> 00:00:36.260
und uns dabei helfen würde, die eine oder andere Galaxie zu retten.

00:00:37.260 --> 00:00:40.260
Ich wusste also, dass solche Roboter nicht wirklich existierten,

00:00:40.260 --> 00:00:42.260
aber ich wusste, dass ich sie bauen wollte.

00:00:42.260 --> 00:00:44.260
Und so vergehen 20 Jahre –

00:00:44.260 --> 00:00:46.260
ich bin nun Studentin im Aufbaustudium am MIT,

00:00:46.260 --> 00:00:48.260
studiere künstliche Intelligenz,

00:00:48.260 --> 00:00:50.260
wir schreiben das Jahr 1997

00:00:50.260 --> 00:00:53.260
und die Nasa hat gerade den ersten Roboter auf den Mars gebracht.

00:00:53.260 --> 00:00:56.260
Aber ironischerweise gibt es in unserem Zuhause immer noch keine Roboter.

00:00:56.260 --> 00:00:58.260
Und ich erinnere mich daran, über all die Gründe

00:00:58.260 --> 00:01:00.260
nachgedacht zu haben, warum das der Fall war.

00:01:00.260 --> 00:01:02.260
Aber einer davon ist mir sofort aufgefallen.

00:01:02.260 --> 00:01:05.260
Bei der Robotertechnik war es immer darum gegangen, mit Dingen zu interagieren,

00:01:05.260 --> 00:01:07.260
nicht mit Menschen –

00:01:07.260 --> 00:01:09.260
mit Sicherheit nicht auf eine soziale Art, die natürlich für uns wäre

00:01:09.260 --> 00:01:11.260
und den Menschen wirklich dabei helfen würde, Roboter zu akzeptieren

00:01:11.260 --> 00:01:13.260
als Bestandteil unseres täglichen Lebens.

00:01:13.260 --> 00:01:16.260
Für mich war das der Leerraum, das war es, was Roboter noch nicht tun konnten.

00:01:16.260 --> 00:01:19.260
In diesem Jahr also begann ich diesen Roboter zu bauen, Kismet,

00:01:19.260 --> 00:01:22.260
den ersten sozialen Roboter der Welt

00:01:22.260 --> 00:01:24.260
Drei Jahre später also –

00:01:24.260 --> 00:01:26.260
nach viel Programmierarbeit,

00:01:26.260 --> 00:01:28.260
während der ich mit anderen Studenden im Labor zusammenarbeitete –

00:01:28.260 --> 00:01:30.260
war Kismet dazu bereit, mit Menschen zu interagieren.

00:01:30.260 --> 00:01:32.260
(Video) Wissenschaftler: Ich möchte dir etwas zeigen.

00:01:32.260 --> 00:01:34.260
Kismet: (Unsinn).

00:01:34.260 --> 00:01:37.260
Wissenschaftler: Das ist die Uhr, die meine Freundin mir geschenkt hat.

00:01:37.260 --> 00:01:39.260
Kismet: (Unsinn).

00:01:39.260 --> 00:01:41.260
Wissenschaftler: Hier, sieh mal, da leuchtet auch ein kleines blaues Licht.

00:01:41.260 --> 00:01:44.260
Ich habe sie diese Woche beinahe verloren.

00:01:44.260 --> 00:01:47.260
Cynthia Breazeal: Kismet interagierte also mit Menschen,

00:01:47.260 --> 00:01:50.260
wie ein Kind ohne Worte, oder bevor es Worte lernt

00:01:50.260 --> 00:01:53.260
und ich denke, dass das gut passte, denn er war wirklich der erste seiner Art.

00:01:53.260 --> 00:01:55.260
Er beherrschte keine Sprache, aber das machte nichts.

00:01:55.260 --> 00:01:57.260
Irgendwie gelang es diesem kleinen Roboter

00:01:57.260 --> 00:02:00.260
Eine tief in uns verwurzelte, soziale Ebene anzuzapfen.

00:02:00.260 --> 00:02:02.260
Und damit das Versprechen einer ganz neuen Art und Weise,

00:02:02.260 --> 00:02:04.260
wie wir mit Robotern interagieren könnten.

00:02:04.260 --> 00:02:06.260
Während der letzten sieben Jahre

00:02:06.260 --> 00:02:08.260
fuhr ich damit fort, diese zwischenmenschliche Dimension der Roboter zu erforschen,

00:02:08.260 --> 00:02:10.260
nun im Media Lab

00:02:10.260 --> 00:02:12.260
mit meinem eigenen Team unglaublich talentierter Studenten.

00:02:12.260 --> 00:02:15.260
Und einer meiner liebsten Roboter ist Leonardo.

00:02:15.260 --> 00:02:18.260
Wir haben Leonardo in Zusammenarbeit mit dem Stan Winston Studio entwickelt.

00:02:18.260 --> 00:02:21.260
Und ich möchte Ihnen einen für mich ganz besonderen Moment von Leo zeigen.

00:02:21.260 --> 00:02:23.260
Das ist Matt Berlin, der mit Leo interagiert,

00:02:23.260 --> 00:02:25.260
Leo mit einem neuen Objekt vertraut macht.

00:02:25.260 --> 00:02:28.260
Und weil es neu ist, weiß Leo noch nichts Rechtes damit anzufangen.

00:02:28.260 --> 00:02:30.260
Aber so wie wir, kann er in gewisser Weise etwas darüber lernen,

00:02:30.260 --> 00:02:33.260
indem er Matts Reaktion beobachtet.

00:02:33.260 --> 00:02:35.260
(Video) Matt Berlin: Hallo Leo.

00:02:38.260 --> 00:02:41.260
Leo, das ist das Krümelmonster.

00:02:44.260 --> 00:02:47.260
Kannst du das Krümelmonster finden?

00:02:52.260 --> 00:02:55.260
Leo, das Krümelmonster ist ganz böse.

00:02:56.260 --> 00:02:58.260
Es ist ganz böse, Leo.

00:03:00.260 --> 00:03:03.260
Das Krümelmonster ist ganz, ganz böse.

00:03:07.260 --> 00:03:09.260
Es ist ein gruseliges Monster.

00:03:09.260 --> 00:03:11.260
Es will deine Kekse stibitzen.

00:03:12.260 --> 00:03:14.260
(Gelächter)

00:03:14.260 --> 00:03:17.260
CB: In Ordnung, also Leo und Krümelmonster

00:03:17.260 --> 00:03:19.260
hatten wahrscheinlich einen schweren Start,

00:03:19.260 --> 00:03:22.260
aber mittlerweile verstehen sie sich bestens.

00:03:22.260 --> 00:03:24.260
Was ich also gelernt habe,

00:03:24.260 --> 00:03:26.260
indem ich diese Systeme konstruiert habe,

00:03:26.260 --> 00:03:28.260
ist, dass Roboter tatsächlich

00:03:28.260 --> 00:03:30.260
eine wirklich verblüffende soziale Technologie sind.

00:03:30.260 --> 00:03:32.260
Dass sie tatsächlich die Fähigkeit besitzen,

00:03:32.260 --> 00:03:34.260
uns auf einer sozialen Ebene anzusprechen

00:03:34.260 --> 00:03:36.260
und mit uns wie ein Partner zu interagieren;

00:03:36.260 --> 00:03:39.260
all das ist Kernbestandteil ihrer Funktionalität.

00:03:39.260 --> 00:03:41.260
Und mit dieser Veränderung unserer Denkweise können wir nun damit beginnen,

00:03:41.260 --> 00:03:44.260
uns neue Fragen und neue Möglichkeiten für Roboter vorzustellen,

00:03:44.260 --> 00:03:47.260
über die wir sonst nicht nachgedacht hätten.

00:03:47.260 --> 00:03:49.260
Aber was meine ich damit, wenn ich sage, dass sie „uns auf einer sozialen Ebene ansprechen“?

00:03:49.260 --> 00:03:51.260
Nun, eines der Dinge, die wir gelernt haben

00:03:51.260 --> 00:03:53.260
ist, dass wenn wir diese Roboter so designen, dass sie mit uns kommunizieren,

00:03:53.260 --> 00:03:55.260
indem sie dieselbe Körpersprache verwenden,

00:03:55.260 --> 00:03:57.260
dieselbe Art von nonverbalen Zeichen, die Menschen verwenden –

00:03:57.260 --> 00:04:00.260
wie es unser humanoider Roboter Nexi hier zeigt –

00:04:00.260 --> 00:04:02.260
dass wir dann sehen, dass die Menschen ähnlich auf Roboter reagieren,

00:04:02.260 --> 00:04:04.260
wie sie auf andere Menschen reagieren.

00:04:04.260 --> 00:04:07.260
Menschen verwenden diese Zeichen, um beispielsweise zu bestimmen, wie überzeugend jemand ist,

00:04:07.260 --> 00:04:09.260
wie sympathisch, wie einnehmend,

00:04:09.260 --> 00:04:11.260
wie vertrauenswürdig.

00:04:11.260 --> 00:04:13.260
Es hat sich herausgestellt, dass das auch für Roboter gilt.

00:04:13.260 --> 00:04:15.260
Es stellt sich jetzt heraus,

00:04:15.260 --> 00:04:18.260
dass Roboter in der Tat zu einem wirklich interessanten neuen wissenschaftlichen Werkzeug werden,

00:04:18.260 --> 00:04:20.260
um menschliches Verhalten zu verstehen.

00:04:20.260 --> 00:04:23.260
Um Fragen zu beantworten, bespielsweise wie es sein kann, dass wir auf Basis einer kurzen Begegnung

00:04:23.260 --> 00:04:26.260
in der Lage dazu sind, einzuschätzen, wie vertrauenswürdig eine andere Person ist?

00:04:26.260 --> 00:04:29.260
Wir glauben, dass Mimikry dabei eine Rolle spielt, aber in welcher Form?

00:04:29.260 --> 00:04:32.260
Ist es das Nachahmen bestimmter Gesten, das den Ausschlag gibt?

00:04:32.260 --> 00:04:34.260
Es stellt sich heraus, dass es wirklich schwer ist,

00:04:34.260 --> 00:04:36.260
das zu erlernen oder zu verstehen, wenn man Menschen beobachtet,

00:04:36.260 --> 00:04:39.260
denn wenn wir interagieren, dann verwenden wir all diese Zeichen automatisch.

00:04:39.260 --> 00:04:41.260
Wir können sie nicht zuverlässig kontrolleren, denn sie geschehen unbewusst für uns.

00:04:41.260 --> 00:04:43.260
Aber mit einem Roboter ist das möglich.

00:04:43.260 --> 00:04:45.260
In diesem Video hier also –

00:04:45.260 --> 00:04:48.260
dieses Video wurde in David DeStenos Labor an der Northeastern University aufgenommen.

00:04:48.260 --> 00:04:50.260
Er ist ein Psychologe, mit dem wir zusammengearbeitet haben.

00:04:50.260 --> 00:04:53.260
Es gibt hier einen Wissenschaftler, der Nexis Zeichensprache sorgfältig kontrolliert,

00:04:53.260 --> 00:04:56.260
um diese Problematik untersuchen zu können.

00:04:56.260 --> 00:04:58.260
Und das Resultat lautet – der Grund, warum das funktioniert, ist –

00:04:58.260 --> 00:05:00.260
weil es sich herausstellt, dass Menschen sich einfach wie Menschne verhalten,

00:05:00.260 --> 00:05:03.260
auch wenn sie mit einem Roboter interagieren.

00:05:03.260 --> 00:05:05.260
Mit dieser Ausschlag gebenden Einsicht

00:05:05.260 --> 00:05:07.260
können wir jetzt damit beginnen,

00:05:07.260 --> 00:05:10.260
uns neue Arten von Anwendungsgebieten für Roboter vorzustellen.

00:05:10.260 --> 00:05:13.260
Zum Beispiel, wenn Roboter auf unsere nonverbalen Zeichen reagieren,

00:05:13.260 --> 00:05:17.260
dann wären sie vielleicht eine coole, neue Kommunikationstechnologie.

00:05:17.260 --> 00:05:19.260
Stellen Sie sich also vor:

00:05:19.260 --> 00:05:21.260
Wie wäre es mit einem Roboter-Accessoire für Ihr Handy?

00:05:21.260 --> 00:05:23.260
Sie rufen Ihre Freundin an, sie platziert ihren Hörer in einem Roboter

00:05:23.260 --> 00:05:25.260
und zack!, sind Sie ein MeBot –

00:05:25.260 --> 00:05:28.260
Sie können Augenkontakt aufnehmen, Sie können mit Ihren Freunden sprechen

00:05:28.260 --> 00:05:30.260
Sie können sich bewegen, Sie können gestikulieren –

00:05:30.260 --> 00:05:33.260
vielleicht das Zweitbeste nach tatsächlicher Anwesenheit, oder?

00:05:33.260 --> 00:05:35.260
Um diese Problematik zu erforschen

00:05:35.260 --> 00:05:38.260
hat mein Student Siggy Adalgeirsson eine Studie angefertigt,

00:05:38.260 --> 00:05:41.260
in der wir menschliche Teilnehmer, Leute, in unser Labor brachten,

00:05:41.260 --> 00:05:43.260
um eine gemeinschaftliche Aufgabe zu erledigen

00:05:43.260 --> 00:05:45.260
mit einem Remote-Projektmitarbeiter.

00:05:45.260 --> 00:05:47.260
Die Aufgabe beinhaltete Punkte

00:05:47.260 --> 00:05:49.260
wie die Betrachtung einer Reihe an Gegenständen auf dem Tisch,

00:05:49.260 --> 00:05:52.260
über die im Hinblick auf ihre Wichtigkeit und Relevanz zum Ausführen einer bestimmten Aufgabe diskutiert wurde –

00:05:52.260 --> 00:05:54.260
schlussendlich wurde das zu einer Überlebensaufgabe –

00:05:54.260 --> 00:05:56.260
und die sie dann bewerten sollten im Hinblick darauf,

00:05:56.260 --> 00:05:58.260
wie wertvoll und wichtig sie ihrer Meinung nach waren.

00:05:58.260 --> 00:06:01.260
Der Remote-Projektmitarbeiter war ein Experimentator aus unserer Gruppe,

00:06:01.260 --> 00:06:03.260
in der sie drei eine von drei verschiedenen Technologien verwendeten,

00:06:03.260 --> 00:06:05.260
um mit den Teilnehmern zu interagieren.

00:06:05.260 --> 00:06:07.260
Die erste war einfach nur der Bildschirm.

00:06:07.260 --> 00:06:10.260
Ganz so wie die heutigen Videokonferenzen.

00:06:10.260 --> 00:06:13.260
Im zweiten Schritt wurde Mobilität hinzugefügt, dabei befand sich der Bildschirm auf einer beweglichen Basis.

00:06:13.260 --> 00:06:16.260
Das ist so wie diese Telepräsenz-Roboter heute, wenn Sie die kennen –

00:06:16.260 --> 00:06:19.260
damit wurde so eine Situation widergespiegelt.

00:06:19.260 --> 00:06:21.260
Und dann der vollständig ausdrucksfähige MeBot.

00:06:21.260 --> 00:06:23.260
Nach diesem Experiment

00:06:23.260 --> 00:06:26.260
baten wir die Menschen, ihre Qualität der Interaktion zu bewerten

00:06:26.260 --> 00:06:28.260
mit der Technologie, mit einem Remote-Projektmitarbeiter,

00:06:28.260 --> 00:06:31.260
über diese Technologie auf verschiedene Arten.

00:06:31.260 --> 00:06:33.260
Wir haben uns die psychologische Einbindung angesehen –

00:06:33.260 --> 00:06:35.260
wie viel Empathie haben Sie für die andere Person gefühlt?

00:06:35.260 --> 00:06:37.260
Wir haben uns das allgemeine Engagement angesehen.

00:06:37.260 --> 00:06:39.260
Wir haben uns ihren Willen zu kooperieren angesehen.

00:06:39.260 --> 00:06:42.260
So sieht das aus, wenn sie nur den Bildschirm verwenden.

00:06:42.260 --> 00:06:45.260
Es stellt sich heraus, dass wenn man Mobilität hinzufügt – die Fähigkeit, um den Tisch herum zu rollen –

00:06:45.260 --> 00:06:47.260
dass man dann einen etwas höheren Anstieg sieht.

00:06:47.260 --> 00:06:50.260
Und man sieht sogar noch einen höheren Anstieg, wenn man die volle Ausdrucksstärke hinzufügt.

00:06:50.260 --> 00:06:52.260
Es scheint also, dass diese physische soziale Verkörperung

00:06:52.260 --> 00:06:54.260
tatsächlich wirklich einen Unterschied macht.

00:06:54.260 --> 00:06:57.260
Versuchen wir nun also, das in einen gewissen Kontext einzubinden.

00:06:57.260 --> 00:07:00.260
Heute wissen wir, dass Familien immer weiter von einander entfernt leben

00:07:00.260 --> 00:07:02.260
und das fordert definitiv seinen Tribut in Bezug auf die Beziehungen innerhalb der Familie

00:07:02.260 --> 00:07:04.260
und die Zusammengehörigkeit der Familie über Distanz.

00:07:04.260 --> 00:07:06.260
Was mich angeht, ich habe drei Jungs

00:07:06.260 --> 00:07:08.260
und ich möchte, dass sie ein wirklich gutes Verhältnis

00:07:08.260 --> 00:07:10.260
zu ihren Großeltern haben.

00:07:10.260 --> 00:07:12.260
Aber meine Eltern leben Tausende von Meilen entfernt,

00:07:12.260 --> 00:07:14.260
also sehen sie einander einfach nicht so oft.

00:07:14.260 --> 00:07:16.260
Wir probieren es mit Skype, wir probieren es mit Telefonaten,

00:07:16.260 --> 00:07:18.260
aber meine Jungs sind ein bisschen – sie wollen nicht wirklich reden,

00:07:18.260 --> 00:07:20.260
sie wollen spielen.

00:07:20.260 --> 00:07:22.260
Sie mögen diesen Gedanken, dass Roboter

00:07:22.260 --> 00:07:25.260
eine neue Art von Spieletechnologie auf Distanz sind.

00:07:25.260 --> 00:07:28.260
Ich stelle mir also einen Moment vor, gar nicht so weit in der Zukunft –

00:07:28.260 --> 00:07:30.260
meine Mutter kann an ihren Computer gehen,

00:07:30.260 --> 00:07:32.260
einen Browser öffnen und sich in einen kleinen Roboter einklinken.

00:07:32.260 --> 00:07:35.260
Und als Oma-Bot

00:07:35.260 --> 00:07:37.260
kann sie jetzt spielen, wirklich spielen

00:07:37.260 --> 00:07:39.260
mit meinen Söhnen, mit ihren Enkelsöhnen,

00:07:39.260 --> 00:07:42.260
in der realen Welt mit echtem Spielzeug.

00:07:42.260 --> 00:07:44.260
Ich kann mir vorstellen, dass Großmütter soziale Aktivitäten unternehmen können

00:07:44.260 --> 00:07:46.260
mit ihren Enkeltöchtern, mit deren Freunden

00:07:46.260 --> 00:07:48.260
und alle möglichen Aktivitäten im Haus gemeinsam erleben können,

00:07:48.260 --> 00:07:50.260
so als würde man eine Gutenachtgeschichte gemeinsam lesen.

00:07:50.260 --> 00:07:52.260
Und mit dieser Technologie

00:07:52.260 --> 00:07:54.260
können sie so zum aktiven Teilnehmer

00:07:54.260 --> 00:07:56.260
im Leben ihrer Enkelkinder werden,

00:07:56.260 --> 00:07:58.260
auf eine Weise, wie es heute nicht möglich ist.

00:07:58.260 --> 00:08:00.260
Denken wir einmal an ein paar andere Gebiete,

00:08:00.260 --> 00:08:02.260
Gesundheit zum Beispiel.

00:08:02.260 --> 00:08:04.260
In den Vereinigten Staaten sind heute

00:08:04.260 --> 00:08:07.260
über 65 Prozent der Menschen entweder übergewichtig oder fettleibig

00:08:07.260 --> 00:08:09.260
und das ist jetzt auch ein großes Problem bei unseren Kindern.

00:08:09.260 --> 00:08:11.260
Und wir wissen, dass mit zunehmendem Alter

00:08:11.260 --> 00:08:14.260
die Tatsache, dass man als junger Mensch fettleibig war, zu chronischen Krankheiten führen kann,

00:08:14.260 --> 00:08:16.260
die nicht nur die Lebensqualität verringern,

00:08:16.260 --> 00:08:19.260
sondern auch eine unvorstellbare wirtschaftliche Belastung unseres Gesundheitssystems darstellen.

00:08:19.260 --> 00:08:21.260
Aber wenn Roboter zum Mitmachen anregen,

00:08:21.260 --> 00:08:23.260
wenn wir gern mit Robotern zusammenarbeiten,

00:08:23.260 --> 00:08:25.260
wenn Roboter überzeugend sind,

00:08:25.260 --> 00:08:27.260
dann kann ein Roboter einem vielleicht dabei helfen,

00:08:27.260 --> 00:08:29.260
eine Diät und ein Sportprogramm aufrechtzuerhalten,

00:08:29.260 --> 00:08:32.260
vielleicht kann er einem dabei helfen, sein Gewicht zu managen.

00:08:32.260 --> 00:08:34.260
So in etwa wie ein digitaler Jiminy Grille –

00:08:34.260 --> 00:08:36.260
aus dem allseits bekannten Märchen –

00:08:36.260 --> 00:08:38.260
eine Art freundlicher Unterstützer, der stets da ist,

00:08:38.260 --> 00:08:40.260
um einem dabei zu helfen, die richtige Entscheidung zu treffen,

00:08:40.260 --> 00:08:42.260
auf die richtige Art, zur richtigen Zeit,

00:08:42.260 --> 00:08:44.260
um einem dabei zu helfen, sich gesunde Gewohnheiten zuzulegen.

00:08:44.260 --> 00:08:46.260
Wir haben diese Idee dann tatsächlich in unserem Labor erforscht.

00:08:46.260 --> 00:08:48.260
Das ist ein Roboter namens Autom.

00:08:48.260 --> 00:08:51.260
Cory Kidd hat diesen Roboter für seine Doktorarbeit entwickelt.

00:08:51.260 --> 00:08:54.260
Und er war als Roboter-Coach für Diät und Sport erschaffen worden.

00:08:54.260 --> 00:08:56.260
Er hatte ein paar einfache, nonverbale Fähigkeiten, die er ausführen konnte.

00:08:56.260 --> 00:08:58.260
Er konnte Augenkontakt mit einem aufnehmen.

00:08:58.260 --> 00:09:00.260
Er konnte Informationen mitteilen, indem er auf einen Bildschirm sah.

00:09:00.260 --> 00:09:02.260
Man konnte ein Bildschirm-Interface verwenden, um Informationen einzugeben,

00:09:02.260 --> 00:09:04.260
wie viele Kalorien man beispielsweise an diesem Tag gegessen hatte,

00:09:04.260 --> 00:09:06.260
wie viel Sport man getrieben hatte.

00:09:06.260 --> 00:09:08.260
Und dann konnte er einem dabei helfen, das für einen nachzuverfolgen.

00:09:08.260 --> 00:09:10.260
Der Roboter sprach mit einer künstlichen Stimme,

00:09:10.260 --> 00:09:12.260
um einen in ein Beratungsgespräch zu verwickeln,

00:09:12.260 --> 00:09:14.260
entwickelt auf Basis von Trainern

00:09:14.260 --> 00:09:16.260
und Patienten undsoweiter.

00:09:16.260 --> 00:09:18.260
Und er konnte eine stabile Verbindung mit einemeingehen

00:09:18.260 --> 00:09:20.260
über diesen Dialog.

00:09:20.260 --> 00:09:22.260
Er konnte einem dabei Helfen, Ziele zu setzen und den Fortschritt nachzuverfolgen

00:09:22.260 --> 00:09:24.260
und würde dabei helfen, einen zu motivieren.

00:09:24.260 --> 00:09:26.260
Eine interessante Frage ist also,

00:09:26.260 --> 00:09:29.260
ob die soziale Verkörperung wirklich von Bedeutung ist. Ist es von Bedeutung, dass es sich um einen Roboter handelt?

00:09:29.260 --> 00:09:32.260
Ist es wirklich nur die Qualität der Beratung und Information, die von Bedeutung ist?

00:09:32.260 --> 00:09:34.260
Um diese Frage zu beantworten,

00:09:34.260 --> 00:09:36.260
haben wir eine Studie in Boston durchgeführt,

00:09:36.260 --> 00:09:39.260
bei der wir eine von drei Vermittlungstechniken in den Wohnräumen der Menschen

00:09:39.260 --> 00:09:41.260
über einen Zeitraum von mehreren Wochen installierten.

00:09:41.260 --> 00:09:44.260
Einerseits handelte es sich dabei um den Roboter Autom, den sie hier gesehen haben.

00:09:44.260 --> 00:09:47.260
Andererseits gab es einen Computer, der dasselbe Touchscreen-Interface hatte

00:09:47.260 --> 00:09:49.260
und bei dem genau dieselben Dialoge abliefen.

00:09:49.260 --> 00:09:51.260
Die Qualität der Beratung war identisch.

00:09:51.260 --> 00:09:53.260
Und die dritte Möglichkeit war ein einfaches Tagebuch mit Zettel und Stift,

00:09:53.260 --> 00:09:55.260
denn das ist die Standard-Methode, die man normalerweise verwendet,

00:09:55.260 --> 00:09:58.260
wenn man ein Diät- und Sportprogramm beginnt.

00:09:58.260 --> 00:10:01.260
Eine der Sachen, die wir uns wirklich ansehen wollten,

00:10:01.260 --> 00:10:04.260
war nicht, wie viel Gewicht die Menschen verlieren würden,

00:10:04.260 --> 00:10:07.260
sondern wie lange sie mit dem Roboter interagieren würden.

00:10:07.260 --> 00:10:10.260
Denn die Herausforderung besteht nicht darin, Gewicht zu verlieren, sondern eher darin, diesen Status dann zu halten.

00:10:10.260 --> 00:10:13.260
Und je nachdem, ob man sich länger mit einem dieser Vermittler beschäftigen konnte,

00:10:13.260 --> 00:10:16.260
war das ein potenzielles Indiz für einen Langzeiterfolg.

00:10:16.260 --> 00:10:18.260
Die erste Sache, die ich untersuchen wollte, war wie lange

00:10:18.260 --> 00:10:20.260
die Menschen mit diesen Systemen interagierten.

00:10:20.260 --> 00:10:22.260
Es stellte sich heraus, dass die Leute mit dem Roboter

00:10:22.260 --> 00:10:24.260
deutlich länger agierten,

00:10:24.260 --> 00:10:27.260
obwohl die Qualität der Beratung identisch mit der des Computers war.

00:10:28.260 --> 00:10:31.260
Als es die Menschen bat, es im Hinblick auf die Qualität der stabilen Verbindung,

00:10:31.260 --> 00:10:33.260
dann wurde der Roboter besser bewertet

00:10:33.260 --> 00:10:35.260
und sie vertrautem dem Roboter mehr.

00:10:35.260 --> 00:10:37.260
(Gelächter)

00:10:37.260 --> 00:10:39.260
Und wenn man sich die emotionale Bindung ansieht,

00:10:39.260 --> 00:10:41.260
war es komplett anders.

00:10:41.260 --> 00:10:43.260
Die Menschen gaben den Robotern Namen.

00:10:43.260 --> 00:10:45.260
Sie haben sie angekleidet.

00:10:45.260 --> 00:10:47.260
(Gelächter)

00:10:47.260 --> 00:10:50.260
Und als wir kamen, um die Roboter am Ender der Studie abzuholen,

00:10:50.260 --> 00:10:52.260
kamen sie sogar mit zum Auto und verabschiedeten sich von den Robotern

00:10:52.260 --> 00:10:54.260
Mit einem Computer haben sie das nicht gemacht.

00:10:54.260 --> 00:10:56.260
Die letzte Sache, über die ich heute sprechen möchte,

00:10:56.260 --> 00:10:58.260
ist die Zukunft der Medien für Kinder.

00:10:58.260 --> 00:11:01.260
Wir wissen, dass Kinder heutzutage eine Menge Zeit vor Bildschirmen verbringen,

00:11:01.260 --> 00:11:04.260
ob das nun der Fernseher, oder ein Computerspiel, oder was auch immer sonst ist.

00:11:04.260 --> 00:11:07.260
Meine Söhne lieben den Bildschirm. Sie lieben den Bildschirm.

00:11:07.260 --> 00:11:10.260
Aber ich möchte, dass sie spielen; als ihre Mutter möchte ich, dass sie spielen,

00:11:10.260 --> 00:11:12.260
in der realen Welt spielen.

00:11:12.260 --> 00:11:15.260
Und deshalb gibt es in meiner Gruppe ein neues Projekt, das ich Ihnen heute präsentieren möchte,

00:11:15.260 --> 00:11:17.260
es heißt Playtime Computing,

00:11:17.260 --> 00:11:19.260
bei dem es darum geht, zu versuchen darüber nachzudenken,

00:11:19.260 --> 00:11:21.260
was an digitalen Medien so vereinnahmend ist

00:11:21.260 --> 00:11:23.260
und es sprichwörtlich vom Bildschirm wegzunehmen,

00:11:23.260 --> 00:11:25.260
in die reale Welt des Kindes zu integrieren,

00:11:25.260 --> 00:11:28.260
wo es viele Eigenschaften des Spielens in der echten Welt übernehmen kann.

00:11:29.260 --> 00:11:33.260
Hier sehen wir also die erste Herangehensweise an diese Idee,

00:11:33.260 --> 00:11:36.260
bei der Charaktere physisch oder virtuell anwesend sein können

00:11:36.260 --> 00:11:38.260
und bei der digitale Inhalte

00:11:38.260 --> 00:11:40.260
sprichwörtlich aus dem Bildschirm herauskommen,

00:11:40.260 --> 00:11:42.260
in die reale Welt und wieder zurück.

00:11:42.260 --> 00:11:44.260
Ich sehe das gern

00:11:44.260 --> 00:11:46.260
wie das Pong von Atari

00:11:46.260 --> 00:11:48.260
dieses Spiels mit überschneidenden Realitäten.

00:11:48.260 --> 00:11:50.260
Aber wir können diese Idee noch weiter vorantreiben

00:11:50.260 --> 00:11:52.260
Was wäre, wenn –

00:11:52.260 --> 00:11:55.260
(Spiel) Nathan: Da kommt er. Juhu!

00:11:55.260 --> 00:11:58.260
CB: – der Charakter selbst in unsere Welt kommen könnte?

00:11:58.260 --> 00:12:00.260
Es stellt sich heraus, dass Kinder es lieben

00:12:00.260 --> 00:12:03.260
wenn ein Charakter real wird und ihre Welt betritt.

00:12:03.260 --> 00:12:05.260
Und wenn er in ihrer Welt ist,

00:12:05.260 --> 00:12:07.260
dann können sie eine Beziehung mit ihm aufbauen und mit ihm ganz anders spielen,

00:12:07.260 --> 00:12:09.260
als sie mit ihm auf dem Bildschirm spielen würden.

00:12:09.260 --> 00:12:11.260
Eine andere wichtige Idee ist diese Vorstellung

00:12:11.260 --> 00:12:14.260
der realitätsübergreifenden Persistenz des Charakters.

00:12:14.260 --> 00:12:16.260
Also müssen Änderungen, welche die Kinder in der realen Welt vornehmen,

00:12:16.260 --> 00:12:18.260
in die virtuelle Welt übersetzt werden.

00:12:18.260 --> 00:12:21.260
Hier also ändert Nathan den Buchstaben A in die Ziffer 2.

00:12:21.260 --> 00:12:23.260
Man kann sich vorstellen, dass diese Symbole

00:12:23.260 --> 00:12:26.260
den Charakteren besondere Fähigkeiten in der virtuellen Welt geben.

00:12:26.260 --> 00:12:29.260
Jetzt schicken sie also den Charakter zurück in diese Welt.

00:12:29.260 --> 00:12:32.260
Und jetzt hat er die besondere Fähigkeit dieser Ziffer.

00:12:32.260 --> 00:12:34.260
Was ich hier schlussendlich versucht habe zu tun,

00:12:34.260 --> 00:12:37.260
das ist die Erschaffung einer wirklich einbindenden Erfahrung für Kinder,

00:12:37.260 --> 00:12:40.260
bei der sie sich wirklich wie ein Teil der Geschichte fühlen können,

00:12:40.260 --> 00:12:42.260
ein Teil dieser Erfahrung.

00:12:42.260 --> 00:12:44.260
Und ich möchte dabei ihre Fantasie so anregen,

00:12:44.260 --> 00:12:47.260
so wie meine als kleines Mädchen angeregt wurde, als ich „Star Wars“ sah.

00:12:47.260 --> 00:12:49.260
Aber ich möchte mehr tun als das.

00:12:49.260 --> 00:12:52.260
Ich möchte, dass sie ihre Erfahrungen selbst erschaffen.

00:12:52.260 --> 00:12:54.260
Ich möchte, dass sie sprichwörtlich dazu in der Lage sind, ihrer Fantasie freien Lauf zu lassen

00:12:54.260 --> 00:12:56.260
in diesen Erfahrungen und sie so zu ihren eigenen zu machen.

00:12:56.260 --> 00:12:58.260
Wir haben verschiedene Ideen dazu erforscht,

00:12:58.260 --> 00:13:00.260
mit Telepräsenz und in einander greifenden Realitäten,

00:13:00.260 --> 00:13:03.260
um Kindern sprichwörtlich zu erlauben, ihre Ideen in diesen Raum zu projektieren,

00:13:03.260 --> 00:13:05.260
in dem andere Kinder mit ihnen interagieren können

00:13:05.260 --> 00:13:07.260
und darauf aufbauen können.

00:13:07.260 --> 00:13:10.260
Ich möchte wirklich neue Wege erschließen mit Medien für Kinder,

00:13:10.260 --> 00:13:13.260
die Kreativität, Lernprozesse und Innovation fördern.

00:13:13.260 --> 00:13:16.260
Ich denke, dass das sehr, sehr wichtig ist.

00:13:16.260 --> 00:13:18.260
Das ist also ein neues Projekt

00:13:18.260 --> 00:13:20.260
Wir haben viele Kinder in diesen Raum eingeladen

00:13:20.260 --> 00:13:23.260
und sie denken, dass das ziemlich cool ist.

00:13:23.260 --> 00:13:25.260
Aber ich kann Ihnen sagen, dass das, was sie am besten fanden,

00:13:25.260 --> 00:13:27.260
der Roboter war.

00:13:27.260 --> 00:13:30.260
Es ist der Roboter, für den sie sich interessieren.

00:13:30.260 --> 00:13:33.260
Roboter berühren etwas zutiefst Menschliches in uns.

00:13:33.260 --> 00:13:35.260
Ob sie uns dabei helfen,

00:13:35.260 --> 00:13:37.260
kreativ und innovativ zu sein,

00:13:37.260 --> 00:13:39.260
oder ob sie uns dabei helfen,

00:13:39.260 --> 00:13:41.260
dass wir uns trotz Distanz stärker verbunden fühlen,

00:13:41.260 --> 00:13:43.260
oder ob sie unser vertrauter Kumpel sind,

00:13:43.260 --> 00:13:45.260
der uns dabei hilft, unsere persönlichen Ziele zu erreichen,

00:13:45.260 --> 00:13:47.260
das Beste aus unserem Selbst zu machen;

00:13:47.260 --> 00:13:50.260
für mich geht es bei Robotern vor allem um Menschen.

00:13:50.260 --> 00:13:52.260
Vielen Dank.

00:13:52.260 --> 00:13:57.260
(Applaus)

