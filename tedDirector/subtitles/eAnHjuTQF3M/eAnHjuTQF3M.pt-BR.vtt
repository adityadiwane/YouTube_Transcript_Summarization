WEBVTT
Kind: captions
Language: pt-BR

00:00:00.000 --> 00:00:15.260
Tradutor: Francisco Paulino Dubiela
Revisor: Rafael Eufrasio

00:00:15.260 --> 00:00:18.260
Desde que eu era uma menininha

00:00:18.260 --> 00:00:20.260
assistindo "Guerra nas Estrelas" pela primeira vez,

00:00:20.260 --> 00:00:22.260
eu fiquei fascinada com a ideia

00:00:22.260 --> 00:00:24.260
de robôs pessoais.

00:00:24.260 --> 00:00:26.260
E quando era uma menininha,

00:00:26.260 --> 00:00:28.260
eu adorava a ideia de um robô que interagia conosco

00:00:28.260 --> 00:00:31.260
mais como um parceiro útil e confiável –

00:00:31.260 --> 00:00:33.260
algo que iria nos alegrar, enriquecer nossas vidas

00:00:33.260 --> 00:00:36.260
e nos ajudar a salvar uma galáxia ou duas.

00:00:37.260 --> 00:00:40.260
Então eu sabia que robôs não existiam de verdade,

00:00:40.260 --> 00:00:42.260
mas sabia que eu queria contrui-los.

00:00:42.260 --> 00:00:44.260
Então 20 anos se passaram –

00:00:44.260 --> 00:00:46.260
eu sou agora uma pós graduanda no MIT

00:00:46.260 --> 00:00:48.260
estudando inteligência artificial,

00:00:48.260 --> 00:00:50.260
o ano é 1997,

00:00:50.260 --> 00:00:53.260
e a NASA acabou de pousar o primeiro robô em Marte.

00:00:53.260 --> 00:00:56.260
Mas os robôs ainda não estão em nossas casas, ironicamente.

00:00:56.260 --> 00:00:58.260
E eu lembro de pensar sobre

00:00:58.260 --> 00:01:00.260
todas as razões porque isso acontece.

00:01:00.260 --> 00:01:02.260
Mas uma me chamou a atenção.

00:01:02.260 --> 00:01:05.260
A robótica era realmente sobre interagir com coisas,

00:01:05.260 --> 00:01:07.260
não com pessoas –

00:01:07.260 --> 00:01:09.260
certamente não de uma forma social que seria natural para nós

00:01:09.260 --> 00:01:11.260
e realmente ajudaria as pessoas a aceitarem robôs

00:01:11.260 --> 00:01:13.260
em nosso cotidiano.

00:01:13.260 --> 00:01:16.260
Para mim, isso era o espaço branco, é o que os robôs não podiam fazer ainda.

00:01:16.260 --> 00:01:19.260
Então, naquele ano, eu comecei a construir esse robô, Kismet,

00:01:19.260 --> 00:01:22.260
o primeiro robô social.

00:01:22.260 --> 00:01:24.260
Então três anos depois –

00:01:24.260 --> 00:01:26.260
um monte de programação,

00:01:26.260 --> 00:01:28.260
trabalhando com outros pós graduandos no laboratório –

00:01:28.260 --> 00:01:30.260
Kismet estava pronto para começar a interagir com as pessoas.

00:01:30.260 --> 00:01:32.260
(Video) Cientista: Eu quero mostrar algo a você.

00:01:32.260 --> 00:01:34.260
Kismet: (Sem sentido).

00:01:34.260 --> 00:01:37.260
Cientista: Isso é um relógio que minha namorada me deu.

00:01:37.260 --> 00:01:39.260
Kismet: (Sem sentido).

00:01:39.260 --> 00:01:41.260
Cientista: É, olha, ele tem uma luzinha azul também.

00:01:41.260 --> 00:01:44.260
Eu quase o perdi essa semana.

00:01:44.260 --> 00:01:47.260
Cynthia Breazeal: Então o Kismet interagia com as pessoas

00:01:47.260 --> 00:01:50.260
como uma criança não-verbal ou pré-verbal,

00:01:50.260 --> 00:01:53.260
que eu assumo que era conveniente pois era o primeiro do seu tipo.

00:01:53.260 --> 00:01:55.260
Ele não expressava linguagem, mas não importava.

00:01:55.260 --> 00:01:57.260
Esse robozinho era de alguma forma capaz

00:01:57.260 --> 00:02:00.260
de acessar algo profundamente social em nós.

00:02:00.260 --> 00:02:02.260
E com isso, a promessa de uma maneira totalmente nova

00:02:02.260 --> 00:02:04.260
de podermos interagir com robôs.

00:02:04.260 --> 00:02:06.260
Então ao longo dos últimos anos

00:02:06.260 --> 00:02:08.260
eu estive continuando a explorar essa dimensão interpessoal dos robôs,

00:02:08.260 --> 00:02:10.260
agora no laboratório de mídia

00:02:10.260 --> 00:02:12.260
com minha própria equipe de estudantes super talentosos.

00:02:12.260 --> 00:02:15.260
E um dos meus robôs favoritos é o Leonardo.

00:02:15.260 --> 00:02:18.260
Nós desenvolvemos o Leonardo em colaboração com o Stan Winston Studio.

00:02:18.260 --> 00:02:21.260
E quero mostrar a vocês um momento especial do Leo para mim.

00:02:21.260 --> 00:02:23.260
Esse é Matt Berlin interagindo com o Leo,

00:02:23.260 --> 00:02:25.260
apresentando um novo objeto ao Leo.

00:02:25.260 --> 00:02:28.260
E por ser novo, Leo não sabe o que fazer com ele.

00:02:28.260 --> 00:02:30.260
Mas um pouco como nós, ele pode meio que aprender sobre ele

00:02:30.260 --> 00:02:33.260
ao ver a reação do Matt.

00:02:33.260 --> 00:02:35.260
(Video) Matt Berlin: Oi, Leo.

00:02:38.260 --> 00:02:41.260
Leo, esse é o Monstro do Biscoito.

00:02:44.260 --> 00:02:47.260
Você pode achar o Monstro do Biscoito?

00:02:52.260 --> 00:02:55.260
Leo, o Monstro do Biscoito é muito mau.

00:02:56.260 --> 00:02:58.260
Ele é muito mau, Leo.

00:03:00.260 --> 00:03:03.260
O Monstro do Biscoito é muito, muito mau.

00:03:07.260 --> 00:03:09.260
Ele é um monstro assustador.

00:03:09.260 --> 00:03:11.260
Ele quer pegar seus biscoitos.

00:03:12.260 --> 00:03:14.260
(Risos)

00:03:14.260 --> 00:03:17.260
CB: Muito bem, então o Leo e o Monstro

00:03:17.260 --> 00:03:19.260
podem ter tido um começo meio difícil,

00:03:19.260 --> 00:03:22.260
mas eles se dão muito bem agora.

00:03:22.260 --> 00:03:24.260
Então, o que aprendi

00:03:24.260 --> 00:03:26.260
por meio da construção desses sistemas

00:03:26.260 --> 00:03:28.260
é que os robôs são realmente

00:03:28.260 --> 00:03:30.260
uma tecnologia social realmente intrigante.

00:03:30.260 --> 00:03:32.260
Onde realmente está sua habilidade

00:03:32.260 --> 00:03:34.260
de apertar nossos botões sociais

00:03:34.260 --> 00:03:36.260
e interagir conosco como um parceiro

00:03:36.260 --> 00:03:39.260
que é uma peça central de sua funcionalidade.

00:03:39.260 --> 00:03:41.260
E com essa mudança de pensamento, nós podemos agora começar a imaginar

00:03:41.260 --> 00:03:44.260
novas questões, novas possibilidades de robôs

00:03:44.260 --> 00:03:47.260
que podemos não ter pensado de outra forma.

00:03:47.260 --> 00:03:49.260
Mas o que quero dizer quando digo "apertar nossos botões sociais"?

00:03:49.260 --> 00:03:51.260
Bem, uma das coisas que aprendemos

00:03:51.260 --> 00:03:53.260
é que, se nós desenhamos esses robôs para se comunicar conosco

00:03:53.260 --> 00:03:55.260
usando a mesma linguagem corporal,

00:03:55.260 --> 00:03:57.260
meio que as mesmas dicas não-verbais que as pessoas usam –

00:03:57.260 --> 00:04:00.260
como o Nexi, nosso robô humanóide, está fazendo aqui –

00:04:00.260 --> 00:04:02.260
o que nós descobrimos é que as pessoas respondem aos robôs

00:04:02.260 --> 00:04:04.260
de um jeito muito similar como responderiam a pessoas.

00:04:04.260 --> 00:04:07.260
As pessoas usam essas dicas para determinar o quanto alguém é persuasivo,

00:04:07.260 --> 00:04:09.260
o quanto é agradável, o quanto é simpático,

00:04:09.260 --> 00:04:11.260
o quanto é confiável.

00:04:11.260 --> 00:04:13.260
Acontece que é o mesmo com os robôs.

00:04:13.260 --> 00:04:15.260
Agora estamos descobrindo

00:04:15.260 --> 00:04:18.260
que robôs estão se tornando uma nova ferramenta científica interessante

00:04:18.260 --> 00:04:20.260
para compreender o comportamento humano.

00:04:20.260 --> 00:04:23.260
Para responder questões do tipo, como é isso que de um encontro breve,

00:04:23.260 --> 00:04:26.260
nós podemos fazer uma estimativa de quanto a outra pessoa é confiável?

00:04:26.260 --> 00:04:29.260
Acredita-se que a imitação exerce um papel, mas como?

00:04:29.260 --> 00:04:32.260
É a imitação de gestos específicos que importa?

00:04:32.260 --> 00:04:34.260
Acontece que é muito difícil

00:04:34.260 --> 00:04:36.260
aprender ou entender isso observando pessoas

00:04:36.260 --> 00:04:39.260
pois quando interagimos nós fazemos todas essas dicas automaticamente.

00:04:39.260 --> 00:04:41.260
Nós não podemos controlá-las porque elas são subconscientes para nós.

00:04:41.260 --> 00:04:43.260
Mas com o robô você pode.

00:04:43.260 --> 00:04:45.260
E nesse vídeo aqui –

00:04:45.260 --> 00:04:48.260
esse é um vídeo feito no laboratório de David DeSteno na Northeastern University.

00:04:48.260 --> 00:04:50.260
Ele é um psicólogo com quem estamos colaborando.

00:04:50.260 --> 00:04:53.260
Há realmente um cientista controlando cuidadosamente as dicas do Nexi

00:04:53.260 --> 00:04:56.260
para poder estudar essa questão.

00:04:56.260 --> 00:04:58.260
E a conclusão – a razão porque isso funciona –

00:04:58.260 --> 00:05:00.260
é porque as pessoas se comportam como pessoas

00:05:00.260 --> 00:05:03.260
mesmo quando interagem com um robô.

00:05:03.260 --> 00:05:05.260
Então dado esse pensamento chave,

00:05:05.260 --> 00:05:07.260
nós podemos agora começar a imaginar

00:05:07.260 --> 00:05:10.260
novos tipos de aplicações para robôs.

00:05:10.260 --> 00:05:13.260
Por exemplo, se os robôs respondem para nossas dicas não-verbais,

00:05:13.260 --> 00:05:17.260
talvez eles possam ser uma nova tecnologia de comunicação interessante.

00:05:17.260 --> 00:05:19.260
Então imaginem isso:

00:05:19.260 --> 00:05:21.260
Que tal um robô acessório para seu celular?

00:05:21.260 --> 00:05:23.260
Você chama sua amiga, ela coloca seu fone num robô

00:05:23.260 --> 00:05:25.260
e, pronto! Você é um MeBot –

00:05:25.260 --> 00:05:28.260
você pode fazer contato visual, você pode conversar com seus amigos,

00:05:28.260 --> 00:05:30.260
você pode se mover, você pode gesticular –

00:05:30.260 --> 00:05:33.260
talvez melhor do que isso seria realmente estar ali, não é?

00:05:33.260 --> 00:05:35.260
Para explorar essa questão

00:05:35.260 --> 00:05:38.260
meu aluno, Siggy Adalgeirsson, fez um estudo

00:05:38.260 --> 00:05:41.260
onde trouxemos participantes humanos, pessoas, para nosso laboratório

00:05:41.260 --> 00:05:43.260
para fazer uma tarefa colaborativa

00:05:43.260 --> 00:05:45.260
com um colaborador remoto.

00:05:45.260 --> 00:05:47.260
A tarefa envolvia coisas

00:05:47.260 --> 00:05:49.260
como olhar para uma série de objetos sobre a mesa,

00:05:49.260 --> 00:05:52.260
discuti-los em termos de sua importância e relevância para executar uma certa tarefa –

00:05:52.260 --> 00:05:54.260
isso acabou sendo uma tarefa de sobrevivência –

00:05:54.260 --> 00:05:56.260
e depois classificá-los em termos

00:05:56.260 --> 00:05:58.260
de quanto eles pensavam que eram valiosos e importantes.

00:05:58.260 --> 00:06:01.260
O colaborador remoto era um experimentador de nosso grupo

00:06:01.260 --> 00:06:03.260
que usou uma das três tecnologias diferentes

00:06:03.260 --> 00:06:05.260
para interagir com os participantes.

00:06:05.260 --> 00:06:07.260
A primeira era apenas a tela.

00:06:07.260 --> 00:06:10.260
Então é como a videoconferência atual.

00:06:10.260 --> 00:06:13.260
A próxima era para adicionar mobilidade, então temos a tela numa base móvel.

00:06:13.260 --> 00:06:16.260
Isso é como, se você está habituado com esses robôs telepresença de hoje –

00:06:16.260 --> 00:06:19.260
isso é o espelhamento dessa situação.

00:06:19.260 --> 00:06:21.260
E depois o MeBot totalmente expressivo.

00:06:21.260 --> 00:06:23.260
Então depois da interação,

00:06:23.260 --> 00:06:26.260
nós pedimos às pessoas para qualificar sua interação

00:06:26.260 --> 00:06:28.260
com a tecnologia, com um colaborador remoto,

00:06:28.260 --> 00:06:31.260
através dessa tecnologia em diferentes formas.

00:06:31.260 --> 00:06:33.260
Nós observamos o envolvimento psicológico –

00:06:33.260 --> 00:06:35.260
o quanto de empatia você sentiu para com a outra pessoa?

00:06:35.260 --> 00:06:37.260
Nós observamos o envolvimento geral.

00:06:37.260 --> 00:06:39.260
Nós observamos seu desejo de cooperar.

00:06:39.260 --> 00:06:42.260
E isso é que nós vemos quando eles usam apenas a tela.

00:06:42.260 --> 00:06:45.260
Acontece que quando você junta mobilidade – a habilidade de girar na mesa –

00:06:45.260 --> 00:06:47.260
você tem um pequeno aumento.

00:06:47.260 --> 00:06:50.260
E você consegue um aumento ainda maior quando junta a expressão completa.

00:06:50.260 --> 00:06:52.260
Então parece que essa incorporação física social

00:06:52.260 --> 00:06:54.260
realmente faz a diferença.

00:06:54.260 --> 00:06:57.260
Agora vamos tentar colocar isso em nosso contexto.

00:06:57.260 --> 00:07:00.260
Hoje sabemos que as famílias estão vivendo cada vez mais distantes,

00:07:00.260 --> 00:07:02.260
e que isso cria obstáculos para as relações familiares

00:07:02.260 --> 00:07:04.260
e laços familiares à distância.

00:07:04.260 --> 00:07:06.260
Para mim, eu tenho três filhos,

00:07:06.260 --> 00:07:08.260
e eu quero que eles tenham uma boa relação

00:07:08.260 --> 00:07:10.260
com seus avôs.

00:07:10.260 --> 00:07:12.260
Mas meus pais vivem a milhares de quilômetros,

00:07:12.260 --> 00:07:14.260
então eles não se encontram com frequência.

00:07:14.260 --> 00:07:16.260
Nós tentamos o Skype, tentamos chamadas de telefone,

00:07:16.260 --> 00:07:18.260
mas meus filhos – eles não querem conversar,

00:07:18.260 --> 00:07:20.260
eles querem brincar.

00:07:20.260 --> 00:07:22.260
Eles adoram a ideia de pensar sobre robôs

00:07:22.260 --> 00:07:25.260
como um novo tipo de tecnologia de brincar à distância.

00:07:25.260 --> 00:07:28.260
Assim imagino uma época não muito longe da atual –

00:07:28.260 --> 00:07:30.260
minha mãe pode ir a seu computador,

00:07:30.260 --> 00:07:32.260
abrir um navegador e se instalar num pequeno robô.

00:07:32.260 --> 00:07:35.260
Como uma vovó-bô,

00:07:35.260 --> 00:07:37.260
ela pode agora brincar, realmente brincar,

00:07:37.260 --> 00:07:39.260
com meus filhos, com seus netos,

00:07:39.260 --> 00:07:42.260
no mundo real com seus brinquedos reais.

00:07:42.260 --> 00:07:44.260
Eu posso imaginar vovós sendo capazes de brincar em grupo

00:07:44.260 --> 00:07:46.260
com sua netas, com seus amigos,

00:07:46.260 --> 00:07:48.260
e capazes de compartilhar todos os tipos de atividades dentro de casa,

00:07:48.260 --> 00:07:50.260
como contar uma estória para dormir.

00:07:50.260 --> 00:07:52.260
E através dessa tecnologia,

00:07:52.260 --> 00:07:54.260
ser capaz de ser um participante ativo

00:07:54.260 --> 00:07:56.260
nas vidas de seus netos

00:07:56.260 --> 00:07:58.260
de um jeito que não é possível hoje.

00:07:58.260 --> 00:08:00.260
Vamos pensar sobre outros domínios,

00:08:00.260 --> 00:08:02.260
como talvez a saúde.

00:08:02.260 --> 00:08:04.260
Nos Estados Unidos de hoje,

00:08:04.260 --> 00:08:07.260
mais de 65 por cento das pessoas estão ou com sobrepeso ou obesas,

00:08:07.260 --> 00:08:09.260
e agora isso é um grande problema de nossas crianças também.

00:08:09.260 --> 00:08:11.260
E sabemos que quando você cresce,

00:08:11.260 --> 00:08:14.260
se você é obeso quando é jovem, isso pode levar a doenças crônicas

00:08:14.260 --> 00:08:16.260
que não só reduzem sua qualidade de vida,

00:08:16.260 --> 00:08:19.260
mas são um obstáculo econômico para nosso sistema de saúde.

00:08:19.260 --> 00:08:21.260
Mas, se os robôs podem ser envolventes,

00:08:21.260 --> 00:08:23.260
se nós gostamos de cooperar com robôs,

00:08:23.260 --> 00:08:25.260
se os robôs são persuasivos,

00:08:25.260 --> 00:08:27.260
talvez um robô possa ajudar você

00:08:27.260 --> 00:08:29.260
a manter um programa de dieta e exercício,

00:08:29.260 --> 00:08:32.260
talvez eles possam ajudar você a administrar seu peso.

00:08:32.260 --> 00:08:34.260
Então meio como um Grilo Falante digital –

00:08:34.260 --> 00:08:36.260
como o famoso conto-de-fada –

00:08:36.260 --> 00:08:38.260
um tipo de presença amigável e solidária que está sempre lá

00:08:38.260 --> 00:08:40.260
para poder ajudá-lo a fazer a decisão certa

00:08:40.260 --> 00:08:42.260
da forma certa, na hora certa,

00:08:42.260 --> 00:08:44.260
para ajudar você a formar hábitos saudáveis.

00:08:44.260 --> 00:08:46.260
Então nós exploramos essa ideia em nosso laboratório.

00:08:46.260 --> 00:08:48.260
Esse é um robô, Autom.

00:08:48.260 --> 00:08:51.260
Cory Kidd desenvolveu esse robô para seu trabalho de doutorado.

00:08:51.260 --> 00:08:54.260
E ele foi desenhado para ser um robô instrutor de dieta e exercício.

00:08:54.260 --> 00:08:56.260
Ele tinha algumas habilidades não-verbais simples.

00:08:56.260 --> 00:08:58.260
Ele podia fazer contato visual com você.

00:08:58.260 --> 00:09:00.260
Ele podia compartilhar informações ao olhar uma tela.

00:09:00.260 --> 00:09:02.260
Você usa uma interface na tela para colocar informações,

00:09:02.260 --> 00:09:04.260
como quantas calorias você comeu no dia,

00:09:04.260 --> 00:09:06.260
quantos exercícios fez.

00:09:06.260 --> 00:09:08.260
E depois ele podia ajudar a acompanhar isso para você.

00:09:08.260 --> 00:09:10.260
E o robô falava com uma voz sintética

00:09:10.260 --> 00:09:12.260
para envolver você num diálogo de orientação

00:09:12.260 --> 00:09:14.260
modelado por treinadores

00:09:14.260 --> 00:09:16.260
e pacientes e daí por diante.

00:09:16.260 --> 00:09:18.260
E ele podia construir uma aliança construtiva com você

00:09:18.260 --> 00:09:20.260
através desse diálogo.

00:09:20.260 --> 00:09:22.260
Ele podia ajudá-lo a atingir objetivos e acompanhar seu progresso,

00:09:22.260 --> 00:09:24.260
e isso ajudaria a motivá-lo.

00:09:24.260 --> 00:09:26.260
Então uma questão interessante é:

00:09:26.260 --> 00:09:29.260
A incorporação social realmente importa? Importa que seja um robô?

00:09:29.260 --> 00:09:32.260
Importa apenas a qualidade de orientação e informação?

00:09:32.260 --> 00:09:34.260
Para resolver essa questão,

00:09:34.260 --> 00:09:36.260
fizemos um estudo na área de Boston

00:09:36.260 --> 00:09:39.260
onde colocamos três intervenções nos lares das pessoas

00:09:39.260 --> 00:09:41.260
por um período de várias semanas.

00:09:41.260 --> 00:09:44.260
Um caso foi o robô que vocês viram lá, Autom.

00:09:44.260 --> 00:09:47.260
Outro foi um computador que executava a mesma interface de toque na tela,

00:09:47.260 --> 00:09:49.260
executava os mesmos diálogos.

00:09:49.260 --> 00:09:51.260
A qualidade de orientação foi idêntica.

00:09:51.260 --> 00:09:53.260
E o terceiro foi apenas uma caneta e um diário de papel,

00:09:53.260 --> 00:09:55.260
porque essa é a intervenção padrão que você tem

00:09:55.260 --> 00:09:58.260
quando começa um programa de dieta e exercício.

00:09:58.260 --> 00:10:01.260
Uma das coisas que realmente queríamos observar

00:10:01.260 --> 00:10:04.260
não era quanto peso as pessoas perdiam,

00:10:04.260 --> 00:10:07.260
mas quanto tempo elas interagiam com o robô.

00:10:07.260 --> 00:10:10.260
Porque o desafio não é perder peso, é continuar a fazer isso.

00:10:10.260 --> 00:10:13.260
E quanto mais você podia interagir com uma dessas intervenções,

00:10:13.260 --> 00:10:16.260
isso é um indicativo, potencialmente, de sucesso a longo prazo.

00:10:16.260 --> 00:10:18.260
Então a primeira coisa que quis observar é

00:10:18.260 --> 00:10:20.260
quanto tempo as pessoas interagiam com esses sistemas.

00:10:20.260 --> 00:10:22.260
Acontece que as pessoas interagiam significativamente

00:10:22.260 --> 00:10:24.260
mais com o robô,

00:10:24.260 --> 00:10:27.260
ainda que a qualidade de orientação fosse idêntica a do computador.

00:10:28.260 --> 00:10:31.260
Quando era perguntado às pessoas para classificar a qualidade da aliança de trabalho,

00:10:31.260 --> 00:10:33.260
as pessoas classificavam melhor o robô

00:10:33.260 --> 00:10:35.260
e elas confiavam mais no robô.

00:10:35.260 --> 00:10:37.260
(Risos)

00:10:37.260 --> 00:10:39.260
E quando você observa o envolvimento emocional,

00:10:39.260 --> 00:10:41.260
ele era completamente diferente.

00:10:41.260 --> 00:10:43.260
As pessoas davam nomes aos robôs.

00:10:43.260 --> 00:10:45.260
Elas vestiam os robôs.

00:10:45.260 --> 00:10:47.260
(Risos)

00:10:47.260 --> 00:10:50.260
E mesmo quando nós vínhamos para pegar os robôs no fim do estudo,

00:10:50.260 --> 00:10:52.260
elas saiam do carro e diziam adeus aos robôs.

00:10:52.260 --> 00:10:54.260
Eles não faziam isso com um computador.

00:10:54.260 --> 00:10:56.260
A última coisa que quero falar hoje

00:10:56.260 --> 00:10:58.260
é o futuro da mídia infantil.

00:10:58.260 --> 00:11:01.260
Sabemos que as crianças gastam muito tempo na frente das telas hoje,

00:11:01.260 --> 00:11:04.260
seja de uma televisão ou de um jogo de computador.

00:11:04.260 --> 00:11:07.260
Meus filhos, eles amam a tela. Eles adoram a tela.

00:11:07.260 --> 00:11:10.260
Mas eu quero que eles brinquem. Como mãe quero que eles brinquem

00:11:10.260 --> 00:11:12.260
numa brincadeira do mundo real.

00:11:12.260 --> 00:11:15.260
Então eu tenho um novo projeto no meu grupo que quero apresentar a vocês hoje

00:11:15.260 --> 00:11:17.260
chamado Playtime Computing

00:11:17.260 --> 00:11:19.260
que é pensar realmente

00:11:19.260 --> 00:11:21.260
sobre o que é tão envolvente na mídia digital

00:11:21.260 --> 00:11:23.260
e trazer isso literalmente para fora da tela,

00:11:23.260 --> 00:11:25.260
para o mundo real da criança,

00:11:25.260 --> 00:11:28.260
onde pode assumir muitas das propriedades da brincadeira reais.

00:11:29.260 --> 00:11:33.260
Então aqui é a primeira exploração dessa ideia,

00:11:33.260 --> 00:11:36.260
onde os personagens podem ser físicos ou virtuais,

00:11:36.260 --> 00:11:38.260
e onde o conteúdo dgital

00:11:38.260 --> 00:11:40.260
pode sair da tela literalmente,

00:11:40.260 --> 00:11:42.260
para o mundo real e voltar.

00:11:42.260 --> 00:11:44.260
Eu gosto de pensar nisso

00:11:44.260 --> 00:11:46.260
como o Pong do Atari

00:11:46.260 --> 00:11:48.260
dessa brincadeira de realidade misturada.

00:11:48.260 --> 00:11:50.260
Mas nós podemos avançar mais essa ideia.

00:11:50.260 --> 00:11:52.260
E se –

00:11:52.260 --> 00:11:55.260
(Jogo) Nathan: Aí vai. Uau!

00:11:55.260 --> 00:11:58.260
– o próprio personagem pudesse entrar no seu mundo?

00:11:58.260 --> 00:12:00.260
Acontece que as crianças adoram isso

00:12:00.260 --> 00:12:03.260
quando o personagem se torna real e entra no mundo delas.

00:12:03.260 --> 00:12:05.260
E quando ele está no seu mundo,

00:12:05.260 --> 00:12:07.260
elas podem se envolver com isso e brincar num jeito

00:12:07.260 --> 00:12:09.260
que é fundamentalmente diferente de como elas brincavam com isso na tela.

00:12:09.260 --> 00:12:11.260
Outra ideia importante é a noção

00:12:11.260 --> 00:12:14.260
da persistência do personagem entre as realidades.

00:12:14.260 --> 00:12:16.260
Então as transformações que as crianças passam no mundo real

00:12:16.260 --> 00:12:18.260
precisam ser traduzidas no mundo virtual.

00:12:18.260 --> 00:12:21.260
Então aqui, o Nathan mudou a letra A para o número 2.

00:12:21.260 --> 00:12:23.260
Você pode imaginar que talvez esses símbolos

00:12:23.260 --> 00:12:26.260
dão ao personagem poderes especiais quando ele vai para o mundo virtual.

00:12:26.260 --> 00:12:29.260
Então elas estão agora enviando o personagem de volta para aquele mundo.

00:12:29.260 --> 00:12:32.260
E agora ele tem o poder do número.

00:12:32.260 --> 00:12:34.260
E finalmente, o que estive tentando fazer aqui

00:12:34.260 --> 00:12:37.260
é criar uma experiência realmente envolvente para crianças,

00:12:37.260 --> 00:12:40.260
onde elas podem realmente sentir como parte dessa estória,

00:12:40.260 --> 00:12:42.260
um parte dessa experiência.

00:12:42.260 --> 00:12:44.260
E eu realmente quero despertar suas imaginações

00:12:44.260 --> 00:12:47.260
da forma que a minha foi quando era criança assistindo "Guerras nas Estrelas".

00:12:47.260 --> 00:12:49.260
Mas eu quero fazer mais do que isso.

00:12:49.260 --> 00:12:52.260
Na verdade eu quero que elas criem essas experiências.

00:12:52.260 --> 00:12:54.260
Eu quero que elas sejam capazes de construir literalmente sua imaginação

00:12:54.260 --> 00:12:56.260
dentro dessas experiências e fazê-las suas próprias.

00:12:56.260 --> 00:12:58.260
Então estivemos explorando um monte de ideias

00:12:58.260 --> 00:13:00.260
com a telepresença e realidade mista

00:13:00.260 --> 00:13:03.260
para permitir que as crianças projetem suas ideias dentro desse espaço

00:13:03.260 --> 00:13:05.260
onde outras crianças podem interagir com elas

00:13:05.260 --> 00:13:07.260
e construir sobre elas.

00:13:07.260 --> 00:13:10.260
Eu realmente quero mostrar novos caminhos da mídia infantil

00:13:10.260 --> 00:13:13.260
que congregam criatividade e aprendizagem e inovação.

00:13:13.260 --> 00:13:16.260
Eu acho que isso é muito importante.

00:13:16.260 --> 00:13:18.260
Então, esse é um novo projeto.

00:13:18.260 --> 00:13:20.260
Nós convidamos um monte de crianças para esse espaço,

00:13:20.260 --> 00:13:23.260
elas acham que ele é bem legal.

00:13:23.260 --> 00:13:25.260
Mas posso garantir, a coisa que elas mais gostam

00:13:25.260 --> 00:13:27.260
é o robô.

00:13:27.260 --> 00:13:30.260
O que elas adoram é o robô.

00:13:30.260 --> 00:13:33.260
Os robôs tocam algo profundamente humanos em nós.

00:13:33.260 --> 00:13:35.260
E se eles nos ajudam

00:13:35.260 --> 00:13:37.260
a nos tornar criativos e inovadores,

00:13:37.260 --> 00:13:39.260
ou se eles nos ajudam

00:13:39.260 --> 00:13:41.260
a nos sentir mais conectados apesar da distância,

00:13:41.260 --> 00:13:43.260
ou se eles são nossos parceiros confiáveis

00:13:43.260 --> 00:13:45.260
que nos ajudam a alcançar nossos objetivos pessoais

00:13:45.260 --> 00:13:47.260
em nos tornar o melhor de nós mesmos,

00:13:47.260 --> 00:13:50.260
para mim, os robôs são tudo sobre pessoas.

00:13:50.260 --> 00:13:52.260
Obrigada.

00:13:52.260 --> 00:13:57.260
(Aplausos)

