WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Veronica Vera
Revisor: Sebastian Betti

00:00:15.260 --> 00:00:18.260
Desde niña,

00:00:18.260 --> 00:00:20.260
viendo por primera vez la "Guerra de las Galaxias",

00:00:20.260 --> 00:00:22.260
quedé fascinada con la idea

00:00:22.260 --> 00:00:24.260
de los robots personales.

00:00:24.260 --> 00:00:26.260
Y como niña,

00:00:26.260 --> 00:00:28.260
me encantaba la idea de un robot que interactuara con nosotros

00:00:28.260 --> 00:00:31.260
como un secuaz servicial en quien confiar...

00:00:31.260 --> 00:00:33.260
algo que disfrutáramos y enriqueciera nuestras vidas

00:00:33.260 --> 00:00:36.260
y nos ayudara a salvar una o dos galaxias.

00:00:37.260 --> 00:00:40.260
Yo sabía que robots como esos realmente no existían,

00:00:40.260 --> 00:00:42.260
pero sabía que quería construirlos.

00:00:42.260 --> 00:00:44.260
Pasaron 20 años...

00:00:44.260 --> 00:00:46.260
soy estudiante de postgrado en el MIT

00:00:46.260 --> 00:00:48.260
y estudio inteligencia artificial,

00:00:48.260 --> 00:00:50.260
es el año 1997,

00:00:50.260 --> 00:00:53.260
y acaba de descender el primer robot de la NASA en Marte.

00:00:53.260 --> 00:00:56.260
Pero, irónicamente, los robots aún no están en nuestra casa.

00:00:56.260 --> 00:00:58.260
Y recuerdo que pensé

00:00:58.260 --> 00:01:00.260
en todas las razones por las que era así.

00:01:00.260 --> 00:01:02.260
Pero una me llamó la atención.

00:01:02.260 --> 00:01:05.260
La robótica se había ocupado de la interacción con las cosas,

00:01:05.260 --> 00:01:07.260
no con las personas;

00:01:07.260 --> 00:01:09.260
no en una forma social que nos resultara natural

00:01:09.260 --> 00:01:11.260
y ayudara a la gente a aceptar a los robots

00:01:11.260 --> 00:01:13.260
en sus vidas diarias.

00:01:13.260 --> 00:01:16.260
Para mí, eso era una incógnita, algo que los robots no podían hacer todavía.

00:01:16.260 --> 00:01:19.260
Y entonces ese año comencé a construir este robot, Kismet,

00:01:19.260 --> 00:01:22.260
el primer robot social del mundo.

00:01:22.260 --> 00:01:24.260
Así que tres años más tarde...

00:01:24.260 --> 00:01:26.260
y mucha programación mediante,

00:01:26.260 --> 00:01:28.260
trabajando en el laboratorio con otros estudiantes de posgrado

00:01:28.260 --> 00:01:30.260
Kismet estaba listo para empezar a interactuar con la gente.

00:01:30.260 --> 00:01:32.260
(Video) Científico: Quiero mostrarte algo.

00:01:32.260 --> 00:01:34.260
Kismet: (Sin sentido).

00:01:34.260 --> 00:01:37.260
Científico: Este es un reloj que me dio mi novia.

00:01:37.260 --> 00:01:39.260
Kismet: (Sin sentido).

00:01:39.260 --> 00:01:41.260
Científico: Sí, mira, también tiene una lucecita azul.

00:01:41.260 --> 00:01:44.260
Casi lo perdí esta semana.

00:01:44.260 --> 00:01:47.260
Cynthia Breazeal: Así Kismet interactuó con la gente

00:01:47.260 --> 00:01:50.260
como un niño que no habla o que todavía no habla,

00:01:50.260 --> 00:01:53.260
que supongo era apropiado, porque en realidad era el primero de su tipo.

00:01:53.260 --> 00:01:55.260
No hablaba el idioma, pero no importaba.

00:01:55.260 --> 00:01:57.260
Este pequeño robot podía de alguna forma

00:01:57.260 --> 00:02:00.260
calar hondo en nuestro ser social.

00:02:00.260 --> 00:02:02.260
Y era la promesa de una forma totalmente nueva

00:02:02.260 --> 00:02:04.260
de interacción con los robots.

00:02:04.260 --> 00:02:06.260
Así que en los últimos años

00:02:06.260 --> 00:02:08.260
continué explorando esta dimensión interpersonal de los robots,

00:02:08.260 --> 00:02:10.260
ahora en el Media Lab [MIT]

00:02:10.260 --> 00:02:12.260
con mi propio equipo de estudiantes muy talentosos.

00:02:12.260 --> 00:02:15.260
Uno de mis robots favoritos es Leonardo.

00:02:15.260 --> 00:02:18.260
Hemos desarrollado a Leonardo en colaboración con Stan Winston Studio.

00:02:18.260 --> 00:02:21.260
Y quiero mostrarles un momento especial para mí de Leo.

00:02:21.260 --> 00:02:23.260
Este es Matt Berlin interactuando con Leo,

00:02:23.260 --> 00:02:25.260
presentándole a Leo un nuevo objeto.

00:02:25.260 --> 00:02:28.260
Y, como es nuevo, Leo no sabe qué hacer realmente con él.

00:02:28.260 --> 00:02:30.260
Pero, al igual que nosotros, puede aprender

00:02:30.260 --> 00:02:33.260
mirando la reacción de Matt.

00:02:33.260 --> 00:02:35.260
(Video) Matt Berlin: Hola Leo.

00:02:38.260 --> 00:02:41.260
Leo, este es Cookie Monster.

00:02:44.260 --> 00:02:47.260
¿Puedes encontrar a Cookie Monster?

00:02:52.260 --> 00:02:55.260
Leo, Cookie Monster es muy malo.

00:02:56.260 --> 00:02:58.260
Es muy malo, Leo.

00:03:00.260 --> 00:03:03.260
Cookie Monster es muy, muy malo.

00:03:07.260 --> 00:03:09.260
Es un monstruo aterrador.

00:03:09.260 --> 00:03:11.260
Quiere tus galletas.

00:03:12.260 --> 00:03:14.260
(Risas)

00:03:14.260 --> 00:03:17.260
CB: Muy bien, Leo y Cookie

00:03:17.260 --> 00:03:19.260
pueden haber tenido un comienzo difícil

00:03:19.260 --> 00:03:22.260
pero ahora se llevan muy bien.

00:03:22.260 --> 00:03:24.260
Lo que aprendí

00:03:24.260 --> 00:03:26.260
al desarrollar estos sistemas

00:03:26.260 --> 00:03:28.260
es que los robots en realidad son

00:03:28.260 --> 00:03:30.260
una tecnología social fascinante

00:03:30.260 --> 00:03:32.260
donde su capacidad real

00:03:32.260 --> 00:03:34.260
para accionar nuestros resortes sociales

00:03:34.260 --> 00:03:36.260
e interactuar con nosotros como socio

00:03:36.260 --> 00:03:39.260
es una parte central de su funcionalidad.

00:03:39.260 --> 00:03:41.260
Y, con ese cambio de mentalidad, ahora podemos imaginar

00:03:41.260 --> 00:03:44.260
nuevos interrogantes, nuevas posibilidades para los robots

00:03:44.260 --> 00:03:47.260
que de otra forma no habríamos pensado.

00:03:47.260 --> 00:03:49.260
Pero, ¿qué quiero decir con "accionar los resortes sociales"?

00:03:49.260 --> 00:03:51.260
Bien, una de las cosas que he aprendido

00:03:51.260 --> 00:03:53.260
es que, si diseñamos estos robots para comunicarse con nosotros

00:03:53.260 --> 00:03:55.260
usando el mismo tipo de lenguaje,

00:03:55.260 --> 00:03:57.260
el mismo tipo de señales no verbales que usa la gente

00:03:57.260 --> 00:04:00.260
-como Nexi, nuestro robot humanoide lo hace aquí-

00:04:00.260 --> 00:04:02.260
vemos que la gente responde a los robots

00:04:02.260 --> 00:04:04.260
muy similar a como responde a otras personas.

00:04:04.260 --> 00:04:07.260
La gente usa estas señales para determinar cosas como cuán persuasivo es alguien,

00:04:07.260 --> 00:04:09.260
cuán simpático, cuán participativo,

00:04:09.260 --> 00:04:11.260
cuán confiable.

00:04:11.260 --> 00:04:13.260
Resulta que es lo mismo para los robots.

00:04:13.260 --> 00:04:15.260
Ahora está resultando que

00:04:15.260 --> 00:04:18.260
los robots se están convirtiendo en una nueva herramienta científica

00:04:18.260 --> 00:04:20.260
muy interesante para entender el comportamiento humano.

00:04:20.260 --> 00:04:23.260
Para responder a preguntas como: ¿cómo es que, a partir de un breve encuentro,

00:04:23.260 --> 00:04:26.260
somos capaces de estimar cuán confiable es otra persona?

00:04:26.260 --> 00:04:29.260
Se cree que la imitación juega un papel, pero ¿cómo?

00:04:29.260 --> 00:04:32.260
¿Es la imitación de gestos específicos lo que importa?

00:04:32.260 --> 00:04:34.260
Resulta que es muy difícil

00:04:34.260 --> 00:04:36.260
aprender o entender esto de mirar a las personas

00:04:36.260 --> 00:04:39.260
porque cuando nos comunicamos hacemos todas estas señales de forma automática.

00:04:39.260 --> 00:04:41.260
No podemos controlarlas en detalle porque para nosotros son subconscientes.

00:04:41.260 --> 00:04:43.260
Pero con un robot se puede.

00:04:43.260 --> 00:04:45.260
Y así en este video...

00:04:45.260 --> 00:04:48.260
este es un video del laboratorio de David DeSteno en la Universidad de Northeastern.

00:04:48.260 --> 00:04:50.260
Él es un psicólogo con quien hemos estado colaborando.

00:04:50.260 --> 00:04:53.260
Hay un control científico cuidadoso de las señales de Nexi

00:04:53.260 --> 00:04:56.260
para poder estudiar estas preguntas.

00:04:56.260 --> 00:04:58.260
Y la conclusión es -la razón por la que esto funciona es-

00:04:58.260 --> 00:05:00.260
porque resulta que la gente se comporta como gente

00:05:00.260 --> 00:05:03.260
aún interactuando con un robot.

00:05:03.260 --> 00:05:05.260
Considerando esta idea clave,

00:05:05.260 --> 00:05:07.260
ahora podemos empezar a imaginar

00:05:07.260 --> 00:05:10.260
nuevos tipos de aplicaciones para los robots.

00:05:10.260 --> 00:05:13.260
Por ejemplo, si los robots responden a nuestras señales no verbales,

00:05:13.260 --> 00:05:17.260
quizá esa sería una nueva tecnología de comunicación.

00:05:17.260 --> 00:05:19.260
Imaginen esto:

00:05:19.260 --> 00:05:21.260
¿Qué tal un accesorio robot para el móvil?

00:05:21.260 --> 00:05:23.260
Uno llama a una amiga, ella pone su auricular en un robot,

00:05:23.260 --> 00:05:25.260
y ¡chan! uno es MeBot;

00:05:25.260 --> 00:05:28.260
se puede hacer contacto visual, hablar con los amigos,

00:05:28.260 --> 00:05:30.260
moverte, hacer gestos...

00:05:30.260 --> 00:05:33.260
tal vez lo más parecido a estar realmente allí, ¿o no?

00:05:33.260 --> 00:05:35.260
Para explorar este interrogante

00:05:35.260 --> 00:05:38.260
mi estudiante, Siggy Adalgeirsson, hizo un estudio

00:05:38.260 --> 00:05:41.260
donde trajimos participantes humanos, gente, a nuestro laboratorio

00:05:41.260 --> 00:05:43.260
para hacer una tarea colaborativa

00:05:43.260 --> 00:05:45.260
con un colaborador a distancia.

00:05:45.260 --> 00:05:47.260
La tarea implicó cosas como

00:05:47.260 --> 00:05:49.260
mirar un conjunto de objetos sobre una mesa,

00:05:49.260 --> 00:05:52.260
analizarlos en términos de su importancia y pertinencia para realizar una determinada tarea

00:05:52.260 --> 00:05:54.260
-esto terminó siendo una tarea de supervivencia-

00:05:54.260 --> 00:05:56.260
y luego clasificarlos en términos

00:05:56.260 --> 00:05:58.260
de cuán valioso e importante pensaban que eran.

00:05:58.260 --> 00:06:01.260
El colaborador a distancia fue un experimentador de nuestro grupo

00:06:01.260 --> 00:06:03.260
donde se usó una de las tres tecnologías diferentes

00:06:03.260 --> 00:06:05.260
para interactuar con los participantes.

00:06:05.260 --> 00:06:07.260
Así que lo primero fue sólo la pantalla.

00:06:07.260 --> 00:06:10.260
Esto es como la videoconferencia de hoy.

00:06:10.260 --> 00:06:13.260
Lo siguiente fue agregarle movilidad: la pantalla sobre una base móvil.

00:06:13.260 --> 00:06:16.260
Si están familiarizados con algunos de los robots telepresenciales de hoy,

00:06:16.260 --> 00:06:19.260
esto es como un reflejo de esa situación.

00:06:19.260 --> 00:06:21.260
Y luego MeBot completamente expresivo.

00:06:21.260 --> 00:06:23.260
Luego de la interacción

00:06:23.260 --> 00:06:26.260
le pedimos a la gente que calificara su calidad de interacción

00:06:26.260 --> 00:06:28.260
con la tecnología, con el colaborador a distancia,

00:06:28.260 --> 00:06:31.260
a través de esta tecnología en diferentes formas.

00:06:31.260 --> 00:06:33.260
Observamos la participación psicológica:

00:06:33.260 --> 00:06:35.260
¿Cuánta empatía sentiste por la otra persona?

00:06:35.260 --> 00:06:37.260
Observamos la participación general.

00:06:37.260 --> 00:06:39.260
Observamos sus deseos de colaborar.

00:06:39.260 --> 00:06:42.260
Y esto es lo que vemos cuando sólo usan la pantalla.

00:06:42.260 --> 00:06:45.260
Resulta que cuando se agrega movilidad -la capacidad de rodar por la mesa-

00:06:45.260 --> 00:06:47.260
se logra un poco más de estímulo.

00:06:47.260 --> 00:06:50.260
Y aún más si se agrega expresividad completa.

00:06:50.260 --> 00:06:52.260
Pareciera como que esta personificación física social

00:06:52.260 --> 00:06:54.260
realmente marca una diferencia.

00:06:54.260 --> 00:06:57.260
Ahora tratemos de darle a esto un poco de contexto.

00:06:57.260 --> 00:07:00.260
Sabemos que las familias de hoy viven cada vez más separadas

00:07:00.260 --> 00:07:02.260
y definitivamente eso tiene un gran impacto en las relaciones

00:07:02.260 --> 00:07:04.260
y en los lazos familiares en la distancia.

00:07:04.260 --> 00:07:06.260
En mi caso, tengo 3 niños pequeños

00:07:06.260 --> 00:07:08.260
y quiero que tengan una relación muy buena

00:07:08.260 --> 00:07:10.260
con sus abuelos.

00:07:10.260 --> 00:07:12.260
Pero mis padres viven a miles de kilómetros de distancia,

00:07:12.260 --> 00:07:14.260
por lo tanto no se ven con mucha frecuencia.

00:07:14.260 --> 00:07:16.260
Intentamos con Skype, con el teléfono,

00:07:16.260 --> 00:07:18.260
pero mis niños son pequeños; realmente no quieren hablar,

00:07:18.260 --> 00:07:20.260
quieren jugar.

00:07:20.260 --> 00:07:22.260
Les encanta la idea de pensar en los robots

00:07:22.260 --> 00:07:25.260
como un nueva tecnología para jugar a la distancia.

00:07:25.260 --> 00:07:28.260
Así que imagino un tiempo no muy lejano...

00:07:28.260 --> 00:07:30.260
mi madre va a su computadora,

00:07:30.260 --> 00:07:32.260
abre un navegador y se conecta con un pequeño robot.

00:07:32.260 --> 00:07:35.260
Y como abuela-robot,

00:07:35.260 --> 00:07:37.260
ahora puede jugar, realmente jugar,

00:07:37.260 --> 00:07:39.260
con mis hijos, con sus nietos,

00:07:39.260 --> 00:07:42.260
en el mundo real, con sus juguetes reales.

00:07:42.260 --> 00:07:44.260
Imagino a las abuelas pudiendo jugar

00:07:44.260 --> 00:07:46.260
con sus nietas, con sus amigos,

00:07:46.260 --> 00:07:48.260
y pudiendo compartir todo tipo de actividades en la casa,

00:07:48.260 --> 00:07:50.260
como compartir un cuento antes de dormir.

00:07:50.260 --> 00:07:52.260
Y a través de esta tecnología

00:07:52.260 --> 00:07:54.260
participar activamente

00:07:54.260 --> 00:07:56.260
en las vidas de sus nietos

00:07:56.260 --> 00:07:58.260
de una forma que hoy no es posible.

00:07:58.260 --> 00:08:00.260
Pensemos en algunos otros ámbitos

00:08:00.260 --> 00:08:02.260
como ser la salud.

00:08:02.260 --> 00:08:04.260
Hoy en EEUU

00:08:04.260 --> 00:08:07.260
más del 65% de las personas tienen sobrepeso o son obesos,

00:08:07.260 --> 00:08:09.260
y también tenemos un gran problema con los niños.

00:08:09.260 --> 00:08:11.260
Y sabemos que a medida que uno envejece en la vida,

00:08:11.260 --> 00:08:14.260
si de joven fue obeso, puede tener enfermedades crónicas

00:08:14.260 --> 00:08:16.260
que no sólo disminuyen la calidad de vida

00:08:16.260 --> 00:08:19.260
sino que son una enorme carga económica para el sistema de salud.

00:08:19.260 --> 00:08:21.260
Pero si los robots pueden ser interesantes,

00:08:21.260 --> 00:08:23.260
si nos gusta colaborar con los robots,

00:08:23.260 --> 00:08:25.260
si los robots son convincentes,

00:08:25.260 --> 00:08:27.260
tal vez un robot puede ayudar

00:08:27.260 --> 00:08:29.260
a mantener un programa de dieta y ejercicios,

00:08:29.260 --> 00:08:32.260
tal vez puede ayudar a controlar el peso.

00:08:32.260 --> 00:08:34.260
Una especie de Pepito Grillo digital,

00:08:34.260 --> 00:08:36.260
como el muy conocido cuento de hadas,

00:08:36.260 --> 00:08:38.260
un sostén amigable que siempre está ahí

00:08:38.260 --> 00:08:40.260
para ayudar a tomar la decisión correcta

00:08:40.260 --> 00:08:42.260
de la forma correcta, en el momento adecuado,

00:08:42.260 --> 00:08:44.260
para ayudar a formar hábitos saludables.

00:08:44.260 --> 00:08:46.260
Así que exploramos esta idea en nuestro laboratorio.

00:08:46.260 --> 00:08:48.260
Este es un robot, Autom.

00:08:48.260 --> 00:08:51.260
Cory Kidd desarrolló este robot para su trabajo de doctorado.

00:08:51.260 --> 00:08:54.260
Y fue diseñado para ser un consejero de dieta y ejercicios.

00:08:54.260 --> 00:08:56.260
Podía realizar un par de habilidades no verbales simples.

00:08:56.260 --> 00:08:58.260
Podía hacer contacto visual.

00:08:58.260 --> 00:09:00.260
Podía compartir información mirando a una pantalla.

00:09:00.260 --> 00:09:02.260
Uno usaba una interfaz de pantalla para ingreso de datos,

00:09:02.260 --> 00:09:04.260
como la cantidad de calorías consumidas ese día,

00:09:04.260 --> 00:09:06.260
y la cantidad de ejercicio realizado.

00:09:06.260 --> 00:09:08.260
Y entonces podía ayudar en el seguimiento.

00:09:08.260 --> 00:09:10.260
Y el robot hablaba con voz sintética

00:09:10.260 --> 00:09:12.260
para entablar un diálogo de consejero

00:09:12.260 --> 00:09:14.260
modelado a partir de

00:09:14.260 --> 00:09:16.260
entrenadores, pacientes, etc.

00:09:16.260 --> 00:09:18.260
Y construía una alianza de trabajo con uno

00:09:18.260 --> 00:09:20.260
mediante ese diálogo.

00:09:20.260 --> 00:09:22.260
Podía ayudar a fijar objetivos y hacer el seguimiento del progreso,

00:09:22.260 --> 00:09:24.260
y servía de motivación.

00:09:24.260 --> 00:09:26.260
Una pregunta interesante es:

00:09:26.260 --> 00:09:29.260
¿La encarnación social es tan importante? ¿Importa que sea un robot?

00:09:29.260 --> 00:09:32.260
¿Es la calidad del asesoramiento y la información lo que realmente importa?

00:09:32.260 --> 00:09:34.260
Para responder esa pregunta

00:09:34.260 --> 00:09:36.260
hicimos un estudio en el área de Boston

00:09:36.260 --> 00:09:39.260
donde pusimos una de tres intervenciones en los hogares

00:09:39.260 --> 00:09:41.260
durante varias semanas.

00:09:41.260 --> 00:09:44.260
Uno de los casos fue el robot que vieron ahí, Autom.

00:09:44.260 --> 00:09:47.260
Otro fue una computadora que ejecutó la misma interfaz de pantalla táctil,

00:09:47.260 --> 00:09:49.260
ejecutó exactamente los mismos diálogos.

00:09:49.260 --> 00:09:51.260
La calidad del asesoramiento fue idéntico.

00:09:51.260 --> 00:09:53.260
Y el tercero fue un bolígrafo y un anotador,

00:09:53.260 --> 00:09:55.260
porque ese es el material típico utilizado

00:09:55.260 --> 00:09:58.260
al empezar la dieta y el ejercicio.

00:09:58.260 --> 00:10:01.260
Así que una de las cosas que realmente queríamos ver

00:10:01.260 --> 00:10:04.260
no era cuánto adelgazaba la gente,

00:10:04.260 --> 00:10:07.260
sino cuánto interactuaban con el robot.

00:10:07.260 --> 00:10:10.260
Porque el desafío no es adelgazar sino mantenerse.

00:10:10.260 --> 00:10:13.260
Y cuanto más interacción haya con el material

00:10:13.260 --> 00:10:16.260
más probable es el éxito a largo plazo.

00:10:16.260 --> 00:10:18.260
Entonces lo primero que quiero observar

00:10:18.260 --> 00:10:20.260
es cuánto tiempo interactuaba la gente con estos sistemas.

00:10:20.260 --> 00:10:22.260
Resulta que la gente interactuaba con el robot

00:10:22.260 --> 00:10:24.260
mucho más,

00:10:24.260 --> 00:10:27.260
aún cuando la calidad del asesoramiento era idéntico al de la computadora.

00:10:28.260 --> 00:10:31.260
Cuando se pidió a la gente que calificara la calidad de la colaboración,

00:10:31.260 --> 00:10:33.260
el robot tuvo mayor calificación

00:10:33.260 --> 00:10:35.260
y confiaban más en él.

00:10:35.260 --> 00:10:37.260
(Risas)

00:10:37.260 --> 00:10:39.260
Y si miramos la integración emocional

00:10:39.260 --> 00:10:41.260
fue completamente diferente.

00:10:41.260 --> 00:10:43.260
La gente le da nombre a los robots.

00:10:43.260 --> 00:10:45.260
Los visten.

00:10:45.260 --> 00:10:47.260
(Risas)

00:10:47.260 --> 00:10:50.260
Incluso cuando pasábamos a recoger los robots al final del estudio,

00:10:50.260 --> 00:10:52.260
nos acompañaban al auto y les decían adiós a los robots.

00:10:52.260 --> 00:10:54.260
No hacían esto con una computadora.

00:10:54.260 --> 00:10:56.260
Por último quiero hablar

00:10:56.260 --> 00:10:58.260
del futuro de los medios para niños.

00:10:58.260 --> 00:11:01.260
Sabemos que hoy los niños pasan mucho tiempo detrás de las pantallas,

00:11:01.260 --> 00:11:04.260
sean de televisión, o de videojuegos, etc.

00:11:04.260 --> 00:11:07.260
Mis hijos adoran la pantalla. Les encanta.

00:11:07.260 --> 00:11:10.260
Pero quiero que jueguen, como madre quiero que ellos jueguen

00:11:10.260 --> 00:11:12.260
juegos del mundo real.

00:11:12.260 --> 00:11:15.260
Por eso tengo un nuevo proyecto en mi grupo que quiero presentarles hoy

00:11:15.260 --> 00:11:17.260
llamado Playtime Computing [Info Recreo, NT]

00:11:17.260 --> 00:11:19.260
que trata de pensar

00:11:19.260 --> 00:11:21.260
qué es lo interesante de los medios digitales

00:11:21.260 --> 00:11:23.260
y llevarlos, literalmente, fuera de la pantalla,

00:11:23.260 --> 00:11:25.260
hacia el mundo real del niño,

00:11:25.260 --> 00:11:28.260
donde pueda adoptar muchas de las propiedades del juego del mundo real.

00:11:29.260 --> 00:11:33.260
Esta es la primera exploración de esta idea

00:11:33.260 --> 00:11:36.260
en la que los personajes pueden ser físicos o virtuales,

00:11:36.260 --> 00:11:38.260
y el contenido digital

00:11:38.260 --> 00:11:40.260
literalmente puede salir de la pantalla

00:11:40.260 --> 00:11:42.260
al mundo real y volver.

00:11:42.260 --> 00:11:44.260
Me gusta pensarlo

00:11:44.260 --> 00:11:46.260
como el Atari Pong

00:11:46.260 --> 00:11:48.260
de este juego de realidad híbrida.

00:11:48.260 --> 00:11:50.260
Pero podemos llevar esta idea más lejos.

00:11:50.260 --> 00:11:52.260
¿Qué tal si...

00:11:52.260 --> 00:11:55.260
(Juego) Nathan: Aquí viene. ¡Sí!

00:11:55.260 --> 00:11:58.260
CB: ...el personaje mismo puede entrar a tu mundo?

00:11:58.260 --> 00:12:00.260
Resulta que a las niños les encanta

00:12:00.260 --> 00:12:03.260
cuando el personaje se vuelve real y entra en su mundo.

00:12:03.260 --> 00:12:05.260
Y cuando está en su mundo,

00:12:05.260 --> 00:12:07.260
se pueden relacionar y jugar de una forma

00:12:07.260 --> 00:12:09.260
totalmente diferente a como juegan en la pantalla.

00:12:09.260 --> 00:12:11.260
También es importante esta idea

00:12:11.260 --> 00:12:14.260
de la persistencia del personaje a través de las realidades.

00:12:14.260 --> 00:12:16.260
Así que los cambios que los niños hacen en el mundo real

00:12:16.260 --> 00:12:18.260
deben trasladarse al mundo virtual.

00:12:18.260 --> 00:12:21.260
Aquí, Nathan ha cambiado la letra A por el número 2.

00:12:21.260 --> 00:12:23.260
Imaginen que quizás estos símbolos

00:12:23.260 --> 00:12:26.260
le dan al personaje poderes especiales cuando entra al mundo virtual.

00:12:26.260 --> 00:12:29.260
Así que ahora están enviando de vuelta al personaje a ese mundo.

00:12:29.260 --> 00:12:32.260
Y ahora tiene poder de número.

00:12:32.260 --> 00:12:34.260
Y, finalmente, aquí estoy tratando de

00:12:34.260 --> 00:12:37.260
crear una experiencia realmente inmersiva para los niños,

00:12:37.260 --> 00:12:40.260
donde de verdad se sientan parte de esa historia,

00:12:40.260 --> 00:12:42.260
parte de esa experiencia.

00:12:42.260 --> 00:12:44.260
Y realmente quiero despertar su imaginación

00:12:44.260 --> 00:12:47.260
así como "La Guerra de las Galaxias" despertó mi imaginación.

00:12:47.260 --> 00:12:49.260
Pero quiero hacer más que eso.

00:12:49.260 --> 00:12:52.260
De hecho, quiero que ellos creen esas experiencias.

00:12:52.260 --> 00:12:54.260
Quiero que sean capaces de construir su imaginación

00:12:54.260 --> 00:12:56.260
con estas experiencias y que las hagan propias.

00:12:56.260 --> 00:12:58.260
Para ello hemos estado explorando un montón de ideas

00:12:58.260 --> 00:13:00.260
en telepresencia y realidad híbrida

00:13:00.260 --> 00:13:03.260
para posibilitarles a los niños proyectar sus ideas en este espacio

00:13:03.260 --> 00:13:05.260
donde puedan interactuar con otros niños

00:13:05.260 --> 00:13:07.260
y construir sobre ello.

00:13:07.260 --> 00:13:10.260
Quiero llegar a nuevas formas de medios para niños

00:13:10.260 --> 00:13:13.260
que fomenten la creatividad, el aprendizaje y la innovación.

00:13:13.260 --> 00:13:16.260
Creo que eso es muy, muy importante.

00:13:16.260 --> 00:13:18.260
Así que este es un nuevo proyecto.

00:13:18.260 --> 00:13:20.260
Hemos invitado a muchos niños a este espacio,

00:13:20.260 --> 00:13:23.260
y ellos piensan que está muy bueno.

00:13:23.260 --> 00:13:25.260
Pero debo decirles que lo que más les gusta

00:13:25.260 --> 00:13:27.260
es el robot.

00:13:27.260 --> 00:13:30.260
Lo que les importa es el robot.

00:13:30.260 --> 00:13:33.260
Los robots nos tocan una fibra humana íntima.

00:13:33.260 --> 00:13:35.260
Y ya sea que nos estén ayudando

00:13:35.260 --> 00:13:37.260
a ser más creativos e innovadores,

00:13:37.260 --> 00:13:39.260
o que nos ayuden

00:13:39.260 --> 00:13:41.260
a sentirnos más conectados a pesar de la distancia,

00:13:41.260 --> 00:13:43.260
o que sean los secuaces en quien confiar

00:13:43.260 --> 00:13:45.260
que nos ayudan a lograr nuestras metas personales

00:13:45.260 --> 00:13:47.260
para dar lo mejor de nosotros mismos,

00:13:47.260 --> 00:13:50.260
para mí hablar de robots es hablar de personas.

00:13:50.260 --> 00:13:52.260
Gracias.

00:13:52.260 --> 00:13:57.260
(Aplausos)

