WEBVTT
Kind: captions
Language: en

00:00:15.260 --> 00:00:18.260
Ever since I was a little girl

00:00:18.260 --> 00:00:20.260
seeing "Star Wars" for the first time,

00:00:20.260 --> 00:00:22.260
I've been fascinated by this idea

00:00:22.260 --> 00:00:24.260
of personal robots.

00:00:24.260 --> 00:00:26.260
And as a little girl,

00:00:26.260 --> 00:00:28.260
I loved the idea of a robot that interacted with us

00:00:28.260 --> 00:00:31.260
much more like a helpful, trusted sidekick --

00:00:31.260 --> 00:00:33.260
something that would delight us, enrich our lives

00:00:33.260 --> 00:00:36.260
and help us save a galaxy or two.

00:00:37.260 --> 00:00:40.260
I knew robots like that didn't really exist,

00:00:40.260 --> 00:00:42.260
but I knew I wanted to build them.

00:00:42.260 --> 00:00:44.260
So 20 years pass --

00:00:44.260 --> 00:00:46.260
I am now a graduate student at MIT

00:00:46.260 --> 00:00:48.260
studying artificial intelligence,

00:00:48.260 --> 00:00:50.260
the year is 1997,

00:00:50.260 --> 00:00:53.260
and NASA has just landed the first robot on Mars.

00:00:53.260 --> 00:00:56.260
But robots are still not in our home, ironically.

00:00:56.260 --> 00:00:58.260
And I remember thinking about

00:00:58.260 --> 00:01:00.260
all the reasons why that was the case.

00:01:00.260 --> 00:01:02.260
But one really struck me.

00:01:02.260 --> 00:01:05.260
Robotics had really been about interacting with things,

00:01:05.260 --> 00:01:07.260
not with people --

00:01:07.260 --> 00:01:09.260
certainly not in a social way that would be natural for us

00:01:09.260 --> 00:01:11.260
and would really help people accept robots

00:01:11.260 --> 00:01:13.260
into our daily lives.

00:01:13.260 --> 00:01:16.260
For me, that was the white space; that's what robots could not do yet.

00:01:16.260 --> 00:01:19.260
And so that year, I started to build this robot, Kismet,

00:01:19.260 --> 00:01:22.260
the world's first social robot.

00:01:22.260 --> 00:01:24.260
Three years later --

00:01:24.260 --> 00:01:26.260
a lot of programming,

00:01:26.260 --> 00:01:28.260
working with other graduate students in the lab --

00:01:28.260 --> 00:01:30.260
Kismet was ready to start interacting with people.

00:01:30.260 --> 00:01:32.260
(Video) Scientist: I want to show you something.

00:01:32.260 --> 00:01:34.260
Kismet: (Nonsense)

00:01:34.260 --> 00:01:37.260
Scientist: This is a watch that my girlfriend gave me.

00:01:37.260 --> 00:01:39.260
Kismet: (Nonsense)

00:01:39.260 --> 00:01:41.260
Scientist: Yeah, look, it's got a little blue light in it too.

00:01:41.260 --> 00:01:44.260
I almost lost it this week.

00:01:44.260 --> 00:01:47.260
Cynthia Breazeal: So Kismet interacted with people

00:01:47.260 --> 00:01:50.260
like kind of a non-verbal child or pre-verbal child,

00:01:50.260 --> 00:01:53.260
which I assume was fitting because it was really the first of its kind.

00:01:53.260 --> 00:01:55.260
It didn't speak language, but it didn't matter.

00:01:55.260 --> 00:01:57.260
This little robot was somehow able

00:01:57.260 --> 00:02:00.260
to tap into something deeply social within us --

00:02:00.260 --> 00:02:02.260
and with that, the promise of an entirely new way

00:02:02.260 --> 00:02:04.260
we could interact with robots.

00:02:04.260 --> 00:02:06.260
So over the past several years

00:02:06.260 --> 00:02:08.260
I've been continuing to explore this interpersonal dimension of robots,

00:02:08.260 --> 00:02:10.260
now at the media lab

00:02:10.260 --> 00:02:12.260
with my own team of incredibly talented students.

00:02:12.260 --> 00:02:15.260
And one of my favorite robots is Leonardo.

00:02:15.260 --> 00:02:18.260
We developed Leonardo in collaboration with Stan Winston Studio.

00:02:18.260 --> 00:02:21.260
And so I want to show you a special moment for me of Leo.

00:02:21.260 --> 00:02:23.260
This is Matt Berlin interacting with Leo,

00:02:23.260 --> 00:02:25.260
introducing Leo to a new object.

00:02:25.260 --> 00:02:28.260
And because it's new, Leo doesn't really know what to make of it.

00:02:28.260 --> 00:02:30.260
But sort of like us, he can actually learn about it

00:02:30.260 --> 00:02:33.260
from watching Matt's reaction.

00:02:33.260 --> 00:02:35.260
(Video) Matt Berlin: Hello, Leo.

00:02:38.260 --> 00:02:41.260
Leo, this is Cookie Monster.

00:02:44.260 --> 00:02:47.260
Can you find Cookie Monster?

00:02:52.260 --> 00:02:55.260
Leo, Cookie Monster is very bad.

00:02:56.260 --> 00:02:58.260
He's very bad, Leo.

00:03:00.260 --> 00:03:03.260
Cookie Monster is very, very bad.

00:03:07.260 --> 00:03:09.260
He's a scary monster.

00:03:09.260 --> 00:03:11.260
He wants to get your cookies.

00:03:12.260 --> 00:03:14.260
(Laughter)

00:03:14.260 --> 00:03:17.260
CB: All right, so Leo and Cookie

00:03:17.260 --> 00:03:19.260
might have gotten off to a little bit of a rough start,

00:03:19.260 --> 00:03:22.260
but they get along great now.

00:03:22.260 --> 00:03:24.260
So what I've learned

00:03:24.260 --> 00:03:26.260
through building these systems

00:03:26.260 --> 00:03:28.260
is that robots are actually

00:03:28.260 --> 00:03:30.260
a really intriguing social technology,

00:03:30.260 --> 00:03:32.260
where it's actually their ability

00:03:32.260 --> 00:03:34.260
to push our social buttons

00:03:34.260 --> 00:03:36.260
and to interact with us like a partner

00:03:36.260 --> 00:03:39.260
that is a core part of their functionality.

00:03:39.260 --> 00:03:41.260
And with that shift in thinking, we can now start to imagine

00:03:41.260 --> 00:03:44.260
new questions, new possibilities for robots

00:03:44.260 --> 00:03:47.260
that we might not have thought about otherwise.

00:03:47.260 --> 00:03:49.260
But what do I mean when I say "push our social buttons?"

00:03:49.260 --> 00:03:51.260
Well, one of the things that we've learned

00:03:51.260 --> 00:03:53.260
is that, if we design these robots to communicate with us

00:03:53.260 --> 00:03:55.260
using the same body language,

00:03:55.260 --> 00:03:57.260
the same sort of non-verbal cues that people use --

00:03:57.260 --> 00:04:00.260
like Nexi, our humanoid robot, is doing here --

00:04:00.260 --> 00:04:02.260
what we find is that people respond to robots

00:04:02.260 --> 00:04:04.260
a lot like they respond to people.

00:04:04.260 --> 00:04:07.260
People use these cues to determine things like how persuasive someone is,

00:04:07.260 --> 00:04:09.260
how likable, how engaging,

00:04:09.260 --> 00:04:11.260
how trustworthy.

00:04:11.260 --> 00:04:13.260
It turns out it's the same for robots.

00:04:13.260 --> 00:04:15.260
It's turning out now

00:04:15.260 --> 00:04:18.260
that robots are actually becoming a really interesting new scientific tool

00:04:18.260 --> 00:04:20.260
to understand human behavior.

00:04:20.260 --> 00:04:23.260
To answer questions like, how is it that, from a brief encounter,

00:04:23.260 --> 00:04:26.260
we're able to make an estimate of how trustworthy another person is?

00:04:26.260 --> 00:04:29.260
Mimicry's believed to play a role, but how?

00:04:29.260 --> 00:04:32.260
Is it the mimicking of particular gestures that matters?

00:04:32.260 --> 00:04:34.260
It turns out it's really hard

00:04:34.260 --> 00:04:36.260
to learn this or understand this from watching people

00:04:36.260 --> 00:04:39.260
because when we interact we do all of these cues automatically.

00:04:39.260 --> 00:04:41.260
We can't carefully control them because they're subconscious for us.

00:04:41.260 --> 00:04:43.260
But with the robot, you can.

00:04:43.260 --> 00:04:45.260
And so in this video here --

00:04:45.260 --> 00:04:48.260
this is a video taken from David DeSteno's lab at Northeastern University.

00:04:48.260 --> 00:04:50.260
He's a psychologist we've been collaborating with.

00:04:50.260 --> 00:04:53.260
There's actually a scientist carefully controlling Nexi's cues

00:04:53.260 --> 00:04:56.260
to be able to study this question.

00:04:56.260 --> 00:04:58.260
And the bottom line is -- the reason why this works is

00:04:58.260 --> 00:05:00.260
because it turns out people just behave like people

00:05:00.260 --> 00:05:03.260
even when interacting with a robot.

00:05:03.260 --> 00:05:05.260
So given that key insight,

00:05:05.260 --> 00:05:07.260
we can now start to imagine

00:05:07.260 --> 00:05:10.260
new kinds of applications for robots.

00:05:10.260 --> 00:05:13.260
For instance, if robots do respond to our non-verbal cues,

00:05:13.260 --> 00:05:17.260
maybe they would be a cool, new communication technology.

00:05:17.260 --> 00:05:19.260
So imagine this:

00:05:19.260 --> 00:05:21.260
What about a robot accessory for your cellphone?

00:05:21.260 --> 00:05:23.260
You call your friend, she puts her handset in a robot,

00:05:23.260 --> 00:05:25.260
and, bam! You're a MeBot --

00:05:25.260 --> 00:05:28.260
you can make eye contact, you can talk with your friends,

00:05:28.260 --> 00:05:30.260
you can move around, you can gesture --

00:05:30.260 --> 00:05:33.260
maybe the next best thing to really being there, or is it?

00:05:33.260 --> 00:05:35.260
To explore this question,

00:05:35.260 --> 00:05:38.260
my student, Siggy Adalgeirsson, did a study

00:05:38.260 --> 00:05:41.260
where we brought human participants, people, into our lab

00:05:41.260 --> 00:05:43.260
to do a collaborative task

00:05:43.260 --> 00:05:45.260
with a remote collaborator.

00:05:45.260 --> 00:05:47.260
The task involved things

00:05:47.260 --> 00:05:49.260
like looking at a set of objects on the table,

00:05:49.260 --> 00:05:52.260
discussing them in terms of their importance and relevance to performing a certain task --

00:05:52.260 --> 00:05:54.260
this ended up being a survival task --

00:05:54.260 --> 00:05:56.260
and then rating them in terms

00:05:56.260 --> 00:05:58.260
of how valuable and important they thought they were.

00:05:58.260 --> 00:06:01.260
The remote collaborator was an experimenter from our group

00:06:01.260 --> 00:06:03.260
who used one of three different technologies

00:06:03.260 --> 00:06:05.260
to interact with the participants.

00:06:05.260 --> 00:06:07.260
The first was just the screen.

00:06:07.260 --> 00:06:10.260
This is just like video conferencing today.

00:06:10.260 --> 00:06:13.260
The next was to add mobility -- so, have the screen on a mobile base.

00:06:13.260 --> 00:06:16.260
This is like, if you're familiar with any of the telepresence robots today --

00:06:16.260 --> 00:06:19.260
this is mirroring that situation.

00:06:19.260 --> 00:06:21.260
And then the fully expressive MeBot.

00:06:21.260 --> 00:06:23.260
So after the interaction,

00:06:23.260 --> 00:06:26.260
we asked people to rate their quality of interaction

00:06:26.260 --> 00:06:28.260
with the technology, with a remote collaborator

00:06:28.260 --> 00:06:31.260
through this technology, in a number of different ways.

00:06:31.260 --> 00:06:33.260
We looked at psychological involvement --

00:06:33.260 --> 00:06:35.260
how much empathy did you feel for the other person?

00:06:35.260 --> 00:06:37.260
We looked at overall engagement.

00:06:37.260 --> 00:06:39.260
We looked at their desire to cooperate.

00:06:39.260 --> 00:06:42.260
And this is what we see when they use just the screen.

00:06:42.260 --> 00:06:45.260
It turns out, when you add mobility -- the ability to roll around the table --

00:06:45.260 --> 00:06:47.260
you get a little more of a boost.

00:06:47.260 --> 00:06:50.260
And you get even more of a boost when you add the full expression.

00:06:50.260 --> 00:06:52.260
So it seems like this physical, social embodiment

00:06:52.260 --> 00:06:54.260
actually really makes a difference.

00:06:54.260 --> 00:06:57.260
Now let's try to put this into a little bit of context.

00:06:57.260 --> 00:07:00.260
Today we know that families are living further and further apart,

00:07:00.260 --> 00:07:02.260
and that definitely takes a toll on family relationships

00:07:02.260 --> 00:07:04.260
and family bonds over distance.

00:07:04.260 --> 00:07:06.260
For me, I have three young boys,

00:07:06.260 --> 00:07:08.260
and I want them to have a really good relationship

00:07:08.260 --> 00:07:10.260
with their grandparents.

00:07:10.260 --> 00:07:12.260
But my parents live thousands of miles away,

00:07:12.260 --> 00:07:14.260
so they just don't get to see each other that often.

00:07:14.260 --> 00:07:16.260
We try Skype, we try phone calls,

00:07:16.260 --> 00:07:18.260
but my boys are little -- they don't really want to talk;

00:07:18.260 --> 00:07:20.260
they want to play.

00:07:20.260 --> 00:07:22.260
So I love the idea of thinking about robots

00:07:22.260 --> 00:07:25.260
as a new kind of distance-play technology.

00:07:25.260 --> 00:07:28.260
I imagine a time not too far from now --

00:07:28.260 --> 00:07:30.260
my mom can go to her computer,

00:07:30.260 --> 00:07:32.260
open up a browser and jack into a little robot.

00:07:32.260 --> 00:07:35.260
And as grandma-bot,

00:07:35.260 --> 00:07:37.260
she can now play, really play,

00:07:37.260 --> 00:07:39.260
with my sons, with her grandsons,

00:07:39.260 --> 00:07:42.260
in the real world with his real toys.

00:07:42.260 --> 00:07:44.260
I could imagine grandmothers being able to do social-plays

00:07:44.260 --> 00:07:46.260
with their granddaughters, with their friends,

00:07:46.260 --> 00:07:48.260
and to be able to share all kinds of other activities around the house,

00:07:48.260 --> 00:07:50.260
like sharing a bedtime story.

00:07:50.260 --> 00:07:52.260
And through this technology,

00:07:52.260 --> 00:07:54.260
being able to be an active participant

00:07:54.260 --> 00:07:56.260
in their grandchildren's lives

00:07:56.260 --> 00:07:58.260
in a way that's not possible today.

00:07:58.260 --> 00:08:00.260
Let's think about some other domains,

00:08:00.260 --> 00:08:02.260
like maybe health.

00:08:02.260 --> 00:08:04.260
So in the United States today,

00:08:04.260 --> 00:08:07.260
over 65 percent of people are either overweight or obese,

00:08:07.260 --> 00:08:09.260
and now it's a big problem with our children as well.

00:08:09.260 --> 00:08:11.260
And we know that as you get older in life,

00:08:11.260 --> 00:08:14.260
if you're obese when you're younger, that can lead to chronic diseases

00:08:14.260 --> 00:08:16.260
that not only reduce your quality of life,

00:08:16.260 --> 00:08:19.260
but are a tremendous economic burden on our health care system.

00:08:19.260 --> 00:08:21.260
But if robots can be engaging,

00:08:21.260 --> 00:08:23.260
if we like to cooperate with robots,

00:08:23.260 --> 00:08:25.260
if robots are persuasive,

00:08:25.260 --> 00:08:27.260
maybe a robot can help you

00:08:27.260 --> 00:08:29.260
maintain a diet and exercise program,

00:08:29.260 --> 00:08:32.260
maybe they can help you manage your weight.

00:08:32.260 --> 00:08:34.260
Sort of like a digital Jiminy --

00:08:34.260 --> 00:08:36.260
as in the well-known fairy tale --

00:08:36.260 --> 00:08:38.260
a kind of friendly, supportive presence that's always there

00:08:38.260 --> 00:08:40.260
to be able to help you make the right decision

00:08:40.260 --> 00:08:42.260
in the right way at the right time

00:08:42.260 --> 00:08:44.260
to help you form healthy habits.

00:08:44.260 --> 00:08:46.260
So we actually explored this idea in our lab.

00:08:46.260 --> 00:08:48.260
This is a robot, Autom.

00:08:48.260 --> 00:08:51.260
Cory Kidd developed this robot for his doctoral work.

00:08:51.260 --> 00:08:54.260
And it was designed to be a robot diet-and-exercise coach.

00:08:54.260 --> 00:08:56.260
It had a couple of simple non-verbal skills it could do.

00:08:56.260 --> 00:08:58.260
It could make eye contact with you.

00:08:58.260 --> 00:09:00.260
It could share information looking down at a screen.

00:09:00.260 --> 00:09:02.260
You'd use a screen interface to enter information,

00:09:02.260 --> 00:09:04.260
like how many calories you ate that day,

00:09:04.260 --> 00:09:06.260
how much exercise you got.

00:09:06.260 --> 00:09:08.260
And then it could help track that for you.

00:09:08.260 --> 00:09:10.260
And the robot spoke with a synthetic voice

00:09:10.260 --> 00:09:12.260
to engage you in a coaching dialogue

00:09:12.260 --> 00:09:14.260
modeled after trainers

00:09:14.260 --> 00:09:16.260
and patients and so forth.

00:09:16.260 --> 00:09:18.260
And it would build a working alliance with you

00:09:18.260 --> 00:09:20.260
through that dialogue.

00:09:20.260 --> 00:09:22.260
It could help you set goals and track your progress,

00:09:22.260 --> 00:09:24.260
and it would help motivate you.

00:09:24.260 --> 00:09:26.260
So an interesting question is,

00:09:26.260 --> 00:09:29.260
does the social embodiment really matter? Does it matter that it's a robot?

00:09:29.260 --> 00:09:32.260
Is it really just the quality of advice and information that matters?

00:09:32.260 --> 00:09:34.260
To explore that question,

00:09:34.260 --> 00:09:36.260
we did a study in the Boston area

00:09:36.260 --> 00:09:39.260
where we put one of three interventions in people's homes

00:09:39.260 --> 00:09:41.260
for a period of several weeks.

00:09:41.260 --> 00:09:44.260
One case was the robot you saw there, Autom.

00:09:44.260 --> 00:09:47.260
Another was a computer that ran the same touch-screen interface,

00:09:47.260 --> 00:09:49.260
ran exactly the same dialogues.

00:09:49.260 --> 00:09:51.260
The quality of advice was identical.

00:09:51.260 --> 00:09:53.260
And the third was just a pen and paper log,

00:09:53.260 --> 00:09:55.260
because that's the standard intervention you typically get

00:09:55.260 --> 00:09:58.260
when you start a diet-and-exercise program.

00:09:58.260 --> 00:10:01.260
So one of the things we really wanted to look at

00:10:01.260 --> 00:10:04.260
was not how much weight people lost,

00:10:04.260 --> 00:10:07.260
but really how long they interacted with the robot.

00:10:07.260 --> 00:10:10.260
Because the challenge is not losing weight, it's actually keeping it off.

00:10:10.260 --> 00:10:13.260
And the longer you could interact with one of these interventions,

00:10:13.260 --> 00:10:16.260
well that's indicative, potentially, of longer-term success.

00:10:16.260 --> 00:10:18.260
So the first thing I want to look at is how long,

00:10:18.260 --> 00:10:20.260
how long did people interact with these systems.

00:10:20.260 --> 00:10:22.260
It turns out that people interacted with the robot

00:10:22.260 --> 00:10:24.260
significantly more,

00:10:24.260 --> 00:10:27.260
even though the quality of the advice was identical to the computer.

00:10:28.260 --> 00:10:31.260
When it asked people to rate it on terms of the quality of the working alliance,

00:10:31.260 --> 00:10:33.260
people rated the robot higher

00:10:33.260 --> 00:10:35.260
and they trusted the robot more.

00:10:35.260 --> 00:10:37.260
(Laughter)

00:10:37.260 --> 00:10:39.260
And when you look at emotional engagement,

00:10:39.260 --> 00:10:41.260
it was completely different.

00:10:41.260 --> 00:10:43.260
People would name the robots.

00:10:43.260 --> 00:10:45.260
They would dress the robots.

00:10:45.260 --> 00:10:47.260
(Laughter)

00:10:47.260 --> 00:10:50.260
And even when we would come up to pick up the robots at the end of the study,

00:10:50.260 --> 00:10:52.260
they would come out to the car and say good-bye to the robots.

00:10:52.260 --> 00:10:54.260
They didn't do this with a computer.

00:10:54.260 --> 00:10:56.260
The last thing I want to talk about today

00:10:56.260 --> 00:10:58.260
is the future of children's media.

00:10:58.260 --> 00:11:01.260
We know that kids spend a lot of time behind screens today,

00:11:01.260 --> 00:11:04.260
whether it's television or computer games or whatnot.

00:11:04.260 --> 00:11:07.260
My sons, they love the screen. They love the screen.

00:11:07.260 --> 00:11:10.260
But I want them to play; as a mom, I want them to play,

00:11:10.260 --> 00:11:12.260
like, real-world play.

00:11:12.260 --> 00:11:15.260
And so I have a new project in my group I wanted to present to you today

00:11:15.260 --> 00:11:17.260
called Playtime Computing

00:11:17.260 --> 00:11:19.260
that's really trying to think about how we can take

00:11:19.260 --> 00:11:21.260
what's so engaging about digital media

00:11:21.260 --> 00:11:23.260
and literally bring it off the screen

00:11:23.260 --> 00:11:25.260
into the real world of the child,

00:11:25.260 --> 00:11:28.260
where it can take on many of the properties of real-world play.

00:11:29.260 --> 00:11:33.260
So here's the first exploration of this idea,

00:11:33.260 --> 00:11:36.260
where characters can be physical or virtual,

00:11:36.260 --> 00:11:38.260
and where the digital content

00:11:38.260 --> 00:11:40.260
can literally come off the screen

00:11:40.260 --> 00:11:42.260
into the world and back.

00:11:42.260 --> 00:11:44.260
I like to think of this

00:11:44.260 --> 00:11:46.260
as the Atari Pong

00:11:46.260 --> 00:11:48.260
of this blended-reality play.

00:11:48.260 --> 00:11:50.260
But we can push this idea further.

00:11:50.260 --> 00:11:52.260
What if --

00:11:52.260 --> 00:11:55.260
(Game) Nathan: Here it comes. Yay!

00:11:55.260 --> 00:11:58.260
CB: -- the character itself could come into your world?

00:11:58.260 --> 00:12:00.260
It turns out that kids love it

00:12:00.260 --> 00:12:03.260
when the character becomes real and enters into their world.

00:12:03.260 --> 00:12:05.260
And when it's in their world,

00:12:05.260 --> 00:12:07.260
they can relate to it and play with it in a way

00:12:07.260 --> 00:12:09.260
that's fundamentally different from how they play with it on the screen.

00:12:09.260 --> 00:12:11.260
Another important idea is this notion

00:12:11.260 --> 00:12:14.260
of persistence of character across realities.

00:12:14.260 --> 00:12:16.260
So changes that children make in the real world

00:12:16.260 --> 00:12:18.260
need to translate to the virtual world.

00:12:18.260 --> 00:12:21.260
So here, Nathan has changed the letter A to the number 2.

00:12:21.260 --> 00:12:23.260
You can imagine maybe these symbols

00:12:23.260 --> 00:12:26.260
give the characters special powers when it goes into the virtual world.

00:12:26.260 --> 00:12:29.260
So they are now sending the character back into that world.

00:12:29.260 --> 00:12:32.260
And now it's got number power.

00:12:32.260 --> 00:12:34.260
And then finally, what I've been trying to do here

00:12:34.260 --> 00:12:37.260
is create a really immersive experience for kids,

00:12:37.260 --> 00:12:40.260
where they really feel like they are part of that story,

00:12:40.260 --> 00:12:42.260
a part of that experience.

00:12:42.260 --> 00:12:44.260
And I really want to spark their imaginations

00:12:44.260 --> 00:12:47.260
the way mine was sparked as a little girl watching "Star Wars."

00:12:47.260 --> 00:12:49.260
But I want to do more than that.

00:12:49.260 --> 00:12:52.260
I actually want them to create those experiences.

00:12:52.260 --> 00:12:54.260
I want them to be able to literally build their imagination

00:12:54.260 --> 00:12:56.260
into these experiences and make them their own.

00:12:56.260 --> 00:12:58.260
So we've been exploring a lot of ideas

00:12:58.260 --> 00:13:00.260
in telepresence and mixed reality

00:13:00.260 --> 00:13:03.260
to literally allow kids to project their ideas into this space

00:13:03.260 --> 00:13:05.260
where other kids can interact with them

00:13:05.260 --> 00:13:07.260
and build upon them.

00:13:07.260 --> 00:13:10.260
I really want to come up with new ways of children's media

00:13:10.260 --> 00:13:13.260
that foster creativity and learning and innovation.

00:13:13.260 --> 00:13:16.260
I think that's very, very important.

00:13:16.260 --> 00:13:18.260
So this is a new project.

00:13:18.260 --> 00:13:20.260
We've invited a lot of kids into this space,

00:13:20.260 --> 00:13:23.260
and they think it's pretty cool.

00:13:23.260 --> 00:13:25.260
But I can tell you, the thing that they love the most

00:13:25.260 --> 00:13:27.260
is the robot.

00:13:27.260 --> 00:13:30.260
What they care about is the robot.

00:13:30.260 --> 00:13:33.260
Robots touch something deeply human within us.

00:13:33.260 --> 00:13:35.260
And so whether they're helping us

00:13:35.260 --> 00:13:37.260
to become creative and innovative,

00:13:37.260 --> 00:13:39.260
or whether they're helping us

00:13:39.260 --> 00:13:41.260
to feel more deeply connected despite distance,

00:13:41.260 --> 00:13:43.260
or whether they are our trusted sidekick

00:13:43.260 --> 00:13:45.260
who's helping us attain our personal goals

00:13:45.260 --> 00:13:47.260
in becoming our highest and best selves,

00:13:47.260 --> 00:13:50.260
for me, robots are all about people.

00:13:50.260 --> 00:13:52.260
Thank you.

00:13:52.260 --> 00:13:57.260
(Applause)

