WEBVTT
Kind: captions
Language: hr

00:00:00.000 --> 00:00:07.000
Prevoditelj: Davorin Jelačić
Recezent: Tilen Pigac - EFZG

00:00:15.260 --> 00:00:18.260
Još otkako sam bila djevojčica

00:00:18.260 --> 00:00:20.260
i gledala "Ratove zvijezda" po prvi puta,

00:00:20.260 --> 00:00:22.260
bila sam očarana idejom

00:00:22.260 --> 00:00:24.260
osobnih robota.

00:00:24.260 --> 00:00:26.260
I kao djevojčica,

00:00:26.260 --> 00:00:28.260
voljela sam ideju robota koji komunicira s nama

00:00:28.260 --> 00:00:31.260
više kao drug koji nam pomaže i kojem vjerujemo --

00:00:31.260 --> 00:00:33.260
nešto što bi nas radovalo, obogatilo nam život

00:00:33.260 --> 00:00:36.260
i pomoglo nam spasiti galaksiju ili dvije.

00:00:37.260 --> 00:00:40.260
Znala sam da takvi roboti ne postoje u stvarnosti,

00:00:40.260 --> 00:00:42.260
ali sam znala da ih želim izrađivati.

00:00:42.260 --> 00:00:44.260
Pa prolazi 20 godina --

00:00:44.260 --> 00:00:46.260
Sada sam studentica diplomskog studija na MIT-u

00:00:46.260 --> 00:00:48.260
na studiju umjetne inteligencije,

00:00:48.260 --> 00:00:50.260
godina je 1997.,

00:00:50.260 --> 00:00:53.260
i NASA je upravo spustila prvog robota na Mars.

00:00:53.260 --> 00:00:56.260
Ali roboti, ironično, još uvijek nisu u našim domovima.

00:00:56.260 --> 00:00:58.260
I sjećam se da sam razmišljala

00:00:58.260 --> 00:01:00.260
o svim razlozima zašto je to slučaj.

00:01:00.260 --> 00:01:02.260
Ali jedan me doista pogodio.

00:01:02.260 --> 00:01:05.260
Robotika se zapravo bavi interakcijom sa stvarima,

00:01:05.260 --> 00:01:07.260
a ne s ljudima --

00:01:07.260 --> 00:01:09.260
sigurno ne na društveni način koji bi nama bio prirodan

00:01:09.260 --> 00:01:11.260
i koji bi stvarno pomogao ljudima da prihvate robote

00:01:11.260 --> 00:01:13.260
u naše svakodnevne živote.

00:01:13.260 --> 00:01:16.260
Za mene, to je onaj bijeli prostor, nešto što roboti još ne mogu.

00:01:16.260 --> 00:01:19.260
I tako sam te godine počela stvarati tog robota, Kismeta,

00:01:19.260 --> 00:01:22.260
prvog društvenog robota na svijetu.

00:01:22.260 --> 00:01:24.260
I tri godine kasnije --

00:01:24.260 --> 00:01:26.260
nakon puno programiranja,

00:01:26.260 --> 00:01:28.260
i posla s drugim diplomcima u laboratoriju --

00:01:28.260 --> 00:01:30.260
Kismet je bio spreman ostvariti interakciju s ljudima.

00:01:30.260 --> 00:01:32.260
(Video) Znanstvenik: Želim ti nešto pokazati.

00:01:32.260 --> 00:01:34.260
Kismet: (Glupost).

00:01:34.260 --> 00:01:37.260
Znanstvenik: Ovo je sat koji mi je djevojka poklonila.

00:01:37.260 --> 00:01:39.260
Kismet: (Glupost).

00:01:39.260 --> 00:01:41.260
Znanstvenik: Da, gledaj, ima i malo plavo svjetlo.

00:01:41.260 --> 00:01:44.260
Skoro sam ga izgubio ovoga tjedna.

00:01:44.260 --> 00:01:47.260
Cynthia Breazeal: Dakle, Kismet je komunicirao s ljudima

00:01:47.260 --> 00:01:50.260
poput djeteta koje ne priča ili koje još nije propričalo,

00:01:50.260 --> 00:01:53.260
što je, pretpostavljam, prikladno jer je doista prvi svoje vrste.

00:01:53.260 --> 00:01:55.260
Nije znao jezik, ali to nije važno.

00:01:55.260 --> 00:01:57.260
Ovaj mali robot je nekako bio u stanju

00:01:57.260 --> 00:02:00.260
dotaknuti nešto duboko društveno u nama.

00:02:00.260 --> 00:02:02.260
I time, obećati potpuno novi način

00:02:02.260 --> 00:02:04.260
na koji bismo mogli komunicirati s robotima.

00:02:04.260 --> 00:02:06.260
U proteklih nekoliko godina

00:02:06.260 --> 00:02:08.260
nastavila sam istraživati tu interpersonalnu dimenziju robota,

00:02:08.260 --> 00:02:10.260
sada u medijskom laboratoriju

00:02:10.260 --> 00:02:12.260
s vlastitim timom nevjerojatno nadarenih studenata.

00:02:12.260 --> 00:02:15.260
Jedan od mojih omiljenih robota je Leonardo.

00:02:15.260 --> 00:02:18.260
Razvili smo Leonarda u suradnji sa studiom Stana Winstona.

00:02:18.260 --> 00:02:21.260
I želim vam pokazati za mene poseban trenutak s Leom.

00:02:21.260 --> 00:02:23.260
Ovdje Matt Berlin komunicira s Leom,

00:02:23.260 --> 00:02:25.260
upoznajući Lea s novim predmetom.

00:02:25.260 --> 00:02:28.260
I budući da je nov, Leo zapravo ne zna što da misli o njemu.

00:02:28.260 --> 00:02:30.260
Ali pomalo kao i mi, može nekako naučiti nešto o tome

00:02:30.260 --> 00:02:33.260
promatrajući Mattovu reakciju.

00:02:33.260 --> 00:02:35.260
(Video) Matt Berlin: Zdravo, Leo.

00:02:38.260 --> 00:02:41.260
Leo, ovo je Cookie Monster.

00:02:44.260 --> 00:02:47.260
Možeš li pronaći Cookie Monstera?

00:02:52.260 --> 00:02:55.260
Leo, Cookie Monster je vrlo loš.

00:02:56.260 --> 00:02:58.260
On je vrlo loš, Leo.

00:03:00.260 --> 00:03:03.260
Cookie Monster je vrlo, vrlo loš.

00:03:07.260 --> 00:03:09.260
On je zastrašujuće čudovište.

00:03:09.260 --> 00:03:11.260
Ono želi uzeti tvoje kolačiće.

00:03:12.260 --> 00:03:14.260
(Smijeh)

00:03:14.260 --> 00:03:17.260
CB: Dobro, dakle Leo i Cookie

00:03:17.260 --> 00:03:19.260
su možda počeli pomalo neugodno,

00:03:19.260 --> 00:03:22.260
ali sada se odlično slažu.

00:03:22.260 --> 00:03:24.260
Ono što sam naučila

00:03:24.260 --> 00:03:26.260
stvarajući ove sustave

00:03:26.260 --> 00:03:28.260
je da su roboti zapravo

00:03:28.260 --> 00:03:30.260
doista intrigantna društvena tehnologija.

00:03:30.260 --> 00:03:32.260
Gdje je, u stvari, njihova sposobnost

00:03:32.260 --> 00:03:34.260
da pritisnu tipke naše društvenosti

00:03:34.260 --> 00:03:36.260
i komuniciraju s nama poput partnera

00:03:36.260 --> 00:03:39.260
onaj jezgreni dio njihove funkcionalnosti.

00:03:39.260 --> 00:03:41.260
S tim pomakom u mišljenju, sada možemo početi zamišljati

00:03:41.260 --> 00:03:44.260
nova pitanja, nove mogućnosti za robote

00:03:44.260 --> 00:03:47.260
o kojima inače možda ne bismo razmišljali.

00:03:47.260 --> 00:03:49.260
No, što mislim kad kažem da „pritišću tipke naše društvenosti?“

00:03:49.260 --> 00:03:51.260
Pa, jedna od stvari koju smo naučili

00:03:51.260 --> 00:03:53.260
je da, ako stvorimo robote da komuniciraju s nama

00:03:53.260 --> 00:03:55.260
rabeći isti govor tijela,

00:03:55.260 --> 00:03:57.260
istu vrstu neverbalnih signala koje koriste ljudi --

00:03:57.260 --> 00:04:00.260
kao što Nexi, naš humanoidni robot čini ovdje --

00:04:00.260 --> 00:04:02.260
ono što otkrivamo je da ljudi reagiraju na robote

00:04:02.260 --> 00:04:04.260
vrlo slično kao što reagiraju na ljude.

00:04:04.260 --> 00:04:07.260
Ljudi koriste te signale da odrede koliko je netko uvjerljiv,

00:04:07.260 --> 00:04:09.260
koliko je simpatičan, koliko zanimljiv,

00:04:09.260 --> 00:04:11.260
koliko mu se može vjerovati.

00:04:11.260 --> 00:04:13.260
Ispostavlja se da je isto s robotima.

00:04:13.260 --> 00:04:15.260
Pokazuje se sada

00:04:15.260 --> 00:04:18.260
da roboti doista postaju stvarno zanimljivo novo znanstveno oruđe

00:04:18.260 --> 00:04:20.260
za razumijevanje ljudskog ponašanja.

00:04:20.260 --> 00:04:23.260
Za odgovaranje na pitanja poput, kako to da, na temelju kratkog susreta,

00:04:23.260 --> 00:04:26.260
možemo procijeniti koliko je druga osoba vrijedna našeg povjerenja?

00:04:26.260 --> 00:04:29.260
Vjeruje se da oponašanje igra ulogu, ali kako?

00:04:29.260 --> 00:04:32.260
Da li je važno oponašanje određenih pokreta?

00:04:32.260 --> 00:04:34.260
Pokazuje se da je stvarno teško

00:04:34.260 --> 00:04:36.260
ovo naučiti ili shvatiti promatrajući ljude

00:04:36.260 --> 00:04:39.260
jer kad komuniciramo svi tim signalima upravljamo automatski.

00:04:39.260 --> 00:04:41.260
Ne možemo ih pažljivo kontrolirati jer su nam podsvjesni.

00:04:41.260 --> 00:04:43.260
Ali s robotom možete.

00:04:43.260 --> 00:04:45.260
Pa u ovom filmu ovdje --

00:04:45.260 --> 00:04:48.260
video je snimljen u laboratoriju Davida DeStenoa na sveučilištu Northeastern.

00:04:48.260 --> 00:04:50.260
On je psiholog s kojim surađujemo.

00:04:50.260 --> 00:04:53.260
Postoji znanstvenik koji pažljivo kontrolira Nexijeve signale

00:04:53.260 --> 00:04:56.260
kako bi mogao proučavati ovo pitanje.

00:04:56.260 --> 00:04:58.260
A zaključak je – razlog zašto ovo funcionira --

00:04:58.260 --> 00:05:00.260
jer se pokazuje da se ljudi ponašaju kao ljudi

00:05:00.260 --> 00:05:03.260
čak i kad komuniciraju s robotom.

00:05:03.260 --> 00:05:05.260
Pa s tim ključnim uvidom,

00:05:05.260 --> 00:05:07.260
možemo početi zamišljati

00:05:07.260 --> 00:05:10.260
nove primjene za robote.

00:05:10.260 --> 00:05:13.260
Na primjer, ako roboti uzvraćaju na naše neverbalne signale,

00:05:13.260 --> 00:05:17.260
možda bi bili sjajna nova komunikacijska tehnologija.

00:05:17.260 --> 00:05:19.260
Zamislite ovo:

00:05:19.260 --> 00:05:21.260
Što mislite o robotskom dodatku za vaš mobitel?

00:05:21.260 --> 00:05:23.260
Nazovete prijateljicu, ona stavi mobitel u robota,

00:05:23.260 --> 00:05:25.260
i, bam!, vi ste JaBot --

00:05:25.260 --> 00:05:28.260
možete ostvariti kontakt pogledom, pričati s prijateljima,

00:05:28.260 --> 00:05:30.260
možete se kretati uokolo, gestikulirati --

00:05:30.260 --> 00:05:33.260
možda sljedeća najbolja stvar nakon stvarne nazočnosti ondje, je li?

00:05:33.260 --> 00:05:35.260
Da bismo ovo ispitali

00:05:35.260 --> 00:05:38.260
moj student, Siggy Adalgeirsson, napravio je studiju

00:05:38.260 --> 00:05:41.260
u kojoj smo doveli ljudske sudionike, ljude, u naš laboratorij

00:05:41.260 --> 00:05:43.260
da izvrše zadatak koji zahtijeva suradnju

00:05:43.260 --> 00:05:45.260
sa suradnikom na daljinu.

00:05:45.260 --> 00:05:47.260
Zadatak je uključivao stvari

00:05:47.260 --> 00:05:49.260
poput gledanja skupa predmeta na stolu,

00:05:49.260 --> 00:05:52.260
raspravljanja o njima u smislu njihove važnosti za obavljanje određenog zadatka --

00:05:52.260 --> 00:05:54.260
što je završilo kao zadatak preživljavanja --

00:05:54.260 --> 00:05:56.260
i zatim rangiranja predmeta prema tome

00:05:56.260 --> 00:05:58.260
koliko su ih smatrali vrijednima ili važnima.

00:05:58.260 --> 00:06:01.260
Udaljeni suradnik je bio eksperimentator iz naše skupine

00:06:01.260 --> 00:06:03.260
pri čemu su koristili jednu od tri različite tehnologije

00:06:03.260 --> 00:06:05.260
za interakciju sa sudionicima.

00:06:05.260 --> 00:06:07.260
Prva je bila običan ekran.

00:06:07.260 --> 00:06:10.260
To je poput današnje video konferencije.

00:06:10.260 --> 00:06:13.260
Sljedeća je bila s dodanom pokretljivošću, pa smo ekran stavili na pokretnu osnovu.

00:06:13.260 --> 00:06:16.260
To je poput, ako ste upoznati s nekim oblikom današnjih telenazočnih robota --

00:06:16.260 --> 00:06:19.260
ovo oponaša tu situaciju.

00:06:19.260 --> 00:06:21.260
I na koncu, potpuno izažajan JaBot.

00:06:21.260 --> 00:06:23.260
Nakon interakcije,

00:06:23.260 --> 00:06:26.260
tražili smo od ljudi da ocijene kvalitetu interakcije

00:06:26.260 --> 00:06:28.260
s tehnologijom, sa suradnikom na daljinu,

00:06:28.260 --> 00:06:31.260
na brojne razne načine.

00:06:31.260 --> 00:06:33.260
Promatrali smo psihološki moment --

00:06:33.260 --> 00:06:35.260
koliko empatije ste osjetili za drugoga?

00:06:35.260 --> 00:06:37.260
Promatrali smo sveukupni angažman.

00:06:37.260 --> 00:06:39.260
Promatrali smo njihovu želju za suradnjom.

00:06:39.260 --> 00:06:42.260
Evo što vidimo kada koriste samo ekran.

00:06:42.260 --> 00:06:45.260
Ispada da kad dodate pokretljivost – mogućnost okretanja na stolu --

00:06:45.260 --> 00:06:47.260
dobijete malo više poticaja.

00:06:47.260 --> 00:06:50.260
A dobijete još više poticaja kada dodate punu izražajnost.

00:06:50.260 --> 00:06:52.260
Pa se čini da ovo fizičko društveno utjelovljenje

00:06:52.260 --> 00:06:54.260
stvarno čini razliku.

00:06:54.260 --> 00:06:57.260
Pokušajmo to sada malo staviti u kontekst.

00:06:57.260 --> 00:07:00.260
Danas znamo da članovi obitelji žive sve udaljenije jedni od drugih,

00:07:00.260 --> 00:07:02.260
i da to definitivno uzima danak u obiteljskim odnosima

00:07:02.260 --> 00:07:04.260
i obiteljskim vezama na daljinu.

00:07:04.260 --> 00:07:06.260
Što se mene tiče, imam tri dječaka,

00:07:06.260 --> 00:07:08.260
i želim da imaju stvarno dobar odnos

00:07:08.260 --> 00:07:10.260
sa svojim djedom i bakom.

00:07:10.260 --> 00:07:12.260
Ali moji roditelji žive tisućama kilometara daleko,

00:07:12.260 --> 00:07:14.260
pa se oni jednostavno ne vide baš često.

00:07:14.260 --> 00:07:16.260
Probamo pomoću Skypea, probamo telefonom,

00:07:16.260 --> 00:07:18.260
ali dečki su maleni – zapravo ne žele pričati,

00:07:18.260 --> 00:07:20.260
žele se igrati.

00:07:20.260 --> 00:07:22.260
Oni vole ideju gledanja na robote

00:07:22.260 --> 00:07:25.260
kao na novu vrstu tehnologije za igranje na daljinu.

00:07:25.260 --> 00:07:28.260
Pa si ja zamišljam vrijeme ne tako daleko od danas --

00:07:28.260 --> 00:07:30.260
kada moja mati može otići do svog računala,

00:07:30.260 --> 00:07:32.260
otvoriti preglednik i uključiti se u malog robota.

00:07:32.260 --> 00:07:35.260
I kao baka-bot,

00:07:35.260 --> 00:07:37.260
može se igrati, zaista igrati,

00:07:37.260 --> 00:07:39.260
s mojim sinovima, svojim unucima,

00:07:39.260 --> 00:07:42.260
u stvarnom svijetu s njegovim pravim igračkama.

00:07:42.260 --> 00:07:44.260
Mogu zamisliti bake kako igraju društvene igre

00:07:44.260 --> 00:07:46.260
sa svojim unukama, prijateljicama,

00:07:46.260 --> 00:07:48.260
kako mogu podijeliti sve ostale aktivnosti po kući,

00:07:48.260 --> 00:07:50.260
kao što razmjenjuju priče za laku noć.

00:07:50.260 --> 00:07:52.260
Pomoću ove tehnologije,

00:07:52.260 --> 00:07:54.260
moći će biti aktivni sudionici

00:07:54.260 --> 00:07:56.260
u životima svoje unučadi

00:07:56.260 --> 00:07:58.260
na način koji danas nije moguć.

00:07:58.260 --> 00:08:00.260
Razmislimo i o nekim drugim područjima,

00:08:00.260 --> 00:08:02.260
poput zdravlja, možda.

00:08:02.260 --> 00:08:04.260
U Sjedinjenim Državama danas je,

00:08:04.260 --> 00:08:07.260
preko 65 posto ljudi pretilo ili gojazno,

00:08:07.260 --> 00:08:09.260
a sada je to velik problem i s našom djecom.

00:08:09.260 --> 00:08:11.260
A znamo da, kako ste stariji u životu,

00:08:11.260 --> 00:08:14.260
ako ste gojazni kad ste mladi, to može voditi u kronične bolesti

00:08:14.260 --> 00:08:16.260
koje ne samo da smanjuju kvalitetu života,

00:08:16.260 --> 00:08:19.260
već su i strahovit ekonomski teret za naš zdravstveni sustav.

00:08:19.260 --> 00:08:21.260
Ali ako roboti mogu zainteresirati,

00:08:21.260 --> 00:08:23.260
ako volimo surađivati s robotima,

00:08:23.260 --> 00:08:25.260
ako su roboti uvjerljivi,

00:08:25.260 --> 00:08:27.260
možda vam robot može pomoći

00:08:27.260 --> 00:08:29.260
da poštujete program dijete i vježbanja,

00:08:29.260 --> 00:08:32.260
možda vam mogu pomoći da kontrolirate svoju težinu.

00:08:32.260 --> 00:08:34.260
Nešto kao digitalna Jiminy --

00:08:34.260 --> 00:08:36.260
dobro poznata bajka --

00:08:36.260 --> 00:08:38.260
svojevrsna prijateljska nazočnost koja pruža podršku i uvijek je tu

00:08:38.260 --> 00:08:40.260
da bi vam pomogla da donesete pravu odluku

00:08:40.260 --> 00:08:42.260
na pravi način, u pravo vrijeme,

00:08:42.260 --> 00:08:44.260
da vam pomogne stvoriti zdrave navike.

00:08:44.260 --> 00:08:46.260
Mi smo zapravo ispitali ovu ideju u našem laboratoriju.

00:08:46.260 --> 00:08:48.260
Ovo je robot, Autom.

00:08:48.260 --> 00:08:51.260
Cory Kidd je razvio ovog robota za svoj doktorski rad.

00:08:51.260 --> 00:08:54.260
Oblikovan je da bude robot trener za ishranu i vježbu.

00:08:54.260 --> 00:08:56.260
Imao je nekoliko jednostavnih neverbalnih vještina.

00:08:56.260 --> 00:08:58.260
Mogao je ostvariti kontakt pogledom s vama.

00:08:58.260 --> 00:09:00.260
Mogao je dijeliti informacije gledajući dolje u ekran.

00:09:00.260 --> 00:09:02.260
Informacije unosite pomoću ekranskog sučelja,

00:09:02.260 --> 00:09:04.260
kao, koliko kalorija ste pojeli toga dana,

00:09:04.260 --> 00:09:06.260
koliko ste vježbali.

00:09:06.260 --> 00:09:08.260
A zatim bi vam robot pomogao pratiti te informacije.

00:09:08.260 --> 00:09:10.260
Robot je govorio sintetičkim glasom

00:09:10.260 --> 00:09:12.260
kako bi vas uključio u trenerski dijalog

00:09:12.260 --> 00:09:14.260
modeliran prema trenerima

00:09:14.260 --> 00:09:16.260
i pacijentima i slično.

00:09:16.260 --> 00:09:18.260
On bi uspostavio radno savezništvo s vama

00:09:18.260 --> 00:09:20.260
kroz taj dijalog.

00:09:20.260 --> 00:09:22.260
Mogao vam je pomoći postaviti ciljeve i pratiti napredak,

00:09:22.260 --> 00:09:24.260
i pomagao vam je u motivaciji.

00:09:24.260 --> 00:09:26.260
Zanimljivo pitanje je, stoga,

00:09:26.260 --> 00:09:29.260
da li je društveno utjelovljenje doista bitno? Je li bitno što je robot?

00:09:29.260 --> 00:09:32.260
Da li je stvarno važna samo kvaliteta savjeta i informacija?

00:09:32.260 --> 00:09:34.260
Da bismo odgovorili na to pitanje,

00:09:34.260 --> 00:09:36.260
napravili smo studiju na području Bostona

00:09:36.260 --> 00:09:39.260
u kojoj smo stavili jednu od tri intervencije ljudima u kuću

00:09:39.260 --> 00:09:41.260
na razdoblje od nekoliko tjedana.

00:09:41.260 --> 00:09:44.260
Jedan slučaj je bio robot koji ste ovdje vidjeli, Autom.

00:09:44.260 --> 00:09:47.260
Druga intervencija je bila računalo koje je imalo isti ekran osjetljiv na dodir,

00:09:47.260 --> 00:09:49.260
i vrtjelo potpuno iste dijaloge.

00:09:49.260 --> 00:09:51.260
Kvaliteta savjeta je bila ista.

00:09:51.260 --> 00:09:53.260
A treća je bila samo olovka i papir za vođenje bilješki,

00:09:53.260 --> 00:09:55.260
jer je to standardna intervencija koju tipično dobijete

00:09:55.260 --> 00:09:58.260
kada započnete program dijete i vježbe.

00:09:58.260 --> 00:10:01.260
Jedna od stvari koju smo stvarno htjeli promotriti

00:10:01.260 --> 00:10:04.260
nije bila koliko su ljudi izgubili na težini,

00:10:04.260 --> 00:10:07.260
već zapravo koliko su dugo komunicirali s robotom.

00:10:07.260 --> 00:10:10.260
Jer nije problem skinuti kile, problem je ne vratiti se na staro.

00:10:10.260 --> 00:10:13.260
I što duže možete komunicirati s jednom od ovih intervencija,

00:10:13.260 --> 00:10:16.260
tim je indikativnije, potencijalno, da ćete postići dugoročniji uspjeh.

00:10:16.260 --> 00:10:18.260
Prvo što želim pogledati je koliko dugo,

00:10:18.260 --> 00:10:20.260
koliko su dugo ljudi bili u interakciji s tim sustavima.

00:10:20.260 --> 00:10:22.260
Pokazalo se da su ljudi komunicirali s robotom

00:10:22.260 --> 00:10:24.260
značajno više,

00:10:24.260 --> 00:10:27.260
premda je kvaliteta savjeta bila identična onoj na računalu.

00:10:28.260 --> 00:10:31.260
Kad ih je pitao da ga ocijene u smislu kvalitete radnog savezništva,

00:10:31.260 --> 00:10:33.260
ljudi su robota ocijenili bolje

00:10:33.260 --> 00:10:35.260
i robotu su vjerovali više.

00:10:35.260 --> 00:10:37.260
(Smijeh)

00:10:37.260 --> 00:10:39.260
A kad pogledate emocionalni angažman,

00:10:39.260 --> 00:10:41.260
sve je bilo različito.

00:10:41.260 --> 00:10:43.260
Ljudi bi robotima dali imena.

00:10:43.260 --> 00:10:45.260
Odijevali su ih.

00:10:45.260 --> 00:10:47.260
(Smijeh)

00:10:47.260 --> 00:10:50.260
I čak kad bismo došli pokupiti robote pri kraju studije,

00:10:50.260 --> 00:10:52.260
izišli bi do automobila i pozdravili se s robotom.

00:10:52.260 --> 00:10:54.260
Nisu to činili s računalom.

00:10:54.260 --> 00:10:56.260
Posljednje o čemu želim danas pričati

00:10:56.260 --> 00:10:58.260
je budućnost dječjih medija.

00:10:58.260 --> 00:11:01.260
Znamo da djeca danas provode puno vremena za ekranima,

00:11:01.260 --> 00:11:04.260
bilo da je riječ o televiziji ili računalnim igrama ili drugome.

00:11:04.260 --> 00:11:07.260
Moji sinovi, oni vole ekran. Vole ekran.

00:11:07.260 --> 00:11:10.260
Ali ja želim da se oni igraju; kao majka želim da se igraju,

00:11:10.260 --> 00:11:12.260
igraju u stvarnom svijetu.

00:11:12.260 --> 00:11:15.260
Pa u svojoj skupini pokrećem novi projekt koji vam želim danas predstaviti

00:11:15.260 --> 00:11:17.260
koji se zove Računala u igri

00:11:17.260 --> 00:11:19.260
koji zapravo pokušava razmišljati

00:11:19.260 --> 00:11:21.260
o tome što je tako zanimljivo kod digitalnih medija

00:11:21.260 --> 00:11:23.260
i doslovno to skinuti s ekrana,

00:11:23.260 --> 00:11:25.260
u stvarni svijet djeteta,

00:11:25.260 --> 00:11:28.260
gdje može poprimiti mnoga obilježja igranja u stvarnom svijetu.

00:11:29.260 --> 00:11:33.260
Evo prvog ispitivanja ove ideje,

00:11:33.260 --> 00:11:36.260
u kojem likovi mogu biti fizički ili virtualni,

00:11:36.260 --> 00:11:38.260
i gdje digitalni sadržaj

00:11:38.260 --> 00:11:40.260
doslovno može sići s ekrana,

00:11:40.260 --> 00:11:42.260
u svijet i natrag.

00:11:42.260 --> 00:11:44.260
Volim o ovome razmišljati

00:11:44.260 --> 00:11:46.260
kao o Atari Pongu

00:11:46.260 --> 00:11:48.260
ove stopljene stvarnosne igre.

00:11:48.260 --> 00:11:50.260
Ali možemo ovu ideju pogurati i dalje.

00:11:50.260 --> 00:11:52.260
Što ako --

00:11:52.260 --> 00:11:55.260
(Igra) Nathan: Stiže. Jee!

00:11:55.260 --> 00:11:58.260
CB: -- sam lik može doći u vaš svijet?

00:11:58.260 --> 00:12:00.260
Pokazuje se da djeca obožavaju

00:12:00.260 --> 00:12:03.260
kad lik postaje stvaran i ulazi u njihov svijet.

00:12:03.260 --> 00:12:05.260
A kad je u njihovom svijetu,

00:12:05.260 --> 00:12:07.260
mogu uspostaviti odnos i igrati se s njime na način

00:12:07.260 --> 00:12:09.260
koji je fundamentalno drukčiji od igranja na ekranu.

00:12:09.260 --> 00:12:11.260
Druga važna ideja je shvaćanje

00:12:11.260 --> 00:12:14.260
opstojnosti lika u različitim realitetima.

00:12:14.260 --> 00:12:16.260
Pa se promjene koje djeca naprave u stvarnom svijetu

00:12:16.260 --> 00:12:18.260
moraju prenijeti u virtualni svijet.

00:12:18.260 --> 00:12:21.260
Ovdje je Nathan promijenio slovo A u broj 2.

00:12:21.260 --> 00:12:23.260
Možete zamisliti da ovi simboli

00:12:23.260 --> 00:12:26.260
daju likovima specijalne moći kad odu u virtualni svijet.

00:12:26.260 --> 00:12:29.260
Pa sada šalju lika natrag u taj svijet.

00:12:29.260 --> 00:12:32.260
I on sada ima brojčanu moć.

00:12:32.260 --> 00:12:34.260
I naposlijetku, ono što sam pokušala ovdje učiniti je

00:12:34.260 --> 00:12:37.260
stvoriti iskustvo u koje će djeca stvarno uroniti,

00:12:37.260 --> 00:12:40.260
u kojem se doista osjećaju kao da su dio priče,

00:12:40.260 --> 00:12:42.260
dio tog iskustva.

00:12:42.260 --> 00:12:44.260
I zaista želim zapaliti njihovu maštu

00:12:44.260 --> 00:12:47.260
onako kako se moja zapalila kad sam kao djevojčica gledala „Ratove zvijezda“.

00:12:47.260 --> 00:12:49.260
Ali želim i više od toga.

00:12:49.260 --> 00:12:52.260
Zapravo želim da oni stvore svoja iskustva.

00:12:52.260 --> 00:12:54.260
Želim da budu u stanju doslovno ugraditi svoju maštu

00:12:54.260 --> 00:12:56.260
u ta iskustva i učiniti ih svojima.

00:12:56.260 --> 00:12:58.260
Dakle, istraživali smo mnoge ideje

00:12:58.260 --> 00:13:00.260
telenazočnosti i mješovite stvarnosti

00:13:00.260 --> 00:13:03.260
kako bismo doslovno omogućili djeci da projiciraju svoje ideje u prostor

00:13:03.260 --> 00:13:05.260
gdje druga djeca mogu komunicirati s njima

00:13:05.260 --> 00:13:07.260
i graditi na tome.

00:13:07.260 --> 00:13:10.260
Zaista želim iznaći nove načine dječjih medija

00:13:10.260 --> 00:13:13.260
koji hrane kreativnost i učenje i inovacije.

00:13:13.260 --> 00:13:16.260
Mislim da je to vrlo, vrlo važno.

00:13:16.260 --> 00:13:18.260
Pa je ovo novi projekt.

00:13:18.260 --> 00:13:20.260
Pozvali smo mnogo djece u ovaj prostor,

00:13:20.260 --> 00:13:23.260
i oni misle da je prilično cool.

00:13:23.260 --> 00:13:25.260
Ali mogu vam reći, ono što najviše vole

00:13:25.260 --> 00:13:27.260
je robot.

00:13:27.260 --> 00:13:30.260
Ono do čega im je stalo je robot.

00:13:30.260 --> 00:13:33.260
Roboti dotiču nešto duboko ljudsko u nama.

00:13:33.260 --> 00:13:35.260
I tako, bez obzira da li nam pomažu

00:13:35.260 --> 00:13:37.260
da postanemo kreativni i inovativni,

00:13:37.260 --> 00:13:39.260
ili nam pomažu

00:13:39.260 --> 00:13:41.260
da se osjećamo bolje povezani usprkos udaljenosti,

00:13:41.260 --> 00:13:43.260
ili su naš drug kojem vjerujemo

00:13:43.260 --> 00:13:45.260
i koji nam pomaže ostvariti osobne ciljeve

00:13:45.260 --> 00:13:47.260
kako bismo postali najbolji što možemo,

00:13:47.260 --> 00:13:50.260
za mene, kod robota su važni ljudi.

00:13:50.260 --> 00:13:52.260
Hvala vam.

00:13:52.260 --> 00:13:57.260
(Pljesak)

