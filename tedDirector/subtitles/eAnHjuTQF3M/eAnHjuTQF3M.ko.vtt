WEBVTT
Kind: captions
Language: ko

00:00:00.000 --> 00:00:07.000
번역: J J LEE
검토: Seongsu JEONG

00:00:15.260 --> 00:00:18.260
어릴적 "스타워즈"를

00:00:18.260 --> 00:00:20.260
처음 봤던 이후로 계속

00:00:20.260 --> 00:00:22.260
저는 개인용 로봇의 아이디어에

00:00:22.260 --> 00:00:24.260
매료되었습니다.

00:00:24.260 --> 00:00:26.260
그리고 어린 소녀로서,

00:00:26.260 --> 00:00:28.260
우리와 소통하고, 매우 유용하며 믿을 수 있는 친구 같은

00:00:28.260 --> 00:00:31.260
로봇의 아이디어를 너무 좋아했습니다.

00:00:31.260 --> 00:00:33.260
그런 것이 우리를 즐겁게 만들고, 우리 삶을 풍요롭게 하며,

00:00:33.260 --> 00:00:36.260
우리가 은하계 한두개를 구할 수 있도록 도와줍니다.

00:00:37.260 --> 00:00:40.260
그런 로봇이 실제로 존재하지 않는다는건 알았지만,

00:00:40.260 --> 00:00:42.260
제가 그것을 만들어 보고 싶어 한다는 걸 깨달았습니다.

00:00:42.260 --> 00:00:44.260
20년이 지났습니다.

00:00:44.260 --> 00:00:46.260
저는 이제 인공지능을 연구하고 있는

00:00:46.260 --> 00:00:48.260
MIT 대학원생입니다.

00:00:48.260 --> 00:00:50.260
1997년은

00:00:50.260 --> 00:00:53.260
나사가 화성에 첫 로봇을 착륙시킨 해였습니다.

00:00:53.260 --> 00:00:56.260
하지만 아이러니하게도 로봇은 아직 우리들의 집에는 없습니다.

00:00:56.260 --> 00:00:58.260
그리고 왜 그것이 문제인가의

00:00:58.260 --> 00:01:00.260
모든 이유들에 대해서 생각한 것을 기억합니다.

00:01:00.260 --> 00:01:02.260
그러다 갑자기 떠오른 생각이 있었습니다.

00:01:02.260 --> 00:01:05.260
로봇공학은 사물들과의 상호작용에 대한 것이지,

00:01:05.260 --> 00:01:07.260
인간과의 상호작용에 관한게 아니었습니다.

00:01:07.260 --> 00:01:09.260
우리에게 자연스럽고, 사람들이 로봇을 우리의 일상에

00:01:09.260 --> 00:01:11.260
로봇을 받아들이도록 하는 사회적 방법은

00:01:11.260 --> 00:01:13.260
확실히 아니었습니다.

00:01:13.260 --> 00:01:16.260
제게 그것은 빈칸이었고, 로봇이 아직까지 할 수 없는 것이었습니다.

00:01:16.260 --> 00:01:19.260
그래서 그 해, 저는 세계 최초의 사회적 로봇인

00:01:19.260 --> 00:01:22.260
이 키즈맷을 만들기 시작했습니다.

00:01:22.260 --> 00:01:24.260
3년 후에,

00:01:24.260 --> 00:01:26.260
수 많은 프로그래밍과

00:01:26.260 --> 00:01:28.260
연구실에 있는 다른 대학원생들과의 협업을 통해

00:01:28.260 --> 00:01:30.260
키즈맷은 사람들과 상호소통을 시작할 준비가 되었습니다.

00:01:30.260 --> 00:01:32.260
(영상) 과학자: 뭔가 보여줄게.

00:01:32.260 --> 00:01:34.260
키즈맷: (아무 의미 없는 말)

00:01:34.260 --> 00:01:37.260
과학자: 내 여자친구가 준 시계야.

00:01:37.260 --> 00:01:39.260
키즈맷: (아무 의미 없는 말)

00:01:39.260 --> 00:01:41.260
과학자: 그래, 봐봐, 파란 불빛도 나온다.

00:01:41.260 --> 00:01:44.260
이번 주에 잃어버릴뻔 했어.

00:01:44.260 --> 00:01:47.260
신시아 브리질: 자, 키즈맷은 정말 최초의 형태였기 때문에

00:01:47.260 --> 00:01:50.260
말을 시작하기 전의 아이처럼 사람과 상호소통하는 것이

00:01:50.260 --> 00:01:53.260
어울린다고 생각했습니다.

00:01:53.260 --> 00:01:55.260
언어를 말하지 못했지만 문제되지 않았습니다.

00:01:55.260 --> 00:01:57.260
이 작은 로봇은 어떻게든 우리 내부의

00:01:57.260 --> 00:02:00.260
깊이 사회적인 것에 다가설 수 있었습니다.

00:02:00.260 --> 00:02:02.260
그리고 그것이 우리가 로봇과 상호소통할 수 있다는

00:02:02.260 --> 00:02:04.260
완전히 새로운 방식의 가능성입니다.

00:02:04.260 --> 00:02:06.260
그래서 지난 몇 년 동안,

00:02:06.260 --> 00:02:08.260
미디어 랩에서, 매우 재능있는 학생들로 이루어진 제 팀과 함께

00:02:08.260 --> 00:02:10.260
로봇의 이런 대인관계적 측면을

00:02:10.260 --> 00:02:12.260
계속해서 탐구해왔습니다.

00:02:12.260 --> 00:02:15.260
제가 제일 좋아하는 로봇은 레오나르도입니다.

00:02:15.260 --> 00:02:18.260
우리는 스탠 윈스톤 스튜디오와 협력하여 레오나르도를 개발했습니다.

00:02:18.260 --> 00:02:21.260
여러분께 레오나르도와 관련해 제게 특별했던 순간을 보여드리고 싶습니다.

00:02:21.260 --> 00:02:23.260
이 사람은 레오와 상호소통하고

00:02:23.260 --> 00:02:25.260
레오에게 새로운 것을 소개하는 맷 베를린입니다.

00:02:25.260 --> 00:02:28.260
새로운 걸 소개했기 때문에, 레오는 무엇을 해야할지 전혀 모릅니다.

00:02:28.260 --> 00:02:30.260
하지만 우리와 유사하게, 레오는 맷의 반응을 관찰하여

00:02:30.260 --> 00:02:33.260
학습할 수 있습니다.

00:02:33.260 --> 00:02:35.260
(영상) 맷 베를린: 안녕, 레오.

00:02:38.260 --> 00:02:41.260
레오, 이것은 쿠키 몬스터야.

00:02:44.260 --> 00:02:47.260
쿠키 몬스터를 찾을 수 있겠어?

00:02:52.260 --> 00:02:55.260
레오, 쿠키 몬스터는 매우 나빠.

00:02:56.260 --> 00:02:58.260
아주 나쁘지, 레오.

00:03:00.260 --> 00:03:03.260
쿠키 몬스터는 아주 아주 나빠.

00:03:07.260 --> 00:03:09.260
무시무시한 괴물이지.

00:03:09.260 --> 00:03:11.260
그건 네 쿠키를 뺏어가고 싶어해.

00:03:12.260 --> 00:03:14.260
(웃음)

00:03:14.260 --> 00:03:17.260
CB: 좋습니다. 그래서 레오와 쿠키는

00:03:17.260 --> 00:03:19.260
첫 만남이 조금은 힘들게 시작한 것 같지만,

00:03:19.260 --> 00:03:22.260
지금은 아주 잘 지내고 있습니다.

00:03:22.260 --> 00:03:24.260
자, 제가 이 시스템을

00:03:24.260 --> 00:03:26.260
개발하면서 배운 것은,

00:03:26.260 --> 00:03:28.260
로봇이 실제로 매우 흥미로운

00:03:28.260 --> 00:03:30.260
사회적 기술이라는 것입니다.

00:03:30.260 --> 00:03:32.260
실제로 우리의 사회적 버튼을 누르고

00:03:32.260 --> 00:03:34.260
우리와 파트너처럼

00:03:34.260 --> 00:03:36.260
상호소통 하는 로봇의 능력은

00:03:36.260 --> 00:03:39.260
로봇 기능의 핵심 부분입니다.

00:03:39.260 --> 00:03:41.260
그리고 그 생각의 변화로, 우리는 이제

00:03:41.260 --> 00:03:44.260
달리 생각 못해 봤었을지도 모를

00:03:44.260 --> 00:03:47.260
로봇에 대한 새로운 문제와 새로운 가능성을 상상할 수 있습니다.

00:03:47.260 --> 00:03:49.260
제가 "사회적 버튼을 누른다"고 했을 때 무엇을 의미하는 것일까요?

00:03:49.260 --> 00:03:51.260
자, 우리가 배워온 것들 중 하나는

00:03:51.260 --> 00:03:53.260
우리가 동일한 바디 랭귀지와

00:03:53.260 --> 00:03:55.260
사람들이 사용하는 동일한 비언어적 신호를 사용하여

00:03:55.260 --> 00:03:57.260
우리와 의사소통하도록 이 로봇들을 디자인 한다면,

00:03:57.260 --> 00:04:00.260
-- 여기 작동하고 있는 휴머노이드 로봇 넥시 같이 말입니다. --

00:04:00.260 --> 00:04:02.260
우리가 발견한 것은 사람들이 사람들에게 반응하는 것과

00:04:02.260 --> 00:04:04.260
매우 유사하게 로봇에게 반응한다는 것입니다.

00:04:04.260 --> 00:04:07.260
사람들은 누군가가 얼마나 설득력 있고, 얼마나 호감이 가는지,

00:04:07.260 --> 00:04:09.260
얼마나 매력적인가, 얼마나 신뢰할 수 있을지를

00:04:09.260 --> 00:04:11.260
결정하기 위해서 이 신호를 이용합니다.

00:04:11.260 --> 00:04:13.260
로봇에게도 동일하다는 것이 나타나고 있습니다.

00:04:13.260 --> 00:04:15.260
로봇이 인간의 행위를 이해하는데

00:04:15.260 --> 00:04:18.260
사실 정말 흥미로운 새 과학적 도구가 되고 있음이

00:04:18.260 --> 00:04:20.260
지금 나타나고 있습니다.

00:04:20.260 --> 00:04:23.260
그런 질문에 답을 하기 위해서, 짧은 만남에서

00:04:23.260 --> 00:04:26.260
다른 사람을 얼마나 신뢰할 수 있을지 어떻게 평가할 수 있을까요?

00:04:26.260 --> 00:04:29.260
흉내는 것을 통해서라고 여겨집니다. 하지만 어떻게요?

00:04:29.260 --> 00:04:32.260
중요한 특정 동작을 흉내내는 것일까요?

00:04:32.260 --> 00:04:34.260
사람들을 관찰하는 것에서

00:04:34.260 --> 00:04:36.260
이를 학습하거나 이해하는 것은 정말 어려운 일입니다.

00:04:36.260 --> 00:04:39.260
우리가 상호소통할 때, 신호들을 무의식적으로 실행하기 때문입니다.

00:04:39.260 --> 00:04:41.260
잠재의식적인 것이기 때문에, 우리는 그것들을 세심하게 통제할 수 없습니다.

00:04:41.260 --> 00:04:43.260
하지만 로봇으로는 가능합니다.

00:04:43.260 --> 00:04:45.260
여기 보시는 영상에서,

00:04:45.260 --> 00:04:48.260
이 영상은 노스이스턴 대학, 데이비드 데스테노의 연구실에서 찍은 영상입니다.

00:04:48.260 --> 00:04:50.260
그는 우리가 함께 일했던 심리학자입니다.

00:04:50.260 --> 00:04:53.260
이 질문을 연구할 수 있도록 넥시의 신호를

00:04:53.260 --> 00:04:56.260
주의 깊게 조절했던 과학자가 실제로 있습니다.

00:04:56.260 --> 00:04:58.260
그리고 결국, 이런 일을 하는 이유는

00:04:58.260 --> 00:05:00.260
사람들이 로봇과 상호소통할 때도

00:05:00.260 --> 00:05:03.260
사람인 것처럼 행동한다는 것을 밝혀내기 때문입니다.

00:05:03.260 --> 00:05:05.260
그래서 핵심 견해를 고려해볼 때,

00:05:05.260 --> 00:05:07.260
우리는 이제 새로운 방식의

00:05:07.260 --> 00:05:10.260
로봇 활용을 상상할 수 있습니다.

00:05:10.260 --> 00:05:13.260
예를 들어, 로봇이 우리의 비언어적 신호에 반응한다면,

00:05:13.260 --> 00:05:17.260
멋지고 새로운 의사소통 기술이 될 것입니다.

00:05:17.260 --> 00:05:19.260
자, 이것을 상상해보세요.

00:05:19.260 --> 00:05:21.260
여러분 휴대폰을 위한 로봇 악세사리는 어떤가요?

00:05:21.260 --> 00:05:23.260
여러분은 친구에게 전화를 합니다. 그녀는 송수화기를 로봇에 올려 놓습니다.

00:05:23.260 --> 00:05:25.260
그리고 짠! 여러분은 이제 '미봇'입니다.

00:05:25.260 --> 00:05:28.260
여러분은 시선을 맞출 수도 있고, 친구들과 대화를 나눌 수도 있습니다.

00:05:28.260 --> 00:05:30.260
돌아다니고, 몸짓을 할 수도 있습니다.

00:05:30.260 --> 00:05:33.260
아마도 실제 그 자리에 같이 있는 것 다음으로 좋은 것이 아닐까요?

00:05:33.260 --> 00:05:35.260
이 질문을 탐구하기 위해서

00:05:35.260 --> 00:05:38.260
제 학생인 '시기 아댈기어슨'은

00:05:38.260 --> 00:05:41.260
원격의 협력자와 협업을 할 수 있도록

00:05:41.260 --> 00:05:43.260
연구실로 데려온 참여자들을

00:05:43.260 --> 00:05:45.260
연구했습니다.

00:05:45.260 --> 00:05:47.260
그 과제는 탁자 위에 놓인

00:05:47.260 --> 00:05:49.260
일련의 물체들을 바라보고,

00:05:49.260 --> 00:05:52.260
그것의 중요성과 특정 작업 수행과의 관련성에 대해 토론하며,

00:05:52.260 --> 00:05:54.260
-- 이것은 서바이벌 과제가 되었습니다. --

00:05:54.260 --> 00:05:56.260
그들이 그 물체들이 얼마나 가치있고 중요하다고

00:05:56.260 --> 00:05:58.260
생각하는지에 대한 등급을 매기는 것을 포함합니다.

00:05:58.260 --> 00:06:01.260
원격 협력자는 참가자들과 상호작용하기 위해

00:06:01.260 --> 00:06:03.260
세 가지의 다른 기술 중 하나를 사용하는

00:06:03.260 --> 00:06:05.260
저희 그룹의 실험자들이었습니다.

00:06:05.260 --> 00:06:07.260
첫 번째 기술은 그냥 화면입니다.

00:06:07.260 --> 00:06:10.260
이것은 오늘날의 비디오 화상회의와 유사합니다.

00:06:10.260 --> 00:06:13.260
다음 기술은 이동성을 더하는 것입니다. 화면을 모바일 기반으로 만듭니다.

00:06:13.260 --> 00:06:16.260
여러분이 오늘날의 텔레프레전스 로봇 같은 것에 익숙하다면,

00:06:16.260 --> 00:06:19.260
이것은 그 환경을 반영하고 있습니다.

00:06:19.260 --> 00:06:21.260
그리고 나서 아주 표현적인 미봇이 있습니다.

00:06:21.260 --> 00:06:23.260
그래서 상호작용 후에,

00:06:23.260 --> 00:06:26.260
우리는 사람들에게 기술과,

00:06:26.260 --> 00:06:28.260
원격 협력자와의 상호작용 품질을

00:06:28.260 --> 00:06:31.260
평가하도록 요청합니다.

00:06:31.260 --> 00:06:33.260
다른 사람에게 얼마나 공감을 느꼈는지

00:06:33.260 --> 00:06:35.260
심리적 관여를 살펴봅니다.

00:06:35.260 --> 00:06:37.260
우리는 전반적인 참여를 살펴봅니다.

00:06:37.260 --> 00:06:39.260
그들이 협력하고자 하는 욕구를 살펴봅니다.

00:06:39.260 --> 00:06:42.260
이것이 화면만을 사용할 때 확인한 것입니다.

00:06:42.260 --> 00:06:45.260
이동성을 더했을 때, --테이블 이리저리로 이동할 수 있는 능력이죠.--

00:06:45.260 --> 00:06:47.260
조금 더 증가하는 것을 볼 수 있습니다.

00:06:47.260 --> 00:06:50.260
그리고 충분한 표현력을 더했을 때, 더 증가하게 되죠.

00:06:50.260 --> 00:06:52.260
그래서 물리적인 사회적 체현이

00:06:52.260 --> 00:06:54.260
실제로 차이를 만드는 것 같습니다.

00:06:54.260 --> 00:06:57.260
이제, 이것을 약간의 맥략에 대입해보기로 하죠.

00:06:57.260 --> 00:07:00.260
오늘날 가족들이 서로 멀리 떨어져 살고 있고,

00:07:00.260 --> 00:07:02.260
그것이 가족 관계에 큰 타격을 주고 있으며,

00:07:02.260 --> 00:07:04.260
가족의 결속은 멀어지고 있다는 것을 알고 있습니다.

00:07:04.260 --> 00:07:06.260
저는 아들 셋이 있습니다.

00:07:06.260 --> 00:07:08.260
그리고 저는 아이들이 할아버지, 할머니와

00:07:08.260 --> 00:07:10.260
정말 좋은 관계를 가지기 원합니다.

00:07:10.260 --> 00:07:12.260
하지만 우리 부모님은 수 천 마일을 떨어져 살고 계시고,

00:07:12.260 --> 00:07:14.260
그래서 서로 자주 보지 못하게 되죠.

00:07:14.260 --> 00:07:16.260
우리는 스카이프나 전화를 이용하지만,

00:07:16.260 --> 00:07:18.260
제 아이들은 어려서 대화를 하기 보다는

00:07:18.260 --> 00:07:20.260
그냥 놀기를 바라죠.

00:07:20.260 --> 00:07:22.260
아이들은 새로운 종류의 원거리 놀이 기술로서

00:07:22.260 --> 00:07:25.260
로봇에 대해 생각하는 아이디어를 좋아합니다.

00:07:25.260 --> 00:07:28.260
자, 저는 멀지 않을 미래를 상상합니다.

00:07:28.260 --> 00:07:30.260
저희 어머니는 컴퓨터로 가서

00:07:30.260 --> 00:07:32.260
브라우저를 열고, 작은 로봇에 접속할 수 있습니다.

00:07:32.260 --> 00:07:35.260
그리고 할머니-봇으로서

00:07:35.260 --> 00:07:37.260
그녀는 손자들과 함께

00:07:37.260 --> 00:07:39.260
손자의 실제 장난감을 가지고

00:07:39.260 --> 00:07:42.260
실제 세상에서 같이 놀 수 있습니다.

00:07:42.260 --> 00:07:44.260
저는 손녀딸이나 친구들과 함께 사회적 놀이를 할 수 있고,

00:07:44.260 --> 00:07:46.260
잠 잘 때의 동화를 나누는 것 같이

00:07:46.260 --> 00:07:48.260
온갖 집에서의 다른 활동들을 나눌 수 있는

00:07:48.260 --> 00:07:50.260
할머니들을 상상할 수 있습니다.

00:07:50.260 --> 00:07:52.260
그리고 이 기술을 통해서,

00:07:52.260 --> 00:07:54.260
오늘날에는 가능하지 않은 방식으로

00:07:54.260 --> 00:07:56.260
그들 손자들의 삶에

00:07:56.260 --> 00:07:58.260
적극적인 참여자가 될 수 있습니다.

00:07:58.260 --> 00:08:00.260
건강과 같은 다른 영역들에 대해서도

00:08:00.260 --> 00:08:02.260
생각해보도록 하죠.

00:08:02.260 --> 00:08:04.260
오늘날 미국에서는,

00:08:04.260 --> 00:08:07.260
65% 이상의 사람들이 과체중이거나 비만이고,

00:08:07.260 --> 00:08:09.260
이제 우리 아이들에게도 큰 문제입니다.

00:08:09.260 --> 00:08:11.260
그리고 여러분이 어릴 때 비만이었다면,

00:08:11.260 --> 00:08:14.260
어릴 때 비만이었다면, 우리 삶의 질을 감소시킬 뿐만 아니라

00:08:14.260 --> 00:08:16.260
우리의 건강관리 시스템에 엄청난 경제적 부담이 되는

00:08:16.260 --> 00:08:19.260
만성 질병으로 이어질 수 있다는 것을 알고 있습니다.

00:08:19.260 --> 00:08:21.260
하지만 로봇이 매력적이라면,

00:08:21.260 --> 00:08:23.260
우리가 로봇과 협력하기는걸 좋아한다면,

00:08:23.260 --> 00:08:25.260
로봇이 설득력을 발휘할 수 있다면,

00:08:25.260 --> 00:08:27.260
아마도 로봇은 여러분이

00:08:27.260 --> 00:08:29.260
다이어트와 운동을 유지하도록,

00:08:29.260 --> 00:08:32.260
체중을 관리하도록 도울 수 있을 것입니다.

00:08:32.260 --> 00:08:34.260
일종의 디지털 지미니 같이,

00:08:34.260 --> 00:08:36.260
-- 유명한 동화에서 처럼 말이죠. --

00:08:36.260 --> 00:08:38.260
옳은 방법, 적절한 시간에 옳은 결정을 내리도록,

00:08:38.260 --> 00:08:40.260
여러분이 건강한 습관을 만들도록

00:08:40.260 --> 00:08:42.260
도와줄 수 있게 언제나 그곳에 있는

00:08:42.260 --> 00:08:44.260
우호적으로 도와주는 존재입니다.

00:08:44.260 --> 00:08:46.260
우리는 실제로 우리 실험실에서 이 아이디어를 탐구했습니다.

00:08:46.260 --> 00:08:48.260
이 로봇은 오톰입니다.

00:08:48.260 --> 00:08:51.260
코리 키드가 박사학위 작품으로 이 로봇을 개발했습니다.

00:08:51.260 --> 00:08:54.260
이 로봇은 다이어트와 운동 코치로 디자인 되었습니다.

00:08:54.260 --> 00:08:56.260
그것은 몇 가지 단순한 비언어적 기능을 가지고 있습니다.

00:08:56.260 --> 00:08:58.260
여러분과 눈을 맞출 수도 있고,

00:08:58.260 --> 00:09:00.260
화면에 내려다 보는 정보를 공유할 수도 있습니다.

00:09:00.260 --> 00:09:02.260
여러분은 그 날 섭취한 칼로리가 얼마인지,

00:09:02.260 --> 00:09:04.260
운동량은 얼마나 되는지 같은 정보를 입력하는

00:09:04.260 --> 00:09:06.260
화면 인터페이스를 사용할 것입니다.

00:09:06.260 --> 00:09:08.260
그리고 나서 여러분을 위해 그 정보를 추척하도록 해줍니다.

00:09:08.260 --> 00:09:10.260
그리고 로봇은 여러분이 트레이너와

00:09:10.260 --> 00:09:12.260
환자 등을 모델로 삼아 구성된

00:09:12.260 --> 00:09:14.260
코칭 문답에 참여하도록

00:09:14.260 --> 00:09:16.260
합성된 음성으로 말합니다.

00:09:16.260 --> 00:09:18.260
그리고 그 문답을 통해 여러분과

00:09:18.260 --> 00:09:20.260
기본적인 협조를 이룰 것입니다.

00:09:20.260 --> 00:09:22.260
목표를 설정하고, 그 과정을 추적하도록 도울 수 있으며,

00:09:22.260 --> 00:09:24.260
여러분에게 동기를 부여할 것입니다.

00:09:24.260 --> 00:09:26.260
흥미로운 질문은 다음과 같습니다.

00:09:26.260 --> 00:09:29.260
사회적 체현이 정말 중요할까요? 로봇이라는 것이 중요할까요?

00:09:29.260 --> 00:09:32.260
권고와 정보의 질이 정말 중요할까요?

00:09:32.260 --> 00:09:34.260
그 문제를 풀기 위해서,

00:09:34.260 --> 00:09:36.260
몇 주 동안 보스턴 지역에서

00:09:36.260 --> 00:09:39.260
여러 가정에 세 가지 중 하나의 개입 방법을

00:09:39.260 --> 00:09:41.260
적용해봤습니다.

00:09:41.260 --> 00:09:44.260
하나의 경우가 여러분이 봤던 로봇, 오톰입니다.

00:09:44.260 --> 00:09:47.260
또 다른 하나는 동일한 터치 스크린 인터페이스를 갖추고,

00:09:47.260 --> 00:09:49.260
동일한 문답이 나타나는 컴퓨터였습니다.

00:09:49.260 --> 00:09:51.260
권고의 질은 동일했습니다.

00:09:51.260 --> 00:09:53.260
세 번째는 그냥 펜과 종이 기록이었습니다.

00:09:53.260 --> 00:09:55.260
여러분이 다이어트와 운동 프로그램을 시작할 때,

00:09:55.260 --> 00:09:58.260
그것이 전형적으로 얻게 되는 표준 간섭이기 때문입니다.

00:09:58.260 --> 00:10:01.260
우리가 진짜 살펴보기 원했던 것 중 하나는

00:10:01.260 --> 00:10:04.260
사람들이 얼마나 체중을 줄였는가가 아니라,

00:10:04.260 --> 00:10:07.260
얼마나 오랫동안 로봇과 상호작용 하는가였습니다.

00:10:07.260 --> 00:10:10.260
과제는 체중을 줄이는 것이 아니라 비만을 방지하는 것입니다.

00:10:10.260 --> 00:10:13.260
그리고 이 조정 중 하나와 오랫동안 상호작용하면 할 수록,

00:10:13.260 --> 00:10:16.260
더 긴 기간의 성공이 잠재적으로 나타납니다.

00:10:16.260 --> 00:10:18.260
그래서 제가 살펴보기 원한 첫 번째 것은

00:10:18.260 --> 00:10:20.260
사람들이 얼마나 오랫동안 이 시스템과 상호작용 하는가입니다.

00:10:20.260 --> 00:10:22.260
권고의 질이 컴퓨터와 동일했음에도 불구하고

00:10:22.260 --> 00:10:24.260
사람들은 로봇과

00:10:24.260 --> 00:10:27.260
더 많이 상호작용 했음이 밝혀졌습니다.

00:10:28.260 --> 00:10:31.260
기본적인 협조의 질에 대해서 평가하도록 요청받았을 때,

00:10:31.260 --> 00:10:33.260
사람들은 로봇에 더 높은 점수를 줬고,

00:10:33.260 --> 00:10:35.260
로봇을 더 신뢰했습니다.

00:10:35.260 --> 00:10:37.260
(웃음)

00:10:37.260 --> 00:10:39.260
그리고 여러분이 감정적 참여를 살펴볼 때,

00:10:39.260 --> 00:10:41.260
그것은 완전히 다릅니다.

00:10:41.260 --> 00:10:43.260
사람들은 로봇에 이름을 붙일 것입니다.

00:10:43.260 --> 00:10:45.260
로봇에 옷도 입힐 것이구요.

00:10:45.260 --> 00:10:47.260
(웃음)

00:10:47.260 --> 00:10:50.260
심지어 연구가 종류되고, 로봇 수거를 위해 사람들을 방문할 때,

00:10:50.260 --> 00:10:52.260
그들은 자동차까지 나와서 로봇에서 작별 인사를 할 것입니다.

00:10:52.260 --> 00:10:54.260
컴퓨터에게는 그렇게 하지 않았죠.

00:10:54.260 --> 00:10:56.260
오늘 마지막으로 말씀드리고 싶은 것은

00:10:56.260 --> 00:10:58.260
아이들이 사용하는 매체의 미래입니다.

00:10:58.260 --> 00:11:01.260
오늘날 아이들은 그것이 텔레비전이던 컴퓨터 게임이던 뭐든간에

00:11:01.260 --> 00:11:04.260
수 많은 시간을 화면 뒤에서 보내고 있다는 것을 우리는 알고 있습니다.

00:11:04.260 --> 00:11:07.260
제 아들들은 화면을 좋아합니다. 화면을 정말 좋아하죠.

00:11:07.260 --> 00:11:10.260
하지만 엄마로서 저는 아이들이

00:11:10.260 --> 00:11:12.260
현실 세계의 놀이와 같이 놀기를 바랍니다.

00:11:12.260 --> 00:11:15.260
그래서 저는 오늘 여러분께 보여드리고 싶은,

00:11:15.260 --> 00:11:17.260
'플레이타임 컴퓨팅'이라는 새로운 프로젝트가 있습니다.

00:11:17.260 --> 00:11:19.260
그것은 디지털 미디어에 대해

00:11:19.260 --> 00:11:21.260
무엇이 매력적인가와 그것을 문자 그대로

00:11:21.260 --> 00:11:23.260
화면에서 꺼내 아이들의 현실 세계로

00:11:23.260 --> 00:11:25.260
가져오는 것을 생각하려는 것입니다.

00:11:25.260 --> 00:11:28.260
그것은 현실 세계 놀이의 많은 특성들을 적용할 수 있습니다.

00:11:29.260 --> 00:11:33.260
여기 이 아이디어의 첫 번째 탐구가 있습니다.

00:11:33.260 --> 00:11:36.260
캐릭터가 물리적 또는 가상적으로 존재할 수 있고,

00:11:36.260 --> 00:11:38.260
디지털 콘텐츠가 문자 그대로

00:11:38.260 --> 00:11:40.260
화면에서 현실로 빠져나왔다

00:11:40.260 --> 00:11:42.260
다시 들어갈 수 있습니다.

00:11:42.260 --> 00:11:44.260
저는 이 혼합된 현실 게임을

00:11:44.260 --> 00:11:46.260
'아타리 퐁'으로

00:11:46.260 --> 00:11:48.260
생각하고 싶습니다.

00:11:48.260 --> 00:11:50.260
하지만 우리는 이 아이디어를 좀더 진행해볼 수 있습니다.

00:11:50.260 --> 00:11:52.260
만일

00:11:52.260 --> 00:11:55.260
(게임) 네이슨: 여기 간다. 야호!

00:11:55.260 --> 00:11:58.260
CB: 캐릭터 자체가 여러분의 실제 세상으로 나온다면 어떨까요?

00:11:58.260 --> 00:12:00.260
캐릭터가 현실이 되고

00:12:00.260 --> 00:12:03.260
그들의 세상으로 나올 때, 아이들이 너무 좋아한다는 것입니다.

00:12:03.260 --> 00:12:05.260
그리고 그것이 그들의 세상에 있을 때,

00:12:05.260 --> 00:12:07.260
아이들은 그것과 관계를 형성하고, 함께 놉니다.

00:12:07.260 --> 00:12:09.260
그것은 화면으로 노는 것과는 근본적으로 다릅니다.

00:12:09.260 --> 00:12:11.260
또 다른 중요한 아이디어는

00:12:11.260 --> 00:12:14.260
현실을 가로질러 캐릭터가 지속하는 개념입니다.

00:12:14.260 --> 00:12:16.260
그래서 현실 세상에서 아이들이 만들어 내는 변화는

00:12:16.260 --> 00:12:18.260
가상 세계로 옮겨져야할 필요가 있습니다.

00:12:18.260 --> 00:12:21.260
자 여기서, 네이슨은 문자 A를 숫자 2로 바꿨습니다.

00:12:21.260 --> 00:12:23.260
이런 심볼들이 가상 세계로 갈 때,

00:12:23.260 --> 00:12:26.260
캐릭터들에게 특별한 능력을 부여한다고 상상할 수 있을 것입니다.

00:12:26.260 --> 00:12:29.260
자, 아이들은 이제 캐릭터를 가상 세계로 돌려보냅니다.

00:12:29.260 --> 00:12:32.260
그리고 그것은 숫자의 능력을 얻었습니다.

00:12:32.260 --> 00:12:34.260
그리고 나서 마지막으로, 여기서 시도한 것은

00:12:34.260 --> 00:12:37.260
아이들이 그 이야기, 그 경험의 일부분이

00:12:37.260 --> 00:12:40.260
된 것처럼 느끼는, 둘러 싸는 듯한 경험을

00:12:40.260 --> 00:12:42.260
창조하는 것입니다.

00:12:42.260 --> 00:12:44.260
"스타워즈"를 보는 작은 소녀로 제 상상력이

00:12:44.260 --> 00:12:47.260
일깨워졌던 것처럼, 아이들의 상상력을 정말 일깨우고 싶습니다.

00:12:47.260 --> 00:12:49.260
하지만 저는 그것보다 더 나아가고 싶습니다.

00:12:49.260 --> 00:12:52.260
저는 사실 그들이 그 경험들을 창조하기 원합니다.

00:12:52.260 --> 00:12:54.260
저는 그들이 문자 그대로 그들의 상상력을 이 경험들로

00:12:54.260 --> 00:12:56.260
만들어낼 수 있고, 그들만의 것으로 만들 수 있기를 원합니다.

00:12:56.260 --> 00:12:58.260
자, 저는 아이들이 그들의 생각을

00:12:58.260 --> 00:13:00.260
다른 아이들과 상호작용하며

00:13:00.260 --> 00:13:03.260
구축할 수 있는 공간에 투영할 수 있도록 만드는

00:13:03.260 --> 00:13:05.260
텔레프레전스와 혼합된 현실에서의

00:13:05.260 --> 00:13:07.260
수 많은 아이디어를 탐구해왔습니다.

00:13:07.260 --> 00:13:10.260
저는 창조성, 학습, 혁신을 기를 수 있는

00:13:10.260 --> 00:13:13.260
어린이 매체의 새로운 방식을 제시하고 싶습니다.

00:13:13.260 --> 00:13:16.260
저는 그것이 아주 아주 중요하다고 생각합니다.

00:13:16.260 --> 00:13:18.260
자, 이것은 새로운 프로젝트입니다.

00:13:18.260 --> 00:13:20.260
우리는 수 많은 아이들을 여기로 초대했고,

00:13:20.260 --> 00:13:23.260
아이들은 그게 아주 멋지다고 생각하죠.

00:13:23.260 --> 00:13:25.260
하지만 저는 그들이 제일 좋아하는 것이

00:13:25.260 --> 00:13:27.260
로봇이라고 말할 수 있습니다.

00:13:27.260 --> 00:13:30.260
그들이 관심을 가지는 것은 로봇입니다.

00:13:30.260 --> 00:13:33.260
로봇은 우리 안에 깊이 존재하는 인간적인 것을 어루만집니다.

00:13:33.260 --> 00:13:35.260
그리고 로봇이 우리가 창조적이고

00:13:35.260 --> 00:13:37.260
혁신적이 되도록 하던지

00:13:37.260 --> 00:13:39.260
우리가 거리에도 불구하고

00:13:39.260 --> 00:13:41.260
보다 깊이 연결되었다고 느끼도록 하던지,

00:13:41.260 --> 00:13:43.260
우리가 최고와 최선의 자아가 되는데 있어

00:13:43.260 --> 00:13:45.260
우리의 개인적 목표들을 성취할 수 있도록

00:13:45.260 --> 00:13:47.260
돕는 신뢰할 수 있는 친구가 되던지 간에,

00:13:47.260 --> 00:13:50.260
제게는 로봇이 사람들에게 최고입니다.

00:13:50.260 --> 00:13:52.260
감사합니다.

00:13:52.260 --> 00:13:57.260
(박수)

