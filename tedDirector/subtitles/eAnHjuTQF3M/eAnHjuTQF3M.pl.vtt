WEBVTT
Kind: captions
Language: pl

00:00:00.000 --> 00:00:07.000
Tłumaczenie: Kinga Skorupska
Korekta: Marcin Cwikla

00:00:15.260 --> 00:00:18.260
Odkąd byłam małą dziewczynką

00:00:18.260 --> 00:00:20.260
i zobaczyłam "Gwiezdne Wojny"

00:00:20.260 --> 00:00:22.260
byłam zafascynowana pomysłem

00:00:22.260 --> 00:00:24.260
robotów osobistych.

00:00:24.260 --> 00:00:26.260
Uwielbiałam to,

00:00:26.260 --> 00:00:28.260
że roboty były między ludźmi

00:00:28.260 --> 00:00:31.260
jako zaufani pomocnicy...

00:00:31.260 --> 00:00:33.260
Miały nas zachwycić, wzbogacić nasze życia

00:00:33.260 --> 00:00:36.260
i pomóc nam uratować kilka galaktyk.

00:00:37.260 --> 00:00:40.260
Takie roboty jeszcze nie istniały,

00:00:40.260 --> 00:00:42.260
ale chciałam je zbudować.

00:00:42.260 --> 00:00:44.260
Po 20 latach...

00:00:44.260 --> 00:00:46.260
jestem absolwentką MIT

00:00:46.260 --> 00:00:48.260
zajmującą się sztuczną inteligencją,

00:00:48.260 --> 00:00:50.260
jest rok 1997,

00:00:50.260 --> 00:00:53.260
NASA wysłała pierwszego robota na Marsa.

00:00:53.260 --> 00:00:56.260
Robotów nadal nie ma w naszych domach.

00:00:56.260 --> 00:00:58.260
Pamiętam, że rozmyślałam

00:00:58.260 --> 00:01:00.260
o przyczynach takiego stanu rzeczy.

00:01:00.260 --> 00:01:02.260
Jedna się wyróżniała.

00:01:02.260 --> 00:01:05.260
Robotyka polega na interakcjach z rzeczami,

00:01:05.260 --> 00:01:07.260
a nie z ludźmi,

00:01:07.260 --> 00:01:09.260
a już na pewno nie na interakcjach naturalnych dla ludzi

00:01:09.260 --> 00:01:11.260
co pomogłoby ludziom zobaczyć roboty

00:01:11.260 --> 00:01:13.260
jako część życia codziennego.

00:01:13.260 --> 00:01:16.260
Roboty tego nie potrafiły, to była biała plama.

00:01:16.260 --> 00:01:19.260
Wtedy zaczęłam budować Kismeta,

00:01:19.260 --> 00:01:22.260
pierwszego robota socjalnego.

00:01:22.260 --> 00:01:24.260
Trzy lata później,

00:01:24.260 --> 00:01:26.260
po masie programowania

00:01:26.260 --> 00:01:28.260
i pracy z innymi absolwentami

00:01:28.260 --> 00:01:30.260
Kismet był gotowy na spotkanie z ludźmi.

00:01:30.260 --> 00:01:32.260
(Film) Naukowiec: Pokażę ci coś.

00:01:32.260 --> 00:01:34.260
Kismet: (Mamrocze).

00:01:34.260 --> 00:01:37.260
Naukowiec: Dostałem to od dziewczyny.

00:01:37.260 --> 00:01:39.260
Kismet: (Mamrocze)

00:01:39.260 --> 00:01:41.260
Naukowiec: Popatrz, ma niebieskie światełko.

00:01:41.260 --> 00:01:44.260
Prawie go zgubiłem.

00:01:44.260 --> 00:01:47.260
CB: Kismet wchodził w interakcje z ludźmi

00:01:47.260 --> 00:01:50.260
jak dziecko, które jeszcze nie umie mówić,

00:01:50.260 --> 00:01:53.260
co pasuje, bo jest pierwszy w swoim rodzaju.

00:01:53.260 --> 00:01:55.260
Nie umiał mówić, ale to nie miało znaczenia.

00:01:55.260 --> 00:01:57.260
Był w stanie oddziaływać

00:01:57.260 --> 00:02:00.260
na naszą socjalną nutę.

00:02:00.260 --> 00:02:02.260
To obietnica nowego sposobu

00:02:02.260 --> 00:02:04.260
interakcji z robotami.

00:02:04.260 --> 00:02:06.260
Przez ostatnie kilka lat

00:02:06.260 --> 00:02:08.260
badałam relacje interpersonalne robotów

00:02:08.260 --> 00:02:10.260
w laboratorium medialnym

00:02:10.260 --> 00:02:12.260
z zespołem utalentowanych studentów.

00:02:12.260 --> 00:02:15.260
Leonardo to mój faworyt.

00:02:15.260 --> 00:02:18.260
Stworzyliśmy go wraz ze Studiem Stana Winstona.

00:02:18.260 --> 00:02:21.260
Pokażę wam szczególny moment.

00:02:21.260 --> 00:02:23.260
Matt Berlin pokazuje Leo nowy obiekt.

00:02:23.260 --> 00:02:25.260
Matt Berlin pokazuje Leo nowy obiekt.

00:02:25.260 --> 00:02:28.260
Leo nie wie co z nim zrobić, bo jest dla niego nowy.

00:02:28.260 --> 00:02:30.260
Ale może się nauczyć,

00:02:30.260 --> 00:02:33.260
obserwując reakcję Matta.

00:02:33.260 --> 00:02:35.260
(Film) MB: Cześć, Leo.

00:02:38.260 --> 00:02:41.260
To Ciasteczkowy Potwór.

00:02:44.260 --> 00:02:47.260
Możesz go znaleźć?

00:02:52.260 --> 00:02:55.260
Ciasteczkowy potwór jest bardzo zły.

00:02:56.260 --> 00:02:58.260
Jest bardzo zły.

00:03:00.260 --> 00:03:03.260
Ciasteczkowy Potwór jest zły, bardzo zły.

00:03:07.260 --> 00:03:09.260
Jest przerażający.

00:03:09.260 --> 00:03:11.260
Chce ukraść twoje ciasteczka.

00:03:12.260 --> 00:03:14.260
(Śmiech)

00:03:14.260 --> 00:03:17.260
SB: Leo i Cookie

00:03:17.260 --> 00:03:19.260
mieli trudne początki,

00:03:19.260 --> 00:03:22.260
ale teraz się dogadują.

00:03:22.260 --> 00:03:24.260
Nauczyłam się,

00:03:24.260 --> 00:03:26.260
dzięki tworzeniu tych systemów,

00:03:26.260 --> 00:03:28.260
że roboty to bardzo ciekawa

00:03:28.260 --> 00:03:30.260
technologia socjalna.

00:03:30.260 --> 00:03:32.260
Są w stanie

00:03:32.260 --> 00:03:34.260
do nas przemawiać,

00:03:34.260 --> 00:03:36.260
być partnerami,

00:03:36.260 --> 00:03:39.260
co jest ich zadaniem.

00:03:39.260 --> 00:03:41.260
Możemy sobie wyobrazić

00:03:41.260 --> 00:03:44.260
nowe pytania i możliwości,

00:03:44.260 --> 00:03:47.260
wcześniej nie do pomyślenia.

00:03:47.260 --> 00:03:49.260
Co dokładnie przez to rozumiem?

00:03:49.260 --> 00:03:51.260
Nauczyłam się, że jeśli zaprojektujemy

00:03:51.260 --> 00:03:53.260
roboty, by się z nami porozumiewały

00:03:53.260 --> 00:03:55.260
używając tej samej mowy ciała,

00:03:55.260 --> 00:03:57.260
tych samych wskazówek, których używają ludzie,

00:03:57.260 --> 00:04:00.260
jak robi to Nexi, nasz robot humanoidalny...

00:04:00.260 --> 00:04:02.260
Ludzie reagują na roboty

00:04:02.260 --> 00:04:04.260
podobnie jak na innych ludzi.

00:04:04.260 --> 00:04:07.260
Szukają wskazówek, by zdecydować czy ktoś jest przekonujący,

00:04:07.260 --> 00:04:09.260
czy da się go polubić, czy jest zajmujący

00:04:09.260 --> 00:04:11.260
lub godny zaufania.

00:04:11.260 --> 00:04:13.260
Podobnie jest z robotami.

00:04:13.260 --> 00:04:15.260
Okazuje się,

00:04:15.260 --> 00:04:18.260
że roboty stają się ciekawym narzędziem

00:04:18.260 --> 00:04:20.260
do badania ludzkich zachowań.

00:04:20.260 --> 00:04:23.260
Możemy się dowiedzieć jak szybko ludzie oceniają

00:04:23.260 --> 00:04:26.260
czy ktoś jest godny zaufania.

00:04:26.260 --> 00:04:29.260
Naśladowanie zachowań odgrywa rolę.

00:04:29.260 --> 00:04:32.260
Czy chodzi o konkretne gesty?

00:04:32.260 --> 00:04:34.260
Trudno to zrozumieć

00:04:34.260 --> 00:04:36.260
obserwując ludzi.

00:04:36.260 --> 00:04:39.260
Nasze zachowania są automatyczne.

00:04:39.260 --> 00:04:41.260
Są podświadome, więc trudno nimi sterować.

00:04:41.260 --> 00:04:43.260
Ale u robota można.

00:04:43.260 --> 00:04:45.260
Ten film był zrobiony w laboratorium

00:04:45.260 --> 00:04:48.260
Dawida DeSteno z Uniwersytetu Północno-Wschodniego.

00:04:48.260 --> 00:04:50.260
To psycholog, z którym współpracowaliśmy.

00:04:50.260 --> 00:04:53.260
Kontrolują sygnały jakie wysyła Nexi,

00:04:53.260 --> 00:04:56.260
żeby zbadać to zagadnienie.

00:04:56.260 --> 00:04:58.260
To działa, bo ludzie

00:04:58.260 --> 00:05:00.260
zachowują się jak ludzie,

00:05:00.260 --> 00:05:03.260
gdy przebywają z robotem.

00:05:03.260 --> 00:05:05.260
Dzięki temu

00:05:05.260 --> 00:05:07.260
możemy sobie wyobrazić

00:05:07.260 --> 00:05:10.260
nowe zastosowania dla robotów.

00:05:10.260 --> 00:05:13.260
Roboty odpowiadają na nasze sygnały,

00:05:13.260 --> 00:05:17.260
mogłyby być nową technologią komunikacyjną.

00:05:17.260 --> 00:05:19.260
Wyobraźcie sobie to:

00:05:19.260 --> 00:05:21.260
Roboty jako akcesoria do telefonu.

00:05:21.260 --> 00:05:23.260
Dzwonicie do znajomych, oni wkładają telefon

00:05:23.260 --> 00:05:25.260
do robota i jesteście JaBotem,

00:05:25.260 --> 00:05:28.260
utrzymujecie kontakt wzrokowy, rozmawiacie,

00:05:28.260 --> 00:05:30.260
poruszacie się, gestykulujecie...

00:05:30.260 --> 00:05:33.260
To prawie jakbyście tam byli. Czy jest różnica?

00:05:33.260 --> 00:05:35.260
By odpowiedzieć na to pytanie

00:05:35.260 --> 00:05:38.260
moja studentka, Siggy Adalgeirsson

00:05:38.260 --> 00:05:41.260
zbadała interakcje ludzi

00:05:41.260 --> 00:05:43.260
podczas grupowego zadania

00:05:43.260 --> 00:05:45.260
z odległym współpracownikiem.

00:05:45.260 --> 00:05:47.260
Zadanie wymagało

00:05:47.260 --> 00:05:49.260
rozpoznania obiektów na stole,

00:05:49.260 --> 00:05:52.260
rozmowy o tym czy są ważne dla wykonania zadania,

00:05:52.260 --> 00:05:54.260
które polegało na przetrwaniu...

00:05:54.260 --> 00:05:56.260
Trzeba było je ocenić

00:05:56.260 --> 00:05:58.260
w zależności od przydatności.

00:05:58.260 --> 00:06:01.260
Tym współpracownikiem był członek naszego zespołu,

00:06:01.260 --> 00:06:03.260
który używał trzech różnych technologii

00:06:03.260 --> 00:06:05.260
by porozumiewać się z grupą.

00:06:05.260 --> 00:06:07.260
Najpierw był ekran.

00:06:07.260 --> 00:06:10.260
To jak dzisiejsze wideokonferencje.

00:06:10.260 --> 00:06:13.260
Potem dodaliśmy mobilność, ekran się poruszał.

00:06:13.260 --> 00:06:16.260
Jak roboty do teleobecności,

00:06:16.260 --> 00:06:19.260
coś w tym stylu.

00:06:19.260 --> 00:06:21.260
Na koniec JaBot - w pełni interaktywny.

00:06:21.260 --> 00:06:23.260
Potem poprosiliśmy ludzi

00:06:23.260 --> 00:06:26.260
by ocenili jakość ich interakcji

00:06:26.260 --> 00:06:28.260
z odległym współpracownikiem

00:06:28.260 --> 00:06:31.260
zależnie od użytej technologii.

00:06:31.260 --> 00:06:33.260
Badaliśmy zaangażowanie psychologiczne...

00:06:33.260 --> 00:06:35.260
Jak głęboką ci ludzie odczuwali empatię?

00:06:35.260 --> 00:06:37.260
Badaliśmy ogólne zaangażowanie.

00:06:37.260 --> 00:06:39.260
Chęć współpracy.

00:06:39.260 --> 00:06:42.260
To się dzieje, gdy jest tylko ekran.

00:06:42.260 --> 00:06:45.260
Jeśli jest mobilny... Porusza się po stole...

00:06:45.260 --> 00:06:47.260
Współczynniki rosną.

00:06:47.260 --> 00:06:50.260
Gdy jest interaktywny jest jeszcze lepiej.

00:06:50.260 --> 00:06:52.260
Fizyczna obecność robi różnicę.

00:06:52.260 --> 00:06:54.260
Fizyczna obecność robi różnicę.

00:06:54.260 --> 00:06:57.260
Pomyślmy o tym w kontekście.

00:06:57.260 --> 00:07:00.260
Członkowie rodzin żyją coraz dalej od siebie,

00:07:00.260 --> 00:07:02.260
co wpływa na ich wzajemne stosunki.

00:07:02.260 --> 00:07:04.260
co wpływa na ich wzajemne stosunki.

00:07:04.260 --> 00:07:06.260
Mam trzech synów,

00:07:06.260 --> 00:07:08.260
chcę żeby mieli dobre stosunki

00:07:08.260 --> 00:07:10.260
z swoimi dziadkami.

00:07:10.260 --> 00:07:12.260
Ale moi rodzice żyją bardzo daleko,

00:07:12.260 --> 00:07:14.260
więc nie widują się tak często.

00:07:14.260 --> 00:07:16.260
Próbujemy Skype, rozmów telefonicznych

00:07:16.260 --> 00:07:18.260
ale moi chłopcy nie chcą rozmawiać,

00:07:18.260 --> 00:07:20.260
chcą się bawić.

00:07:20.260 --> 00:07:22.260
Uwielbiam myśleć o robotach,

00:07:22.260 --> 00:07:25.260
jako nowych zabawkach na odległość.

00:07:25.260 --> 00:07:28.260
Niedługo moja mama mogłaby

00:07:28.260 --> 00:07:30.260
podejść do komputera

00:07:30.260 --> 00:07:32.260
i połączyć się z robotem.

00:07:32.260 --> 00:07:35.260
Jako BabciaBot

00:07:35.260 --> 00:07:37.260
mogłaby się bawić

00:07:37.260 --> 00:07:39.260
z moimi synami,

00:07:39.260 --> 00:07:42.260
w prawdziwym świecie prawdziwymi zabawkami.

00:07:42.260 --> 00:07:44.260
Babcie będą mogły się bawić

00:07:44.260 --> 00:07:46.260
ze swoimi wnukami, przyjaciółmi

00:07:46.260 --> 00:07:48.260
wykonując różne czynności w domu,

00:07:48.260 --> 00:07:50.260
jak czytanie na dobranoc.

00:07:50.260 --> 00:07:52.260
Dzięki tej technologii

00:07:52.260 --> 00:07:54.260
będzie można brać czynny udział

00:07:54.260 --> 00:07:56.260
w życiu wnuków

00:07:56.260 --> 00:07:58.260
w sposób dziś niemożliwy.

00:07:58.260 --> 00:08:00.260
Pomyślmy o czymś innym.

00:08:00.260 --> 00:08:02.260
Zdrowie.

00:08:02.260 --> 00:08:04.260
Dziś w Stanach 65% ludzi

00:08:04.260 --> 00:08:07.260
ma nadwagę lub jest otyła,

00:08:07.260 --> 00:08:09.260
to spory problem, także u dzieci.

00:08:09.260 --> 00:08:11.260
Dziecięca otyłość

00:08:11.260 --> 00:08:14.260
prowadzi do chorób w dorosłym życiu,

00:08:14.260 --> 00:08:16.260
które zmniejszają jakość życia

00:08:16.260 --> 00:08:19.260
i są ciężarem dla naszej służby zdrowia.

00:08:19.260 --> 00:08:21.260
Ale roboty mogą być zajmujące,

00:08:21.260 --> 00:08:23.260
lubimy z nimi współpracować,

00:08:23.260 --> 00:08:25.260
jeśli będą przekonujące

00:08:25.260 --> 00:08:27.260
może będą w stanie pomóc

00:08:27.260 --> 00:08:29.260
w trzymaniu się diety i ćwiczeń,

00:08:29.260 --> 00:08:32.260
co pomoże ludziom schudnąć.

00:08:32.260 --> 00:08:34.260
Jak cyfrowy świerszcz Jiminy

00:08:34.260 --> 00:08:36.260
ze znanej bajki...

00:08:36.260 --> 00:08:38.260
Pomocna obecność, zawsze przy tobie,

00:08:38.260 --> 00:08:40.260
gdy trzeba podjąć decyzję,

00:08:40.260 --> 00:08:42.260
w samą porę by pomóc tworzyć

00:08:42.260 --> 00:08:44.260
zdrowe nawyki.

00:08:44.260 --> 00:08:46.260
To też badaliśmy w laboratorium.

00:08:46.260 --> 00:08:48.260
To Autom, robot.

00:08:48.260 --> 00:08:51.260
Cory Kidd stworzył go jako pracę doktorancką.

00:08:51.260 --> 00:08:54.260
Robot jest trenerem i pomaga przy diecie.

00:08:54.260 --> 00:08:56.260
Może robić kilka rzeczy.

00:08:56.260 --> 00:08:58.260
Może patrzeć na ciebie.

00:08:58.260 --> 00:09:00.260
Pokazywać informacje na ekranie.

00:09:00.260 --> 00:09:02.260
Używa się interfejsu by wpisać

00:09:02.260 --> 00:09:04.260
ile kalorii się zjadło

00:09:04.260 --> 00:09:06.260
i ile się ćwiczyło.

00:09:06.260 --> 00:09:08.260
Pomaga się we wszystkim ogarnąć.

00:09:08.260 --> 00:09:10.260
Robot używa syntetycznej mowy

00:09:10.260 --> 00:09:12.260
by rozmawiać naśladując trenerów i ich klientów.

00:09:12.260 --> 00:09:14.260
by rozmawiać naśladując trenerów i ich klientów.

00:09:14.260 --> 00:09:16.260
by rozmawiać naśladując trenerów i ich klientów.

00:09:16.260 --> 00:09:18.260
Buduje profesjonalne stosunki

00:09:18.260 --> 00:09:20.260
poprzez rozmowę.

00:09:20.260 --> 00:09:22.260
Pomaga ustanawiać cele i sprawdzać postęp,

00:09:22.260 --> 00:09:24.260
pomaga w motywacji.

00:09:24.260 --> 00:09:26.260
Więc, czy socjalne wcielenie ma znaczenie?

00:09:26.260 --> 00:09:29.260
Czy to ważne, że mamy robota?

00:09:29.260 --> 00:09:32.260
Czy chodzi tylko o jakość informacji?

00:09:32.260 --> 00:09:34.260
Tak więc do rozwiązania tej kwestii,

00:09:34.260 --> 00:09:36.260
przeprowadziliśmy badania w okolicach Bostonu.

00:09:36.260 --> 00:09:39.260
Daliśmy ludziom trzy warianty do domu

00:09:39.260 --> 00:09:41.260
na kilka tygodni.

00:09:41.260 --> 00:09:44.260
Jednym z nich był Autom.

00:09:44.260 --> 00:09:47.260
Inny to komputer z tym samym interfejsem

00:09:47.260 --> 00:09:49.260
i dialogami.

00:09:49.260 --> 00:09:51.260
Jakość porad była taka sama.

00:09:51.260 --> 00:09:53.260
Trzeci to zwyczajny zapis na papierze,

00:09:53.260 --> 00:09:55.260
bo to standard przy diecie i ćwiczeniach.

00:09:55.260 --> 00:09:58.260
bo to standard przy diecie i ćwiczeniach.

00:09:58.260 --> 00:10:01.260
Chcieliśmy zobaczyć

00:10:01.260 --> 00:10:04.260
nie ile ludzie stracili na wadze,

00:10:04.260 --> 00:10:07.260
ale jak dużo czasu poświęcali robotowi.

00:10:07.260 --> 00:10:10.260
Bo chodzi o to, by stracone kilogramy nie wróciły.

00:10:10.260 --> 00:10:13.260
Im więcej czasu poświęca się tym interwencjom

00:10:13.260 --> 00:10:16.260
tym większa szansa na sukces.

00:10:16.260 --> 00:10:18.260
Popatrzmy jak dużo czasu

00:10:18.260 --> 00:10:20.260
ludzie poświęcali tym systemom.

00:10:20.260 --> 00:10:22.260
Z robotem spędzali dużo więcej czasu mimo tego,

00:10:22.260 --> 00:10:24.260
Z robotem spędzali dużo więcej czasu mimo tego,

00:10:24.260 --> 00:10:27.260
że jakość porad była identyczna do komputera.

00:10:28.260 --> 00:10:31.260
Gdy spytaliśmy z czym najlepiej się pracowało,

00:10:31.260 --> 00:10:33.260
ludzie wybierali robota

00:10:33.260 --> 00:10:35.260
i bardziej mu ufali.

00:10:35.260 --> 00:10:37.260
(Śmiech)

00:10:37.260 --> 00:10:39.260
Gdy zbadamy zaangażowanie emocjonalne,

00:10:39.260 --> 00:10:41.260
też były różnice.

00:10:41.260 --> 00:10:43.260
Ludzie dawali robotom imiona.

00:10:43.260 --> 00:10:45.260
Ubierali je.

00:10:45.260 --> 00:10:47.260
(Śmiech)

00:10:47.260 --> 00:10:50.260
Gdy przychodziliśmy by je zabrać na koniec,

00:10:50.260 --> 00:10:52.260
wychodzili z nami, żeby się pożegnać.

00:10:52.260 --> 00:10:54.260
Nie robili tego z komputerem.

00:10:54.260 --> 00:10:56.260
Na koniec chcę opowiedzieć

00:10:56.260 --> 00:10:58.260
o przyszłości mediów dla dzieci.

00:10:58.260 --> 00:11:01.260
Dzieci siedzą przy monitorach cały czas,

00:11:01.260 --> 00:11:04.260
czy to przy telewizji czy komputerach.

00:11:04.260 --> 00:11:07.260
Moi chłopcy uwielbiają monitory. Uwielbiają.

00:11:07.260 --> 00:11:10.260
Chcę, żeby się bawili, jako mama,

00:11:10.260 --> 00:11:12.260
w prawdziwym świecie.

00:11:12.260 --> 00:11:15.260
Zaczęłam nowy projekt, który dziś zaprezentuję.

00:11:15.260 --> 00:11:17.260
Playtime Computing.

00:11:17.260 --> 00:11:19.260
Bada on, co jest absorbujące

00:11:19.260 --> 00:11:21.260
w cyfrowych mediach,

00:11:21.260 --> 00:11:23.260
by przenieść to poza monitor

00:11:23.260 --> 00:11:25.260
do realnego świata dzieci,

00:11:25.260 --> 00:11:28.260
gdzie można to wpleść do specyfiki realnych zabaw.

00:11:29.260 --> 00:11:33.260
To pierwsza wariacja na temat tego pomysłu,

00:11:33.260 --> 00:11:36.260
postaci mogą być fizyczne lub wirtualne,

00:11:36.260 --> 00:11:38.260
a cyfrowa treść wychodzi poza ekran

00:11:38.260 --> 00:11:40.260
a cyfrowa treść wychodzi poza ekran

00:11:40.260 --> 00:11:42.260
do świata realnego.

00:11:42.260 --> 00:11:44.260
To jak Atari Pong

00:11:44.260 --> 00:11:46.260
To jak Atari Pong

00:11:46.260 --> 00:11:48.260
gra wymieszana z realem.

00:11:48.260 --> 00:11:50.260
Możemy pójść dalej.

00:11:50.260 --> 00:11:52.260
Co jeśli...

00:11:52.260 --> 00:11:55.260
(Gra) Nathan: Uwaga! Hurra!

00:11:55.260 --> 00:11:58.260
CB: postać mogłaby przejść do świata relanego.

00:11:58.260 --> 00:12:00.260
Dzieci uwielbiają gdy postaci

00:12:00.260 --> 00:12:03.260
stają się realne i wchodzą do ich świata.

00:12:03.260 --> 00:12:05.260
W ich świecie

00:12:05.260 --> 00:12:07.260
to do nich bardziej przemawia,

00:12:07.260 --> 00:12:09.260
bawią się inaczej, niż z ekranem.

00:12:09.260 --> 00:12:11.260
Innym ważnym pomysłem

00:12:11.260 --> 00:12:14.260
jest obecność postaci między światami.

00:12:14.260 --> 00:12:16.260
Zmiany jakie następują w realu

00:12:16.260 --> 00:12:18.260
muszą pojawiać się w świecie wirtualnym.

00:12:18.260 --> 00:12:21.260
Nathan zmienił literę A na numer 2.

00:12:21.260 --> 00:12:23.260
Może te symbole dają postaciom moce,

00:12:23.260 --> 00:12:26.260
które mogą wykorzystać w świecie wirtualnym.

00:12:26.260 --> 00:12:29.260
Teraz wysyłają tam te postacie.

00:12:29.260 --> 00:12:32.260
Mają one nową moc.

00:12:32.260 --> 00:12:34.260
Właśnie to staramy się zrobić,

00:12:34.260 --> 00:12:37.260
tworzymy całościowe doświadczenie dla dzieci,

00:12:37.260 --> 00:12:40.260
by dzieci czuły się jego częścią.

00:12:40.260 --> 00:12:42.260
by dzieci czuły się jego częścią.

00:12:42.260 --> 00:12:44.260
Chcę pobudzić ich wyobraźnię,

00:12:44.260 --> 00:12:47.260
jak się stało ze mną i filmem "Gwiezdne Wojny".

00:12:47.260 --> 00:12:49.260
Chce zrobić więcej.

00:12:49.260 --> 00:12:52.260
Chcę by tworzyły te doświadczenia.

00:12:52.260 --> 00:12:54.260
Chcę by mogły dokładać swoje wyobrażenia

00:12:54.260 --> 00:12:56.260
do rzeczywistości i ją przekształcać.

00:12:56.260 --> 00:12:58.260
Badaliśmy wiele pomysłów

00:12:58.260 --> 00:13:00.260
na teleobecność i mieszaną rzeczywistość

00:13:00.260 --> 00:13:03.260
by pozwolić dzieciom tworzyć rzeczywistość

00:13:03.260 --> 00:13:05.260
w której będą bawić się z innymi dziećmi,

00:13:05.260 --> 00:13:07.260
korzystając z ich wyobraźni.

00:13:07.260 --> 00:13:10.260
Chcę wymyślić nowe sposoby na jakie media dla dzieci

00:13:10.260 --> 00:13:13.260
będą promować kreatywność, naukę i innowację.

00:13:13.260 --> 00:13:16.260
To bardzo ważne.

00:13:16.260 --> 00:13:18.260
To tyle co do nowego projektu.

00:13:18.260 --> 00:13:20.260
Zaprosiliśmy sporo dzieci,

00:13:20.260 --> 00:13:23.260
bardzo im się podoba.

00:13:23.260 --> 00:13:25.260
A najbardziej kochają roboty.

00:13:25.260 --> 00:13:27.260
A najbardziej kochają roboty.

00:13:27.260 --> 00:13:30.260
Na nich im najbardziej zależy.

00:13:30.260 --> 00:13:33.260
Roboty dotykają naszego człowieczeństwa.

00:13:33.260 --> 00:13:35.260
Czy to gdy pomagają nam

00:13:35.260 --> 00:13:37.260
być kreatywnymi i innowacyjnymi,

00:13:37.260 --> 00:13:39.260
czy to kiedy umożliwiają

00:13:39.260 --> 00:13:41.260
uczucie bliskości,

00:13:41.260 --> 00:13:43.260
czy to gdy są pomocnikami

00:13:43.260 --> 00:13:45.260
w osiąganiu naszych celów

00:13:45.260 --> 00:13:47.260
i stawaniu się lepszymi.

00:13:47.260 --> 00:13:50.260
Roboty są dla ludzi.

00:13:50.260 --> 00:13:52.260
Dziękuję.

00:13:52.260 --> 00:13:57.260
(Brawa)

