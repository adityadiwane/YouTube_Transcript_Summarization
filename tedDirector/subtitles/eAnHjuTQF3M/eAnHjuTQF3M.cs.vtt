WEBVTT
Kind: captions
Language: cs

00:00:00.000 --> 00:00:07.000
Překladatel: Ondrej Cikanek
Korektor: Marek Vanžura

00:00:15.260 --> 00:00:18.260
Už jako malou holku,

00:00:18.260 --> 00:00:20.260
co poprvé viděla Hvězdné války,

00:00:20.260 --> 00:00:22.260
mě fascinovala myšlenka

00:00:22.260 --> 00:00:24.260
osobních robotů.

00:00:24.260 --> 00:00:26.260
A taky už jako malá holka

00:00:26.260 --> 00:00:28.260
jsem milovala představu robota, který s námi interaguje,

00:00:28.260 --> 00:00:31.260
spíš něco jako užitečný kámoš, kterému věříme,

00:00:31.260 --> 00:00:33.260
něco, co nás potěší, obohatí naše životy

00:00:33.260 --> 00:00:36.260
a pomůže nám zachránit nějakou tu galaxii.

00:00:37.260 --> 00:00:40.260
Takže jsem věděla, že takoví roboti doopravdy neexistují,

00:00:40.260 --> 00:00:42.260
ale věděla jsem, že je chci stavět.

00:00:42.260 --> 00:00:44.260
Uplynulo 20 let

00:00:44.260 --> 00:00:46.260
a já jsem postgraduální student umělé inteligence na MIT

00:00:46.260 --> 00:00:48.260
MIT (Massachusetts Institute of Technology).

00:00:48.260 --> 00:00:50.260
Píše se rok 1997

00:00:50.260 --> 00:00:53.260
a NASA poprvé přístává s robotem na Marsu.

00:00:53.260 --> 00:00:56.260
Ironií ale bylo, že roboti stále nebyli v našich domovech.

00:00:56.260 --> 00:00:58.260
A pamatuju si, že jsem přemýšlela

00:00:58.260 --> 00:01:00.260
o všech důvodech, proč tomu tak je.

00:01:00.260 --> 00:01:02.260
Jeden z nich mě ale zarazil více než ostatní.

00:01:02.260 --> 00:01:05.260
Robotika byla hlavně o interakci věcí,

00:01:05.260 --> 00:01:07.260
nikoliv lidí --

00:01:07.260 --> 00:01:09.260
rozhodně ne v takové podobě, která by nám byla přirozená

00:01:09.260 --> 00:01:11.260
a která by nám pomohla přijmout roboty

00:01:11.260 --> 00:01:13.260
do našich každodenních životů.

00:01:13.260 --> 00:01:16.260
Pro mě to bylo takové bílé místo představující to, co roboti zatím nedokážou.

00:01:16.260 --> 00:01:19.260
A tak jsem v tom roce začala stavět robota, Kismeta,

00:01:19.260 --> 00:01:22.260
prvního sociálního robota na světě.

00:01:22.260 --> 00:01:24.260
A tak o tři roky --

00:01:24.260 --> 00:01:26.260
a spoustu programování později,

00:01:26.260 --> 00:01:28.260
díky spolupráci s dalšími studenty v laboratoři,

00:01:28.260 --> 00:01:30.260
Kismet byl připraven začít interagovat s lidmi.

00:01:30.260 --> 00:01:32.260
(Video) Vědec: Chci ti něco ukázat.

00:01:32.260 --> 00:01:34.260
Kismet: (Nesmysl).

00:01:34.260 --> 00:01:37.260
Vědec: Tohle jsou hodinky, které jsem dostal od své přítelkyně.

00:01:37.260 --> 00:01:39.260
Kismet: (Nesmysl).

00:01:39.260 --> 00:01:41.260
Vědec: Jo, podívej, má to i modré světýlko.

00:01:41.260 --> 00:01:44.260
Tento týden jsem je málem ztratil.

00:01:44.260 --> 00:01:47.260
Cynthia Breazeal: Takže Kismet interagoval s lidmi,

00:01:47.260 --> 00:01:50.260
něco jako nemluvně nebo batole,

00:01:50.260 --> 00:01:53.260
což si myslím, že odpovídá, protože byl opravdu první svého druhu.

00:01:53.260 --> 00:01:55.260
Nemluvil žádným jazykem, ale to nevadilo.

00:01:55.260 --> 00:01:57.260
Tenhle malý robot byl jaksi schopen

00:01:57.260 --> 00:02:00.260
vzbudit hluboko v nás něco lidského.

00:02:00.260 --> 00:02:02.260
A s tím také příslib úplně nového způsobu,

00:02:02.260 --> 00:02:04.260
jak můžeme interagovat s roboty.

00:02:04.260 --> 00:02:06.260
Takže v posledních několika letech

00:02:06.260 --> 00:02:08.260
pokračuji v prozkoumávání tohoto mezilidského rozměru robotů

00:02:08.260 --> 00:02:10.260
v mediální laboratoři

00:02:10.260 --> 00:02:12.260
se svým vlastním týmem neskutečně talentovaných studentů.

00:02:12.260 --> 00:02:15.260
Jeden z mých oblíbených robotů je Leonardo.

00:02:15.260 --> 00:02:18.260
Leonarda jsem vyvinuli ve spolupráci se Stan Winston Studiem.

00:02:18.260 --> 00:02:21.260
A tak vám chci ukázat jeden pro mě výjimečný okamžik.

00:02:21.260 --> 00:02:23.260
Tohle je Matt Berlin, který komunikuje s Leem -

00:02:23.260 --> 00:02:25.260
- představuje Leovi nový předmět.

00:02:25.260 --> 00:02:28.260
A protože je nový, Leo neví, co s ním.

00:02:28.260 --> 00:02:30.260
Ale podobně jako my, může se o něm něco dozvědět

00:02:30.260 --> 00:02:33.260
pomocí pozorování Mattových reakcí.

00:02:33.260 --> 00:02:35.260
(Video) Matt Berlin: Ahoj Leo.

00:02:38.260 --> 00:02:41.260
Leo, tohle je Cookie Monster (Sušenková příšera)

00:02:44.260 --> 00:02:47.260
Dokážeš najít Cookie Monstera (Sušenkovou příšeru)?

00:02:52.260 --> 00:02:55.260
Leo, Cookie Monster (Sušenková příšera) je velmi zlá.

00:02:56.260 --> 00:02:58.260
Ona je velmi zlá, Leo.

00:03:00.260 --> 00:03:03.260
Cookie Monster (Sušenková příšera) je velmi, velmi zlá.

00:03:07.260 --> 00:03:09.260
Je to strašidelná příšera.

00:03:09.260 --> 00:03:11.260
Chce ti vzít tvé sušenky.

00:03:12.260 --> 00:03:14.260
(Smích)

00:03:14.260 --> 00:03:17.260
CB: Takže, Leo a Cookie

00:03:17.260 --> 00:03:19.260
možná měli těžší začátky,

00:03:19.260 --> 00:03:22.260
ale nyní spolu už vycházejí v pohodě.

00:03:22.260 --> 00:03:24.260
Takže co jsem se naučila

00:03:24.260 --> 00:03:26.260
během návrhu těchto systémů je to,

00:03:26.260 --> 00:03:28.260
že roboti jsou v podstatě

00:03:28.260 --> 00:03:30.260
skutečně úchvatnou společenskou technologií.

00:03:30.260 --> 00:03:32.260
V podstatě je to jejich schopnost

00:03:32.260 --> 00:03:34.260
probudit v nás sociální cítění

00:03:34.260 --> 00:03:36.260
a interagovat (komunikovat) s námi jako s partnerem,

00:03:36.260 --> 00:03:39.260
to je jádrem jejich fungování.

00:03:39.260 --> 00:03:41.260
A s touto změnou úhlu pohledu si můžeme nyní začít

00:03:41.260 --> 00:03:44.260
klást nové otázky a představovat nové možnosti,

00:03:44.260 --> 00:03:47.260
nad kterými bychom se jinak asi nezamysleli.

00:03:47.260 --> 00:03:49.260
Ale co vlastně mám na mysli tím, že v nás "probouzí sociální cítění"?

00:03:49.260 --> 00:03:51.260
Jednou z věcí, které jsme se naučili

00:03:51.260 --> 00:03:53.260
je to, že pokud navrhujeme roboty ke komunikaci s lidmi tak,

00:03:53.260 --> 00:03:55.260
aby měli stejnou řeč těla,

00:03:55.260 --> 00:03:57.260
stejná neverbální gesta jako lidé --

00:03:57.260 --> 00:04:00.260
jako zde náš humanoidní robot Nexi --

00:04:00.260 --> 00:04:02.260
zjišťujeme, že lidé reagují na roboty

00:04:02.260 --> 00:04:04.260
velmi podobně jako na lidi.

00:04:04.260 --> 00:04:07.260
Lidé používají tyto podněty k určení toho, jak je někdo přesvědčivý,

00:04:07.260 --> 00:04:09.260
sympatický, okouzlující,

00:04:09.260 --> 00:04:11.260
nebo důvěryhodný.

00:04:11.260 --> 00:04:13.260
Ukazuje se, že u robotů to funguje stejně.

00:04:13.260 --> 00:04:15.260
Nyní se ukazuje,

00:04:15.260 --> 00:04:18.260
že roboti se vlastně stávají opravdu zajímavým vědeckým nástrojem

00:04:18.260 --> 00:04:20.260
umožňujícím porozumět lidskému chování.

00:04:20.260 --> 00:04:23.260
Odpovídá na otázky jako třeba jak jsme schopni z krátkého setkání

00:04:23.260 --> 00:04:26.260
odhadnout důvěryhodnost druhé osoby.

00:04:26.260 --> 00:04:29.260
Má se za to, že mimika hraje roli, ale jakou?

00:04:29.260 --> 00:04:32.260
Je to o tom, že vyjadřujeme mimikou určitá gesta?

00:04:32.260 --> 00:04:34.260
Ukazuje se, že je velmi těžké

00:04:34.260 --> 00:04:36.260
se toto naučit, nebo pochopit pozorováním ostatních,

00:04:36.260 --> 00:04:39.260
protože když interagujeme, děláme všechna tato gesta automaticky.

00:04:39.260 --> 00:04:41.260
Nemůžeme je pečlivě ovládat, protože je děláme podvědomě.

00:04:41.260 --> 00:04:43.260
Ale u robotů můžeme.

00:04:43.260 --> 00:04:45.260
Jako třeba na tomto videu,

00:04:45.260 --> 00:04:48.260
které pochází z laboratoře Davida DeStenoa z Northeastern University (Severovýchodní univerzity).

00:04:48.260 --> 00:04:50.260
Je to psycholog, se kterým spolupracujeme.

00:04:50.260 --> 00:04:53.260
Vědec pečlivě ovládá Nexiho podněty,

00:04:53.260 --> 00:04:56.260
aby byl schopen studovat tuto problematiku.

00:04:56.260 --> 00:04:58.260
A to podstatné je -- důvod, proč tohle funguje, je --

00:04:58.260 --> 00:05:00.260
že se ukazuje, že lidé se chovají lidsky

00:05:00.260 --> 00:05:03.260
i když interagují s robotem.

00:05:03.260 --> 00:05:05.260
Díky tomuto klíčovému zjištění

00:05:05.260 --> 00:05:07.260
si můžeme nyní představit

00:05:07.260 --> 00:05:10.260
nové možnosti využití robotů.

00:05:10.260 --> 00:05:13.260
Například, když roboti reagují na neverbální podněty,

00:05:13.260 --> 00:05:17.260
možná by se dali použít jako skvělá, nová komunikační technologie.

00:05:17.260 --> 00:05:19.260
Představte si tohle:

00:05:19.260 --> 00:05:21.260
Co třeba robotické příslušenství pro váš mobil?

00:05:21.260 --> 00:05:23.260
Zavoláte kamarádce, ona vloží svůj mobil do robota,

00:05:23.260 --> 00:05:25.260
a abrakadabra, jste MeBot (JáBot) --

00:05:25.260 --> 00:05:28.260
můžete navázat oční kontakt, bavit se s přáteli,

00:05:28.260 --> 00:05:30.260
můžete se pohybovat, gestikulovat,

00:05:30.260 --> 00:05:33.260
možná skoro tak dobré jako tam přímo být. Nebo ne?

00:05:33.260 --> 00:05:35.260
K prozkoumání této problematiky

00:05:35.260 --> 00:05:38.260
můj student, Siggy Adalgeirsson, provedl studii,

00:05:38.260 --> 00:05:41.260
při které pozval lidské účastníky, lidi, do naší laboratoře,

00:05:41.260 --> 00:05:43.260
aby splnili kolaborativní úkol

00:05:43.260 --> 00:05:45.260
s kolegou na dálku.

00:05:45.260 --> 00:05:47.260
Úkol zahrnoval věci,

00:05:47.260 --> 00:05:49.260
jako pozorování objektů na stole

00:05:49.260 --> 00:05:52.260
o nichž se diskutovalo v souvislosti s jejich důležitostí a relevancí pro daný úkol --

00:05:52.260 --> 00:05:54.260
nakonec se jednalo o hru o přežití --

00:05:54.260 --> 00:05:56.260
a poté bylo třeba předměty oznámkovat

00:05:56.260 --> 00:05:58.260
podle jejich přínosu a důležitosti.

00:05:58.260 --> 00:06:01.260
Vzdálený kolega byl experimentátorem z naší skupiny a

00:06:01.260 --> 00:06:03.260
byly použity tři různé technologie

00:06:03.260 --> 00:06:05.260
pro interakci s ostatními účastníky.

00:06:05.260 --> 00:06:07.260
První technologií byla pouze obrazovka.

00:06:07.260 --> 00:06:10.260
Něco jako dnešní videokonference.

00:06:10.260 --> 00:06:13.260
Druhá technologie byla obohacena o mobilitu, takže obrazovka měla pohyblivý podstavec.

00:06:13.260 --> 00:06:16.260
To je něco jako dnešní teleprezenční roboti, pokud jste je viděli.

00:06:16.260 --> 00:06:19.260
Tak asi taková situace.

00:06:19.260 --> 00:06:21.260
A potom plně se vyjadřující MeBot (JáBot).

00:06:21.260 --> 00:06:23.260
Po skončení interakce

00:06:23.260 --> 00:06:26.260
byli účastníci požádáni, aby ohodnotili kvalitu interakce

00:06:26.260 --> 00:06:28.260
s danou technologií, respektive vzdáleným kolegou,

00:06:28.260 --> 00:06:31.260
pomocí té dané technologie z více úhlů pohledu.

00:06:31.260 --> 00:06:33.260
Sledovali jsme psychologické zapojení --

00:06:33.260 --> 00:06:35.260
kolik empatie cítili k druhé osobě.

00:06:35.260 --> 00:06:37.260
Sledovali jsme celkovou angažovanost.

00:06:37.260 --> 00:06:39.260
Sledovali jsme jejich vůli spolupracovat.

00:06:39.260 --> 00:06:42.260
Tohle jsou výsledky při použití pouhé obrazovky.

00:06:42.260 --> 00:06:45.260
Když se přidá mobilita -- možnost pohybovat se po stole --

00:06:45.260 --> 00:06:47.260
čísla trochu stoupnou.

00:06:47.260 --> 00:06:50.260
A ještě více vzrostou, když se přidá možnost plného vyjadřování.

00:06:50.260 --> 00:06:52.260
Takže to vypadá, že toto fyzicky-sociální ztělesnění

00:06:52.260 --> 00:06:54.260
vlastně skutečně pomáhá.

00:06:54.260 --> 00:06:57.260
Zkusme nyní zasadit tento příběh do kontextu.

00:06:57.260 --> 00:07:00.260
V dnešní době jsou jednotlivé části rodin od sebe čím dál více vzdálené,

00:07:00.260 --> 00:07:02.260
což si vybírá svou daň na rodinných vztazích

00:07:02.260 --> 00:07:04.260
a rodinných poutech na dálku.

00:07:04.260 --> 00:07:06.260
Já mám například tři malé kluky

00:07:06.260 --> 00:07:08.260
a chci, aby měli dobrý vztah

00:07:08.260 --> 00:07:10.260
s jejich prarodiči.

00:07:10.260 --> 00:07:12.260
Ale moji rodiče žijí tisíce mil daleko,

00:07:12.260 --> 00:07:14.260
takže se s mými syny moc často nesetkávají.

00:07:14.260 --> 00:07:16.260
Zkoušíme Skype, telefony,

00:07:16.260 --> 00:07:18.260
ale kluci jsou malí -- a prostě si nechtějí povídat,

00:07:18.260 --> 00:07:20.260
chtějí si hrát.

00:07:20.260 --> 00:07:22.260
Oni zbožňují nápad mít roboty

00:07:22.260 --> 00:07:25.260
jako nový druh technologie umožňující hraní si na dálku.

00:07:25.260 --> 00:07:28.260
A tak si dokážu představit, že zanedlouho --

00:07:28.260 --> 00:07:30.260
bude moci moje mamka vzít počítač,

00:07:30.260 --> 00:07:32.260
otevřít prohlížeč a připojit se do malého robota.

00:07:32.260 --> 00:07:35.260
A jako babička-bot

00:07:35.260 --> 00:07:37.260
si bude moci hrát, skutečně hrát,

00:07:37.260 --> 00:07:39.260
s mými syny, jejími vnuky,

00:07:39.260 --> 00:07:42.260
v reálném světě s reálnými hračkami.

00:07:42.260 --> 00:07:44.260
Dokážu si představit babičky schopné hrát společenské hry

00:07:44.260 --> 00:07:46.260
s jejich vnučkami a jejich kamarády,

00:07:46.260 --> 00:07:48.260
a budou schopné sdílet všemožné další domácí aktivity

00:07:48.260 --> 00:07:50.260
jako například pohádku na dobrou noc.

00:07:50.260 --> 00:07:52.260
A pomocí této technologie

00:07:52.260 --> 00:07:54.260
se budou moci stát aktivními účastníky

00:07:54.260 --> 00:07:56.260
životů jejich vnoučat takovým způsobem,

00:07:56.260 --> 00:07:58.260
jakým to dnes není možné.

00:07:58.260 --> 00:08:00.260
Podívejme se na další oblasti

00:08:00.260 --> 00:08:02.260
jako třeba zdraví.

00:08:02.260 --> 00:08:04.260
V současné době ve Spojených státech

00:08:04.260 --> 00:08:07.260
má 65 % lidí nadváhu nebo jsou obézní,

00:08:07.260 --> 00:08:09.260
a i pro naše děti je to nyní velký problém.

00:08:09.260 --> 00:08:11.260
A víme, že v pokročilejším věku,

00:08:11.260 --> 00:08:14.260
pokud jste obézní jako dítě, může obezita vést k chronickým nemocem,

00:08:14.260 --> 00:08:16.260
což nejen snižuje kvalitu života,

00:08:16.260 --> 00:08:19.260
ale také vytváří ekonomické břímě pro systém zdravotní péče.

00:08:19.260 --> 00:08:21.260
Ale pokud roboti dokážou být poutaví,

00:08:21.260 --> 00:08:23.260
pokud s nimi budeme rádi spolupracovat

00:08:23.260 --> 00:08:25.260
a pokud budou roboti přesvědčiví,

00:08:25.260 --> 00:08:27.260
tak vám může robot pomoct

00:08:27.260 --> 00:08:29.260
držet dietu nebo dodržovat tréninkový plán,

00:08:29.260 --> 00:08:32.260
možná mohou pomoci s udržováním váhy.

00:08:32.260 --> 00:08:34.260
Něco jako digitální Jiminy --

00:08:34.260 --> 00:08:36.260
stejně jako ve známé pohádce --

00:08:36.260 --> 00:08:38.260
taková přátelská bytost poskytující oporu, která je vždy nablízku,

00:08:38.260 --> 00:08:40.260
aby nám pomohla udělat správné rozhodnutí

00:08:40.260 --> 00:08:42.260
správným způsobem, ve správném čase,

00:08:42.260 --> 00:08:44.260
abychom si vytvořili zdravé návyky.

00:08:44.260 --> 00:08:46.260
A tak jsme se zabývali tímto nápadem v naší laboratoři.

00:08:46.260 --> 00:08:48.260
Tohle je náš robot, Autom.

00:08:48.260 --> 00:08:51.260
Cory Kidd vyvinul tohoto robota v rámci své dizertační práce.

00:08:51.260 --> 00:08:54.260
A byl navržen tak, aby byl výživovým poradcem a osobním trenérem.

00:08:54.260 --> 00:08:56.260
Měl pár jednoduchých neverbálních dovedností.

00:08:56.260 --> 00:08:58.260
Mohl s vámi navázat oční kontakt.

00:08:58.260 --> 00:09:00.260
Mohl sdělovat informace pomocí obrazovky.

00:09:00.260 --> 00:09:02.260
Mohli jste použít jeho obrazovku na vložení informací,

00:09:02.260 --> 00:09:04.260
jako například kolik jste ten den snědli kalorií,

00:09:04.260 --> 00:09:06.260
jak moc jste cvičili.

00:09:06.260 --> 00:09:08.260
A on vám potom pomáhal udržovat záznamy.

00:09:08.260 --> 00:09:10.260
A ten robot mluvil syntetickým hlasem,

00:09:10.260 --> 00:09:12.260
aby s vámi navázal dialog,

00:09:12.260 --> 00:09:14.260
navržený po vzoru skutečných trenérů

00:09:14.260 --> 00:09:16.260
a pacientů a tak dále.

00:09:16.260 --> 00:09:18.260
A s vámi by vytvořil pracovní spojenectví

00:09:18.260 --> 00:09:20.260
pomocí tohoto dialogu.

00:09:20.260 --> 00:09:22.260
To by vám pomohlo nastavit cíle a sledovat postup,

00:09:22.260 --> 00:09:24.260
a také pomoci vás motivovat.

00:09:24.260 --> 00:09:26.260
Zajímavou otázkou je,

00:09:26.260 --> 00:09:29.260
zda na tom sociálním ztělesnění opravu záleží? Záleží na tom, že je to robot?

00:09:29.260 --> 00:09:32.260
Nebo je to jen o kvalitě rad a informací?

00:09:32.260 --> 00:09:34.260
Abychom tuto otázku zodpověděli,

00:09:34.260 --> 00:09:36.260
provedli jsme studii poblíž Bostonu,

00:09:36.260 --> 00:09:39.260
během které jsme otestovali tři různé technologie ve třech různých domácnostech

00:09:39.260 --> 00:09:41.260
po dobu několika týdnů.

00:09:41.260 --> 00:09:44.260
V prvním případě to byl robot, kterého tu vidíte, Autom.

00:09:44.260 --> 00:09:47.260
Druhým byl počítač, na jehož dotykové obrazovce běželo to stejné rozhraní

00:09:47.260 --> 00:09:49.260
s těmi stejnými dialogy.

00:09:49.260 --> 00:09:51.260
Kvalita rad byla totožná.

00:09:51.260 --> 00:09:53.260
Třetím byl jen papírový zápisník a pero,

00:09:53.260 --> 00:09:55.260
protože to je standardní postup,

00:09:55.260 --> 00:09:58.260
když se začíná s dietou nebo tréninkovým programem.

00:09:58.260 --> 00:10:01.260
Jednou z věcí, na které jsme se zaměřili,

00:10:01.260 --> 00:10:04.260
nebylo, kolik lidé zhubli,

00:10:04.260 --> 00:10:07.260
ale jak dlouho interagovali s robotem.

00:10:07.260 --> 00:10:10.260
Protože tou hlavní výzvou není samotné hubnutí, ale spíše udržení snížené váhy.

00:10:10.260 --> 00:10:13.260
A čím déle vydržíte interagovat s danou technologií,

00:10:13.260 --> 00:10:16.260
tím větší je potenciál dlouhodobého úspěchu.

00:10:16.260 --> 00:10:18.260
Takže tou první věcí, kterou jsme zkoumali, bylo,

00:10:18.260 --> 00:10:20.260
jak dlouho lidé interagovali s těmito systémy.

00:10:20.260 --> 00:10:22.260
Ukázalo se, že lidé interagovali s robotem

00:10:22.260 --> 00:10:24.260
mnohem déle,

00:10:24.260 --> 00:10:27.260
přestože kvalita informací byla totožná jako na počítači.

00:10:28.260 --> 00:10:31.260
Když jsme požádali lidi, aby systémy zhodnotili z hlediska kvality pracovního spojenectví,

00:10:31.260 --> 00:10:33.260
lidé dali robotovi vyšší známky

00:10:33.260 --> 00:10:35.260
a také mu více důvěřovali.

00:10:35.260 --> 00:10:37.260
(Smích)

00:10:37.260 --> 00:10:39.260
A když se podíváte na emocionální angažovanost,

00:10:39.260 --> 00:10:41.260
rozdíl byl zřejmý.

00:10:41.260 --> 00:10:43.260
Lidé dávali robotům jména.

00:10:43.260 --> 00:10:45.260
Oblékali je.

00:10:45.260 --> 00:10:47.260
(Smích)

00:10:47.260 --> 00:10:50.260
A dokonce když jsme si přišli robota na konci studie vyzvednout,

00:10:50.260 --> 00:10:52.260
šli se s robotem rozloučit.

00:10:52.260 --> 00:10:54.260
A tohle se nedá říct o počítači.

00:10:54.260 --> 00:10:56.260
Poslední věcí, o které chci dneska mluvit,

00:10:56.260 --> 00:10:58.260
je budoucnost dětských médií.

00:10:58.260 --> 00:11:01.260
Víme, že v dnešní době tráví děti spoustu času před obrazovkami,

00:11:01.260 --> 00:11:04.260
ať už je to televize, počítačové hry, nebo cokoliv jiného.

00:11:04.260 --> 00:11:07.260
Mí synové, oni prostě milují obrazovku. Milují obrazovku.

00:11:07.260 --> 00:11:10.260
Ale já chci, aby si hráli; jako máma chci, aby si hráli

00:11:10.260 --> 00:11:12.260
hry v reálném světě.

00:11:12.260 --> 00:11:15.260
A tak pracuje můj tým na novém projektu, který vám chci dnes představit,

00:11:15.260 --> 00:11:17.260
jmenuje se Playtime Computing,

00:11:17.260 --> 00:11:19.260
a zamýšlí se nad tím,

00:11:19.260 --> 00:11:21.260
co je vlastně tak poutavé na digitálních médiích

00:11:21.260 --> 00:11:23.260
a pokusit se to přenést z obrazovek

00:11:23.260 --> 00:11:25.260
do reálného světa dětí,

00:11:25.260 --> 00:11:28.260
kde to může nabrat mnoho vlastností z reálných her.

00:11:29.260 --> 00:11:33.260
Tak tady je první výsledek tohoto nápadu,

00:11:33.260 --> 00:11:36.260
ve kterém mohou být znaky fyzické, nebo virtuální,

00:11:36.260 --> 00:11:38.260
a ve kterém digitální obsah

00:11:38.260 --> 00:11:40.260
doslova vystupuje z obrazovky

00:11:40.260 --> 00:11:42.260
do reálného světa a naopak.

00:11:42.260 --> 00:11:44.260
Připomíná mi to

00:11:44.260 --> 00:11:46.260
Atari Pong

00:11:46.260 --> 00:11:48.260
této hry se smíšenou realitou.

00:11:48.260 --> 00:11:50.260
Ale můžeme posunout ten nápad ještě dále.

00:11:50.260 --> 00:11:52.260
Co když --

00:11:52.260 --> 00:11:55.260
(Hra) Nathan: Už je to tady, jáj!

00:11:55.260 --> 00:11:58.260
CB: -- samotný znak přijde do našeho reálného světa?

00:11:58.260 --> 00:12:00.260
Ukazuje se, že děti zbožňují,

00:12:00.260 --> 00:12:03.260
když se znak zhmotní a vstoupí do jejich reálného světa.

00:12:03.260 --> 00:12:05.260
A když je v jejich světě,

00:12:05.260 --> 00:12:07.260
mohou s ním navázat vztah a hrát si s ním způsobem,

00:12:07.260 --> 00:12:09.260
který je naprosto odlišný od toho, jak si s ním hrají na obrazovce.

00:12:09.260 --> 00:12:11.260
Další důležitou myšlenkou je podmínka

00:12:11.260 --> 00:12:14.260
přetrvávání znaků napříč realitami.

00:12:14.260 --> 00:12:16.260
Takže co děti změní v reálném světě,

00:12:16.260 --> 00:12:18.260
se musí přenést do toho virtuálního.

00:12:18.260 --> 00:12:21.260
A tak zde, Nathan změnil písmeno A na číslici 2.

00:12:21.260 --> 00:12:23.260
Můžete si třeba představit, že tyto symboly

00:12:23.260 --> 00:12:26.260
dávají znakům zvláštní moc, když vstoupí do virtuálního světa.

00:12:26.260 --> 00:12:29.260
Takže oni teď posílají ten znak zpět do toho virtuálního světa.

00:12:29.260 --> 00:12:32.260
A ten znak má teď číselnou moc.

00:12:32.260 --> 00:12:34.260
A potom konečně, to, o co se tu snažím,

00:12:34.260 --> 00:12:37.260
je vytvořit opravdu úchvatný zážitek pro děti,

00:12:37.260 --> 00:12:40.260
kde budou cítit, že jsou součástí příběhu,

00:12:40.260 --> 00:12:42.260
součástí toho zážitku.

00:12:42.260 --> 00:12:44.260
A já chci skutečně vyšperkovat jejich představivost stejně,

00:12:44.260 --> 00:12:47.260
jako byly moje představy vyšperkovány, když jsem jako malá holka sledovala "Hvězdné války".

00:12:47.260 --> 00:12:49.260
Ale já chci jít ještě dál.

00:12:49.260 --> 00:12:52.260
Chci, aby si tyto zážitky samy vytvářely.

00:12:52.260 --> 00:12:54.260
Chci, aby si mohly doslova vybudovat za svých představ

00:12:54.260 --> 00:12:56.260
vlastní zážitky.

00:12:56.260 --> 00:12:58.260
Takže zkoumáme mnoho nápadů

00:12:58.260 --> 00:13:00.260
v oblastech teleprezence a smíšené reality,

00:13:00.260 --> 00:13:03.260
abychom doslova umožnili dětem projektovat jejich nápady do tohoto prostoru,

00:13:03.260 --> 00:13:05.260
kde s nimi mohou interagovat další děti

00:13:05.260 --> 00:13:07.260
a dále je rozvíjet.

00:13:07.260 --> 00:13:10.260
Doopravdy chci přijít s novými možnostmi dětských médií,

00:13:10.260 --> 00:13:13.260
které podporují kreativitu a učení a inovaci.

00:13:13.260 --> 00:13:16.260
Myslím, že je to nesmírně důležité.

00:13:16.260 --> 00:13:18.260
A tak tohle je nový projekt.

00:13:18.260 --> 00:13:20.260
Pozvali jsme děti do tohoto prostoru

00:13:20.260 --> 00:13:23.260
a jim se to moc líbí.

00:13:23.260 --> 00:13:25.260
Ale řeknu vám, že to, co se jim líbí úplně nejvíc,

00:13:25.260 --> 00:13:27.260
je ten robot.

00:13:27.260 --> 00:13:30.260
To, co je zajímá, je ten robot.

00:13:30.260 --> 00:13:33.260
Roboti v nás vzbuzují něco lidského.

00:13:33.260 --> 00:13:35.260
A tak ať už nám pomáhají

00:13:35.260 --> 00:13:37.260
se stát kreativními, inovativními,

00:13:37.260 --> 00:13:39.260
nebo nám pomáhají

00:13:39.260 --> 00:13:41.260
se cítit více propojeni s druhými navzdory vzdálenosti,

00:13:41.260 --> 00:13:43.260
nebo jsou náš kámoš, kterému věříme,

00:13:43.260 --> 00:13:45.260
který nám pomáhá dosáhnout našich osobních cílů

00:13:45.260 --> 00:13:47.260
a stát se lepšími lidmi,

00:13:47.260 --> 00:13:50.260
pro mě osobně, roboti jsou pouze o lidech.

00:13:50.260 --> 00:13:52.260
Děkuji vám.

00:13:52.260 --> 00:13:57.260
(Potlesk)

