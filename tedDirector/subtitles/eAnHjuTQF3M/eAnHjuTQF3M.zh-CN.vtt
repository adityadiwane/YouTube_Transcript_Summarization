WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:07.000
翻译人员: Guo Tang
校对人员: Felix Chen

00:00:15.260 --> 00:00:18.260
我还是个小女孩

00:00:18.260 --> 00:00:20.260
第一次看“星球大战”时，

00:00:20.260 --> 00:00:22.260
我就着迷于

00:00:22.260 --> 00:00:24.260
个人机器人的想法。

00:00:24.260 --> 00:00:26.260
作为一个小女孩，

00:00:26.260 --> 00:00:28.260
我喜欢与我们互动的机器人更像是

00:00:28.260 --> 00:00:31.260
一个有助的，值得信赖的伙伴的想法 --

00:00:31.260 --> 00:00:33.260
可以令我们欢乐，充实我们的生活，

00:00:33.260 --> 00:00:36.260
并帮助我们拯救一两个银河系。

00:00:37.260 --> 00:00:40.260
因此我知道那样的机器人实际上并不存在，

00:00:40.260 --> 00:00:42.260
但是我知道我想要制作出它们。

00:00:42.260 --> 00:00:44.260
二十年过去了--

00:00:44.260 --> 00:00:46.260
现在我是在MIT的一个研究生

00:00:46.260 --> 00:00:48.260
学习人工智能，

00:00:48.260 --> 00:00:50.260
在1997年，

00:00:50.260 --> 00:00:53.260
美国国家航空和航天管理局发射了登上火星的第一个机器人。

00:00:53.260 --> 00:00:56.260
讽刺的是，机器人却始终不在我们的家里。

00:00:56.260 --> 00:00:58.260
我记得我考虑了

00:00:58.260 --> 00:01:00.260
所有的原因。

00:01:00.260 --> 00:01:02.260
但是有一个原因令我作罢。

00:01:02.260 --> 00:01:05.260
机器人技术的确是与事物互动，

00:01:05.260 --> 00:01:07.260
而并非人类--

00:01:07.260 --> 00:01:09.260
的确不是以一种自然的社交方式

00:01:09.260 --> 00:01:11.260
来使人们接受机器人

00:01:11.260 --> 00:01:13.260
进入我们的日常生活中。

00:01:13.260 --> 00:01:16.260
对我来说，这是片空白，这是机器人还无法做到的。

00:01:16.260 --> 00:01:19.260
所以那一年，我开始制造这个机器人，Kismet,

00:01:19.260 --> 00:01:22.260
世界上第一个社交机器人。

00:01:22.260 --> 00:01:24.260
三年之后--

00:01:24.260 --> 00:01:26.260
许多的程序，

00:01:26.260 --> 00:01:28.260
和其他的研究生一起在实验室工作--

00:01:28.260 --> 00:01:30.260
Kismet已经做好了和人类互动的准备。

00:01:30.260 --> 00:01:32.260
（视频）科学家：我想向你们展示些东西。

00:01:32.260 --> 00:01:34.260
Kismet：（无意义的声音）。

00:01:34.260 --> 00:01:37.260
科学家：这是我女朋友送给我的手表。

00:01:37.260 --> 00:01:39.260
Kismet：（无意义的声音）。

00:01:39.260 --> 00:01:41.260
科学家：看，它里面有一个小蓝灯。

00:01:41.260 --> 00:01:44.260
这周我差点丢了它。

00:01:44.260 --> 00:01:47.260
辛西娅 布雷齐尔: Kismet 与人类互动

00:01:47.260 --> 00:01:50.260
正如一个不能说话或者是发声前的孩子，

00:01:50.260 --> 00:01:53.260
我认为这很合适因为它是第一个这类的机器人。

00:01:53.260 --> 00:01:55.260
他不会说任何语言，但是无所谓。

00:01:55.260 --> 00:01:57.260
这个小机器人却可以

00:01:57.260 --> 00:02:00.260
深深触动我们内心的交际性。

00:02:00.260 --> 00:02:02.260
于是，这预示了一种我们能与机器人

00:02:02.260 --> 00:02:04.260
交流的全新的方式。

00:02:04.260 --> 00:02:06.260
因此过去的这几年

00:02:06.260 --> 00:02:08.260
我持续地探索机器人的这些与人互动的各个方面，

00:02:08.260 --> 00:02:10.260
现在在媒体实验室

00:02:10.260 --> 00:02:12.260
和我的无与伦比的天才学生们组成的团队。

00:02:12.260 --> 00:02:15.260
我最喜欢的一个机器人是里昂纳多.

00:02:15.260 --> 00:02:18.260
我们与斯坦·温斯顿工作室一起研发了里昂纳多。

00:02:18.260 --> 00:02:21.260
我想向你们展示一个我与里昂纳多的特殊的时刻。

00:02:21.260 --> 00:02:23.260
这是迈特·柏林正在和里昂纳多互动，

00:02:23.260 --> 00:02:25.260
向里昂介绍一种新的物体。

00:02:25.260 --> 00:02:28.260
因为是新事物，里昂纳多并不知道对此该怎么做。

00:02:28.260 --> 00:02:30.260
但是有点像我们，他可以通过观察

00:02:30.260 --> 00:02:33.260
马特的反映来学习。

00:02:33.260 --> 00:02:35.260
（视频）马特柏林：你好，里昂。

00:02:38.260 --> 00:02:41.260
里昂，这是饼干怪兽。

00:02:44.260 --> 00:02:47.260
你可以找到饼干怪兽吗？

00:02:52.260 --> 00:02:55.260
里昂，饼干怪兽非常的坏。

00:02:56.260 --> 00:02:58.260
他很坏，里昂。

00:03:00.260 --> 00:03:03.260
饼干怪兽是非常非常的坏。

00:03:07.260 --> 00:03:09.260
他是个可怕的怪兽。

00:03:09.260 --> 00:03:11.260
他想得到你的饼干。

00:03:12.260 --> 00:03:14.260
（笑声）

00:03:14.260 --> 00:03:17.260
辛西娅·布雷齐尔：里昂和饼干

00:03:17.260 --> 00:03:19.260
开始交往的时候有点困难，

00:03:19.260 --> 00:03:22.260
但是他们现在相处得很好。

00:03:22.260 --> 00:03:24.260
所以我所学到的是

00:03:24.260 --> 00:03:26.260
经过建立这些系统，

00:03:26.260 --> 00:03:28.260
机器是实际上是

00:03:28.260 --> 00:03:30.260
一种真正有趣的社交科技。

00:03:30.260 --> 00:03:32.260
机器人有能力

00:03:32.260 --> 00:03:34.260
触动我们的交际按钮

00:03:34.260 --> 00:03:36.260
像我们的伙伴一样同我们交流

00:03:36.260 --> 00:03:39.260
这是他们功能的核心。

00:03:39.260 --> 00:03:41.260
有了这种思考上的变化，我们现在可以开始想象

00:03:41.260 --> 00:03:44.260
对于机器人我们不曾想到的

00:03:44.260 --> 00:03:47.260
新的问题和心得可能性。

00:03:47.260 --> 00:03:49.260
但什么是我所说的“触动我们交际的按钮”呢？

00:03:49.260 --> 00:03:51.260
我们所学到的一件事情

00:03:51.260 --> 00:03:53.260
就是，如果我们设计这些机器人来和我们交流

00:03:53.260 --> 00:03:55.260
用相同的肢体语言，

00:03:55.260 --> 00:03:57.260
用和人类相同的所谓的非语言暗示 --

00:03:57.260 --> 00:04:00.260
像Nexi, 我们的类人机器人在这里所做的 --

00:04:00.260 --> 00:04:02.260
我们发现，我们对机器人的回应

00:04:02.260 --> 00:04:04.260
十分类似于我们对他人的回应。

00:04:04.260 --> 00:04:07.260
人们用这些线索来决定一个人多有说服力，

00:04:07.260 --> 00:04:09.260
多讨人喜爱，多迷人，

00:04:09.260 --> 00:04:11.260
多值得信任。

00:04:11.260 --> 00:04:13.260
实际上，机器人也一样。

00:04:13.260 --> 00:04:15.260
结果现在

00:04:15.260 --> 00:04:18.260
机器人实际上变成了一种非常有趣的新的科学工具

00:04:18.260 --> 00:04:20.260
来理解人类行为。

00:04:20.260 --> 00:04:23.260
来回答一些类似这样的问题：从一次简短的相见，

00:04:23.260 --> 00:04:26.260
我们能够判断另一个人有多值得信任么？

00:04:26.260 --> 00:04:29.260
模仿被认为在起作用，但究竟是如何呢？

00:04:29.260 --> 00:04:32.260
是不是模仿一个特定的姿势有影响呢？

00:04:32.260 --> 00:04:34.260
事实上从观察人类

00:04:34.260 --> 00:04:36.260
来学习这些或者理解这些是非常难的

00:04:36.260 --> 00:04:39.260
因为当我们互动时我们不用自主地做出所有的这些暗示。

00:04:39.260 --> 00:04:41.260
我们不能小心地控制他们因为他们是我们的潜意识。

00:04:41.260 --> 00:04:43.260
但是和机器人互动时你却可以。

00:04:43.260 --> 00:04:45.260
因此在这段视频中--

00:04:45.260 --> 00:04:48.260
这是一段在东北大学大卫·德斯迪诺的实验室里录制的视频。

00:04:48.260 --> 00:04:50.260
他是一名和我们合作过的心理学家。

00:04:50.260 --> 00:04:53.260
有科学家在仔细控制着Nexi的肢体暗示信号

00:04:53.260 --> 00:04:56.260
来研究这个问题。

00:04:56.260 --> 00:04:58.260
结论是 - -这样做有效的原因是 --

00:04:58.260 --> 00:05:00.260
结果是人们行动正如人类

00:05:00.260 --> 00:05:03.260
就算他们和机器人互动。

00:05:03.260 --> 00:05:05.260
因此有了那个关键的洞察之后，

00:05:05.260 --> 00:05:07.260
我们现在可以开始想象

00:05:07.260 --> 00:05:10.260
机器人新的应用程序。

00:05:10.260 --> 00:05:13.260
例如，如果机器人对我们非语言的暗示做出反应，

00:05:13.260 --> 00:05:17.260
他们可能成为一种很酷的，新的交流技术。

00:05:17.260 --> 00:05:19.260
因此，想象一下：

00:05:19.260 --> 00:05:21.260
给你的手机一个机器人佩饰怎么样？

00:05:21.260 --> 00:05:23.260
你可以告诉你的朋友，她将她的耳机放在一个机器人里，

00:05:23.260 --> 00:05:25.260
然后，嘣！你就是一个MeBot--

00:05:25.260 --> 00:05:28.260
你可以利用眼神交流，你可以和你的朋友交流，

00:05:28.260 --> 00:05:30.260
你可以到处移动，你可以做肢体语言--

00:05:30.260 --> 00:05:33.260
或许退而求其次地真实的存在于此，不是么？

00:05:33.260 --> 00:05:35.260
为了探索这个问题

00:05:35.260 --> 00:05:38.260
我的学生，Siggy Adalgeirsson，做了一个研究

00:05:38.260 --> 00:05:41.260
我们召集了一些参与者在我们的实验室

00:05:41.260 --> 00:05:43.260
与一个远程合作者

00:05:43.260 --> 00:05:45.260
共同完成一个合作任务。

00:05:45.260 --> 00:05:47.260
任务包括

00:05:47.260 --> 00:05:49.260
想看桌子上放置的一系列东西，

00:05:49.260 --> 00:05:52.260
然后讨论这些东西对于完成一个特定任务-最终是一个生存任务--

00:05:52.260 --> 00:05:54.260
的相关性和重要性--

00:05:54.260 --> 00:05:56.260
然后根据他们认为这样东西多有价值

00:05:56.260 --> 00:05:58.260
多重要来打分。

00:05:58.260 --> 00:06:01.260
远程合作者是一个来自我们组的试验人员

00:06:01.260 --> 00:06:03.260
他们使用三种不同的科技手段

00:06:03.260 --> 00:06:05.260
来与参与者互动。

00:06:05.260 --> 00:06:07.260
第一种是屏幕。

00:06:07.260 --> 00:06:10.260
就像如今的视频会议一样。

00:06:10.260 --> 00:06:13.260
第二种我们加入了移动性，一个便携的屏幕。

00:06:13.260 --> 00:06:16.260
就像，如果你熟悉任何现有的远程呈现机器人的话 --

00:06:16.260 --> 00:06:19.260
这与那种情形相似。

00:06:19.260 --> 00:06:21.260
接着是能充分表现的MeBot。

00:06:21.260 --> 00:06:23.260
因此在互动之后，

00:06:23.260 --> 00:06:26.260
我们要求人们和一个远程的合作者

00:06:26.260 --> 00:06:28.260
用这种科技以不同的方式，

00:06:28.260 --> 00:06:31.260
去评价他们与科技互动的质量，

00:06:31.260 --> 00:06:33.260
我们考虑了心理的投入度--

00:06:33.260 --> 00:06:35.260
你有多么设身处地地考虑另一个人？

00:06:35.260 --> 00:06:37.260
我们看了整体的参与度。

00:06:37.260 --> 00:06:39.260
我们考虑了他们合作的欲望度。

00:06:39.260 --> 00:06:42.260
这是他们只是用屏幕的结果。

00:06:42.260 --> 00:06:45.260
如果你加入移动性 -- 在桌子上转动的能力 --

00:06:45.260 --> 00:06:47.260
你能得到一点提高。

00:06:47.260 --> 00:06:50.260
但如果加入完全的表达，你能得到更高的提高。

00:06:50.260 --> 00:06:52.260
所以看上去实体的交流化身

00:06:52.260 --> 00:06:54.260
能起重要的作用。

00:06:54.260 --> 00:06:57.260
现在把这个放入大一点的社会环境。

00:06:57.260 --> 00:07:00.260
我们知道如今家庭成员之间住的越来越远，

00:07:00.260 --> 00:07:02.260
这距离确实给我们的家庭关系

00:07:02.260 --> 00:07:04.260
和家庭联结打了折扣。

00:07:04.260 --> 00:07:06.260
就我而言，我有三个小儿子，

00:07:06.260 --> 00:07:08.260
我想让他们和他们的爷爷奶奶

00:07:08.260 --> 00:07:10.260
有很好的关系。

00:07:10.260 --> 00:07:12.260
但是我的父母住得远隔千里，

00:07:12.260 --> 00:07:14.260
所以他们并不能那么经常见到彼此。

00:07:14.260 --> 00:07:16.260
我们尝试Skype, 我们尝试打电话，

00:07:16.260 --> 00:07:18.260
但是我的孩子们还小 -- 他们不想说话，

00:07:18.260 --> 00:07:20.260
他们想玩儿。

00:07:20.260 --> 00:07:22.260
他们会喜欢这个机器人成为

00:07:22.260 --> 00:07:25.260
一种新的远程游戏科技的想法。

00:07:25.260 --> 00:07:28.260
所以我想象在不远的将来 --

00:07:28.260 --> 00:07:30.260
我的妈妈能够坐在电脑前，

00:07:30.260 --> 00:07:32.260
打开一个浏览窗然后化身为一个小小的机器人。

00:07:32.260 --> 00:07:35.260
如同机器人奶奶，

00:07:35.260 --> 00:07:37.260
她可以游戏，真正的游戏，

00:07:37.260 --> 00:07:39.260
和我的儿子，她的孙子，

00:07:39.260 --> 00:07:42.260
在这个真实世界和他的真实的玩具。

00:07:42.260 --> 00:07:44.260
我可以想象祖母们能够和她们的孙女，她们的朋友

00:07:44.260 --> 00:07:46.260
做一些社交的游戏，

00:07:46.260 --> 00:07:48.260
并且可以分享在房屋周围的所有的其他的活动，

00:07:48.260 --> 00:07:50.260
如同分享一个睡前的故事。

00:07:50.260 --> 00:07:52.260
通过这种科技，

00:07:52.260 --> 00:07:54.260
成为一个活跃的参与者

00:07:54.260 --> 00:07:56.260
在她们的孙子的生活中

00:07:56.260 --> 00:07:58.260
以一种今天不可能的方式。

00:07:58.260 --> 00:08:00.260
让我们来想像其他的一些领域，

00:08:00.260 --> 00:08:02.260
如同健康，

00:08:02.260 --> 00:08:04.260
今天在美国，

00:08:04.260 --> 00:08:07.260
超过65%的人超重或者有肥胖症，

00:08:07.260 --> 00:08:09.260
现在我们的孩子也有同样的问题。

00:08:09.260 --> 00:08:11.260
我们知道如果你变老，

00:08:11.260 --> 00:08:14.260
如果你在年轻的时候肥胖，那将导致慢性疾病

00:08:14.260 --> 00:08:16.260
那将不仅仅降低我们生活的质量，

00:08:16.260 --> 00:08:19.260
并且对保健系统也还是一个硕大的经济负担。

00:08:19.260 --> 00:08:21.260
但是如果机器人可以有趣味，

00:08:21.260 --> 00:08:23.260
如果我们愿意和机器人合作，

00:08:23.260 --> 00:08:25.260
如果机器人有说服力，

00:08:25.260 --> 00:08:27.260
一个机器人可能可以帮助你

00:08:27.260 --> 00:08:29.260
维持一个饮食和锻炼项目，

00:08:29.260 --> 00:08:32.260
他们可能可以帮助你管理你的体重。

00:08:32.260 --> 00:08:34.260
这正像是我们熟知的

00:08:34.260 --> 00:08:36.260
童话故事中的电子吉米尼，

00:08:36.260 --> 00:08:38.260
机器人作为一种友好支持的存在

00:08:38.260 --> 00:08:40.260
总能在那里帮你做出正确抉择

00:08:40.260 --> 00:08:42.260
以合适的方式，在合适的时间，

00:08:42.260 --> 00:08:44.260
来帮你组建健康习惯。

00:08:44.260 --> 00:08:46.260
因此我们实际上已经探索了这个主意。

00:08:46.260 --> 00:08:48.260
这是一个机器人，叫Autom.

00:08:48.260 --> 00:08:51.260
克里·基德为他的博士论文发明了这个机器人

00:08:51.260 --> 00:08:54.260
他被设计为一个机器人健康饮食锻炼教练。

00:08:54.260 --> 00:08:56.260
它由一些简单的非语言技巧。

00:08:56.260 --> 00:08:58.260
它可以与你眼神交流。

00:08:58.260 --> 00:09:00.260
它可以低头看屏幕与你分享信息。

00:09:00.260 --> 00:09:02.260
你将用一个屏幕界面输入信息，

00:09:02.260 --> 00:09:04.260
像你今天吃了多少卡路里，

00:09:04.260 --> 00:09:06.260
运动了多少

00:09:06.260 --> 00:09:08.260
他就能追踪记录那些

00:09:08.260 --> 00:09:10.260
同时机器人可以用它人造的合成声音

00:09:10.260 --> 00:09:12.260
与你进行指导对话。

00:09:12.260 --> 00:09:14.260
这些对话模拟真实的

00:09:14.260 --> 00:09:16.260
训练者与病人的交流。

00:09:16.260 --> 00:09:18.260
所以通过对话，它可以与你形成

00:09:18.260 --> 00:09:20.260
一种工作同盟。

00:09:20.260 --> 00:09:22.260
它帮你建立目标，记录你的进程，

00:09:22.260 --> 00:09:24.260
帮助你激励你。

00:09:24.260 --> 00:09:26.260
因此一个有趣的问题就是，

00:09:26.260 --> 00:09:29.260
这种社会的载体真的重要吗？这种载体是一个机器人有关系吗？

00:09:29.260 --> 00:09:32.260
还是知识建议和信息的质量有影响？

00:09:32.260 --> 00:09:34.260
因此去解决那个问题，

00:09:34.260 --> 00:09:36.260
我们在波士顿地区作了一个研究

00:09:36.260 --> 00:09:39.260
在几周时间里，我们把三种介入方式的一种

00:09:39.260 --> 00:09:41.260
放入人们的家中。

00:09:41.260 --> 00:09:44.260
一种是你看过的机器人， Autom.

00:09:44.260 --> 00:09:47.260
另一种是一个有同样触摸屏幕界面，

00:09:47.260 --> 00:09:49.260
运行完全相同的对话。

00:09:49.260 --> 00:09:51.260
建议的质量也完全相同。

00:09:51.260 --> 00:09:53.260
第三种是一支笔和一张纸，

00:09:53.260 --> 00:09:55.260
因为那是传统上开始一项

00:09:55.260 --> 00:09:58.260
饮食锻炼计划典型的介入方式。

00:09:58.260 --> 00:10:01.260
所以我们特别想要关注的是

00:10:01.260 --> 00:10:04.260
不是人们减少了多少体重，

00:10:04.260 --> 00:10:07.260
而是他们与机器人能维持多久的交流。

00:10:07.260 --> 00:10:10.260
因为挑战不是减去重量，而是保持重量下降。

00:10:10.260 --> 00:10:13.260
所以你能越长时间与这些介入方式互动，

00:10:13.260 --> 00:10:16.260
就越能表明有潜在获得长久成功的可能。

00:10:16.260 --> 00:10:18.260
所以我想看的第一件事情就是多久，

00:10:18.260 --> 00:10:20.260
人们可以与这些系统互动多久。

00:10:20.260 --> 00:10:22.260
结果是人们和机器人互动的时间

00:10:22.260 --> 00:10:24.260
远远多于其他，

00:10:24.260 --> 00:10:27.260
尽管建议的质量和电脑是完全一样的。

00:10:28.260 --> 00:10:31.260
当询问人们去评价相互合作的质量

00:10:31.260 --> 00:10:33.260
人们评价机器人更高

00:10:33.260 --> 00:10:35.260
他们更相信机器人。

00:10:35.260 --> 00:10:37.260
（笑声）

00:10:37.260 --> 00:10:39.260
当我们看到感性的介入，

00:10:39.260 --> 00:10:41.260
是完全的不同情况。

00:10:41.260 --> 00:10:43.260
人们愿意给机器人起名字。

00:10:43.260 --> 00:10:45.260
人们愿意给机器人穿衣服。

00:10:45.260 --> 00:10:47.260
（笑声）

00:10:47.260 --> 00:10:50.260
甚至当我们结束学习研究取回机器人的时候，

00:10:50.260 --> 00:10:52.260
他们愿意从车中走出来并对机器人说再见。

00:10:52.260 --> 00:10:54.260
他们从未对电脑作过这些。

00:10:54.260 --> 00:10:56.260
今天我想要谈的最后一件事情就是

00:10:56.260 --> 00:10:58.260
孩子媒体的未来。

00:10:58.260 --> 00:11:01.260
我们知道现在孩子花更多的时间在屏幕之后，

00:11:01.260 --> 00:11:04.260
不论是电视还是电脑游戏或者别的。

00:11:04.260 --> 00:11:07.260
我的儿子，他们热爱屏幕。他们热爱屏幕。

00:11:07.260 --> 00:11:10.260
但是我希望他们游戏，如果一个妈妈我希望他们

00:11:10.260 --> 00:11:12.260
能像在真实世界里一样游戏。

00:11:12.260 --> 00:11:15.260
所以我想向你们呈现我组里的一个新项目

00:11:15.260 --> 00:11:17.260
名为游戏时间计算

00:11:17.260 --> 00:11:19.260
这技术想要把

00:11:19.260 --> 00:11:21.260
电子媒体中最有趣吸引的东西

00:11:21.260 --> 00:11:23.260
带出屏幕，

00:11:23.260 --> 00:11:25.260
带入到孩子们的真实的世界，

00:11:25.260 --> 00:11:28.260
拥有现实中有喜的许多性质。

00:11:29.260 --> 00:11:33.260
所以这是这种理念的第一个探索，

00:11:33.260 --> 00:11:36.260
游戏角色可以使实体的和虚拟的，

00:11:36.260 --> 00:11:38.260
其中，电子的内容

00:11:38.260 --> 00:11:40.260
能走出屏幕

00:11:40.260 --> 00:11:42.260
进入现实然后回去。

00:11:42.260 --> 00:11:44.260
我喜欢把这想象成

00:11:44.260 --> 00:11:46.260
这种虚拟现实游戏的

00:11:46.260 --> 00:11:48.260
Atar Pong (第一台街机游戏机)

00:11:48.260 --> 00:11:50.260
但我们可以将这个想法发展得更远。

00:11:50.260 --> 00:11:52.260
如果--

00:11:52.260 --> 00:11:55.260
（游戏）内森：他来了，耶！

00:11:55.260 --> 00:11:58.260
辛西娅·布雷齐尔：--卡通人物本身能进入你的世界？

00:11:58.260 --> 00:12:00.260
结果是孩子们很爱它

00:12:00.260 --> 00:12:03.260
当那个卡通人物变成了真实的并且进入他们的世界。

00:12:03.260 --> 00:12:05.260
当它在他们的世界，

00:12:05.260 --> 00:12:07.260
他们可以与它建立联系，用一种与他们在屏幕里玩

00:12:07.260 --> 00:12:09.260
完全不同的方式，在现实里与它玩。

00:12:09.260 --> 00:12:11.260
另一个重要的概念是卡通形象穿越

00:12:11.260 --> 00:12:14.260
现实的一致性。

00:12:14.260 --> 00:12:16.260
所以孩子们在现实中做的变化

00:12:16.260 --> 00:12:18.260
也许要进入虚拟世界。

00:12:18.260 --> 00:12:21.260
因此这里，内森把字母A改成了数字2。

00:12:21.260 --> 00:12:23.260
你可以想象当这些象征进入虚拟世界时

00:12:23.260 --> 00:12:26.260
他能给与这些人物特殊的力量。

00:12:26.260 --> 00:12:29.260
所以他们现在将这些人物送回那个世界。

00:12:29.260 --> 00:12:32.260
现在他得到了数字的力量。

00:12:32.260 --> 00:12:34.260
最终，我一直努力在做的

00:12:34.260 --> 00:12:37.260
就是为孩子们创造一个真正沉浸在其中的体验，

00:12:37.260 --> 00:12:40.260
他们能够搞到他们是故事中的一部分，

00:12:40.260 --> 00:12:42.260
经历中的一部分。

00:12:42.260 --> 00:12:44.260
我真的希望能够激发他们的想象力

00:12:44.260 --> 00:12:47.260
正如我是个小女孩观看“星球大战”被启发的那样。

00:12:47.260 --> 00:12:49.260
但是我想要做更多。

00:12:49.260 --> 00:12:52.260
我实际上想让他们创造这些经验。

00:12:52.260 --> 00:12:54.260
我想让他们能够真的将他们的想象力

00:12:54.260 --> 00:12:56.260
建造到这些经验中，成为他们自己的经验。

00:12:56.260 --> 00:12:58.260
所以我们在远程呈现和混合现实领域

00:12:58.260 --> 00:13:00.260
探索了许多理念

00:13:00.260 --> 00:13:03.260
能够允许孩子把他们的想法投射在这个空间，

00:13:03.260 --> 00:13:05.260
在那里其他的孩子能够同他们互动

00:13:05.260 --> 00:13:07.260
进一步发挥想象。

00:13:07.260 --> 00:13:10.260
我真地想要找到孩童媒体的新方向

00:13:10.260 --> 00:13:13.260
能培养创造力，学习能力，和创新能力。

00:13:13.260 --> 00:13:16.260
我认为这非常非常的重要

00:13:16.260 --> 00:13:18.260
所以这是一个新的项目。

00:13:18.260 --> 00:13:20.260
我们邀请了一些孩子来到这个空间

00:13:20.260 --> 00:13:23.260
他们以为这个十分的酷

00:13:23.260 --> 00:13:25.260
但是我可以告诉你，他们最爱的是

00:13:25.260 --> 00:13:27.260
机器人。

00:13:27.260 --> 00:13:30.260
他们所关心的是机器人。

00:13:30.260 --> 00:13:33.260
机器人触动我们深处的人性。

00:13:33.260 --> 00:13:35.260
因此它们是否帮助我们

00:13:35.260 --> 00:13:37.260
变得更加富有创造力和创新能力，

00:13:37.260 --> 00:13:39.260
或者他们帮助我们

00:13:39.260 --> 00:13:41.260
彼此跨越距离，更加联结，

00:13:41.260 --> 00:13:43.260
还是他们是我们可信赖的好帮手

00:13:43.260 --> 00:13:45.260
帮我们实现我们的个人目标

00:13:45.260 --> 00:13:47.260
实现更高更好的自我，

00:13:47.260 --> 00:13:50.260
对我而言，机器人是与人类有关的一切。

00:13:50.260 --> 00:13:52.260
谢谢。

00:13:52.260 --> 00:13:57.260
（掌声）

