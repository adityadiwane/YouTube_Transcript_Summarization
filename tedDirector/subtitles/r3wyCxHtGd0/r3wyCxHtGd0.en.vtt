WEBVTT
Kind: captions
Language: en

00:00:13.160 --> 00:00:17.160
You know, I'm struck by how one of the implicit themes of TED

00:00:17.160 --> 00:00:20.160
is compassion, these very moving demonstrations we've just seen:

00:00:21.160 --> 00:00:25.160
HIV in Africa, President Clinton last night.

00:00:25.160 --> 00:00:30.160
And I'd like to do a little collateral thinking, if you will,

00:00:30.160 --> 00:00:35.160
about compassion and bring it from the global level to the personal.

00:00:35.160 --> 00:00:37.160
I'm a psychologist, but rest assured,

00:00:37.160 --> 00:00:38.160
I will not bring it to the scrotal.

00:00:39.160 --> 00:00:43.160
(Laughter)

00:00:44.160 --> 00:00:46.160
There was a very important study done a while ago

00:00:46.160 --> 00:00:50.160
at Princeton Theological Seminary that speaks to why it is

00:00:51.160 --> 00:00:54.160
that when all of us have so many opportunities to help,

00:00:54.160 --> 00:00:57.160
we do sometimes, and we don't other times.

00:00:58.160 --> 00:01:01.160
A group of divinity students at the Princeton Theological Seminary

00:01:02.160 --> 00:01:06.160
were told that they were going to give a practice sermon

00:01:06.160 --> 00:01:09.160
and they were each given a sermon topic.

00:01:09.160 --> 00:01:12.160
Half of those students were given, as a topic,

00:01:12.160 --> 00:01:14.160
the parable of the Good Samaritan:

00:01:14.160 --> 00:01:16.160
the man who stopped the stranger in --

00:01:17.160 --> 00:01:19.160
to help the stranger in need by the side of the road.

00:01:19.160 --> 00:01:22.160
Half were given random Bible topics.

00:01:22.160 --> 00:01:25.160
Then one by one, they were told they had to go to another building

00:01:26.160 --> 00:01:27.160
and give their sermon.

00:01:27.160 --> 00:01:30.160
As they went from the first building to the second,

00:01:30.160 --> 00:01:33.160
each of them passed a man who was bent over and moaning,

00:01:34.160 --> 00:01:38.160
clearly in need. The question is: Did they stop to help?

00:01:38.160 --> 00:01:39.160
The more interesting question is:

00:01:40.160 --> 00:01:43.160
Did it matter they were contemplating the parable

00:01:43.160 --> 00:01:47.160
of the Good Samaritan? Answer: No, not at all.

00:01:48.160 --> 00:01:51.160
What turned out to determine whether someone would stop

00:01:51.160 --> 00:01:52.160
and help a stranger in need

00:01:52.160 --> 00:01:55.160
was how much of a hurry they thought they were in --

00:01:56.160 --> 00:02:00.160
were they feeling they were late, or were they absorbed

00:02:00.160 --> 00:02:01.160
in what they were going to talk about.

00:02:02.160 --> 00:02:04.160
And this is, I think, the predicament of our lives:

00:02:05.160 --> 00:02:09.160
that we don't take every opportunity to help

00:02:09.160 --> 00:02:12.160
because our focus is in the wrong direction.

00:02:12.160 --> 00:02:15.160
There's a new field in brain science, social neuroscience.

00:02:16.160 --> 00:02:20.160
This studies the circuitry in two people's brains

00:02:20.160 --> 00:02:22.160
that activates while they interact.

00:02:22.160 --> 00:02:26.160
And the new thinking about compassion from social neuroscience

00:02:26.160 --> 00:02:30.160
is that our default wiring is to help.

00:02:30.160 --> 00:02:34.160
That is to say, if we attend to the other person,

00:02:35.160 --> 00:02:38.160
we automatically empathize, we automatically feel with them.

00:02:39.160 --> 00:02:41.160
There are these newly identified neurons, mirror neurons,

00:02:41.160 --> 00:02:45.160
that act like a neuro Wi-Fi, activating in our brain

00:02:45.160 --> 00:02:49.160
exactly the areas activated in theirs. We feel "with" automatically.

00:02:49.160 --> 00:02:53.160
And if that person is in need, if that person is suffering,

00:02:54.160 --> 00:02:58.160
we're automatically prepared to help. At least that's the argument.

00:02:58.160 --> 00:03:01.160
But then the question is: Why don't we?

00:03:01.160 --> 00:03:03.160
And I think this speaks to a spectrum

00:03:04.160 --> 00:03:06.160
that goes from complete self-absorption,

00:03:07.160 --> 00:03:09.160
to noticing, to empathy and to compassion.

00:03:09.160 --> 00:03:13.160
And the simple fact is, if we are focused on ourselves,

00:03:14.160 --> 00:03:17.160
if we're preoccupied, as we so often are throughout the day,

00:03:17.160 --> 00:03:20.160
we don't really fully notice the other.

00:03:20.160 --> 00:03:22.160
And this difference between the self and the other focus

00:03:22.160 --> 00:03:23.160
can be very subtle.

00:03:23.160 --> 00:03:27.160
I was doing my taxes the other day, and I got to the point

00:03:27.160 --> 00:03:29.160
where I was listing all of the donations I gave,

00:03:30.160 --> 00:03:33.160
and I had an epiphany, it was -- I came to my check

00:03:33.160 --> 00:03:36.160
to the Seva Foundation and I noticed that I thought,

00:03:36.160 --> 00:03:38.160
boy, my friend Larry Brilliant would really be happy

00:03:39.160 --> 00:03:40.160
that I gave money to Seva.

00:03:40.160 --> 00:03:43.160
Then I realized that what I was getting from giving

00:03:43.160 --> 00:03:47.160
was a narcissistic hit -- that I felt good about myself.

00:03:47.160 --> 00:03:52.160
Then I started to think about the people in the Himalayas

00:03:52.160 --> 00:03:54.160
whose cataracts would be helped, and I realized

00:03:55.160 --> 00:03:58.160
that I went from this kind of narcissistic self-focus

00:03:59.160 --> 00:04:02.160
to altruistic joy, to feeling good

00:04:02.160 --> 00:04:06.160
for the people that were being helped. I think that's a motivator.

00:04:06.160 --> 00:04:09.160
But this distinction between focusing on ourselves

00:04:09.160 --> 00:04:10.160
and focusing on others

00:04:10.160 --> 00:04:13.160
is one that I encourage us all to pay attention to.

00:04:13.160 --> 00:04:16.160
You can see it at a gross level in the world of dating.

00:04:17.160 --> 00:04:20.160
I was at a sushi restaurant a while back

00:04:20.160 --> 00:04:23.160
and I overheard two women talking about the brother of one woman,

00:04:24.160 --> 00:04:27.160
who was in the singles scene. And this woman says,

00:04:27.160 --> 00:04:29.160
"My brother is having trouble getting dates,

00:04:29.160 --> 00:04:31.160
so he's trying speed dating." I don't know if you know speed dating?

00:04:31.160 --> 00:04:35.160
Women sit at tables and men go from table to table,

00:04:35.160 --> 00:04:38.160
and there's a clock and a bell, and at five minutes, bingo,

00:04:39.160 --> 00:04:41.160
the conversation ends and the woman can decide

00:04:41.160 --> 00:04:45.160
whether to give her card or her email address to the man

00:04:45.160 --> 00:04:47.160
for follow up. And this woman says,

00:04:47.160 --> 00:04:51.160
"My brother's never gotten a card, and I know exactly why.

00:04:51.160 --> 00:04:56.160
The moment he sits down, he starts talking non-stop about himself;

00:04:56.160 --> 00:04:57.160
he never asks about the woman."

00:04:58.160 --> 00:05:03.160
And I was doing some research in the Sunday Styles section

00:05:03.160 --> 00:05:06.160
of The New York Times, looking at the back stories of marriages --

00:05:06.160 --> 00:05:09.160
because they're very interesting -- and I came to the marriage

00:05:09.160 --> 00:05:12.160
of Alice Charney Epstein. And she said

00:05:12.160 --> 00:05:14.160
that when she was in the dating scene,

00:05:15.160 --> 00:05:17.160
she had a simple test she put people to.

00:05:18.160 --> 00:05:20.160
The test was: from the moment they got together,

00:05:20.160 --> 00:05:23.160
how long it would take the guy to ask her a question

00:05:23.160 --> 00:05:25.160
with the word "you" in it.

00:05:25.160 --> 00:05:29.160
And apparently Epstein aced the test, therefore the article.

00:05:29.160 --> 00:05:30.160
(Laughter)

00:05:30.160 --> 00:05:32.160
Now this is a -- it's a little test

00:05:32.160 --> 00:05:34.160
I encourage you to try out at a party.

00:05:34.160 --> 00:05:36.160
Here at TED there are great opportunities.

00:05:38.160 --> 00:05:41.160
The Harvard Business Review recently had an article called

00:05:41.160 --> 00:05:44.160
"The Human Moment," about how to make real contact

00:05:44.160 --> 00:05:47.160
with a person at work. And they said, well,

00:05:47.160 --> 00:05:50.160
the fundamental thing you have to do is turn off your BlackBerry,

00:05:51.160 --> 00:05:54.160
close your laptop, end your daydream

00:05:55.160 --> 00:05:57.160
and pay full attention to the person.

00:05:58.160 --> 00:06:02.160
There is a newly coined word in the English language

00:06:03.160 --> 00:06:06.160
for the moment when the person we're with whips out their BlackBerry

00:06:06.160 --> 00:06:09.160
or answers that cell phone, and all of a sudden we don't exist.

00:06:10.160 --> 00:06:14.160
The word is "pizzled": it's a combination of puzzled and pissed off.

00:06:14.160 --> 00:06:17.160
(Laughter)

00:06:17.160 --> 00:06:23.160
I think it's quite apt. It's our empathy, it's our tuning in

00:06:24.160 --> 00:06:27.160
which separates us from Machiavellians or sociopaths.

00:06:27.160 --> 00:06:32.160
I have a brother-in-law who's an expert on horror and terror --

00:06:32.160 --> 00:06:35.160
he wrote the Annotated Dracula, the Essential Frankenstein --

00:06:35.160 --> 00:06:36.160
he was trained as a Chaucer scholar,

00:06:36.160 --> 00:06:38.160
but he was born in Transylvania

00:06:38.160 --> 00:06:40.160
and I think it affected him a little bit.

00:06:40.160 --> 00:06:44.160
At any rate, at one point my brother-in-law, Leonard,

00:06:44.160 --> 00:06:46.160
decided to write a book about a serial killer.

00:06:46.160 --> 00:06:49.160
This is a man who terrorized the very vicinity we're in

00:06:50.160 --> 00:06:52.160
many years ago. He was known as the Santa Cruz strangler.

00:06:53.160 --> 00:06:57.160
And before he was arrested, he had murdered his grandparents,

00:06:57.160 --> 00:07:00.160
his mother and five co-eds at UC Santa Cruz.

00:07:01.160 --> 00:07:03.160
So my brother-in-law goes to interview this killer

00:07:04.160 --> 00:07:06.160
and he realizes when he meets him

00:07:06.160 --> 00:07:07.160
that this guy is absolutely terrifying.

00:07:08.160 --> 00:07:10.160
For one thing, he's almost seven feet tall.

00:07:10.160 --> 00:07:13.160
But that's not the most terrifying thing about him.

00:07:13.160 --> 00:07:18.160
The scariest thing is that his IQ is 160: a certified genius.

00:07:19.160 --> 00:07:23.160
But there is zero correlation between IQ and emotional empathy,

00:07:23.160 --> 00:07:24.160
feeling with the other person.

00:07:25.160 --> 00:07:27.160
They're controlled by different parts of the brain.

00:07:28.160 --> 00:07:30.160
So at one point, my brother-in-law gets up the courage

00:07:31.160 --> 00:07:33.160
to ask the one question he really wants to know the answer to,

00:07:33.160 --> 00:07:36.160
and that is: how could you have done it?

00:07:36.160 --> 00:07:38.160
Didn't you feel any pity for your victims?

00:07:38.160 --> 00:07:41.160
These were very intimate murders -- he strangled his victims.

00:07:42.160 --> 00:07:44.160
And the strangler says very matter-of-factly,

00:07:44.160 --> 00:07:49.160
"Oh no. If I'd felt the distress, I could not have done it.

00:07:49.160 --> 00:07:55.160
I had to turn that part of me off. I had to turn that part of me off."

00:07:55.160 --> 00:08:00.160
And I think that that is very troubling,

00:08:01.160 --> 00:08:05.160
and in a sense, I've been reflecting on turning that part of us off.

00:08:05.160 --> 00:08:07.160
When we focus on ourselves in any activity,

00:08:08.160 --> 00:08:11.160
we do turn that part of ourselves off if there's another person.

00:08:12.160 --> 00:08:17.160
Think about going shopping and think about the possibilities

00:08:17.160 --> 00:08:19.160
of a compassionate consumerism.

00:08:20.160 --> 00:08:22.160
Right now, as Bill McDonough has pointed out,

00:08:24.160 --> 00:08:28.160
the objects that we buy and use have hidden consequences.

00:08:28.160 --> 00:08:31.160
We're all unwitting victims of a collective blind spot.

00:08:32.160 --> 00:08:34.160
We don't notice and don't notice that we don't notice

00:08:35.160 --> 00:08:41.160
the toxic molecules emitted by a carpet or by the fabric on the seats.

00:08:42.160 --> 00:08:47.160
Or we don't know if that fabric is a technological

00:08:47.160 --> 00:08:51.160
or manufacturing nutrient; it can be reused

00:08:51.160 --> 00:08:53.160
or does it just end up at landfill? In other words,

00:08:53.160 --> 00:08:58.160
we're oblivious to the ecological and public health

00:08:59.160 --> 00:09:02.160
and social and economic justice consequences

00:09:02.160 --> 00:09:04.160
of the things we buy and use.

00:09:06.160 --> 00:09:10.160
In a sense, the room itself is the elephant in the room,

00:09:10.160 --> 00:09:14.160
but we don't see it. And we've become victims

00:09:14.160 --> 00:09:17.160
of a system that points us elsewhere. Consider this.

00:09:18.160 --> 00:09:21.160
There's a wonderful book called

00:09:22.160 --> 00:09:24.160
Stuff: The Hidden Life of Everyday Objects.

00:09:25.160 --> 00:09:28.160
And it talks about the back story of something like a t-shirt.

00:09:28.160 --> 00:09:31.160
And it talks about where the cotton was grown

00:09:31.160 --> 00:09:33.160
and the fertilizers that were used and the consequences

00:09:33.160 --> 00:09:37.160
for soil of that fertilizer. And it mentions, for instance,

00:09:37.160 --> 00:09:40.160
that cotton is very resistant to textile dye;

00:09:40.160 --> 00:09:43.160
about 60 percent washes off into wastewater.

00:09:43.160 --> 00:09:46.160
And it's well known by epidemiologists that kids

00:09:46.160 --> 00:09:51.160
who live near textile works tend to have high rates of leukemia.

00:09:52.160 --> 00:09:56.160
There's a company, Bennett and Company, that supplies Polo.com,

00:09:57.160 --> 00:10:02.160
Victoria's Secret -- they, because of their CEO, who's aware of this,

00:10:03.160 --> 00:10:07.160
in China formed a joint venture with their dye works

00:10:07.160 --> 00:10:09.160
to make sure that the wastewater

00:10:09.160 --> 00:10:13.160
would be properly taken care of before it returned to the groundwater.

00:10:13.160 --> 00:10:17.160
Right now, we don't have the option to choose the virtuous t-shirt

00:10:18.160 --> 00:10:22.160
over the non-virtuous one. So what would it take to do that?

00:10:25.160 --> 00:10:28.160
Well, I've been thinking. For one thing,

00:10:28.160 --> 00:10:33.160
there's a new electronic tagging technology that allows any store

00:10:33.160 --> 00:10:37.160
to know the entire history of any item on the shelves in that store.

00:10:38.160 --> 00:10:40.160
You can track it back to the factory. Once you can track it

00:10:40.160 --> 00:10:44.160
back to the factory, you can look at the manufacturing processes

00:10:44.160 --> 00:10:48.160
that were used to make it, and if it's virtuous,

00:10:48.160 --> 00:10:52.160
you can label it that way. Or if it's not so virtuous,

00:10:52.160 --> 00:10:56.160
you can go into -- today, go into any store,

00:10:56.160 --> 00:10:59.160
put your scanner on a palm onto a barcode,

00:10:59.160 --> 00:11:01.160
which will take you to a website.

00:11:01.160 --> 00:11:03.160
They have it for people with allergies to peanuts.

00:11:04.160 --> 00:11:06.160
That website could tell you things about that object.

00:11:07.160 --> 00:11:08.160
In other words, at point of purchase,

00:11:08.160 --> 00:11:12.160
we might be able to make a compassionate choice.

00:11:12.160 --> 00:11:18.160
There's a saying in the world of information science:

00:11:18.160 --> 00:11:21.160
ultimately everybody will know everything.

00:11:21.160 --> 00:11:23.160
And the question is: will it make a difference?

00:11:25.160 --> 00:11:28.160
Some time ago when I was working for The New York Times,

00:11:29.160 --> 00:11:31.160
it was in the '80s, I did an article

00:11:31.160 --> 00:11:33.160
on what was then a new problem in New York --

00:11:33.160 --> 00:11:35.160
it was homeless people on the streets.

00:11:35.160 --> 00:11:39.160
And I spent a couple of weeks going around with a social work agency

00:11:39.160 --> 00:11:42.160
that ministered to the homeless. And I realized seeing the homeless

00:11:42.160 --> 00:11:47.160
through their eyes that almost all of them were psychiatric patients

00:11:47.160 --> 00:11:51.160
that had nowhere to go. They had a diagnosis. It made me --

00:11:52.160 --> 00:11:55.160
what it did was to shake me out of the urban trance where,

00:11:56.160 --> 00:11:59.160
when we see, when we're passing someone who's homeless

00:11:59.160 --> 00:12:02.160
in the periphery of our vision, it stays on the periphery.

00:12:04.160 --> 00:12:06.160
We don't notice and therefore we don't act.

00:12:09.160 --> 00:12:14.160
One day soon after that -- it was a Friday -- at the end of the day,

00:12:14.160 --> 00:12:17.160
I went down -- I was going down to the subway. It was rush hour

00:12:17.160 --> 00:12:19.160
and thousands of people were streaming down the stairs.

00:12:19.160 --> 00:12:21.160
And all of a sudden as I was going down the stairs

00:12:21.160 --> 00:12:24.160
I noticed that there was a man slumped to the side,

00:12:24.160 --> 00:12:28.160
shirtless, not moving, and people were just stepping over him --

00:12:29.160 --> 00:12:30.160
hundreds and hundreds of people.

00:12:31.160 --> 00:12:34.160
And because my urban trance had been somehow weakened,

00:12:35.160 --> 00:12:38.160
I found myself stopping to find out what was wrong.

00:12:39.160 --> 00:12:41.160
The moment I stopped, half a dozen other people

00:12:42.160 --> 00:12:43.160
immediately ringed the same guy.

00:12:44.160 --> 00:12:46.160
And we found out that he was Hispanic, he didn't speak any English,

00:12:46.160 --> 00:12:51.160
he had no money, he'd been wandering the streets for days, starving,

00:12:51.160 --> 00:12:52.160
and he'd fainted from hunger.

00:12:52.160 --> 00:12:54.160
Immediately someone went to get orange juice,

00:12:54.160 --> 00:12:56.160
someone brought a hotdog, someone brought a subway cop.

00:12:57.160 --> 00:13:00.160
This guy was back on his feet immediately.

00:13:00.160 --> 00:13:04.160
But all it took was that simple act of noticing,

00:13:05.160 --> 00:13:06.160
and so I'm optimistic.

00:13:06.160 --> 00:13:07.160
Thank you very much.

00:13:07.160 --> 00:13:09.160
(Applause)

