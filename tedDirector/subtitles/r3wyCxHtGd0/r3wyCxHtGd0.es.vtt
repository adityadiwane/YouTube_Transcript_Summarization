WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Ruth Alonso
Revisor: Patricia Tatis

00:00:13.160 --> 00:00:17.160
¿Saben?, me sorprende que uno de los temas implícitos de TED

00:00:17.160 --> 00:00:20.160
sea la compasión. Acabamos de ver demostraciones muy emotivas:

00:00:21.160 --> 00:00:25.160
como la de anoche del Presidente Clinton, sobre el VIH en África.

00:00:25.160 --> 00:00:30.160
Y me gustaría hacer un poco de pensamiento colateral, por así llamarlo,

00:00:30.160 --> 00:00:35.160
sobre la compasión, y llevarlo de lo global a lo personal.

00:00:35.160 --> 00:00:37.160
Soy psicólogo, pero tranquilos,

00:00:37.160 --> 00:00:38.160
que no lo llevaré al plano sexual.

00:00:39.160 --> 00:00:43.160
(Risas)

00:00:44.160 --> 00:00:46.160
Hace tiempo se realizó un estudio muy importante

00:00:46.160 --> 00:00:50.160
en el Semirario Teológico de Princeton que nos habla de por qué

00:00:51.160 --> 00:00:54.160
cuando todos nosotros tenemos tantas oportunidades de ayudar,

00:00:54.160 --> 00:00:57.160
a veces lo hacemos y a veces no.

00:00:58.160 --> 00:01:01.160
A un grupo de estudiantes de teología en el Seminario de Teología en Princeton

00:01:02.160 --> 00:01:06.160
se les dijo que iban a dar un sermón de práctica,

00:01:06.160 --> 00:01:09.160
y a cada uno se le dio un tema para el sermón.

00:01:09.160 --> 00:01:12.160
A la mitad de esos alumnos se les dio como tema,

00:01:12.160 --> 00:01:14.160
la parábola del buen samaritano:

00:01:14.160 --> 00:01:16.160
el hombre que se paró para ayudar al desconocido --

00:01:17.160 --> 00:01:19.160
al necesitado que estaba en un lado de la carretera.

00:01:19.160 --> 00:01:22.160
A la otra mitad se les dio temas bíblicos aleatorios.

00:01:22.160 --> 00:01:25.160
Luego, uno a uno, se les dijo que tenían que ir a otro edificio

00:01:26.160 --> 00:01:27.160
y dar el sermón.

00:01:27.160 --> 00:01:30.160
Mientras iban desde el primer edificio hasta el segundo,

00:01:30.160 --> 00:01:33.160
todos se cruzaron con un hombre que estaba encogido, se quejaba y estaba

00:01:34.160 --> 00:01:38.160
claramente necesitado. La pregunta es: ¿se detuvieron a ayudarlo?

00:01:38.160 --> 00:01:39.160
La pregunta más interesante es:

00:01:40.160 --> 00:01:43.160
¿Importó que estuvieran pensando en la parábola

00:01:43.160 --> 00:01:47.160
del buen samaritano? Respuesta: no, en lo absoluto.

00:01:48.160 --> 00:01:51.160
Lo que resultó determinar si alguien se detendría

00:01:51.160 --> 00:01:52.160
a ayudar a un desconocido necesitado

00:01:52.160 --> 00:01:55.160
fue cuánta prisa creían que tenían --

00:01:56.160 --> 00:02:00.160
¿pensaban que llegaban tarde, o estaban absortos

00:02:00.160 --> 00:02:01.160
pensando en lo que iban a hablar?

00:02:02.160 --> 00:02:04.160
Y este es, según creo, el problema de nuestras vidas:

00:02:05.160 --> 00:02:09.160
que no aprovechamos todas las oportunidades para ayudar,

00:02:09.160 --> 00:02:12.160
porque nuestro foco apunta en la dirección equivocada.

00:02:12.160 --> 00:02:15.160
Hay una nueva disciplina en neurociencia, la neurociencia social.

00:02:16.160 --> 00:02:20.160
Estudia los circuitos en los cerebros de dos personas

00:02:20.160 --> 00:02:22.160
que se activan cuando éstas interactúan.

00:02:22.160 --> 00:02:26.160
Y la nueva manera de pensar sobre la compasión en neurociencia social

00:02:26.160 --> 00:02:30.160
es que nuestra reacción, por defecto, es ayudar.

00:02:30.160 --> 00:02:34.160
Es decir, si prestamos atención a la otra persona,

00:02:35.160 --> 00:02:38.160
automáticamente nos identificamos, automáticamente sentimos como él.

00:02:39.160 --> 00:02:41.160
Existen unas neuronas identificadas recientemente, neuronas espejo,

00:02:41.160 --> 00:02:45.160
que actúan como una conexión inhálambrica neuronal, al activar en nuestro cerebro

00:02:45.160 --> 00:02:49.160
exactamente las áreas activadas en el cerebro de otro. Nos identificamos automáticamente.

00:02:49.160 --> 00:02:53.160
Y si esa persona está necesitada, si esa persona está sufriendo,

00:02:54.160 --> 00:02:58.160
automáticamente estamos listos para ayudar. Por lo menos esa es la idea.

00:02:58.160 --> 00:03:01.160
Pero entonces la pregunta es: ¿por qué no lo hacemos?

00:03:01.160 --> 00:03:03.160
Y creo que esto tiene que ver con un espectro

00:03:04.160 --> 00:03:06.160
que va desde el ensimismamiento absoluto,

00:03:07.160 --> 00:03:09.160
hasta el hecho de darse cuenta y tener empatía y compasión.

00:03:09.160 --> 00:03:13.160
Y el simple hecho es que, si nos centramos en nosotros mismos,

00:03:14.160 --> 00:03:17.160
si estamos preocupados, como tantas veces lo estamos a lo largo del día,

00:03:17.160 --> 00:03:20.160
realmente no percibimos al otro del todo.

00:03:20.160 --> 00:03:22.160
Y esta diferencia entre centrarse en uno mismo o en el otro

00:03:22.160 --> 00:03:23.160
puede ser muy sutil.

00:03:23.160 --> 00:03:27.160
Estaba haciendo la declaración de los impuestos hace unos días, y llegué al punto

00:03:27.160 --> 00:03:29.160
en que tenía que declarar todas las donaciones que había hecho,

00:03:30.160 --> 00:03:33.160
y tuve una epifanía, fue -- llegué al cheque que mandé

00:03:33.160 --> 00:03:36.160
a la Fundación Seva y me di cuenta de que pensé,

00:03:36.160 --> 00:03:38.160
vaya, mi amigo Larry Brilliant estaría muy contento

00:03:39.160 --> 00:03:40.160
de que yo haya dado dinero a Seva.

00:03:40.160 --> 00:03:43.160
Entonces me di cuenta de que lo que yo estaba recibiendo por dar

00:03:43.160 --> 00:03:47.160
era una dosis de narcisismo -- de sentirme bien conmigo mismo.

00:03:47.160 --> 00:03:52.160
Entonces empecé a pensar en la gente en el Himalaya

00:03:52.160 --> 00:03:54.160
cuyas cataratas mejorarían, y me di cuenta

00:03:55.160 --> 00:03:58.160
de que fui de una clase de ensimismamiento narcisista

00:03:59.160 --> 00:04:02.160
a una alegría altruísta, a sentirme bien

00:04:02.160 --> 00:04:06.160
por la gente a la que estaba ayudando. Creo que eso motiva.

00:04:06.160 --> 00:04:09.160
Pero esta distinción entre centrarnos en nosotros mismos

00:04:09.160 --> 00:04:10.160
y centrarnos en otros,

00:04:10.160 --> 00:04:13.160
es a la que los animo a prestar atención.

00:04:13.160 --> 00:04:16.160
Lo pueden ver de manera generalizada en el mundo de las citas amorosas.

00:04:17.160 --> 00:04:20.160
Hace un tiempo estaba en un restaurante de sushi

00:04:20.160 --> 00:04:23.160
y escuché a dos mujeres hablar sobre el hermano de una de ellas,

00:04:24.160 --> 00:04:27.160
que estaba soltero. Y una mujer dice:

00:04:27.160 --> 00:04:29.160
"A mi hermano le está resultando difícil salir con alguien,

00:04:29.160 --> 00:04:31.160
así que está intentándolo con citas rápidas". No sé si conocen las citas rápidas.

00:04:31.160 --> 00:04:35.160
Las mujeres se sientan en mesas y los hombres van de mesa en mesa,

00:04:35.160 --> 00:04:38.160
y hay un reloj y una campana, y a los cinco minutos, bingo,

00:04:39.160 --> 00:04:41.160
la conversación termina y la mujer decide

00:04:41.160 --> 00:04:45.160
si darle su tarjeta o su correo electrónico al hombre

00:04:45.160 --> 00:04:47.160
para continuar. Y la mujer dice:

00:04:47.160 --> 00:04:51.160
"A mi hermano nunca le han dado ninguna tarjeta. Y sé exactamente por qué.

00:04:51.160 --> 00:04:56.160
En cuanto se sienta, empieza a hablar sin parar sobre sí mismo,

00:04:56.160 --> 00:04:57.160
y nunca le pregunta sobre ella".

00:04:58.160 --> 00:05:03.160
Yo estaba estudiando la sección "Sunday Styles" (Estilos de domingo) del New York Times,

00:05:03.160 --> 00:05:06.160
mirando la historia detrás de algunos matrimonios

00:05:06.160 --> 00:05:09.160
porque son muy interesantes -- y llegué al matrimonio de

00:05:09.160 --> 00:05:12.160
Alice Charney Epstein. Y decía

00:05:12.160 --> 00:05:14.160
que cuando ella estaba buscando pareja,

00:05:15.160 --> 00:05:17.160
tenía una prueba sencilla que ella aplicaba.

00:05:18.160 --> 00:05:20.160
La prueba era: desde el momento en el que se conocieran,

00:05:20.160 --> 00:05:23.160
¿cuánto tiempo le llevaría al hombre hacerle una pregunta

00:05:23.160 --> 00:05:25.160
con la palabra "tú" en ella?

00:05:25.160 --> 00:05:29.160
Y aparentemente Epstein lo hizo muy bien, de ahí el artículo.

00:05:29.160 --> 00:05:30.160
(Risas)

00:05:30.160 --> 00:05:32.160
Ahora éste es un-- es un pequeño test

00:05:32.160 --> 00:05:34.160
que les animo a que usen en una fiesta.

00:05:34.160 --> 00:05:36.160
En TED hay grandes oportunidades.

00:05:38.160 --> 00:05:41.160
La Harvard Business Review tenía un artículo hace poco titulado

00:05:41.160 --> 00:05:44.160
"El momento humano", sobre cómo crear contacto real

00:05:44.160 --> 00:05:47.160
con una persona en el trabajo. Y decía que

00:05:47.160 --> 00:05:50.160
lo más importante que tienes que hacer es apagar tu Blackberry,

00:05:51.160 --> 00:05:54.160
cerrar tu computadora portátil, dejar de soñar despierto

00:05:55.160 --> 00:05:57.160
y prestar toda tu atención a la persona.

00:05:58.160 --> 00:06:02.160
Hay una palabra acuñada recientemente en el idioma inglés

00:06:03.160 --> 00:06:06.160
para describir el momento en el que la persona con la que estamos saca su Blackberry

00:06:06.160 --> 00:06:09.160
o responde a una llamada en el móvil y de repente no existimos.

00:06:10.160 --> 00:06:14.160
La palabra es "pizzled": una combinación entre confundido y enojado.

00:06:14.160 --> 00:06:17.160
(Risas)

00:06:17.160 --> 00:06:23.160
Me parece bastante apropiada. Es nuestra empatía, nuestra capacidad para conectar

00:06:24.160 --> 00:06:27.160
lo que nos separa de la gente maquiavélica o de los sociópatas.

00:06:27.160 --> 00:06:32.160
Tengo un cuñado que es experto en horror y terror-

00:06:32.160 --> 00:06:35.160
escribió "Drácula Anotado", "Frankenstein Esencial" --

00:06:35.160 --> 00:06:36.160
fue entrenado como especialista en Chaucer,

00:06:36.160 --> 00:06:38.160
pero nació en Transilvania

00:06:38.160 --> 00:06:40.160
y creo que eso le afectó un poco.

00:06:40.160 --> 00:06:44.160
De todos modos, en cierto momento mi cuñado, Leonardo,

00:06:44.160 --> 00:06:46.160
decidió escribir un libro sobre un asesino en serie.

00:06:46.160 --> 00:06:49.160
Se trata de un hombre que hace muchos años sembró el pánico en esta zona.

00:06:50.160 --> 00:06:52.160
Se le conocía como el estrangulador de Santa Cruz.

00:06:53.160 --> 00:06:57.160
Y antes de que fuera arrestado, había asesinado a sus abuelos,

00:06:57.160 --> 00:07:00.160
a su madre y a cinco chicas en la universidad de UC Santa Cruz.

00:07:01.160 --> 00:07:03.160
Así que mi cuñado va a entrevistar a este asesino

00:07:04.160 --> 00:07:06.160
y se da cuenta cuando lo conoce que

00:07:06.160 --> 00:07:07.160
el hombre es absolutamente aterrador.

00:07:08.160 --> 00:07:10.160
Por un lado, mide casi siete pies de alto.

00:07:10.160 --> 00:07:13.160
Pero eso no es lo peor.

00:07:13.160 --> 00:07:18.160
Lo que más miedo da es que su coeficiente intelectual es de 160: un genio acreditado.

00:07:19.160 --> 00:07:23.160
Pero la correlación entre el coeficiente intelectual y la empatía emocional,

00:07:23.160 --> 00:07:24.160
el sentir con la otra persona, es nula.

00:07:25.160 --> 00:07:27.160
Están controlados por diferentes partes del cerebro.

00:07:28.160 --> 00:07:30.160
Así que en un momento determinado, mi cuñado se arma de valor

00:07:31.160 --> 00:07:33.160
y le hace una pregunta cuya respuesta realmente quiere saber.

00:07:33.160 --> 00:07:36.160
Y la pregunta es: ¿cómo pudo hacerlo?

00:07:36.160 --> 00:07:38.160
¿No sintió lástima alguna por sus víctimas?

00:07:38.160 --> 00:07:41.160
Fueron asesinatos muy íntimos -- extranguló a sus víctimas.

00:07:42.160 --> 00:07:44.160
Y el extrangulador le dice impasible:

00:07:44.160 --> 00:07:49.160
"Oh, no. Si me hubiera afligido, no podría haberlo hecho.

00:07:49.160 --> 00:07:55.160
Tuve que desconectar esa parte de mí. Tuve que desconectar esa parte de mí".

00:07:55.160 --> 00:08:00.160
Y creo que eso es muy preocupante.

00:08:01.160 --> 00:08:05.160
Y, en cierto sentido, he estado reflexionando sobre el hecho de desconectar esa parte de nosotros.

00:08:05.160 --> 00:08:07.160
Cuando nos centramos en nosotros, en cualquier actividad,

00:08:08.160 --> 00:08:11.160
desconectamos esa parte de nosotros si hay otra persona.

00:08:12.160 --> 00:08:17.160
Piensen en ir de compras y piensen en las posibilidades

00:08:17.160 --> 00:08:19.160
de un consumismo compasivo.

00:08:20.160 --> 00:08:22.160
Ahora mismo, como señaló Bill McDonough,

00:08:24.160 --> 00:08:28.160
los objetos que compramos y usamos esconden consecuencias.

00:08:28.160 --> 00:08:31.160
Todos somos víctimas involuntarias de un talón de Aquiles colectivo.

00:08:32.160 --> 00:08:34.160
No percibimos y no nos damos cuenta de que no percibimos

00:08:35.160 --> 00:08:41.160
las moléculas tóxicas emitidas por una alfombra o por el tejido de los asientos.

00:08:42.160 --> 00:08:47.160
O no sabemos si ese tejido es un nutriente tecnológico

00:08:47.160 --> 00:08:51.160
o de manufactura; ¿puede reutilizarse

00:08:51.160 --> 00:08:53.160
o se va directamente a un vertedero? En otras palabras,

00:08:53.160 --> 00:08:58.160
somos ajenos a las consecuencias ecológicas, de salud pública,

00:08:59.160 --> 00:09:02.160
sociales y de justicia económica

00:09:02.160 --> 00:09:04.160
de las cosas que compramos y usamos.

00:09:06.160 --> 00:09:10.160
En cierto sentido, lo tenemos a la vista,

00:09:10.160 --> 00:09:14.160
pero no lo vemos. Y nos hemos convertido en víctimas

00:09:14.160 --> 00:09:17.160
de un sistema que nos distrae. Consideren esto.

00:09:18.160 --> 00:09:21.160
Hay un libro maravilloso llamado:

00:09:22.160 --> 00:09:24.160
"Cosas: la vida oculta de los objetos cotidianos".

00:09:25.160 --> 00:09:28.160
Y habla de la historia detrás de una camiseta.

00:09:28.160 --> 00:09:31.160
Y habla de dónde se cultivó el algodón,

00:09:31.160 --> 00:09:33.160
y de los fertilizantes que se usaron y de las consecuencias

00:09:33.160 --> 00:09:37.160
de ese fertilizante para la tierra. Y menciona, por ejemplo,

00:09:37.160 --> 00:09:40.160
que el algodón es muy resistente a los tintes textiles;

00:09:40.160 --> 00:09:43.160
alrededor del 60 por ciento se convierte en agua residual.

00:09:43.160 --> 00:09:46.160
Y los epidemiólogos saben bien que los niños

00:09:46.160 --> 00:09:51.160
que viven cerca de fábricas textiles son más propensos a la leucemia.

00:09:52.160 --> 00:09:56.160
Hay una compañía, Bennett and Company, que abastece a Polo.com,

00:09:57.160 --> 00:10:02.160
a Victoria's Secret -- ellos, gracias a su director ejecutivo, que es consciente de esto,

00:10:03.160 --> 00:10:07.160
hicieron una alianza estratégica en China, para trabajar conjuntamente sus trabajos con tintes

00:10:07.160 --> 00:10:09.160
para asegurarse que sus aguas residuales

00:10:09.160 --> 00:10:13.160
serían depuradas antes de volver a los canales subterráneos.

00:10:13.160 --> 00:10:17.160
Ahora mismo, no tenemos la opción de decidir entre la camiseta elaborada con consciencia social

00:10:18.160 --> 00:10:22.160
y la que no lo ha sido. ¿Qué se requeriría para tener esa opción?

00:10:25.160 --> 00:10:28.160
Bueno, he estado pensando. Por un lado,

00:10:28.160 --> 00:10:33.160
hay una nueva tecnología de etiquetado electrónico que permite que cualquier tienda

00:10:33.160 --> 00:10:37.160
sepa la historia completa de cualquier objeto en los estantes de esa tienda.

00:10:38.160 --> 00:10:40.160
Puedes rastrearlo hasta la fábrica. Una vez que lo has rastreado hasta la fábrica

00:10:40.160 --> 00:10:44.160
puedes fijarte en los procesos de manufactura

00:10:44.160 --> 00:10:48.160
que se usaron para hacerlo, y si se ha confeccionado con compasión

00:10:48.160 --> 00:10:52.160
lo puedes etiquetar de ese modo. O, si no,

00:10:52.160 --> 00:10:56.160
puedes entrar -- hoy, entrar en cualquier tienda,

00:10:56.160 --> 00:10:59.160
poner tu escáner en la palma de la mano y aplicarlo a un código de barras

00:10:59.160 --> 00:11:01.160
que te llevará a una página web.

00:11:01.160 --> 00:11:03.160
Lo tienen para gente con alergia a los cacahuates.

00:11:04.160 --> 00:11:06.160
Esa página podría decirte cosas sobre ese objeto.

00:11:07.160 --> 00:11:08.160
En otras palabras, al momento de comprar,

00:11:08.160 --> 00:11:12.160
quizás podamos hacer una elección compasiva.

00:11:12.160 --> 00:11:18.160
Hay un dicho en el mundo de la ciencia de la información:

00:11:18.160 --> 00:11:21.160
Al final, todos sabrán todo.

00:11:21.160 --> 00:11:23.160
Y la pregunta es: ¿hará esto una diferencia?

00:11:25.160 --> 00:11:28.160
Hace algún tiempo cuando trabajaba para el New York Times,

00:11:29.160 --> 00:11:31.160
en los años 80, escribí un artículo

00:11:31.160 --> 00:11:33.160
sobre lo que entonces era un nuevo problema en Nueva York --

00:11:33.160 --> 00:11:35.160
las personas sin hogar que estaban en la calle.

00:11:35.160 --> 00:11:39.160
Y pasé un par de semanas dando vueltas por ahí con una agencia de trabajo social

00:11:39.160 --> 00:11:42.160
que se dedicaba a los desamparados. Y me di cuenta al mirar a los desamparados a los ojos,

00:11:42.160 --> 00:11:47.160
de que casi todos eran pacientes psiquiátricos

00:11:47.160 --> 00:11:51.160
sin un lugar adonde ir. Estaban diagnosticados. Me hizo --

00:11:52.160 --> 00:11:55.160
lo que hizo fue sacarme del trance urbano por el cual,

00:11:56.160 --> 00:11:59.160
cuando miramos, cuando pasamos al lado de una persona sin hogar

00:11:59.160 --> 00:12:02.160
en la periferia de nuestra visión, se queda en la periferia.

00:12:04.160 --> 00:12:06.160
No nos fijamos, y, en consecuencia, no actuamos.

00:12:09.160 --> 00:12:14.160
Un día próximo a eso -- era un viernes -- al final del día,

00:12:14.160 --> 00:12:17.160
bajé -- iba al tren subterráneo. Era una hora crucial

00:12:17.160 --> 00:12:19.160
y miles de personas bajaban las escaleras como una corriente.

00:12:19.160 --> 00:12:21.160
Y de repente al yo bajar las escaleras

00:12:21.160 --> 00:12:24.160
me fijé en que había un hombre inclinado hacia un costado,

00:12:24.160 --> 00:12:28.160
sin camisa, sin moverse, y la gente estaba pasando por encima de él --

00:12:29.160 --> 00:12:30.160
cientos y cientos de personas.

00:12:31.160 --> 00:12:34.160
Y como mi trance urbano se había delibitado de alguna manera,

00:12:35.160 --> 00:12:38.160
me vi a mí mismo deteniéndome para averiguar qué le pasaba.

00:12:39.160 --> 00:12:41.160
En cuanto me detuve, media docena de personas más

00:12:42.160 --> 00:12:43.160
rodearon al tipo inmediatamente.

00:12:44.160 --> 00:12:46.160
Y averiguamos que era hispano, que no hablaba nada de inglés,

00:12:46.160 --> 00:12:51.160
que no tenía dinero, que llevaba días deambulando por las calles, hambriento,

00:12:51.160 --> 00:12:52.160
y que se había desmayado de hambre.

00:12:52.160 --> 00:12:54.160
Inmediatamente alguien fue a conseguir un jugo de naranja,

00:12:54.160 --> 00:12:56.160
alguien le consiguió un "hotdog", alguien trajo a un policía del tren.

00:12:57.160 --> 00:13:00.160
El tipo estaba en pie inmediatamente.

00:13:00.160 --> 00:13:04.160
Pero todo lo que hizo falta fue el simple hecho de fijarse.

00:13:05.160 --> 00:13:06.160
Así que soy optimista.

00:13:06.160 --> 00:13:07.160
Muchas gracias.

00:13:07.160 --> 00:13:09.160
(Aplausos)

