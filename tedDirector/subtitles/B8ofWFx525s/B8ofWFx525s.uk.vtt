WEBVTT
Kind: captions
Language: uk

00:00:00.000 --> 00:00:07.000
Перекладач: Dmitriy Baykov
Утверджено: Kato Despati

00:00:15.260 --> 00:00:17.260
Марк Цукерберг,

00:00:17.260 --> 00:00:20.260
журналіст ставив йому питання про стрічку новин.

00:00:20.260 --> 00:00:22.260
Журналіст запитував його:

00:00:22.260 --> 00:00:24.260
"Чому це так важливо?"

00:00:24.260 --> 00:00:26.260
Цукерберг відповів:

00:00:26.260 --> 00:00:28.260
"Білка, що помирає у вашому дворі

00:00:28.260 --> 00:00:31.260
може бути більш релевантною до ваших інтересів просто зараз

00:00:31.260 --> 00:00:34.260
ніж люди, що гинуть в Африці".

00:00:34.260 --> 00:00:36.260
Я хочу поговорити про те,

00:00:36.260 --> 00:00:39.260
як Інтернет, що базується на цій ідеї релевантності може виглядати.

00:00:40.260 --> 00:00:42.260
В той час коли я підростав

00:00:42.260 --> 00:00:44.260
в насправді сільській місцевості штату Мен,

00:00:44.260 --> 00:00:47.260
Інтернет означав для мене щось зовсім інше.

00:00:47.260 --> 00:00:49.260
Він означав зв'язок з усім світом.

00:00:49.260 --> 00:00:52.260
Він означав дещо таке, що мало поєднати нас всіх разом.

00:00:52.260 --> 00:00:55.260
І я був упевнений, що це буде чудово для демокрітії

00:00:55.260 --> 00:00:58.260
і для нашого суспільства.

00:00:58.260 --> 00:01:00.260
Але існує цей зсув

00:01:00.260 --> 00:01:02.260
в тому, як інформація тече онлайн,

00:01:02.260 --> 00:01:05.260
і він невидимий.

00:01:05.260 --> 00:01:07.260
І якщо ми не звернемо увагу на нього,

00:01:07.260 --> 00:01:10.260
він може стати реальною проблемою.

00:01:10.260 --> 00:01:13.260
Я вперше помітив це в місці, де я проводжу доволі багато часу -

00:01:13.260 --> 00:01:15.260
моя сторінка у Facebook.

00:01:15.260 --> 00:01:18.260
Я прогресивний, політично -- великий сюрприз --

00:01:18.260 --> 00:01:20.260
але я завжди відходив від моїх переконань, щоб зустрітися з консерваторами.

00:01:20.260 --> 00:01:22.260
Мені подобається чути про що вони думають;

00:01:22.260 --> 00:01:24.260
Мені подобається бачити посилання, якими вони діляться;

00:01:24.260 --> 00:01:26.260
Мені подобається дізнаватись певні речі.

00:01:26.260 --> 00:01:29.260
Я був здивований коли одного дня помітив,

00:01:29.260 --> 00:01:32.260
що консерватори зникли з моєї стрічки новин на Facebook.

00:01:33.260 --> 00:01:35.260
Виявилося, що відбувалося те,

00:01:35.260 --> 00:01:39.260
що Facebook вивчав, на які посилання я натискав,

00:01:39.260 --> 00:01:41.260
і він помітив, що власне,

00:01:41.260 --> 00:01:43.260
я натискав частіше на посилання від моїх друзів лібералів

00:01:43.260 --> 00:01:46.260
ніж на посилання моїх друзів консерваторів.

00:01:46.260 --> 00:01:48.260
І не радячись зі мною,

00:01:48.260 --> 00:01:50.260
він відсіяв їх.

00:01:50.260 --> 00:01:53.260
Вони зникли.

00:01:54.260 --> 00:01:56.260
Але Facebook не єдине місце

00:01:56.260 --> 00:01:58.260
де провадять такого роду невидиме, алгоритмічне

00:01:58.260 --> 00:02:01.260
редагування Інтернету.

00:02:01.260 --> 00:02:03.260
Google також це робить.

00:02:03.260 --> 00:02:06.260
Якщо я шукаю дещо, і ви шукаєте те саме,

00:02:06.260 --> 00:02:08.260
навіть просто зараз, в той самиий час,

00:02:08.260 --> 00:02:11.260
ми можемо отримати дуже різні результати нашого пошуку.

00:02:11.260 --> 00:02:14.260
Навіть якщо ви вилогувались, один інженер сказав мені,

00:02:14.260 --> 00:02:16.260
- існує 57 сигналів

00:02:16.260 --> 00:02:19.260
які зчитує Google --

00:02:19.260 --> 00:02:22.260
все, починаючи з того який комп'ютер ви використовуєте,

00:02:22.260 --> 00:02:24.260
який браузер ви використовуєте

00:02:24.260 --> 00:02:26.260
закінчуючи тим де ви знаходитеся --

00:02:26.260 --> 00:02:29.260
Все це він використовує, щоб персоналізувати результати вашого пошуку.

00:02:29.260 --> 00:02:31.260
Замисліться про це на мить:

00:02:31.260 --> 00:02:35.260
більше не існує стандартного Google.

00:02:35.260 --> 00:02:38.260
І ви знаєте, найсмішніше в цьому те, що це важко побачити.

00:02:38.260 --> 00:02:40.260
Ви не можете побачити, наскільки відрізняються ваші результати пошуку

00:02:40.260 --> 00:02:42.260
від результатів когось іншого.

00:02:42.260 --> 00:02:44.260
Але пару тижнів тому,

00:02:44.260 --> 00:02:47.260
Я попросив декількох свої друзів загуглити "Єгипет"

00:02:47.260 --> 00:02:50.260
і надіслати мені скріншоти того, що вони отримали.

00:02:50.260 --> 00:02:53.260
Ось скріншот мого друга Скотта.

00:02:54.260 --> 00:02:57.260
А ось скріншот мого друга Денієла.

00:02:57.260 --> 00:02:59.260
Коли ви поставите їх поруч,

00:02:59.260 --> 00:03:01.260
вам навіть не потрібно читати посилання

00:03:01.260 --> 00:03:03.260
щоб, побачити які відмінні ці дві сторінки.

00:03:03.260 --> 00:03:05.260
Але коли ви прочитаєте посилання,

00:03:05.260 --> 00:03:08.260
це просто дивовижно.

00:03:09.260 --> 00:03:12.260
Данієль зовсім не отримав результатів стосовно протестів у Єгипті

00:03:12.260 --> 00:03:14.260
на першій сторінці результатів пошуку в Google.

00:03:14.260 --> 00:03:16.260
Результати Скотта були переповнені ними.

00:03:16.260 --> 00:03:18.260
І це була велика новина на той час.

00:03:18.260 --> 00:03:21.260
Ось наскільки різними стають результати пошуку.

00:03:21.260 --> 00:03:24.260
Але це стосується не тільки Google та Facebook.

00:03:24.260 --> 00:03:26.260
Це щось таке, що пронизує Інтернет.

00:03:26.260 --> 00:03:29.260
Існує ціла низка компаній, які роблять такого роду персоналізацію.

00:03:29.260 --> 00:03:32.260
Yahoo News, найбільший сайт новин в Інтернеті,

00:03:32.260 --> 00:03:35.260
тепер персоналізовано -- різні люди отримують різні новини.

00:03:36.260 --> 00:03:39.260
Huffington Post, Washington Post, New York Times --

00:03:39.260 --> 00:03:42.260
всі вони "фліртують" з персоналізацією по-різному.

00:03:42.260 --> 00:03:45.260
І це дуже швидко скеровує нас

00:03:45.260 --> 00:03:47.260
до світу, в якому

00:03:47.260 --> 00:03:51.260
Інтернет показує нам те, що, на його думку, ми хочемо бачити,

00:03:51.260 --> 00:03:54.260
але не обов'язково те, що нам потрібно бачити.

00:03:54.260 --> 00:03:57.260
Як Ерік Шмідт сказав:

00:03:57.260 --> 00:04:00.260
"Це стане дуже складним для людей, подивитися або спожити щось

00:04:00.260 --> 00:04:02.260
що не було, певною мірою,

00:04:02.260 --> 00:04:05.260
підігнане під них."

00:04:05.260 --> 00:04:07.260
Отже я вважаю, що це проблема.

00:04:07.260 --> 00:04:10.260
І я вважаю, що якщо взяти всі ці фільтри разом,

00:04:10.260 --> 00:04:12.260
взяти всі ці алгоритми,

00:04:12.260 --> 00:04:15.260
ви отримаєте те що я називаю "фільтрова бульбашка".

00:04:16.260 --> 00:04:19.260
І ваша фільтрова бульбашка є вашою власною, персональною,

00:04:19.260 --> 00:04:21.260
унікальною підмножиною інформації

00:04:21.260 --> 00:04:23.260
в якій ви живете онлайн.

00:04:23.260 --> 00:04:26.260
І те, що в середини вашої бульбашки

00:04:26.260 --> 00:04:29.260
залежить від того, хто ви і що ви робите.

00:04:29.260 --> 00:04:33.260
Але справа в тому, що ви не вирішуєте, що потрапить всередину.

00:04:33.260 --> 00:04:35.260
І набагато важливіше,

00:04:35.260 --> 00:04:38.260
- ви навіть не бачити ту інформацію яка відфільтровується.

00:04:38.260 --> 00:04:40.260
Отже одна з проблем з "фільтровою бульбашкою"

00:04:40.260 --> 00:04:43.260
була виявлена дослідниками Netflix.

00:04:43.260 --> 00:04:46.260
А вони спостерігали черги відтворення в Netflix і помітили щось цікаве.

00:04:46.260 --> 00:04:48.260
те, що, вірогідно, помічали багато з нас,

00:04:48.260 --> 00:04:50.260
існують деякі фільми

00:04:50.260 --> 00:04:53.260
вони просто прослизають в наші будинки.

00:04:53.260 --> 00:04:56.260
Вони стають у чергу, і просто вистрілюють.

00:04:56.260 --> 00:04:58.260
Отже "Iron Man" вистрілює,

00:04:58.260 --> 00:05:00.260
а "Waiting for Superman"

00:05:00.260 --> 00:05:02.260
може дійсно довго чекати.

00:05:02.260 --> 00:05:04.260
Що вони виявили,

00:05:04.260 --> 00:05:06.260
це те, що в наший чергах Netfix

00:05:06.260 --> 00:05:09.260
відбувається ця епічна боротьба

00:05:09.260 --> 00:05:12.260
між бажаними нами в майбутньому

00:05:12.260 --> 00:05:15.260
і між більш імпульсивними нами теперішніми.

00:05:15.260 --> 00:05:17.260
Ви знаєте, ми всі хочемо бути кимось

00:05:17.260 --> 00:05:19.260
хто дивився "Rashomon" (японський художній чорно-білий фільм 1950 року)

00:05:19.260 --> 00:05:21.260
але саме зараз

00:05:21.260 --> 00:05:24.260
ми хочемо, переглянути "Ейс Вентура" вчетверте.

00:05:24.260 --> 00:05:27.260
(Сміх)

00:05:27.260 --> 00:05:29.260
Тому ліпша редакція дає нам те, і інше.

00:05:29.260 --> 00:05:31.260
Воно дає нам трохи Джастіна Бібера

00:05:31.260 --> 00:05:33.260
і трохи Афганістану.

00:05:33.260 --> 00:05:35.260
Воно дає нам трохи "інформаційних овочів";

00:05:35.260 --> 00:05:38.260
воно дає нам трішки "інформаційного десерту".

00:05:38.260 --> 00:05:40.260
І проблема з цими видами алгоритмічних фільтрів,

00:05:40.260 --> 00:05:42.260
цих персоналізованих фільтрів,

00:05:42.260 --> 00:05:44.260
в тім, що вони, переважно, беруть до уваги

00:05:44.260 --> 00:05:48.260
те, на що ви натисли першим,

00:05:48.260 --> 00:05:52.260
що може порушувати той баланс.

00:05:52.260 --> 00:05:55.260
І замість збалансованої "інформаційної дієти",

00:05:55.260 --> 00:05:57.260
ви можете опинитися в оточенні

00:05:57.260 --> 00:05:59.260
інформаційного фаст-фуду.

00:05:59.260 --> 00:06:01.260
Це свідчить про те,

00:06:01.260 --> 00:06:04.260
що ми, направду, хибно зрозуміли цю історію про Інтернет.

00:06:04.260 --> 00:06:06.260
У "трансляційному" суспільстві --

00:06:06.260 --> 00:06:08.260
ось якою є його міфологія --

00:06:08.260 --> 00:06:10.260
у "трансляційному" суспільстві,

00:06:10.260 --> 00:06:12.260
були ті вартові, редактори,

00:06:12.260 --> 00:06:15.260
і вони контролювали потоки інформації.

00:06:15.260 --> 00:06:18.260
Та з'явився Інтернет, і змів їх зі свого шляху,

00:06:18.260 --> 00:06:20.260
й це дозволило всім нам об'єднатися,

00:06:20.260 --> 00:06:22.260
і це було дивовижно.

00:06:22.260 --> 00:06:25.260
Але насправді це не зовсім те, що відбувається зараз.

00:06:26.260 --> 00:06:29.260
Що ми бачимо, більшою мірою - передача факелу

00:06:29.260 --> 00:06:31.260
від людей-брамарів

00:06:31.260 --> 00:06:34.260
до алгоритмічних вартових.

00:06:34.260 --> 00:06:37.260
І справа в тому, що алгоритми

00:06:37.260 --> 00:06:40.260
ще не мають, чогось на зразок вбудованої етики

00:06:40.260 --> 00:06:43.260
яку мали редактори.

00:06:43.260 --> 00:06:46.260
Отже, якщо алгоритми будуть коригувати світ для нас,

00:06:46.260 --> 00:06:49.260
якщо вони будуть вирішувати, що ми зможемо побачити, а що ні

00:06:49.260 --> 00:06:51.260
тоді ми повинні упевнитися,

00:06:51.260 --> 00:06:54.260
що вони не просто прив'язані до релевантності.

00:06:54.260 --> 00:06:56.260
Ми повинні пересвідчитись, що вони також покажуть нам речі

00:06:56.260 --> 00:06:59.260
які є незручними, кидають виклик або просто важливі --

00:06:59.260 --> 00:07:01.260
це те що робить TED --

00:07:01.260 --> 00:07:03.260
інші точки зору.

00:07:03.260 --> 00:07:05.260
А справа в тому, що ми насправді були тут раніше

00:07:05.260 --> 00:07:07.260
як суспільство.

00:07:08.260 --> 00:07:11.260
У 1915 році, не те щоб газети багато писали про

00:07:11.260 --> 00:07:14.260
громадські обов'язки.

00:07:14.260 --> 00:07:16.260
Тоді люди помітили

00:07:16.260 --> 00:07:19.260
що вони роблять щось насправді дуже важливе.

00:07:19.260 --> 00:07:21.260
Насправді неможливо отримати

00:07:21.260 --> 00:07:23.260
функціюючу демократію

00:07:23.260 --> 00:07:27.260
якщо громадяни не отримають гарний потік інформації,

00:07:28.260 --> 00:07:31.260
газети були критичними, тому що вони виступали в якості фільтру,

00:07:31.260 --> 00:07:33.260
а тоді розвинулася журналістська етика.

00:07:33.260 --> 00:07:35.260
Вона не була досконалою,

00:07:35.260 --> 00:07:38.260
але вона провела нас крізь минуле сторіччя.

00:07:38.260 --> 00:07:40.260
Тож тепер,

00:07:40.260 --> 00:07:43.260
ми, в якомусь сенсі, в Інтернеті ми знов опинилися в 1915 році.

00:07:44.260 --> 00:07:47.260
І нам потрібні нові вартові,

00:07:47.260 --> 00:07:49.260
котрі закодують той різновид відповідальність

00:07:49.260 --> 00:07:51.260
в код який вони пишуть.

00:07:51.260 --> 00:07:54.260
Я знаю, що тут є багато людей з Facebook і Google --

00:07:54.260 --> 00:07:56.260
Ларрі і Сергій -

00:07:56.260 --> 00:07:58.260
люди, які допомогли побудувати Інтернет в тому вигляді, який існує зараз,

00:07:58.260 --> 00:08:00.260
і я вдячний за це.

00:08:00.260 --> 00:08:03.260
Але ми дійсно повинні переконатися,

00:08:03.260 --> 00:08:06.260
що в цих алгоритмах закодовано

00:08:06.260 --> 00:08:09.260
відчуття публічного життя, відчуття громадської відповідальності.

00:08:09.260 --> 00:08:12.260
Ми хочемо, щоб ви впевнились, що вони достатньо прозорі,

00:08:12.260 --> 00:08:14.260
і ми можемо побачити які правила вони використовують,

00:08:14.260 --> 00:08:17.260
обумовлюючи те, що проривається крізь наші фільтри.

00:08:17.260 --> 00:08:19.260
І нам потрібно, щоб ви дали нам певний контроль,

00:08:19.260 --> 00:08:21.260
так, щоб ми могли вирішувати

00:08:21.260 --> 00:08:24.260
що проходить крізь фільтри, а що ні.

00:08:24.260 --> 00:08:26.260
Бо я вважаю

00:08:26.260 --> 00:08:28.260
нам дійсно потрібно, щоб Інтернет був тим,

00:08:28.260 --> 00:08:30.260
про що ми всі мріяли.

00:08:30.260 --> 00:08:33.260
Нам потрібно, щоб він всіх нас поєднав.

00:08:33.260 --> 00:08:36.260
Нам потрібно, щоб він представляв нам нові ідеї,

00:08:36.260 --> 00:08:39.260
нових людей і відмінні перспективи.

00:08:40.260 --> 00:08:42.260
Але він не зможе цьог о зробити,

00:08:42.260 --> 00:08:45.260
якщо залишить нас в ізоляції "Мережі на одну особу".

00:08:45.260 --> 00:08:47.260
Дякую за увагу.

00:08:47.260 --> 00:08:58.260
(Оплески)

