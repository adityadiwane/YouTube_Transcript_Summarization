WEBVTT
Kind: captions
Language: ko

00:00:00.000 --> 00:00:07.000
번역: J J LEE
검토: Bianca Lee

00:00:15.260 --> 00:00:17.260
한 언론인이

00:00:17.260 --> 00:00:20.260
마크 주커버그에게 
뉴스 피드에 대한 질문을 했습니다.

00:00:20.260 --> 00:00:22.260
그 언론인은 이렇게 물었죠.

00:00:22.260 --> 00:00:24.260
"이것이 왜 그렇게 중요한가요?"

00:00:24.260 --> 00:00:26.260
주커버그가 답했습니다.

00:00:26.260 --> 00:00:28.260
"아프리카에서 죽어가는 사람들 보다

00:00:28.260 --> 00:00:31.260
여러분 앞마당에서 죽어가는 다람쥐가

00:00:31.260 --> 00:00:34.260
지금 당장은 더 관심이 갈지도 모릅니다."

00:00:34.260 --> 00:00:36.260
저는 관련성의 아이디어에 바탕을 둔

00:00:36.260 --> 00:00:39.260
웹이 어떤 것인가에 대해서 
말하고자 합니다.

00:00:40.260 --> 00:00:42.260
제가 메인주의 시골에서

00:00:42.260 --> 00:00:44.260
성장할 때는,

00:00:44.260 --> 00:00:47.260
인터넷은 제게 아주 
다른 것을 의미했습니다.

00:00:47.260 --> 00:00:49.260
세계와의 연결을 의미했죠.

00:00:49.260 --> 00:00:52.260
우리를 다함께 연결할 뭔가를 의미했죠.

00:00:52.260 --> 00:00:55.260
저는 인터넷이 민주주의와 우리 사회에

00:00:55.260 --> 00:00:58.260
유익할 것이라고 확신했습니다.

00:00:58.260 --> 00:01:00.260
하지만 온라인에서

00:01:00.260 --> 00:01:02.260
어떻게 정보가 공급되는지에 
변화가 존재하고,

00:01:02.260 --> 00:01:05.260
그것은 눈에 띄지 않죠.

00:01:05.260 --> 00:01:07.260
그리고 거기에 관심을 
기울이지 않는다면,

00:01:07.260 --> 00:01:10.260
진짜 문제가 될 수 있습니다.

00:01:10.260 --> 00:01:13.260
저는 이것을 제가 많은 시간을 
보내는 페이스북에서

00:01:13.260 --> 00:01:15.260
처음으로 인지했습니다.

00:01:15.260 --> 00:01:18.260
저는 진보적 정치 성향을 가지고 있습니다. 
놀랄만한 일인가요.

00:01:18.260 --> 00:01:20.260
하지만 저는 늘 보수적 성향의 사람들을 
만나려고 노력했습니다.

00:01:20.260 --> 00:01:22.260
저는 그들이 생각하는 바를 
경청하기 좋아합니다.

00:01:22.260 --> 00:01:24.260
저는 그들이 연관되어 있는 것을 
확인하기 좋아합니다.

00:01:24.260 --> 00:01:26.260
저는 이것 저것 배우는 것을 좋아합니다.

00:01:26.260 --> 00:01:29.260
그래서 어느날 보수주의자들이 
제 페이스북 피드에서

00:01:29.260 --> 00:01:32.260
사라졌다는 것을 알았을 때 
깜짝 놀랐습니다.

00:01:33.260 --> 00:01:35.260
페이스북이 제가 어떤 링크를

00:01:35.260 --> 00:01:39.260
클릭하는지 살펴보고 있었고, 
그것은 실제로

00:01:39.260 --> 00:01:41.260
제가 보수적 성향의 친구들 보다

00:01:41.260 --> 00:01:43.260
진보적 성향을 가진 친구들의 링크를

00:01:43.260 --> 00:01:46.260
더 많이 클릭했다는 것을 
나타내는 것이었죠.

00:01:46.260 --> 00:01:48.260
그리고 제 의견을 묻지도 않고

00:01:48.260 --> 00:01:50.260
페이스북은 그것을 편집해 버렸습니다.

00:01:50.260 --> 00:01:53.260
그들은 사라졌죠.

00:01:54.260 --> 00:01:56.260
페이스북만이 이런 눈에 띄지 않는

00:01:56.260 --> 00:01:58.260
알고리즘적인 웹 편집을

00:01:58.260 --> 00:02:01.260
실행하고 있는 것이 아닙니다.

00:02:01.260 --> 00:02:03.260
구글 역시 그렇게 합니다.

00:02:03.260 --> 00:02:06.260
제가 뭔가를 검색하고, 
여러분이 검색을 한다면,

00:02:06.260 --> 00:02:08.260
바로 지금 동시에 검색을 할지라도,

00:02:08.260 --> 00:02:11.260
서로 다른 검색 결과를 얻을 것입니다.

00:02:11.260 --> 00:02:14.260
한 엔지니어가 제게 말하길, 
비록 로그 아웃 했을지라도

00:02:14.260 --> 00:02:16.260
여러분의 질의 결과에

00:02:16.260 --> 00:02:19.260
개별적으로 맞추기 위해

00:02:19.260 --> 00:02:22.260
구글은 57개의 신호들을 살펴본다고 합니다.

00:02:22.260 --> 00:02:24.260
어떤 종류의 컴퓨터를 사용하는지,

00:02:24.260 --> 00:02:26.260
어떤 종류의 브라우저를 사용하는지,

00:02:26.260 --> 00:02:29.260
어느 지역에 있는지까지 모든 것을 말이죠.

00:02:29.260 --> 00:02:31.260
잠시 그것을 생각해보세요.

00:02:31.260 --> 00:02:35.260
표준화된 구글은 
더 이상 존재하지 않습니다.

00:02:35.260 --> 00:02:38.260
그리고 재미있는 것은 
이것이 눈에 띄기 힘들다는 것입니다.

00:02:38.260 --> 00:02:40.260
여러분의 검색 결과가 
다른 사람들의 것과

00:02:40.260 --> 00:02:42.260
얼마나 다른지 볼 수 없습니다.

00:02:42.260 --> 00:02:44.260
하지만 2주 전에,

00:02:44.260 --> 00:02:47.260
저는 친구들에게 
구글에서 "이집트"를 검색해보고

00:02:47.260 --> 00:02:50.260
그 결과의 스크린 샷을 
보내달라고 부탁했습니다.

00:02:50.260 --> 00:02:53.260
여기 제 친구 스콧의 
스크린 샷이 있습니다.

00:02:54.260 --> 00:02:57.260
그리고 제 친구 다니엘의 
스크린 샷입니다.

00:02:57.260 --> 00:02:59.260
그것들을 나란히 놓고 볼 때,

00:02:59.260 --> 00:03:01.260
이 두 페이지가 어떻게 다른지

00:03:01.260 --> 00:03:03.260
링크들을 읽어볼 필요도 없습니다.

00:03:03.260 --> 00:03:05.260
하지만 그 링크들을 읽어보면,

00:03:05.260 --> 00:03:08.260
정말 아주 놀랄만합니다.

00:03:09.260 --> 00:03:12.260
다니엘은 구글 검색 결과의 
첫 페이지에서 이집트에서의

00:03:12.260 --> 00:03:14.260
시위에 대해 아무런 결과도 얻지 못했습니다.

00:03:14.260 --> 00:03:16.260
스콧의 결과는 시위에 대해 가득했습니다.

00:03:16.260 --> 00:03:18.260
시위는 그 당시의 가장 큰 뉴스거리였죠.

00:03:18.260 --> 00:03:21.260
그것이 이 결과들이 
얼마나 달라지는가 하는 것입니다.

00:03:21.260 --> 00:03:24.260
구글과 페이스북만 그런 것이 아닙니다.

00:03:24.260 --> 00:03:26.260
이것은 웹에 광범위하게 
나타나는 것입니다.

00:03:26.260 --> 00:03:29.260
이런 개인화를 실행하고 있는
수 많은 기업들이 존재합니다.

00:03:29.260 --> 00:03:32.260
인터넷 최대 뉴스 사이트인 
야후 뉴스는

00:03:32.260 --> 00:03:35.260
이제 개인화 되어, 서로 다른 사람들이
서로 다른 결과를 얻습니다.

00:03:36.260 --> 00:03:39.260
허핑톤 포스트, 워싱턴 포스트, 뉴욕 타임즈 등

00:03:39.260 --> 00:03:42.260
모두가 개인화를 다양한 방식으로
시도하고 있습니다.

00:03:42.260 --> 00:03:45.260
이것이 인터넷이 우리가 보기 원한다고

00:03:45.260 --> 00:03:47.260
생각하지만 우리가 반드시

00:03:47.260 --> 00:03:51.260
볼 필요는 없는 것을 보여주는 세상으로

00:03:51.260 --> 00:03:54.260
빠르게 움직이게 하고 있습니다.

00:03:54.260 --> 00:03:57.260
에릭 슈미트가

00:03:57.260 --> 00:04:00.260
"어떤 의미에서, 사람들이 
그들에게 맞춰지지 않은

00:04:00.260 --> 00:04:02.260
뭔가를 보고, 소비한다는 것은

00:04:02.260 --> 00:04:05.260
매우 힘든 일이 될 것입니다."
라고 말한 대로

00:04:05.260 --> 00:04:07.260
저는 이것이 정말 문제라고 
생각합니다.

00:04:07.260 --> 00:04:10.260
여러분이 이런 필터들과 알고리즘들을

00:04:10.260 --> 00:04:12.260
함께 사용한다면, 제가 필터 버블이라

00:04:12.260 --> 00:04:15.260
부르는 것을 겪을 것이라고 생각합니다.

00:04:16.260 --> 00:04:19.260
여러분의 필터 버블은 온라인에서

00:04:19.260 --> 00:04:21.260
살아가는 여러분만의 개인적인

00:04:21.260 --> 00:04:23.260
유일무이한 정보 우주입니다.

00:04:23.260 --> 00:04:26.260
여러분의 필터 버블 안에 있는 것은

00:04:26.260 --> 00:04:29.260
여러분이 누구인가, 여러분이 
무엇을 하는가에 달려있습니다.

00:04:29.260 --> 00:04:33.260
하지만 무엇이 포함될지 
여러분이 결정하지 않습니다.

00:04:33.260 --> 00:04:35.260
그리고 보다 중요하게는,

00:04:35.260 --> 00:04:38.260
실제로 무엇이 편집되어 
사라지는지 확인하지 않습니다.

00:04:38.260 --> 00:04:40.260
필터 버블의 문제점 중 하나는

00:04:40.260 --> 00:04:43.260
넷플릭스의 연구자들에 의해
발견되었습니다.

00:04:43.260 --> 00:04:46.260
그들은 넷플릭스의 큐(queue)를 들여다 봤고, 아마도 우리 중 많은 수가 인지해 왔을

00:04:46.260 --> 00:04:48.260
재미난 뭔가를 알아냈습니다.

00:04:48.260 --> 00:04:50.260
압축 된 후, 즉시 우리의 가정으로

00:04:50.260 --> 00:04:53.260
압축이 해제됬던 
영화 파일들이 있었던 겁니다.

00:04:53.260 --> 00:04:56.260
영화들은 큐에 들어가고, 
바로 압축이 해제됩니다.

00:04:56.260 --> 00:04:58.260
"아이언맨"은 바로 압축이 풀어지고,

00:04:58.260 --> 00:05:00.260
"슈퍼맨을 기다리며"는

00:05:00.260 --> 00:05:02.260
오랜 시간 대기열을 탑니다.

00:05:02.260 --> 00:05:04.260
우리 넷플릭스 큐에서

00:05:04.260 --> 00:05:06.260
그들이 발견한 것은

00:05:06.260 --> 00:05:09.260
우리 열망하는 미래의 자아들과

00:05:09.260 --> 00:05:12.260
보다 충동적인 현재의 자아 사이에서

00:05:12.260 --> 00:05:15.260
서사시적인 투쟁이 존재한다는 것입니다.

00:05:15.260 --> 00:05:17.260
우리는 모두 "라쇼몽"을 본

00:05:17.260 --> 00:05:19.260
사람이 되기를 바라지만,

00:05:19.260 --> 00:05:21.260
당장은

00:05:21.260 --> 00:05:24.260
"에이스 벤츄라"를 
네 번째로 보기 원합니다.

00:05:24.260 --> 00:05:27.260
(웃음)

00:05:27.260 --> 00:05:29.260
최상의 편집은 우리에게
양쪽 측면을 조금씩 건내줍니다.

00:05:29.260 --> 00:05:31.260
저스틴 비버에 대해 조금,

00:05:31.260 --> 00:05:33.260
아프가니스탄에 대해 조금 건내주죠.

00:05:33.260 --> 00:05:35.260
그것은 우리에게 
정보 야채를 제공합니다.

00:05:35.260 --> 00:05:38.260
그것은 우리에게 
정보 디저트를 제공하죠.

00:05:38.260 --> 00:05:40.260
이런 종류의 알고리즘 필터,

00:05:40.260 --> 00:05:42.260
개인화 필터의 문제점은

00:05:42.260 --> 00:05:44.260
여러분이 가장 처음에 무엇을 클릭하는지

00:05:44.260 --> 00:05:48.260
주로 탐색을 하기 때문에

00:05:48.260 --> 00:05:52.260
균형을 깰 수가 있다는 것입니다.

00:05:52.260 --> 00:05:55.260
균형잡힌 정보 식단 대신에,

00:05:55.260 --> 00:05:57.260
정보 정크 푸드로

00:05:57.260 --> 00:05:59.260
둘러싸일 수 있습니다.

00:05:59.260 --> 00:06:01.260
이것은 실제로 인터넷에 대해

00:06:01.260 --> 00:06:04.260
우리가 원하는 것이 아닌 기사를 
볼 수도 있다는 것을 시사합니다.

00:06:04.260 --> 00:06:06.260
정보 배급 사회에서

00:06:06.260 --> 00:06:08.260
이것은 어떻게 시작되는 
이야기인가 하는 것입니다.

00:06:08.260 --> 00:06:10.260
방송 사회에서는

00:06:10.260 --> 00:06:12.260
정보관리자, 편집자가 있어서

00:06:12.260 --> 00:06:15.260
정보의 흐름을 제어했습니다.

00:06:15.260 --> 00:06:18.260
인터넷이 등장하자 모든 것을 쓸어버렸고,

00:06:18.260 --> 00:06:20.260
우리 모두가 함께 연결되도록 했습니다.

00:06:20.260 --> 00:06:22.260
그것은 정말 대단했습니다.

00:06:22.260 --> 00:06:25.260
하지만 그것은 실제로 
바로 지금 벌어지는 일이 아닙니다.

00:06:26.260 --> 00:06:29.260
우리가 보고 있는 것은 오히려 
인간 정보 관리자에서

00:06:29.260 --> 00:06:31.260
알고리즘 정보 관리자로

00:06:31.260 --> 00:06:34.260
주도권이 넘어가는 것입니다.

00:06:34.260 --> 00:06:37.260
문제는 그 알고리즘은 아직까지

00:06:37.260 --> 00:06:40.260
편집자들과 같이 일종의 내면적 윤리를

00:06:40.260 --> 00:06:43.260
가지고 있지 못하다는 것입니다.

00:06:43.260 --> 00:06:46.260
그래서 알고리즘이 우리를 위해
세상을 조율할 것이라면,

00:06:46.260 --> 00:06:49.260
또 알고리즘이 우리가 무엇을 보고
보지 않을지 결정할 것이라면,

00:06:49.260 --> 00:06:51.260
그것이 그저 관련성에

00:06:51.260 --> 00:06:54.260
맞춰진 것이 아님을 확실히 할 
필요가 있습니다.

00:06:54.260 --> 00:06:56.260
또한 거북하거나, 
도전적이거나, 또는 중요한

00:06:56.260 --> 00:06:59.260
다른 관점들을 우리에게 
보여주기도 한다는 것을

00:06:59.260 --> 00:07:01.260
확실히 할 필요가 있습니다.

00:07:01.260 --> 00:07:03.260
이것이 TED가 하는 일입니다.

00:07:03.260 --> 00:07:05.260
우린 사실 하나의 사회로서 전에 여기

00:07:05.260 --> 00:07:07.260
있어왔던 것입니다.

00:07:08.260 --> 00:07:11.260
그것은 1915년 신문들이 
그들의 시민적 책임에 대해

00:07:11.260 --> 00:07:14.260
많이 노력했던 것과는 다릅니다.

00:07:14.260 --> 00:07:16.260
그 당시 사람들은

00:07:16.260 --> 00:07:19.260
신문이 아주 중요한 일을 
하고 있음을 인지했습니다.

00:07:19.260 --> 00:07:21.260
사실, 시민들에게 괜찮은 정보가

00:07:21.260 --> 00:07:23.260
유입되지 못한다면,

00:07:23.260 --> 00:07:27.260
민주주의가 제 기능을
할 수가 없습니다.

00:07:28.260 --> 00:07:31.260
신문이 필터로서 작용했기 때문에
매우 중요했고,

00:07:31.260 --> 00:07:33.260
그리고 나서 기자의 윤리가
발전했습니다.

00:07:33.260 --> 00:07:35.260
완벽하지는 않지만,

00:07:35.260 --> 00:07:38.260
우리가 지난 세기를 지나오게 했습니다.

00:07:38.260 --> 00:07:40.260
그래서 현재,

00:07:40.260 --> 00:07:43.260
우리는 웹상에서 1915년으로 
돌아와 있는 것과 같습니다.

00:07:44.260 --> 00:07:47.260
그런 책임을 그들이 만들고 있는

00:07:47.260 --> 00:07:49.260
코드로 표현할

00:07:49.260 --> 00:07:51.260
새로운 정보 관리자가 필요합니다.

00:07:51.260 --> 00:07:54.260
페이스북과 구글에 있는 많은 분들이
여기 오신 것으로 압니다.

00:07:54.260 --> 00:07:56.260
래리와 세르게이는

00:07:56.260 --> 00:07:58.260
현재 상황으로 웹을 구축하는데 
일조한 사람들이고,

00:07:58.260 --> 00:08:00.260
그것에 대단히 감사를 드립니다.

00:08:00.260 --> 00:08:03.260
하지만 거기 있는 이 알고리즘들이

00:08:03.260 --> 00:08:06.260
공공의 삶의 의미와 
시민적 책임의 의미로

00:08:06.260 --> 00:08:09.260
만들어진 것인지 확실히 할 
필요가 있습니다.

00:08:09.260 --> 00:08:12.260
우리 필터들을 통해서 결정하는 규칙들이

00:08:12.260 --> 00:08:14.260
어떤 것인지 볼 수 있을만큼 
충분히 투명한지

00:08:14.260 --> 00:08:17.260
확실히 할 필요가 있습니다.

00:08:17.260 --> 00:08:19.260
여러분이 저희에게 
약간의 제어권을 주면

00:08:19.260 --> 00:08:21.260
무엇이 전달되고

00:08:21.260 --> 00:08:24.260
무엇이 그렇지 않을지 
결정할 수 있습니다.

00:08:24.260 --> 00:08:26.260
저는 우리 모두가

00:08:26.260 --> 00:08:28.260
꿈꾸는 것이 되는 인터넷이 정말

00:08:28.260 --> 00:08:30.260
필요하다고 생각하기 때문입니다.

00:08:30.260 --> 00:08:33.260
우리 모두를 연결하기 위해 
그것이 필요합니다.

00:08:33.260 --> 00:08:36.260
우리에게 새로운 아이디어와 
새로운 사람들,

00:08:36.260 --> 00:08:39.260
다른 시각들을 소개하기 위해
그것이 필요합니다.

00:08:40.260 --> 00:08:42.260
웹에서 우리 모두가 개개인으로 외따로 있다면

00:08:42.260 --> 00:08:45.260
그렇게 되지 않을 것입니다.

00:08:45.260 --> 00:08:47.260
감사합니다.

00:08:47.260 --> 00:08:58.260
(박수)

