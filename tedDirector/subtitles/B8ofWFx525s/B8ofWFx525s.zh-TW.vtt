WEBVTT
Kind: captions
Language: zh-TW

00:00:00.000 --> 00:00:07.000
譯者: Ana Choi
審譯者: Felix Leung

00:00:15.260 --> 00:00:17.540
有位新聞工作者問馬克·祖克柏

00:00:17.540 --> 00:00:20.260
一個關於動態消息的問题。

00:00:20.260 --> 00:00:22.260
那新聞工作者問他：

00:00:22.260 --> 00:00:24.260
「動態消息究竟為什麼重要？」

00:00:24.260 --> 00:00:26.260
馬克·祖克柏說：

00:00:26.260 --> 00:00:28.260
「一隻松鼠正死在你的前院，

00:00:28.260 --> 00:00:31.260
對你來說可能會比

00:00:31.260 --> 00:00:34.260
非洲人正在死去更有關切性。」

00:00:34.260 --> 00:00:36.260
現在我想談論

00:00:36.260 --> 00:00:39.260
當網路基於「相關性」會是什麼樣子。

00:00:40.260 --> 00:00:42.260
我在缅因州

00:00:42.260 --> 00:00:44.260
極之郊區的環境長大，

00:00:44.260 --> 00:00:47.260
網路的意義對我極之不同。

00:00:47.260 --> 00:00:49.260
它意味著與世界的連接。

00:00:49.260 --> 00:00:52.260
它意味著與所有人的連接。

00:00:52.260 --> 00:00:55.260
當時我非常肯定它會有助民主

00:00:55.260 --> 00:00:58.260
及會有助我們的社會。

00:00:58.260 --> 00:01:00.260
但現在網路上

00:01:00.260 --> 00:01:02.260
资料流動的形色漸漸地、

00:01:02.260 --> 00:01:05.260
無形地在轉移。

00:01:05.260 --> 00:01:07.260
假若我們不留心注意，

00:01:07.260 --> 00:01:10.260
它可能會變成一個問题。

00:01:10.260 --> 00:01:13.260
我在我經常流覽的地方
首先注意到這個問題，

00:01:13.260 --> 00:01:15.260
這個地方當然是我的臉書頁面。

00:01:15.260 --> 00:01:18.260
可想而知，我對政治的態度是進步主義，

00:01:18.260 --> 00:01:21.220
但我亦會叛經離道地結識保守主義者。

00:01:21.220 --> 00:01:23.070
我喜歡知道他們在想什麼；

00:01:23.070 --> 00:01:24.910
我喜歡知道他們與什麼有聯繫；

00:01:24.910 --> 00:01:26.900
我喜歡能從中學到一些東西。

00:01:26.900 --> 00:01:29.260
因此有一天我很駕訝當我察覺到

00:01:29.260 --> 00:01:32.260
有關保守派主義的消息
從我臉書的動態消息消失。

00:01:33.260 --> 00:01:36.050
理由是因為

00:01:36.050 --> 00:01:39.260
臉書能看見我按過哪些連結，

00:01:39.260 --> 00:01:40.620
它注意到

00:01:40.620 --> 00:01:43.940
我其實按自由黨朋友的連結

00:01:43.940 --> 00:01:46.260
多過保守派朋友的連結。

00:01:46.260 --> 00:01:48.260
在未與我商量過的情況下，

00:01:48.260 --> 00:01:50.260
它便編走那些連結。

00:01:50.260 --> 00:01:53.260
那些消息全消失了。

00:01:54.260 --> 00:01:56.620
但不是淨只是臉書

00:01:56.620 --> 00:01:59.360
會做這種無形的、算法式的

00:01:59.360 --> 00:02:01.260
來編輯網路。

00:02:01.260 --> 00:02:03.260
Google（谷歌）也會這樣。

00:02:03.260 --> 00:02:06.260
若我在搜尋一樣東西，
你也在搜索一樣東西，

00:02:06.260 --> 00:02:08.260
即使是在現在、同一個時間，

00:02:08.260 --> 00:02:11.260
我們搜索的結果都會不同。

00:02:11.260 --> 00:02:14.890
一個工程師曾告訴過我，
即使你登出帳戶，

00:02:14.890 --> 00:02:17.430
仍然有 57 個訊號

00:02:17.430 --> 00:02:19.260
在被谷歌觀察著：

00:02:19.260 --> 00:02:22.260
從你所用的電腦類型

00:02:22.260 --> 00:02:24.260
到你所用的瀏覽器

00:02:24.260 --> 00:02:26.260
甚至是你的所在位置，

00:02:26.260 --> 00:02:29.260
它會以這些來量身訂造你的搜尋結果。

00:02:29.260 --> 00:02:31.260
試想一下：

00:02:31.260 --> 00:02:35.260
現在已經沒有標準的谷歌。

00:02:35.260 --> 00:02:38.260
而且，好笑的是，這很難察覺的。

00:02:38.260 --> 00:02:40.260
你根本無法看到你的搜尋結果

00:02:40.260 --> 00:02:42.260
會跟其他人的有所不同。

00:02:42.260 --> 00:02:44.260
所以在兩個星期前，

00:02:44.260 --> 00:02:47.260
我請一些朋友用谷歌搜尋「埃及」，

00:02:47.260 --> 00:02:50.260
並且寄給我他們搜尋結果的螢幕截圖。

00:02:50.260 --> 00:02:53.830
這張是我朋友史考特的截圖，

00:02:55.080 --> 00:02:57.860
而這張是我朋友丹尼爾的截圖。

00:02:57.860 --> 00:02:59.660
當你將它們並排比較，

00:02:59.660 --> 00:03:01.260
你根本不用細看那些連結

00:03:01.260 --> 00:03:03.680
就可以看得出這兩頁是不一樣。

00:03:03.680 --> 00:03:05.260
但當你細看這些連結，

00:03:05.260 --> 00:03:08.260
這確實是蠻驚人的。

00:03:09.260 --> 00:03:12.890
在丹尼爾的谷歌搜尋結果第一頁裡，

00:03:12.890 --> 00:03:14.740
完全沒有關於埃及抗議的連結。

00:03:14.740 --> 00:03:16.260
在史考特的搜尋結果就有很多。

00:03:16.260 --> 00:03:18.260
但在那陣子卻是當日的大新聞。

00:03:18.260 --> 00:03:21.260
這就是搜尋結果越來越不同的例子。

00:03:21.260 --> 00:03:24.260
不只是谷歌及臉書。

00:03:24.260 --> 00:03:26.820
這趨勢在網路正漸散播。

00:03:26.820 --> 00:03:29.980
現有很多機構都實施個人化。

00:03:29.980 --> 00:03:33.170
雅虎新聞，網路上最大型的新聞網站，

00:03:33.170 --> 00:03:36.770
現在已經個人化，
即是不同人會看到不同的東西。

00:03:36.770 --> 00:03:39.540
哈芬登郵報、華盛頓郵報、紐約時報等等

00:03:39.540 --> 00:03:43.010
都正在用不同方式盤弄個人化。

00:03:43.010 --> 00:03:45.260
這種趨勢正在快速地推我們

00:03:45.260 --> 00:03:47.260
前往一個新世界，

00:03:47.260 --> 00:03:51.260
一個網路應為我們想看的世界，

00:03:51.260 --> 00:03:54.260
但未必是一個我們需要看到的世界。

00:03:54.260 --> 00:03:57.150
正如艾立克·史密特所說：

00:03:57.150 --> 00:04:00.260
「現在很難要人們觀看或消化一些

00:04:00.260 --> 00:04:02.260
一點兒也沒有替他們

00:04:02.260 --> 00:04:05.260
量身訂造的東西。」

00:04:05.260 --> 00:04:07.260
我認為這是一個問題，

00:04:07.260 --> 00:04:10.970
而且我想，如果將
全部的過濾器放在一起，

00:04:10.970 --> 00:04:12.650
用盡所有算法，

00:04:12.650 --> 00:04:15.260
得到的是一個我稱為
「過濾氣泡」的東西。

00:04:16.260 --> 00:04:19.260
而你的過濾氣泡便是你個人

00:04:19.260 --> 00:04:21.260
在網上存在的

00:04:21.260 --> 00:04:23.260
獨特資料宇宙。

00:04:23.260 --> 00:04:26.260
你個人過濾氣泡的內容

00:04:26.260 --> 00:04:29.260
基於你是誰和你的行為。

00:04:29.260 --> 00:04:33.260
但問題是，氣泡的內容不是你可選擇。

00:04:33.260 --> 00:04:35.260
更重要的是，

00:04:35.260 --> 00:04:39.110
你完全看不到什麼被刪除。

00:04:39.110 --> 00:04:40.790
過濾氣泡的其中一個問題

00:04:40.790 --> 00:04:43.260
被 Netflix 的研究員發現。

00:04:43.260 --> 00:04:46.260
當在察看 Netflix 的電影列表時，
他們發覺一樣有趣的現象，

00:04:46.260 --> 00:04:48.260
可能我們很多人亦有察覺到，

00:04:48.260 --> 00:04:50.260
也就是，有些電影

00:04:50.260 --> 00:04:53.260
馬上就會被訂去看。

00:04:53.260 --> 00:04:56.260
才剛入上架，就馬上被訂去看了。

00:04:56.260 --> 00:04:58.260
例如《鋼鐵人》很快就被看完，

00:04:58.260 --> 00:05:00.260
但《等待超人》

00:05:00.260 --> 00:05:02.260
便真要等很久。

00:05:02.260 --> 00:05:04.260
他們發現

00:05:04.260 --> 00:05:06.260
在我們 Netflix 的列表裡，

00:05:06.260 --> 00:05:09.260
正在發生一個很巨型的鬥爭：

00:05:09.260 --> 00:05:12.260
我們未來的自我志向

00:05:12.260 --> 00:05:15.260
和現在較衝動的自我之間在拔河。

00:05:15.260 --> 00:05:17.260
我們全都想成為那個

00:05:17.260 --> 00:05:19.260
曾經看過《羅生門》的人，

00:05:19.260 --> 00:05:21.260
但現在

00:05:21.260 --> 00:05:24.260
我們想看第四遍的《王牌威龍》。

00:05:24.260 --> 00:05:27.260
（笑聲）

00:05:27.260 --> 00:05:30.050
所以其實最好的編輯
是每樣都給我們一些。

00:05:30.050 --> 00:05:31.720
它會給我們一點小賈斯汀，

00:05:31.720 --> 00:05:33.260
亦會給我們一些阿富汗。

00:05:33.260 --> 00:05:35.260
它會給我們一些像蔬菜一樣的重要資訊，

00:05:35.260 --> 00:05:38.260
亦會給我們一些像甜點一樣的資訊。

00:05:39.130 --> 00:05:41.680
所以對這類算法式過濾和

00:05:41.680 --> 00:05:43.140
這些個人過濾的挑戰，

00:05:43.140 --> 00:05:45.160
是因為，它們主要是看

00:05:45.160 --> 00:05:47.800
你首先按的是什麼連結，

00:05:48.910 --> 00:05:52.260
這個方法會有阻平衡。

00:05:52.260 --> 00:05:55.260
你不但沒得到均衡的資訊菜單，

00:05:55.260 --> 00:05:57.260
你可能會得到

00:05:57.260 --> 00:05:59.260
很多垃圾資訊。

00:06:00.280 --> 00:06:02.020
這個想法是在說

00:06:02.020 --> 00:06:05.060
可能我們對網路的印象是不正確。

00:06:05.060 --> 00:06:06.260
在這個廣播社會，

00:06:06.260 --> 00:06:08.260
根據流傳的說法，

00:06:08.260 --> 00:06:10.260
在這個廣播社會，

00:06:10.260 --> 00:06:12.260
有一些看門人，叫編輯者，

00:06:12.260 --> 00:06:15.260
他們控制資料的流通。

00:06:15.260 --> 00:06:18.260
隨後登場便是網際網路，
它掃走這些看門人，

00:06:18.260 --> 00:06:20.970
讓我們全部人可無阻地聯繫在一起，

00:06:20.970 --> 00:06:22.550
這真是棒啊。

00:06:22.550 --> 00:06:25.260
但實在不是這樣。

00:06:26.260 --> 00:06:29.260
我們看到的是像傳火炬，

00:06:29.260 --> 00:06:31.260
由人類看門人

00:06:31.260 --> 00:06:34.260
到算法看門人。

00:06:34.960 --> 00:06:37.260
但現在這種算法程式

00:06:37.260 --> 00:06:40.260
還未有編輯人

00:06:40.260 --> 00:06:43.260
所擁有的嵌入概念。

00:06:43.260 --> 00:06:46.260
所以若我們讓算法
用它的方式來看世界，

00:06:46.260 --> 00:06:49.810
若讓它來決定我們
可看什麼、不可看什麼，

00:06:49.810 --> 00:06:51.690
那我們便要確定

00:06:51.690 --> 00:06:54.260
它的決定不只是基於關切性。

00:06:54.260 --> 00:06:56.260
我們要確定它亦會給我們看一些

00:06:56.260 --> 00:06:59.810
我們看了未必舒服，
但有重要性及有挑戰性的東西，

00:06:59.810 --> 00:07:01.260
正如 TED 大會那樣

00:07:01.260 --> 00:07:03.260
會展示其他觀點。

00:07:03.260 --> 00:07:05.260
其實像現在這種過濾

00:07:05.260 --> 00:07:07.260
在以前的社會也發生過。

00:07:08.260 --> 00:07:12.600
在 1915 年，
那時的報章對它們的民事責任

00:07:12.600 --> 00:07:14.260
不太在意。

00:07:14.260 --> 00:07:16.260
之後人們發覺到

00:07:16.260 --> 00:07:19.140
報章實在很重要。

00:07:19.140 --> 00:07:20.180
因為事實上，

00:07:20.180 --> 00:07:23.260
一個正常運作的民主社會是不存在的，

00:07:23.260 --> 00:07:27.260
除非人民能獲得有效的資訊流通。

00:07:28.260 --> 00:07:31.260
所以報章對事有評論，
因為它們扮演過濾網，

00:07:31.260 --> 00:07:33.260
也因此才有新聞道德的構成。

00:07:33.260 --> 00:07:35.260
雖然不是完美，

00:07:35.260 --> 00:07:38.260
但這種方式帶我們走過上一個世紀。

00:07:38.260 --> 00:07:40.260
現在，

00:07:40.260 --> 00:07:43.260
在網上我們又像回到 1915 年。

00:07:44.260 --> 00:07:47.260
我們需要新的看門人

00:07:47.260 --> 00:07:49.260
將道德責任

00:07:49.260 --> 00:07:51.260
輸入它們算法的程式裡。

00:07:51.260 --> 00:07:55.020
我知道在座很多人替臉書及谷歌工作，

00:07:55.020 --> 00:07:56.260
像賴利和塞吉，

00:07:56.260 --> 00:07:58.260
很多人參與建立現今的網際網路，

00:07:58.260 --> 00:08:00.260
我對此很感謝。

00:08:00.260 --> 00:08:03.260
但我們真的需要你們確保

00:08:03.260 --> 00:08:06.260
這些算法的程式裡

00:08:06.260 --> 00:08:09.260
要有公眾生活和民事責任感。

00:08:10.230 --> 00:08:13.090
我們需要你們確保
它有一定的透明度，

00:08:13.090 --> 00:08:14.790
讓我們能知道是用什麼準則

00:08:14.790 --> 00:08:17.260
來決定什麼可通過過濾網。

00:08:17.260 --> 00:08:19.770
而且我們需要你們
給予一些控制力，

00:08:19.770 --> 00:08:21.260
讓我們可以選擇

00:08:21.260 --> 00:08:24.260
什麼能通過和不通過。

00:08:24.260 --> 00:08:26.260
因為我認為

00:08:26.260 --> 00:08:28.260
我們真的需要網路

00:08:28.260 --> 00:08:30.950
成為一個我們夢寐以求的平臺。

00:08:30.950 --> 00:08:33.260
我們需要它連結所有人。

00:08:33.260 --> 00:08:36.260
我們需要它給我們介紹新的想法、

00:08:36.260 --> 00:08:39.260
新的人和不同觀點。

00:08:40.260 --> 00:08:42.260
而它是不可能辦到這些，

00:08:42.260 --> 00:08:46.290
如果它將我們孤立在
唯一自我旳網路裡就絕不可能。

00:08:46.290 --> 00:08:47.360
謝謝。

00:08:47.360 --> 00:08:50.330
（鼓掌）

