WEBVTT
Kind: captions
Language: lt

00:00:00.000 --> 00:00:07.000
Translator: Monika Ciurlionyte
Reviewer: Laura Bojarskaitė

00:00:15.260 --> 00:00:17.260
Mark Zuckerberg,

00:00:17.260 --> 00:00:20.260
žurnalistas jo klausinėjo apie naujienų srautą.

00:00:20.260 --> 00:00:22.260
Ir žurnalistas jo paklausė,

00:00:22.260 --> 00:00:24.260
"Kodėl tai taip svarbu?"

00:00:24.260 --> 00:00:26.260
Ir Zuckerberg atsakė,

00:00:26.260 --> 00:00:28.260
"Voverė, dvesianti tavo kieme

00:00:28.260 --> 00:00:31.260
šią akimirką tau ko gero aktualesnė,

00:00:31.260 --> 00:00:34.260
nei žmonės, mirštantys Afrikoje."

00:00:34.260 --> 00:00:36.260
Taigi aš norėčiau pakalbėti apie tai,

00:00:36.260 --> 00:00:39.260
kaip atrodytų žiniatinklis paremtas tokia aktualumo idėja.

00:00:40.260 --> 00:00:42.260
Kai aš augau

00:00:42.260 --> 00:00:44.260
atitolusoje kaimo vietovėje Maine,

00:00:44.260 --> 00:00:47.260
internetas man reiškė kažką visai kitko.

00:00:47.260 --> 00:00:49.260
Jis reiškė ryšį su pasauliu.

00:00:49.260 --> 00:00:52.260
Jis reiškė kažką, kas mus visus sujungia.

00:00:52.260 --> 00:00:55.260
Ir aš buvau įsitikinęs, kad tai bus labai naudinga demokratijai

00:00:55.260 --> 00:00:58.260
ir mūsų visuomenei.

00:00:58.260 --> 00:01:00.260
Bet yra vienas pasikeitimas

00:01:00.260 --> 00:01:02.260
informacijos sklidime internetu,

00:01:02.260 --> 00:01:05.260
ir jis yra nematomas.

00:01:05.260 --> 00:01:07.260
Ir jei mes į jį nekreipsime dėmesio,

00:01:07.260 --> 00:01:10.260
tai gali tapti tikra problema.

00:01:10.260 --> 00:01:13.260
Pirmą kartą aš tai pastebėjau ten, kur praleidžiu labai daug laiko -

00:01:13.260 --> 00:01:15.260
savo Facebook puslapyje.

00:01:15.260 --> 00:01:18.260
Politiškai aš esu progresyvių pažiūrų - nieko čia keisto -

00:01:18.260 --> 00:01:20.260
bet visada specialiai stengiuosi susipažinti su konservatoriais.

00:01:20.260 --> 00:01:22.260
Man patinka klausytis, apie ką jie galvoja;

00:01:22.260 --> 00:01:24.260
mėgstu stebėti, kokias nuorodas jie siunčia;

00:01:24.260 --> 00:01:26.260
man patinka šį bei tą išmokti.

00:01:26.260 --> 00:01:29.260
Todėl buvau labai nustebęs, kai vieną dieną pastebėjau,

00:01:29.260 --> 00:01:32.260
kad konservatoriai dingo iš mano Facebook naujienų.

00:01:33.260 --> 00:01:35.260
Paaiškėjo, kad

00:01:35.260 --> 00:01:39.260
Facebook stebėjo, kurias nuorodas aš spausdavau,

00:01:39.260 --> 00:01:41.260
ir matė, kad iš tiesų

00:01:41.260 --> 00:01:43.260
aš dažniau spausdavau savo liberaliųjų draugų nuorodas,

00:01:43.260 --> 00:01:46.260
o ne draugų konservatorių.

00:01:46.260 --> 00:01:48.260
Ir su manimi nepasitarę,

00:01:48.260 --> 00:01:50.260
jie išmetė nuorodas lauk.

00:01:50.260 --> 00:01:53.260
Jos dingo.

00:01:54.260 --> 00:01:56.260
Taigi Facebook nėra vienintelė vieta,

00:01:56.260 --> 00:01:58.260
kur vyksta toks nematomas, algoritminis

00:01:58.260 --> 00:02:01.260
tinklo redagavimas.

00:02:01.260 --> 00:02:03.260
Google tai irgi daro.

00:02:03.260 --> 00:02:06.260
Jei aš kažko ieškosiu, ir tu kažko ieškosi,

00:02:06.260 --> 00:02:08.260
net ir dabar, visiškai tuo pačiu metu,

00:02:08.260 --> 00:02:11.260
mes ko gero gausim labai skirtingus rezultatus.

00:02:11.260 --> 00:02:14.260
Net jei esi išsiregistravęs, kaip vienas inžinierius man sakė,

00:02:14.260 --> 00:02:16.260
yra 57 signalai,

00:02:16.260 --> 00:02:19.260
kuriuos Google vertina -

00:02:19.260 --> 00:02:22.260
nuo to, kokį kompiuterį tu naudoji,

00:02:22.260 --> 00:02:24.260
iki to, kokia naršykle naudojiesi,

00:02:24.260 --> 00:02:26.260
kur esi geografiškai -

00:02:26.260 --> 00:02:29.260
ši informacija naudojama asmeniškai adaptuoti tavo užklausos rezultatus.

00:02:29.260 --> 00:02:31.260
Pamastykite apie tai minutėlę:

00:02:31.260 --> 00:02:35.260
standartiškas Google nebeegzistuoja.

00:02:35.260 --> 00:02:38.260
Ir žinot, keisčiausia tai, kad tai labai sunku pastebėti.

00:02:38.260 --> 00:02:40.260
Jūs nematote, kiek jūsų paieškos rezultatai skiriasi

00:02:40.260 --> 00:02:42.260
nuo bet kurio kito žmogaus.

00:02:42.260 --> 00:02:44.260
Bet prieš porą savaičių

00:02:44.260 --> 00:02:47.260
aš paprašiau savo draugų "pagooglinti" "Egiptas"

00:02:47.260 --> 00:02:50.260
ir atsiųsti man gautų rezultatų ekrano nuotraukas.

00:02:50.260 --> 00:02:53.260
Štai mano draugo Scott ekrano nuotrauka.

00:02:54.260 --> 00:02:57.260
Ir štai mano draugo Daniel ekrano nuotrauka.

00:02:57.260 --> 00:02:59.260
Kai sudedi abi vieną šalia kitos,

00:02:59.260 --> 00:03:01.260
net nereikia skaityti nuorodų,

00:03:01.260 --> 00:03:03.260
kad pamatytum, kiek daug skiriasi šie du puslapiai.

00:03:03.260 --> 00:03:05.260
Bet kai vis dėlto paskaitai nuorodas,

00:03:05.260 --> 00:03:08.260
tai yra tikrai gana neįtikėtina.

00:03:09.260 --> 00:03:12.260
Daniel pirmame Google rezultatų puslapyje negavo jokių nuorodų

00:03:12.260 --> 00:03:14.260
apie Egipte vykstančius protestus.

00:03:14.260 --> 00:03:16.260
Scott rezultatuose buvo daugybė informacijos apie tai.

00:03:16.260 --> 00:03:18.260
O ši istorija tada buvo tikrai populiari.

00:03:18.260 --> 00:03:21.260
Štai kokie skirtingi tampa paieškos rezultatai.

00:03:21.260 --> 00:03:24.260
Ir tai ne vien tik Google ir Facebook.

00:03:24.260 --> 00:03:26.260
Tai vyksta visame žiniatinklyje.

00:03:26.260 --> 00:03:29.260
Yra spiečius kompanijų, kurios taiko tokią personalizaciją.

00:03:29.260 --> 00:03:32.260
Yahoo News, didžiausias naujienų puslapis internete,

00:03:32.260 --> 00:03:35.260
dabar taip pat yra personalizuotas -- skirtingi žmonės gauna skirtingas naujienas.

00:03:36.260 --> 00:03:39.260
Huffington Post, Washington Post, New York Times --

00:03:39.260 --> 00:03:42.260
visi vienaip ar kitaip koketuoja su personalizacijos idėja.

00:03:42.260 --> 00:03:45.260
Ir tai mus labai greitai veda

00:03:45.260 --> 00:03:47.260
link pasaulio, kuriame

00:03:47.260 --> 00:03:51.260
internetas rodo mums tik tai, ką jis galvoja mes norime matyti,

00:03:51.260 --> 00:03:54.260
bet nebūtinai tai, ką mes turėtume pamatyti.

00:03:54.260 --> 00:03:57.260
Kaip Eric Schmidt pasakė,

00:03:57.260 --> 00:04:00.260
"Žmonėms bus labai sunku kažką žiūrėti ir vartoti

00:04:00.260 --> 00:04:02.260
kas kažkuria prasme

00:04:02.260 --> 00:04:05.260
nebuvo pritaikytas būtent jiems."

00:04:05.260 --> 00:04:07.260
Aš tikrai manau, kad tai yra problema.

00:04:07.260 --> 00:04:10.260
Ir aš manau, kad jeigu paimtume visus šiuos filtrus,

00:04:10.260 --> 00:04:12.260
visus algoritmus,

00:04:12.260 --> 00:04:15.260
susidurtumėte su filtro burbulu, kaip aš tai vadinu.

00:04:16.260 --> 00:04:19.260
Ir jūsų filtro burbulas yra asmeninė,

00:04:19.260 --> 00:04:21.260
unikali informacijos visata,

00:04:21.260 --> 00:04:23.260
kurioje gyvenate, kai būnate internete.

00:04:23.260 --> 00:04:26.260
Ir kas yra jūsų filtro burbule

00:04:26.260 --> 00:04:29.260
priklauso nuo to, kas jūs esate ir priklauso nuo to, ką jus veikiate.

00:04:29.260 --> 00:04:33.260
Bet dalykas yra tas, kad jūs negalite nuspręsti, kas į jį patenka.

00:04:33.260 --> 00:04:35.260
Ir svarbiausia,

00:04:35.260 --> 00:04:38.260
jūs iš tiesų net nematote, kas yra išredaguota.

00:04:38.260 --> 00:04:40.260
Taigi vieną iš šio filtro burbulo problemų

00:04:40.260 --> 00:04:43.260
atrado keli Netflix mokslininkai.

00:04:43.260 --> 00:04:46.260
Jie stebėjo Netflix filmų eiles ir pastebėjo kai ką šiek tiek juokingo,

00:04:46.260 --> 00:04:48.260
ką dauguma mūsų turbūt irgi pastebėjo,

00:04:48.260 --> 00:04:50.260
o tai yra, kad kai kurie filmai

00:04:50.260 --> 00:04:53.260
tiesiog atsiranda ir dingsta iš mūsų namų eilės.

00:04:53.260 --> 00:04:56.260
Jie įeina į eilę ir joje neužsibūna.

00:04:56.260 --> 00:04:58.260
Taigi "Geležinis žmogus" peržiūrėtas,

00:04:58.260 --> 00:05:00.260
o "Belaukiant Supermeno" eilės

00:05:00.260 --> 00:05:02.260
gali tekti laukti gana ilgai.

00:05:02.260 --> 00:05:04.260
Ką Netflix mokslininkai atrado

00:05:04.260 --> 00:05:06.260
buvo tai, kad Netflix filmų eilėse

00:05:06.260 --> 00:05:09.260
vyksta epinė kova

00:05:09.260 --> 00:05:12.260
tarp mūsų siekiamo ateities savęs

00:05:12.260 --> 00:05:15.260
ir mūsų labiau impulsyvaus dabartinio savęs.

00:05:15.260 --> 00:05:17.260
Žinot, mes visi norime tapti tais,

00:05:17.260 --> 00:05:19.260
kurie žiūri "Rasiomonas",

00:05:19.260 --> 00:05:21.260
bet dabar

00:05:21.260 --> 00:05:24.260
mes norime ketvirtą kartą peržiūrėti "Eisas Ventura".

00:05:24.260 --> 00:05:27.260
(Juokas)

00:05:27.260 --> 00:05:29.260
Taigi geriausias redagavimas leidžia mums pabūti abiem savimis.

00:05:29.260 --> 00:05:31.260
Tai mums suteikia truputį informacijos apie Justin Bieber

00:05:31.260 --> 00:05:33.260
ir truputį Afganistano naujienų.

00:05:33.260 --> 00:05:35.260
Tai mums suteikia informacijos "daržovių"

00:05:35.260 --> 00:05:38.260
ir informacijos "desertui".

00:05:38.260 --> 00:05:40.260
Ir didžiausias sunkumas su šiais algoritminiais filtrais,

00:05:40.260 --> 00:05:42.260
šiais personalizuotais filtrais,

00:05:42.260 --> 00:05:44.260
yra susijęs su tuo, kad filtrai daugiausiai

00:05:44.260 --> 00:05:48.260
kreipia dėmesį į tai, ką jūs paspaudžiate primiausia,

00:05:48.260 --> 00:05:52.260
o tai gali tą filtrą išbalansuoti.

00:05:52.260 --> 00:05:55.260
Ir tuomet vietoje subalansuotos informacijos dietos

00:05:55.260 --> 00:05:57.260
jums gali tekti

00:05:57.260 --> 00:05:59.260
greitas, nesveikas informacijos maistas.

00:05:59.260 --> 00:06:01.260
Ką tai sako,

00:06:01.260 --> 00:06:04.260
yra tai, kad išties mes suprantame internetą neteisingai.

00:06:04.260 --> 00:06:06.260
Transliacijų visuomenėje --

00:06:06.260 --> 00:06:08.260
štai kokia išties etologinio mito istorija --

00:06:08.260 --> 00:06:10.260
transliacijų visuomenėje

00:06:10.260 --> 00:06:12.260
buvo žmonės atsakingi už priėjimą prie informacijos, redaktoriai

00:06:12.260 --> 00:06:15.260
ir jie kontroliavo informacijos srautus.

00:06:15.260 --> 00:06:18.260
Ir tada atsirado internetas ir nušlavė juos nuo kelio,

00:06:18.260 --> 00:06:20.260
o tai leido mums susijungti,

00:06:20.260 --> 00:06:22.260
kas buvo labai jėga.

00:06:22.260 --> 00:06:25.260
Tačiau tai nėra, kas išties dabar vyksta.

00:06:26.260 --> 00:06:29.260
Ką mes dabar matome yra daugiau deglo perdavinėjimas

00:06:29.260 --> 00:06:31.260
iš žmonių, atsakingų už priėjimą prie informacijos

00:06:31.260 --> 00:06:34.260
algoritmams.

00:06:34.260 --> 00:06:37.260
Ir esmė yra ta, kad algoritmai

00:06:37.260 --> 00:06:40.260
dar neturi įtvirtintos etikos,

00:06:40.260 --> 00:06:43.260
kurią turi redaktoriai.

00:06:43.260 --> 00:06:46.260
Taigi, jeigu algoritmai kuruos mums pasaulį,

00:06:46.260 --> 00:06:49.260
jeigu jie spręs, ką mes galime matyti ir ko ne,

00:06:49.260 --> 00:06:51.260
tuomet mums reikia užsitikrinti,

00:06:51.260 --> 00:06:54.260
kad jų pagrindas nėra aktualumas.

00:06:54.260 --> 00:06:56.260
Mums reikia užtikrinti, kad jie taip pat mums parodys dalykus,

00:06:56.260 --> 00:06:59.260
kurie yra nesmagūs, sudėtingi arba svarbūs --

00:06:59.260 --> 00:07:01.260
tai būtent ką daro TED --

00:07:01.260 --> 00:07:03.260
rodo kitus požiūrius.

00:07:03.260 --> 00:07:05.260
O svarbiausia, kad mes tokioje situacijoje jau buvome

00:07:05.260 --> 00:07:07.260
patekę kaip visuomenė.

00:07:08.260 --> 00:07:11.260
1915 laikraščiai tikrai neliejo daug prakaito

00:07:11.260 --> 00:07:14.260
dėl savo pilietinės atsakomybės.

00:07:14.260 --> 00:07:16.260
Tuomet žmonės pastebėjo,

00:07:16.260 --> 00:07:19.260
kad jie darė kažką labai svarbaus.

00:07:19.260 --> 00:07:21.260
Tai, faktiškai, yra negalėjimas

00:07:21.260 --> 00:07:23.260
turėti funkcionuojančią demokratiją,

00:07:23.260 --> 00:07:27.260
jeigu piliečiai negauna tinkamo informacijos srauto.

00:07:28.260 --> 00:07:31.260
Žmonės suprato, kad laikraščiai buvo kritiškai svarbūs, nes jie

00:07:31.260 --> 00:07:33.260
buvo kaip filtrai, o tada susiformavo žurnalistinė etika.

00:07:33.260 --> 00:07:35.260
Tai nebuvo puiku,

00:07:35.260 --> 00:07:38.260
bet mes taip pragyvenom paskutinį amžių.

00:07:38.260 --> 00:07:40.260
Ir taip dabar

00:07:40.260 --> 00:07:43.260
mes lyg ir grįžom į 1915 metus tinkle.

00:07:44.260 --> 00:07:47.260
Ir mums reikia naujų žmonių, nuo kurių priklauso priėjimas prie informacijos,

00:07:47.260 --> 00:07:49.260
kurie koduotų tą atsakomybę

00:07:49.260 --> 00:07:51.260
į kodą, kurį jie dabar kuria.

00:07:51.260 --> 00:07:54.260
Aš žinau, kad čia yra daug žmonių iš Facebook ir iš Google --

00:07:54.260 --> 00:07:56.260
Larry ir Sergey --

00:07:56.260 --> 00:07:58.260
žmonės, kurie padėjo sukurti žiniatinklį tokį, koks jis dabar yra,

00:07:58.260 --> 00:08:00.260
ir aš esu dėl to dėkingas.

00:08:00.260 --> 00:08:03.260
Bet mums reikia, kad jūs užtikrintumėte,

00:08:03.260 --> 00:08:06.260
kad šie algoritmai turėtų įkoduotą

00:08:06.260 --> 00:08:09.260
viešo gyvenimo jausmą ir pilietinės atsakomybės jausmą.

00:08:09.260 --> 00:08:12.260
Mums reikia, kad jūs užtikrintumėt, kad jie yra pakankamai skaidrūs,

00:08:12.260 --> 00:08:14.260
kad mes galėtume matyti kokios yra taisyklės,

00:08:14.260 --> 00:08:17.260
kurios nustato, kas pereina pro mūsų filtrus.

00:08:17.260 --> 00:08:19.260
Ir mums reikia, kad duotumėte mums šiek tiek kontrolės,

00:08:19.260 --> 00:08:21.260
kad galėtume nuspręsti,

00:08:21.260 --> 00:08:24.260
kas praeina pro filtrą ir kas ne.

00:08:24.260 --> 00:08:26.260
Nes aš manau,

00:08:26.260 --> 00:08:28.260
kad mums reikia interneto būtent tokio,

00:08:28.260 --> 00:08:30.260
apie kokį ir svajojome.

00:08:30.260 --> 00:08:33.260
Mums reikia kad jis mus sujungtų.

00:08:33.260 --> 00:08:36.260
Mums reikia, kad jis mums pristatytų naujų idėjų

00:08:36.260 --> 00:08:39.260
ir supažindintų su naujais žmonėmis ir naujomis perspektyvomis.

00:08:40.260 --> 00:08:42.260
Ir jis to neatliks,

00:08:42.260 --> 00:08:45.260
jeigu mes liksime izoliuoti vieno žmogaus žiniatinklyje.

00:08:45.260 --> 00:08:47.260
Ačiū.

00:08:47.260 --> 00:08:58.260
(Plojimai)

