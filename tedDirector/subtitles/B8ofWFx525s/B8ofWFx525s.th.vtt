WEBVTT
Kind: captions
Language: th

00:00:00.000 --> 00:00:07.000
Translator: Unnawut Leepaisalsuwanna
Reviewer: Peeraya Maetasatidsuk

00:00:15.260 --> 00:00:17.260
มาร์ค ซัคเกอร์เบิร์ก

00:00:17.260 --> 00:00:20.260
มีผู้สื่อข่าวคนหนึ่งถามเขาเกี่ยวกับระบบ news feed

00:00:20.260 --> 00:00:22.260
เขาถูกถามว่า

00:00:22.260 --> 00:00:24.260
"ทำไมมันสำคัญนักล่ะ?"

00:00:24.260 --> 00:00:26.260
ซัคเกอร์เบิร์กตอบว่า

00:00:26.260 --> 00:00:28.260
"กระรอกที่ตายอยู่หน้าบ้านของคุณ

00:00:28.260 --> 00:00:31.260
อาจจะน่าสนใจสำหรับคุณในตอนนี้

00:00:31.260 --> 00:00:34.260
มากกว่าคนที่กำลังตายในแอฟริกา"

00:00:34.260 --> 00:00:36.260
ผมเลยอยากจะพูดเกี่ยวกับ

00:00:36.260 --> 00:00:39.260
ว่าอินเทอร์เน็ตที่มีพื้นฐานบนความคิดแบบนั้นจะเป็นอย่างไร

00:00:40.260 --> 00:00:42.260
เมื่อตอนที่ผมเติบโตขึ้น

00:00:42.260 --> 00:00:44.260
ในชนบทของรัฐเมน

00:00:44.260 --> 00:00:47.260
ความหมายของอินเทอร์เน็ตแตกต่างจากตอนนี้มาก

00:00:47.260 --> 00:00:49.260
มันหมายถึง การเชื่อมโยงโลกเข้าด้วยกัน

00:00:49.260 --> 00:00:52.260
มันคือสิ่งที่เชื่อมเราทุกคนบนโลกเข้าด้วยกัน

00:00:52.260 --> 00:00:55.260
และผมเชื่อว่ามันจะดีต่อประชาธิปไตย

00:00:55.260 --> 00:00:58.260
และดีต่อสังคมของเรา

00:00:58.260 --> 00:01:00.260
แต่แล้วก็มีการเปลี่ยนแปลง

00:01:00.260 --> 00:01:02.260
กับวิธีที่ข้อมูลถูกแพร่กระจาย

00:01:02.260 --> 00:01:05.260
ซึ่งเรามองไม่เห็น

00:01:05.260 --> 00:01:07.260
และถ้าเราไม่สนใจมันเลย

00:01:07.260 --> 00:01:10.260
มันอาจเป็นปัญหาใหญ่ได้

00:01:10.260 --> 00:01:13.260
ผมรู้สึกได้ครั้งแรก จากที่ผมใช้เวลาส่วนใหญ่

00:01:13.260 --> 00:01:15.260
บนหน้าเฟสบุ๊คของผม

00:01:15.260 --> 00:01:18.260
ผมเป็นเสรีนิยมนะ ในทางการเมือง

00:01:18.260 --> 00:01:20.260
แต่ผมก็ชอบพูดคุยกับพวกอนุรักษ์นิยม

00:01:20.260 --> 00:01:22.260
ผมชอบฟังว่าเขาคิดเห็นอย่างไร

00:01:22.260 --> 00:01:24.260
ผมชอบดูว่าเขาแชร์อะไรกันบ้าง

00:01:24.260 --> 00:01:26.260
ผมชอบเรียนรู้อะไรใหม่ๆ

00:01:26.260 --> 00:01:29.260
แล้วผมก็ตกใจ เพราะวันหนึ่ง

00:01:29.260 --> 00:01:32.260
นักอนุรักษ์นิยมหายไปจากเฟสบุ๊คของผมหมดเลย

00:01:33.260 --> 00:01:35.260
ผมพบว่า

00:01:35.260 --> 00:01:39.260
เฟสบุ๊คกำลังศึกษาว่าผมคลิกลิงค์อะไรบ้าง

00:01:39.260 --> 00:01:41.260
และมันเห็นว่า

00:01:41.260 --> 00:01:43.260
ผมคลิกลิงค์ของเพื่อนเสรีนิยม

00:01:43.260 --> 00:01:46.260
มากกว่าเพื่อนอนุรักษ์นิยมของผม

00:01:46.260 --> 00:01:48.260
และโดยที่ไม่ปรึกษาผมก่อน

00:01:48.260 --> 00:01:50.260
เฟสบุ๊คก็กรองทุกอย่างออก

00:01:50.260 --> 00:01:53.260
มันหายไปหมดเลย

00:01:54.260 --> 00:01:56.260
และเฟสบุ๊คก็ไม่ใช่ที่เดียว

00:01:56.260 --> 00:01:58.260
ที่ทำหน้าที่บรรณาธิการเว็บ

00:01:58.260 --> 00:02:01.260
ด้วยกลไกที่เรามองไม่เห็น

00:02:01.260 --> 00:02:03.260
กูเกิลก็เช่นกัน

00:02:03.260 --> 00:02:06.260
ถ้าผมและคุณค้นสิ่งเดียวกัน

00:02:06.260 --> 00:02:08.260
แม้กระทั่งตอนนี้ในเวลาเดียวกัน

00:02:08.260 --> 00:02:11.260
เราอาจจะได้ผลลัพธ์ที่แตกต่างกันมาก

00:02:11.260 --> 00:02:14.260
วิศวกรคนหนึ่งบอกผมว่า แม้กระทั่งตอนที่คุณออกจากระบบ

00:02:14.260 --> 00:02:16.260
มีปัจจัย 57 อย่าง

00:02:16.260 --> 00:02:19.260
ที่กูเกิลใช้ตัดสินใจ --

00:02:19.260 --> 00:02:22.260
ตั้งแต่ชนิดของคอมพิวเตอร์ที่คุณใช้

00:02:22.260 --> 00:02:24.260
เบราว์เซอร์ที่คุณใช้

00:02:24.260 --> 00:02:26.260
ถึงสถานที่ที่คุณเล่นอยู่ --

00:02:26.260 --> 00:02:29.260
เพื่อคัดกรองผลลัพธ์ให้เรา

00:02:29.260 --> 00:02:31.260
ลองคิดดูดีๆ

00:02:31.260 --> 00:02:35.260
เราไม่มีกูเกิลที่เป็นมาตรฐานอีกแล้ว

00:02:35.260 --> 00:02:38.260
แล้วคุณรู้ไหม ที่น่าตกใจคือ เราไม่รู้ตัว

00:02:38.260 --> 00:02:40.260
คุณไม่รู้ว่าผลลัพธ์ของคุณ

00:02:40.260 --> 00:02:42.260
แตกต่างจากคนอื่นอย่างไร

00:02:42.260 --> 00:02:44.260
แต่ไม่กี่สัปดาห์ที่แล้ว

00:02:44.260 --> 00:02:47.260
ผมวานเพื่อนผมให้ค้นคำว่า "อียิปต์"

00:02:47.260 --> 00:02:50.260
แล้วถ่ายรูปหน้าจอมาให้ผมดู

00:02:50.260 --> 00:02:53.260
นี่คือหน้าจอของเพื่อนผม สก๊อตต์

00:02:54.260 --> 00:02:57.260
และนี่ของเพื่อนผมอีกคน แดเนียล

00:02:57.260 --> 00:02:59.260
ลองเปรียบเทียบกันดู

00:02:59.260 --> 00:03:01.260
โดยไม่ต้องอ่านเลยด้วยซ้ำ

00:03:01.260 --> 00:03:03.260
คุณก็เห็นว่ามันแตกต่างกันแค่ไหน

00:03:03.260 --> 00:03:05.260
แล้วลองอ่านดูสิ

00:03:05.260 --> 00:03:08.260
มันน่าตกใจมากเลยนะ

00:03:09.260 --> 00:03:12.260
ที่แดเนียลไม่ได้ผลลัพธ์เกี่ยวกับการประท้วงในอียิปต์

00:03:12.260 --> 00:03:14.260
บนผลการค้นหาหน้าแรกเลย

00:03:14.260 --> 00:03:16.260
แต่ของสก๊อตต์กลับมีเต็มไปหมด

00:03:16.260 --> 00:03:18.260
ทั้งๆที่เรื่องที่อียิปต์เป็นข่าวดังของช่วงนั้น

00:03:18.260 --> 00:03:21.260
นั่นคือความแตกต่างที่เราเห็นได้ชัด

00:03:21.260 --> 00:03:24.260
และมันไม่ใช่แค่กูเกิล และเฟสบุ๊ค

00:03:24.260 --> 00:03:26.260
มันกำลังลามไปทั่วอินเทอร์เน็ต

00:03:26.260 --> 00:03:29.260
มีบริษัทมากมายที่ทำแบบเดียวกัน

00:03:29.260 --> 00:03:32.260
ยาฮูนิวส์ เว็บไซต์ข่าวที่ใหญ่ที่สุดบนอินเทอร์เน็ต

00:03:32.260 --> 00:03:35.260
ก็ได้ปรับแต่งบริการให้เข้ากับแต่ละบุคคลแล้วเหมือนกัน

00:03:36.260 --> 00:03:39.260
ฮัฟฟิงตันโพสต์ วอชิงตันโพสต์ นิวยอร์คไทมส์

00:03:39.260 --> 00:03:42.260
ก็ปรับแต่งด้วยวิธีต่างๆ

00:03:42.260 --> 00:03:45.260
และมันกำลังผลักดันเรา

00:03:45.260 --> 00:03:47.260
ไปสู่โลกที่อินเทอร์เน็ต

00:03:47.260 --> 00:03:51.260
แสดงให้เราเห็นสิ่งที่มันคิดว่าเราอยากเห็น

00:03:51.260 --> 00:03:54.260
แต่ไม่จำเป็นว่าเป็นสิ่งที่เราควรจะเห็น

00:03:54.260 --> 00:03:57.260
ดังที่ เอริค ชมิดต์ ได้กล่าวไว้ว่า

00:03:57.260 --> 00:04:00.260
"มันจะเป็นไปได้ยาก ที่จะให้ผู้คนดูหรือบริโภค

00:04:00.260 --> 00:04:02.260
สิ่งที่ไม่ได้ถูกปรับแต่ง

00:04:02.260 --> 00:04:05.260
มาเพื่อพวกเขาเลย"

00:04:05.260 --> 00:04:07.260
ผมคิดว่านี่เป็นปัญหา

00:04:07.260 --> 00:04:10.260
และผมคิดว่าถ้าคุณเอาตัวกรองทั้งหมดนี้

00:04:10.260 --> 00:04:12.260
เอาอัลกอริทึมทั้งหมดมารวมกัน

00:04:12.260 --> 00:04:15.260
คุณจะได้ ฟองสบู่จากการกรองข้อมูล

00:04:16.260 --> 00:04:19.260
และฟองสบู่นี้ของคุณ

00:04:19.260 --> 00:04:21.260
ก็เป็นโลกแห่งข้อมูลของคุณคนเดียว

00:04:21.260 --> 00:04:23.260
ที่คุณมีบนอินเทอร์เน็ต

00:04:23.260 --> 00:04:26.260
และสิ่งที่อยู่ในฟองสบู่ของคุณ

00:04:26.260 --> 00:04:29.260
ขึ้นอยู่กับว่าคุณคือใครและคุณทำอะไร

00:04:29.260 --> 00:04:33.260
แต่คุณไม่ได้เป็นผู้ตัดสินใจว่าจะใส่อะไรลงไปบ้าง

00:04:33.260 --> 00:04:35.260
และที่สำคัญกว่านั้น

00:04:35.260 --> 00:04:38.260
คุณไม่รู้ว่าอะไรถูกกรองออกไปบ้าง

00:04:38.260 --> 00:04:40.260
ปัญหาหนึ่งของการกรองข้อมูลนี้

00:04:40.260 --> 00:04:43.260
ถูกค้นพบโดยนักวิจัยที่ เน็ตฟลิกซ์

00:04:43.260 --> 00:04:46.260
พวกเขามองการใช้งานเว็บเน็ตฟลิกซ์ แล้วค้นพบอะไรบางอย่าง

00:04:46.260 --> 00:04:48.260
ซึ่งพวกเราหลายคนก็คงพบเช่นกัน

00:04:48.260 --> 00:04:50.260
มีหนังบางเรื่อง

00:04:50.260 --> 00:04:53.260
ที่ส่งตรงถึงบ้านเราได้ในทันที

00:04:53.260 --> 00:04:56.260
เรากดเข้าคิว แล้วมันก็มาถึงเลย

00:04:56.260 --> 00:04:58.260
เช่น "Iron Man" ถูกส่งมาในทันที

00:04:58.260 --> 00:05:00.260
แต่ "Waiting for Superman"

00:05:00.260 --> 00:05:02.260
ก็ทำให้เรารอนานเหลือเกิน

00:05:02.260 --> 00:05:04.260
สิ่งที่เขาค้นพบ

00:05:04.260 --> 00:05:06.260
ก็คือในคิวของเรา

00:05:06.260 --> 00:05:09.260
มีการฉุดรั้งกันอยู่

00:05:09.260 --> 00:05:12.260
ระหว่างตัวตนที่เราอยากเป็นในอนาคต

00:05:12.260 --> 00:05:15.260
กับตัวตนซึ่งใจร้อนของเราในปัจจุบัน

00:05:15.260 --> 00:05:17.260
พวกเราทุกคนอยากเป็น

00:05:17.260 --> 00:05:19.260
คนที่เคยดู "ราโชมอน"

00:05:19.260 --> 00:05:21.260
แต่ตอนนี้

00:05:21.260 --> 00:05:24.260
เราอยากดู "วงศ์คำเหลา" เป็นรอบที่สี่

00:05:24.260 --> 00:05:27.260
(เสียงหัวเราะ)

00:05:27.260 --> 00:05:29.260
เพราะฉะนั้นการคัดกรองที่ดีควรให้เราทั้งสองอย่าง

00:05:29.260 --> 00:05:31.260
ทั้งจัสติน บีเบอร์บ้าง

00:05:31.260 --> 00:05:33.260
และเรื่องอัฟกานิสถานบ้าง

00:05:33.260 --> 00:05:35.260
มันให้ข้อมูลประเทืองปัญญาเราบ้าง

00:05:35.260 --> 00:05:38.260
แต่ก็ให้ของหวานให้เราผ่อนคลายด้วย

00:05:38.260 --> 00:05:40.260
และความท้าทายของอัลกอริทึมที่ใช้กรองเหล่านี้

00:05:40.260 --> 00:05:42.260
การกรองเฉพาะบุคคลเหล่านี้

00:05:42.260 --> 00:05:44.260
ก็คือ การที่มันมองแค่ว่า

00:05:44.260 --> 00:05:48.260
เราคลิกอะไรก่อน

00:05:48.260 --> 00:05:52.260
ทำให้เสียสมดุลนั้นไป

00:05:52.260 --> 00:05:55.260
และแทนที่จะได้ข้อมูลที่ครบถ้วนทุกหมู่

00:05:55.260 --> 00:05:57.260
เราอาจจะได้แค่

00:05:57.260 --> 00:05:59.260
ข้อมูลขยะ

00:05:59.260 --> 00:06:01.260
สิ่งที่เราเห็นคือ

00:06:01.260 --> 00:06:04.260
เราอาจจะมองภาพของอินเทอร์เน็ตผิดไป

00:06:04.260 --> 00:06:06.260
ในสังคมแห่งการกระจายข่าวสาร --

00:06:06.260 --> 00:06:08.260
นี่คือตำนานเริ่มแรกนะ --

00:06:08.260 --> 00:06:10.260
ในสังคมแห่งการกระจายข่าวสาร

00:06:10.260 --> 00:06:12.260
เรามีผู้คุมประตู หรือบรรณาธิการ

00:06:12.260 --> 00:06:15.260
เป็นผู้คุมการกระจายของข้อมูล

00:06:15.260 --> 00:06:18.260
แล้วอินเทอร์เน็ตก็เข้ามากวาดเอาหน้าที่เหล่านั้นออกไป

00:06:18.260 --> 00:06:20.260
และทำให้พวกเราได้เชื่อมต่อเข้าด้วยกัน

00:06:20.260 --> 00:06:22.260
มันเจ๋งเลยล่ะ

00:06:22.260 --> 00:06:25.260
แต่นั่นไม่ใช่สิ่งที่กำลังเกิดขึ้น

00:06:26.260 --> 00:06:29.260
สิ่งที่เราเห็นตอนนี้ เหมือนการเปลี่ยนไม้ผลัด

00:06:29.260 --> 00:06:31.260
จากบรรณาธิการที่เป็นมนุษย์

00:06:31.260 --> 00:06:34.260
ไปเป็นอัลกอริทึมแทน

00:06:34.260 --> 00:06:37.260
และปัญหาก็คือ อัลกอริทึมพวกนี้

00:06:37.260 --> 00:06:40.260
ยังไม่เข้าใจหลักจรรยาบรรณ

00:06:40.260 --> 00:06:43.260
ที่บรรณาธิการมี

00:06:43.260 --> 00:06:46.260
ดังนั้น หากเราจะให้อัลกอริทึมพวกนี้ คอยดูแลข้อมูลให้เรา

00:06:46.260 --> 00:06:49.260
หากมันจะตัดสินใจให้ ว่าเราควรเห็นอะไร และไม่ควรเห็นอะไร

00:06:49.260 --> 00:06:51.260
เราก็ควรจะต้องมั่นใจได้ว่า

00:06:51.260 --> 00:06:54.260
มันไม่ได้แสดงเพียงสิ่งที่สัมพันธ์กับเราอย่างเดียว

00:06:54.260 --> 00:06:56.260
เราต้องมั่นใจได้ว่ามันจะแสดง

00:06:56.260 --> 00:06:59.260
สิ่งที่เราไม่สบายใจที่จะดู สิ่งที่ท้าทาย หรือสิ่งที่สำคัญต่อเราเช่นกัน --

00:06:59.260 --> 00:07:01.260
และนี่คือสิ่งที่ TED ทำ --

00:07:01.260 --> 00:07:03.260
แสดงมุมมองของคนอื่น

00:07:03.260 --> 00:07:05.260
และเราก็เคยผ่านจุดนี้มาก่อนแล้ว

00:07:05.260 --> 00:07:07.260
ในฐานะสังคมเดียวกัน

00:07:08.260 --> 00:07:11.260
ในปี 1915 เหล่าหนังสือพิมพ์ยังไม่ค่อยเข้าใจ

00:07:11.260 --> 00:07:14.260
เรื่องความรับผิดชอบต่อสังคมเท่าไหร่นัก

00:07:14.260 --> 00:07:16.260
แล้วผู้คนก็เริ่มสังเกตเห็น

00:07:16.260 --> 00:07:19.260
ว่าพวกเขากำลังทำหน้าที่สำคัญ

00:07:19.260 --> 00:07:21.260
ที่ว่าคุณไม่สามารถ

00:07:21.260 --> 00:07:23.260
มีประชาธิปไตยที่แท้จริงได้

00:07:23.260 --> 00:07:27.260
หากประชาชนไม่ได้ข้อมูลที่ครบถ้วน

00:07:28.260 --> 00:07:31.260
และหนังสือพิมพ์ก็เป็นส่วนสำคัญ เพราะมันทำหน้าที่เหมือนตัวกรอง

00:07:31.260 --> 00:07:33.260
แล้วจรรยาบรรณนักข่าว ก็ถือกำเนิดขึ้น

00:07:33.260 --> 00:07:35.260
มันไม่ได้สมบูรณ์แบบ

00:07:35.260 --> 00:07:38.260
แต่มันก็ทำให้เราก้าวผ่านศตวรรษนั้นมาได้

00:07:38.260 --> 00:07:40.260
ดังนั้น ในตอนนี้

00:07:40.260 --> 00:07:43.260
เราเหมือนย้อนกลับไปที่ปี 1915 บนอินเทอร์เน็ต

00:07:44.260 --> 00:07:47.260
และเราต้องการผู้คุมประตูคนใหม่

00:07:47.260 --> 00:07:49.260
ที่สามารถเข้าใจความรับผิดชอบแบบเดิม

00:07:49.260 --> 00:07:51.260
และนำมันเข้าไปอยู่ในโค้ดของระบบ

00:07:51.260 --> 00:07:54.260
ผมรู้ว่าในที่นี้มีหลายคนที่มาจากเฟสบุ๊คและกูเกิล

00:07:54.260 --> 00:07:56.260
แลร์รี่ และ เซอร์เกย์ --

00:07:56.260 --> 00:07:58.260
ผู้คนที่ช่วยสร้างอินเทอร์เน็ตให้เป็นอย่างที่มันเป็นอยู่

00:07:58.260 --> 00:08:00.260
ผมรู้สึกซาบซึ้งมาก

00:08:00.260 --> 00:08:03.260
แต่เราต้องมั่นใจให้ได้ว่า

00:08:03.260 --> 00:08:06.260
อัลกอริทึมเหล่านี้รู้จัก

00:08:06.260 --> 00:08:09.260
ความหมายของบ้านเมือง และความรับผิดชอบต่อสังคม

00:08:09.260 --> 00:08:12.260
เราต้องการให้คุณแน่ใจว่า สิ่งเหล่านี้โปร่งใสเพียงพอ

00:08:12.260 --> 00:08:14.260
ที่ทำให้เรารู้ว่ามีกฎอะไรบ้าง

00:08:14.260 --> 00:08:17.260
ที่กำหนดว่าอะไรจะถูกกรองเข้าออก

00:08:17.260 --> 00:08:19.260
และเราต้องการควบคุมมันบ้าง

00:08:19.260 --> 00:08:21.260
เพื่อที่เราจะตัดสินใจ

00:08:21.260 --> 00:08:24.260
ว่าเราต้องการ หรือไม่ต้องการเห็นอะไร

00:08:24.260 --> 00:08:26.260
เพราะผมคิดว่า

00:08:26.260 --> 00:08:28.260
เราต้องการให้อินเทอร์เน็ตเป็นสิ่งนั้น

00:08:28.260 --> 00:08:30.260
ที่เราฝันอยากให้มันเป็น

00:08:30.260 --> 00:08:33.260
เราต้องการมัน เพื่อเชื่อมเราทุกคนเข้าด้วยกัน

00:08:33.260 --> 00:08:36.260
เราต้องการมัน เพื่อค้นพบสิ่งใหม่ๆ

00:08:36.260 --> 00:08:39.260
ผู้คนใหม่ๆ และมุมมองใหม่ๆ

00:08:40.260 --> 00:08:42.260
และมันจะทำสิ่งเหล่านั้นไม่ได้เลย

00:08:42.260 --> 00:08:45.260
ถ้ามันปล่อยเราให้โดดเดี่ยวอยู่เพียงแค่ในเว็บของเรา

00:08:45.260 --> 00:08:47.260
ขอบคุณครับ

00:08:47.260 --> 00:08:58.260
(เสียงปรบมือ)

