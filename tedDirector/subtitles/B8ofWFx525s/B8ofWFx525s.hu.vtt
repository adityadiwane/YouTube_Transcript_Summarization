WEBVTT
Kind: captions
Language: hu

00:00:00.000 --> 00:00:07.000
Fordító: Maria Ruzsane Cseresnyes
Lektor: Anna Patai

00:00:15.260 --> 00:00:17.260
Mark Zuckerbergnek

00:00:17.260 --> 00:00:20.260
feltett egy kérdést egy újságíró a new feeddel kapcsolatban,

00:00:20.260 --> 00:00:22.260
És azt kérdezte tőle az újságíró:

00:00:22.260 --> 00:00:24.260
"Tulajdonképpen miért olyan fontos ez?"

00:00:24.260 --> 00:00:26.260
És Zuckerberg azt felelte,

00:00:26.260 --> 00:00:28.260
"Az, hogy egy mókus éppen a házunk előtt haldoklik,

00:00:28.260 --> 00:00:31.260
lehet, hogy sokkal jobban érdekel minket ebben a pillanatban,

00:00:31.260 --> 00:00:34.260
mint hogy Afrikában emberek halnak meg."

00:00:34.260 --> 00:00:36.260
És arról akarok most beszélni, hogy milyen is

00:00:36.260 --> 00:00:39.260
lehet az a web, amely a fontosság ilyen felfogására épít.

00:00:40.260 --> 00:00:42.260
Gyerekkoromban, Maine Államban,

00:00:42.260 --> 00:00:44.260
egy igazi falusi környzetben,

00:00:44.260 --> 00:00:47.260
az internet valami egészen mást jelentett számomra.

00:00:47.260 --> 00:00:49.260
Kapcsolatot jelentett a világgal.

00:00:49.260 --> 00:00:52.260
Valami olyat, ami mindannyiunkat össze fog kötni.

00:00:52.260 --> 00:00:55.260
És biztos voltam benne, hogy ez remek dolog lesz a demokrácia

00:00:55.260 --> 00:00:58.260
és a társadalmunk számára.

00:00:58.260 --> 00:01:00.260
De van itt egy változás abban,

00:01:00.260 --> 00:01:02.260
ahogyan az információ online áramlik,

00:01:02.260 --> 00:01:05.260
és ez láthatatlan marad.

00:01:05.260 --> 00:01:07.260
És ha nem figyelünk rá,

00:01:07.260 --> 00:01:10.260
abból valóban baj lehet.

00:01:10.260 --> 00:01:13.260
Először egy olyan helyen figyeltem fel rá, ahol sok időt töltök --

00:01:13.260 --> 00:01:15.260
a Facebook oldalamon.

00:01:15.260 --> 00:01:18.260
Politikailag haladó vagyok -- micsoda meglepetés --

00:01:18.260 --> 00:01:20.260
de mindig mindent megteszek azért, hogy konzervatíokkal találkozzam.

00:01:20.260 --> 00:01:22.260
Szeretem hallani, hogy hogyan vélekednek.

00:01:22.260 --> 00:01:24.260
Szeretem látni, hogy mi köti össze őket;

00:01:24.260 --> 00:01:26.260
szeretek megtudni egy-két dolgot.

00:01:26.260 --> 00:01:29.260
Nagyon meglepődtem valamelyik nap.

00:01:29.260 --> 00:01:32.260
hogy a konzervatívok eltűntek a Facebook feedemből.

00:01:33.260 --> 00:01:35.260
És kiderült, hogy az történt,

00:01:35.260 --> 00:01:39.260
hogy a Facebook figyelte, hogy milyen linkekre kattintok,

00:01:39.260 --> 00:01:41.260
és észrevette, hogy valóban,

00:01:41.260 --> 00:01:43.260
többet kattintottam a liberális barátaim linkjére,

00:01:43.260 --> 00:01:46.260
mint a konzervatív barátaiméra.

00:01:46.260 --> 00:01:48.260
És anélkül, hogy engem megkérdezett volna,

00:01:48.260 --> 00:01:50.260
kihagyta őket.

00:01:50.260 --> 00:01:53.260
Eltűntek.

00:01:54.260 --> 00:01:56.260
De nem a Facebook az egyetlen,

00:01:56.260 --> 00:01:58.260
ami ilyen észrevétlen, algoritmikus módon

00:01:58.260 --> 00:02:01.260
szerkesztget a web-en.

00:02:01.260 --> 00:02:03.260
A Google is ezt csinálja.

00:02:03.260 --> 00:02:06.260
Ha én is, meg te is keresel valamit,

00:02:06.260 --> 00:02:08.260
ugyanazt, és egyidejűleg,

00:02:08.260 --> 00:02:11.260
akár egészen különböző eredményt is kaphatunk.

00:02:11.260 --> 00:02:14.260
Egy mérnök mondta, hogy még kijelentkezéskor is

00:02:14.260 --> 00:02:16.260
57 jelzést

00:02:16.260 --> 00:02:19.260
figyel a Google --

00:02:19.260 --> 00:02:22.260
kezdve azon, hogy milyen számítógépen dolgozunk,

00:02:22.260 --> 00:02:24.260
milyen böngészőt használunk

00:02:24.260 --> 00:02:26.260
honnan internetezünk --

00:02:26.260 --> 00:02:29.260
hogy azután ennek megfelelően személyre szabja a lekérdezés eredményét.

00:02:29.260 --> 00:02:31.260
Gondoljunk csak utána egy pillanatra:

00:02:31.260 --> 00:02:35.260
szó sincs már többet a szabványos Google-ról.

00:02:35.260 --> 00:02:38.260
És tudják, az a furcsa, hogy ezt nehéz észrevenni.

00:02:38.260 --> 00:02:40.260
Nem látjuk, hogy mennyire más nálunk a keresés eredménye,

00:02:40.260 --> 00:02:42.260
mint másoknál.

00:02:42.260 --> 00:02:44.260
De néhány hete

00:02:44.260 --> 00:02:47.260
megkértem egy pár barátomat hogy keressenek rá a Google-ban Egyiptomra.

00:02:47.260 --> 00:02:50.260
és küldjék át a kapott eredmény képernyőjét.

00:02:50.260 --> 00:02:53.260
Itt van Scott barátomé.

00:02:54.260 --> 00:02:57.260
És itt Danielé.

00:02:57.260 --> 00:02:59.260
Ha egymás mellé tesszük őket,

00:02:59.260 --> 00:03:01.260
el se kell, hogy olvassuk a linkeket ahhoz,

00:03:01.260 --> 00:03:03.260
hogy lássuk, mennyire más a két oldal.

00:03:03.260 --> 00:03:05.260
De ha elolvassuk a linkeket,

00:03:05.260 --> 00:03:08.260
valóban nagyon figyelemre méltó,

00:03:09.260 --> 00:03:12.260
hogy Daniel semmit nem kapott az egyiptomi tűntetésekről

00:03:12.260 --> 00:03:14.260
az első lapon.

00:03:14.260 --> 00:03:16.260
míg Scott ererménye tele volt velük.

00:03:16.260 --> 00:03:18.260
És ez volt a nap története akkoriban,

00:03:18.260 --> 00:03:21.260
hogy mennyire más volt a két eredmény.

00:03:21.260 --> 00:03:24.260
És hát nem csak a Google-nál és a Facebooknál van ez.

00:03:24.260 --> 00:03:26.260
Ez egy olyan jelenség, ami egyre terjed a weben.

00:03:26.260 --> 00:03:29.260
A cégek tömege használ ilyen személyre szabást.

00:03:29.260 --> 00:03:32.260
A Yahoo News, a legnagyobb hír-oldal az interneten,

00:03:32.260 --> 00:03:35.260
mostanában vált személyessé -- különböző emberek különböző dolgokat kapnak.

00:03:36.260 --> 00:03:39.260
A Huffington Post, a Washington Post, a New York Times --

00:03:39.260 --> 00:03:42.260
mindegyik kacérkodik valamilyen formában a személyre szabással.

00:03:42.260 --> 00:03:45.260
És ez nagyon gyorsan elvisz

00:03:45.260 --> 00:03:47.260
egy olyan világ felé, amelyben

00:03:47.260 --> 00:03:51.260
az internet azt mutatja meg nekünk, amiről azt gondolja, hogy látni szeretnénk,

00:03:51.260 --> 00:03:54.260
és nem szükségképp azt, amit látnunk kell.

00:03:54.260 --> 00:03:57.260
Ahogyan Eric Schmidt mondta,

00:03:57.260 --> 00:04:00.260
"Nagyon nehéz lesz az embereknek meglátni vagy használni bármit is,

00:04:00.260 --> 00:04:02.260
ami nincs valamiképp

00:04:02.260 --> 00:04:05.260
hozzájuk igazítva."

00:04:05.260 --> 00:04:07.260
Úgy gondolom, hogy ez baj.

00:04:07.260 --> 00:04:10.260
Azt hiszem, hogy ha vesszük mindezeket a szűrőket,

00:04:10.260 --> 00:04:12.260
az összes algoritmust,

00:04:12.260 --> 00:04:15.260
akkor megkapjuk azt amit én szűrőburoknak nevezek.

00:04:16.260 --> 00:04:19.260
És a szűrőburkunk a saját, személyes

00:04:19.260 --> 00:04:21.260
különbejáratú információs világunk,

00:04:21.260 --> 00:04:23.260
amiben online élünk.

00:04:23.260 --> 00:04:26.260
És, hogy mi van ebben a szűrőburokban,

00:04:26.260 --> 00:04:29.260
az azon múlik, hogy kik vagyunk, mit csinálunk.

00:04:29.260 --> 00:04:33.260
De az a helyzet, hogy nem mi döntjük el, hogy mi kerül bele.

00:04:33.260 --> 00:04:35.260
És, ami még fontosabb,

00:04:35.260 --> 00:04:38.260
hogy nem igazán látjuk, hogy mi marad ki belőle.

00:04:38.260 --> 00:04:40.260
A szűrőburok egyik problémáját

00:04:40.260 --> 00:04:43.260
a Netflix kutatói fedezték fel.

00:04:43.260 --> 00:04:46.260
Nézték a Netflix várólistákat, és valami vicces dolgot vettek észre,

00:04:46.260 --> 00:04:48.260
valami olyat, amit valószínűleg többen észrevettünk már,

00:04:48.260 --> 00:04:50.260
hogy vannak filmek,

00:04:50.260 --> 00:04:53.260
amiket szinte azonnal letöltünk.

00:04:53.260 --> 00:04:56.260
Hozzáadjuk a várólistához és szinte azonnal letöltjük.

00:04:56.260 --> 00:04:58.260
Pl. az "Iron Man"-t azonnal letöltjük,

00:04:58.260 --> 00:05:00.260
míg "Waiting for Superman"

00:05:00.260 --> 00:05:02.260
tényleg sokáig várhat.

00:05:02.260 --> 00:05:04.260
Azt fedezték fel,

00:05:04.260 --> 00:05:06.260
hogy a mi Netflix várólistáinkon

00:05:06.260 --> 00:05:09.260
ádáz harc folyik a két énünk között:

00:05:09.260 --> 00:05:12.260
az egyik énünk, aki a jövőben szeretnénk lenni,

00:05:12.260 --> 00:05:15.260
a másik a pillanatnyi impulzív énünk.

00:05:15.260 --> 00:05:17.260
Tudják, mindannyian szeretnénk azok közé tartozni,

00:05:17.260 --> 00:05:19.260
akik látták már a "Rashomon"-t

00:05:19.260 --> 00:05:21.260
de épp most

00:05:21.260 --> 00:05:24.260
inkább az "Ace Ventura"-t szeretnénk megnézni, negyedszerre.

00:05:24.260 --> 00:05:27.260
(Nevetés)

00:05:27.260 --> 00:05:29.260
Így a legjobb szerkesztés mindkettőből ad egy kicsit.

00:05:29.260 --> 00:05:31.260
Ad egy kicsit Justin Bieber-ből

00:05:31.260 --> 00:05:33.260
és egy kicsit Afganisztánból.

00:05:33.260 --> 00:05:35.260
Ad egy kevés információ-főzeléket,

00:05:35.260 --> 00:05:38.260
és egy keveset a desszertből.

00:05:38.260 --> 00:05:40.260
A nehézség az ilyen algoritmikus szűrőkkel,

00:05:40.260 --> 00:05:42.260
ezekkel a személyre szóló szűrőkkel,

00:05:42.260 --> 00:05:44.260
hogy többnyire azt nézik,

00:05:44.260 --> 00:05:48.260
hogy mire kilkkelünk először,

00:05:48.260 --> 00:05:52.260
ezzel elronthatják az egyensúlyt.

00:05:52.260 --> 00:05:55.260
És a kiegyensúlyozott információ-étrend helyett

00:05:55.260 --> 00:05:57.260
a végén csupa információ-hamburgerrel

00:05:57.260 --> 00:05:59.260
leszünk körülvéve.

00:05:59.260 --> 00:06:01.260
Ez azt sugallja,

00:06:01.260 --> 00:06:04.260
hogy valójában félreértésben lehetünk az internettel kapcsolatban.

00:06:04.260 --> 00:06:06.260
A hírközlésben --

00:06:06.260 --> 00:06:08.260
ez az, ahogyan a mítoszok keletkeznek --

00:06:08.260 --> 00:06:10.260
a hírközlésben

00:06:10.260 --> 00:06:12.260
ott voltak az őrök, a szerkesztők,

00:06:12.260 --> 00:06:15.260
és az ő kezükben voltak az információ csatornái.

00:06:15.260 --> 00:06:18.260
És jött az internet és elsöpörte őket az útból,

00:06:18.260 --> 00:06:20.260
és lehetővé tette, hogy mindannyian kapcsolatba kerüljünk egymással,

00:06:20.260 --> 00:06:22.260
és ez döbbenetes volt.

00:06:22.260 --> 00:06:25.260
De most éppenséggel nem ez történik,

00:06:26.260 --> 00:06:29.260
Amit most látunk, az az, ahogyan a

00:06:29.260 --> 00:06:31.260
a hús-vér őrök átadják a stafétabotot

00:06:31.260 --> 00:06:34.260
az algoritmikus őröknek.

00:06:34.260 --> 00:06:37.260
És hát az algoritmusoknak

00:06:37.260 --> 00:06:40.260
nincs meg az a belső etikája,

00:06:40.260 --> 00:06:43.260
amit a szerkesztők használtak.

00:06:43.260 --> 00:06:46.260
Így ha az algoritmusok fogják elrendezni a világot a számunkra,

00:06:46.260 --> 00:06:49.260
ha azok döntik el, hogy mit nézzünk meg és mit ne,

00:06:49.260 --> 00:06:51.260
akkor biztosítanunk kell, hogy

00:06:51.260 --> 00:06:54.260
ne csupán a relevancia szerint legyenek programozva.

00:06:54.260 --> 00:06:56.260
Biztosítanunk kell, hogy olyan dolgokat is megmutassanak,

00:06:56.260 --> 00:06:59.260
amelyek kényelmetlenek, provokatívak vagy fontosak --

00:06:59.260 --> 00:07:01.260
ezt teszi a TED --

00:07:01.260 --> 00:07:03.260
más nézőpontokat is.

00:07:03.260 --> 00:07:05.260
Mint társadalom, voltunk már korábban is

00:07:05.260 --> 00:07:07.260
ilyen helyzetben.

00:07:08.260 --> 00:07:11.260
Nem mintha 1915-ben az újságok sokat

00:07:11.260 --> 00:07:14.260
törődtek volna a polgári felelősséggel.

00:07:14.260 --> 00:07:16.260
Azután az emberek észrevették,

00:07:16.260 --> 00:07:19.260
hogy valami nagyon fontosat csináltak.

00:07:19.260 --> 00:07:21.260
Hogy nem létezhet

00:07:21.260 --> 00:07:23.260
működő demokrácia úgy,

00:07:23.260 --> 00:07:27.260
hogy az állampolgárok ne kapnák meg a megfelelő információkat.

00:07:28.260 --> 00:07:31.260
Hogy az újságok azért voltak kulcsfontosságúak, mert úgy működtek, mint valami szűrő,

00:07:31.260 --> 00:07:33.260
és azután kifejlődött az újságírói etika.

00:07:33.260 --> 00:07:35.260
Nem volt tökéletes,

00:07:35.260 --> 00:07:38.260
de átsegített minket az előző századon.

00:07:38.260 --> 00:07:40.260
És így most

00:07:40.260 --> 00:07:43.260
ez valami visszatérés-féle 1915-höz a web-en.

00:07:44.260 --> 00:07:47.260
És szükségünk van új őrökre,

00:07:47.260 --> 00:07:49.260
hogy belekódolják ezt a felelősséget

00:07:49.260 --> 00:07:51.260
a kódba, amit írnak.

00:07:51.260 --> 00:07:54.260
Tudom, hogy sokan vannak itt a Facebook-tól és a Google-tól --

00:07:54.260 --> 00:07:56.260
Larry és Sergey --

00:07:56.260 --> 00:07:58.260
olyan emberek, akik segítettek olyanná formálni a web-et, amilyen,

00:07:58.260 --> 00:08:00.260
és ezért hálás vagyok nekik.

00:08:00.260 --> 00:08:03.260
De tényleg szükségünk van önökre, hogy biztosítsák,

00:08:03.260 --> 00:08:06.260
hogy ezekben az algoritmusokban be legyen kódolva

00:08:06.260 --> 00:08:09.260
a közélet ítélőképessége, a polgári felelősség tudata.

00:08:09.260 --> 00:08:12.260
Szükségünk van önökre, hogy biztosítsák az átláthatóságot,

00:08:12.260 --> 00:08:14.260
hogy láthassuk, hogy mik azok a szabályok,

00:08:14.260 --> 00:08:17.260
amelyek meghatározzák, hogy mi megy át a szűrőinken.

00:08:17.260 --> 00:08:19.260
És szükség van önökre azért is, hogy adjanak bizonyos ellenőrzési lehetőséget,

00:08:19.260 --> 00:08:21.260
hogy mi magunk tudjuk előírni,

00:08:21.260 --> 00:08:24.260
hogy mi menjen át és mi ne.

00:08:24.260 --> 00:08:26.260
Mivel azt gondolom,

00:08:26.260 --> 00:08:28.260
hogy valóban szükségünk van rá, hogy az legyen az internet

00:08:28.260 --> 00:08:30.260
amiről mindannyian álmodtunk.

00:08:30.260 --> 00:08:33.260
Szükségünk van rá, hogy valamennyiünket összekössön.

00:08:33.260 --> 00:08:36.260
Szükségünk van rá, hogy megmutasson új gondolatokat,

00:08:36.260 --> 00:08:39.260
új embereket és különböző távlatokat.

00:08:40.260 --> 00:08:42.260
És ez nem történhet meg úgy,

00:08:42.260 --> 00:08:45.260
ha egymástól elszigetelve maradunk a weben.

00:08:45.260 --> 00:08:47.260
Köszönöm.

00:08:47.260 --> 00:08:58.260
(Taps)

