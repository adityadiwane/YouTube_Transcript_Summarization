WEBVTT
Kind: captions
Language: id

00:00:00.000 --> 00:00:07.000
Translator: Amir Sudjono
Reviewer: Irma Amelia

00:00:15.260 --> 00:00:17.260
Mark Zuckerberg,

00:00:17.260 --> 00:00:20.260
seorang wartawan menanyakan padanya pertanyaan tentang feed berita.

00:00:20.260 --> 00:00:22.260
Dan wartawan itu menanyakan kepadanya,

00:00:22.260 --> 00:00:24.260
"Mengapa ini sangat penting?"

00:00:24.260 --> 00:00:26.260
Dan Zuckerberg menjawab,

00:00:26.260 --> 00:00:28.260
"Seekor tupai yang sekarat di halaman depan Anda

00:00:28.260 --> 00:00:31.260
mungkin lebih relevan dengan minat Anda sekarang

00:00:31.260 --> 00:00:34.260
dibandingkan orang-orang sekarat di Afrika."

00:00:34.260 --> 00:00:36.260
Dan saya ingin berbicara tentang

00:00:36.260 --> 00:00:39.260
bagaimana sebuah Web yang didasari pemikiran relevansi itu akan terlihat.

00:00:40.260 --> 00:00:42.260
Ketika saya tumbuh dewasa

00:00:42.260 --> 00:00:44.260
di daerah yang sangat pedesaan di Maine,

00:00:44.260 --> 00:00:47.260
Internet berarti sangat berbeda bagi saya.

00:00:47.260 --> 00:00:49.260
Ia berarti koneksi ke dunia.

00:00:49.260 --> 00:00:52.260
Ia berarti sesuatu yang dapat menghubungkan kita semua.

00:00:52.260 --> 00:00:55.260
Dan saya yakin Internet akan sangat bagus untuk demokrasi

00:00:55.260 --> 00:00:58.260
dan untuk masyarakat kita.

00:00:58.260 --> 00:01:00.260
Tetapi ada perubahan

00:01:00.260 --> 00:01:02.260
dalam bagaimana informasi mengalir online,

00:01:02.260 --> 00:01:05.260
dan ini tidak terlihat.

00:01:05.260 --> 00:01:07.260
Dan jika kita tidak memperhatikannya,

00:01:07.260 --> 00:01:10.260
ini dapat menjadi masalah nyata.

00:01:10.260 --> 00:01:13.260
Jadi pertama kali saya memperhatikan ini di tempat saya menghabiskan banyak waktu --

00:01:13.260 --> 00:01:15.260
halaman Facebook saya.

00:01:15.260 --> 00:01:18.260
Saya progresif secara politik -- kejutan besar --

00:01:18.260 --> 00:01:20.260
tetapi saya selalu berusaha untuk bertemu dengan para konservatif

00:01:20.260 --> 00:01:22.260
Saya suka mendengar apa yang mereka pikirkan;

00:01:22.260 --> 00:01:24.260
Saya suka melihat yang mereka tautkan;

00:01:24.260 --> 00:01:26.260
Saya suka belajar satu dua hal.

00:01:26.260 --> 00:01:29.260
Dan saya terkejut waktu satu hari saya perhatikan

00:01:29.260 --> 00:01:32.260
bahwa para konservatif telah menghilang dari Facebook feed saya.

00:01:33.260 --> 00:01:35.260
Dan ternyata yang terjadi

00:01:35.260 --> 00:01:39.260
adalah bahwa Facebook melihat tautan mana yang saya klik,

00:01:39.260 --> 00:01:41.260
dan FB mengetahui bahwa, sebenarnya,

00:01:41.260 --> 00:01:43.260
Saya mengklik lebih banyak tautan dari teman-teman liberal saya

00:01:43.260 --> 00:01:46.260
dibanding tautan dari teman-teman konservatif saya.

00:01:46.260 --> 00:01:48.260
Dan tanpa menanyakan saya tentang itu,

00:01:48.260 --> 00:01:50.260
mereka telah diedit.

00:01:50.260 --> 00:01:53.260
Tautan ini menghilang.

00:01:54.260 --> 00:01:56.260
Jadi Facebook bukanlah tempat satu-satunya

00:01:56.260 --> 00:01:58.260
yang melakukan pengeditan secara tidak terlihat, secara algoritmik

00:01:58.260 --> 00:02:01.260
terhadap Web.

00:02:01.260 --> 00:02:03.260
Google juga melakukannya.

00:02:03.260 --> 00:02:06.260
Jika saya mencari sesuatu, dan Anda mencari sesuatu,

00:02:06.260 --> 00:02:08.260
bahkan sekarang pada saat yang bersamaan,

00:02:08.260 --> 00:02:11.260
kita akan mendapatkan hasil pencarian yang sangat berbeda.

00:02:11.260 --> 00:02:14.260
Bahkan jika Anda telah keluar, seorang insinyur mengatakan kepada saya,

00:02:14.260 --> 00:02:16.260
ada 57 sinyal

00:02:16.260 --> 00:02:19.260
yang Google lihat --

00:02:19.260 --> 00:02:22.260
semua dari komputer apa yang Anda dipakai,

00:02:22.260 --> 00:02:24.260
dari browser apa yang dipakai Anda,

00:02:24.260 --> 00:02:26.260
dimana Anda berada --

00:02:26.260 --> 00:02:29.260
yang dipakai untuk menyesuaikan hasil pertanyaan Anda.

00:02:29.260 --> 00:02:31.260
Pikirkanlah sebentar:

00:02:31.260 --> 00:02:35.260
sudah tidak ada Google standar lagi.

00:02:35.260 --> 00:02:38.260
Dan tahukah Anda, yang lucu dari hal ini adalah ini sulit untuk dilihat.

00:02:38.260 --> 00:02:40.260
Anda tidak dapat melihat bagaimana hasil pencarian Anda berbeda

00:02:40.260 --> 00:02:42.260
dari orang lain.

00:02:42.260 --> 00:02:44.260
Tetapi dua minggu lalu,

00:02:44.260 --> 00:02:47.260
Saya tanya beberapa orang untuk mencari "Mesir" di Google

00:02:47.260 --> 00:02:50.260
dan mengirimkan saya gambar layar yang mereka dapatkan.

00:02:50.260 --> 00:02:53.260
Jadi ini gambar layar milik Scott teman saya.

00:02:54.260 --> 00:02:57.260
Dan ini gambar layar milik teman saya Daniel.

00:02:57.260 --> 00:02:59.260
Jika Anda letakan mereka berdekatan,

00:02:59.260 --> 00:03:01.260
Anda tidak harus melihat tautannya

00:03:01.260 --> 00:03:03.260
untuk melihat bagaimana dua halaman ini berbeda.

00:03:03.260 --> 00:03:05.260
Tapi jika Anda membaca tautannya,

00:03:05.260 --> 00:03:08.260
ini sangat luar biasa.

00:03:09.260 --> 00:03:12.260
Daniel tidak mendapatkan apapun tentang protes di Mesir

00:03:12.260 --> 00:03:14.260
di halaman pertama hasil pencarian Googlenya.

00:03:14.260 --> 00:03:16.260
Di hasil Scott ada banyak sekali.

00:03:16.260 --> 00:03:18.260
Dan inilah cerita besar di hari itu.

00:03:18.260 --> 00:03:21.260
Itulah bagaimana hasil pencarian ini menjadi berbeda.

00:03:21.260 --> 00:03:24.260
Jadi ini bukan hanya Google dan Facebook saja.

00:03:24.260 --> 00:03:26.260
Ini adalah sesuatu yang melanda seluruh Web.

00:03:26.260 --> 00:03:29.260
Ada banyak perusahaan yang melakukan personalisasi semacam ini.

00:03:29.260 --> 00:03:32.260
Yahoo News, portal berita terbesar di Internet,

00:03:32.260 --> 00:03:35.260
sekarang sudah dipersonalisasi -- orang berbeda mendapat hasil berbeda.

00:03:36.260 --> 00:03:39.260
Huffington Post, Washington Post, New York Times --

00:03:39.260 --> 00:03:42.260
semuanya melakukan personalisasi dengan bermacam cara.

00:03:42.260 --> 00:03:45.260
Dan ini mengantarkan kita dengan sangat cepat

00:03:45.260 --> 00:03:47.260
ke dunia dimana

00:03:47.260 --> 00:03:51.260
Internet memperlihatkan ke kita apa yang ia pikir kita mau lihat,

00:03:51.260 --> 00:03:54.260
tetapi bukan berarti yang kita perlu lihat.

00:03:54.260 --> 00:03:57.260
Seperti yang Eric Schmidt katakan,

00:03:57.260 --> 00:04:00.260
"Akan sangat sulit bagi orang-orang untuk melihat atau mengkonsumsi sesuatu

00:04:00.260 --> 00:04:02.260
yang dalam arti tertentu belum

00:04:02.260 --> 00:04:05.260
disesuaikan untuk mereka."

00:04:05.260 --> 00:04:07.260
Jadi saya pikir ini adalah suatu masalah.

00:04:07.260 --> 00:04:10.260
Dan saya pikir, jika Anda ambil semua filter ini,

00:04:10.260 --> 00:04:12.260
Anda ambil semua algoritma ini,

00:04:12.260 --> 00:04:15.260
Anda mendapatkan yang saya sebut gelembung filter.

00:04:16.260 --> 00:04:19.260
Dan gelembung filter Anda adalah dunia informasi milik Anda sendiri

00:04:19.260 --> 00:04:21.260
yang unik

00:04:21.260 --> 00:04:23.260
yang anda tinggali waktu online.

00:04:23.260 --> 00:04:26.260
Dan apa yang ada di gelembung filter Anda

00:04:26.260 --> 00:04:29.260
tergantung dari siapa Anda, dan tergantung pada apa yang Anda lakukan.

00:04:29.260 --> 00:04:33.260
Tetapi masalahnya Anda tidak memutuskan apa yang masuk.

00:04:33.260 --> 00:04:35.260
Dan lebih penting lagi,

00:04:35.260 --> 00:04:38.260
Anda tidak melihat apa yang disunting keluar.

00:04:38.260 --> 00:04:40.260
Jadi salah satu masalah dari gelembung filter

00:04:40.260 --> 00:04:43.260
ditemukan oleh beberapa peneliti di Netflix.

00:04:43.260 --> 00:04:46.260
Mereka melihat antrian Netflix, dan mereka menemukan sesuatu yang lucu

00:04:46.260 --> 00:04:48.260
yang banyak dari kita mungkin perhatikan,

00:04:48.260 --> 00:04:50.260
yaitu ada beberapa film

00:04:50.260 --> 00:04:53.260
yang sepertinya langsung terkirim ke rumah kita.

00:04:53.260 --> 00:04:56.260
Mereka masuk ke antrian, dan mereka langsung terkirim.

00:04:56.260 --> 00:04:58.260
Jadi "Iron Man" langsung terkirim,

00:04:58.260 --> 00:05:00.260
dan "Waiting for Superman"

00:05:00.260 --> 00:05:02.260
dapat menunggu untuk waktu yang sangat lama.

00:05:02.260 --> 00:05:04.260
Yang mereka temukan

00:05:04.260 --> 00:05:06.260
adalah di antrian Netflix kami

00:05:06.260 --> 00:05:09.260
ada perjuangan hebat yang terjadi

00:05:09.260 --> 00:05:12.260
antara diri kita yang aspiratif di masa mendatang

00:05:12.260 --> 00:05:15.260
dan diri kita yang impulsif di masa sekarang.

00:05:15.260 --> 00:05:17.260
Anda tahu kita semua mau untuk menjadi seseorang

00:05:17.260 --> 00:05:19.260
yang telah menonton "Rashomon,"

00:05:19.260 --> 00:05:21.260
tetapi sekarang

00:05:21.260 --> 00:05:24.260
kita ingin menonton "Ace Ventura" untuk keempat kalinya.

00:05:24.260 --> 00:05:27.260
(Tawa)

00:05:27.260 --> 00:05:29.260
Jadi pengeditan yang terbaik memberi kita keduanya.

00:05:29.260 --> 00:05:31.260
Ia memberi kita sedikit Justin Beiber

00:05:31.260 --> 00:05:33.260
dan sedikit Afghanistan.

00:05:33.260 --> 00:05:35.260
Ia memberi kita beberapa sayuran informasi,

00:05:35.260 --> 00:05:38.260
Ia memberi kita beberapa makanan penutup informasi.

00:05:38.260 --> 00:05:40.260
Dan tantangannya dengan sejenis filter algoritmik ini,

00:05:40.260 --> 00:05:42.260
filter yang telah disesuaikan seperti ini,

00:05:42.260 --> 00:05:44.260
adalah, karena mereka pada dasarnya mencari

00:05:44.260 --> 00:05:48.260
apa yang Anda klik pertama kali,

00:05:48.260 --> 00:05:52.260
itu akan menjadikannya tidak seimbang.

00:05:52.260 --> 00:05:55.260
Dan bukannya informasi diet seimbang,

00:05:55.260 --> 00:05:57.260
Anda akhirnya dapat terkepung

00:05:57.260 --> 00:05:59.260
oleh informasi junk food.

00:05:59.260 --> 00:06:01.260
Apa yang ini tunjukkan

00:06:01.260 --> 00:06:04.260
adalah nyatanya kita mungkin telah mendapatkan cerita tentang Internet dengan salah.

00:06:04.260 --> 00:06:06.260
Di masyarakat penyiaran --

00:06:06.260 --> 00:06:08.260
ini adalah bagaimana mitologi pendiri mengatakan --

00:06:08.260 --> 00:06:10.260
di masyarakat siaran,

00:06:10.260 --> 00:06:12.260
ada penjaga gerbang, sang editor,

00:06:12.260 --> 00:06:15.260
dan mereka mengkontrol aliran informasi.

00:06:15.260 --> 00:06:18.260
Dan akhirnya datang Internet dan ia menyapu mereka keluar,

00:06:18.260 --> 00:06:20.260
dan ia memungkinkan kita untuk terhubung satu sama lain,

00:06:20.260 --> 00:06:22.260
dan ini sangat luar biasa.

00:06:22.260 --> 00:06:25.260
Tetapi ini bukanlah apa yang nyatanya terjadi sekarang.

00:06:26.260 --> 00:06:29.260
Apa yang kita lihat adalah pemindahan obor

00:06:29.260 --> 00:06:31.260
dari penjaga gerbang manusia

00:06:31.260 --> 00:06:34.260
ke penjaga gawang algoritmik.

00:06:34.260 --> 00:06:37.260
Dan masalahnya adalah algoritma

00:06:37.260 --> 00:06:40.260
belum memiliki etika yang tersirat

00:06:40.260 --> 00:06:43.260
yang para editor punya.

00:06:43.260 --> 00:06:46.260
Jadi jika algoritma akan menyediakan dunia untuk kita,

00:06:46.260 --> 00:06:49.260
jika mereka akan memutuskan apa yang dapat kita lihat dan apa yang tidak bisa kita lihat,

00:06:49.260 --> 00:06:51.260
jadi kita perlu untuk memastikan

00:06:51.260 --> 00:06:54.260
bahwa mereka bukan saja diprogram untuk relevansi.

00:06:54.260 --> 00:06:56.260
Kita perlu pastikan bahwa mereka juga menunjukan kita hal-hal

00:06:56.260 --> 00:06:59.260
yang tidak nyaman atau menantang atau penting --

00:06:59.260 --> 00:07:01.260
inilah yang TED lakukan --

00:07:01.260 --> 00:07:03.260
sudut pandang orang lain.

00:07:03.260 --> 00:07:05.260
Dan sebenarnya kita pernah berada disini sebelumnya

00:07:05.260 --> 00:07:07.260
sebagai sebuah masyarakat.

00:07:08.260 --> 00:07:11.260
Di 1915, tidaklah seperti koran memikirkan banyak

00:07:11.260 --> 00:07:14.260
tentang tanggung jawab mereka sebagai warna negara.

00:07:14.260 --> 00:07:16.260
Lalu orang-orang memperhatikan

00:07:16.260 --> 00:07:19.260
Bahwa mereka melakukan sesuatu yang sangat penting.

00:07:19.260 --> 00:07:21.260
Bahwa, sesungguhnya, Anda tidak bisa mendapatkan

00:07:21.260 --> 00:07:23.260
demokrasi yang berfungsi

00:07:23.260 --> 00:07:27.260
jika warga negaranya tidak mendapatkan aliran informasi yang baik.

00:07:28.260 --> 00:07:31.260
Koran sangat penting, karena mereka bertindak sebagai filter,

00:07:31.260 --> 00:07:33.260
dan akhirnya etika wartawan terbentuk.

00:07:33.260 --> 00:07:35.260
Itu tidak sempurna,

00:07:35.260 --> 00:07:38.260
tetap berhasil membawa kita melewati seabad terakhir.

00:07:38.260 --> 00:07:40.260
Dan sekarang,

00:07:40.260 --> 00:07:43.260
kita seperti kembali di tahun 1915 di Web.

00:07:44.260 --> 00:07:47.260
Dan kita perlu penjaga gerbang baru

00:07:47.260 --> 00:07:49.260
untuk mengkode tanggung jawab seperti ini

00:07:49.260 --> 00:07:51.260
menjadi kode yang mereka tulis.

00:07:51.260 --> 00:07:54.260
Saya tahu banyak orang di sini dari Facebook atau Google --

00:07:54.260 --> 00:07:56.260
Larry dan Sergey --

00:07:56.260 --> 00:07:58.260
orang-orang yang telah membantu kita membangun Web seperti sekarang,

00:07:58.260 --> 00:08:00.260
dan saya berterima kasih untuk itu.

00:08:00.260 --> 00:08:03.260
Tetapi kami sangat memerlukan Anda untuk memastikan

00:08:03.260 --> 00:08:06.260
bahwa algoritma-algoritma ini memiliki kode

00:08:06.260 --> 00:08:09.260
rasa dari kehidupan publik, rasa tanggung jawab kewarganegaraan.

00:08:09.260 --> 00:08:12.260
Kita perlu Anda untuk memastikan bahwa mereka cukup transparan

00:08:12.260 --> 00:08:14.260
sehingga kita dapat melihat aturan-aturan

00:08:14.260 --> 00:08:17.260
yang menentukan apa yang bisa melewati filter kita.

00:08:17.260 --> 00:08:19.260
Dan kita butuh Anda untuk memberi kita kontrol,

00:08:19.260 --> 00:08:21.260
sehingga kita bisa memutuskan

00:08:21.260 --> 00:08:24.260
apa yang bisa lewat dan apa yang tidak.

00:08:24.260 --> 00:08:26.260
Karena saya pikir

00:08:26.260 --> 00:08:28.260
kita sangat membutuhkan Internet untuk menjadi sesuatu

00:08:28.260 --> 00:08:30.260
yang kita impikan.

00:08:30.260 --> 00:08:33.260
Kita membutuhkannya untuk menghubungkan kita semua.

00:08:33.260 --> 00:08:36.260
Kita membutuhkannya untuk memperkenalkan kita kepada pemikiran baru

00:08:36.260 --> 00:08:39.260
dan orang-orang baru dan perspektif berbeda.

00:08:40.260 --> 00:08:42.260
Dan itu tidak akan terjadi

00:08:42.260 --> 00:08:45.260
jika kita menjadi terisolasi di satu Web.

00:08:45.260 --> 00:08:47.260
Terima kasih.

00:08:47.260 --> 00:08:58.260
(Tepuk tangan)

