WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Smaranda Farnoaga
Corector: Ariana Bleau Lugo

00:00:15.260 --> 00:00:17.260
Mark Zuckerberg a fost întrebat

00:00:17.260 --> 00:00:20.260
despre știrile personalizate 'News Feed' de pe Facebook.

00:00:20.260 --> 00:00:22.260
Jurnalistul l-a întrebat:

00:00:22.260 --> 00:00:24.260
"De ce sunt atât de importante?"

00:00:24.260 --> 00:00:26.260
Iar Zuckerberg a răspuns:

00:00:26.260 --> 00:00:28.260
"O veveriță care moare pe gazonul din fața casei

00:00:28.260 --> 00:00:31.260
poate fi mai relevantă pentru interesele tale momentane

00:00:31.260 --> 00:00:34.260
decât oamenii care mor în Africa."

00:00:34.260 --> 00:00:36.260
Vreau să vă vorbesc

00:00:36.260 --> 00:00:39.260
despre cum arată Internetul bazat pe această idee de relevanță.

00:00:40.260 --> 00:00:42.260
Când eram copil și locuiam

00:00:42.260 --> 00:00:44.260
într-o zonă rurală din statul Maine,

00:00:44.260 --> 00:00:47.260
Internetul însemna ceva foarte diferit pentru mine.

00:00:47.260 --> 00:00:49.260
Însemna o legatură cu lumea.

00:00:49.260 --> 00:00:52.260
Însemna ceva ce ne putea uni pe toți.

00:00:52.260 --> 00:00:55.260
Eram sigur că urma să fie grozav pentru democrație

00:00:55.260 --> 00:00:58.260
și pentru societatea noastră.

00:00:58.260 --> 00:01:00.260
Însă s-a petrecut o deviere

00:01:00.260 --> 00:01:02.260
în modul cum circulă informația on-line,

00:01:02.260 --> 00:01:05.260
iar această abatere e invizibilă.

00:01:05.260 --> 00:01:07.260
Dacă nu suntem atenți

00:01:07.260 --> 00:01:10.260
poate deveni o problemă gravă.

00:01:10.260 --> 00:01:13.260
Prima dată am observat asta într-un loc unde petrec mult timp --

00:01:13.260 --> 00:01:15.260
pagina mea de Facebook.

00:01:15.260 --> 00:01:18.260
Din punct de vedere politic, eu sunt progresist -- nu-i surpriză aici --

00:01:18.260 --> 00:01:20.260
dar m-am străduit mereu să cunosc conservatori.

00:01:20.260 --> 00:01:22.260
Îmi place să aud părerile lor;

00:01:22.260 --> 00:01:24.260
îmi place să văd ce link-uri postează,

00:01:24.260 --> 00:01:26.260
îmi place să învăț lucruri.

00:01:26.260 --> 00:01:29.260
Astfel, am fost foarte surprins să observ într-o zi

00:01:29.260 --> 00:01:32.260
că toți conservatorii dispăruseră din feed-ul meu de pe Facebook.

00:01:33.260 --> 00:01:35.260
Iar ce se întâmplase

00:01:35.260 --> 00:01:39.260
era că Facebook se uita la ce link-uri apăsam

00:01:39.260 --> 00:01:41.260
și a observat că apăsam

00:01:41.260 --> 00:01:43.260
mai mult pe link-urile prietenilor liberali

00:01:43.260 --> 00:01:46.260
decât pe ale prietenilor conservatori.

00:01:46.260 --> 00:01:48.260
Și, fără să mă consulte,

00:01:48.260 --> 00:01:50.260
îi ștersese.

00:01:50.260 --> 00:01:53.260
Dispăruseră.

00:01:54.260 --> 00:01:56.260
Facebook nu este singurul loc

00:01:56.260 --> 00:01:58.260
care face acest fel de

00:01:58.260 --> 00:02:01.260
editare algoritmică, invizibilă a Internetului.

00:02:01.260 --> 00:02:03.260
Și Google face la fel.

00:02:03.260 --> 00:02:06.260
Dacă eu caut ceva și tu cauți același lucru,

00:02:06.260 --> 00:02:08.260
chiar acum, în același moment,

00:02:08.260 --> 00:02:11.260
am obține rezultate de căutare total diferite.

00:02:11.260 --> 00:02:14.260
Chiar dacă nu ești logat, mi-a spus un inginer,

00:02:14.260 --> 00:02:16.260
există 57 de semnale

00:02:16.260 --> 00:02:19.260
la care se uită Google --

00:02:19.260 --> 00:02:22.260
totul: ce fel de computer folosești,

00:02:22.260 --> 00:02:24.260
ce fel de browser utilizezi,

00:02:24.260 --> 00:02:26.260
locul în care te afli --

00:02:26.260 --> 00:02:29.260
pe care le folosește pentru a personaliza rezulatatele căutarii.

00:02:29.260 --> 00:02:31.260
Gândiți-vă pentru un moment:

00:02:31.260 --> 00:02:35.260
nu mai există un Google standard.

00:02:35.260 --> 00:02:38.260
Și e ciudat că-i foarte greu să observi asta.

00:02:38.260 --> 00:02:40.260
Nu vezi cât de diferite sunt rezultatele căutării tale

00:02:40.260 --> 00:02:42.260
față de ale altcuiva.

00:02:42.260 --> 00:02:44.260
Acum vreo două săptămâni

00:02:44.260 --> 00:02:47.260
am rugat câțiva prieteni să caute pe Google cuvântul "Egipt"

00:02:47.260 --> 00:02:50.260
și să-mi trimită imaginea ecranului obținut.

00:02:50.260 --> 00:02:53.260
Iată imaginea de la prietenul meu Scott.

00:02:54.260 --> 00:02:57.260
Iar aici e imaginea de la prietenul meu Daniel.

00:02:57.260 --> 00:02:59.260
Când le pui una lângă cealaltă,

00:02:59.260 --> 00:03:01.260
nici nu trebuie să citești link-urile

00:03:01.260 --> 00:03:03.260
ca să vezi cât de diferite sunt aceste două pagini.

00:03:03.260 --> 00:03:05.260
Dar când citești link-urile,

00:03:05.260 --> 00:03:08.260
diferența e remarcabilă.

00:03:09.260 --> 00:03:12.260
Daniel nu avea nimic despre protestele din Egipt

00:03:12.260 --> 00:03:14.260
în prima pagină de rezultate Google.

00:03:14.260 --> 00:03:16.260
Rezultatele lui Scott erau pline de menționări.

00:03:16.260 --> 00:03:18.260
Iar asta era marea știre a zilei atunci.

00:03:18.260 --> 00:03:21.260
Iată cât de diferite devin aceste rezultate.

00:03:21.260 --> 00:03:24.260
Dar nu e vorba numai de Google și Facebook.

00:03:24.260 --> 00:03:26.260
E un fenomen care traversează tot Internetul.

00:03:26.260 --> 00:03:29.260
O mulțime de companii fac astfel de personalizari.

00:03:29.260 --> 00:03:32.260
Yahoo News, cel mai mare site de știri de pe Internet

00:03:32.260 --> 00:03:35.260
e personalizat acum -- oameni diferiți primesc răspunsuri diferite.

00:03:36.260 --> 00:03:39.260
Huffington Post, Washington Post, The New York Times --

00:03:39.260 --> 00:03:42.260
toți personalizează cu diverse filtre.

00:03:42.260 --> 00:03:45.260
Iar asta ne împinge foarte rapid

00:03:45.260 --> 00:03:47.260
către o lume în care

00:03:47.260 --> 00:03:51.260
Internetul ne oferă ce crede că vrem să vedem,

00:03:51.260 --> 00:03:54.260
dar nu neaparat ce avem nevoie să vedem.

00:03:54.260 --> 00:03:57.260
După cum spnea Eric Schmidt,

00:03:57.260 --> 00:04:00.260
"Va fi foarte greu ca oamenii să se uite sau să consume ceva

00:04:00.260 --> 00:04:02.260
care nu a fost, într-un fel

00:04:02.260 --> 00:04:05.260
croit pentru ei."

00:04:05.260 --> 00:04:07.260
Eu cred că asta e o problemă.

00:04:07.260 --> 00:04:10.260
Și cred că dacă iei împreună toate aceste filtre,

00:04:10.260 --> 00:04:12.260
iei toți acești algoritmi,

00:04:12.260 --> 00:04:15.260
obții un turn de fildeș, un spațiu filtrat.

00:04:16.260 --> 00:04:19.260
Iar turnul tău de fildeș este

00:04:19.260 --> 00:04:21.260
universul tău personal de informație

00:04:21.260 --> 00:04:23.260
în care trăiești on-line.

00:04:23.260 --> 00:04:26.260
Iar ce se află în această proximitate filtrată

00:04:26.260 --> 00:04:29.260
depinde de cine ești și ce faci.

00:04:29.260 --> 00:04:33.260
Problema însă e că nu tu decizi ce intră în acest spațiu.

00:04:33.260 --> 00:04:35.260
Chiar mai important,

00:04:35.260 --> 00:04:38.260
nu vezi ce se șterge.

00:04:38.260 --> 00:04:40.260
Așa că, una din problemele cu filtrarea

00:04:40.260 --> 00:04:43.260
a fost descoperită de niște cercetători la Netflix.

00:04:43.260 --> 00:04:46.260
Ei se uitau la listele Netflix și au observat ceva ciudat

00:04:46.260 --> 00:04:48.260
ce probabil mulți am observat,

00:04:48.260 --> 00:04:50.260
și anume că există unele filme

00:04:50.260 --> 00:04:53.260
care apar imediat la noi în casă.

00:04:53.260 --> 00:04:56.260
Cum intră în listă sunt ditecționate imediat către noi.

00:04:56.260 --> 00:04:58.260
Astfel, "Iron Man" apare imediat,

00:04:58.260 --> 00:05:00.260
iar "Waiting for Superman"

00:05:00.260 --> 00:05:02.260
poate aștepta mult timp.

00:05:02.260 --> 00:05:04.260
Ceea ce au descoperit

00:05:04.260 --> 00:05:06.260
a fost că în listele noastre de Netflix

00:05:06.260 --> 00:05:09.260
se duce o luptă crâncenă între

00:05:09.260 --> 00:05:12.260
aspirațiile eu-lui nostru viitor

00:05:12.260 --> 00:05:15.260
și eu-ul mai impulsiv din prezent.

00:05:15.260 --> 00:05:17.260
Toți vrem să fim cineva

00:05:17.260 --> 00:05:19.260
care a vizionat filmul 'Rashomon',

00:05:19.260 --> 00:05:21.260
însă momentan,

00:05:21.260 --> 00:05:24.260
vrem să ne uităm la Ace Ventura a patra oara.

00:05:24.260 --> 00:05:27.260
(Râsete)

00:05:27.260 --> 00:05:29.260
O editare bună ne dă puțin din amândouă.

00:05:29.260 --> 00:05:31.260
Ne dă un pic de Justin Bieber

00:05:31.260 --> 00:05:33.260
și un pic de Afganistan.

00:05:33.260 --> 00:05:35.260
Ne hrănește și cu ceva informații-vegetale

00:05:35.260 --> 00:05:38.260
și cu informații-desert.

00:05:38.260 --> 00:05:40.260
Problema cu aceste filtre algoritmice,

00:05:40.260 --> 00:05:42.260
aceste filtre personalizate,

00:05:42.260 --> 00:05:44.260
e că se uită în principal

00:05:44.260 --> 00:05:48.260
la ce ai apăsat prima dată

00:05:48.260 --> 00:05:52.260
și pot dezechilibra acea balanță.

00:05:52.260 --> 00:05:55.260
În loc de o dieta informațională echilibrată

00:05:55.260 --> 00:05:57.260
ajungi să fi înconjurat

00:05:57.260 --> 00:05:59.260
de informații - junk-food.

00:05:59.260 --> 00:06:01.260
Asta sugrează de fapt

00:06:01.260 --> 00:06:04.260
că poate înțelegem greșit rolul Internetului.

00:06:04.260 --> 00:06:06.260
Într-o societate de transmisiuni --

00:06:06.260 --> 00:06:08.260
așa spune mitologia fondării --

00:06:08.260 --> 00:06:10.260
într-o societate de transmisiuni

00:06:10.260 --> 00:06:12.260
existau acești paznici care editau

00:06:12.260 --> 00:06:15.260
și controlau fluxul informațiilor.

00:06:15.260 --> 00:06:18.260
Când a apărut Internetul au fost înlăturați

00:06:18.260 --> 00:06:20.260
și ne-a permis tuturor să ne conectăm împreună

00:06:20.260 --> 00:06:22.260
și a fost grozav.

00:06:22.260 --> 00:06:25.260
Dar nu asta se întamplă acum.

00:06:26.260 --> 00:06:29.260
Ce vedem e mai degrabă predarea torței

00:06:29.260 --> 00:06:31.260
de la paznicii umani

00:06:31.260 --> 00:06:34.260
la cei algoritmici.

00:06:34.260 --> 00:06:37.260
Dar algoritmii

00:06:37.260 --> 00:06:40.260
nu au încă încorporat genul de etică

00:06:40.260 --> 00:06:43.260
pe care-l aveau editorii.

00:06:43.260 --> 00:06:46.260
Iar dacă algoritmii ne vor filtra lumea,

00:06:46.260 --> 00:06:49.260
dacă ei vor decide ce vedem și ce nu

00:06:49.260 --> 00:06:51.260
atunci trebuie să ne asigurăm

00:06:51.260 --> 00:06:54.260
că nu sunt ajustate doar de relevanță.

00:06:54.260 --> 00:06:56.260
Trebuie să ne asigurăm că ne arată și lucruri

00:06:56.260 --> 00:06:59.260
incomode, provocatoare sau importante --

00:06:59.260 --> 00:07:01.260
cum face TED --

00:07:01.260 --> 00:07:03.260
unghiuri opozante.

00:07:03.260 --> 00:07:05.260
Am mai fost în trecut

00:07:05.260 --> 00:07:07.260
în această situație ca societate.

00:07:08.260 --> 00:07:11.260
În 1915 ziarele nu se străduiau prea mult

00:07:11.260 --> 00:07:14.260
cu responsabilitățiile lor civice.

00:07:14.260 --> 00:07:16.260
Apoi oamenii au observat

00:07:16.260 --> 00:07:19.260
că făceau ceva foarte important.

00:07:19.260 --> 00:07:21.260
Au realizat că nu puteai să ai

00:07:21.260 --> 00:07:23.260
o democrație funcțională

00:07:23.260 --> 00:07:27.260
dacă cetățenii nu primeau un flux de informații bun.

00:07:28.260 --> 00:07:31.260
La început ziarele criticau și filtrau,

00:07:31.260 --> 00:07:33.260
dar apoi s-a dezvoltat etica jurnalistică.

00:07:33.260 --> 00:07:35.260
Nu era perfect,

00:07:35.260 --> 00:07:38.260
dar ne-au servit bine secolul trecut.

00:07:38.260 --> 00:07:40.260
Dar acum într-un fel

00:07:40.260 --> 00:07:43.260
ne-am întors în 1915 pe Internet.

00:07:44.260 --> 00:07:47.260
Avem nevoie de paznici noi

00:07:47.260 --> 00:07:49.260
care să includă acea responsabilitate

00:07:49.260 --> 00:07:51.260
în codul pe care-l scriu.

00:07:51.260 --> 00:07:54.260
Știu că sunt aici mulți de la Facebook și Google --

00:07:54.260 --> 00:07:56.260
Larry și Sergey -

00:07:56.260 --> 00:07:58.260
care au ajutat la construirea Internetului actual

00:07:58.260 --> 00:08:00.260
și sunt recunoscător pentru asta.

00:08:00.260 --> 00:08:03.260
Dar trebuie să ne asigurăm

00:08:03.260 --> 00:08:06.260
că acești algoritmi conțin în codul lor

00:08:06.260 --> 00:08:09.260
un sens al vieții publice, un simț al responsabilității civice.

00:08:09.260 --> 00:08:12.260
Trebuie să ne asigurăm că sunt suficient de transparenți

00:08:12.260 --> 00:08:14.260
încât să vedem regulile

00:08:14.260 --> 00:08:17.260
care determină ce trece de filtrele noastre.

00:08:17.260 --> 00:08:19.260
Și avem nevoie să ne redați controlul

00:08:19.260 --> 00:08:21.260
să putem decide

00:08:21.260 --> 00:08:24.260
ce trece și ce nu trece.

00:08:24.260 --> 00:08:26.260
Deoarece eu cred

00:08:26.260 --> 00:08:28.260
că Internetul trebuie să fie acel lucru

00:08:28.260 --> 00:08:30.260
la care toți am visat că va fi.

00:08:30.260 --> 00:08:33.260
Avem nevoie să ne aducă pe toți împreună.

00:08:33.260 --> 00:08:36.260
Avem nevoie să ne expună la idei noi,

00:08:36.260 --> 00:08:39.260
oameni noi și perspective diferite.

00:08:40.260 --> 00:08:42.260
Iar asta nu se va întâmpla

00:08:42.260 --> 00:08:45.260
dacă ne izolează într-un Internet de o persoană.

00:08:45.260 --> 00:08:47.260
Vă mulțumesc.

00:08:47.260 --> 00:08:58.260
(Aplauze)

