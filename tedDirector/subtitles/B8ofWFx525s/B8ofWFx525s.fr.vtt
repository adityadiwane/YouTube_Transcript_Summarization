WEBVTT
Kind: captions
Language: fr

00:00:00.000 --> 00:00:07.000
Traducteur: Amélie Gourdon
Relecteur: Elaine Green

00:00:15.260 --> 00:00:17.260
Mark Zuckerberg [créateur de Facebook],

00:00:17.260 --> 00:00:20.260
un journaliste lui posait une question à propos du fil d’actualité.

00:00:20.260 --> 00:00:22.260
Et le journaliste lui demandait

00:00:22.260 --> 00:00:24.260
"Pourquoi est-ce si important ?"

00:00:24.260 --> 00:00:26.260
Et Zuckerberg a dit,

00:00:26.260 --> 00:00:28.260
"Un écureuil mourant dans votre jardin

00:00:28.260 --> 00:00:31.260
peut être plus pertinent pour vos intérêts du moment

00:00:31.260 --> 00:00:34.260
que les gens qui meurent en Afrique."

00:00:34.260 --> 00:00:36.260
Et je veux parler

00:00:36.260 --> 00:00:39.260
de ce à quoi ressemblerait un internet basé sur cette idée de pertinence.

00:00:40.260 --> 00:00:42.260
Alors, pendant que je grandissais

00:00:42.260 --> 00:00:44.260
dans une région vraiment rurale du Maine [États-Unis],

00:00:44.260 --> 00:00:47.260
l'internet signifiait quelque chose de vraiment différent pour moi.

00:00:47.260 --> 00:00:49.260
Cela signifiait une connexion avec le monde.

00:00:49.260 --> 00:00:52.260
Ça signifiait quelque chose qui nous connecterait tous ensemble.

00:00:52.260 --> 00:00:55.260
Et j'étais sûr que ça allait être formidable pour la démocratie

00:00:55.260 --> 00:00:58.260
et pour notre société.

00:00:58.260 --> 00:01:00.260
Mais il y a ce changement

00:01:00.260 --> 00:01:02.260
dans la façon dont l'information circule en ligne,

00:01:02.260 --> 00:01:05.260
et c'est invisible.

00:01:05.260 --> 00:01:07.260
Et si nous n'y prêtons pas attention,

00:01:07.260 --> 00:01:10.260
cela pourrait être un réel problème.

00:01:10.260 --> 00:01:13.260
Alors, j'ai d'abord remarqué cela dans un espace où je passe beaucoup de temps --

00:01:13.260 --> 00:01:15.260
ma page Facebook.

00:01:15.260 --> 00:01:18.260
Je suis progressiste, politiquement -- grande surprise --

00:01:18.260 --> 00:01:20.260
mais je me suis toujours démené pour rencontrer des conservateurs.

00:01:20.260 --> 00:01:22.260
J'aime écouter ce qu'ils pensent ;

00:01:22.260 --> 00:01:24.260
j'aime voir à quoi ils se connectent ;

00:01:24.260 --> 00:01:26.260
j'aime apprendre une chose ou deux.

00:01:26.260 --> 00:01:29.260
Et donc j'ai été surpris quand un jour j'ai remarqué

00:01:29.260 --> 00:01:32.260
que les conservateurs avaient disparu de mon fil Facebook.

00:01:33.260 --> 00:01:35.260
Et ce qu'il apparut qu'il se passait

00:01:35.260 --> 00:01:39.260
est que Facebook regardait chaque lien que je cliquais,

00:01:39.260 --> 00:01:41.260
et s'apercevait qu'en fait,

00:01:41.260 --> 00:01:43.260
je cliquais plus souvent les liens de mes amis libéraux

00:01:43.260 --> 00:01:46.260
que les liens de mes amis conservateurs.

00:01:46.260 --> 00:01:48.260
Et sans me consulter à ce propos,

00:01:48.260 --> 00:01:50.260
Facebook les avait éliminés.

00:01:50.260 --> 00:01:53.260
Ils avaient disparus.

00:01:54.260 --> 00:01:56.260
Alors Facebook n'est pas le seul espace

00:01:56.260 --> 00:01:58.260
à opérer ce genre d'algorithme invisible

00:01:58.260 --> 00:02:01.260
triant l'internet.

00:02:01.260 --> 00:02:03.260
Google le fait aussi.

00:02:03.260 --> 00:02:06.260
Si je cherche quelque chose et que vous cherchez quelque chose,

00:02:06.260 --> 00:02:08.260
quand même maintenant exactement au même moment,

00:02:08.260 --> 00:02:11.260
nous pourrions obtenir des résultats différents.

00:02:11.260 --> 00:02:14.260
Même si vous êtes déconnectés, un ingénieur m'a dit,

00:02:14.260 --> 00:02:16.260
il y a 57 indicateurs

00:02:16.260 --> 00:02:19.260
que Google regarde --

00:02:19.260 --> 00:02:22.260
tout du type d'ordinateur depuis lequel vous surfez

00:02:22.260 --> 00:02:24.260
jusqu'au type de navigateur que vous utilisez

00:02:24.260 --> 00:02:26.260
en passant par votre location géographique --

00:02:26.260 --> 00:02:29.260
et qui sont utilisés pour personnaliser vos résultats de recherche.

00:02:29.260 --> 00:02:31.260
Pensez-y une seconde :

00:02:31.260 --> 00:02:35.260
il n'y a plus de Google générique.

00:02:35.260 --> 00:02:38.260
Et vous savez, ce qui est drôle dans cette histoire, c'est que c'est difficile à percevoir.

00:02:38.260 --> 00:02:40.260
Vous ne pouvez pas voir à quel point vos résultats de recherche sont différents

00:02:40.260 --> 00:02:42.260
de ceux de n'importe qui d'autre.

00:02:42.260 --> 00:02:44.260
Mais il y a quelques semaines,

00:02:44.260 --> 00:02:47.260
j'ai demandé à quelques amis de chercher "Égypte" sur Google

00:02:47.260 --> 00:02:50.260
et de m'envoyer des captures d'écrans de ce qu'ils avaient obtenu.

00:02:50.260 --> 00:02:53.260
Donc, voici ce que mon ami Scott a obtenu.

00:02:54.260 --> 00:02:57.260
Et voilà ce que mon ami Daniel a trouvé.

00:02:57.260 --> 00:02:59.260
Quand vous mettez leurs résultats côte-à-côte,

00:02:59.260 --> 00:03:01.260
vous n'avez même pas besoin de lire les liens

00:03:01.260 --> 00:03:03.260
pour voir à quel point ces deux pages sont différentes.

00:03:03.260 --> 00:03:05.260
Mais si vous lisez les liens,

00:03:05.260 --> 00:03:08.260
c'est tout à fait remarquable.

00:03:09.260 --> 00:03:12.260
Daniel n'a rien obtenu du tout concernant les manifestations en Égypte

00:03:12.260 --> 00:03:14.260
sur sa première page de résultats donnés par Google.

00:03:14.260 --> 00:03:16.260
Les résultats de Scott en étaient pleins.

00:03:16.260 --> 00:03:18.260
Et ça faisait les gros titres chaque jour à l'époque.

00:03:18.260 --> 00:03:21.260
C'est à ce point que les résultats deviennent différents.

00:03:21.260 --> 00:03:24.260
Alors, ce n'est pas juste Google et Facebook.

00:03:24.260 --> 00:03:26.260
Il s'agit de quelque chose qui balaye l'internet.

00:03:26.260 --> 00:03:29.260
Il y a tout un tas d'entreprises qui pratiquent ce genre de personnalisation.

00:03:29.260 --> 00:03:32.260
Yahoo Actualités, le plus grand site d'actualité sur internet,

00:03:32.260 --> 00:03:35.260
est maintenant personnalisé -- différentes personnes voient différentes choses.

00:03:36.260 --> 00:03:39.260
Le Huffington Post, le Washington Post, le New York Times --

00:03:39.260 --> 00:03:42.260
tous flirtent avec la personnalisation d'une façon ou d'une autre.

00:03:42.260 --> 00:03:45.260
Et cela nous emmène très rapidement

00:03:45.260 --> 00:03:47.260
vers un monde dans lequel

00:03:47.260 --> 00:03:51.260
l'internet nous montre ce qu'il pense que nous voulons voir,

00:03:51.260 --> 00:03:54.260
mais pas nécessairement ce que nous avons besoin de voir.

00:03:54.260 --> 00:03:57.260
Comme l'a dit Eric Schmidt [président de Google],

00:03:57.260 --> 00:04:00.260
"Il sera très difficile pour les gens de regarder ou de consommer

00:04:00.260 --> 00:04:02.260
ce qui n'a pas d'une certaine façon

00:04:02.260 --> 00:04:05.260
été fait sur mesure pour eux."

00:04:05.260 --> 00:04:07.260
Donc je pense que c'est un réel problème.

00:04:07.260 --> 00:04:10.260
Et je pense que, si vous prenez tous ces filtres ensemble,

00:04:10.260 --> 00:04:12.260
si vous prenez tous ces algorithmes,

00:04:12.260 --> 00:04:15.260
vous obtenez ce que j'appelle une bulle de filtres.

00:04:16.260 --> 00:04:19.260
Et votre bulle de filtres est votre propre, personnel,

00:04:19.260 --> 00:04:21.260
unique univers d'information

00:04:21.260 --> 00:04:23.260
dans lequel vous vivez en ligne.

00:04:23.260 --> 00:04:26.260
Et ce qui est dans votre bulle de filtres

00:04:26.260 --> 00:04:29.260
dépend de qui vous êtes, et dépend de que vous faites.

00:04:29.260 --> 00:04:33.260
Mais le truc, c'est que vous ne décidez pas ce qui entre dedans.

00:04:33.260 --> 00:04:35.260
Et plus important,

00:04:35.260 --> 00:04:38.260
vous ne voyez pas en fait ce qui se trouve rejeté.

00:04:38.260 --> 00:04:40.260
Donc l'un des problèmes de la bulle de filtres

00:04:40.260 --> 00:04:43.260
a été découvert par des chercheurs de chez Netflix [site de vidéo à la demande].

00:04:43.260 --> 00:04:46.260
Ils étudiaient les files d'attentes Netflix, et ont remarqué une chose assez drôle,

00:04:46.260 --> 00:04:48.260
que beaucoup d'entre nous ont certainement remarqué,

00:04:48.260 --> 00:04:50.260
et qui est qu'il y a certains films

00:04:50.260 --> 00:04:53.260
qui semblent juste remonter la file très vite pour entrer dans nos foyers.

00:04:53.260 --> 00:04:56.260
Ils entrent dans la file, et ils la remontent immédiatement.

00:04:56.260 --> 00:04:58.260
Donc "Iron Man" arrive aussitôt,

00:04:58.260 --> 00:05:00.260
et "Waiting for Superman"

00:05:00.260 --> 00:05:02.260
peut attendre vraiment très longtemps.

00:05:02.260 --> 00:05:04.260
Ce qu'ils ont découvert

00:05:04.260 --> 00:05:06.260
c'est que dans les files d'attente de Netflix,

00:05:06.260 --> 00:05:09.260
il y a une bataille épique qui se joue

00:05:09.260 --> 00:05:12.260
entre ce que nous aspirons à être dans le futur

00:05:12.260 --> 00:05:15.260
et ce que nous sommes plus impulsivement dans le présent.

00:05:15.260 --> 00:05:17.260
Vous savez, nous voulons tous être quelqu'un

00:05:17.260 --> 00:05:19.260
qui a vu "Rashōmon",

00:05:19.260 --> 00:05:21.260
mais pour le moment

00:05:21.260 --> 00:05:24.260
nous voulons voir "Ace Ventura, détective chiens et chats" pour la quatrième fois.

00:05:24.260 --> 00:05:27.260
(Rires)

00:05:27.260 --> 00:05:29.260
Donc la meilleure des éditions nous donne un peu des deux.

00:05:29.260 --> 00:05:31.260
Il nous donne un petit peu de Justin Bieber

00:05:31.260 --> 00:05:33.260
et un petit peu d'Afghanistan.

00:05:33.260 --> 00:05:35.260
Il nous donne de l'information "légumes",

00:05:35.260 --> 00:05:38.260
il nous donne de l'information "dessert".

00:05:38.260 --> 00:05:40.260
Et le défi avec ce genre de filtres algorithmiques,

00:05:40.260 --> 00:05:42.260
ces filtres personnalisés,

00:05:42.260 --> 00:05:44.260
c'est que, parce qu'ils observent principalement

00:05:44.260 --> 00:05:48.260
ce que vous cliquez en premier,

00:05:48.260 --> 00:05:52.260
ça peut déstabiliser cet équilibre.

00:05:52.260 --> 00:05:55.260
Et au lieu d'un régime d'information équilibré,

00:05:55.260 --> 00:05:57.260
vous pouvez finir entouré

00:05:57.260 --> 00:05:59.260
d'information "malbouffe".

00:05:59.260 --> 00:06:01.260
Ce que cela suggère

00:06:01.260 --> 00:06:04.260
c'est en fait que nous pourrions avoir fait fausse route à propos d'internet.

00:06:04.260 --> 00:06:06.260
Dans une société de diffusion --

00:06:06.260 --> 00:06:08.260
comme disent les mythes fondateurs --

00:06:08.260 --> 00:06:10.260
dans une société de diffusion,

00:06:10.260 --> 00:06:12.260
il y avait ces gardiens du temple, les éditeurs,

00:06:12.260 --> 00:06:15.260
et ils contrôlaient les flux d'information.

00:06:15.260 --> 00:06:18.260
Et puis l'internet est arrivé et les a balayé du chemin,

00:06:18.260 --> 00:06:20.260
nous permettant tous de nous connecter,

00:06:20.260 --> 00:06:22.260
et c'était génial.

00:06:22.260 --> 00:06:25.260
Mais ce n'est pas ce qui se passe en fait à l'heure actuelle.

00:06:26.260 --> 00:06:29.260
Ce que nous voyons est plus un passage de témoin

00:06:29.260 --> 00:06:31.260
des gardiens humains

00:06:31.260 --> 00:06:34.260
aux gardiens algorithmiques.

00:06:34.260 --> 00:06:37.260
Et le problème c'est que les algorithmes

00:06:37.260 --> 00:06:40.260
n'ont pas encore le genre d'éthique intégrée

00:06:40.260 --> 00:06:43.260
que les éditeurs avaient.

00:06:43.260 --> 00:06:46.260
Donc si les algorithmes vont inventorier le monde pour nous,

00:06:46.260 --> 00:06:49.260
s'ils vont décider ce que nous pouvons voir et ce que nous ne pouvons pas voir,

00:06:49.260 --> 00:06:51.260
alors nous devons nous assurer

00:06:51.260 --> 00:06:54.260
qu'ils ne se sont pas basés uniquement sur la pertinence.

00:06:54.260 --> 00:06:56.260
Nous devons nous assurer qu'ils nous montrent aussi des choses

00:06:56.260 --> 00:06:59.260
qui sont inconfortables ou stimulantes ou importantes --

00:06:59.260 --> 00:07:01.260
c'est ce que TED fait --

00:07:01.260 --> 00:07:03.260
d'autres points de vue.

00:07:03.260 --> 00:07:05.260
Et le fait est que nous avons déjà été dans cette situation auparavant,

00:07:05.260 --> 00:07:07.260
en tant que société.

00:07:08.260 --> 00:07:11.260
En 1915, ce n'est pas comme si les journaux avaient des suées

00:07:11.260 --> 00:07:14.260
à propos de leurs responsabilités civiques.

00:07:14.260 --> 00:07:16.260
Et alors les gens ont remarqué

00:07:16.260 --> 00:07:19.260
qu'ils faisaient quelque chose de vraiment important.

00:07:19.260 --> 00:07:21.260
Qu'en fait, vous ne pourriez pas avoir

00:07:21.260 --> 00:07:23.260
une démocratie qui fonctionne

00:07:23.260 --> 00:07:27.260
si les citoyens n'avaient pas accès à un bon flot d'information.

00:07:28.260 --> 00:07:31.260
Que les journaux étaient cruciaux, parce qu'ils agissaient en tant que filtre,

00:07:31.260 --> 00:07:33.260
et alors l'éthique journalistique s'est développée.

00:07:33.260 --> 00:07:35.260
Ce n'était pas parfait,

00:07:35.260 --> 00:07:38.260
mais ça nous a menés à travers le siècle dernier.

00:07:38.260 --> 00:07:40.260
Et donc maintenant,

00:07:40.260 --> 00:07:43.260
on est en sorte retourné en 1915 sur internet.

00:07:44.260 --> 00:07:47.260
Et nous avons besoin que les nouveaux gardiens

00:07:47.260 --> 00:07:49.260
incorporent cette espèce de responsabilité

00:07:49.260 --> 00:07:51.260
dans le code qu'ils sont en train d'écrire.

00:07:51.260 --> 00:07:54.260
Je sais qu'il y a beaucoup de gens ici de Facebook et Google --

00:07:54.260 --> 00:07:56.260
Larry et Sergey --

00:07:56.260 --> 00:07:58.260
des gens qui ont contribué à construire internet tel qu'il est,

00:07:58.260 --> 00:08:00.260
et j'ai de la gratitude pour ça.

00:08:00.260 --> 00:08:03.260
Mais nous avons vraiment besoin que vous vous assuriez

00:08:03.260 --> 00:08:06.260
que ces algorithmes incorporent

00:08:06.260 --> 00:08:09.260
une sensibilité pour la vie publique, sensibilité pour la responsabilité civique.

00:08:09.260 --> 00:08:12.260
Nous avons besoin que vous vous assuriez qu'ils sont suffisamment transparents

00:08:12.260 --> 00:08:14.260
pour que nous puissions voir quelles sont les règles

00:08:14.260 --> 00:08:17.260
qui déterminent ce qui passe à travers les filtres.

00:08:17.260 --> 00:08:19.260
Et nous avons besoin que vous nous donniez du contrôle,

00:08:19.260 --> 00:08:21.260
pour que nous puissions décider

00:08:21.260 --> 00:08:24.260
ce qui passe les filtres et ce qui ne les passe pas.

00:08:24.260 --> 00:08:26.260
Parce que je pense

00:08:26.260 --> 00:08:28.260
que nous avons vraiment besoin qu'internet soit cette chose

00:08:28.260 --> 00:08:30.260
que nous avons tous rêvée qu'il serait.

00:08:30.260 --> 00:08:33.260
Nous avons besoin qu'il nous connecte tous ensemble.

00:08:33.260 --> 00:08:36.260
Nous avons besoin qu'il nous fasse connaître de nouvelles idées

00:08:36.260 --> 00:08:39.260
et de nouvelles personnes, de différentes perspectives.

00:08:40.260 --> 00:08:42.260
Et il ne va pas faire cela

00:08:42.260 --> 00:08:45.260
s’il nous laisse isolés dans un réseau fait d'une personne.

00:08:45.260 --> 00:08:47.260
Merci.

00:08:47.260 --> 00:08:58.260
(Applaudissements)

