WEBVTT
Kind: captions
Language: iw

00:00:00.000 --> 00:00:07.000
מתרגם: Yubal Masalker
מבקר: Ido Dekkers

00:00:15.260 --> 00:00:17.260
מארק צוקרברג,

00:00:17.260 --> 00:00:20.260
עיתונאי שאל אותו על עדכון חדשות שוטף.

00:00:20.260 --> 00:00:22.260
הוא שאל אותו,

00:00:22.260 --> 00:00:24.260
"מדוע זה כה חשוב?"

00:00:24.260 --> 00:00:26.260
וצוקרברג ענה

00:00:26.260 --> 00:00:28.260
שסנאי גוסס בחזית ביתנו

00:00:28.260 --> 00:00:31.260
עשוי להיות יותר רלוונטי לאינטרסים המיידיים שלנו

00:00:31.260 --> 00:00:34.260
מאשר אנשים גוססים באפריקה.

00:00:34.260 --> 00:00:36.260
אז ברצוני לדבר על

00:00:36.260 --> 00:00:39.260
איך אינטרנט המתבסס על הרעיון הנ"ל עשוי להיראות.

00:00:40.260 --> 00:00:42.260
כאשר גדלתי

00:00:42.260 --> 00:00:44.260
באזור כפרי במיין,

00:00:44.260 --> 00:00:47.260
האינטרנט היה בשבילי משהו אחר לגמרי.

00:00:47.260 --> 00:00:49.260
הוא היה עבורי קשר לעולם.

00:00:49.260 --> 00:00:52.260
הוא היה עבורי משהו העשוי לקשר את כולנו ביחד.

00:00:52.260 --> 00:00:55.260
והייתי בטוח שהוא הולך להיות נפלא בשביל הדמוקרטיה

00:00:55.260 --> 00:00:58.260
והחברה שלנו.

00:00:58.260 --> 00:01:00.260
אבל מול עינינו מתחולל שינוי

00:01:00.260 --> 00:01:02.260
באופן בו המידע זורם ברשת,

00:01:02.260 --> 00:01:05.260
והשינוי הוא בלתי נראה.

00:01:05.260 --> 00:01:07.260
ואם לא נשים לב לזה,

00:01:07.260 --> 00:01:10.260
זו עלולה להיות בעיה רצינית.

00:01:10.260 --> 00:01:13.260
בפעם הראשונה הבחנתי בזה היכן שאני מבלה המון זמן --

00:01:13.260 --> 00:01:15.260
דף הפייסבוק שלי.

00:01:15.260 --> 00:01:18.260
אני ליברל מבחינה פוליטית -- איזו הפתעה --

00:01:18.260 --> 00:01:20.260
אבל תמיד עשיתי הכל כדי לפגוש שמרנים.

00:01:20.260 --> 00:01:22.260
אני אוהב לשמוע על מה הם חושבים;

00:01:22.260 --> 00:01:24.260
אני אוהב לראות עם מה הם מקושרים;

00:01:24.260 --> 00:01:26.260
אני אוהב ללמוד דברים חדשים.

00:01:26.260 --> 00:01:29.260
ולכן הופתעתי כאשר הבחנתי יום אחד

00:01:29.260 --> 00:01:32.260
שהשמרנים נעלמו מעדכוני הפייסבוק שלי.

00:01:33.260 --> 00:01:35.260
ומה שהתברר הוא

00:01:35.260 --> 00:01:39.260
שפייסבוק עקבה אחריי -- על איזה קישורים אני מקליק,

00:01:39.260 --> 00:01:41.260
והיא שמה לב שבעצם

00:01:41.260 --> 00:01:43.260
אני מקליק יותר על קישורים של

00:01:43.260 --> 00:01:46.260
חברים ליברליים מאשר אלו של חברים שמרניים.

00:01:46.260 --> 00:01:48.260
ומבלי להתייעץ איתי על כך,

00:01:48.260 --> 00:01:50.260
היא סיננה אותם החוצה.

00:01:50.260 --> 00:01:53.260
הם נעלמו.

00:01:54.260 --> 00:01:56.260
אבל פייסבוק אינה המקום היחיד

00:01:56.260 --> 00:01:58.260
אשר מבצע סוג כזה של עריכה

00:01:58.260 --> 00:02:01.260
אלגוריתמית בלתי נראית ברשת.

00:02:01.260 --> 00:02:03.260
גם גוגל עושה את זה.

00:02:03.260 --> 00:02:06.260
אם אני מחפש משהו, ואתם מחפשים משהו,

00:02:06.260 --> 00:02:08.260
אפילו עכשיו, בו-זמנית,

00:02:08.260 --> 00:02:11.260
אנו עשויים לקבל תוצאות חיפוש מאוד שונות.

00:02:11.260 --> 00:02:14.260
גם כאשר יוצאים מהמערכת, סיפר לי מהנדס אחד,

00:02:14.260 --> 00:02:16.260
ישנם 57 סימנים

00:02:16.260 --> 00:02:19.260
שגוגל עוקבת אחריהם --

00:02:19.260 --> 00:02:22.260
כל דבר החל מאיזה מחשב אנו משתמשים

00:02:22.260 --> 00:02:24.260
דרך באיזה דפדפן משתמשים

00:02:24.260 --> 00:02:26.260
ועד למקום בו אנו נמצאים --

00:02:26.260 --> 00:02:29.260
והיא משתמשת בהם כדי לתפור לנו את תוצאות חיפושנו.

00:02:29.260 --> 00:02:31.260
תחשבו על זה שניה:

00:02:31.260 --> 00:02:35.260
אין יותר גוגל זהה לכולם.

00:02:35.260 --> 00:02:38.260
ומה שמצחיק בכל זה הוא שקשה להבחין בזה.

00:02:38.260 --> 00:02:40.260
אי-אפשר לראות כמה שונים תוצאות החיפוש שלך

00:02:40.260 --> 00:02:42.260
מאלו של מישהו אחר.

00:02:42.260 --> 00:02:44.260
אבל לפני כמה שבועות,

00:02:44.260 --> 00:02:47.260
ביקשתי ממספר חברים לחפש בגוגל "מצרים"

00:02:47.260 --> 00:02:50.260
ולשלוח לי צילומי מסך של התוצאות שלהם.

00:02:50.260 --> 00:02:53.260
אז הנה צילום מסך של חברי סקוט.

00:02:54.260 --> 00:02:57.260
וזה של חברי דניאל.

00:02:57.260 --> 00:02:59.260
כאשר מניחים אותם זה לצד זה,

00:02:59.260 --> 00:03:01.260
אין אפילו צורך לקרוא מה כתוב בתוצאות

00:03:01.260 --> 00:03:03.260
כדי לראות עד כמה שונים שני העמודים.

00:03:03.260 --> 00:03:05.260
אבל כאשר קוראים את התוצאות,

00:03:05.260 --> 00:03:08.260
זה באמת די מוזר.

00:03:09.260 --> 00:03:12.260
דניאל לא קיבל שום דבר על ההפגנות במצרים

00:03:12.260 --> 00:03:14.260
בעמוד הראשון של התוצאות.

00:03:14.260 --> 00:03:16.260
אבל התוצאות שסקוט קיבל מלאות בהן.

00:03:16.260 --> 00:03:18.260
וזה היה אז ה-סיפור של אותו יום.

00:03:18.260 --> 00:03:21.260
זה כמה שהתוצאות נעשות שונות.

00:03:21.260 --> 00:03:24.260
אבל זה לא רק גוגל ופייסבוק.

00:03:24.260 --> 00:03:26.260
זה משהו שסוחף איתו את כל הרשת.

00:03:26.260 --> 00:03:29.260
יש מגוון של חברות אשר מבצעות סינון אישי כזה.

00:03:29.260 --> 00:03:32.260
"חדשות יאהו", אתר החדשות הכי גדול ברשת,

00:03:32.260 --> 00:03:35.260
הוא עכשיו בעל סינון אישי -- כל אחד מקבל משהו אחר.

00:03:36.260 --> 00:03:39.260
"הפינגטון פוסט", ה"וושינגטון פוסט", ה"ניו-יורק טיימס" --

00:03:39.260 --> 00:03:42.260
כולם מפלרטטים עם סינונים אישיים באופנים שונים.

00:03:42.260 --> 00:03:45.260
וזה לוקח אותנו במהירות

00:03:45.260 --> 00:03:47.260
אל עולם שבו

00:03:47.260 --> 00:03:51.260
האינטרנט מראה לנו את מה שנדמה לו שאנו רוצים לראות,

00:03:51.260 --> 00:03:54.260
אבל לא בהכרח את מה שאנו צריכים לראות.

00:03:54.260 --> 00:03:57.260
כפי שאריק שמידט אמר,

00:03:57.260 --> 00:04:00.260
"יהיה זה בלתי אפשרי לאנשים לראות או לצרוך משהו

00:04:00.260 --> 00:04:02.260
שבמובן מסויים

00:04:02.260 --> 00:04:05.260
לא נתפר עבורם."

00:04:05.260 --> 00:04:07.260
לכן אני סבור שזו אכן בעיה.

00:04:07.260 --> 00:04:10.260
ואני חושב שאם נוטלים את כל המסננים ביחד,

00:04:10.260 --> 00:04:12.260
נוטלים את כל האלגוריתמים הללו,

00:04:12.260 --> 00:04:15.260
מקבלים את מה שאני מכנה בועת סינון.

00:04:16.260 --> 00:04:19.260
ובועת הסינון שלך היא עולם המידע האישי

00:04:19.260 --> 00:04:21.260
והמיוחד שלך

00:04:21.260 --> 00:04:23.260
שאתה חי בו ברשת.

00:04:23.260 --> 00:04:26.260
ומה שבתוך בועת הסינון שלך

00:04:26.260 --> 00:04:29.260
תלוי במי שאתה, וזה תלוי במה שאתה עושה.

00:04:29.260 --> 00:04:33.260
אבל העניין הוא שאינך מחליט מה נכנס לתוכה.

00:04:33.260 --> 00:04:35.260
ויותר חשוב,

00:04:35.260 --> 00:04:38.260
אינך רואה את מה שמסננים החוצה.

00:04:38.260 --> 00:04:40.260
את אחת הבעיות

00:04:40.260 --> 00:04:43.260
של בועות הסינון גילו כמה חוקרים מנטפליקס.

00:04:43.260 --> 00:04:46.260
הם היו מסתכלים בטורי נטפליקס והם שמו לב לדבר מצחיק

00:04:46.260 --> 00:04:48.260
שרבים מאיתנו בטח שמו לב אליו,

00:04:48.260 --> 00:04:50.260
והוא שיש כמה סרטים

00:04:50.260 --> 00:04:53.260
שמגיעים במהירות היישר לביתינו.

00:04:53.260 --> 00:04:56.260
הם נכנסים לתור ונפתחים מייד לפנינו.

00:04:56.260 --> 00:04:58.260
כך ש-"Iron man" נפתח מייד,

00:04:58.260 --> 00:05:00.260
ו-"Waiting for Superman"

00:05:00.260 --> 00:05:02.260
יכול לחכות ממש הרבה זמן.

00:05:02.260 --> 00:05:04.260
מה שהם מצאו

00:05:04.260 --> 00:05:06.260
היה שבטורי הנטפליקס שלנו

00:05:06.260 --> 00:05:09.260
מתנהל מאבק איתנים

00:05:09.260 --> 00:05:12.260
בין העצמי העתידי, השאפתני שלנו

00:05:12.260 --> 00:05:15.260
לבין העצמי היותר אימפולסיבי שלנו השייך להווה.

00:05:15.260 --> 00:05:17.260
אנו כולנו שואפים להיות זה

00:05:17.260 --> 00:05:19.260
שראה כבר את "Rashomon",

00:05:19.260 --> 00:05:21.260
אבל ברגע זה ממש

00:05:21.260 --> 00:05:24.260
אנו רוצים לצפות ב-"Ace Ventura" בפעם הרביעית.

00:05:24.260 --> 00:05:27.260
(צחוק)

00:05:27.260 --> 00:05:29.260
אז העריכה המוצלחת ביותר נותנת לנו קצת משניהם.

00:05:29.260 --> 00:05:31.260
היא נותנת לנו קצת מג'סטין ביבר

00:05:31.260 --> 00:05:33.260
וקצת מאפגניסטן.

00:05:33.260 --> 00:05:35.260
היא נותנת לנו קצת מידע על ירקות,

00:05:35.260 --> 00:05:38.260
וקצת מידע על קינוח.

00:05:38.260 --> 00:05:40.260
והקושי עם מסננים אלגוריתמיים כאלה,

00:05:40.260 --> 00:05:42.260
עם המסננים הללו המותאמים אישית,

00:05:42.260 --> 00:05:44.260
הוא שבגלל שהם מסתכלים בעיקר

00:05:44.260 --> 00:05:48.260
על מה שאנו מקליקים עליו ראשון,

00:05:48.260 --> 00:05:52.260
זה יכול להפר את האיזון.

00:05:52.260 --> 00:05:55.260
ואז במקום דיאטת מידע מאוזנת,

00:05:55.260 --> 00:05:57.260
נמצא את עצמנו מוקפים

00:05:57.260 --> 00:05:59.260
בג'נק-פוד של מידע.

00:05:59.260 --> 00:06:01.260
כל זה מצביע על כך

00:06:01.260 --> 00:06:04.260
שאנו מפספסים את כל מטרת האינטרנט.

00:06:04.260 --> 00:06:06.260
בחברה מבוססת שידורים --

00:06:06.260 --> 00:06:08.260
כך על-פי מיתוס ההיווסדות --

00:06:08.260 --> 00:06:10.260
בחברה מבוססת שידורים,

00:06:10.260 --> 00:06:12.260
היו אלה שומרי-הסף, העורכים,

00:06:12.260 --> 00:06:15.260
והם שלטו על ברז המידע.

00:06:15.260 --> 00:06:18.260
ואז בא האינטרנט וניפנף אותם הצידה,

00:06:18.260 --> 00:06:20.260
וזה איפשר לנו להתחבר זה לזה,

00:06:20.260 --> 00:06:22.260
וזה היה פשוט נפלא.

00:06:22.260 --> 00:06:25.260
אבל לא זה מה שקורה כעת.

00:06:26.260 --> 00:06:29.260
מה שאנו עדים לו זה העברת המפתחות

00:06:29.260 --> 00:06:31.260
משומרי-סף אנושיים

00:06:31.260 --> 00:06:34.260
לשומרי-סף אלגוריתמיים.

00:06:34.260 --> 00:06:37.260
והעניין הוא שהאלגוריתמים

00:06:37.260 --> 00:06:40.260
חסרים עדיין את האתיקה הפנימית

00:06:40.260 --> 00:06:43.260
שהיתה לעורכים.

00:06:43.260 --> 00:06:46.260
כך שאם האלגוריתמים הולכים לנהל לנו את העולם,

00:06:46.260 --> 00:06:49.260
אם הם הולכים להחליט מה נזכה לראות ומה לא נזכה,

00:06:49.260 --> 00:06:51.260
אז עלינו לוודא

00:06:51.260 --> 00:06:54.260
שהם לא מכווננים רק לפי מידת הרלוונטיות.

00:06:54.260 --> 00:06:56.260
עלינו לוודא שהם גם מראים לנו דברים

00:06:56.260 --> 00:06:59.260
שאינם נוחים או שהם מאתגרים או שהם חשובים --

00:06:59.260 --> 00:07:01.260
זה מה ש-TED עושה --

00:07:01.260 --> 00:07:03.260
נקודות מבט שונות.

00:07:03.260 --> 00:07:05.260
והעניין הוא שכבר היינו בסרט הזה

00:07:05.260 --> 00:07:07.260
כחברה.

00:07:08.260 --> 00:07:11.260
ב-1915, זה לא שלעיתונים היה יותר מדי איכפת

00:07:11.260 --> 00:07:14.260
מהאחריות האזרחית שלהם.

00:07:14.260 --> 00:07:16.260
ואז אנשים שמו לב

00:07:16.260 --> 00:07:19.260
שהעיתונים עושים משהו באמת חשוב.

00:07:19.260 --> 00:07:21.260
שלמעשה, קשה לקיים

00:07:21.260 --> 00:07:23.260
דמוקרטיה מתפקדת

00:07:23.260 --> 00:07:27.260
אם אזרחים לא זוכים לזרם שוטף ויעיל של מידע.

00:07:28.260 --> 00:07:31.260
שהעיתונים היו דבר קריטי, היות והם פעלו בתור מסננים,

00:07:31.260 --> 00:07:33.260
וכך התפתחה אתיקה עיתונאית.

00:07:33.260 --> 00:07:35.260
היא לא היתה מושלמת,

00:07:35.260 --> 00:07:38.260
אבל היא ליוותה אותנו בכל המאה שעברה.

00:07:38.260 --> 00:07:40.260
ועכשיו,

00:07:40.260 --> 00:07:43.260
אנו שוב בחזרה במין אותו מצב של 1915, אבל ברשת.

00:07:44.260 --> 00:07:47.260
ואנו צריכים ששומרי-הסף החדשים

00:07:47.260 --> 00:07:49.260
יקודדו את האחריות הזו,

00:07:49.260 --> 00:07:51.260
בתוך התוכנות שהם כותבים.

00:07:51.260 --> 00:07:54.260
אני יודע שיש כאן הרבה אנשים מפייסבוק וגוגל --

00:07:54.260 --> 00:07:56.260
לארי וסרגיי --

00:07:56.260 --> 00:07:58.260
אנשים שתרמו לבניית הרשת כפי שהיא,

00:07:58.260 --> 00:08:00.260
ואני אסיר-תודה על כך.

00:08:00.260 --> 00:08:03.260
אבל אנו באמת צריכים שאתם תוודאו

00:08:03.260 --> 00:08:06.260
שבתוך האלגוריתמים הללו יקודדו

00:08:06.260 --> 00:08:09.260
גם המודעות לציבור, המודעות לאחריות אזרחית.

00:08:09.260 --> 00:08:12.260
אנו צריכים שאתם תבטיחו שהם יהיו שקופים מספיק

00:08:12.260 --> 00:08:14.260
כדי שנוכל לראות מה הם הכללים

00:08:14.260 --> 00:08:17.260
אשר קובעים מה יעבור את הסינון.

00:08:17.260 --> 00:08:19.260
ואנו צריכים שתתנו לנו שליטה מסויימת,

00:08:19.260 --> 00:08:21.260
כך שנוכל להחליט

00:08:21.260 --> 00:08:24.260
מה יעבור ומה לא.

00:08:24.260 --> 00:08:26.260
כי אני סבור

00:08:26.260 --> 00:08:28.260
שאנו באמת צריכים שהאינטרנט יהיה הדבר

00:08:28.260 --> 00:08:30.260
שכולנו חלמנו שהוא יהיה.

00:08:30.260 --> 00:08:33.260
אנו צריכים שהוא יחבר את כולנו זה לזה.

00:08:33.260 --> 00:08:36.260
אנו צריכים שהוא יביא לפנינו רעיונות חדשים

00:08:36.260 --> 00:08:39.260
ואנשים חדשים ונקודות מבט שונות.

00:08:40.260 --> 00:08:42.260
וזה לא יוכל לקרות

00:08:42.260 --> 00:08:45.260
אם זה ישאיר את כולנו מבודדים ברשת השייכת ליחיד.

00:08:45.260 --> 00:08:47.260
תודה לכם.

00:08:47.260 --> 00:08:58.260
(מחיאות כפיים)

