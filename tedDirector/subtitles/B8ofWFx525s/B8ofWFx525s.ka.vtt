WEBVTT
Kind: captions
Language: ka

00:00:00.000 --> 00:00:07.000
Translator: Nana Dikhaminjia
Reviewer: Levan Lashauri

00:00:15.260 --> 00:00:17.260
მარკ ცუკერბერგს ჟურნალისტი

00:00:17.260 --> 00:00:20.260
ფეისბუკის სიახლეების ზოლის
შესახებ ეკითხებოდა.

00:00:20.260 --> 00:00:22.260
შეკითხვა იყო:

00:00:22.260 --> 00:00:24.260
„რატომ არის ეს ასეთი მნიშვნელოვანი?“

00:00:24.260 --> 00:00:26.260
ცუკერბერგმა უპასუხა:

00:00:26.260 --> 00:00:28.260
„ამ წუთას თქვენ ეზოში მომაკვდავი ციყვი,

00:00:28.260 --> 00:00:31.260
შეიძლება უფრო შეესაბამებოდეს
თქვენს ინტერესებს,

00:00:31.260 --> 00:00:34.260
ვიდრე აფრიკაში მომაკვდავი ადამიანები“

00:00:34.260 --> 00:00:36.260
დღეს მინდა ვისაუბრო იმაზე,

00:00:36.260 --> 00:00:39.590
თუ როგორი შეიძლება იყოს შესაბამისობის
ამ იდეაზე დაფუძნებული ინტერნეტი,

00:00:40.260 --> 00:00:42.260
მოზარდობის პერიოდში,

00:00:42.260 --> 00:00:44.260
მეინის შტატის ერთ-ერთ რაიონში,

00:00:44.260 --> 00:00:47.260
ინტერნეტი განსაკუთრებული რამ იყო ჩემთვის.

00:00:47.260 --> 00:00:49.260
ის ნიშნავდა კავშირს მსოფლიოსთან.

00:00:49.260 --> 00:00:52.260
ნიშნავდა იმას, რაც ყველა ჩვენგანს
ერთმანეთთან დაგვაკავშირებდა.

00:00:52.260 --> 00:00:55.260
მჯეროდა, რომ ის არაჩვეულებრივი
რამ იქნებოდა დემოკრატიისა

00:00:55.260 --> 00:00:57.850
და ჩვენი საზოგადოებისთვის.

00:00:57.850 --> 00:00:59.380
მაგრამ ახლა

00:00:59.380 --> 00:01:02.260
ინფორმაციის ონლაინ გავრცელების
წესები შეიცვალა

00:01:02.260 --> 00:01:05.260
და ეს ცვლილება უხილავია.

00:01:05.260 --> 00:01:07.260
ამ ცვლილების უყურადღებოდ დატოვება,

00:01:07.260 --> 00:01:10.260
მნიშვნელოვან პრობლემებს გამოიწვევს.

00:01:10.260 --> 00:01:13.260
პირველად ეს ცვლილება იქ შევნიშნე,
სადაც დიდ დროს ვატარებ,

00:01:13.260 --> 00:01:15.260
ჩემ ფეისბუკის გვერდზე.

00:01:15.260 --> 00:01:18.260
პოლიტიკურად პროგრესული ვარ,
რა სიურპრიზია, მაგრამ ყოველთვის

00:01:18.260 --> 00:01:20.260
ვცდილობდი კონსერვატორებთან ურთიერთობას.

00:01:20.260 --> 00:01:22.260
მინდა ვიცოდე, რაზე ფიქრობენ ისინი;

00:01:22.260 --> 00:01:24.260
მინდა ვხედავდე, თუ რასთან აიგივებენ თავს;

00:01:24.260 --> 00:01:26.260
მომწონს სიახლეების გაგება და სწავლა.

00:01:26.260 --> 00:01:29.260
და გამიკვირდა, როცა ერთ დღეს შევამჩნიე,

00:01:29.260 --> 00:01:32.260
რომ კონსერვატორები გაქრნენ 
ჩემი სიახლეების გვერდიდან.

00:01:33.260 --> 00:01:35.260
როგორც აღმოჩნდა,

00:01:35.260 --> 00:01:39.260
ფეისბუკი აკვირდებოდა, რა ბმულებს ვხსნიდი

00:01:39.260 --> 00:01:41.260
და შეამჩნია, რომ უფრო ხშირად

00:01:41.260 --> 00:01:43.260
ჩემი ლიბერალური მეგობრების ბმულებს ვხსნიდი

00:01:43.260 --> 00:01:46.260
ვიდრე კონსერვატორი მეგობრებისას

00:01:46.260 --> 00:01:48.260
და ისე, რომ არც არაფერი უკითხავს,

00:01:48.260 --> 00:01:50.260
მან ისინი ამოაგდო ჩემი სიახლეებიდან.

00:01:50.260 --> 00:01:53.480
ისინი გაქრნენ.

00:01:54.260 --> 00:01:56.260
ფეისბუქი არ არის ერთადერთი ადგილი,

00:01:56.260 --> 00:01:58.260
რომელიც ახდენს ინტერნეტის ამგვარ უხილავ,

00:01:58.260 --> 00:02:01.260
ალგორითმულ რედაქტირებას.

00:02:01.260 --> 00:02:03.260
გუგლიც იგივეს აკეთებს.

00:02:03.260 --> 00:02:06.260
თუკი მე და თქვენ ერთი და იგივე სიტყვებს
ჩავწერთ საძიებო ზოლში,

00:02:06.260 --> 00:02:08.260
თუნდაც ახლა, ერთი და იგივე დროს,

00:02:08.260 --> 00:02:11.260
ძიების განსხვავებულ შედეგებს მივიღებთ.

00:02:11.260 --> 00:02:14.260
გუგლის სისტემაში თქვენი
მომხმარებლითაც რომ არ იყოთ შესული,

00:02:14.260 --> 00:02:16.690
ერთმა ინჟინერმა მითხრა,
რომ არსებობს 57 სიგნალი,

00:02:16.690 --> 00:02:19.260
რომელსაც გუგლი აკვირდება,

00:02:19.260 --> 00:02:22.260
დაწყებული იმით, თუ როგორ კომპიუტერს

00:02:22.260 --> 00:02:24.260
და რომელ ინტერნეტ-ბრაუზერს იყენებთ,

00:02:24.260 --> 00:02:26.260
დამთავრებული თქვენი ადგილმდებარეობით

00:02:26.260 --> 00:02:29.260
და ამ სიგნალების გამოყენებით 
თქვენზე არგებს ძიების შედეგებს.

00:02:29.260 --> 00:02:31.260
დაფიქრდით ამაზე სულ ერთი წამით:

00:02:31.260 --> 00:02:35.260
უკვე აღარ არსებობს სტანდარტული გუგლი.

00:02:35.260 --> 00:02:38.260
და ყველაზე საინტერესო ისაა,
რომ ეს მოქმედება თითქმის უხილავია.

00:02:38.260 --> 00:02:40.260
თქვენ ვერ ხედავთ, როგორ განსხვავდება

00:02:40.260 --> 00:02:42.320
თქვენი ძიების შედეგები
სხვების შედეგებისგან.

00:02:42.320 --> 00:02:44.260
რამდენიმე კვირის წინ,

00:02:44.260 --> 00:02:47.260
მე ვთხოვე ჩემს მეგობრებს, 
გუგლში მოეძებნათ „ეგვიპტე“

00:02:47.260 --> 00:02:50.260
და ჩემთვის გამოეგზავნათ შედეგები.

00:02:50.260 --> 00:02:53.260
აი, ჩემი მეგობრის სკოტის ეკრანის სურათი.

00:02:54.260 --> 00:02:57.260
აი, ჩემი მეგობრის დენიელის ეკრანის სურათი.

00:02:57.260 --> 00:02:59.260
როცა მათ გვერდიგვერდ დადებთ,

00:02:59.260 --> 00:03:01.260
ბმულების წაკითხვაც კი არ გჭირდებათ,

00:03:01.260 --> 00:03:03.260
რომ დაინახოთ სხვაობა ამ ორ გვერდს შორის.

00:03:03.260 --> 00:03:05.260
მაგრამ თუ ბმულებსაც წაიკითხავთ,

00:03:05.260 --> 00:03:08.260
მაშინ ეს სხვა მნიშვნელობას შეიძენს.

00:03:09.260 --> 00:03:12.260
დენიელს არაფერი მიუღია 
ეგვიპტის პროტესტების შესახებ

00:03:12.260 --> 00:03:14.260
გუგლის საძიებო შედეგების პირველ გვერდზე.

00:03:14.260 --> 00:03:16.260
სკოტის შედეგები სავსე იყო ამ ინფორმაციით

00:03:16.260 --> 00:03:18.260
და ეს პროტესტები იყო დღის მთავარი ამბავი.

00:03:18.260 --> 00:03:21.260
აი, ამდენად განსხვავებული ხდება 
ძიების შედეგები.

00:03:21.260 --> 00:03:24.260
მხოლოდ გუგლი და ფეისბუქი არ იქცევა ასე.

00:03:24.260 --> 00:03:26.260
ეს უკვე მთელ ინტერნეტზე ვრცელდება.

00:03:26.260 --> 00:03:29.260
უამრავი კომპანია მიმართავს 
ამ ტიპის პერსონალიზაციას.

00:03:29.260 --> 00:03:32.260
იაჰუუ ნიუსი, ინტერნეტის ყველაზე 
დიდი საინფორმაციო პორტალი,

00:03:32.260 --> 00:03:35.390
უკვე პერსონალიზებულია, ყოველი ადამიანი
განსხვავებულ შედეგს იღებს.

00:03:36.260 --> 00:03:39.260
ჰაფინგტონ პოსტი, ვაშინგტონ პოსტი, 
ნიუ იორკ ტაიმსი,

00:03:39.260 --> 00:03:42.260
ყველა ეთამაშება პერსონალიზაციას 
ამა თუ იმ ფორმით

00:03:42.260 --> 00:03:45.260
და ამ ყველაფერს ძალიან სწრაფად მივყავართ

00:03:45.260 --> 00:03:47.260
იმ სამყაროსკენ,

00:03:47.260 --> 00:03:51.260
სადაც ინტერნეტი ყოველთვის გვიჩვენებს იმას,
რისი ნახვაც გვსურს მისი აზრით,

00:03:51.260 --> 00:03:54.550
მაგრამ მათ შორის შეიძლება არ იყოს ის,
რისი ნახვა მართლაც გვჭირდება.

00:03:54.550 --> 00:03:57.260
როგორც ერიკ შმიდტი ამბობს,

00:03:57.260 --> 00:04:00.260
„ხალხისთვის რთული იქნებოდა
იმის ყურება, ან გამოყენება,

00:04:00.260 --> 00:04:02.260
რაც გარკვეული თვალსაზრისით,

00:04:02.260 --> 00:04:05.260
მათზე არაა მორგებული“.

00:04:05.260 --> 00:04:07.260
ვფიქრობ, რომ ეს პრობლემაა

00:04:07.260 --> 00:04:10.260
და მე ვფიქრობ, რომ თუკი
ყველა ასეთ ფილტრს შევკრებთ,

00:04:10.260 --> 00:04:12.260
ყველა ალგორითმს ერთად შევკრებთ,

00:04:12.260 --> 00:04:15.930
მივიღებთ იმას,
რასაც მე "გაფილტრულ ბუშტს" ვუწოდებ.

00:04:16.260 --> 00:04:19.260
თითოეული თქვენგანის
"გაფილტრული ბუშტი" არის თქვენი პირადი,

00:04:19.260 --> 00:04:21.260
უნიკალური ინფორმაციული სამყარო,

00:04:21.260 --> 00:04:23.260
რომელშიც თქვენ ონლაინ ცხოვრობთ.

00:04:23.260 --> 00:04:26.260
და თქვენი "გაფილტრული ბუშტი"

00:04:26.260 --> 00:04:29.260
დამოკიდებულია იმაზე, თუ რას
წარმოადგენთ და საქმიანობთ თქვენ.

00:04:29.260 --> 00:04:33.260
პრობლემა ისაა, რომ თქვენ თავად
არ წყვეტთ, რა ხვდება შიგნით

00:04:33.260 --> 00:04:35.260
და რაც უფრო მნიშვნელოვანია,

00:04:35.260 --> 00:04:38.260
თქვენ ვერც კი ხედავთ, რა წაიშალა.

00:04:38.260 --> 00:04:40.260
გაფილტრული ბუშტის ერთ-ერთი პრობლემა

00:04:40.260 --> 00:04:43.090
ნეტფლიქსზე აღმოაჩინა რამდენიმე მკვლევარმა.

00:04:43.090 --> 00:04:46.260
ისინი უყურებდნენ ნეტფლიქსის რიგებს, 
და აღმოაჩინეს რაღაც უცნაური,

00:04:46.260 --> 00:04:48.380
რაც ალბათ
ბევრ ჩვენგანს შეუმჩნევია მანამდე,

00:04:48.380 --> 00:04:50.260
რომ არის ზოგიერთი ფილმი,

00:04:50.260 --> 00:04:53.260
რომელიც პირდაპირ მოდის ჩვენს სახლებში.

00:04:53.260 --> 00:04:56.260
ანუ დგებით რიგში, და ეს ფილმები
პირდაპირ მოდიან:

00:04:56.260 --> 00:04:58.260
„რკინის კაცი“ უცებ მოდის

00:04:58.260 --> 00:05:00.260
ხოლო „სუპერმენის ლოდინს“

00:05:00.260 --> 00:05:02.260
შეიძლება დიდი ხნის ლოდინი დასჭირდეს.

00:05:02.260 --> 00:05:04.260
რაც მათ აღმოაჩინეს,

00:05:04.260 --> 00:05:06.260
არის ნეტფლიქსის რიგში

00:05:06.260 --> 00:05:09.260
გამართული ბრძოლა

00:05:09.260 --> 00:05:12.260
ჩვენს მომავალ სასურველ მესა

00:05:12.260 --> 00:05:15.260
და ჩვენს უფრო იმპულსურ
ამჟამინდელ მეს შორის.

00:05:15.260 --> 00:05:17.260
იცით, რომ ყველას გვსურს ვიყოთ ვიღაც,

00:05:17.260 --> 00:05:19.260
ვისაც უნახავს „რაშომონი“,

00:05:19.260 --> 00:05:21.260
მაგრამ ამ წუთას

00:05:21.260 --> 00:05:24.260
ჩვენ გვსურს მეოთხეჯერ ვუყუროთ 
"ეის ვენტურას",

00:05:24.260 --> 00:05:26.860
(სიცილი)

00:05:26.860 --> 00:05:29.260
მაშ, საუკეთესო შერჩევა მოგვცემს 
ცოტაოდენ ორივეს:

00:05:29.260 --> 00:05:31.260
მოგვცემს მცირე რაოდენობით ჯასტინ ბიბერს

00:05:31.260 --> 00:05:33.260
და მცირე რაოდენობით ავღანეთს.

00:05:33.260 --> 00:05:35.260
მოგვცემს ცოტა ბოსტნეულ ინფორმაციას;

00:05:35.260 --> 00:05:38.260
და ცოტა ტკბილეულ ინფორმაციას.

00:05:38.260 --> 00:05:40.260
ამ ტიპის ალგორითმული ფილტრების პრობლემა,

00:05:40.260 --> 00:05:42.260
ამ პერსონალიზებული ფილტრების პრობლემაა,

00:05:42.260 --> 00:05:44.260
რომ რადგან ისინი მეტწილად აკვირდებიან

00:05:44.260 --> 00:05:48.260
თუ რა ბმულებს აჭერთ თქვენ პირველად,

00:05:48.260 --> 00:05:52.260
ისინი არღვევენ ამ ბალანსს.

00:05:52.260 --> 00:05:55.260
ანუ ბალანსირებული საინფორმაციო 
დიეტის ნაცვლად,

00:05:55.260 --> 00:05:57.260
თქვენ რჩებით

00:05:57.260 --> 00:05:59.260
მავნე საინფორმაციო საკვების ამარა.

00:05:59.260 --> 00:06:00.950
ეს მიდგომა ნიშნავს,

00:06:00.950 --> 00:06:04.260
რომ ჩვენ შეიძლება არასწორად გვესმოდეს
ინტერნეტის არსი.

00:06:04.260 --> 00:06:06.030
დაარსების ლეგენდის თანახმად,

00:06:06.030 --> 00:06:07.860
სამაუწყებლო საზოგადოებაში,

00:06:07.860 --> 00:06:09.980
სამაუწყებლო საზოგადოებაში,

00:06:09.980 --> 00:06:12.260
იყვნენ კარიბჭის მცველები, რედაქტორები,

00:06:12.260 --> 00:06:15.260
რომლებიც აკონტროლებდნენ 
საინფორმაციო ნაკადს.

00:06:15.260 --> 00:06:18.260
შემდეგ მოვიდა ინტერნეტი, 
რომელმაც განდევნა ისინი

00:06:18.260 --> 00:06:20.790
და საშუალება მოგვცა,
ყველა დავკავშირებოდით ერთმანეთს

00:06:20.790 --> 00:06:22.260
და ეს შესანიშნავი იყო.

00:06:22.260 --> 00:06:25.260
მაგრამ ახლა ასე აღარ ხდება.

00:06:26.260 --> 00:06:29.260
ჩვენ ვხედავთ, როგორ გადაეცემა გასაღები

00:06:29.260 --> 00:06:31.260
ადამიანი მცველებისგან

00:06:31.260 --> 00:06:34.260
ალგორითმულ მცველებს.

00:06:34.260 --> 00:06:37.260
და საქმე ისაა, რომ ალგორითმებს

00:06:37.260 --> 00:06:40.260
ჯერ არ აქვთ თანდაყოლილი ეთიკა,

00:06:40.260 --> 00:06:43.260
რაც ადამიან რედაქტორებს ჰქონდათ.

00:06:43.260 --> 00:06:46.260
ამგვარად, თუკი ალგორითმებმა უნდა
მართონ სამყარო ჩვენს ნაცვლად,

00:06:46.260 --> 00:06:49.260
თუკი მათ უნდა გადაწყვიტონ,
რა უნდა ვნახოთ და რა არა,

00:06:49.260 --> 00:06:51.260
მაშინ უნდა დავრწმუნდეთ,

00:06:51.260 --> 00:06:54.260
რომ მათი მოქმედება მხოლოდ
შესაბამისობას არ უკავშირდება.

00:06:54.260 --> 00:06:56.260
უნდა დავრწმუნდეთ, რომ ისინი გვიჩვენებენ,

00:06:56.260 --> 00:06:59.260
რაც არაკომფორტულია, გამომწვევია,
ან მნიშვნელოვანი.

00:06:59.260 --> 00:07:01.260
ანუ, როგორც TED აკეთებს,

00:07:01.260 --> 00:07:03.260
გვაცნობს განსხვავებულ თვალთახედვებს.

00:07:03.260 --> 00:07:05.260
საქმე ისაა, რომ უკვე გავიარეთ

00:07:05.260 --> 00:07:07.260
ასეთი მდგომარეობა, როგორც საზოგადოებამ.

00:07:08.260 --> 00:07:11.260
1915 წელს, გაზეთებს დიდად არ ანაღვლებდათ

00:07:11.260 --> 00:07:14.260
სამოქალაქო პასუხისმგებლობა.

00:07:14.260 --> 00:07:16.260
შემდეგ ადამიანებმა შეამჩნიეს,

00:07:16.260 --> 00:07:19.260
რომ ისინი რაღაც მნიშვნელოვანს აკეთებდნენ.

00:07:19.260 --> 00:07:21.260
რომ სინამდვილეში

00:07:21.260 --> 00:07:23.260
დემოკრატია ვერ იმუშავებს,

00:07:23.260 --> 00:07:27.410
თუკი მოქალაქეები არ იღებენ 
ინფორმაციის კარგ ნაკადს,

00:07:28.260 --> 00:07:31.260
რომ გაზეთები მნიშვნელოვანია,
რადგან ისინი ფილტრივით მოქმედებენ

00:07:31.260 --> 00:07:33.260
და შემდეგ განვითარდა ჟურნალისტური ეთიკა.

00:07:33.260 --> 00:07:35.260
ის არ იყო სრულყოფილი,

00:07:35.260 --> 00:07:38.260
მაგრამ მან გადაგვატანინა ბოლო საუკუნე.

00:07:38.260 --> 00:07:40.260
ახლა კი,

00:07:40.260 --> 00:07:43.860
ჩვენ თითქოს უკან 2015-ში დავბრუნდით, 
ინტერნეტის მხრივ.

00:07:44.260 --> 00:07:47.260
ჩვენ გვჭირდება,
რომ კარიბჭის ახალმა მცველებმა

00:07:47.260 --> 00:07:49.260
მსგავსი პასუხისმგებლობა ჩანერგონ

00:07:49.260 --> 00:07:51.260
იმ ალგორითმების კოდებში, რომელთაც ქმნიან.

00:07:51.260 --> 00:07:54.260
ვიცი, რომ აქ ფეისბუკის და გუგლის 
ბევრი თანამშრომელი იმყოფება

00:07:54.260 --> 00:07:56.260
ლარი და სერგეი, ადამიანები,

00:07:56.260 --> 00:07:58.260
ვინც ინტერნეტი შექმნა დღევანდელი სახით

00:07:58.260 --> 00:08:00.260
და მე თქვენი მადლიერი ვარ.

00:08:00.260 --> 00:08:03.260
მაგრამ თქვენ უნდა უზრუნველყოთ,

00:08:03.260 --> 00:08:06.260
რომ ამ ალგორითმებში ჩადებული იყოს

00:08:06.260 --> 00:08:09.260
საზოგადობრივი ცხოვრების,
სამოქალაქო პასუხისმგებლობის შეგრძნება.

00:08:09.260 --> 00:08:12.260
თქვენ უნდა გახადოთ ეს ალგორითმები
საკმარისად გამჭვირვალე,

00:08:12.260 --> 00:08:14.260
რომ დავინახოთ, თუ რა წესებით

00:08:14.260 --> 00:08:17.260
განისაზღვრება ჩვენს ფილტრებში შემოსული
ინფორმაციის ნაკადი.

00:08:17.260 --> 00:08:19.260
გვსურს, რომ გარკვეული კონტროლი გვქონდეს,

00:08:19.260 --> 00:08:21.260
რომ თავად შეგვეძლოს გადაწყვეტა,

00:08:21.260 --> 00:08:24.260
თუ რა შემოვა ჩვენს ბუშტში და რა არა.

00:08:24.260 --> 00:08:26.260
რადგან მე ვფიქრობ,

00:08:26.260 --> 00:08:28.260
რომ ჩვენ მართლა გვჭირდება ისეთი ინტერნეტი,

00:08:28.260 --> 00:08:30.260
რომელზეც ყოველი ჩვენგანი ოცნებობდა.

00:08:30.260 --> 00:08:33.260
ჩვენ გვჭირდება ის, რომ ერთმანეთთან
დაგვაკავშიროს.

00:08:33.260 --> 00:08:36.260
გვჭირდება, რომ გაგვაცნოს ახალი იდეები,

00:08:36.260 --> 00:08:39.260
ახალი ადამიანები და განსხვავებული ხედვები.

00:08:40.260 --> 00:08:42.260
ეს კი არასდროს მოხდება,

00:08:42.260 --> 00:08:45.260
თუკი ის ყოველ ჩვენგანს იზოლირებულად,
საკუთარ ქსელში დატოვებს.

00:08:45.260 --> 00:08:47.260
გმადლობთ.

00:08:47.260 --> 00:08:58.260
(აპლოდისმენტები)

