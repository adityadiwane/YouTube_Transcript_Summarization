WEBVTT
Kind: captions
Language: hy

00:00:00.000 --> 00:00:07.000
Translator: Gohar Khachatryan
Reviewer: Arpiné Grigoryan

00:00:15.260 --> 00:00:17.260
Մարկ Ցուկերբերգին

00:00:17.260 --> 00:00:20.260
մի անգամ լրագրողներից մեկը հարցրել է Ֆեյսբուքի լրահոսի /newsfeed/ մասին:

00:00:20.260 --> 00:00:22.260
Լրագրողը հարցրել է.

00:00:22.260 --> 00:00:24.260
«Ինչու՞ է դա այդքան կարևոր»։

00:00:24.260 --> 00:00:26.260
Եվ Ցուկերբերգը պատասխանել է.

00:00:26.260 --> 00:00:28.260
«Ձեր բակում մահացող սկյուռը

00:00:28.260 --> 00:00:31.260
այս պահին կարող է ձեր հետաքրքրություններին ավելի համապատասխանի,

00:00:31.260 --> 00:00:34.260
քան Աֆրիկայում մահացող մարդիկ»։

00:00:34.260 --> 00:00:36.260
Ես ցանկանում եմ խոսել այսօր այն մասին,

00:00:36.260 --> 00:00:39.260
թե ինչ է դառնում ինտերնետը՝ երբ այն հիմնվում է ռելևանտության վրա:

00:00:40.260 --> 00:00:42.260
Երբ ես մեծանում էի

00:00:42.260 --> 00:00:44.260
Մայնում տեղակայված մի գյուղաբնակ վայրում,

00:00:44.260 --> 00:00:47.260
Ինտերնետը ինձ համար բոլորովին այլ բան էր նշանակում:

00:00:47.260 --> 00:00:49.260
Այն ինձ համար արտաքին աշխարհի հետ կապվելու միջոց էր:

00:00:49.260 --> 00:00:52.260
Այն մի բան էր, ինչը կարող է մեզ բոլորիս իրար միացնել:

00:00:52.260 --> 00:00:55.260
Եվ ես հավատացած էի, որ այն շատ լավ ազդեցություն է ունենալու ժողովրդավարության և

00:00:55.260 --> 00:00:58.260
հասարակության վրա:

00:00:58.260 --> 00:01:00.260
Սակայն տեղի է ունեցել փոփոխություն,

00:01:00.260 --> 00:01:02.260
տեղեկատվության օնլայն հոսքի ձևի մեջ,

00:01:02.260 --> 00:01:05.260
և այդ փոփոխությունն անտեսանելի է:

00:01:05.260 --> 00:01:07.260
Եվ եթե մենք ուշադրություն չդարձնենք դրան,

00:01:07.260 --> 00:01:10.260
ապա այն կարող է վերածվել մի մեծ խնդրի:

00:01:10.260 --> 00:01:13.260
Առաջին անգամ ես դա նկատեցի այնտեղ, որտեղ անցկացնում էի իմ ժամանակի հիմնական մասը՝

00:01:13.260 --> 00:01:15.260
Ֆեյսբուքի իմ էջում:

00:01:15.260 --> 00:01:18.260
Իմ քաղաքական հայացքներով ես առաջադիմական եմ, սական անակնկալ՝

00:01:18.260 --> 00:01:20.260
ես միշտ անում էի ամեն հնարավոր բան, պահպանողականների հետ առնչվելու համար:

00:01:20.260 --> 00:01:22.260
Ես սիրում եմ լսել, թե ինչ են նրանք մտածում,

00:01:22.260 --> 00:01:24.260
ես սիրում եմ տեսնել, թե ինչ հղումներով են միմյանց հետ կիսվում,

00:01:24.260 --> 00:01:26.260
սիրում եմ որոշակի բաներ սովորել իրենցից:

00:01:26.260 --> 00:01:29.260
Եվ մի օր ես անակընկալի եկա, երբ նկատեցի,

00:01:29.260 --> 00:01:32.260
որ պահպանողականների մասին տեղեկատվությունն անհետացել է իմ Ֆեյսբուքի լրահոսից:

00:01:33.260 --> 00:01:35.260
Եվ պարզվեց,

00:01:35.260 --> 00:01:39.260
որ Ֆեյսբուքը հետևում է, թե ինչ էջեր եմ ես այցելում

00:01:39.260 --> 00:01:41.260
և նշում այն,

00:01:41.260 --> 00:01:43.260
որ ես ավելի հաճախ էի կարդում իմ լիբերալ ընկերների էջերը,

00:01:43.260 --> 00:01:46.260
քան իմ պահպանողական ընկերների էջերը:

00:01:46.260 --> 00:01:48.260
Եվ առանց ինձ հարցնելու

00:01:48.260 --> 00:01:50.260
այն ամբողջովին ֆիլտրել է վերջիններս:

00:01:50.260 --> 00:01:53.260
Դրանք անհետացել էին:

00:01:54.260 --> 00:01:56.260
Ֆեյսբուքը միակ տեղը չէ,

00:01:56.260 --> 00:01:58.260
որն անում է նմանատիպ անտեսանելի ալգորիթմիկ

00:01:58.260 --> 00:02:01.260
խմբագրումներ Ինտերնետում:

00:02:01.260 --> 00:02:03.260
Գուգլը նույնպես անում է դա:

00:02:03.260 --> 00:02:06.260
Եթե ես որևէ մի բանի որոնեմ, և դուք նույն բանը որոնեք

00:02:06.260 --> 00:02:08.260
հենց այս պահին, այստեղ,

00:02:08.260 --> 00:02:11.260
մենք երկուսս էլ կստանանք տարբեր արդյունքներ:

00:02:11.260 --> 00:02:14.260
Մի ինժեներ ինձ ասել է, որ նույնիսկ եթե դուք դուրս եկած լինեք համակարգից

00:02:14.260 --> 00:02:16.260
կան 57 ազդանշաններ

00:02:16.260 --> 00:02:19.260
որոնցով առաջնորդվում է Գուգլը՝

00:02:19.260 --> 00:02:22.260
հաշվի առնելով ամեն ինչ, սկսած նրանից, թե ինչպիսի համակարգչից եք դուք օգտվում,

00:02:22.260 --> 00:02:24.260
ինչպիսի բրաուզերից եք օգտվում,

00:02:24.260 --> 00:02:26.260
վերջացրած նրանից, թե որտեղ եք դուք տեղակայված՝

00:02:26.260 --> 00:02:29.260
և այն օգտագործում է այդ ամենը, որպեսզի ստանա անհատական որոնման արդյունքներ:

00:02:29.260 --> 00:02:31.260
Մի պահ մտածեք սրա մասին.

00:02:31.260 --> 00:02:35.260
չկա այլևս ստանդարտ Գուգլ:

00:02:35.260 --> 00:02:38.260
Եվ գիտեք, ամենազավեշտալին այն է, որ դա դժվար է նկատել:

00:02:38.260 --> 00:02:40.260
Դուք չեք կարող տեսնել, թե ինչքանով են ձեր որոնման արդյունքները

00:02:40.260 --> 00:02:42.260
տարբերվում մեկ ուրիշի արդյունքներից:

00:02:42.260 --> 00:02:44.260
Մի քանի շաբաթ առաջ,

00:02:44.260 --> 00:02:47.260
ես խնդրեցի իմ մի քանի ընկերներին Գուգլում որոնել «Եգիպտոս» բառը

00:02:47.260 --> 00:02:50.260
և ուղարկել ինձ իրենց որոնման արդյունքները:

00:02:50.260 --> 00:02:53.260
Ահա իմ ընկեր Սկոթի արդյունքները:

00:02:54.260 --> 00:02:57.260
Ահա իմ ընկեր Դանիելի արդյունքները:

00:02:57.260 --> 00:02:59.260
Երբ երկու որոնման արդյունքները դնում ես կողք կողքի,

00:02:59.260 --> 00:03:01.260
նույնիսկ հարկավոր չէ կարդալ հղումները,

00:03:01.260 --> 00:03:03.260
տեսնելու համար, թե ինչքանով են այդ երկու էջերը տարբերվում միմյանցից:

00:03:03.260 --> 00:03:05.260
Սակայն, երբ սկսում ես կարդալ հղումները,

00:03:05.260 --> 00:03:08.260
տարբերությունն ուշագրավ է:

00:03:09.260 --> 00:03:12.260
Դանիելը իր որոնման առաջին էջում ոչ մի արդյունք չի ստացել

00:03:12.260 --> 00:03:14.260
Եգիպտոսում տեղի ունեցող բողոքի ցույցերի մասին:

00:03:14.260 --> 00:03:16.260
Սկոթի արդյունքների մեջ բողոքներին վերաբերող բազմաթիվ հղումներ կային:

00:03:16.260 --> 00:03:18.260
Իսկ բողոքները տվյալ օրվա ամենակարևոր նորությունն էր:

00:03:18.260 --> 00:03:21.260
Ահա թե ինչքան կարող են տարբերվել որոնման արդյունքները միմյանցից:

00:03:21.260 --> 00:03:24.260
Եվ սա միայն Գուգլը և Ֆեյսբուքը չէ, որ անում են:

00:03:24.260 --> 00:03:26.260
Սա այն է, ինչ կատարվում է ամբողջ համացանցում:

00:03:26.260 --> 00:03:29.260
Կան բազմաթիվ ընկերություններ, որոնք նմանատիպ անձնավորված մոտեցում են ցուցաբերում:

00:03:29.260 --> 00:03:32.260
Yahoo-ի նորությունները՝ համացանցի ամենամեծ նորությունների կայքը

00:03:32.260 --> 00:03:35.260
այժմ արդեն անձնավորված է՝ տարբեր մարդիկ ստանում են տարբեր տեսակի տեղեկատվություն:

00:03:36.260 --> 00:03:39.260
Huffington Post-ը, Washington Post-ը, New York Times-ը

00:03:39.260 --> 00:03:42.260
բոլորը կատարում են տեղեկատվության ֆիլտրում:

00:03:42.260 --> 00:03:45.260
Ես սա շատ արագ

00:03:45.260 --> 00:03:47.260
ստեղծում է մի իրականություն,

00:03:47.260 --> 00:03:51.260
որտեղ ինտերնետը ցույց է տալիս մեզ այն, ինչ, իր կարծիքով, մենք ցանկանում ենք տեսնել,

00:03:51.260 --> 00:03:54.260
բայց ոչ այն, ինչ իրականում մեզ հարկավոր է տեսնել:

00:03:54.260 --> 00:03:57.260
Ինչպես ասել է Էրիկ Շմիտը,

00:03:57.260 --> 00:04:00.260
«Մարդկանց համար շատ բարդ է դիտել կամ օգտագործել մի բան,

00:04:00.260 --> 00:04:02.260
ինչը, որոշակի առումով,

00:04:02.260 --> 00:04:05.260
համապատասխանեցված չէ իրենց համար»։

00:04:05.260 --> 00:04:07.260
Այսպիսով ես լիովին հավատացած եմ, որ սա խնդիր է:

00:04:07.260 --> 00:04:10.260
Եվ ես կարծում եմ, եթե մենք ի մի բերենք այս բոլոր ֆիլտրերը

00:04:10.260 --> 00:04:12.260
և բոլոր ալգորիթմները,

00:04:12.260 --> 00:04:15.260
ապա կստանանք այն, ինչն ես անվանում եմ «ֆիլտրող փուչիկ»:

00:04:16.260 --> 00:04:19.260
Եվ ձեր «ֆիլտրող փուչիկ»-ը ձեր անձնական

00:04:19.260 --> 00:04:21.260
յուրօրինակ տիեզերքն է այն տեղեկատվության,

00:04:21.260 --> 00:04:23.260
որի մեջ դուք ապրում եք օնլայն:

00:04:23.260 --> 00:04:26.260
Ձեր «ֆիլտրող փուչիկի» պարունակությունը

00:04:26.260 --> 00:04:29.260
կախված է նրանից, թե ով եք դուք և ինչով եք զբաղվում:

00:04:29.260 --> 00:04:33.260
Սակայն բանն այն է, որ դուք չեք որոշում ինչ տեղեկատվություն է այն ներառում:

00:04:33.260 --> 00:04:35.260
Եվ ամենակարևորը՝

00:04:35.260 --> 00:04:38.260
դուք նույնիսկ չեք տեսնում թե ինչը չի ներառվում այնտեղ:

00:04:38.260 --> 00:04:40.260
Այսպիսով, «ֆիլտրող փուչիկների» հիմնական խնդիրը

00:04:40.260 --> 00:04:43.260
բացահայտվել է Netflix-ի մի քանի հետազոտողների կողմից:

00:04:43.260 --> 00:04:46.260
Նրանք հետևում էին Netflix-ի ֆիլմերի դիտումների հերթագրումներին և նկատեցին զավեշտալի մի բան,

00:04:46.260 --> 00:04:48.260
ինչ շատերս հնարավոր է նկատել ենք՝

00:04:48.260 --> 00:04:50.260
կան որոշակի ֆիլմեր,

00:04:50.260 --> 00:04:53.260
որոնք արագ հայտնվում են ցուցակում և նույնքան արագ անհետանում (դիտվում)։

00:04:53.260 --> 00:04:56.260
Դրանք հայտնվում եմ հերթի ցուցակի մեջ, այնուհետև անմիջապես դուրս գալիս (դիտում են)։

00:04:56.260 --> 00:04:58.260
Օրինակ, «Երկաթե մարդը» շատ արագ դուրս է թռնում,

00:04:58.260 --> 00:05:00.260
իսկ «Սպասելով սուպերմենին» ֆիլմը

00:05:00.260 --> 00:05:02.260
կարող է շատ երկար սպասել իր հերթին։

00:05:02.260 --> 00:05:04.260
Նրանք հայտնաբերեցին,

00:05:04.260 --> 00:05:06.260
որ Netfix-ի հերթերում,

00:05:06.260 --> 00:05:09.260
տեղի է ունենում հսկայական պայքար,

00:05:09.260 --> 00:05:12.260
երկու «ես»-երի միջև` այն, ինչպես մենք ցանկանում ենք լինել

00:05:12.260 --> 00:05:15.260
և ավելի իմպուլսիվ, այսօրվա «ես»-ի միջև։

00:05:15.260 --> 00:05:17.260
Մենք բոլորս էլ ուզում ենք լինել մեկը,

00:05:17.260 --> 00:05:19.260
որ դիտում է «Ռաշոմոն»-ը

00:05:19.260 --> 00:05:21.260
բայց տվյալ պահին,

00:05:21.260 --> 00:05:24.260
մենք ցանկանում ենք 4-րդ անգամ դիտել «Էյս Վենտուրա»-ն։

00:05:24.260 --> 00:05:27.260
(Ծիծաղ)

00:05:27.260 --> 00:05:29.260
Լավագույն խմբագրումը տալիս է մեզ ամեն ինչից քիչ-քիչ՝

00:05:29.260 --> 00:05:31.260
այն բերում է մի քիչ տեղեկություն Ջասթին Բիեբերի մասին,

00:05:31.260 --> 00:05:33.260
և մի քիչ էլ տեղեկություն Աֆղանստանի մասին:

00:05:33.260 --> 00:05:35.260
Այն մեզ տալիս է մի քիչ տեղեկատվական բանջարեղեն,

00:05:35.260 --> 00:05:38.260
և մի քիչ տեղեկատվական աղանդեր:

00:05:38.260 --> 00:05:40.260
Այսպիսի ալգորիթմիկ ֆիլտրերի հետ խնդիրը նրանում է,

00:05:40.260 --> 00:05:42.260
որ անձնավորված ֆիլտրները,

00:05:42.260 --> 00:05:44.260
հիմնականում առաջնորդվում են նրանով,

00:05:44.260 --> 00:05:48.260
թե ինչ հղում ենք մենք առաջինը սեղմում,

00:05:48.260 --> 00:05:52.260
այդ իսկ պատճառով այն խախտում է հավասարակշռությունը:

00:05:52.260 --> 00:05:55.260
Եվ հավասարակշռված տեղեկատվական սննդի փոխարեն,

00:05:55.260 --> 00:05:57.260
դուք ստանում եք

00:05:57.260 --> 00:05:59.260
տեղեկատվական արագ պատրաստվող սնունդ:

00:05:59.260 --> 00:06:01.260
Դա նշանակում է,

00:06:01.260 --> 00:06:04.260
որ մենք ինտերնետի մասին սխալ պատկերացում ենք ստանում։

00:06:04.260 --> 00:06:06.260
Եթեր հեռարձակվող հասարակության մեջ

00:06:06.260 --> 00:06:08.260
հիմնական գործընթացն ընթանում է հետևյալ կերպ.

00:06:08.260 --> 00:06:10.260
եթեր հեռարձակվող հասարակության մեջ

00:06:10.260 --> 00:06:12.260
կային ստուգողներ, խմբագիրներ,

00:06:12.260 --> 00:06:15.260
ովքեր վերահսկում էին տեղեկատվության հոսքը:

00:06:15.260 --> 00:06:18.260
Եվ ահա հայտնվում է համացանցը և հեռացնում նրանց բոլորին ճանապարհից՝

00:06:18.260 --> 00:06:20.260
ընձեռելով մեզ հնարավորություն կապվել միմյանց հետ,

00:06:20.260 --> 00:06:22.260
և դա հրաշալի էր:

00:06:22.260 --> 00:06:25.260
Բայդ դա այն չէ, ինչ տեղի է ունենում այսօր։

00:06:26.260 --> 00:06:29.260
Այն, ինչին մենք հիմա վկա ենք՝ ընդհամենը տեղափոխում է

00:06:29.260 --> 00:06:31.260
մարդկային ստուգողներից

00:06:31.260 --> 00:06:34.260
ալգորիթմիկ ստուգողների։

00:06:34.260 --> 00:06:37.260
Եվ բանը նրանում է, որ ալգորիթմերը

00:06:37.260 --> 00:06:40.260
դեռևս չունեն ներկառուցված էթիկական նորմեր,

00:06:40.260 --> 00:06:43.260
ի տարբերություն խմբագիրների:

00:06:43.260 --> 00:06:46.260
Եթե ալգորիթմերն են այսուհետ ղեկավարելու աշխարհը մեր փոխարեն,

00:06:46.260 --> 00:06:49.260
եթե դրանք են որոշելու, թե ինչը մենք պետք է տեսնենք և ինչը՝ ոչ,

00:06:49.260 --> 00:06:51.260
ապա մենք պետք է համոզված լինենք,

00:06:51.260 --> 00:06:54.260
որ դրանք հիմնված չլինեն զուտ ռելևանտության վրա։

00:06:54.260 --> 00:06:56.260
Մենք պետք է համոզված լինենք, որ մեզ ցույց են տալիս այն տեղեկատվությունը,

00:06:56.260 --> 00:06:59.260
որը կարող է տհաճ լինի կամ մարտահրավեր նետի կամ կարևոր լինի՝

00:06:59.260 --> 00:07:01.260
մի բան, որ անում է TED-ը, այն է՝

00:07:01.260 --> 00:07:03.260
ներկայացնել տարբեր կարծիքներ:

00:07:03.260 --> 00:07:05.260
Բանն այն է, որ մենք որպես հասարակություն,

00:07:05.260 --> 00:07:07.260
արդեն անցել ենք այս ամենի միջով։

00:07:08.260 --> 00:07:11.260
1915 թ-ին թերթերն առանձնապես մտահոգված չէին

00:07:11.260 --> 00:07:14.260
իրենց քաղաքացիական պարտականություններով։

00:07:14.260 --> 00:07:16.260
Հետո մարդիկ նկատեցին,

00:07:16.260 --> 00:07:19.260
դրանք իրականում շատ կարևոր են։

00:07:19.260 --> 00:07:21.260
Հնարավոր չէ կառուցել

00:07:21.260 --> 00:07:23.260
ժողովրդավարություն,

00:07:23.260 --> 00:07:27.260
երբ քաղաքացիները չեն ստանում տեղեկատվության հոսք:

00:07:28.260 --> 00:07:31.260
Նախկինում թերթերը շատ կարևոր էին, որովհետև դրանք կրում էին ֆիլտրողի դեր,

00:07:31.260 --> 00:07:33.260
այնուհետև դրա հետևանքով զարգացավ լրագրողական էթիկայի կիրառումը:

00:07:33.260 --> 00:07:35.260
Այն կատարյալ չէր,

00:07:35.260 --> 00:07:38.260
սակայն ուղղորդեց մեզ անցյալ դարաշրջանի ընթացքում:

00:07:38.260 --> 00:07:40.260
Եվ ահա այժմ

00:07:40.260 --> 00:07:43.260
մենք ինչ-որ չափով վերադարձել ենք 1915 թվական՝ համացանցի առումով:

00:07:44.260 --> 00:07:47.260
Եվ մեզ հիմա հարկավոր են նոր ստուգողներ,

00:07:47.260 --> 00:07:49.260
որոնք նման պատասխանատվություն կհաղորդեն

00:07:49.260 --> 00:07:51.260
ծրագրերին, որոնք ստեղծվում են։

00:07:51.260 --> 00:07:54.260
Ես գիտեմ, որ շատերդ այստեղ աշխատում եք Ֆեյսբուքում և Գուգլում՝

00:07:54.260 --> 00:07:56.260
Լարրին և Սերգեյը

00:07:56.260 --> 00:07:58.260
այն մարդիկ են, ովքեր նպաստել են համացանցի ստեղծմանը,

00:07:58.260 --> 00:08:00.260
և ես շատ շնորհակալ եմ իրենցից:

00:08:00.260 --> 00:08:03.260
Բայց մենք պետք է անենք ամեն բան,

00:08:03.260 --> 00:08:06.260
որպեսզի այդ ալգորիթմներն իրենց մեջ ունենան

00:08:06.260 --> 00:08:09.260
քաղաքացիական պատասխանատվության զգացում։

00:08:09.260 --> 00:08:12.260
Մենք պետք է համոզվենք, որ դրանք բավականաչափ թափանցիկ են,

00:08:12.260 --> 00:08:14.260
որ մենք կարող ենք հասկանալ այն օրենքները,

00:08:14.260 --> 00:08:17.260
որոնք որոշում են, թե ինչպես է տեղեկատվությունը ֆիլտրվում։

00:08:17.260 --> 00:08:19.260
Եվ մեզ անհրաժեշտ է որոշակի վերահսկում,

00:08:19.260 --> 00:08:21.260
որպեսզի մենք կարողանանք որոշել,

00:08:21.260 --> 00:08:24.260
թե ինչն է ֆիլտրվում, իսկը ինչը՝ ոչ։

00:08:24.260 --> 00:08:26.260
Որովհետև ես հավատացած եմ,

00:08:26.260 --> 00:08:28.260
որ մեզ համար անհրաժեշտ է, որ ինտերնետն ունենա այն նշանակությունը,

00:08:28.260 --> 00:08:30.260
որի մասին մենք երազում էինք։

00:08:30.260 --> 00:08:33.260
Մեզ անհրաժեշտ է, որ այն միավորի մեզ բոլորիս։

00:08:33.260 --> 00:08:36.260
Մեզ անհրաժեշտ է, որ այն ծանոթացնի մեզ նոր գաղափարների,

00:08:36.260 --> 00:08:39.260
նոր մարդկանց և նոր հեռանկարների հետ։

00:08:40.260 --> 00:08:42.260
Եվ այդ բոլորը տեղի չի ունենա,

00:08:42.260 --> 00:08:45.260
եթե այն մեկուսացրած թողնի մեզ մեկ մարդու ցանցում։

00:08:45.260 --> 00:08:47.260
Շնորհակալություն։

00:08:47.260 --> 00:08:58.260
(Ծափահարություններ)

