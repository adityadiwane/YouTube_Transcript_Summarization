WEBVTT
Kind: captions
Language: pl

00:00:00.000 --> 00:00:07.000
Tłumaczenie: Sebastian Misiewicz
Korekta: Marek Kasiak

00:00:15.260 --> 00:00:17.260
Markowi Zuckerbergowi

00:00:17.260 --> 00:00:20.260
dziennikarz zadał pytanie o kanały informacyjne.

00:00:20.260 --> 00:00:22.260
Zapytał go:

00:00:22.260 --> 00:00:24.260
"Dlaczego są one takie istotne?"

00:00:24.260 --> 00:00:26.260
Zuckerberg powiedział:

00:00:26.260 --> 00:00:28.260
"Wiewiórka umierająca w twoim ogródku

00:00:28.260 --> 00:00:31.260
może być bardziej dla ciebie istotna

00:00:31.260 --> 00:00:34.260
niż ludzie umierający w Afryce."

00:00:34.260 --> 00:00:36.260
Chciałbym powiedzieć, jak

00:00:36.260 --> 00:00:39.260
może wyglądać Internet bazujący na takiej idei.

00:00:40.260 --> 00:00:42.260
Kiedy dorastałem

00:00:42.260 --> 00:00:44.260
na wsi w stanie Maine,

00:00:44.260 --> 00:00:47.260
Internet oznaczał dla mnie coś bardzo odmiennego.

00:00:47.260 --> 00:00:49.260
Był połączeniem ze światem.

00:00:49.260 --> 00:00:52.260
Czymś, co połączyłoby nas razem.

00:00:52.260 --> 00:00:55.260
Byłem pewien, że będzie wspaniały dla demokracji

00:00:55.260 --> 00:00:58.260
i naszego społeczeństwa.

00:00:58.260 --> 00:01:00.260
Jednak jest zmiana

00:01:00.260 --> 00:01:02.260
w przepływie informacji online,

00:01:02.260 --> 00:01:05.260
która jest niewidoczna.

00:01:05.260 --> 00:01:07.260
Jeżeli nie zwrócimy na nią uwagi

00:01:07.260 --> 00:01:10.260
może stać się problemem.

00:01:10.260 --> 00:01:13.260
Pierwszy raz to zobaczyłem na swoim profilu na Facebook.

00:01:13.260 --> 00:01:15.260
Pierwszy raz to zobaczyłem na swoim profilu na Facebook.

00:01:15.260 --> 00:01:18.260
Jestem nowoczesny, politycznie (wielka niespodzianka)

00:01:18.260 --> 00:01:20.260
jednak zawsze wychodzę naprzeciw konserwatystom.

00:01:20.260 --> 00:01:22.260
Lubię słuchać tego, co mają do powiedzenia,

00:01:22.260 --> 00:01:24.260
widzieć, do czego się odnoszą,

00:01:24.260 --> 00:01:26.260
uczyć się paru rzeczy.

00:01:26.260 --> 00:01:29.260
Zaskoczyło mnie pewnego dnia,

00:01:29.260 --> 00:01:32.260
konserwatyści zniknęli z mojego Facebooka.

00:01:33.260 --> 00:01:35.260
Okazało się, że Facebook

00:01:35.260 --> 00:01:39.260
sprawdzał, co klikałem

00:01:39.260 --> 00:01:41.260
i zauważał, właściwie, że

00:01:41.260 --> 00:01:43.260
klikałem więcej na linki liberalnych znajomych

00:01:43.260 --> 00:01:46.260
od linków konserwatywnych kolegów.

00:01:46.260 --> 00:01:48.260
Bez mojej konsultacji

00:01:48.260 --> 00:01:50.260
odrzucał je.

00:01:50.260 --> 00:01:53.260
One zniknęły.

00:01:54.260 --> 00:01:56.260
Facebook nie jest jedynym miejscem,

00:01:56.260 --> 00:01:58.260
gdzie dokonywana jest ta niewidoczna,

00:01:58.260 --> 00:02:01.260
algorytmiczna selekcja Internetu.

00:02:01.260 --> 00:02:03.260
Google też to robi.

00:02:03.260 --> 00:02:06.260
Jeżeli będziemy szukali tego samego,

00:02:06.260 --> 00:02:08.260
nawet teraz w tym samym czasie

00:02:08.260 --> 00:02:11.260
to możemy otrzymać różne wyniki.

00:02:11.260 --> 00:02:14.260
Nawet, gdy nie jesteś zalogowany, powiedział mi jeden inżynier,

00:02:14.260 --> 00:02:16.260
jest 57 sygnałów

00:02:16.260 --> 00:02:19.260
na które patrzy Google.

00:02:19.260 --> 00:02:22.260
Poczynając od komputera,

00:02:22.260 --> 00:02:24.260
używanej przeglądarki,

00:02:24.260 --> 00:02:26.260
po lokację, które

00:02:26.260 --> 00:02:29.260
kroją pod osobę wyniki wyszukiwania.

00:02:29.260 --> 00:02:31.260
Pomyśl przez chwilę,

00:02:31.260 --> 00:02:35.260
nie ma już standardowego Google.

00:02:35.260 --> 00:02:38.260
Śmieszne jest to, że tego nie widać.

00:02:38.260 --> 00:02:40.260
Nie widać, jak różne są twoje

00:02:40.260 --> 00:02:42.260
wyniki od czyichś.

00:02:42.260 --> 00:02:44.260
Parę tygodnie temu,

00:02:44.260 --> 00:02:47.260
poprosiłem znajomych o wyszukanie "Egipt"

00:02:47.260 --> 00:02:50.260
i przesłanie screenów z wynikami.

00:02:50.260 --> 00:02:53.260
To jest screen Scotta.

00:02:54.260 --> 00:02:57.260
A to screen Daniela.

00:02:57.260 --> 00:02:59.260
Układając je koło siebie

00:02:59.260 --> 00:03:01.260
nawet nie trzeba czytać linków

00:03:01.260 --> 00:03:03.260
by zobaczyć różnicę.

00:03:03.260 --> 00:03:05.260
Jeżeli przeczytasz linki

00:03:05.260 --> 00:03:08.260
to znajdziesz coś niezwykłego.

00:03:09.260 --> 00:03:12.260
Daniel nic nie otrzymał na temat protestów w Egipcie

00:03:12.260 --> 00:03:14.260
na pierwszej stronie wyników.

00:03:14.260 --> 00:03:16.260
Strona Scotta była w nie obfita.

00:03:16.260 --> 00:03:18.260
To było niezła historia swego czasu.

00:03:18.260 --> 00:03:21.260
Tak różne stały się teraz wyniki.

00:03:21.260 --> 00:03:24.260
Nie tylko Google i Facebook tak robi.

00:03:24.260 --> 00:03:26.260
Ten problem pomiata całą siecią.

00:03:26.260 --> 00:03:29.260
Istnieje cały szereg firm wykonujących taką personalizację.

00:03:29.260 --> 00:03:32.260
Yahoo News, największa strona internetowa z wiadomościami,

00:03:32.260 --> 00:03:35.260
jest spersonalizowana, różni ludzie otrzymują różne wyniki.

00:03:36.260 --> 00:03:39.260
Huffington Post, Washington Post, New York Times,

00:03:39.260 --> 00:03:42.260
wszystkie bawią się z personalizacją na różne sposoby.

00:03:42.260 --> 00:03:45.260
To idzie wszystko w kierunku

00:03:45.260 --> 00:03:47.260
świata, w którym Internet pokazuje

00:03:47.260 --> 00:03:51.260
wyniki, które sam myśli, że chcemy,

00:03:51.260 --> 00:03:54.260
ale niekoniecznie to, co powinniśmy zobaczyć.

00:03:54.260 --> 00:03:57.260
Tak, jak Eric Schmidt powiedział:

00:03:57.260 --> 00:04:00.260
"Będzie bardzo trudno ludziom oglądać, czy konsumować

00:04:00.260 --> 00:04:02.260
coś, co w pewnym sensie

00:04:02.260 --> 00:04:05.260
nie zostało do nich dostosowane."

00:04:05.260 --> 00:04:07.260
Dlatego sądzę, że to jest problem.

00:04:07.260 --> 00:04:10.260
Sądzę, że biorąc wszystkie filtry razem,

00:04:10.260 --> 00:04:12.260
wszystkie te algorytmy,

00:04:12.260 --> 00:04:15.260
otrzymamy coś, co nazywam bańką z filtrami.

00:04:16.260 --> 00:04:19.260
Twoja bańka jest twoim własnym

00:04:19.260 --> 00:04:21.260
unikalnym informacyjnym wszechświatem,

00:04:21.260 --> 00:04:23.260
w którym żyjesz online.

00:04:23.260 --> 00:04:26.260
Zawartość bańki zależy od tego

00:04:26.260 --> 00:04:29.260
kim jesteś i co robisz.

00:04:29.260 --> 00:04:33.260
Szkopuł w tym, że nie decydujesz o tym co trafia,

00:04:33.260 --> 00:04:35.260
a co ważniejsze, co zostaje wycięte z wyników.

00:04:35.260 --> 00:04:38.260
a co ważniejsze, co zostaje wycięte z wyników.

00:04:38.260 --> 00:04:40.260
Pewien problem w bańkach z filtrami

00:04:40.260 --> 00:04:43.260
odkryli naukowcy z Netflix.

00:04:43.260 --> 00:04:46.260
Patrzyli na kolejki w Netflix i zauważyli coś dziwnego,

00:04:46.260 --> 00:04:48.260
co wieli z nas pewnie zauważyło,

00:04:48.260 --> 00:04:50.260
że są niektóre filmy, które

00:04:50.260 --> 00:04:53.260
wpadają i wypadają z naszych domów.

00:04:53.260 --> 00:04:56.260
Wchodzą do kolejki i zaraz z niej wypadają.

00:04:56.260 --> 00:04:58.260
"Iron Man" tak wypada,

00:04:58.260 --> 00:05:00.260
"Waiting for Superman" również

00:05:00.260 --> 00:05:02.260
może czekać długi czas.

00:05:02.260 --> 00:05:04.260
Odkryli, że w kolejkach

00:05:04.260 --> 00:05:06.260
Netflix toczy się walka

00:05:06.260 --> 00:05:09.260
pomiędzy naszymi przyszłymi

00:05:09.260 --> 00:05:12.260
ambicjami, a teraźniejszymi

00:05:12.260 --> 00:05:15.260
impulsywnymi osobowościami.

00:05:15.260 --> 00:05:17.260
Wszyscy chcielibyśmy być

00:05:17.260 --> 00:05:19.260
kimś, kto oglądał "Rashomon",

00:05:19.260 --> 00:05:21.260
ale w tej chwili

00:05:21.260 --> 00:05:24.260
chcemy oglądać po raz czwarty "Ace Ventura".

00:05:24.260 --> 00:05:27.260
(Śmiech)

00:05:27.260 --> 00:05:29.260
Najlepsze dopasowanie daje nam coś z ich obu.

00:05:29.260 --> 00:05:31.260
Trochę Justina Biebera

00:05:31.260 --> 00:05:33.260
i trochę Afganistanu.

00:05:33.260 --> 00:05:35.260
Daje nam trochę warzyw,

00:05:35.260 --> 00:05:38.260
tak jak i trochę deseru.

00:05:38.260 --> 00:05:40.260
Wyzwaniem tych algorytmów w filtrach,

00:05:40.260 --> 00:05:42.260
personalizujących filtrów,

00:05:42.260 --> 00:05:44.260
jest to, ponieważ patrzą one

00:05:44.260 --> 00:05:48.260
na co się najpierw kliknie

00:05:48.260 --> 00:05:52.260
co może wytrącić je z równowagi.

00:05:52.260 --> 00:05:55.260
Zamiast zbalansowanej diety,

00:05:55.260 --> 00:05:57.260
możesz skończyć otoczonym

00:05:57.260 --> 00:05:59.260
przez śmieci informacyjne.

00:05:59.260 --> 00:06:01.260
Sugeruje to, że rzeczywiście

00:06:01.260 --> 00:06:04.260
możemy mieć trop, że Internet idzie w złym kierunku.

00:06:04.260 --> 00:06:06.260
W rozgłaszającym społeczeństwie,

00:06:06.260 --> 00:06:08.260
tak brzmi podstawowa mitologia,

00:06:08.260 --> 00:06:10.260
w takim społeczeństwie,

00:06:10.260 --> 00:06:12.260
byli strażnicy, redaktorzy,

00:06:12.260 --> 00:06:15.260
którzy kontrolowali przepływ informacji.

00:06:15.260 --> 00:06:18.260
Przyszedł internet i ich wymiótł,

00:06:18.260 --> 00:06:20.260
co pozwoliło nam się nawzajem połączyć,

00:06:20.260 --> 00:06:22.260
a to jest niesamowite.

00:06:22.260 --> 00:06:25.260
Jednak nie to teraz się dzieje.

00:06:26.260 --> 00:06:29.260
Widzimy podawanie sobie pochodni

00:06:29.260 --> 00:06:31.260
od strażników do ich

00:06:31.260 --> 00:06:34.260
algorytmicznych odpowiedników.

00:06:34.260 --> 00:06:37.260
Z algorytmami jest tak, że

00:06:37.260 --> 00:06:40.260
nie posiadają wbudowanej etyki,

00:06:40.260 --> 00:06:43.260
którą mieli redaktorzy.

00:06:43.260 --> 00:06:46.260
Jeżeli algorytmy będą naszymi kuratorami,

00:06:46.260 --> 00:06:49.260
będą decydowały o tym co widzimy, a co nie,

00:06:49.260 --> 00:06:51.260
to musimy się upewnić,

00:06:51.260 --> 00:06:54.260
że nie steruje ich związek.

00:06:54.260 --> 00:06:56.260
Upewnijmy się, że również pokazują nam rzeczy,

00:06:56.260 --> 00:06:59.260
które są niewygodnie, wyzywające, czy ważne,

00:06:59.260 --> 00:07:01.260
to co robi TED,

00:07:01.260 --> 00:07:03.260
inne punkty widzenia.

00:07:03.260 --> 00:07:05.260
Już tu byliśmy jako społeczność, taka prawda.

00:07:05.260 --> 00:07:07.260
Już tu byliśmy jako społeczność, taka prawda.

00:07:08.260 --> 00:07:11.260
W 1915, gazety nie przejmowały się za bardzo

00:07:11.260 --> 00:07:14.260
obywatelskimi obowiązkami.

00:07:14.260 --> 00:07:16.260
Potem ludzie zauważyli, że

00:07:16.260 --> 00:07:19.260
one robiły coś bardzo ważnego.

00:07:19.260 --> 00:07:21.260
Naprawdę nie można

00:07:21.260 --> 00:07:23.260
mieć funkcjonującej demokracji,

00:07:23.260 --> 00:07:27.260
jeżeli obywatele nie mają dobrego przepływu informacji.

00:07:28.260 --> 00:07:31.260
Gazety były istotne, bo działały jak filtr,

00:07:31.260 --> 00:07:33.260
a potem etyka dziennikarska się rozwinęła.

00:07:33.260 --> 00:07:35.260
Nie było to perfekcyjne,

00:07:35.260 --> 00:07:38.260
ale przetrwaliśmy dzięki temu poprzedni wiek.

00:07:38.260 --> 00:07:40.260
Teraz, wróciliśmy

00:07:40.260 --> 00:07:43.260
tak jakby do 1915 w sieci.

00:07:44.260 --> 00:07:47.260
Potrzebujemy nowych strażników

00:07:47.260 --> 00:07:49.260
by zawarli tą odpowiedzialność

00:07:49.260 --> 00:07:51.260
w kodzie, który piszą.

00:07:51.260 --> 00:07:54.260
Wiem, że jest tu wiele ludzi z Facebooka i Google,

00:07:54.260 --> 00:07:56.260
Larry i Sergiej,

00:07:56.260 --> 00:07:58.260
ludzie, którzy pomogli zbudować sieć taką, jaką jest,

00:07:58.260 --> 00:08:00.260
za to jestem im wdzięczny.

00:08:00.260 --> 00:08:03.260
Potrzebujemy, abyście upewnili się,

00:08:03.260 --> 00:08:06.260
że te algorytmy zawierają w sobie

00:08:06.260 --> 00:08:09.260
wyczucie publicznego życia, obywatelskiego obowiązku.

00:08:09.260 --> 00:08:12.260
Upewnijcie się, że są wystarczająco przezroczyste

00:08:12.260 --> 00:08:14.260
byśmy mogli dostrzec reguły,

00:08:14.260 --> 00:08:17.260
które decydują, co przepuszcza filtr.

00:08:17.260 --> 00:08:19.260
Musicie dać nam trochę kontroli,

00:08:19.260 --> 00:08:21.260
byśmy sami zdecydowali,

00:08:21.260 --> 00:08:24.260
co przechodzi, a co nie.

00:08:24.260 --> 00:08:26.260
Ponieważ myślę,

00:08:26.260 --> 00:08:28.260
że potrzebujemy by Internet był tym czymś

00:08:28.260 --> 00:08:30.260
o czym marzyliśmy, że będzie.

00:08:30.260 --> 00:08:33.260
Musi nas ze sobą łączyć.

00:08:33.260 --> 00:08:36.260
Musi nam przedstawiać nowe idee,

00:08:36.260 --> 00:08:39.260
nowych ludzi i różne perspektywy.

00:08:40.260 --> 00:08:42.260
Nie uda się to, jeżeli

00:08:42.260 --> 00:08:45.260
zostaniemy wyobcowani w sieci do jednostki.

00:08:45.260 --> 00:08:47.260
Dziękuję.

00:08:47.260 --> 00:08:58.260
(Oklaski)

