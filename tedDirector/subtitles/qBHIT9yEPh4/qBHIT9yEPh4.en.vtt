WEBVTT
Kind: captions
Language: en

00:00:12.160 --> 00:00:16.160
So I'm here to tell you a story of success from Africa.

00:00:16.160 --> 00:00:19.160
A year and a half ago,

00:00:19.160 --> 00:00:21.160
four of the five people who are full time members

00:00:21.160 --> 00:00:23.160
at Ushahidi,

00:00:23.160 --> 00:00:26.160
which means "testimony" in Swahili,

00:00:26.160 --> 00:00:28.160
were TED Fellows.

00:00:28.160 --> 00:00:31.160
A year ago in Kenya we had post-election violence.

00:00:31.160 --> 00:00:34.160
And in that time we prototyped and built,

00:00:34.160 --> 00:00:36.160
in about three days, a system that would allow

00:00:36.160 --> 00:00:38.160
anybody with a mobile phone

00:00:38.160 --> 00:00:41.160
to send in information and reports on what was happening around them.

00:00:41.160 --> 00:00:43.160
We took what we knew about Africa,

00:00:43.160 --> 00:00:45.160
the default device,

00:00:45.160 --> 00:00:47.160
the mobile phone, as our common denominator,

00:00:47.160 --> 00:00:49.160
and went from there.

00:00:49.160 --> 00:00:52.160
We got reports like this.

00:00:56.160 --> 00:00:59.160
This is just a couple of them from January 17th, last year.

00:01:02.160 --> 00:01:05.160
And our system was rudimentary. It was very basic.

00:01:05.160 --> 00:01:08.160
It was a mash-up that used data that we collected from people,

00:01:08.160 --> 00:01:10.160
and we put it on our map.

00:01:10.160 --> 00:01:12.160
But then we decided we needed to do something more.

00:01:12.160 --> 00:01:14.160
We needed to take what we had built

00:01:14.160 --> 00:01:17.160
and create a platform out of it so that it could be used elsewhere in the world.

00:01:17.160 --> 00:01:20.160
And so there is a team of developers

00:01:20.160 --> 00:01:23.160
from all over Africa, who are part of this team now --

00:01:23.160 --> 00:01:25.160
from Ghana, from Malawi, from Kenya.

00:01:25.160 --> 00:01:29.160
There is even some from the U.S.

00:01:29.160 --> 00:01:32.160
We're building for smartphones, so that it can be used in the developed world,

00:01:32.160 --> 00:01:34.160
as well as the developing world.

00:01:34.160 --> 00:01:36.160
We are realizing that this is true.

00:01:36.160 --> 00:01:38.160
If it works in Africa then it will work anywhere.

00:01:38.160 --> 00:01:41.160
And so we build for it in Africa first

00:01:41.160 --> 00:01:43.160
and then we move to the edges.

00:01:43.160 --> 00:01:46.160
It's now been deployed in the Democratic Republic of the Congo.

00:01:46.160 --> 00:01:49.160
It's being used by NGOs all over East Africa,

00:01:49.160 --> 00:01:52.160
small NGOs doing their own little projects.

00:01:52.160 --> 00:01:54.160
Just this last month it was deployed by

00:01:54.160 --> 00:01:57.160
Al Jazeera in Gaza.

00:01:57.160 --> 00:01:59.160
But that's actually not what I'm here to talk about.

00:01:59.160 --> 00:02:01.160
I'm here to talk about the next big thing,

00:02:01.160 --> 00:02:03.160
because what we're finding out is that

00:02:03.160 --> 00:02:05.160
we have this capacity to report

00:02:05.160 --> 00:02:09.160
eyewitness accounts of what's going on in real time.

00:02:09.160 --> 00:02:12.160
We're seeing this in events like Mumbai recently,

00:02:12.160 --> 00:02:14.160
where it's so much easier to report now

00:02:14.160 --> 00:02:16.160
than it is to consume it.

00:02:16.160 --> 00:02:18.160
There is so much information; what do you do?

00:02:18.160 --> 00:02:21.160
This is the Twitter reports for over three days

00:02:21.160 --> 00:02:23.160
just covering Mumbai.

00:02:23.160 --> 00:02:25.160
How do you decide what is important?

00:02:25.160 --> 00:02:28.160
What is the veracity level of what you're looking at?

00:02:28.160 --> 00:02:30.160
So what we find is that there is this

00:02:30.160 --> 00:02:32.160
great deal of wasted crisis information

00:02:32.160 --> 00:02:35.160
because there is just too much information for us to

00:02:35.160 --> 00:02:38.160
actually do anything with right now.

00:02:38.160 --> 00:02:40.160
And what we're actually really concerned with

00:02:40.160 --> 00:02:42.160
is this first three hours.

00:02:42.160 --> 00:02:44.160
What we are looking at is the first three hours.

00:02:44.160 --> 00:02:47.160
How do we deal with that information that is coming in?

00:02:47.160 --> 00:02:49.160
You can't understand what is actually happening.

00:02:49.160 --> 00:02:51.160
On the ground and around the world

00:02:51.160 --> 00:02:53.160
people are still curious,

00:02:53.160 --> 00:02:56.160
and trying to figure out what is going on. But they don't know.

00:02:56.160 --> 00:02:59.160
So what we built of course, Ushahidi,

00:02:59.160 --> 00:03:01.160
is crowdsourcing this information.

00:03:01.160 --> 00:03:04.160
You see this with Twitter, too. You get this information overload.

00:03:04.160 --> 00:03:06.160
So you've got a lot of information. That's great.

00:03:06.160 --> 00:03:08.160
But now what?

00:03:08.160 --> 00:03:11.160
So we think that there is something interesting we can do here.

00:03:11.160 --> 00:03:13.160
And we have a small team who is working on this.

00:03:13.160 --> 00:03:15.160
We think that we can actually create

00:03:15.160 --> 00:03:17.160
a crowdsourced filter.

00:03:17.160 --> 00:03:20.160
Take the crowd and apply them to the information.

00:03:20.160 --> 00:03:22.160
And by rating it and by rating

00:03:22.160 --> 00:03:24.160
the different people who submit information,

00:03:24.160 --> 00:03:26.160
we can get refined results

00:03:26.160 --> 00:03:28.160
and weighted results.

00:03:28.160 --> 00:03:30.160
So that we have a better understanding

00:03:30.160 --> 00:03:32.160
of the probability of something being true or not.

00:03:32.160 --> 00:03:35.160
This is the kind of innovation that is,

00:03:35.160 --> 00:03:37.160
quite frankly -- it's interesting that it's coming from Africa.

00:03:37.160 --> 00:03:40.160
It's coming from places that you wouldn't expect.

00:03:40.160 --> 00:03:42.160
From young, smart developers.

00:03:42.160 --> 00:03:45.160
And it's a community around it that has decided to build this.

00:03:45.160 --> 00:03:47.160
So, thank you very much.

00:03:47.160 --> 00:03:49.160
And we are very happy to be part of the TED family.

00:03:49.160 --> 00:03:50.160
(Applause)

