WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Paola Lucciola
Revisore: Giacomo Boschi

00:00:12.160 --> 00:00:15.160
Ciao! Mi chiamo Golan Levin.

00:00:15.160 --> 00:00:17.160
Sono un artista ed un ingegnere

00:00:17.160 --> 00:00:19.160
che è una forma di ibrido sempre più diffusa.

00:00:19.160 --> 00:00:22.160
Ma rientro ancora in questa strana categoria

00:00:22.160 --> 00:00:24.160
che le persone non sembrano riuscire a comprendere.

00:00:24.160 --> 00:00:28.160
E mi stavo guardando intorno e ho trovato questa fantastica fotografia.

00:00:28.160 --> 00:00:31.160
È una lettera dell' "Artforum" del 1967

00:00:31.160 --> 00:00:34.160
che dice "Non possiamo assolutamente immaginare di fare un'edizione speciale

00:00:34.160 --> 00:00:37.160
sull'elettronica o i computer nell'arte." E ancora non l'hanno fatta.

00:00:37.160 --> 00:00:42.160
E siccome uno pensa che voi gente, in quanto digerati, siate più illuminati,

00:00:42.160 --> 00:00:45.160
l'altro giorno sono andato nell'application store dell'iPhone della Apple.

00:00:45.160 --> 00:00:49.160
Dov'è la voce arte? Ho trovato produttività. Ho trovato sport.

00:00:49.160 --> 00:00:53.160
E in qualche modo l'idea che uno possa voler fare arte per l'iPhone,

00:00:53.160 --> 00:00:55.160
come io e i miei amici stiamo facendo,

00:00:55.160 --> 00:00:58.160
non è ancora contemplata nel nostro modo di concepire

00:00:58.160 --> 00:01:00.160
l'utilizzo dei computer.

00:01:00.160 --> 00:01:02.160
Così, da entrambe le direzioni, c'è una certa, io credo, mancanza di comprensione

00:01:02.160 --> 00:01:04.160
su cosa possa significare essere un artista che usa materiali

00:01:04.160 --> 00:01:06.160
di tutti i giorni.

00:01:06.160 --> 00:01:08.160
Ciò che io credo gli artisti siano obbligati a fare

00:01:08.160 --> 00:01:12.160
è esplorare realmente il potenziale espressivo dei nuovi strumenti che abbiamo.

00:01:12.160 --> 00:01:14.160
Nel mio caso specifico, sono un artista

00:01:14.160 --> 00:01:16.160
e sono veramente interessato a

00:01:16.160 --> 00:01:18.160
espandere il vocabolario dell'azione umana

00:01:18.160 --> 00:01:21.160
e fondamentalmente dare potere alle persone attraverso l'interattività.

00:01:21.160 --> 00:01:24.160
Voglio che le persone si scoprano attori,

00:01:24.160 --> 00:01:28.160
nel senso di attori creativi, attraverso queste esperienze interattive.

00:01:28.160 --> 00:01:31.160
Gran parte del mio lavoro consiste nel tentare di liberarmi di questo.

00:01:31.160 --> 00:01:33.160
Questa è la fotografia della scrivania di un mio studente.

00:01:33.160 --> 00:01:35.160
E quando dico scrivania non in intendo solo

00:01:35.160 --> 00:01:38.160
il piano effettivo su cui il mouse ha consumato la superficie.

00:01:38.160 --> 00:01:40.160
Se guardate attentamente potete vedere anche

00:01:40.160 --> 00:01:43.160
un accenno del menu Apple, qui in alto a sinistra,

00:01:43.160 --> 00:01:45.160
dove il mondo virtuale ha letteralmente

00:01:45.160 --> 00:01:47.160
perforato quello fisico.

00:01:47.160 --> 00:01:51.160
Questo è, come disse una volta Joy Mountford,

00:01:51.160 --> 00:01:53.160
"Il mouse è probabilmente la cannuccia più stretta

00:01:53.160 --> 00:01:55.160
da cui si possa provare a succhiare le espressioni umane"

00:01:55.160 --> 00:01:58.160
(Risate)

00:01:58.160 --> 00:02:01.160
E ciò che sto realmente tentando di fare è fare in modo che le persone abbiano

00:02:01.160 --> 00:02:03.160
delle esperienze interattive più ricche.

00:02:03.160 --> 00:02:05.160
Come possiamo liberarci del mouse e usare tutto il nostro corpo

00:02:05.160 --> 00:02:08.160
come mezzo per esplorare esperienze estetiche,

00:02:08.160 --> 00:02:10.160
non necessariamente quelle utilitarie?

00:02:10.160 --> 00:02:13.160
Io scrivo dei software. È così che lo faccio.

00:02:13.160 --> 00:02:15.160
E molte delle mie esperienze

00:02:15.160 --> 00:02:17.160
assomigliano a degli specchi in qualche modo.

00:02:17.160 --> 00:02:19.160
Perché questo è, in qualche maniera, il primo modo

00:02:19.160 --> 00:02:21.160
in cui le persone scoprono il proprio potenziale

00:02:21.160 --> 00:02:23.160
come attori e la propria energia.

00:02:23.160 --> 00:02:26.160
Chiedendosi "Chi è quella persona nello specchio? Oh sono io."

00:02:26.160 --> 00:02:28.160
Quindi, per darvi un esempio,

00:02:28.160 --> 00:02:30.160
questo è un progetto dello scorso anno.

00:02:30.160 --> 00:02:32.160
Chiamato Interstitial Fragment Processor.

00:02:32.160 --> 00:02:36.160
E permette alle persone di esplorare le forme negative che creano

00:02:36.160 --> 00:02:39.160
mentre svolgono le loro faccende quotidiane.

00:02:53.160 --> 00:02:55.160
Perciò quando le persone creano delle forme con le mani o la testa

00:02:55.160 --> 00:02:57.160
eccetera, o le una con le altre,

00:02:57.160 --> 00:03:00.160
queste forme producono letteralmente dei suoni e vengono fuori dal nulla.

00:03:00.160 --> 00:03:04.160
Fondamentalmente prendendo ciò che spesso è una specie di spazio invisibile

00:03:04.160 --> 00:03:07.160
o che passa inosservato, e rendendolo qualcosa di reale,

00:03:07.160 --> 00:03:10.160
che le persone possono apprezzare e usare in modo creativo.

00:03:10.160 --> 00:03:13.160
Quindi di nuovo, le persone in questo modo scoprono il loro lato creativo.

00:03:13.160 --> 00:03:15.160
E la loro personalità viene fuori

00:03:15.160 --> 00:03:18.160
in modi totalmente unici.

00:03:18.160 --> 00:03:21.160
Poi oltre all'uso dell'intero corpo come input,

00:03:21.160 --> 00:03:23.160
qualcosa che ho esplorato già da un po'

00:03:23.160 --> 00:03:25.160
è stato l'uso della voce.

00:03:25.160 --> 00:03:29.160
Che è un sistema immensamente espressivo per noi, la vocalizzazione.

00:03:29.160 --> 00:03:31.160
Cantare è uno dei modi più antichi che abbiamo

00:03:31.160 --> 00:03:34.160
per farci sentire e capire.

00:03:34.160 --> 00:03:36.160
E mi sono imbattuto in questa fantastica ricerca di Wolfgang Köhler,

00:03:36.160 --> 00:03:40.160
il cosiddetto padre della psicologia della Gestalt, del 1927,

00:03:40.160 --> 00:03:42.160
che ha mostrato ad un pubblico come voi

00:03:42.160 --> 00:03:44.160
queste due forme.

00:03:44.160 --> 00:03:46.160
E ha detto loro che una si chiamava Maluma

00:03:46.160 --> 00:03:48.160
e un'altra si chiamava Taketa. Qual è quale?

00:03:48.160 --> 00:03:52.160
Qualcuno vuole provare ad indovinare?

00:03:52.160 --> 00:03:54.160
Maluma è quella di sopra. Sì. Quindi

00:03:54.160 --> 00:03:57.160
come lui afferma qui, la maggior parte delle persone risponde senza esitazioni.

00:03:57.160 --> 00:03:59.160
Quindi ciò che stiamo vedendo davvero qui è un fenomeno

00:03:59.160 --> 00:04:01.160
chiamato fonestesia,

00:04:01.160 --> 00:04:03.160
che è un tipo di sinestesia che ognuno di voi possiede.

00:04:03.160 --> 00:04:05.160
E quindi, mentre il Dr. Oliver Sacks ha spiegato

00:04:05.160 --> 00:04:07.160
come forse una persona su un milione

00:04:07.160 --> 00:04:09.160
ha in effetti una vera sinestesia,

00:04:09.160 --> 00:04:11.160
nel caso in cui sentano dei colori o assaporino delle forme, e cose del genere,

00:04:11.160 --> 00:04:13.160
la fonestesia è qualcosa che tutti possiamo sperimentare ad un certo livello.

00:04:13.160 --> 00:04:16.160
Si tratta di mappature tra diversi dominii percettivi,

00:04:16.160 --> 00:04:19.160
come durezza, affilatura, luminosità e oscurità,

00:04:19.160 --> 00:04:21.160
e i fonemi con cui siamo capaci di parlare.

00:04:21.160 --> 00:04:23.160
Quindi negli ultimi 70 anni ci sono state ricerche in cui

00:04:23.160 --> 00:04:25.160
gli psicologi cognitivi hanno in effetti intuito

00:04:25.160 --> 00:04:27.160
fino a che punto, ad esempio,

00:04:27.160 --> 00:04:31.160
la L, la M e la B sono associate maggiormente con forme come queste,

00:04:31.160 --> 00:04:35.160
e la P, la T e la K sono generalmente più associate a forme come queste.

00:04:35.160 --> 00:04:37.160
E a questo punto iniziamo ad avere una mappatura tra curvature

00:04:37.160 --> 00:04:39.160
che possiamo sfruttare numericamente,

00:04:39.160 --> 00:04:42.160
una mappatura relativa tra curvatura e discorso.

00:04:42.160 --> 00:04:45.160
Perciò mi sono chiesto, che succederebbe se potessimo scorrerle all'indietro?

00:04:45.160 --> 00:04:47.160
E di conseguenza è nato il progetto chiamato Remark

00:04:47.160 --> 00:04:49.160
che è una collaborazione con Zachary Lieberman

00:04:49.160 --> 00:04:51.160
e l'Ars Electronica Futurelab.

00:04:51.160 --> 00:04:53.160
E questa è un'installazione interattiva che presenta

00:04:53.160 --> 00:04:55.160
la finzione di un discorso che proietta ombre visibili.

00:04:55.160 --> 00:04:58.160
Quindi l'idea è che tu entri in una specie di luce magica.

00:04:58.160 --> 00:05:01.160
E quando lo fai vedi le ombre del tuo stesso discorso.

00:05:01.160 --> 00:05:03.160
Ed è come se volassero via, fuori dalla tua testa.

00:05:03.160 --> 00:05:06.160
Se il sistema di riconoscimento vocale del computer

00:05:06.160 --> 00:05:10.160
è capace di capire quello che dici, allora lo scandisce.

00:05:10.160 --> 00:05:12.160
E se non lo è allora produce una forma molto fonesteticamente

00:05:12.160 --> 00:05:14.160
vicina al suono che hai prodotto.

00:05:14.160 --> 00:05:17.160
Mostriamone un video.

00:06:03.160 --> 00:06:05.160
(Applausi)

00:06:05.160 --> 00:06:08.160
Grazie. E su questo progetto qui,

00:06:08.160 --> 00:06:11.160
stavo lavorando con il grande vocalist astratto, Jaap Blonk.

00:06:11.160 --> 00:06:14.160
E lui è un esperto mondiale nell'eseguire la "Ursonate",

00:06:14.160 --> 00:06:16.160
che è una poesia di mezz'ora senza senso

00:06:16.160 --> 00:06:18.160
di Kurt Schwitters, scritta negli anni 20.

00:06:18.160 --> 00:06:22.160
È una mezzora di non senso molto fantasioso.

00:06:22.160 --> 00:06:24.160
Ed è quasi impossibile da eseguire.

00:06:24.160 --> 00:06:27.160
Ma Jaap è uno dei più grandi esperti del mondo di questa recitazione.

00:06:27.160 --> 00:06:29.160
Ed in questo progetto abbiamo sviluppato

00:06:29.160 --> 00:06:32.160
una forma di sottotoli intelligenti in tempo reale.

00:06:32.160 --> 00:06:35.160
Questi sono quindi i nostri sottotitoli in diretta

00:06:35.160 --> 00:06:38.160
prodotti da un computer che conosce il testo della "Ursonate",

00:06:38.160 --> 00:06:41.160
fortunatamente anche Jaap lo conosce bene.

00:06:41.160 --> 00:06:46.160
E il computer riproduce il testo esattamente mentre Jaap lo recita.

00:06:53.160 --> 00:06:55.160
Per cui tutto il testo che state per vedere

00:06:55.160 --> 00:06:57.160
è generato in tempo reale dal computer

00:06:57.160 --> 00:07:00.160
che visualizza ciò che lui fa con la voce.

00:08:10.160 --> 00:08:13.160
Qui potete vedere l'allestimento in cui c'è uno schermo con i sottotitoli dietro di lui.

00:08:34.160 --> 00:08:36.160
Ok. Quindi...

00:08:36.160 --> 00:08:41.160
(Applausi)

00:08:41.160 --> 00:08:43.160
I video interi sono online se siete interessati.

00:08:43.160 --> 00:08:45.160
Ho avuto diverse reazioni durante l'esecuzione live.

00:08:45.160 --> 00:08:47.160
Perché c'è gente che si rende conto

00:08:47.160 --> 00:08:49.160
che i sottotitoli in diretta sono una specie di ossimoro

00:08:49.160 --> 00:08:52.160
dal momento che normalmente c'è qualcuno che li produce successivamente.

00:08:52.160 --> 00:08:55.160
E poi c'è stato un gruppo di persone che hanno reagito tipo "Cosa c'è di tanto speciale?

00:08:55.160 --> 00:08:57.160
Vedo sempre i sottotitoli in televisione."

00:08:57.160 --> 00:09:00.160
Capite? Non si immaginano la persona nella cabina che li batte al computer.

00:09:00.160 --> 00:09:03.160
Quindi oltre al corpo, e oltre alla voce,

00:09:03.160 --> 00:09:05.160
un'altra cosa alla quale mi sono molto interessato

00:09:05.160 --> 00:09:07.160
recentemente è l'uso degli occhi,

00:09:07.160 --> 00:09:11.160
o dello sguardo, in termini di come le persone si relazionano le une alle altre.

00:09:11.160 --> 00:09:13.160
C'è una grossa quantità di informazioni non verbali

00:09:13.160 --> 00:09:15.160
che viene comunicata con gli occhi.

00:09:15.160 --> 00:09:17.160
Ed è una delle sfide tecniche più interessanti

00:09:17.160 --> 00:09:19.160
tra quelle presenti al momento nella disciplina informatica,

00:09:19.160 --> 00:09:21.160
potere avere una telecamera capace di capire,

00:09:21.160 --> 00:09:23.160
da una distanza abbastanza grande,

00:09:23.160 --> 00:09:26.160
come queste piccole palline stiano in effetti guardando da una parte piuttosto che un'altra,

00:09:26.160 --> 00:09:28.160
per rivelare ciò a cui siete veramente interessati,

00:09:28.160 --> 00:09:30.160
e a cosa la vostra attenzione sia diretta.

00:09:30.160 --> 00:09:33.160
C'è quindi una forte componente di comunicazione emozionale qui.

00:09:33.160 --> 00:09:37.160
Ed ho quindi iniziato, con una serie di diversi progetti,

00:09:37.160 --> 00:09:40.160
a capire come le persone si possano relazionare alle macchine attraverso gli occhi.

00:09:40.160 --> 00:09:43.160
E fondamentalmente a domandarmi,

00:09:43.160 --> 00:09:48.160
Cosa succederebbe se l'arte fosse cosciente che la stiamo guardando?

00:09:48.160 --> 00:09:50.160
Come potrebbe rispondere, in qualche modo,

00:09:50.160 --> 00:09:53.160
per far capire o sabotare il fatto che la stiamo guardando?

00:09:53.160 --> 00:09:56.160
E cosa potrebbe fare se potesse guardarci a sua volta?

00:09:56.160 --> 00:09:58.160
Queste sono quindi le domande che mi sono posto nei progetti successivi.

00:09:58.160 --> 00:10:01.160
Nel primo, che sto per mostrarvi, chiamato Eyecode,

00:10:01.160 --> 00:10:03.160
abbiamo un pezzo di software interattivo

00:10:03.160 --> 00:10:05.160
nel quale, se leggiamo questo piccolo cerchio,

00:10:05.160 --> 00:10:08.160
"la traccia lasciata dallo sguardo dell'osservatore precedente

00:10:08.160 --> 00:10:11.160
guarda alla traccia lasciata dallo sguardo dell'osservatore precedente."

00:10:11.160 --> 00:10:13.160
L'idea è che si tratti di un'immagine costruita completamente

00:10:13.160 --> 00:10:15.160
dalla sua stessa esperienza cronologica dell'essere osservata

00:10:15.160 --> 00:10:17.160
da diverse persone durante un'installazione.

00:10:17.160 --> 00:10:22.160
Allora passiamo alla dimostrazione del vivo.

00:10:22.160 --> 00:10:26.160
Facciamo partire questo e vediamo se funziona.

00:10:26.160 --> 00:10:29.160
Ok. Ah, ci sono un sacco di begli schermi luminosi.

00:10:29.160 --> 00:10:31.160
C'è prima un piccolo test screen che mostra che funziona.

00:10:31.160 --> 00:10:33.160
Adesso lo nascondo

00:10:33.160 --> 00:10:35.160
così potete vedere che ciò che fa

00:10:35.160 --> 00:10:38.160
è registrare i miei occhi ogni volta che sbatto le palpebre.

00:10:44.160 --> 00:10:48.160
Ciao? E posso... ciao... ok.

00:10:48.160 --> 00:10:50.160
E a prescindere da dove sono, ciò che abbiamo qui

00:10:50.160 --> 00:10:53.160
è un sistema di tracciamento degli occhi che cerca di trovare i miei occhi.

00:10:53.160 --> 00:10:55.160
E se mi allontano molto sono sfocato.

00:10:55.160 --> 00:10:57.160
Vedete, abbiano questi puntini sfocati tipo questi

00:10:57.160 --> 00:11:00.160
che magari assomigliano agli occhi solo in modo molto astratto.

00:11:00.160 --> 00:11:03.160
Ma se mi avvicino molto e guardo diritto nella camera

00:11:03.160 --> 00:11:05.160
di questo computer allora vedrete questi begl'occhi nitidi.

00:11:05.160 --> 00:11:09.160
Potete pensarlo come una sorta di modo di battere a macchina con i vostri occhi.

00:11:09.160 --> 00:11:11.160
E ciò che battete sono registrazioni dei vostri occhi

00:11:11.160 --> 00:11:13.160
come se steste guardando gli occhi di altre persone.

00:11:13.160 --> 00:11:16.160
Perciò ogni persona guarda gli sguardi

00:11:16.160 --> 00:11:18.160
di tutti quelli venuti prima di loro.

00:11:18.160 --> 00:11:20.160
E ciò è possibile anche in installazioni più grandi

00:11:20.160 --> 00:11:22.160
in cui ci sono migliaia e migliaia di occhi

00:11:22.160 --> 00:11:24.160
che le persone possono guardare,

00:11:24.160 --> 00:11:26.160
in modo che uno veda chi guarda le persone che guardano

00:11:26.160 --> 00:11:28.160
le persone che hanno guardato prima di loro.

00:11:28.160 --> 00:11:31.160
Aggiungo solo un paio di occhiate in più.

00:11:31.160 --> 00:11:34.160
E potete vedere come, ancora una volta, cerca in qualche modo di trovare i miei occhi

00:11:34.160 --> 00:11:37.160
e prevedere come meglio può quando sbatterò le palpebre.

00:11:37.160 --> 00:11:39.160
Bene. Togliamo questo.

00:11:39.160 --> 00:11:42.160
Perciò questo è questa specie di sistema di osservazione ricorsivo.

00:11:42.160 --> 00:11:44.160
(Applausi)

00:11:44.160 --> 00:11:46.160
Grazie.

00:11:46.160 --> 00:11:48.160
L'ultimo paio di pezzi che sto per mostrarvi

00:11:48.160 --> 00:11:50.160
fanno parte fondamentalmente nel nuovo regno della robotica, nuovo per me.

00:11:50.160 --> 00:11:52.160
è chiamato Opto-Isolator.

00:11:52.160 --> 00:11:55.160
Sto per mostrarvi un video della vecchia versione.

00:11:55.160 --> 00:11:57.160
Che dura solo un minuto. Ok.

00:12:06.160 --> 00:12:08.160
In questo caso, l'Opto-Isolator sbatte la palpebra

00:12:08.160 --> 00:12:10.160
in risposta al battito di palpebra di qualcun'altro.

00:12:10.160 --> 00:12:13.160
Per cui sbatte la palpebra un secondo dopo di voi.

00:12:13.160 --> 00:12:16.160
Questo è un dispositivo che serve a ridurre

00:12:16.160 --> 00:12:19.160
il fenomeno del fissare fino ai materiali più semplici possibili.

00:12:19.160 --> 00:12:21.160
Un solo occhio,

00:12:21.160 --> 00:12:23.160
che ti guarda, eliminando qualsiasi altra cosa faccia parte della faccia.

00:12:23.160 --> 00:12:26.160
Per considerare lo sguardo in modo isolato

00:12:26.160 --> 00:12:29.160
come una specie di elemento a sé stante.

00:12:29.160 --> 00:12:32.160
E allo stesso tempo, cerca di impegnarsi in ciò che potreste chiamare

00:12:32.160 --> 00:12:34.160
comuni comportamenti psico-sociali di sguardi.

00:12:34.160 --> 00:12:36.160
Tipo distogliere lo sguardo se lo fissi troppo a lungo

00:12:36.160 --> 00:12:38.160
perché diventa timido.

00:12:38.160 --> 00:12:41.160
O cose del genere.

00:12:41.160 --> 00:12:44.160
Ok. Allora l'ultimo progetto che vado a mostrarvi

00:12:44.160 --> 00:12:47.160
è questo nuovo chiamato Snout.

00:12:47.160 --> 00:12:49.160
(Risate)

00:12:49.160 --> 00:12:51.160
Si tratta di un muso alto otto piedi,

00:12:51.160 --> 00:12:53.160
con un occhio mobile.

00:12:53.160 --> 00:12:54.160
(Risate)

00:12:54.160 --> 00:12:57.160
E all'interno ha un braccio robotico di 800 libbre

00:12:57.160 --> 00:12:59.160
che ho preso in prestito

00:12:59.160 --> 00:13:00.160
(Risate)

00:13:00.160 --> 00:13:02.160
da un amico.

00:13:02.160 --> 00:13:03.160
(Risate)

00:13:03.160 --> 00:13:05.160
È utile avere buoni amici.

00:13:05.160 --> 00:13:08.160
Sono al Carnegie Mellon. Abbiamo un fantastico Istituto di Robotica lì.

00:13:08.160 --> 00:13:10.160
Vorrei mostrarvi questa cosa chiamata Snout che è...

00:13:10.160 --> 00:13:12.160
L'idea alla base di questo progetto è di

00:13:12.160 --> 00:13:16.160
costruire un robot che sembri continuamente sorpreso di vederti.

00:13:16.160 --> 00:13:20.160
(Risate)

00:13:20.160 --> 00:13:22.160
L'idea è fondamentalmente che...

00:13:22.160 --> 00:13:24.160
se fa costantemente tipo "Huh?... Huh?"

00:13:24.160 --> 00:13:28.160
È per questo che il suo secondo nome è Doubletaker, colui che prende due volte.

00:13:28.160 --> 00:13:30.160
È sempre come se facesse un doppio: "Che?"

00:13:30.160 --> 00:13:32.160
L'idea è praticamente che ti guardi

00:13:32.160 --> 00:13:34.160
e ti faccia sentire tipo,

00:13:34.160 --> 00:13:36.160
"Cos'ho che non va? Sono le mie scarpe?"

00:13:36.160 --> 00:13:39.160
"Ho qualcosa tra i capelli?" Eccoci. Bene.

00:14:10.160 --> 00:14:12.160
Lo osserva...

00:14:20.160 --> 00:14:22.160
Per voi capoccioni, ecco un piccolo dietro le quinte.

00:14:22.160 --> 00:14:24.160
Ha un sistema visivo computerizzato

00:14:24.160 --> 00:14:27.160
e cerca di guardare le persone che si muovono di più.

00:14:39.160 --> 00:14:41.160
Questi sono i suoi target.

00:14:42.160 --> 00:14:44.160
Quassù c'è lo scheletro,

00:14:44.160 --> 00:14:47.160
che è quello che in effetti sta cercando di fare.

00:14:54.160 --> 00:14:57.160
Si tratta davvero di creare un linguaggio del corpo nuovo per una creatura nuova.

00:14:57.160 --> 00:14:59.160
Hollywood lo fa tutto il tempo naturalmente.

00:14:59.160 --> 00:15:01.160
Ma anche di usare il linguaggio del corpo per comunicare qualcosa

00:15:01.160 --> 00:15:03.160
alla persona che lo sta guardando.

00:15:03.160 --> 00:15:05.160
Questo linguaggio sta comunicando che è sorpreso di vedervi,

00:15:05.160 --> 00:15:08.160
e gli interessa guardarvi.

00:15:08.160 --> 00:15:10.160
(Risate)

00:15:10.160 --> 00:15:19.160
(Applausi)

00:15:19.160 --> 00:15:21.160
Grazie mille. Questo è tutto per oggi.

00:15:21.160 --> 00:15:24.160
E sono molto felice di essere qui. Grazie mille.

00:15:24.160 --> 00:15:27.160
(Applausi)

