WEBVTT
Kind: captions
Language: pl

00:00:00.000 --> 00:00:07.000
Tłumaczenie: Jacek Malewski
Korekta: Marcin Kasiak

00:00:12.160 --> 00:00:15.160
Nazywam się Golan Levin.

00:00:15.160 --> 00:00:17.160
Jestem artystą-inżynierem.

00:00:17.160 --> 00:00:19.160
Choć to coraz powszechniejszy rodzaj hybrydy,

00:00:19.160 --> 00:00:22.160
ciągle jeszcze wpadam w tę dziwną dziurę

00:00:22.160 --> 00:00:24.160
gdzie nikt mnie nie rozumie.

00:00:24.160 --> 00:00:28.160
Myszkując tak po otoczeniu, znalazłem tę wspaniałą ilustrację.

00:00:28.160 --> 00:00:31.160
List opublikowany w piśmie “Artforum” z 1967 roku, mówiący:

00:00:31.160 --> 00:00:34.160
”Nie potrafimy sobie wyobrazić, że kiedykolwiek wydamy specjalny numer

00:00:34.160 --> 00:00:37.160
poświęcony sztuce elektronicznej lub komputerowej.” I do dziś tego nie zrobili.

00:00:37.160 --> 00:00:42.160
I niech się nam nie wydaje, że my jako elita, jako digerati, należymy do tych bardziej oświeconych.

00:00:42.160 --> 00:00:45.160
Wszedłem kiedyś do sklepu z aplikacjami na iPhone'a, firmy Apple.

00:00:45.160 --> 00:00:49.160
Gdzie jest Sztuka? Znalazłem produkcyjność, znalazłem sport.

00:00:49.160 --> 00:00:53.160
I w jakiś dziwny sposób sam pomysł, że ktoś chciałby tworzyć dzieła sztuki dla iPhone'a,

00:00:53.160 --> 00:00:55.160
coś, czym ja i moi przyjaciele właśnie się zajmujemy,

00:00:55.160 --> 00:00:58.160
wciąż nie znajduje odbicia w naszym pojęciu

00:00:58.160 --> 00:01:00.160
do czego powinny służyć nam komputery.

00:01:00.160 --> 00:01:02.160
Myślę, że po obu stronach - twócy i odbiorcy - istnieje brak zrozumienia

00:01:02.160 --> 00:01:04.160
co oznacza bycie artystą używającym w swej twórczości

00:01:04.160 --> 00:01:06.160
współczesnych mu materiałów.

00:01:06.160 --> 00:01:08.160
Myślę, że obowiązkiem artystów jest

00:01:08.160 --> 00:01:12.160
twórcze eksplorowanie potencjału ekspresji nowych narzędzi, jakie posiadamy.

00:01:12.160 --> 00:01:14.160
W moim przypadku, będąc artystą,

00:01:14.160 --> 00:01:16.160
jestem zainteresowany

00:01:16.160 --> 00:01:18.160
rozrzerzaniem języka ludzkich działań

00:01:18.160 --> 00:01:21.160
i wzbogacaniem ludzi poprzez interaktywność.

00:01:21.160 --> 00:01:24.160
Chcialbym, aby ludzie odkrywali w sobie kreatywnych aktorów,

00:01:24.160 --> 00:01:28.160
poprzez interaktywne doświadczenia.

00:01:28.160 --> 00:01:31.160
Podłożem wielu moich prac jest próba ucieczki od czegoś takiego jak...

00:01:31.160 --> 00:01:33.160
To jest zdjęcie pulpitu jednego z moich studentów.

00:01:33.160 --> 00:01:35.160
I kiedy mowię pulpit to mam na myśli więcej

00:01:35.160 --> 00:01:38.160
niż samą powierzchnię biurka, “wygryzioną” przez myszkę jego komputera.

00:01:38.160 --> 00:01:40.160
Patrząc uważnie, możemy zauważyć

00:01:40.160 --> 00:01:43.160
w lewym górnym rogu ślad przypominający pasek menu Appla,

00:01:43.160 --> 00:01:45.160
miejsce, w którym świat wirtualny dosłownie

00:01:45.160 --> 00:01:47.160
przebił się do świata materialnego.

00:01:47.160 --> 00:01:51.160
Właśnie o czymś takim Joy Mountford powiedział kiedyś:

00:01:51.160 --> 00:01:53.160
“‘ogonek’ myszki, to najcieńsze połączenie,

00:01:53.160 --> 00:01:55.160
przez które mógłby przepłynąć całokształt wyrazu ludzkich emocji.”

00:01:55.160 --> 00:01:58.160
(śmiech)

00:01:58.160 --> 00:02:01.160
Czego tak naprawdę próbuję dokonać, to umożliwienie ludziom

00:02:01.160 --> 00:02:03.160
posiadania bogatszych interaktywnych doznań.

00:02:03.160 --> 00:02:05.160
Aby uciekając od komputerowej myszki, mogli używać całego ciała

00:02:05.160 --> 00:02:08.160
jako sposobu odkrywania doznań estetycznych,

00:02:08.160 --> 00:02:10.160
nawet niekoniecznie pożytecznych bądź niezbędnych im w życiu.

00:02:10.160 --> 00:02:13.160
Aby to osiągnąć, piszę programy komputerowe.

00:02:13.160 --> 00:02:15.160
Większość moich eksperymentów

00:02:15.160 --> 00:02:17.160
przypomina w pewien sposób lustro.

00:02:17.160 --> 00:02:19.160
Ponieważ właśnie w lustrze ludzie często po raz pierwszy

00:02:19.160 --> 00:02:21.160
odkrywają swoje zdolności aktorskie,

00:02:21.160 --> 00:02:23.160
stając się swą własną agencją teatralną.

00:02:23.160 --> 00:02:26.160
Mówiąc sobie: “Kim jest ta postać w lustrze? Ach, to właśnie ja.”

00:02:26.160 --> 00:02:28.160
Dla przykładu -

00:02:28.160 --> 00:02:30.160
to jest projekt z zeszłego roku.

00:02:30.160 --> 00:02:32.160
Nazwałem go Procesorem Fragmentów Międzywęzłowych.

00:02:32.160 --> 00:02:36.160
Projekt ten umożliwia ludziom odkrywanie pustych przestrzeni,

00:02:36.160 --> 00:02:39.160
które sami kreują, podczas swoich codziennych zajęć.

00:02:53.160 --> 00:02:55.160
Otóż, gdy ludzie przy pomocy swych rąk, głów itp.-

00:02:55.160 --> 00:02:57.160
sami lub wraz z innymi - zamykają przestrzeń, tworząc z niej formy,

00:02:57.160 --> 00:03:00.160
formy te dosłownie produkują dźwięki, materializując się na ekranie.

00:03:00.160 --> 00:03:04.160
W zasadzie polega to na wychwytywaniu tej dotychczas niewidzianej czy

00:03:04.160 --> 00:03:07.160
niedostrzeganej przestrzeni i przeobrażaniu jej w coś realnego.

00:03:07.160 --> 00:03:10.160
W coś, co ludzie mogą docenić jako tworzywo dla swojej inwencji.

00:03:10.160 --> 00:03:13.160
W ten sposób ludzie odkrywają swoje zasoby kreatywności.

00:03:13.160 --> 00:03:15.160
Ich osobowość ujawnia się

00:03:15.160 --> 00:03:18.160
w zupełnie niepowtarzalny sposób.

00:03:18.160 --> 00:03:21.160
Oprócz używania całego ciała jako wprowadzanego "tworzywa"

00:03:21.160 --> 00:03:23.160
od pewnego czasu zajmuję się

00:03:23.160 --> 00:03:25.160
wykorzystywaniem głosu.

00:03:25.160 --> 00:03:29.160
Niezwykle ekspresywnym środkiem wyrazu, jakim jest dla nas wokalizacja.

00:03:29.160 --> 00:03:31.160
Śpiew jest jednym z najstarszych sposobów

00:03:31.160 --> 00:03:34.160
aby dać się usłyszeć i zrozumieć.

00:03:34.160 --> 00:03:36.160
Natknąłem się na fantastyczną pracę Wolfganga Köhlera,

00:03:36.160 --> 00:03:40.160
zwanego ojcem psychologi postaci (gestaltyzmu).

00:03:40.160 --> 00:03:42.160
W roku 1927 pokazał on podobnemu do tego tu audytorium,

00:03:42.160 --> 00:03:44.160
dwie figury.

00:03:44.160 --> 00:03:46.160
Powiedział: jedna z nich nazywa się Maluma

00:03:46.160 --> 00:03:48.160
a druga Takita. Która jest którą?

00:03:48.160 --> 00:03:52.160
Kto się odważy zaryzykować odpowiedź?

00:03:52.160 --> 00:03:54.160
Maluma to ta górna. Zgadza się.

00:03:54.160 --> 00:03:57.160
Jak sam stwierdził, większość ludzi odpowiadała bez wahania.

00:03:57.160 --> 00:03:59.160
To, co tak naprawdę tu postrzegamy, to zjawisko

00:03:59.160 --> 00:04:01.160
zwane fonestezją,

00:04:01.160 --> 00:04:03.160
będące pewnym rodzajem synestezji, którą wszyscy posiadamy.

00:04:03.160 --> 00:04:05.160
A zatem, jak mówił dr Oliver Sacks,

00:04:05.160 --> 00:04:07.160
może tylko jedna osoba na milion

00:04:07.160 --> 00:04:09.160
posiada prawdziwą zdolność synestezji,

00:04:09.160 --> 00:04:11.160
pozwalającą słyszeć kolory lub czuć smak kształtów itp., natomiast fonestezja

00:04:11.160 --> 00:04:13.160
jest czymś, czego wszyscy do pewnego stopnia doświadczamy.

00:04:13.160 --> 00:04:16.160
Chodzi tu o mapowanie pomiędzy różnymi obszarami percepcji

00:04:16.160 --> 00:04:19.160
cech takich, jak twardość, ostrość, jasność, ciemność,

00:04:19.160 --> 00:04:21.160
a fonemami, których możemy używać, by mówić.

00:04:21.160 --> 00:04:23.160
W ciągu 70 lat badacze zajmujący się psychologią poznawczą

00:04:23.160 --> 00:04:25.160
zdołali określić stopień

00:04:25.160 --> 00:04:27.160
w jakim, powiedzmy sobie,

00:04:27.160 --> 00:04:31.160
głoski L, M i B są kojarzone z takim ksztaltem,

00:04:31.160 --> 00:04:35.160
a na przykład głoski P, T i K z kształtem takim jak ten.

00:04:35.160 --> 00:04:37.160
I tu nagle zaczynamy uzyskiwać mapowanie pomiędzy krzywiznami

00:04:37.160 --> 00:04:39.160
które możemy wykorzystywać numerycznie,

00:04:39.160 --> 00:04:42.160
relatywne mapowanie pomiędzy krzywiznami a naszą mową.

00:04:42.160 --> 00:04:45.160
Przyszło mi wówczas do głowy: co stanie się gdy odwrócimy ten proces?

00:04:45.160 --> 00:04:47.160
Tak narodził się projekt Remark (Komentarz),

00:04:47.160 --> 00:04:49.160
realizowany we współpracy z Zacharym Liebermanem

00:04:49.160 --> 00:04:51.160
i Ars Electronic Futurelab.

00:04:51.160 --> 00:04:53.160
To taka interaktywna instalacja wywołująca wrażenie,

00:04:53.160 --> 00:04:55.160
że mowa tworzy widoczne dla nas cienie sylwetek.

00:04:55.160 --> 00:04:58.160
Wygląda to tak: wstępujemy w rodzaj magicznego światła

00:04:58.160 --> 00:05:01.160
i widzimy kształty wywołane naszym głosem

00:05:01.160 --> 00:05:03.160
jak gdyby wyfruwające z naszej głowy.

00:05:03.160 --> 00:05:06.160
Jeśli komputerowy system rozpoznawania mowy

00:05:06.160 --> 00:05:10.160
jest w stanie rozpoznać co mówimy, pisze to na ekranie,

00:05:10.160 --> 00:05:12.160
jeśli nie, pokazuje nam kształt ściśle powiązany fonestetycznie

00:05:12.160 --> 00:05:14.160
z wytworzonymi dźwiękami.

00:05:14.160 --> 00:05:17.160
Obejrzyjmy to na filmie

00:06:03.160 --> 00:06:05.160
(aplauz)

00:06:05.160 --> 00:06:08.160
Dziękuję. Nad następnym projektem

00:06:08.160 --> 00:06:11.160
pracowałem wspólnie ze wspaniałym “abstrakcyjnym” wokalistą, Jaapem Blonk.

00:06:11.160 --> 00:06:14.160
Jaap jest światowym ekspertem w deklamowaniu “Ursonaty”,

00:06:14.160 --> 00:06:16.160
półgodzinnego poematu nonsensu,

00:06:16.160 --> 00:06:18.160
napisanego latach 20-stych przez Kurta Schwittersa.

00:06:18.160 --> 00:06:22.160
Ursonata zawiera pół godziny bardzo ustrukturyzowanego nonsensu,

00:06:22.160 --> 00:06:24.160
i uchodzi za wręcz niemożliwą do wykonania.

00:06:24.160 --> 00:06:27.160
Na szczęście Jaap należy do światowych ekspertów, w deklamacji tego utworu.

00:06:27.160 --> 00:06:29.160
W tym projekcie stworzyliśmy rodzaj

00:06:29.160 --> 00:06:32.160
inteligentnych napisów do filmu, powstających się w czasie rzeczywistym.

00:06:32.160 --> 00:06:35.160
Nasze napisy produkowane są "na żywo"

00:06:35.160 --> 00:06:38.160
przez komputer znający treść “Ursonaty”;

00:06:38.160 --> 00:06:41.160
który Jaap, na szczęście, zna równie dobrze.

00:06:41.160 --> 00:06:46.160
Czyli tekst pojawia się w tym samym momencie, kiedy Jaap go recytuje.

00:06:53.160 --> 00:06:55.160
Tak więc wszystkie napisy jakie zobaczycie,

00:06:55.160 --> 00:06:57.160
będą generowane w czasie rzeczywistym przez komputer,

00:06:57.160 --> 00:07:00.160
wizualizujący wszystko to, co Jaap robi ze swoim głosem

00:08:10.160 --> 00:08:13.160
W takiej, jak tu konfiguracji, ekran z napisami znajduje się za jego plecami

00:08:34.160 --> 00:08:36.160
Dobra, następny...

00:08:36.160 --> 00:08:41.160
(aplauz)

00:08:41.160 --> 00:08:43.160
Dla zainteresowanych dostępne są w Sieci pełne wersje tych filmów.

00:08:43.160 --> 00:08:45.160
Reakcje podczas naszego występu były podzielone,

00:08:45.160 --> 00:08:47.160
ponieważ niektórzy ludzie uważają określenie:

00:08:47.160 --> 00:08:49.160
"napisy 'na żywo'” za oksymoron.

00:08:49.160 --> 00:08:52.160
Z reguły robi się je dopiero po zakończeniu produkcji.

00:08:52.160 --> 00:08:55.160
Była też grupa, mówiąca: "Cóż w tym takiego?"

00:08:55.160 --> 00:08:57.160
"Codziennie widzę napisy w telewizorze." Wyobrażacie to sobie?

00:08:57.160 --> 00:09:00.160
Nawet przez chwilę nie pomyśleli o tym gościu w "pudle", który wszystko to musi wystukać.

00:09:00.160 --> 00:09:03.160
Tak więc oprócz ciała, i oprócz głosu

00:09:03.160 --> 00:09:05.160
zainteresował mnie ostatnio sposób,

00:09:05.160 --> 00:09:07.160
w jaki korzystamy z naszych oczu,

00:09:07.160 --> 00:09:11.160
a zwłaszcza jak ludzie odnoszą się do siebie poprzez spojrzenia.

00:09:11.160 --> 00:09:13.160
Doprawdy znaczna ilość niewerbalnych komunikatów

00:09:13.160 --> 00:09:15.160
przekazywana jest poprzez kontakt wzrokowy.

00:09:15.160 --> 00:09:17.160
Jest to jedno z najbardziej interesujących wyzwań,

00:09:17.160 --> 00:09:19.160
stawianych ostatnio informatyce.

00:09:19.160 --> 00:09:21.160
Możliwość posiadania kamery będącej w stanie określić,

00:09:21.160 --> 00:09:23.160
nawet ze sporej odległości,

00:09:23.160 --> 00:09:26.160
w którym kierunku nasze gałki oczne są skierowane,

00:09:26.160 --> 00:09:28.160
zdradzając jednocześnie, co nas zainteresowało

00:09:28.160 --> 00:09:30.160
lub przyciągnęło naszą uwagę.

00:09:30.160 --> 00:09:33.160
Czyli zachodzi tu przekaz wielu emocjonalnych komunikatów.

00:09:33.160 --> 00:09:37.160
Rozpocząłem więc całą serię różnych projektów,

00:09:37.160 --> 00:09:40.160
aby zrozumieć, jak ludzie, mogą kontaktować się z maszyną przy pomocy oczu.

00:09:40.160 --> 00:09:43.160
Przede wszystkim zaś, by zadać następujące pytania.

00:09:43.160 --> 00:09:48.160
Co stałoby się, gdyby sztuka była świadoma tego, że na nią patrzymy?

00:09:48.160 --> 00:09:50.160
Jak mogłaby reagować, w sensie

00:09:50.160 --> 00:09:53.160
potwierdzenia bądź zignorowania faktu, że na nią patrzymy?

00:09:53.160 --> 00:09:56.160
I co uczyniłaby sztuka, gdyby mogła patrzeć na nas?

00:09:56.160 --> 00:09:58.160
Odpowiedzi na te pytania próbowałem znaleźć w projektach które teraz przedstawię.

00:09:58.160 --> 00:10:01.160
Pierwszy projekt nazywa się Kod Oka (Eyecode).

00:10:01.160 --> 00:10:03.160
Jest to prosty interaktywny program komputerowy,

00:10:03.160 --> 00:10:05.160
w którym, jak czytamy w tym małym kółeczku:

00:10:05.160 --> 00:10:08.160
“ślad zostawiony przez spojrzenie poprzedniego obserwatora,

00:10:08.160 --> 00:10:11.160
spogląda na ślad po spojrzeniu pozostawionym przez poprzedniego obserwatora”.

00:10:11.160 --> 00:10:13.160
Pomysł polega na tym, że obraz składa się całkowicie

00:10:13.160 --> 00:10:15.160
z historii spojrzeń rzuconych na niego

00:10:15.160 --> 00:10:17.160
przez oglądających go w trakcie wystawy, ludzi.

00:10:17.160 --> 00:10:22.160
Pozwólcie mi włączyć instalację i zademonstrować to na żywo.

00:10:22.160 --> 00:10:26.160
Sprawdźmy wspólnie, czy i jak to działa.

00:10:26.160 --> 00:10:29.160
Dobra. Dodam jeszcze tylko, że mamy sporo lepszych, jasnych nagrań,

00:10:29.160 --> 00:10:31.160
Tutaj używamy małego ekranu testowego, jedynie by pokazać działanie programu.

00:10:31.160 --> 00:10:33.160
Zasłonię to nieco

00:10:33.160 --> 00:10:35.160
i teraz możecie zobaczyć, co się dzieje.

00:10:35.160 --> 00:10:38.160
Program rejestruje obraz moich oczu za każdym razem, kiedy mrugam.

00:10:44.160 --> 00:10:48.160
Halo?!! I znowu... hej.... działa.

00:10:48.160 --> 00:10:50.160
Niezależnie od tego, gdzie ja się znajduję

00:10:50.160 --> 00:10:53.160
system okulograficzny [eye-tracking] próbuje zlokalizować moje oczy.

00:10:53.160 --> 00:10:55.160
Jeśli zbytnio się oddalę obraz będzie zamazany,

00:10:55.160 --> 00:10:57.160
powstaną nieostre plamy

00:10:57.160 --> 00:11:00.160
przypominające tylko abstrakcję moich oczu.

00:11:00.160 --> 00:11:03.160
Jeśli jednak odpowiednio zbliżę się i spojrzę prosto w kamerę laptopa,

00:11:03.160 --> 00:11:05.160
zobaczycie dobry, ostry obraz oczu.

00:11:05.160 --> 00:11:09.160
W pewnym sensie przypomina to pisanie na laptopie za pomocą oczu.

00:11:09.160 --> 00:11:11.160
To co „zapisujemy”, to rejestracja naszych spojrzeń,

00:11:11.160 --> 00:11:13.160
kiedy patrzymy w oczy innym ludziom,

00:11:13.160 --> 00:11:16.160
bowiem każdy z nas spogląda

00:11:16.160 --> 00:11:18.160
na spojrzenia swoich poprzedników.

00:11:18.160 --> 00:11:20.160
Projekt ten Istnieje już też w formie większej instalacji,

00:11:20.160 --> 00:11:22.160
gdzie są zapisane tysiące oczu

00:11:22.160 --> 00:11:24.160
na które ludzie mogą spoglądać

00:11:24.160 --> 00:11:26.160
spójrzmy na to tak: kto spogląda na oczy ludzi,

00:11:26.160 --> 00:11:28.160
patrzących na oczy ludzi, patrzących tak przed nimi.

00:11:28.160 --> 00:11:31.160
Mrugnę jeszcze kilka razy. Mryg. Mryg.

00:11:31.160 --> 00:11:34.160
Znów możemy zaobserwować, jak program szuka moich oczu,

00:11:34.160 --> 00:11:37.160
starając się dobrze ocenić moment mrugnięcia

00:11:37.160 --> 00:11:39.160
Dobrze. Zostawimy to na razie,

00:11:39.160 --> 00:11:42.160
ten nasz rodzaj rekursywnego systemu obserwacji.

00:11:42.160 --> 00:11:44.160
(aplauz)

00:11:44.160 --> 00:11:46.160
Dziękuję.

00:11:46.160 --> 00:11:48.160
Pokażę teraz kilka obiektow, które stanowią w zasadzie

00:11:48.160 --> 00:11:50.160
nowe osiagnięcia w dziedzinie robotyki. To znaczy dla mnie, są one nowe.

00:11:50.160 --> 00:11:52.160
Ten nazywa się Opto-Izolator

00:11:52.160 --> 00:11:55.160
Pokażę nagranie zawierające jego starszą wersję,

00:11:55.160 --> 00:11:57.160
ktora trwa około minuty.

00:12:06.160 --> 00:12:08.160
W tym nagraniu Opto-Izolator mruga

00:12:08.160 --> 00:12:10.160
w odpowiedzi na nasze mrugnięcie.

00:12:10.160 --> 00:12:13.160
Mruga sekundę po nas.

00:12:13.160 --> 00:12:16.160
To urządzenie, zrobione z możliwie najprostszych materiałów

00:12:16.160 --> 00:12:19.160
ma na celu ograniczenie zjawiska gapienia się.

00:12:19.160 --> 00:12:21.160
Tylko jedno, wpatrzone w nas oko,

00:12:21.160 --> 00:12:23.160
z pominięciem wszelkich innych elementów twarzy.

00:12:23.160 --> 00:12:26.160
Jego wpatrujące się spojrzenie odbierane jest jako coś oderwanego

00:12:26.160 --> 00:12:29.160
od całej reszty, jak swego rodzaju element.

00:12:29.160 --> 00:12:32.160
Jednocześnie oko to stara się nawiązać, nazwijmy to,

00:12:32.160 --> 00:12:34.160
psycho-socjalny kontakt z obserwatorem.

00:12:34.160 --> 00:12:36.160
Wydaje się odwracać wzrok, gdy patrzymy na nie zbyt długo,

00:12:36.160 --> 00:12:38.160
jak gdyby czuło się zawstydzone.

00:12:38.160 --> 00:12:41.160
Lub coś w tym rodzaju.

00:12:41.160 --> 00:12:44.160
Ostatni projekt, który przedstawię

00:12:44.160 --> 00:12:47.160
nazywa się Wąchadło.

00:12:47.160 --> 00:12:49.160
(śmiech)

00:12:49.160 --> 00:12:51.160
Jest to taka 2 i pół metrowa rura

00:12:51.160 --> 00:12:53.160
z wyłupiastym okiem,

00:12:53.160 --> 00:12:54.160
(śmiech)

00:12:54.160 --> 00:12:57.160
mieszcząca w środku 362 kilogramowe ramię robota,

00:12:57.160 --> 00:12:59.160
pożyczone

00:12:59.160 --> 00:13:00.160
(śmiech)

00:13:00.160 --> 00:13:02.160
od kumpla,

00:13:02.160 --> 00:13:03.160
(śmiech)

00:13:03.160 --> 00:13:05.160
Nie ma to, jak mieć dobrych przyjaciół

00:13:05.160 --> 00:13:08.160
w Carnegie Mellon. Mamy tam wspaniały Instytut Robotyki.

00:13:08.160 --> 00:13:10.160
Dlatego mogę tu dziś przedstawić Wam Wąchadło.

00:13:10.160 --> 00:13:12.160
Ideą tego projektu było zrobienie

00:13:12.160 --> 00:13:16.160
robota, który cały czas wydaje się być zaskoczony tym, że nas widzi.

00:13:16.160 --> 00:13:20.160
(śmiech)

00:13:20.160 --> 00:13:22.160
Generalnie wygląda to tak, że przez cały czas,

00:13:22.160 --> 00:13:24.160
zachowuje się w stylu: „He? Kto to?.... Kto?”

00:13:24.160 --> 00:13:28.160
Dlatego na drugie imię ma Namierzacz. Namierzacz Podwójny.

00:13:28.160 --> 00:13:30.160
Taki, co to zawsze się nam dwukrotnie przygląda, jakby myśląc: "Coś tu nie gra..."

00:13:30.160 --> 00:13:32.160
W efekcie czujemy się trochę głupio,

00:13:32.160 --> 00:13:34.160
zastanawiamy się: "O co mu chodzi?"

00:13:34.160 --> 00:13:36.160
"Co jest? Pękło mi sznurowadlo?"

00:13:36.160 --> 00:13:39.160
"A może gołąb mi na głowę...?”. No właśnie.

00:14:10.160 --> 00:14:12.160
Patrzcie, jak go sprawdza...

00:14:20.160 --> 00:14:22.160
Dla nerdów trochę "zakulisowych" informacji o tym przedsięwzięciu.

00:14:22.160 --> 00:14:24.160
Robot posiada system wizji komputerowej

00:14:24.160 --> 00:14:27.160
i próbuje przyglądać się ludziom, którzy najwięcej się przemieszczają.

00:14:39.160 --> 00:14:41.160
To są jego „ofiary”.

00:14:42.160 --> 00:14:44.160
U góry widzimy jego szkielet

00:14:44.160 --> 00:14:47.160
oraz to co w danym momencie próbuje zrobić.

00:14:54.160 --> 00:14:57.160
Tak na prawdę jest to próba stworzenia nowego „języka ciała” dla nowego tworu

00:14:57.160 --> 00:14:59.160
W Hollywood oczywiście robi się to na codzień.

00:14:59.160 --> 00:15:01.160
Przy tym ten "język ciała" powinien też przekazywać coś

00:15:01.160 --> 00:15:03.160
patrzącej na ten twór osobie.

00:15:03.160 --> 00:15:05.160
Jego ruchy dają nam do zrozumienia, że jest zaskoczony, widząc nas

00:15:05.160 --> 00:15:08.160
i że patrzy na nas z zainteresowaniem.

00:15:08.160 --> 00:15:10.160
(śmiech)

00:15:10.160 --> 00:15:19.160
(aplauz)

00:15:19.160 --> 00:15:21.160
Bardzo dziekuję. To wszystko, co mam dla Was na dziś.

00:15:21.160 --> 00:15:24.160
Jestem naprawdę szczęśliwy, mogąc tu być. Dziękuję. Dziękuję bardzo.

00:15:24.160 --> 00:15:27.160
(aplauz)

