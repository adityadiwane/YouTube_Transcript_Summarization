WEBVTT
Kind: captions
Language: ko

00:00:00.000 --> 00:00:07.000
번역: yu gang - hyun
검토: Jihyeon J. Kim

00:00:12.832 --> 00:00:14.111
여러분께 묻고 싶습니다.

00:00:15.422 --> 00:00:17.365
컴퓨터가 시를 쓸 수 있을까요?

00:00:18.959 --> 00:00:21.036
도발적인 질문이지만

00:00:21.715 --> 00:00:23.233
잠시 생각해 보신다면

00:00:23.267 --> 00:00:26.047
다른 의문이 갑자기 떠오를 것입니다.

00:00:26.769 --> 00:00:28.150
컴퓨터가 뭘까?

00:00:28.710 --> 00:00:30.285
시는 또 뭐지?

00:00:30.707 --> 00:00:32.396
창의성은 뭘까?

00:00:33.650 --> 00:00:34.822
하지만 이런 질문들은

00:00:34.870 --> 00:00:37.940
인류가 평생을 바쳐 답을 
찾아가는 질문들이지

00:00:37.964 --> 00:00:40.188
단순히 TED 강연 한 번으로 
답할 수 있는게 아닙니다.

00:00:40.188 --> 00:00:42.633
그래서, 우리는 다른 방법으로 
접근해 보려합니다.

00:00:42.697 --> 00:00:44.800
여기, 시가 두 편 있습니다.

00:00:45.839 --> 00:00:48.115
하나는 사람이 썼고

00:00:48.139 --> 00:00:50.241
다른 하나는 컴퓨터가 썼습니다.

00:00:50.754 --> 00:00:53.164
두 시를 보고 각각 누가 
지었는지 알아내 보세요.

00:00:53.858 --> 00:00:55.014
시작합니다!

00:00:55.038 --> 00:00:59.094
시 1: 작은 파리야 / 너의 여름날 놀이를 /
내 부주의한 손이 / 쓸어 버렸구나.

00:00:59.118 --> 00:01:02.512
나는 너와 같은 파리가 아니냐?
아니면 너는 / 나와 같은 사람이 아니냐?

00:01:02.536 --> 00:01:05.835
시 2 : 우리는 느낄 수 있네 / 
네 삶의 아침을 통한 행동가를

00:01:05.859 --> 00:01:08.650
잠시 멈춰서 보시오, 교황이여.
나는 싫어하네/모든 아무 밤도 시작하는/위대한 (...)

00:01:08.870 --> 00:01:11.049
좋아요, 시간이 다 되었습니다.

00:01:11.513 --> 00:01:15.609
1번 시가 사람이 쓴 시라고 
생각하신다면 손을 들어보세요.

00:01:17.547 --> 00:01:19.037
좋아요, 대부분이 손을 드셨네요.

00:01:19.061 --> 00:01:22.084
그러면 2번을 사람이 썼다고 
생각하시는 분 손 들어보세요.

00:01:23.172 --> 00:01:24.362
대담하신 분들이네요.

00:01:24.855 --> 00:01:29.140
첫 번째 시는 시인 
윌리엄 블레이크의 시입니다.

00:01:29.784 --> 00:01:32.733
두 번째 시는 알고리즘이 썼습니다.

00:01:32.757 --> 00:01:36.449
제 페이스북 피드에 있는 모든 글자들을

00:01:36.473 --> 00:01:39.236
알고리즘을 통해 재배열하는
방법이 이용됐죠.

00:01:39.260 --> 00:01:42.850
그 방법에 대해서는 조금 있다가
설명해 드리도록 하겠습니다.

00:01:43.218 --> 00:01:45.622
그럼, 다른 문제를 내 보겠습니다.

00:01:46.398 --> 00:01:48.491
이번에도, 시들을 전부 다 
읽어 볼 시간은 없습니다.

00:01:48.515 --> 00:01:50.127
그냥 여러분들의 직감을 
믿으시면 됩니다.

00:01:50.151 --> 00:01:54.196
시 1 : 사자는 포효하고 개는 짖네.
흥미롭고 매력적인 것은

00:01:54.220 --> 00:01:58.523
새는 포효하거나 짖지 않고 나는 것이네.
동물들의 놀라운 이야기는

00:01:58.547 --> 00:02:02.607
내 꿈 속에 나오고 나는 그들을 노래하네
내가 지치거나 피곤하지 않다면.

00:02:02.631 --> 00:02:06.616
시 2 : 오! 캥거루, 세퀸장식, 초콜릿 소다!
/ 너는 참 아름답구나!

00:02:06.640 --> 00:02:10.412
진주/ 하모니카, 대추, 아스피린!
모두/ 사람들이 말하는 것이네. (...)

00:02:10.492 --> 00:02:12.180
좋아요 시간이 다 되었네요.

00:02:12.204 --> 00:02:15.341
첫 번째 시가 사람이 
쓴 시라고 생각하신다면

00:02:15.365 --> 00:02:16.580
손을 들어주세요.

00:02:17.687 --> 00:02:18.841
좋습니다.

00:02:18.865 --> 00:02:21.540
그럼 두 번째 시가 사람이 
쓴 시라고 생각하시는 분

00:02:21.564 --> 00:02:22.719
손을 들어주세요.

00:02:23.779 --> 00:02:27.589
절반 정도로 나뉘었네요.

00:02:28.157 --> 00:02:29.593
이번 건 좀 더 어러우셨을겁니다.

00:02:29.617 --> 00:02:31.329
답을 알려드리죠.

00:02:31.353 --> 00:02:34.836
첫 번째 시는 랙터라고 불리는 
알고리즘에 의해 지어졌습니다.

00:02:34.860 --> 00:02:37.862
1970년대에 만들어진 알고리즘이죠.

00:02:37.886 --> 00:02:41.075
두 번째 시는 프랭크 오하라라는 
사람이 지었습니다.

00:02:41.099 --> 00:02:43.767
제가 가장 좋아하는
'인간' 시인 중 한 명이죠.

00:02:44.631 --> 00:02:47.689
(웃음)

00:02:48.046 --> 00:02:51.274
지금까지 우리는 시에 대한 
'튜링 테스트'를 해 보았습니다.

00:02:52.018 --> 00:02:56.565
'튜링 테스트'는 1950년에 
앨런 튜링이라는사람에 의해

00:02:56.589 --> 00:02:58.153
아래의 질문에 답하려고 제안되었습니다.

00:02:58.177 --> 00:02:59.814
'컴퓨터가 생각을 할 수 있는가?'

00:03:00.245 --> 00:03:03.645
앨런 튜링은 만약 컴퓨터가 사람과 
텍스트를 기반으로 대화를 할 때

00:03:03.649 --> 00:03:06.117
상대방이 자신이 인간과 대화하고 있는지

00:03:06.141 --> 00:03:08.911
아니면 컴퓨터와 대화하고 있는지를 
알아내지 못할 정도의

00:03:08.935 --> 00:03:11.901
언어 구사력을 가질 수 있다면

00:03:11.925 --> 00:03:14.781
컴퓨터는 지능을 가질 수 
있다고 믿었습니다.

00:03:15.270 --> 00:03:18.565
그래서 2013년, 
저와 제 친구 벤자민 럴드는

00:03:18.589 --> 00:03:21.577
시에 대한 '온라인 튜링 테스트 ' 를 
만들었습니다.

00:03:21.601 --> 00:03:22.512
이름은 bot or not 이고

00:03:22.512 --> 00:03:24.946
여러분 혼자 해 볼 수도 있습니다.

00:03:24.970 --> 00:03:27.221
하지만, 기본적으로, 그것은 우리가 
조금 전 한 게임과 같습니다.

00:03:27.245 --> 00:03:28.773
여러분은 시를 보게 될 것이고

00:03:28.797 --> 00:03:30.955
그 시를 사람이 지었는지,
컴퓨터가 지었는지 모릅니다.

00:03:30.955 --> 00:03:32.121
그걸 추측해야만 하죠.

00:03:32.599 --> 00:03:36.230
수많은 사람들이 테스트에 
참가하였습니다.

00:03:36.254 --> 00:03:37.703
테스트 결과가 나왔죠.

00:03:37.727 --> 00:03:39.155
결과는 어땠을까요?

00:03:39.704 --> 00:03:42.583
글쎄요, 튜링은 만약 
컴퓨터가 30% 확률로

00:03:42.607 --> 00:03:45.626
자신이 사람인 것처럼 
상대방을 속일 수 있다면

00:03:45.650 --> 00:03:48.047
그 컴퓨터는 지능에 대한 튜링테스트를
통과한 것이라고 말했습니다.

00:03:48.625 --> 00:03:51.063
'bot or not' 프로그램 
데이터 베이스에는

00:03:51.087 --> 00:03:54.066
65% 정도의 확룰로 사람들을 속인

00:03:54.090 --> 00:03:55.485
시들이 존재합니다.

00:03:55.959 --> 00:03:58.776
자, 질문에 대한 답이 나온 것 같군요.

00:03:59.546 --> 00:04:01.894
'튜링 테스트'의 논리에 따르면

00:04:01.918 --> 00:04:03.846
컴퓨터는 시를 쓸 수 있을까요?

00:04:03.870 --> 00:04:06.221
네, 물론 쓸 수 있습니다.

00:04:07.782 --> 00:04:11.008
하지만 이 대답이 기분이 좀 나쁘시다면

00:04:11.008 --> 00:04:12.099
괜찮습니다, 그럴 수 있어요.

00:04:12.189 --> 00:04:14.019
만약 본능적으로 수많은 
반응들이 나온다면

00:04:14.053 --> 00:04:17.258
그것도 괜찮습니다.
왜냐하면 이게 끝이 아니기 때문이죠.

00:04:18.594 --> 00:04:20.918
그럼 마자막 테스트를 해 봅시다.

00:04:22.000 --> 00:04:23.234
다시 한번, 시를 읽으시고

00:04:23.254 --> 00:04:25.683
어떤 것이 사람이 쓴 
시인지 말해 주세요.

00:04:25.707 --> 00:04:29.425
시 1 : 레그 깃발은 예쁜 깃발.
/ 그리고 리본들.

00:04:29.449 --> 00:04:33.770
깃발의 리본들/ 착용하는 물건/
착용하는 물건들인 이유. (...)

00:04:33.794 --> 00:04:37.712
시 2 : 다친 사슴이 가장 높이 뛴다,
/ 수선화의 소리가 들린다.

00:04:37.736 --> 00:04:41.182
지금까지 깃발의 소리를 듣는다
/ 나는 사냥꾼이 말하는 소리를 듣는다.

00:04:41.206 --> 00:04:44.042
이것은 죽음의 황홀함,
/ 그리고 나면 거의 끝난다.

00:04:44.042 --> 00:04:46.531
좋아요 시간이 다 되었네요.

00:04:46.555 --> 00:04:50.392
1번 시가 사람이 썼다고 
생각하시면 손을 들어보세요.

00:04:51.973 --> 00:04:55.011
그럼 두 번째 시라고 
생각하시면 손 들어주세요.

00:04:55.035 --> 00:04:57.366
오, 손을 많이 드셨네요

00:04:58.327 --> 00:05:01.295
그럼 여러분들은 첫 번째 시가

00:05:01.319 --> 00:05:05.312
사람 시인인 거트루드 슈타인이 
썼다는 걸 알면 놀라시겠네요.

00:05:06.100 --> 00:05:11.138
그리고 두 번째 시는 RKCP라고 불리는 
알고리즘이 썼습니다.

00:05:11.162 --> 00:05:14.481
자 그럼 이야기를 이어가기 전에,
제가 짧고 단순하게

00:05:14.505 --> 00:05:16.286
어떻게 RKCP가 작동하는지 
알려드리겠습니다.

00:05:16.873 --> 00:05:20.673
RKCP는 레이 커즈와일이 
고안한 알고리즘입니다.

00:05:20.687 --> 00:05:22.643
그는 구글에서 
엔지니어 이사를 맡고 있고

00:05:22.643 --> 00:05:25.353
인공 지능에 대한 
확고한 믿음을 가지고 있죠.

00:05:25.822 --> 00:05:29.813
RKCP에 원시 텍스트가 투입되면

00:05:29.837 --> 00:05:34.306
RKCP는 그것을 분석해 
어떤 형식으로 쓰여졌는지 알아낸 후

00:05:34.330 --> 00:05:36.278
원시 텍스트을 모방하여

00:05:36.302 --> 00:05:38.830
새 문장을 만들어 냅니다.

00:05:38.854 --> 00:05:40.967
우리가 전에 보았던 시들도 
모두 그렇게 만들어졌습니다.

00:05:40.991 --> 00:05:43.616
여러분들이 모두 사람이
쓴 것이라고 생각했던 두 번째 시 또한

00:05:43.640 --> 00:05:46.240
시인 에밀이 디킨슨의 수많은 시들이

00:05:46.240 --> 00:05:47.249
투입되었습니다.

00:05:47.273 --> 00:05:49.462
RKCP는 그녀의 문체를 알아냈고

00:05:49.486 --> 00:05:50.651
그 문체를 학습하여

00:05:50.675 --> 00:05:54.933
같은 형식의 문체를 이용해 
시를 재생산했습니다.

00:05:56.732 --> 00:05:58.910
하지만 RKCP에 대해 
알아야 할 중요한 것은

00:05:58.934 --> 00:06:01.772
RKCP는 시에 사용되는 어휘들의 
뜻을 모른다는 것입니다.

00:06:02.359 --> 00:06:04.635
언어는 단지 원자재일 뿐입니다.

00:06:04.659 --> 00:06:06.819
중국어가 될 수도,
스웨덴어가 될 수도,

00:06:06.843 --> 00:06:11.022
여러분의 페이스북 피드에서
수집된 언어일 수도 있습니다.

00:06:11.046 --> 00:06:12.698
그건 단지 원자재일 뿐이죠.

00:06:13.380 --> 00:06:17.587
그럼에도 불구하고, RKCP는 사람인
거트루드 슈타인의 시보다도

00:06:17.587 --> 00:06:19.408
사람이 쓴 것 같은

00:06:19.452 --> 00:06:21.605
시를 창조해 낼 수 있습니다.

00:06:22.846 --> 00:06:26.918
우리는 지금까지 '튜링테스트'를 
역으로 생각해 보았습니다.

00:06:27.940 --> 00:06:33.119
그러니까, 사람인 거트루드 슈타인은

00:06:33.143 --> 00:06:36.881
자신의 시를 컴퓨터가 썼다고 믿게

00:06:36.905 --> 00:06:38.731
대다수의 사람을 속인 겁니다.

00:06:39.176 --> 00:06:43.317
그러므로, '튜링테스트'를 역으로 
생각해 본 결과는,

00:06:43.341 --> 00:06:45.257
거트루드 슈타인이 컴퓨터라는 거네요.

00:06:45.281 --> 00:06:46.743
(웃음)

00:06:47.358 --> 00:06:48.652
혼란스러우신가요?

00:06:49.193 --> 00:06:50.708
이 정도면 충분한 것 같습니다.

00:06:51.546 --> 00:06:55.662
지금까지 우리는 
사람처럼 글을 쓰는 사람도

00:06:55.686 --> 00:06:58.797
컴퓨터처럼 글을 쓰는 컴퓨터도

00:06:58.821 --> 00:07:01.876
사람처럼 글을 쓰는 컴퓨터도

00:07:01.900 --> 00:07:05.532
심지어 아마 가장 혼란스러우시겠지만

00:07:05.556 --> 00:07:07.931
컴퓨터처럼 글을 쓰는 
사람도 보았습니다.

00:07:08.938 --> 00:07:10.704
그래서 우리가 이것들부터
얻을 수 있는게 도대체 뭘까요?

00:07:11.611 --> 00:07:14.768
윌리엄 블레이크가 거트루드 슈타인보다

00:07:14.792 --> 00:07:16.041
더 인간답다고 해야 하나요?

00:07:16.065 --> 00:07:19.111
아니면, 거트루드 슈타인이 
윌리엄 블레이크보다 더 컴퓨터답다고요?

00:07:19.135 --> 00:07:20.687
(웃음)

00:07:20.711 --> 00:07:23.034
이 질문들은 거의 2년 동안
제가 제 자신에게

00:07:23.058 --> 00:07:24.523
묻고 있는 질문입니다.

00:07:24.547 --> 00:07:26.856
그리고 저는 답을 얻지 못했습니다.

00:07:26.880 --> 00:07:29.210
하지만 제가 한 질문들은 
인간과 기술간의

00:07:29.234 --> 00:07:31.768
관계에 대한 큰 통찰들입니다.

00:07:32.999 --> 00:07:36.608
제 첫 번째 통찰은, 어떤 이유에선지

00:07:36.632 --> 00:07:39.743
우리는 시를 '인간이라는 것'과
연관시킨다는 것입니다.

00:07:40.197 --> 00:07:43.912
우리가 '컴퓨터가 시를 쓸 수 있을까?'
라고 질문하는 것은

00:07:43.936 --> 00:07:45.129
다음 질문들과 같습니다.

00:07:45.153 --> 00:07:46.951
'인간이라는 것'은 무엇인가?'

00:07:46.975 --> 00:07:50.147
'인간이라는 범주에 
어떤 경계를 세워야 하는가?'

00:07:50.171 --> 00:07:53.829
어떻게 '누구 또는 무엇'이
이 범주에 속한다고 말할 수 있는가? '

00:07:54.376 --> 00:07:57.727
이건 본질적으로 철학적 질문이라고 
저는 믿습니다.

00:07:57.751 --> 00:07:59.980
그리고 이 질문들은 '튜링 테스트' 처럼
'예' 또는 '아니요' 테스트를 통해

00:08:00.004 --> 00:08:01.331
답해질 수 있는 것이 아닙니다.

00:08:01.805 --> 00:08:04.850
저는 또한 앨런 튜링이 
이것을 이해했었으며

00:08:04.874 --> 00:08:08.179
1950년, 그가 '철학적 도발'로써
이 테스트를 고안했고,

00:08:08.203 --> 00:08:11.005
실행했다고 믿습니다.

00:08:13.124 --> 00:08:18.665
제 두번째 통찰에 대해 설명하자면,
우리는 시에 대해 튜링테스트를 할 때

00:08:18.689 --> 00:08:22.149
컴퓨터의 역량을 시험하고 
있는 것이 아닙니다.

00:08:22.173 --> 00:08:25.066
왜냐하면 시 - 생산 알고리즘들은

00:08:25.090 --> 00:08:29.653
매우 간단하고, 
1950년대 정도부터 존재했으니까요.

00:08:31.055 --> 00:08:34.173
우리가 '튜링 테스트'를 통해 
정말로 하고 있는 것은

00:08:34.197 --> 00:08:38.812
'무엇이 인간성을 구성하는가'에 대한
의견을 모으는 것입니다.

00:08:40.313 --> 00:08:43.042
제가 알아낸 것은

00:08:43.066 --> 00:08:46.038
우리가 좀 전에 알아낸 것과 같습니다.

00:08:46.062 --> 00:08:48.540
우리는 윌리엄 블레이크가
거트루드 슈타인보다

00:08:48.564 --> 00:08:50.129
더 인간답다고 말했었습니다.

00:08:50.153 --> 00:08:52.615
물론, 이건 정말로 윌리엄 블레이크가

00:08:52.639 --> 00:08:54.467
더 인간답다는 의미는 아닙니다.

00:08:54.491 --> 00:08:56.818
또는, 거트루드 슈타인이 
더 컴퓨터답다는 의미도 아닙니다.

00:08:57.533 --> 00:09:02.247
이건 단순히 '인간'이라는
범주가 불안정하다는 뜻입니다.

00:09:03.450 --> 00:09:05.524
이것은 제가 '인간이라는 것' 이

00:09:05.548 --> 00:09:08.311
차갑고, 딱딱한 사실이 아닌

00:09:08.832 --> 00:09:11.964
우리의 의견들로 구성되어 있으며, 
시간이 지남에 따라

00:09:11.988 --> 00:09:14.843
변하는 것이라는 것을 
이해하게 해 주었습니다.

00:09:16.671 --> 00:09:20.054
제 마지막 통찰은 '컴퓨터'라는 것이

00:09:20.054 --> 00:09:25.180
우리가 보여주는 인간의 생각을
반영하는 '거울' 처럼

00:09:25.204 --> 00:09:26.579
작동한다는 것입니다.

00:09:26.958 --> 00:09:28.842
우리가 에밀리 디킨슨을 보여주면

00:09:28.866 --> 00:09:31.187
그것은 우리에게 
에밀리 디킨슨을 돌려줍니다.

00:09:31.768 --> 00:09:33.602
우리가 윌리엄 블레이크를 보여주면

00:09:33.626 --> 00:09:35.911
그것은 우리에게 
윌리엄 블레이크를 반영해 줍니다.

00:09:35.935 --> 00:09:37.774
우리가 거트루드 슈타인을 보여주면

00:09:37.798 --> 00:09:40.268
우리는 거트루드 슈타인을 
다시 받습니다.

00:09:41.083 --> 00:09:43.451
어떠한 다른 기술보다도

00:09:43.475 --> 00:09:48.640
컴퓨터는 우리가 가르치는 
인간의 생각을 반영하는 거울입니다.

00:09:50.061 --> 00:09:52.348
여러분은 아마도 최근 들어

00:09:52.372 --> 00:09:55.234
인공지능에 대한 많은 
이야기를 들었을 겁니다.

00:09:56.694 --> 00:09:59.524
그리고 대부분 대화의 주제는

00:10:00.292 --> 00:10:01.481
우리가 만들 수 있을까?

00:10:02.383 --> 00:10:05.518
우리가 지능적인 컴퓨터를 
만들 수 있을까?

00:10:05.542 --> 00:10:08.305
우리가 창조적인 컴퓨터를 
만들 수 있을까?

00:10:08.329 --> 00:10:11.342
우리는 끝없이 인간 같은 컴퓨터를 
만들 수 있을까?'

00:10:11.342 --> 00:10:13.190
라고 질문하는 것처럼 보입니다.

00:10:13.961 --> 00:10:15.517
하지만 우리는 방금

00:10:15.541 --> 00:10:18.629
'인간이라는 것'이 과학적 사실이 아닌

00:10:18.653 --> 00:10:22.183
영원히 가변적인, 
시간이 지남에 따라 변해가는

00:10:22.207 --> 00:10:24.738
사슬과 같은 생각이라는 
사실을 보았습니다.

00:10:24.762 --> 00:10:27.914
그러므로 미래에 
우리가 인공지능에 대해

00:10:27.938 --> 00:10:30.324
고심하기 시작할 때

00:10:30.348 --> 00:10:32.253
우리는 단지 우리자신에게 
'우리가 만들 수 있을까?'

00:10:32.277 --> 00:10:33.645
라고 질문해서는 안됩니다.

00:10:33.669 --> 00:10:35.563
우리는 자신에게 
이 질문을 해야 합니다.

00:10:35.587 --> 00:10:39.710
'우리는 컴퓨터가 인간의 어떤 생각을 
반영해 나타내기를 원하는가? '

00:10:39.820 --> 00:10:42.513
이것은 본질적으로 철학적 생각이며

00:10:42.537 --> 00:10:45.534
소프트웨어 만으로는 
답할 수 없는 질문입니다.

00:10:45.558 --> 00:10:50.535
저는 '인간'이라는 종의 존재적 반영의
순간이 필요하다고 믿습니다.

00:10:51.040 --> 00:10:52.193
감사합니다.

00:10:52.217 --> 00:10:54.912
(박수)

