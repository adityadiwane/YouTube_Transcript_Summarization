WEBVTT
Kind: captions
Language: en

00:00:26.000 --> 00:00:28.000
I've got apparently 18 minutes

00:00:28.000 --> 00:00:31.000
to convince you that history has a direction, an arrow;

00:00:31.000 --> 00:00:34.000
that in some fundamental sense, it's good;

00:00:34.000 --> 00:00:37.000
that the arrow points to something positive.

00:00:37.000 --> 00:00:41.000
Now, when the TED people first approached me about giving this upbeat talk --

00:00:41.000 --> 00:00:42.000
(Laughter)

00:00:42.000 --> 00:00:48.000
-- that was before the cartoon of Muhammad had triggered global rioting.

00:00:48.000 --> 00:00:50.000
It was before the avian flu had reached Europe.

00:00:50.000 --> 00:00:52.000
It was before Hamas had won the Palestinian election,

00:00:52.000 --> 00:00:56.000
eliciting various counter-measures by Israel.

00:00:56.000 --> 00:01:00.000
And to be honest, if I had known when I was asked to give this upbeat talk

00:01:00.000 --> 00:01:03.000
that even as I was giving the upbeat talk,

00:01:03.000 --> 00:01:06.000
the apocalypse would be unfolding --

00:01:06.000 --> 00:01:07.000
(Laughter)

00:01:07.000 --> 00:01:11.000
-- I might have said, "Is it okay if I talk about something else?"

00:01:11.000 --> 00:01:16.000
But I didn't, OK. So we're here. I'll do what I can. I'll do what I can.

00:01:17.000 --> 00:01:19.000
I've got to warn you:

00:01:19.000 --> 00:01:26.000
the sense in which my worldview is upbeat has always been kind of subtle,

00:01:26.000 --> 00:01:28.000
sometimes even elusive.

00:01:28.000 --> 00:01:29.000
(Laughter)

00:01:29.000 --> 00:01:32.000
The sense in which I can be uplifting and inspiring --

00:01:32.000 --> 00:01:35.000
I mean, there's always been a kind of a certain grim dimension

00:01:35.000 --> 00:01:39.000
to the way I try to uplift, so if grim inspiration --

00:01:39.000 --> 00:01:40.000
(Laughter)

00:01:40.000 --> 00:01:44.000
-- if grim inspiration is not a contradiction in terms, that is, I'm afraid,

00:01:44.000 --> 00:01:48.000
the most you can hope for. OK, today -- that's if I succeed.

00:01:48.000 --> 00:01:50.000
I'll see what I can do. OK?

00:01:50.000 --> 00:01:52.000
Now, in one sense,

00:01:52.000 --> 00:01:55.000
the claim that history has a direction is not that controversial.

00:01:55.000 --> 00:01:58.000
If you're just talking about social structure,

00:01:58.000 --> 00:02:00.000
OK, clearly that's gotten more complex

00:02:00.000 --> 00:02:03.000
a little over the last 10,000 years -- has reached higher and higher levels.

00:02:03.000 --> 00:02:05.000
And in fact, that's actually sustaining

00:02:05.000 --> 00:02:09.000
a long-standing trend that predates human beings, OK,

00:02:09.000 --> 00:02:12.000
that biological evolution was doing for us.

00:02:12.000 --> 00:02:17.000
Because what happened in the beginning, this stuff encases itself in a cell,

00:02:17.000 --> 00:02:20.000
then cells start hanging out together in societies.

00:02:20.000 --> 00:02:23.000
Eventually they get so close, they form multicellular organisms,

00:02:23.000 --> 00:02:28.000
then you get complex multicellular organisms; they form societies.

00:02:28.000 --> 00:02:31.000
But then at some point, one of these multicellular organisms

00:02:31.000 --> 00:02:34.000
does something completely amazing with this stuff, which is

00:02:34.000 --> 00:02:39.000
it launches a whole second kind of evolution: cultural evolution.

00:02:39.000 --> 00:02:42.000
And amazingly, that evolution sustains the trajectory

00:02:42.000 --> 00:02:47.000
that biological evolution had established toward greater complexity.

00:02:47.000 --> 00:02:50.000
By cultural evolution we mean the evolution of ideas.

00:02:50.000 --> 00:02:53.000
A lot of you have heard the term "memes." The evolution of technology,

00:02:53.000 --> 00:02:55.000
I pay a lot of attention to, so, you know,

00:02:55.000 --> 00:02:59.000
one of the first things you got was a little hand axe.

00:02:59.000 --> 00:03:04.000
Generations go by, somebody says, hey, why don't we put it on a stick?

00:03:04.000 --> 00:03:07.000
(Laughter)

00:03:07.000 --> 00:03:10.000
Just absolutely delights the little ones.

00:03:10.000 --> 00:03:12.000
Next best thing to a video game.

00:03:12.000 --> 00:03:14.000
This may not seem to impress,

00:03:14.000 --> 00:03:18.000
but technological evolution is progressive, so another 10, 20,000 years,

00:03:18.000 --> 00:03:20.000
and armaments technology takes you here.

00:03:20.000 --> 00:03:21.000
(Laughter)

00:03:21.000 --> 00:03:25.000
Impressive. And the rate of technological evolution speeds up,

00:03:25.000 --> 00:03:29.000
so a mere quarter of a century after this, you get this, OK.

00:03:29.000 --> 00:03:31.000
(Laughter)

00:03:31.000 --> 00:03:33.000
And this.

00:03:33.000 --> 00:03:34.000
(Laughter)

00:03:34.000 --> 00:03:37.000
I'm sorry -- it was a cheap laugh, but I wanted to find a way

00:03:37.000 --> 00:03:40.000
to transition back to this idea of the unfolding apocalypse,

00:03:40.000 --> 00:03:42.000
and I thought that might do it.

00:03:42.000 --> 00:03:49.000
(Applause)

00:03:49.000 --> 00:03:54.000
So, what threatens to happen with this unfolding apocalypse

00:03:54.000 --> 00:03:58.000
is the collapse of global social organization.

00:03:58.000 --> 00:04:01.000
Now, first let me remind you how much work it took to get us where we are,

00:04:01.000 --> 00:04:04.000
to be on the brink of true global social organization.

00:04:04.000 --> 00:04:10.000
Originally, you had the most complex societies, the hunter-gatherer village.

00:04:10.000 --> 00:04:12.000
Stonehenge is the remnant of a chiefdom,

00:04:12.000 --> 00:04:15.000
which is what you get with the invention of agriculture: multi-village polity

00:04:15.000 --> 00:04:18.000
with centralized rule.

00:04:18.000 --> 00:04:23.000
With the invention of writing, you start getting cities. This is blurry. I kind of like that

00:04:23.000 --> 00:04:26.000
because it makes it look like a one-celled organism and reminds you

00:04:26.000 --> 00:04:30.000
how many levels organic organization has already moved through

00:04:30.000 --> 00:04:36.000
to get to this point. And then you get to, you know, you get empires.

00:04:36.000 --> 00:04:40.000
I want to stress, you know, social organization can transcend political bounds.

00:04:40.000 --> 00:04:44.000
This is the Silk Road connecting the Chinese Empire and the Roman Empire.

00:04:44.000 --> 00:04:47.000
So you had social complexity spanning the whole continent,

00:04:47.000 --> 00:04:52.000
even if no polity did similarly. Today, you've got nation states.

00:04:52.000 --> 00:04:55.000
Point is: there's obviously collaboration and organization going on

00:04:55.000 --> 00:04:57.000
beyond national bounds.

00:04:57.000 --> 00:05:00.000
This is actually just a picture of the earth at night,

00:05:00.000 --> 00:05:02.000
and I'm just putting it up because I think it's pretty.

00:05:02.000 --> 00:05:07.000
Does kind of convey the sense that this is an integrated system.

00:05:07.000 --> 00:05:13.000
Now, I explained this growth of complexity by reference to something

00:05:13.000 --> 00:05:17.000
called "non-zero sumness."

00:05:17.000 --> 00:05:22.000
Assuming that a few of you did not do the assigned reading, very quickly,

00:05:22.000 --> 00:05:27.000
the key idea is the distinction between zero-sum games, in which correlations

00:05:27.000 --> 00:05:30.000
are inverse: always a winner and a loser.

00:05:30.000 --> 00:05:34.000
Non-zero-sum games in which correlations can be positive, OK.

00:05:34.000 --> 00:05:38.000
So like in tennis, usually it's win-lose;

00:05:38.000 --> 00:05:41.000
it always adds up to zero-zero-sum. But if you're playing doubles,

00:05:41.000 --> 00:05:43.000
the person on your side of the net, they're in the same boat as you,

00:05:43.000 --> 00:05:45.000
so you're playing a non-zero-sum game with them.

00:05:45.000 --> 00:05:48.000
It's either for the better or for the worse, OK.

00:05:48.000 --> 00:05:53.000
A lot of forms of non-zero-sum behavior in the realm of economics and so on

00:05:53.000 --> 00:05:57.000
in everyday life often leads to cooperation.

00:05:57.000 --> 00:05:59.000
The argument I make is basically that, well,

00:05:59.000 --> 00:06:01.000
non-zero-sum games have always been part of life.

00:06:01.000 --> 00:06:03.000
You have them in hunter-gatherer societies,

00:06:03.000 --> 00:06:08.000
but then through technological evolution, new forms of technology arise

00:06:08.000 --> 00:06:13.000
that facilitate or encourage the playing of non-zero-sum games,

00:06:13.000 --> 00:06:16.000
involving more people over larger territory.

00:06:16.000 --> 00:06:20.000
Social structure adapts to accommodate this possibility and

00:06:20.000 --> 00:06:23.000
to harness this productive potential, so you get cities, you know,

00:06:23.000 --> 00:06:26.000
and you get all the non-zero-sum games you don't think about

00:06:26.000 --> 00:06:27.000
that are being played across the world.

00:06:27.000 --> 00:06:30.000
Like, have you ever thought when you buy a car,

00:06:30.000 --> 00:06:32.000
how many people on how many different continents contributed

00:06:32.000 --> 00:06:37.000
to the manufacture of that car? Those are people in effect

00:06:37.000 --> 00:06:39.000
you're playing a non-zero-sum game with.

00:06:39.000 --> 00:06:46.000
I mean, there are certainly plenty of them around.

00:06:46.000 --> 00:06:49.000
Now, this sounds like an intrinsically upbeat worldview in a way,

00:06:49.000 --> 00:06:52.000
because when you think of non-zero, you think win-win, you know,

00:06:52.000 --> 00:06:54.000
that's good. Well, there are a few reasons

00:06:54.000 --> 00:06:57.000
that actually it's not intrinsically upbeat.

00:06:57.000 --> 00:07:01.000
First of all, it can accommodate; it doesn't deny the existence

00:07:01.000 --> 00:07:04.000
of inequality exploitation war.

00:07:04.000 --> 00:07:06.000
But there's a more fundamental reason

00:07:06.000 --> 00:07:09.000
that it's not intrinsically upbeat, because a non-zero-sum game,

00:07:09.000 --> 00:07:13.000
all it tells you for sure is that the fortunes will be correlated for better or worse.

00:07:13.000 --> 00:07:19.000
It doesn't necessarily predict a win-win outcome.

00:07:19.000 --> 00:07:21.000
So, in a way, the question is: on what grounds

00:07:21.000 --> 00:07:25.000
am I upbeat at all about history? And the answer is,

00:07:25.000 --> 00:07:29.000
first of all, on balance I would say people have played their games

00:07:29.000 --> 00:07:33.000
to more win-win outcomes than lose-lose outcomes. On balance,

00:07:33.000 --> 00:07:39.000
I think history is a net positive in the non-zero-sum game department.

00:07:39.000 --> 00:07:44.000
And a testament to this is the thing that most amazes me,

00:07:44.000 --> 00:07:46.000
most impresses me, and most uplifts me,

00:07:46.000 --> 00:07:51.000
which is that there is a moral dimension to history;

00:07:51.000 --> 00:07:54.000
there is a moral arrow. We have seen moral progress over time.

00:07:54.000 --> 00:07:58.000
2,500 years ago, members of one Greek city-state

00:07:58.000 --> 00:08:01.000
considered members of another Greek city-state subhuman

00:08:01.000 --> 00:08:06.000
and treated them that way. And then this moral revolution arrived,

00:08:06.000 --> 00:08:10.000
and they decided that actually, no, Greeks are human beings.

00:08:10.000 --> 00:08:13.000
It's just the Persians who aren't fully human

00:08:13.000 --> 00:08:15.000
and don't deserve to be treated very nicely.

00:08:15.000 --> 00:08:18.000
But this was progress -- you know, give them credit. And now today,

00:08:18.000 --> 00:08:21.000
we've seen more progress. I think -- I hope -- most people here would say

00:08:21.000 --> 00:08:24.000
that all people everywhere are human beings,

00:08:24.000 --> 00:08:27.000
deserve to be treated decently,

00:08:27.000 --> 00:08:31.000
unless they do something horrendous, regardless of race or religion.

00:08:31.000 --> 00:08:35.000
And you have to read your ancient history to realize what a revolution that has been,

00:08:35.000 --> 00:08:37.000
OK. This was not a prevalent view,

00:08:37.000 --> 00:08:42.000
few thousand years ago, and I attribute it to this non-zero-sum dynamic.

00:08:42.000 --> 00:08:46.000
I think that's the reason there is as much tolerance toward nationalities,

00:08:46.000 --> 00:08:51.000
ethnicities, religions as there is today. If you asked me,

00:08:51.000 --> 00:08:53.000
you know, why am I not in favor of bombing Japan,

00:08:53.000 --> 00:08:56.000
well, I'm only half-joking when I say they built my car.

00:08:56.000 --> 00:08:58.000
We have this non-zero-sum relationship,

00:08:58.000 --> 00:09:04.000
and I think that does lead to a kind of a tolerance to the extent that you realize

00:09:04.000 --> 00:09:08.000
that someone else's welfare is positively correlated with yours --

00:09:08.000 --> 00:09:10.000
you're more likely to cut them a break.

00:09:10.000 --> 00:09:15.000
I kind of think this is a kind of a business-class morality.

00:09:15.000 --> 00:09:19.000
Unfortunately, I don't fly trans-Atlantic business class often enough

00:09:19.000 --> 00:09:22.000
to know, or any other kind of business class really,

00:09:22.000 --> 00:09:26.000
but I assume that in business class, you don't hear many expressions of, you know,

00:09:26.000 --> 00:09:29.000
bigotry about racial groups or ethnic groups,

00:09:29.000 --> 00:09:32.000
because the people who are flying trans-Atlantic business class

00:09:32.000 --> 00:09:34.000
are doing business with all these people; they're making money

00:09:34.000 --> 00:09:38.000
off all these people. And I really do think that, in that sense at least,

00:09:38.000 --> 00:09:41.000
capitalism has been a constructive force,

00:09:41.000 --> 00:09:43.000
and more fundamentally, it's a non-zero-sumness

00:09:43.000 --> 00:09:47.000
that has been a constructive force in expanding people's realm

00:09:47.000 --> 00:09:52.000
of moral awareness. I think the non-zero-sum dynamic,

00:09:52.000 --> 00:09:56.000
which is not only economic by any means -- it's not always commerce --

00:09:56.000 --> 00:10:01.000
but it has driven us to the verge of a moral truth,

00:10:01.000 --> 00:10:04.000
which is the fundamental equality of everyone. It has done that.

00:10:04.000 --> 00:10:09.000
As it has moved global, moved us toward a global level of social organization,

00:10:09.000 --> 00:10:11.000
it has driven us toward moral truth.

00:10:11.000 --> 00:10:14.000
I think that's wonderful.

00:10:14.000 --> 00:10:17.000
Now, back to the unfolding apocalypse.

00:10:17.000 --> 00:10:19.000
And you may wonder, OK, that's all fine,

00:10:19.000 --> 00:10:21.000
sounds great -- moral direction in history --

00:10:21.000 --> 00:10:30.000
but what about this so-called clash of civilizations? Well, first of all,

00:10:30.000 --> 00:10:33.000
I would emphasize that it fits into the non-zero-sum framework,

00:10:33.000 --> 00:10:35.000
OK. If you look at the relationship

00:10:35.000 --> 00:10:38.000
between the so-called Muslim world and Western world --

00:10:38.000 --> 00:10:41.000
two terms I don't like, but can't really avoid;

00:10:41.000 --> 00:10:45.000
in such a short span of time, they're efficient if nothing else --

00:10:45.000 --> 00:10:48.000
it is non-zero-sum. And by that I mean,

00:10:48.000 --> 00:10:52.000
if people in the Muslim world get more hateful, more resentful,

00:10:52.000 --> 00:10:53.000
less happy with their place in the world,

00:10:53.000 --> 00:10:57.000
it'll be bad for the West. If they get more happy, it'll be good for the West.

00:10:57.000 --> 00:11:02.000
So that is a non-zero-sum dynamic.

00:11:02.000 --> 00:11:06.000
And I would say the non-zero-sum dynamic is only going to grow more intense over time

00:11:06.000 --> 00:11:11.000
because of technological trends, but more intense in a kind of negative way.

00:11:11.000 --> 00:11:17.000
It's the downside correlation of their fortunes that will become more and more possible.

00:11:17.000 --> 00:11:22.000
And one reason is because of something I call the "growing lethality of hatred."

00:11:22.000 --> 00:11:26.000
More and more, it's possible for grassroots hatred abroad

00:11:26.000 --> 00:11:31.000
to manifest itself in the form of organized violence on American soil.

00:11:31.000 --> 00:11:34.000
And that's pretty new, and I think it's probably going to get a lot worse

00:11:34.000 --> 00:11:37.000
-- this capacity -- because of

00:11:37.000 --> 00:11:41.000
trends in information technology, in technologies that can be used

00:11:41.000 --> 00:11:47.000
for purposes of munitions like biotechnology and nanotechnology.

00:11:47.000 --> 00:11:49.000
We may be hearing more about that today.

00:11:49.000 --> 00:11:52.000
And there's something I worry about especially, which is that

00:11:52.000 --> 00:11:58.000
this dynamic will lead to a kind of a feedback cycle that puts us on a slippery slope.

00:11:58.000 --> 00:12:01.000
What I have in mind is: terrorism happens here; we overreact to it.

00:12:01.000 --> 00:12:05.000
That, you know, we're not sufficiently surgical in our retaliation

00:12:05.000 --> 00:12:07.000
leads to more hatred abroad, more terrorism.

00:12:07.000 --> 00:12:11.000
We overreact because being human, we feel like retaliating,

00:12:11.000 --> 00:12:13.000
and it gets worse and worse and worse.

00:12:13.000 --> 00:12:17.000
You could call this the positive feedback of negative vibes,

00:12:17.000 --> 00:12:19.000
but I think in something so spooky,

00:12:19.000 --> 00:12:22.000
we really shouldn't have the word positive there at all, even in a technical sense.

00:12:22.000 --> 00:12:25.000
So let's call it the death spiral of negativity.

00:12:25.000 --> 00:12:27.000
(Laughter)

00:12:27.000 --> 00:12:29.000
I assure you if it happens, at the end, both the West

00:12:29.000 --> 00:12:32.000
and the Muslim world will have suffered.

00:12:32.000 --> 00:12:38.000
So, what do we do? Well, first of all, we can do a lot more with arms control,

00:12:38.000 --> 00:12:40.000
the international regulation of dangerous technologies.

00:12:40.000 --> 00:12:42.000
I have a whole global governance sermon

00:12:42.000 --> 00:12:44.000
that I will spare you right now,

00:12:44.000 --> 00:12:47.000
because I don't think that's going to be enough anyway, although it's essential.

00:12:47.000 --> 00:12:49.000
I think we're going to have to have a major round

00:12:49.000 --> 00:12:51.000
of moral progress in the world.

00:12:51.000 --> 00:12:56.000
I think you're just going to have to see less hatred among groups,

00:12:56.000 --> 00:13:02.000
less bigotry, and, you know, racial groups, religious groups, whatever.

00:13:02.000 --> 00:13:04.000
I've got to admit I feel silly saying that.

00:13:04.000 --> 00:13:07.000
It sounds so kind of Pollyannaish. I feel like Rodney King, you know,

00:13:07.000 --> 00:13:09.000
saying, why can't we all just get along?

00:13:09.000 --> 00:13:15.000
But hey, I don't really see any alternative, given the way I read the situation.

00:13:15.000 --> 00:13:18.000
There's going to have to be moral progress.

00:13:18.000 --> 00:13:22.000
There's going to have to be a lessening of the amount of hatred in the world,

00:13:22.000 --> 00:13:26.000
given how dangerous it's becoming.

00:13:26.000 --> 00:13:29.000
In my defense, I'd say, as naive as this may sound,

00:13:29.000 --> 00:13:32.000
it's ultimately grounded in cynicism.

00:13:32.000 --> 00:13:33.000
That is to say --

00:13:33.000 --> 00:13:34.000
(Laughter)

00:13:34.000 --> 00:13:39.000
-- thank you, thank you. That is to say, remember: my whole view

00:13:39.000 --> 00:13:42.000
of morality is that it boils down to self-interest.

00:13:42.000 --> 00:13:44.000
It's when people's fortunes are correlated.

00:13:44.000 --> 00:13:47.000
It's when your welfare conduces to mine, that I decide, oh yeah,

00:13:47.000 --> 00:13:51.000
I'm all in favor of your welfare. That's what's responsible

00:13:51.000 --> 00:13:54.000
for this growth of this moral progress so far,

00:13:54.000 --> 00:13:57.000
and I'm saying we once again have a correlation of fortunes,

00:13:57.000 --> 00:14:01.000
and if people respond to it intelligently, we will see

00:14:01.000 --> 00:14:04.000
the development of tolerance and so on --

00:14:04.000 --> 00:14:07.000
the norms that we need, you know.

00:14:07.000 --> 00:14:11.000
We will see the further evolution of this kind of business-class morality.

00:14:11.000 --> 00:14:17.000
So, these two things, you know, if they get people's attention

00:14:17.000 --> 00:14:20.000
and drive home the positive correlation and people do what's in their self-interests,

00:14:20.000 --> 00:14:24.000
which is further the moral evolution,

00:14:24.000 --> 00:14:27.000
then they could actually have a constructive effect.

00:14:27.000 --> 00:14:30.000
And that's why I lump growing lethality of hatred

00:14:30.000 --> 00:14:33.000
and death spiral of negativity under the general rubric,

00:14:33.000 --> 00:14:35.000
reasons to be cheerful.

00:14:35.000 --> 00:14:37.000
(Laughter)

00:14:37.000 --> 00:14:39.000
Doing the best I can, OK.

00:14:39.000 --> 00:14:40.000
(Laughter)

00:14:40.000 --> 00:14:42.000
I never called myself Mr. Uplift.

00:14:42.000 --> 00:14:45.000
I'm just doing what I can here.

00:14:45.000 --> 00:14:46.000
(Laughter)

00:14:46.000 --> 00:14:49.000
Now, launching a moral revolution has got to be hard, right?

00:14:49.000 --> 00:14:51.000
I mean, what do you do?

00:14:51.000 --> 00:14:53.000
And I think the answer is a lot of different people

00:14:53.000 --> 00:14:56.000
are going to have to do a lot of different things.

00:14:56.000 --> 00:15:01.000
We all start where we are. Speaking as an American

00:15:01.000 --> 00:15:05.000
who has children whose security 10, 20, 30 years down the road

00:15:05.000 --> 00:15:08.000
I worry about -- what I personally want to start out doing

00:15:08.000 --> 00:15:12.000
is figuring out why so many people around the world hate us, OK.

00:15:12.000 --> 00:15:16.000
I think that's a worthy research project myself.

00:15:16.000 --> 00:15:21.000
I also like it because it's an intrinsically kind of morally redeeming exercise.

00:15:21.000 --> 00:15:23.000
Because to understand why somebody

00:15:23.000 --> 00:15:25.000
in a very different culture does something --

00:15:25.000 --> 00:15:27.000
somebody you're kind of viewing as alien,

00:15:27.000 --> 00:15:29.000
who's doing things you consider strange

00:15:29.000 --> 00:15:33.000
in a culture you consider strange -- to really understand why they do

00:15:33.000 --> 00:15:37.000
the things they do is a morally redeeming accomplishment,

00:15:37.000 --> 00:15:39.000
because you've got to relate their experience to yours.

00:15:39.000 --> 00:15:43.000
To really understand it, you've got to say, "Oh, I get it.

00:15:43.000 --> 00:15:45.000
So when they feel resentful, it's kind of like

00:15:45.000 --> 00:15:47.000
the way I feel resentful when this happens,

00:15:47.000 --> 00:15:51.000
and for somewhat the same reasons." That's true understanding.

00:15:51.000 --> 00:15:57.000
And I think that is an expansion of your moral compass when you manage to do that.

00:15:57.000 --> 00:16:00.000
It's especially hard to do when people hate you, OK,

00:16:00.000 --> 00:16:03.000
because you don't really, in a sense, want

00:16:03.000 --> 00:16:05.000
to completely understand why people hate you.

00:16:05.000 --> 00:16:07.000
I mean, you want to hear the reason, but you don't want to be able to relate to it.

00:16:07.000 --> 00:16:09.000
You don't want it to make sense, right? (Laughter)

00:16:09.000 --> 00:16:11.000
You don't want to say, "Well, yeah, I can kind of understand

00:16:11.000 --> 00:16:13.000
how a human being in those circumstances

00:16:13.000 --> 00:16:16.000
would hate the country I live in." That's not a pleasant thing,

00:16:16.000 --> 00:16:22.000
but I think it's something that we're going to have to get used to and

00:16:22.000 --> 00:16:33.000
work on. Now, I want to stress that to understand, you know --

00:16:33.000 --> 00:16:36.000
there are people who don't like this whole business of understanding

00:16:36.000 --> 00:16:40.000
the grassroots, the root causes of things; they don't want to know

00:16:40.000 --> 00:16:43.000
why people hate us. I want to understand it.

00:16:43.000 --> 00:16:45.000
The reason you're trying to understand why they hate us,

00:16:45.000 --> 00:16:48.000
is to get them to quit hating us. The idea

00:16:48.000 --> 00:16:52.000
when you go through this moral exercise of really coming to appreciate

00:16:52.000 --> 00:16:57.000
their humanity and better understand them, is part of an effort

00:16:57.000 --> 00:16:59.000
to get them to appreciate your humanity in the long run.

00:16:59.000 --> 00:17:03.000
I think it's the first step toward that. That's the long-term goal.

00:17:03.000 --> 00:17:08.000
There are people who worry about this, and in fact,

00:17:08.000 --> 00:17:13.000
I, myself, apparently, was denounced on national TV

00:17:13.000 --> 00:17:17.000
a couple of nights ago because of an op-ed I'd written.

00:17:17.000 --> 00:17:19.000
It was kind of along these lines, and the allegation was

00:17:19.000 --> 00:17:23.000
that I have, quote, "affection for terrorists."

00:17:23.000 --> 00:17:26.000
Now, the good news is that the person who said it was Ann Coulter.

00:17:26.000 --> 00:17:28.000
(Laughter)

00:17:28.000 --> 00:17:30.000
(Applause)

00:17:30.000 --> 00:17:32.000
I mean, if you've got to have an enemy, do make it Ann Coulter.

00:17:32.000 --> 00:17:33.000
(Laughter)

00:17:33.000 --> 00:17:37.000
But it's not a crazy concern, OK, because understanding behavior

00:17:37.000 --> 00:17:39.000
can lead to a kind of empathy,

00:17:39.000 --> 00:17:42.000
and it can make it a little harder to deliver tough love, and so on.

00:17:42.000 --> 00:17:49.000
But I think we're a lot closer to erring on the side of not comprehending

00:17:49.000 --> 00:17:53.000
the situation clearly enough, than in comprehending it so clearly

00:17:53.000 --> 00:17:56.000
that we just can't, you know, get the army out to kill terrorists.

00:17:56.000 --> 00:17:59.000
So I'm not really worried about it. So --

00:17:59.000 --> 00:18:01.000
(Laughter)

00:18:01.000 --> 00:18:06.000
-- I mean, we're going to have to work on a lot of fronts,

00:18:06.000 --> 00:18:13.000
but if we succeed -- if we succeed -- then once again,

00:18:13.000 --> 00:18:17.000
non-zero-sumness and the recognition of non-zero-sum dynamics

00:18:17.000 --> 00:18:21.000
will have forced us to a higher moral level.

00:18:21.000 --> 00:18:26.000
And a kind of saving higher moral level,

00:18:26.000 --> 00:18:28.000
something that kind of literally saves the world.

00:18:28.000 --> 00:18:31.000
If you look at the word "salvation" in the Bible --

00:18:31.000 --> 00:18:34.000
the Christian usage that we're familiar with --

00:18:34.000 --> 00:18:37.000
saving souls, that people go to heaven -- that's actually a latecomer.

00:18:37.000 --> 00:18:43.000
The original meaning of the word "salvation" in the Bible is about saving the social system.

00:18:43.000 --> 00:18:46.000
"Yahweh is our Savior" means "He has saved the nation of Israel,"

00:18:46.000 --> 00:18:49.000
which at the time, was a pretty high-level social organization.

00:18:49.000 --> 00:18:53.000
Now, social organization has reached the global level, and I guess,

00:18:53.000 --> 00:18:57.000
if there's good news I can say I'm bringing you, it's just that

00:18:57.000 --> 00:19:03.000
all the salvation of the world requires is the intelligent pursuit

00:19:03.000 --> 00:19:09.000
of self-interests in a disciplined and careful way.

00:19:09.000 --> 00:19:12.000
It's going to be hard. I say we give it a shot anyway

00:19:12.000 --> 00:19:15.000
because we've just come too far to screw it up now.

00:19:15.000 --> 00:19:17.000
Thanks.

00:19:17.000 --> 00:19:19.000
(Applause)

