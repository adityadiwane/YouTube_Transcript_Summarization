WEBVTT
Kind: captions
Language: pt

00:00:00.000 --> 00:00:07.000
Tradutor: Maurício Kakuei Tanaka
Revisor: Maricene Crus

00:00:12.645 --> 00:00:15.116
Há dez anos, os pesquisadores
da visão computacional

00:00:15.136 --> 00:00:19.316
achavam que fazer um computador
distinguir um cão de um gato

00:00:19.340 --> 00:00:21.316
seria quase impossível,

00:00:21.340 --> 00:00:25.036
mesmo com o avanço significativo
da inteligência artificial.

00:00:25.060 --> 00:00:28.620
Agora podemos fazer isso
com precisão superior a 99%.

00:00:29.500 --> 00:00:31.220
Chamamos de classificação de imagem:

00:00:31.240 --> 00:00:34.476
fornecer ao computador uma imagem,
atribuir a ela um rótulo,

00:00:34.500 --> 00:00:37.590
e os computadores também reconhecem
milhares de outras categorias.

00:00:38.500 --> 00:00:41.396
Sou aluno da Universidade de Washington,

00:00:41.420 --> 00:00:43.316
e trabalho no projeto "Darknet",

00:00:43.340 --> 00:00:47.876
uma estrutura de rede neural para preparar
e testar modelos de visão computacional.

00:00:47.900 --> 00:00:52.656
Vamos ver o que o Darknet
acha desta imagem que temos.

00:00:54.340 --> 00:00:57.780
Quando executamos
nosso classificador nela,

00:00:57.800 --> 00:01:00.376
não sabemos apenas se é um cão ou um gato,

00:01:00.396 --> 00:01:02.756
obtemos realmente a raça específica.

00:01:02.780 --> 00:01:04.956
É o nível de detalhe que temos agora.

00:01:04.980 --> 00:01:06.596
E está correto:

00:01:06.620 --> 00:01:08.460
meu cachorro é mesmo um malamute.

00:01:08.860 --> 00:01:13.196
Temos feito avanços incríveis
na classificação de imagens,

00:01:13.220 --> 00:01:17.200
mas o que acontece quando executamos
o classificador em uma imagem como esta?

00:01:18.900 --> 00:01:20.100
Bem...

00:01:24.460 --> 00:01:28.356
Vemos que o classificador retorna
um prognóstico bastante semelhante.

00:01:28.380 --> 00:01:31.476
Está certo: há um malamute na imagem.

00:01:31.500 --> 00:01:35.196
Mas só com este rótulo, não sabemos
realmente muito a respeito

00:01:35.220 --> 00:01:36.887
do que está acontecendo na imagem.

00:01:36.911 --> 00:01:38.631
Precisamos de algo mais convincente.

00:01:39.060 --> 00:01:41.676
Trabalho com um assunto
chamado detecção de objetos,

00:01:41.700 --> 00:01:44.636
em que analisamos a imagem
e tentamos achar todos os objetos,

00:01:44.660 --> 00:01:47.846
colocamos molduras ao redor deles
e dizemos o que eles são.

00:01:48.220 --> 00:01:51.500
Isso é o que acontece quando executamos
um detector nesta imagem.

00:01:53.060 --> 00:01:55.316
Com este tipo de resultado,

00:01:55.340 --> 00:01:58.036
podemos fazer muito mais
com a visão computacional.

00:01:58.060 --> 00:02:01.036
Vemos que o detector identifica
que há um gato e um cachorro.

00:02:01.060 --> 00:02:04.606
Sabe a posição relativa e o tamanho deles.

00:02:04.606 --> 00:02:08.496
Pode até identificar algumas informações
extras, como um livro ao fundo.

00:02:09.100 --> 00:02:12.356
Se quiserem construir um sistema
atualizado de visão computacional,

00:02:12.380 --> 00:02:15.836
como um veículo autodirigível
ou um sistema robótico,

00:02:15.860 --> 00:02:18.316
este é o tipo de informação
que vocês precisam.

00:02:18.340 --> 00:02:21.579
Precisam de algo para poder
interagir com o mundo físico.

00:02:22.579 --> 00:02:24.370
Quando comecei a detectar objetos,

00:02:24.390 --> 00:02:28.156
demorava 20 segundos
para processar uma única imagem.

00:02:28.180 --> 00:02:32.060
Para ter uma ideia da importância
da velocidade nesta área,

00:02:32.940 --> 00:02:35.476
aqui está um exemplo
de um detector de objetos

00:02:35.500 --> 00:02:37.916
que leva dois segundos
para processar uma imagem.

00:02:37.940 --> 00:02:40.556
É dez vezes mais rápido

00:02:40.580 --> 00:02:44.116
que o detector de 20 segundos por imagem.

00:02:44.140 --> 00:02:48.856
Você podem ver que, quando são feitos
os prognósticos, tudo mudou,

00:02:49.700 --> 00:02:53.556
o que não seria muito útil
para uma aplicação.

00:02:53.580 --> 00:02:56.076
Se aumentarmos a velocidade em dez vezes,

00:02:56.100 --> 00:02:58.916
teremos um detector executando
a cinco quadros por segundo.

00:02:58.940 --> 00:03:02.406
Isso é muito melhor, mas, por exemplo,

00:03:02.500 --> 00:03:04.796
se houver algum movimento significativo,

00:03:04.820 --> 00:03:07.630
eu não gostaria de um sistema
como esse dirigindo meu carro.

00:03:08.940 --> 00:03:12.410
Este é nosso sistema de detecção
rodando em tempo real em meu laptop.

00:03:12.820 --> 00:03:15.956
Ele acompanha suavemente
meu movimento ao redor do quadro,

00:03:15.980 --> 00:03:19.700
e é potente para uma grande variedade
de mudanças de tamanho,

00:03:21.260 --> 00:03:22.460
pose,

00:03:23.100 --> 00:03:24.560
para frente, para trás.

00:03:24.560 --> 00:03:25.690
Isso é ótimo.

00:03:25.710 --> 00:03:27.956
É o que realmente precisamos

00:03:27.980 --> 00:03:30.986
se formos construir sistemas
atualizados de visão computacional.

00:03:31.006 --> 00:03:33.270
(Aplausos)

00:03:36.100 --> 00:03:38.276
Em apenas alguns anos,

00:03:38.300 --> 00:03:40.956
passamos de 20 segundos por imagem

00:03:40.980 --> 00:03:44.516
a 20 milissegundos, mil vezes mais rápido.

00:03:44.540 --> 00:03:45.956
Como chegamos lá?

00:03:45.980 --> 00:03:48.996
No passado, os sistemas
de detecção de objetos

00:03:49.020 --> 00:03:50.956
pegavam uma imagem como esta,

00:03:50.980 --> 00:03:53.436
dividiam-na em várias partes

00:03:53.460 --> 00:03:56.716
e depois executavam
um classificador em cada uma delas.

00:03:56.740 --> 00:03:59.276
As pontuações altas
para esse classificador

00:03:59.300 --> 00:04:02.436
eram consideradas detecções na imagem.

00:04:02.460 --> 00:04:06.516
Mas isso envolvia rodar um classificador
milhares de vezes em uma imagem,

00:04:06.540 --> 00:04:10.360
milhares de avaliações de rede neural
para fazer a detecção.

00:04:11.060 --> 00:04:15.596
Em vez disso, preparamos uma única rede
para fazer toda a detecção para nós.

00:04:15.620 --> 00:04:19.900
Ela cria todas as molduras
e probabilidades de classe ao mesmo tempo.

00:04:20.500 --> 00:04:23.996
Com nosso sistema, em vez de analisar
uma imagem milhares de vezes

00:04:24.020 --> 00:04:26.806
para fazer a detecção,
olhamos apenas uma vez.

00:04:26.806 --> 00:04:29.780
Por isso, chamamos de método
"YOLO" de detecção de objetos.

00:04:32.700 --> 00:04:35.656
Com essa velocidade, não estamos
limitados somente a imagens;

00:04:35.656 --> 00:04:38.216
podemos processar vídeos em tempo real.

00:04:38.216 --> 00:04:40.716
Em vez de ver apenas
aquele gato e cachorro,

00:04:40.740 --> 00:04:43.700
podemos ver o movimento
e a interação entre eles.

00:04:46.380 --> 00:04:48.440
Este é um detector que desenvolvemos

00:04:48.460 --> 00:04:52.840
em 80 classes diferentes

00:04:52.860 --> 00:04:56.116
no conjunto de dados "COCO" da Microsoft.

00:04:56.140 --> 00:04:59.476
Ele contém todo tipo de coisas,
como colher, garfo, tigela,

00:04:59.500 --> 00:05:01.300
objetos comuns assim.

00:05:02.180 --> 00:05:05.276
Contém uma variedade
de coisas mais exóticas:

00:05:05.300 --> 00:05:08.556
animais, carros, zebras, girafas.

00:05:08.580 --> 00:05:10.180
Agora vamos fazer algo divertido.

00:05:10.200 --> 00:05:13.736
Iremos para a plateia e veremos
que tipo de coisas podemos detectar.

00:05:13.760 --> 00:05:16.320
Alguém quer um bicho de pelúcia?

00:05:17.820 --> 00:05:20.182
Há alguns ursinhos de pelúcia por aí.

00:05:23.560 --> 00:05:26.396
Podemos diminuir um pouco
nossa tolerância de detecção,

00:05:26.420 --> 00:05:29.820
para poder encontrar
mais de vocês na plateia.

00:05:31.380 --> 00:05:33.806
Vamos ver se conseguirmos
pegar os sinais de PARE.

00:05:33.826 --> 00:05:36.000
Encontramos algumas mochilas.

00:05:37.700 --> 00:05:39.540
Vamos ampliar um pouco.

00:05:42.140 --> 00:05:43.010
Isso é ótimo.

00:05:43.030 --> 00:05:47.816
Todo o processamento acontece
em tempo real no laptop.

00:05:48.900 --> 00:05:49.930
É importante lembrar

00:05:49.950 --> 00:05:53.596
que este é um sistema de detecção
de objetos de uso geral.

00:05:53.620 --> 00:05:58.620
Podemos desenvolver isso
para qualquer domínio de imagem.

00:06:00.140 --> 00:06:02.676
O mesmo código que usamos

00:06:02.700 --> 00:06:05.156
para encontrar sinais
de PARE ou pedestres,

00:06:05.180 --> 00:06:07.156
bicicletas em um veículo autodirigível,

00:06:07.180 --> 00:06:10.036
pode ser usado para encontrar
células cancerígenas

00:06:10.060 --> 00:06:13.076
em uma biópsia de tecido.

00:06:13.100 --> 00:06:17.140
Existem pesquisadores em todo o mundo
que já utilizam esta tecnologia

00:06:18.060 --> 00:06:21.476
para avanços em coisas
como medicina, robótica.

00:06:21.500 --> 00:06:22.876
Esta manhã, li um artigo

00:06:22.900 --> 00:06:27.476
sobre um recenseamento
de animais no Nairobi National Park

00:06:27.500 --> 00:06:30.636
utilizando o YOLO como parte
deste sistema de detecção.

00:06:30.660 --> 00:06:33.756
Isso porque o Darknet tem o código aberto

00:06:33.780 --> 00:06:36.300
de domínio público, gratuito
para qualquer um usar.

00:06:37.420 --> 00:06:39.256
(Aplausos)

00:06:43.140 --> 00:06:48.076
Mas queríamos tornar a detecção
ainda mais acessível e utilizável.

00:06:48.100 --> 00:06:52.156
Então, por meio de uma combinação
de otimização de modelo,

00:06:52.180 --> 00:06:54.476
aproximação e binarização de redes,

00:06:54.500 --> 00:06:58.420
temos realmente a detecção de objetos
sendo executada em um celular.

00:07:04.620 --> 00:07:07.620
(Aplausos)

00:07:10.780 --> 00:07:15.836
Estou realmente animado,
pois temos uma solução muito potente

00:07:15.860 --> 00:07:18.156
para esta questão de visão computacional.

00:07:18.180 --> 00:07:22.036
Qualquer um pode pegar
e construir algo com ele.

00:07:22.060 --> 00:07:25.236
O restante depende agora de vocês

00:07:25.260 --> 00:07:28.196
e das pessoas em todo o mundo
com acesso a este software.

00:07:28.220 --> 00:07:31.876
Mal posso esperar para ver
o que elas farão com essa tecnologia.

00:07:31.900 --> 00:07:33.116
Obrigado.

00:07:33.140 --> 00:07:35.130
(Aplausos)

