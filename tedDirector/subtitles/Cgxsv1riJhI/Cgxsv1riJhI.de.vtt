WEBVTT
Kind: captions
Language: de

00:00:00.000 --> 00:00:07.000
Übersetzung: Janine Drotschmann
Lektorat: Sonja Maria Neef

00:00:12.645 --> 00:00:13.816
Vor zehn Jahren

00:00:13.816 --> 00:00:16.616
gingen Forscher für 
Maschinelles Sehen davon aus,

00:00:16.616 --> 00:00:18.720
dass es für einen Computer 
kaum möglich sei,

00:00:18.740 --> 00:00:21.336
eine Katze von einem Hund 
zu unterscheiden,

00:00:21.336 --> 00:00:25.050
trotz großer Fortschritte
auf dem Feld der Künstlichen Intelligenz.

00:00:25.060 --> 00:00:29.193
Mittlerweile ist das zu über 99% möglich.

00:00:29.193 --> 00:00:31.356
Man nennt diese Aufgabe 
"Bildklassifikation".

00:00:31.380 --> 00:00:34.676
Sie geben dem Computer ein Bild
mit einer expliziten Bezeichnung,

00:00:34.676 --> 00:00:37.957
und der Computer kennt zusätzlich
tausende weiterer Kategorien dafür.

00:00:38.547 --> 00:00:41.170
Ich studiere an der Universität 
von Washington

00:00:41.170 --> 00:00:43.366
und arbeite an einem 
Projekt namens "Darknet",

00:00:43.366 --> 00:00:45.216
einem Framework für neurale Netzwerke,

00:00:45.216 --> 00:00:48.276
mit dem Modelle zur Bilderkennung
trainiert und getestet werden.

00:00:48.276 --> 00:00:50.876
Sehen wir mal, was Darknet

00:00:50.900 --> 00:00:52.840
über das Bild denkt, das wir hier haben.

00:00:54.340 --> 00:00:55.870
Wenn wir unseren Klassifikator

00:00:56.320 --> 00:00:57.760
auf dieses Bild loslassen,

00:00:57.760 --> 00:01:00.936
sehen wir, dass nicht nur
"Hund" oder "Katze" vorausgesagt wird,

00:01:00.936 --> 00:01:03.350
er gibt sogar eine Aussage
über die konkrete Rasse.

00:01:03.350 --> 00:01:05.616
Dieser Genauigkeitsgrad 
ist im Moment möglich.

00:01:05.616 --> 00:01:06.770
Und es stimmt --

00:01:06.770 --> 00:01:09.480
es handelt sich tatsächlich
um einen Alaskan Malamute.

00:01:09.480 --> 00:01:13.190
Wir haben beachtliche Fortschritte
in der Bildklassifikation gemacht.

00:01:13.190 --> 00:01:15.480
Was aber passiert,
wenn wir unserem Klassifikator

00:01:15.480 --> 00:01:17.204
ein solches Bild vorlegen?

00:01:18.900 --> 00:01:20.100
Nun ...

00:01:24.460 --> 00:01:28.356
Wir sehen, dass der Klassifikator
so ziemlich das gleiche Ergebnis liefert.

00:01:28.380 --> 00:01:31.476
Und es stimmt wieder --
da ist ein Malamute abgebildet.

00:01:31.500 --> 00:01:35.090
Doch mit dieser Aussage allein
wissen wir noch nicht viel darüber,

00:01:35.090 --> 00:01:36.957
was sich genau in dem Bild abspielt.

00:01:36.957 --> 00:01:38.821
Wir brauchen etwas Leisungsfähigeres.

00:01:39.060 --> 00:01:41.676
Ich arbeite an einer Aufgabe
namens "Objekterkennung".

00:01:41.700 --> 00:01:44.636
Hier versuchen wir,
alle Objekte in einem Bild zu erkennen.

00:01:44.660 --> 00:01:46.806
Wir ziehen um jedes Objekt
eine Markierungsbox

00:01:46.806 --> 00:01:48.660
und versehen sie mit einer Bezeichnung.

00:01:48.660 --> 00:01:52.840
Jetzt sehen wir, was der Erkenner
über das Bild sagt.

00:01:53.090 --> 00:01:54.976
Mit dieser Art Ergebnis können wir

00:01:55.020 --> 00:01:58.036
viel mehr mit den Algorithmen
des Maschinellen Sehens anfangen.

00:01:58.060 --> 00:02:01.000
Wir sehen, dass eine Katze 
und ein Hund erkannt wird.

00:02:01.000 --> 00:02:03.626
Der Erkenner liefert ihre
relativen Positionen im Bild,

00:02:03.626 --> 00:02:04.556
ihre Größe,

00:02:04.580 --> 00:02:06.516
und vielleicht sogar noch mehr:

00:02:06.540 --> 00:02:08.500
Im Hintergrund ist ein Buch zu sehen.

00:02:09.100 --> 00:02:12.320
Wenn man das Maschinelle Sehen
in einem größeren System nutzen will,

00:02:12.320 --> 00:02:15.836
etwa in einem selbstfahrenden Fahrzeug
oder einem Robotsystem,

00:02:15.860 --> 00:02:18.316
braucht man genau solche Informationen,

00:02:18.340 --> 00:02:21.579
auf deren Basis man mit 
der physischen Welt interagieren kann.

00:02:21.979 --> 00:02:24.836
Als ich damit anfing,
in der Objekterkennung zu arbeiten,

00:02:24.860 --> 00:02:28.156
dauerte die Verarbeitung
zwanzig Sekunden für jedes einzelne Bild.

00:02:28.180 --> 00:02:32.060
Um ein Gefühl dafür zu bekommen,
warum Geschwindigkeit hier so wichtig ist,

00:02:32.940 --> 00:02:35.260
zeige ich Ihnen einen Objekterkenner,

00:02:35.260 --> 00:02:38.276
der zwei Sekunden braucht,
um ein Einzelbild zu verarbeiten --

00:02:38.276 --> 00:02:40.556
was bereits zehnmal schneller ist

00:02:40.580 --> 00:02:44.060
als der Zwanzig-Sekunden-Klassifikator.

00:02:44.060 --> 00:02:46.846
Bis dieser Erkenner 
seine Voraussagen bekannt gibt,

00:02:46.846 --> 00:02:49.440
hat sich der Zustand der Welt
bereits völlig verändert.

00:02:49.700 --> 00:02:52.116
Das wäre für die praktische Anwendung

00:02:52.140 --> 00:02:53.556
völlig ungeeignet.

00:02:53.580 --> 00:02:56.076
Wenn wir ihn noch einmal
zehnmal schneller machen,

00:02:56.100 --> 00:02:58.916
verarbeitet der Erkenner 
fünf Bilder pro Sekunde.

00:02:58.940 --> 00:03:00.476
Das ist deutlich besser.

00:03:00.500 --> 00:03:02.476
Wenn jedoch beispielsweise

00:03:02.500 --> 00:03:04.796
eine nennenswerte Bewegung stattfindet --

00:03:04.820 --> 00:03:08.020
Ich würde nicht wollen, dass 
ein solches System mein Auto steuert.

00:03:08.940 --> 00:03:12.380
Das ist unser Erkennungssystem.
Es läuft in Echtzeit auf meinem Laptop.

00:03:12.820 --> 00:03:15.956
Es verfolgt mich flüssig, 
während ich mich im Bildbereich bewege,

00:03:15.980 --> 00:03:19.700
ist robust gegenüber 
Veränderungen der Größe,

00:03:21.260 --> 00:03:22.460
der Stellung,

00:03:23.100 --> 00:03:24.956
Vorder- oder Rückseite.

00:03:24.980 --> 00:03:26.196
Das ist großartig.

00:03:26.220 --> 00:03:27.956
So etwas brauchen wir,

00:03:27.980 --> 00:03:30.876
wenn wir das Maschinelle Sehen
in Systeme einbauen wollen.

00:03:30.900 --> 00:03:34.900
(Applaus)

00:03:36.100 --> 00:03:38.276
In nur ein paar Jahren

00:03:38.300 --> 00:03:40.956
haben wir es von zwanzig Sekunden pro Bild

00:03:40.980 --> 00:03:44.516
zu zwanzig Millisekunden pro Bild 
geschafft. Eintausendmal schneller.

00:03:44.540 --> 00:03:45.956
Wie haben wir das gemacht?

00:03:45.980 --> 00:03:48.996
Nun, in der Vergangenheit
nahmen Objekterkenner

00:03:49.020 --> 00:03:50.956
ein solches Bild

00:03:50.980 --> 00:03:53.436
und teilten es in viele 
kleinere Bereiche ein.

00:03:53.460 --> 00:03:56.716
Der Klassifikator verarbeitete
jeden einzelnen dieser Bereiche.

00:03:56.740 --> 00:03:59.276
Erreichte etwas 
einen hohen Score im Klassifikator,

00:03:59.300 --> 00:04:02.436
wurde es als erkanntes Objekt gewertet.

00:04:02.460 --> 00:04:06.516
Dies bedeutete aber, den Klassifikator 
tausende Male für ein Bild anzuwenden.

00:04:06.540 --> 00:04:09.670
Tausende von Auswertungen
neuraler Netzwerke für die Erkennung.

00:04:11.060 --> 00:04:15.596
Wir haben stattdessen ein einzelnes
neurales Netzwerk trainiert,

00:04:15.620 --> 00:04:19.900
das alle Markierungsboxen und
Wahrscheinlichkeiten simultan berechnet.

00:04:20.500 --> 00:04:23.930
Unser System ermöglicht es,
statt tausende Male ein Bild anzusehen,

00:04:23.930 --> 00:04:25.576
um die Objekte darin zu erkennen,

00:04:25.576 --> 00:04:27.586
das Bild nur ein einziges Mal anzusehen.

00:04:27.586 --> 00:04:30.560
Deswegen nennen wir unsere 
Methode der Objekterkennung "YOLO".

00:04:31.180 --> 00:04:35.156
Mit einer solchen Geschwindigkeit
sind wir nicht auf Bilder beschränkt --

00:04:35.180 --> 00:04:37.596
wir können ganze Videos 
in Echtzeit verarbeiten.

00:04:37.620 --> 00:04:40.716
Statt nur eine Katze 
und einen Hund zu sehen,

00:04:40.740 --> 00:04:43.700
können wir beobachten, wie sie 
sich bewegen und interagieren.

00:04:46.380 --> 00:04:48.436
Diesen Erkenner haben wir

00:04:48.460 --> 00:04:52.836
auf 80 verschiedene Klassen

00:04:52.860 --> 00:04:56.116
aus Microsofts COCO-Daten trainiert.

00:04:56.140 --> 00:04:59.476
Er kennt alle möglichen Objekte
wie Löffel, Gabel, Schüssel --

00:04:59.500 --> 00:05:01.300
alltägliche Gegenstände,

00:05:02.180 --> 00:05:05.276
aber auch exotischere:

00:05:05.300 --> 00:05:08.556
Tiere, Autos, Zebras, Giraffen.

00:05:08.580 --> 00:05:10.516
Jetzt machen wir etwas Lustiges.

00:05:10.540 --> 00:05:12.636
Wir richten die Kamera auf das Publikum

00:05:12.660 --> 00:05:14.676
und sehen, was wir erkennen können.

00:05:14.700 --> 00:05:16.320
Möchte jemand ein Plüschtier?

00:05:17.820 --> 00:05:19.582
Hier sind ein paar Teddybären.

00:05:21.860 --> 00:05:26.396
Wir können die Empfindlichkeit
des Erkenners ein wenig senken,

00:05:26.420 --> 00:05:29.820
um mehr einzelne Personen
im Publikum zu erkennen.

00:05:31.100 --> 00:05:33.836
Lassen Sie uns sehen,
ob wir diese Stoppschilder bekommen.

00:05:33.836 --> 00:05:35.620
Wir sehen einige Rucksäcke ...

00:05:37.700 --> 00:05:39.540
Wir zoomen etwas hinein ...

00:05:42.140 --> 00:05:43.396
Das ist großartig.

00:05:43.420 --> 00:05:46.596
Die gesamte Verarbeitung 
passiert in Echtzeit

00:05:46.620 --> 00:05:47.820
auf dem Laptop.

00:05:48.900 --> 00:05:50.356
Man darf nicht vergessen,

00:05:50.380 --> 00:05:53.596
dass das ein ganz allgemeines
Objekterkennungssystem ist.

00:05:53.620 --> 00:05:58.620
Wir können es also
für jede Art von Bildern trainieren.

00:05:59.980 --> 00:06:02.510
Denselben Code, den wir benutzen,

00:06:02.510 --> 00:06:05.316
damit ein selbstfahrendes Fahrzeug
Stoppschilder, Fußgänger

00:06:05.316 --> 00:06:07.166
oder Fahrräder erkennen kann,

00:06:07.180 --> 00:06:10.036
kann man auch nutzen, um Krebszellen

00:06:10.060 --> 00:06:13.076
in einer Gewebeprobe ausfindig zu machen.

00:06:13.100 --> 00:06:17.140
Forscher auf der ganzen Welt
nutzen diese Technologie bereits,

00:06:18.060 --> 00:06:21.350
um Fortschritte auf Gebieten
wie Medizin oder Robotik zu erzielen.

00:06:21.350 --> 00:06:23.656
Heute morgen habe ich 
einen Fachartikel gelesen:

00:06:23.656 --> 00:06:27.476
Im Nationalpark von Nairobi
wurde eine Zählung der Tiere vorgenommen,

00:06:27.500 --> 00:06:30.636
mit YOLO als Teil des Erkennungssystems.

00:06:30.660 --> 00:06:33.756
Das ist möglich, weil Darknet quelloffen,

00:06:33.760 --> 00:06:36.300
frei zugänglich 
und für alle verwendbar ist.

00:06:37.420 --> 00:06:43.116
(Applaus)

00:06:43.140 --> 00:06:48.076
Aber wir wollten Bilderkennung
sogar noch leichter nutzbar machen.

00:06:48.100 --> 00:06:51.460
Daher haben wir durch Modelloptimierung,

00:06:51.460 --> 00:06:54.476
Binarisierung des neuralen Netzes
und Approximation erreicht,

00:06:54.500 --> 00:06:58.420
dass die Objekterkennung
sogar auf einem Mobiltelefon läuft.

00:07:04.620 --> 00:07:09.940
(Applaus)

00:07:10.780 --> 00:07:15.190
Das ist aufregend, weil wir 
damit eine ziemlich mächtige Lösung

00:07:15.190 --> 00:07:18.156
für dieses grundlegende Problem 
des Maschinellen Sehens haben.

00:07:18.180 --> 00:07:22.036
Jeder kann sie nutzen
und etwas damit bauen.

00:07:22.060 --> 00:07:25.236
Nun liegt es bei Ihnen

00:07:25.260 --> 00:07:28.396
und allen Menschen auf der Welt
mit Zugang zu dieser Software.

00:07:28.396 --> 00:07:32.276
Ich bin gespannt zu sehen, welche Ideen 
sie mit dieser Technologie umsetzen.

00:07:32.276 --> 00:07:33.116
Vielen Dank.

00:07:33.140 --> 00:07:36.580
(Applaus)

