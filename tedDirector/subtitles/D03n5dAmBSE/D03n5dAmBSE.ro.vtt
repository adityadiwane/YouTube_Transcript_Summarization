WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Florin Bejgu
Corector: Alina Cincan

00:00:15.260 --> 00:00:17.260
Până la sfârșitul acestui an,

00:00:17.260 --> 00:00:20.260
vor fi aproape un miliard de persoane pe planetă

00:00:20.260 --> 00:00:22.260
care folosesc în mod regulat rețelele sociale.

00:00:22.260 --> 00:00:24.260
Singurul lucru pe care îl au în comun cu toții

00:00:24.260 --> 00:00:27.260
este că vor muri.

00:00:27.260 --> 00:00:30.260
Cu toate că acest gând poate fi oarecum morbid,

00:00:30.260 --> 00:00:32.260
eu cred că are totuși câteva implicații profunde

00:00:32.260 --> 00:00:34.260
ce merita cercetate.

00:00:34.260 --> 00:00:37.260
Ceea ce m-a făcut să mă gândesc la asta

00:00:37.260 --> 00:00:40.260
a fost un articol pe un blog semnat de Derek K. Miller la începutul anului,

00:00:40.260 --> 00:00:43.260
care a fost un jurnalist ce a scris despre știință și tehnologie

00:00:43.260 --> 00:00:45.260
și care a murit de cancer.

00:00:45.260 --> 00:00:48.260
Și ceea ce Miller a făcut a fost să ceară familiei și prietenilor săi să scrie un articol pe blog

00:00:48.260 --> 00:00:50.260
ce a fost publicat la scurt timp după ce a murit.

00:00:50.260 --> 00:00:52.260
Iată de la ce a pornit totul.

00:00:52.260 --> 00:00:54.260
A zis, "Iată. Am murit

00:00:54.260 --> 00:00:56.260
și aceasta este ultima mea postare pe blog.

00:00:56.260 --> 00:00:59.260
In avans, am cerut ca odată ce trupul meu a murit

00:00:59.260 --> 00:01:01.260
pedepsit de cancer,

00:01:01.260 --> 00:01:04.260
familia și prietenii să publice acest mesaj scris de mine --

00:01:04.260 --> 00:01:06.260
prima parte a procesului

00:01:06.260 --> 00:01:09.260
de transformare a unui website activ într-o arhivă."

00:01:09.260 --> 00:01:11.260
Acum, ca jurnalist,

00:01:11.260 --> 00:01:13.260
Arhiva lui Miller poate a fost mai bine scrisă

00:01:13.260 --> 00:01:15.260
și mai atent întreținută decât majoritatea,

00:01:15.260 --> 00:01:17.260
dar ce contează este că toți cei de azi

00:01:17.260 --> 00:01:19.260
creăm o arhivă

00:01:19.260 --> 00:01:21.260
ce e cumva complet diferită

00:01:21.260 --> 00:01:23.260
de orice a fost creat

00:01:23.260 --> 00:01:25.260
de orice altă generație precedentă.

00:01:25.260 --> 00:01:27.260
Hai să ne gândim puțin.

00:01:27.260 --> 00:01:29.260
Chiar acum sunt 48 de ore de filme

00:01:29.260 --> 00:01:32.260
încărcate pe YouTube în fiecare minut.

00:01:32.260 --> 00:01:36.260
200 de milioane de Tweet-uri sunt postate zilnic.

00:01:36.260 --> 00:01:39.260
Iar utilizatorul mediu de Facebook

00:01:39.260 --> 00:01:43.260
creează 90 de bucăți de conținut în fiecare lună.

00:01:43.260 --> 00:01:46.260
Așa că atunci când te gândești la părinții și bunicii tăi,

00:01:46.260 --> 00:01:48.260
cel mult au creat

00:01:48.260 --> 00:01:50.260
câteva poze și filmulețe de familie,

00:01:50.260 --> 00:01:53.260
sau un jurnal ce stă într-o cutie pe undeva.

00:01:53.260 --> 00:01:56.260
Dar azi noi creăm cu toții acestă arhivă digitală bogată

00:01:56.260 --> 00:01:58.260
ce va trăi în nor la nesfârșit,

00:01:58.260 --> 00:02:00.260
ani după ce noi nu mai suntem.

00:02:00.260 --> 00:02:03.260
Și cred că asta va crea câteva oportunități incredibil de intrigante

00:02:03.260 --> 00:02:05.260
pentru tehnologi.

00:02:05.260 --> 00:02:07.260
Ca să fie clar, eu sunt jurnalist și nu tehnolog,

00:02:07.260 --> 00:02:09.260
așa că ce aș vrea să fac pe scurt

00:02:09.260 --> 00:02:11.260
este să pictez o imagine

00:02:11.260 --> 00:02:14.260
a ceea ce prezentul și viitorul o să arate.

00:02:14.260 --> 00:02:16.260
Acum vedem deja că există niște servicii

00:02:16.260 --> 00:02:18.260
ce sunt făcute să ne lase să decidem

00:02:18.260 --> 00:02:21.260
ce se întâmplă cu profilul nostru online și conturile noastre de pe rețelele sociale

00:02:21.260 --> 00:02:23.260
după ce murim.

00:02:23.260 --> 00:02:25.260
Unul dintre ele de fapt, în mod interesant,

00:02:25.260 --> 00:02:27.260
m-a găsit când m-am logat la raionul de delicatese

00:02:27.260 --> 00:02:29.260
la un restaurant din New york

00:02:29.260 --> 00:02:32.260
pe foursquare.

00:02:32.260 --> 00:02:34.260
(Înregistrare) Adam Ostrow: Bună ziua.

00:02:34.260 --> 00:02:36.260
Moartea: Adam?

00:02:36.260 --> 00:02:38.260
AO: Da.

00:02:38.260 --> 00:02:41.260
Moartea: Moartea te poate găsi oriunde, oricând,

00:02:41.260 --> 00:02:44.260
chiar și la raionul de produse organice.

00:02:44.260 --> 00:02:46.260
AO: Cine este?

00:02:46.260 --> 00:02:49.260
Moartea: Du-te la ifidie.net (dacămor.net)

00:02:49.260 --> 00:02:51.260
înainte să fie prea târziu.

00:02:51.260 --> 00:02:53.260
(Râsete)

00:02:53.260 --> 00:02:55.260
Adam Ostrow: Destul de înfiorător, nu?

00:02:55.260 --> 00:02:57.260
Ceea ce face acest serviciu, destul de simplu,

00:02:57.260 --> 00:02:59.260
este să te lase să creezi un mesaj sau un video

00:02:59.260 --> 00:03:02.260
ce poate fi postat pe Facebook după ce mori.

00:03:02.260 --> 00:03:04.260
Un alt serviciu existent

00:03:04.260 --> 00:03:06.260
se numește 1.000 Memories (1.000 Amintiri).

00:03:06.260 --> 00:03:08.260
Ceea ce poți face este să creezi un omagiu online celor apropriați,

00:03:08.260 --> 00:03:11.260
cuprinzând poze și filme și povestiri

00:03:11.260 --> 00:03:14.260
ce pot fi postate după ce ai decedat.

00:03:14.260 --> 00:03:17.260
Dar ceea ce urmează cred că este mult mai interesant.

00:03:17.260 --> 00:03:20.260
Cred că o mulțime din voi ați auzit de Deb Roy

00:03:20.260 --> 00:03:22.260
care, în Martie,

00:03:22.260 --> 00:03:26.260
a demonstrat cum a fost posibil să analizeze mai mult de 90.000 de ore de înregistrări video.

00:03:26.260 --> 00:03:28.260
Cred că odată ce abilitatea mașinilor

00:03:28.260 --> 00:03:30.260
de a înțelege limbajul uman și procesa mari cantități de date

00:03:30.260 --> 00:03:32.260
se îmbunătățește continuu,

00:03:32.260 --> 00:03:34.260
va deveni posibil

00:03:34.260 --> 00:03:36.260
să analizăm o întreagă viață de conținut --

00:03:36.260 --> 00:03:39.260
de Tweet-uri, de fotografii, de filme, de postări pe blog --

00:03:39.260 --> 00:03:41.260
pe care le producem în număr așa de mare.

00:03:41.260 --> 00:03:43.260
Și cred că odată cu asta,

00:03:43.260 --> 00:03:46.260
va fi posibil ca persoana noastră digitală

00:03:46.260 --> 00:03:49.260
să continue să interacționeze în lumea reală mult după ce noi nu mai suntem,

00:03:49.260 --> 00:03:52.260
datorită imensității de conținut pe care îl creăm

00:03:52.260 --> 00:03:55.260
și abilității tehnologice de a-l putea interpreta.

00:03:55.260 --> 00:03:58.260
Acum deja începem să vedem câteva experimente.

00:03:58.260 --> 00:04:00.260
Unul dintre servicii numit My Next Tweet (Următorul meu Tweet)

00:04:00.260 --> 00:04:03.260
analizează tot șirul de Tweet-uri, tot ce ai postat pe Twitter,

00:04:03.260 --> 00:04:06.260
ca să poată face predicții a ceea ce urmează să spui.

00:04:06.260 --> 00:04:08.260
Așadar acum, după cum puteți vedea,

00:04:08.260 --> 00:04:10.260
rezultatele pot fi oarecum amuzante.

00:04:10.260 --> 00:04:12.260
Vă puteți imagina ce poate face ceva ca asta

00:04:12.260 --> 00:04:14.260
5, 10 sau 20 de ani de acum înainte

00:04:14.260 --> 00:04:17.260
pe măsură ce capacitățile noastre tehnologice se îmbunătățesc.

00:04:17.260 --> 00:04:19.260
Mergând ceva mai departe,

00:04:19.260 --> 00:04:21.260
laboratorul media al MIT lucrează la roboți

00:04:21.260 --> 00:04:24.260
ce pot interacționa aproape ca oamenii.

00:04:24.260 --> 00:04:26.260
Dar dacă acei roboți ar putea interacționa

00:04:26.260 --> 00:04:29.260
pe baza caracteristicilor unice ale unei anumite persoane

00:04:29.260 --> 00:04:31.260
bazată pe sute de mii de piese de conținut

00:04:31.260 --> 00:04:34.260
pe care acea persoană le produce în timpul vieții?

00:04:34.260 --> 00:04:36.260
În final, să ne gândim la aceasta faimoasă scenă

00:04:36.260 --> 00:04:38.260
din noaptea alegerilor din 2008

00:04:38.260 --> 00:04:40.260
din Statele Unite,

00:04:40.260 --> 00:04:42.260
când CNN a proiectat o hologramă

00:04:42.260 --> 00:04:44.260
a artistului hip hop will.i.am în studioul lor

00:04:44.260 --> 00:04:47.260
pentru un interviu cu Anderson Cooper.

00:04:47.260 --> 00:04:49.260
Dacă am putea să folosim același tip de tehnologie

00:04:49.260 --> 00:04:53.260
să proiectăm o reprezentare a celor dragi în sufrageria noastră --

00:04:53.260 --> 00:04:55.260
interacționând într-un mod foarte real

00:04:55.260 --> 00:04:58.260
bazat pe conținutul produs de ei în timp ce erau în viață.

00:04:58.260 --> 00:05:01.260
Cred că acest lucru va deveni complet posibil

00:05:01.260 --> 00:05:03.260
pe măsură ce cantitatea de date pe care le folosim

00:05:03.260 --> 00:05:05.260
și abilitatea tehnologică de a le interpreta

00:05:05.260 --> 00:05:08.260
se dezvoltă exponențial.

00:05:08.260 --> 00:05:10.260
Așadar în încheiere, cred că tot ce trebuie să ne gândim

00:05:10.260 --> 00:05:12.260
este dacă vrem ca acest lucru să devină realitate --

00:05:12.260 --> 00:05:14.260
și dacă e așa,

00:05:14.260 --> 00:05:17.260
ce înseamnă pentru definiția de viață și tot ce urmează după ea.

00:05:17.260 --> 00:05:19.260
Vă mulțumesc foarte mult.

00:05:19.260 --> 00:05:23.260
(Aplauze)

