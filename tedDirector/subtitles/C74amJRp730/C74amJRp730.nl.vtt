WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Maxime Van Damme
Nagekeken door: Peter van de Ven

00:00:12.780 --> 00:00:13.980
Beeld je eens in

00:00:14.770 --> 00:00:16.090
dat je een ruimte in gaat,

00:00:17.300 --> 00:00:19.436
een controlekamer met een aantal mensen,

00:00:19.450 --> 00:00:22.650
100 mensen gebogen over een bureau
met kleine wijzerplaatjes.

00:00:23.100 --> 00:00:24.620
En dat die controlekamer

00:00:25.500 --> 00:00:29.196
de gedachten en gevoelens zal bepalen

00:00:29.220 --> 00:00:30.460
van een miljard mensen.

00:00:32.250 --> 00:00:34.320
Dit mag dan wel klinken
als science fiction,

00:00:35.140 --> 00:00:37.356
maar het bestaat al,

00:00:37.380 --> 00:00:39.200
nu, vandaag.

00:00:39.860 --> 00:00:43.220
Ik weet het, omdat ik vroeger
in één van deze controlekamers zat.

00:00:43.979 --> 00:00:46.270
Ik was een ontwerpethicus bij Google,

00:00:46.270 --> 00:00:49.900
waar ik bestudeerde hoe je de gedachten
van mensen ethisch kunt besturen.

00:00:50.380 --> 00:00:51.930
Want waar we niet over praten,

00:00:51.930 --> 00:00:55.836
is hoe een handvol mensen
bij een handvol technologiebedrijven

00:00:55.860 --> 00:01:01.540
met hun keuzes bepalen
wat een miljard mensen vandaag denken.

00:01:02.040 --> 00:01:03.956
Als jij je telefoon tevoorschijn haalt

00:01:03.980 --> 00:01:07.076
en zij ontwerpen hoe die werkt
of wat er op je overzicht staat,

00:01:07.100 --> 00:01:10.316
claimt hij kleine blokjes tijd
in onze gedachten.

00:01:10.340 --> 00:01:13.476
Als je een berichtje ziet,
plaatst dat gedachten in je hoofd

00:01:13.500 --> 00:01:15.610
die je misschien niet
van plan was te hebben.

00:01:16.220 --> 00:01:18.706
Als je over dat bericht veegt,

00:01:18.740 --> 00:01:22.735
zorgt dat dat je wat tijd zult besteden
door ergens ingezogen te worden

00:01:22.770 --> 00:01:25.625
waar je niet van plan was
om te worden ingezogen.

00:01:26.960 --> 00:01:29.030
Wanneer we praten over technologie

00:01:29.740 --> 00:01:32.556
hebben we het meestal
over haar onbegrensde mogelijkheden;

00:01:32.580 --> 00:01:34.430
het kan elke kant op gaan.

00:01:35.090 --> 00:01:36.576
Maar serieus,

00:01:36.590 --> 00:01:40.100
ik zal je vertellen waarom het
een hele specifieke richting uit gaat.

00:01:40.660 --> 00:01:43.220
Want het evolueert
niet eender welke kant uit.

00:01:43.640 --> 00:01:47.990
Er is een verborgen doel dat bepaalt
hoe onze technologie zich ontwikkeld

00:01:48.020 --> 00:01:51.370
en dat doel is de race voor onze aandacht.

00:01:52.660 --> 00:01:55.396
Want iedere nieuwe site --

00:01:55.420 --> 00:01:58.156
TED, verkiezingen, politici,

00:01:58.180 --> 00:02:00.156
spelletjes, zelfs meditatie apps --

00:02:00.180 --> 00:02:02.500
moet strijden om één ding.

00:02:02.980 --> 00:02:04.716
Dat is onze aandacht.

00:02:04.740 --> 00:02:07.150
En daar hebben we maar zoveel van.

00:02:08.260 --> 00:02:10.676
De beste manier om iemand
z'n aandacht te krijgen,

00:02:10.700 --> 00:02:13.140
is door te weten
hoe iemand z'n brein werkt.

00:02:13.620 --> 00:02:15.956
En er zijn een heleboel
overredingstechnieken

00:02:15.980 --> 00:02:19.476
die ik leerde tijdens m'n studies
in het 'overredingstechnologie lab'

00:02:19.500 --> 00:02:21.280
om de aandacht te krijgen.

00:02:21.700 --> 00:02:23.490
Een simpel voorbeeld is YouTube.

00:02:23.820 --> 00:02:26.756
YouTube wil je zo lang mogelijk
op hun site houden.

00:02:26.780 --> 00:02:28.210
Dus wat doen ze?

00:02:28.660 --> 00:02:31.120
Ze spelen automatisch de volgende video.

00:02:31.530 --> 00:02:34.970
Stel dat dat goed werkt
en ze houden je wat langer vast.

00:02:34.970 --> 00:02:37.490
Als je Netflix bent,
dan kijk je daar naar en zegt:

00:02:37.490 --> 00:02:39.282
"Dat verkleint mijn marktaandeel,

00:02:39.282 --> 00:02:42.142
dus ik ga de volgende aflevering
automatisch afspelen."

00:02:43.140 --> 00:02:46.026
Maar Facebook zeg dan:
"Dat verkleint mijn marktaandeel,

00:02:46.026 --> 00:02:49.060
dus nu moet ik alle videos
op de nieuwsfeed automatisch afspelen

00:02:49.060 --> 00:02:51.132
nog voor je op 'play' klikt."

00:02:52.140 --> 00:02:55.300
Dus het internet
evolueert niet in het wilde weg.

00:02:56.140 --> 00:03:00.556
De reden dat het op dit moment 
voelt alsof het ons erin zuigt,

00:03:00.580 --> 00:03:02.956
is vanwege die race om onze aandacht.

00:03:02.980 --> 00:03:06.506
We weten waar dit heen gaat;
technologie is niet neutraal.

00:03:07.140 --> 00:03:10.556
Het wordt die race naar het
diepste punt van de hersenstam;

00:03:10.580 --> 00:03:12.780
over wie het diepste kan gaan.

00:03:13.740 --> 00:03:16.070
Laat me je een voorbeeld
geven van Snapchat.

00:03:16.070 --> 00:03:17.350
Mocht je het niet weten,

00:03:17.350 --> 00:03:21.660
Snapchat is onder Amerikaanse tieners
de populairste manier om te communiceren.

00:03:21.660 --> 00:03:26.120
Dus als je, net als ik,
berichtjes gebruikt om te communiceren:

00:03:26.120 --> 00:03:30.220
Snapchat is hetzelfde voor tieners;
het heeft wel 100 miljoen gebruikers.

00:03:30.220 --> 00:03:32.690
Zij introduceerden iets
wat ze 'Snapstreaks' noemen,

00:03:32.690 --> 00:03:34.420
wat het aantal dagen op rij toont

00:03:34.420 --> 00:03:36.796
dat twee mensen met elkaar
hebben gecommuniceerd.

00:03:37.620 --> 00:03:39.476
Wat ze dus doen,

00:03:39.500 --> 00:03:42.950
is twee mensen iets geven
wat ze niet willen verliezen.

00:03:43.820 --> 00:03:47.150
Want als je een tiener bent
en je hebt 150 dagen op een rij,

00:03:47.150 --> 00:03:49.100
dan wil je dat niet verliezen.

00:03:49.100 --> 00:03:53.560
Bedenk wat dit voor kleine blokjes tijd
in het brein van kinderen claimt.

00:03:53.980 --> 00:03:56.386
Dit is geen theorie:
als kinderen op vakantie gaan,

00:03:56.386 --> 00:03:59.596
blijken ze hun paswoorden
aan tot wel vijf vrienden te geven

00:03:59.620 --> 00:04:01.836
om hun Snapstreaks gaande te houden

00:04:01.860 --> 00:04:03.876
als zij het zelf niet kunnen doen.

00:04:03.900 --> 00:04:05.836
En ze hebben er wel 30,

00:04:05.860 --> 00:04:10.046
dus moeten ze foto's nemen
van plaatjes of muren of plafonds

00:04:13.020 --> 00:04:15.690
Ze hebben dus niet eens
echte conversaties.

00:04:15.690 --> 00:04:18.046
We zijn geneigd om te denken:

00:04:18.046 --> 00:04:21.990
oh, die gebruiken Snapchat
zoals wij vroeger de telefoon.

00:04:21.990 --> 00:04:23.660
Dat kan geen kwaad.

00:04:24.300 --> 00:04:28.589
Maar als we in de jaren 70
zaten te kletsen aan de telefoon,

00:04:29.039 --> 00:04:31.950
zaten er aan de andere kant
van het scherm geen 100 ingenieurs

00:04:31.950 --> 00:04:34.536
die exact wisten hoe je
psychologisch in elkaar steekt

00:04:34.536 --> 00:04:37.520
en je van twee kanten
aan het lijntje hielden.

00:04:38.260 --> 00:04:41.660
Als je hier een beetje boos van wordt,

00:04:42.500 --> 00:04:45.076
merk dan op dat die gedachte
je vanzelf binnenvalt.

00:04:45.100 --> 00:04:48.780
Woede is ook een hele goede manier
om je aandacht te krijgen.

00:04:49.700 --> 00:04:52.706
Want we kiezen niet voor woede,
het overkomt ons.

00:04:52.740 --> 00:04:55.910
Als jij de Facebook nieuwsfeed bent,
of je dat nu wilt of niet,

00:04:55.910 --> 00:04:58.796
dan profiteer je ervan als iemand boos is.

00:04:58.820 --> 00:05:01.160
Want woede plaatst niet alleen

00:05:01.160 --> 00:05:04.970
een reactie in jouw
emotionele tijd en ruimte,

00:05:05.010 --> 00:05:07.606
we willen die woede
ook delen met andere mensen.

00:05:07.630 --> 00:05:11.486
We willen het delen en zeggen:
"Kan je geloven dat ze dat zeiden?"

00:05:12.340 --> 00:05:15.670
Dus woede werkt heel goed
om aandacht te krijgen,

00:05:15.670 --> 00:05:17.540
zo goed dat als Facebook de keuze had

00:05:17.540 --> 00:05:20.980
tussen het tonen van een woedende
en een kalme nieuwsfeed,

00:05:21.840 --> 00:05:23.850
ze je de woedende feed
zouden willen tonen.

00:05:23.850 --> 00:05:26.120
Niet omdat iemand dat bewust koos,

00:05:26.120 --> 00:05:29.440
maar omdat dat beter werkt
om je aandacht te krijgen.

00:05:30.940 --> 00:05:33.930
En de controlekamer van de nieuwsfeed

00:05:33.930 --> 00:05:36.800
hoeft ons geen
verantwoording af te leggen.

00:05:36.800 --> 00:05:39.186
Het hoeft alleen maar
de aandacht te maximaliseren.

00:05:39.186 --> 00:05:42.796
Het is ook verantwoordelijk,
vanwege het bedrijfsmodel van adverteren,

00:05:42.820 --> 00:05:46.496
jegens degene die de controlekamer
genoeg kan betalen om te kunnen zeggen:

00:05:46.496 --> 00:05:47.866
"Die groep daar.

00:05:47.866 --> 00:05:50.790
Ik wil deze gedachten
in hun hoofd brengen."

00:05:51.580 --> 00:05:53.140
Je kunt gewoon richten.

00:05:53.860 --> 00:05:58.966
Je kunt je leugens precies richten
op de mensen die het meest vatbaar zijn.

00:05:59.900 --> 00:06:03.280
En omdat dit winstgevend is,
zal dit enkel nog verergeren.

00:06:04.860 --> 00:06:07.020
Dus ben ik vandaag hier,

00:06:07.980 --> 00:06:10.780
omdat de prijs zo duidelijk is.

00:06:11.970 --> 00:06:14.030
Ik ken geen dringender probleem dan dit,

00:06:14.030 --> 00:06:17.380
want dit probleem zit onder
alle andere problemen.

00:06:18.540 --> 00:06:21.576
Het ontneemt ons niet alleen de vrijheid

00:06:21.576 --> 00:06:25.120
om onze aandacht te besteden
en het leven te leven wat we willen.

00:06:25.540 --> 00:06:29.076
Het verandert de manier
waarop we onze conversaties voeren,

00:06:29.100 --> 00:06:32.170
het verandert onze democratie
en het verandert ons vermogen

00:06:32.170 --> 00:06:35.600
om de gesprekken en relaties
te hebben die we met elkaar willen.

00:06:36.980 --> 00:06:38.756
Het treft iedereen,

00:06:38.780 --> 00:06:42.140
omdat een miljard mensen
er zo een in zijn zak heeft.

00:06:45.180 --> 00:06:47.020
Hoe herstellen we dit?

00:06:48.900 --> 00:06:51.836
We moeten drie dingen radicaal veranderen

00:06:51.860 --> 00:06:54.090
aan de technologie
en aan onze samenleving.

00:06:55.540 --> 00:06:59.340
Ten eerste moeten we inzien
dat we overreed kunnen worden.

00:07:00.570 --> 00:07:03.286
Zodra je inziet dat je geest
geprogrammeerd kan worden

00:07:03.286 --> 00:07:04.730
om kleine gedachten te hebben

00:07:04.730 --> 00:07:07.346
met kleine blokjes tijd
die je niet gekozen hebt,

00:07:07.370 --> 00:07:11.686
zou je dat inzicht niet willen gebruiken
om jezelf ertegen te beschermen?

00:07:12.420 --> 00:07:15.626
Ik denk dat we onszelf
fundamenteel anders moeten zien.

00:07:15.660 --> 00:07:19.100
Het is bijna als een nieuwe periode
in de historie, zoals de Verlichting,

00:07:19.100 --> 00:07:21.430
maar dan een Verlichting
in zelfbewustzijn:

00:07:21.430 --> 00:07:23.540
dat we overreed kunnen worden

00:07:23.970 --> 00:07:26.590
en dat er iets zou kunnen zijn
wat we willen beschermen.

00:07:27.220 --> 00:07:31.796
Ten tweede zullen we nieuwe modellen
en verantwoordingssystemen nodig hebben,

00:07:31.820 --> 00:07:35.130
zodat als de wereld beter
en steeds overredender wordt --

00:07:35.130 --> 00:07:37.390
want het zal alleen maar
overredender worden --

00:07:37.390 --> 00:07:39.140
dat de mensen in die controlekamers

00:07:39.140 --> 00:07:42.036
verantwoordelijk en transparant
zijn voor wat wij willen.

00:07:42.060 --> 00:07:44.756
De enige vorm van ethische
overreding die bestaat,

00:07:44.780 --> 00:07:46.716
is wanneer de doelen van de overreder

00:07:46.740 --> 00:07:48.940
overeenstemmen met
de doelen van de overrede.

00:07:49.400 --> 00:07:53.300
Dat betekent vraagtekens zetten bij zaken
als het bedrijfsmodel van adverteren.

00:07:54.540 --> 00:07:55.816
Tot slot

00:07:55.840 --> 00:07:57.910
hebben we een renaissance
van design nodig,

00:07:58.900 --> 00:08:01.956
want heb je eenmaal
dit inzicht in de menselijke aard,

00:08:01.980 --> 00:08:04.956
dat je de tijdlijn van een miljard
mensen kan sturen --

00:08:04.980 --> 00:08:07.716
realiseer je dat er mensen zijn
die een wens hebben

00:08:07.740 --> 00:08:10.876
over wat ze willen doen,
en denken, en voelen,

00:08:10.876 --> 00:08:12.710
en hoe ze willen geïnformeerd worden,

00:08:12.710 --> 00:08:15.290
en we worden gewoon
in die andere richtingen getrokken.

00:08:15.290 --> 00:08:18.650
Een miljard mensen wordt gewoon in
verschillende richtingen getrokken.

00:08:18.650 --> 00:08:21.696
Beeld je een volledige
design-renaissance in

00:08:22.140 --> 00:08:23.940
die is gericht op het produceren

00:08:23.940 --> 00:08:27.936
van de meest nuttige
en meest gewenste tijdlijn.

00:08:28.330 --> 00:08:29.806
En dat zou twee zaken inhouden:

00:08:29.810 --> 00:08:33.906
de eerste is bescherming
tegen tijdlijnen die we niet willen,

00:08:33.906 --> 00:08:36.300
de gedachten die we niet willen denken,

00:08:36.300 --> 00:08:39.560
zodat wanneer die 'ping' klinkt,
we er niet door worden weggezogen.

00:08:39.560 --> 00:08:43.646
De tweede zou ons in staat stellen
om het leven te leiden dat we willen.

00:08:43.680 --> 00:08:45.460
Laat me je een voorbeeld geven.

00:08:45.810 --> 00:08:48.556
Vandaag zegt je vriend
bijvoorbeeld een etentje af

00:08:48.580 --> 00:08:52.355
en je voelt je een beetje eenzaam.

00:08:52.379 --> 00:08:53.836
Dus wat doe je op dat moment?

00:08:53.860 --> 00:08:55.139
Je opent Facebook.

00:08:56.780 --> 00:08:58.476
Op dat moment

00:08:58.500 --> 00:09:01.876
willen de ontwerpers
in de controlekamer maar één ding:

00:09:01.900 --> 00:09:05.590
je zo lang mogelijk aan het scherm houden.

00:09:06.460 --> 00:09:10.356
Wat nu als die designers
in plaats daarvan een tijdlijn maakten

00:09:10.380 --> 00:09:13.626
die op basis van alle
gegevens die ze hadden

00:09:13.650 --> 00:09:16.996
jou zouden helpen uit te gaan
met mensen waar je om geeft?

00:09:17.020 --> 00:09:22.436
Stel je voor hoe alle eenzaamheid
in de samenleving zou worden verzacht

00:09:22.460 --> 00:09:25.956
als Facebook de mensen
die tijdlijn zou willen bieden.

00:09:25.980 --> 00:09:27.555
Of beeld je een ander gesprek in.

00:09:27.579 --> 00:09:30.660
Stel je wil iets heel controversieels
posten op Facebook,

00:09:30.660 --> 00:09:32.550
wat belangrijk is om te kunnen doen,

00:09:32.550 --> 00:09:34.790
over controversiële zaken praten.

00:09:34.790 --> 00:09:37.300
Op dit moment is er
dat grote vak voor je opmerking,

00:09:37.300 --> 00:09:40.730
alsof het je vraagt:
welke toets wil je indrukken?

00:09:40.990 --> 00:09:43.290
Ofwel, het heeft
allerlei dingetjes gepland

00:09:43.290 --> 00:09:45.560
die je op het scherm zult blijven doen.

00:09:45.560 --> 00:09:48.620
Beeld je in dat er in plaats daarvan
een andere knop was die zei:

00:09:48.620 --> 00:09:50.620
"Waar zou je nu
het meest bij gebaat zijn?"

00:09:50.620 --> 00:09:52.636
En je klikt op 'een etentje geven'.

00:09:52.660 --> 00:09:54.580
En vlak daaronder staat:

00:09:54.580 --> 00:09:56.476
"Wie wil er naar het etentje komen?"

00:09:56.500 --> 00:09:59.756
Je zou nog steeds een gesprek
hebben over iets controversieels,

00:09:59.780 --> 00:10:03.516
maar je zou het hebben
op de beste plaats op jouw tijdlijn,

00:10:03.540 --> 00:10:07.856
namelijk die avond thuis,
met een paar vrienden om erover te praten.

00:10:08.820 --> 00:10:11.980
Dus beeld je in dat we
een 'zoek en vervang' doen

00:10:12.770 --> 00:10:17.906
op alle tijdlijnen die ons momenteel
tot meer en meer schermtijd verleiden

00:10:18.900 --> 00:10:23.296
en al die tijdlijnen vervangen
door wat we in ons leven willen.

00:10:26.780 --> 00:10:28.620
Het hoeft niet zo te zijn.

00:10:30.180 --> 00:10:32.436
In plaats van onze aandacht
het lastig te maken,

00:10:32.460 --> 00:10:36.726
stel dat we deze data en ons inzicht
in de menselijke natuur zouden gebruiken

00:10:36.760 --> 00:10:39.796
om ons een bovenmenselijk
vermogen te geven om te focussen,

00:10:39.820 --> 00:10:43.956
een bovenmenselijk talent om onze
aandacht te geven aan waar we van houden,

00:10:43.980 --> 00:10:46.596
en een bovenmenselijk talent
om conversaties te hebben

00:10:46.620 --> 00:10:48.620
die we nodig hebben voor democratie.

00:10:51.420 --> 00:10:54.100
De meest complexe uitdagingen ter wereld

00:10:56.100 --> 00:10:59.220
vereisen niet alleen
onze individuele aandacht.

00:11:00.140 --> 00:11:04.000
Ze vereisen het gezamenlijk gebruiken
en coördineren van onze aandacht.

00:11:04.030 --> 00:11:05.800
De klimaatverandering zal vereisen

00:11:05.800 --> 00:11:09.196
dat heel wat mensen hun aandacht
samen kunnen coördineren

00:11:09.220 --> 00:11:11.116
in de meest krachtige manier.

00:11:11.140 --> 00:11:14.860
Stel dat we een bovenmenselijk vermogen
ontwikkelen om dat te doen.

00:11:18.820 --> 00:11:22.980
Soms zijn 's werelds meest dringende
en belangrijke problemen

00:11:23.860 --> 00:11:28.260
niet deze hypothetische dingen die
we zouden kunnen creëren in de toekomst.

00:11:28.290 --> 00:11:32.456
Soms bevinden zich de meest
dringende problemen vlak voor onze neus,

00:11:32.500 --> 00:11:35.770
de dingen die al de gedachten
van een miljard mensen bepalen.

00:11:36.390 --> 00:11:39.796
In plaats van opgewonden te worden
over de nieuwe 'augmented reality'

00:11:39.820 --> 00:11:43.116
en virtual reality en de coole dingen
die zouden kunnen gebeuren,

00:11:43.140 --> 00:11:46.296
die ook onderhevig zullen zijn
aan dezelfde race voor aandacht,

00:11:46.330 --> 00:11:49.146
moeten we misschien eerst
de strijd om de aandacht verhelpen

00:11:49.146 --> 00:11:51.380
op het ding dat iedereen
al in zijn zak heeft.

00:11:51.780 --> 00:11:53.666
In plaats ons van gek te laten maken

00:11:53.666 --> 00:11:57.466
door de spannendste, nieuwe,
coole, chique onderwijs apps,

00:11:57.490 --> 00:12:00.546
kunnen we iets doen aan hoe
het brein van kinderen wordt verkwist

00:12:00.570 --> 00:12:03.570
aan het heen en weer zenden
van lege berichten.

00:12:03.860 --> 00:12:07.896
(Applaus)

00:12:07.920 --> 00:12:09.546
In plaats van ons zorgen te maken

00:12:09.570 --> 00:12:13.236
over gevaarlijke losgeslagen
artificiële intelligentie in de toekomst

00:12:13.260 --> 00:12:15.500
die maar één doel voor ogen hebben,

00:12:16.300 --> 00:12:18.010
zouden we iets kunnen doen

00:12:18.010 --> 00:12:21.236
aan de losgeslagen artificiële
intelligentie die nu al bestaat,

00:12:21.260 --> 00:12:24.550
namelijk die nieuwsfeeds
met maar één doel voor ogen.

00:12:25.730 --> 00:12:29.626
Net zoals we in plaats van weg te lopen
en op andere planeten te gaan leven,

00:12:29.640 --> 00:12:31.926
we beter kunnen zorgen
voor die waar we al zijn.

00:12:31.946 --> 00:12:35.940
(Applaus)

00:12:39.860 --> 00:12:41.636
Dit probleem oplossen

00:12:41.660 --> 00:12:45.460
is cruciaal voor het oplossen
van alle andere problemen.

00:12:46.420 --> 00:12:50.346
Alles in ons leven
en in onze collectieve problemen

00:12:50.380 --> 00:12:54.470
vereist het vermogen om onze aandacht
te richten op waar we om geven.

00:12:55.570 --> 00:12:57.160
Aan het einde van ons leven

00:12:58.060 --> 00:13:01.070
hebben we alleen
onze aandacht en onze tijd.

00:13:01.330 --> 00:13:03.656
Waar kunnen we die het best aan besteden?

00:13:03.656 --> 00:13:04.826
Dank je.

00:13:04.826 --> 00:13:07.900
(Applaus)

00:13:17.580 --> 00:13:20.516
Chris Anderson: Tristan,
dank je. Wacht nog even.

00:13:20.540 --> 00:13:21.876
Allereerst, dank je.

00:13:21.900 --> 00:13:24.600
Ik weet dat we je heel laat
gevraagd hebben om te spreken

00:13:24.600 --> 00:13:29.436
en dat je een stressvolle week had
om dit samen te rapen, dus dank je.

00:13:30.500 --> 00:13:34.476
Sommige luisteraars zullen zeggen
dat je eigenlijk klaagt over verslaving

00:13:34.500 --> 00:13:37.806
en voor de mensen die dit doen,
is het feitelijk interessant.

00:13:37.830 --> 00:13:39.146
Al deze design beslissingen

00:13:39.170 --> 00:13:42.416
hebben gebruikersinhoud voortgebracht
die fantastisch interessant is.

00:13:42.420 --> 00:13:44.246
De wereld is interessanter dan ooit.

00:13:44.270 --> 00:13:45.486
Wat is daar mis mee?

00:13:45.510 --> 00:13:47.606
Tristan Harris: Ik vind
dit heel interessant.

00:13:47.630 --> 00:13:52.436
Als je YouTube bent, bijvoorbeeld,

00:13:52.460 --> 00:13:54.900
wil je altijd een volgende
interessante video tonen.

00:13:54.900 --> 00:13:57.050
Je wil die suggesties steeds beter maken.

00:13:57.050 --> 00:13:59.470
Maar zelfs al kon je
de perfecte video voorstellen

00:13:59.470 --> 00:14:01.390
die iedereen zou willen bekijken,

00:14:01.390 --> 00:14:04.260
je maakt de kijker alleen maar
verslaafd aan video's kijken.

00:14:04.260 --> 00:14:08.726
Wat we missen is het uitvinden
wat onze grenzen zouden zijn.

00:14:08.726 --> 00:14:11.430
Je zou willen dat YouTube
iets wist over in slaap vallen.

00:14:11.430 --> 00:14:12.980
De CEO van Netflix zei pas:

00:14:12.980 --> 00:14:16.276
"Onze grootste concurrenten
zijn Facebook, YouTube en slaap."

00:14:18.040 --> 00:14:21.420
Ook moeten we inzien
dat de mens niet onbegrensd is

00:14:21.420 --> 00:14:24.190
en dat we zekere grenzen
of dimensies in ons leven hebben

00:14:24.190 --> 00:14:26.520
die we geëerbiedigd 
en gerespecteerd willen zien.

00:14:26.520 --> 00:14:28.476
Technologie kan hierbij helpen.

00:14:28.500 --> 00:14:31.116
(Applaus)

00:14:31.140 --> 00:14:32.836
CA: Zou je kunnen zeggen

00:14:32.860 --> 00:14:38.856
dat een deel van het probleem hier is
dat we een naïeve menselijke aard hebben?

00:14:38.880 --> 00:14:41.510
Veel hiervan is gerechtvaardigd
omdat we dit zelf willen

00:14:41.510 --> 00:14:43.696
en die algoritmes
doen juist geweldig hun werk

00:14:43.696 --> 00:14:45.876
in het bedienen van die voorkeur.

00:14:45.876 --> 00:14:47.396
Maar welke voorkeur?

00:14:47.420 --> 00:14:50.130
We hebben voorkeuren omtrent dingen

00:14:50.130 --> 00:14:52.316
waarom we echt geven
als we erover nadenken

00:14:52.340 --> 00:14:55.396
versus onze instinctieve voorkeuren.

00:14:55.420 --> 00:15:00.070
Als we die nuances in de menselijke aard
in de ontwerpen konden implementeren,

00:15:00.100 --> 00:15:01.556
zou dat een stap vooruit zijn?

00:15:01.580 --> 00:15:02.710
TH: Absoluut.

00:15:02.710 --> 00:15:06.510
Nu is het alsof onze technologie
eigenlijk alleen aan ons oerbrein vraagt:

00:15:06.810 --> 00:15:11.650
hoe hou ik je impulsief bezig
met het eerstvolgende kleine dingetje.

00:15:11.650 --> 00:15:12.670
In plaats van

00:15:12.670 --> 00:15:15.306
waar kun je in jouw leven
nu het best tijd aan besteden?

00:15:15.306 --> 00:15:16.970
Wat zou de perfecte tijdlijn zijn,

00:15:16.970 --> 00:15:20.700
waar ben je op dit moment bij gebaat,
tijdens je laatste dag bij TED.

00:15:20.700 --> 00:15:24.446
CA: Dus als Facebook
en Google ons zouden vragen:

00:15:24.820 --> 00:15:27.716
"Hey, wil je dat we je
beschouwende brein verbeteren

00:15:27.760 --> 00:15:29.416
of je oerbrein? Kies maar."

00:15:29.780 --> 00:15:31.860
TH: Precies. Dat zou een manier zijn, ja.

00:15:34.178 --> 00:15:37.036
CA: Je zei overreedbaarheid,
dat is een interessant woord,

00:15:37.060 --> 00:15:39.670
want volgens mij zijn er
twee soorten overreedbaarheid.

00:15:39.670 --> 00:15:42.430
Er is de overreedbaarheid
die we nu toepassen,

00:15:42.430 --> 00:15:44.590
van redeneren, denken en debatteren.

00:15:44.590 --> 00:15:47.110
Maar ik denk dat je bijna
over een andere soort praat,

00:15:47.110 --> 00:15:48.640
een meer instinctieve soort,

00:15:48.640 --> 00:15:51.050
van overreed worden
zonder te weten dat je nadenkt.

00:15:51.050 --> 00:15:53.690
TH: Exact. De reden dat ik zo
veel om dit probleem geef,

00:15:53.690 --> 00:15:57.450
is dat ik studeerde in het 
Persuasive Technology Lab op Stanford

00:15:57.450 --> 00:15:59.780
dat studenten exact
deze technieken leerde.

00:15:59.780 --> 00:16:03.576
Er zijn conferenties en workshops
die mensen al deze listige manieren leren

00:16:03.600 --> 00:16:06.656
om de aandacht van mensen te krijgen
en hun leven te manipuleren.

00:16:06.656 --> 00:16:09.140
En het is omdat de meesten
niet weten dat dat bestaat

00:16:09.140 --> 00:16:11.116
dat deze conversatie zo belangrijk is.

00:16:11.540 --> 00:16:15.316
CA: Tristan, jij en ik kennen beiden
zo veel mensen van deze bedrijven.

00:16:15.340 --> 00:16:17.316
Er zijn er zelfs veel hier aanwezig.

00:16:17.340 --> 00:16:18.641
Ik weet niet wat jij denkt,

00:16:18.641 --> 00:16:21.750
maar mijn ervaring is
dat er geen tekort is aan goede wil.

00:16:21.750 --> 00:16:24.050
Mensen willen een betere wereld.

00:16:24.050 --> 00:16:27.660
Ze zijn eigenlijk - ze willen het echt.

00:16:28.140 --> 00:16:33.146
Ik denk niet dat je wil zeggen
dat dit kwaadwillige mensen zijn.

00:16:33.190 --> 00:16:35.830
Het is een systeem
dat ongewilde consequenties heeft

00:16:35.830 --> 00:16:37.556
die uit de hand zijn gelopen.

00:16:37.560 --> 00:16:39.140
TH: Ja, de strijd om de aandacht.

00:16:39.140 --> 00:16:42.380
Het is de klassieke race naar de bodem
wanneer je aandacht wil hebben

00:16:42.380 --> 00:16:43.546
en het is zo gespannen.

00:16:43.550 --> 00:16:46.650
De enige manier om meer te krijgen
is lager op de hersenstam gaan,

00:16:46.650 --> 00:16:49.076
lager naar woede, lager naar emotie,

00:16:49.100 --> 00:16:50.796
lager in het oerbrein.

00:16:50.820 --> 00:16:54.376
CA: Heel erg bedankt om ons
hierover iets wijzer te maken.

00:16:54.410 --> 00:16:57.076
Tristan Harris, dank je.
TH: Dank je.

00:16:57.100 --> 00:16:59.340
(Applaus)

