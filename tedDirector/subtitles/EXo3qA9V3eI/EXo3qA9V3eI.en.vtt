WEBVTT
Kind: captions
Language: en

00:00:12.371 --> 00:00:14.467
Steve Ramirez: My first
year of grad school,

00:00:14.491 --> 00:00:15.907
I found myself in my bedroom

00:00:15.931 --> 00:00:18.207
eating lots of Ben &amp; Jerry's

00:00:18.231 --> 00:00:19.891
watching some trashy TV

00:00:19.915 --> 00:00:23.118
and maybe, maybe listening
to Taylor Swift.

00:00:23.142 --> 00:00:24.859
I had just gone through a breakup.

00:00:24.883 --> 00:00:26.306
(Laughter)

00:00:26.330 --> 00:00:28.502
So for the longest time, all I would do

00:00:28.526 --> 00:00:32.318
is recall the memory of this
person over and over again,

00:00:32.342 --> 00:00:34.811
wishing that I could get
rid of that gut-wrenching,

00:00:34.835 --> 00:00:37.344
visceral "blah" feeling.

00:00:37.368 --> 00:00:39.627
Now, as it turns out,
I'm a neuroscientist,

00:00:39.651 --> 00:00:42.029
so I knew that the memory of that person

00:00:42.053 --> 00:00:45.169
and the awful, emotional undertones
that color in that memory,

00:00:45.193 --> 00:00:47.803
are largely mediated
by separate brain systems.

00:00:47.827 --> 00:00:50.304
And so I thought, what if we could
go into the brain

00:00:50.328 --> 00:00:52.258
and edit out that nauseating feeling

00:00:52.282 --> 00:00:55.228
but while keeping the memory
of that person intact?

00:00:55.252 --> 00:00:57.919
Then I realized, maybe
that's a little bit lofty for now.

00:00:57.943 --> 00:01:00.432
So what if we could start
off by going into the brain

00:01:00.456 --> 00:01:03.065
and just finding a single
memory to begin with?

00:01:03.089 --> 00:01:05.579
Could we jump-start
that memory back to life,

00:01:05.603 --> 00:01:09.447
maybe even play with the contents
of that memory?

00:01:09.471 --> 00:01:11.676
All that said, there is one person
in the entire world right now

00:01:11.700 --> 00:01:13.843
that I really hope is not
watching this talk.

00:01:13.867 --> 00:01:17.672
(Laughter)

00:01:17.696 --> 00:01:20.961
So there is a catch. There is a catch.

00:01:20.985 --> 00:01:23.749
These ideas probably remind
you of "Total Recall,"

00:01:23.773 --> 00:01:25.723
"Eternal Sunshine of the Spotless Mind,"

00:01:25.747 --> 00:01:27.026
or of "Inception."

00:01:27.050 --> 00:01:28.812
But the movie stars that we work with

00:01:28.836 --> 00:01:30.545
are the celebrities of the lab.

00:01:30.569 --> 00:01:32.445
Xu Liu: Test mice.

00:01:32.469 --> 00:01:33.573
(Laughter)

00:01:33.597 --> 00:01:36.727
As neuroscientists, we work
in the lab with mice

00:01:36.751 --> 00:01:40.137
trying to understand how memory works.

00:01:40.161 --> 00:01:42.706
And today, we hope
to convince you that now

00:01:42.730 --> 00:01:45.922
we are actually able to activate
a memory in the brain

00:01:45.946 --> 00:01:48.092
at the speed of light.

00:01:48.116 --> 00:01:51.198
To do this, there's only two simple
steps to follow.

00:01:51.222 --> 00:01:54.708
First, you find and label
a memory in the brain,

00:01:54.732 --> 00:01:58.338
and then you activate it with a switch.

00:01:58.362 --> 00:01:59.783
As simple as that.

00:01:59.807 --> 00:02:01.605
(Laughter)

00:02:01.629 --> 00:02:03.450
SR: Are you convinced?

00:02:03.474 --> 00:02:07.171
So, turns out finding a memory
in the brain isn't all that easy.

00:02:07.195 --> 00:02:09.974
XL: Indeed. This is way more
difficult than, let's say,

00:02:09.998 --> 00:02:12.378
finding a needle in a haystack,

00:02:12.402 --> 00:02:15.117
because at least, you know,
the needle is still something

00:02:15.141 --> 00:02:17.467
you can physically put your fingers on.

00:02:17.491 --> 00:02:19.444
But memory is not.

00:02:19.468 --> 00:02:22.482
And also, there's way
more cells in your brain

00:02:22.506 --> 00:02:27.548
than the number of straws
in a typical haystack.

00:02:27.572 --> 00:02:30.427
So yeah, this task does
seem to be daunting.

00:02:30.451 --> 00:02:34.106
But luckily, we got help
from the brain itself.

00:02:34.130 --> 00:02:36.561
It turned out that all we need
to do is basically

00:02:36.585 --> 00:02:38.554
to let the brain form a memory,

00:02:38.578 --> 00:02:42.384
and then the brain will tell
us which cells are involved

00:02:42.408 --> 00:02:44.150
in that particular memory.

00:02:44.174 --> 00:02:46.507
SR: So what was going on in my brain

00:02:46.531 --> 00:02:48.601
while I was recalling the memory of an ex?

00:02:48.625 --> 00:02:51.003
If you were to just completely
ignore human ethics for a second

00:02:51.027 --> 00:02:52.671
and slice up my brain right now,

00:02:52.695 --> 00:02:54.886
you would see that there
was an amazing number

00:02:54.910 --> 00:02:57.867
of brain regions that were active
while recalling that memory.

00:02:57.891 --> 00:03:00.779
Now one brain region
that would be robustly active

00:03:00.803 --> 00:03:02.786
in particular is called the hippocampus,

00:03:02.810 --> 00:03:05.241
which for decades has
been implicated in processing

00:03:05.265 --> 00:03:07.657
the kinds of memories
that we hold near and dear,

00:03:07.681 --> 00:03:10.231
which also makes it
an ideal target to go into

00:03:10.255 --> 00:03:13.016
and to try and find and maybe
reactivate a memory.

00:03:13.040 --> 00:03:15.410
XL: When you zoom in into the hippocampus,

00:03:15.434 --> 00:03:17.758
of course you will see lots of cells,

00:03:17.782 --> 00:03:20.789
but we are able to find
which cells are involved

00:03:20.813 --> 00:03:22.265
in a particular memory,

00:03:22.289 --> 00:03:24.883
because whenever a cell is active,

00:03:24.907 --> 00:03:26.431
like when it's forming a memory,

00:03:26.455 --> 00:03:30.104
it will also leave a footprint
that will later allow us to know

00:03:30.128 --> 00:03:32.806
these cells are recently active.

00:03:32.830 --> 00:03:35.164
SR: So the same way
that building lights at night

00:03:35.188 --> 00:03:38.617
let you know that somebody's probably
working there at any given moment,

00:03:38.641 --> 00:03:41.202
in a very real sense, there
are biological sensors

00:03:41.226 --> 00:03:43.156
within a cell that are turned on

00:03:43.180 --> 00:03:45.291
only when that cell was just working.

00:03:45.315 --> 00:03:47.601
They're sort of biological
windows that light up

00:03:47.625 --> 00:03:49.816
to let us know that that cell
was just active.

00:03:49.840 --> 00:03:51.974
XL: So we clipped part of this sensor,

00:03:51.998 --> 00:03:55.121
and attached that to a switch
to control the cells,

00:03:55.145 --> 00:03:59.021
and we packed this switch
into an engineered virus

00:03:59.045 --> 00:04:01.609
and injected that into the brain
of the mice.

00:04:01.633 --> 00:04:04.243
So whenever a memory is being formed,

00:04:04.267 --> 00:04:06.591
any active cells for that memory

00:04:06.615 --> 00:04:09.333
will also have this switch installed.

00:04:09.357 --> 00:04:11.548
SR: So here is what the hippocampus
looks like

00:04:11.572 --> 00:04:13.798
after forming a fear memory, for example.

00:04:13.822 --> 00:04:15.938
The sea of blue that you see here

00:04:15.962 --> 00:04:17.890
are densely packed brain cells,

00:04:17.914 --> 00:04:19.435
but the green brain cells,

00:04:19.459 --> 00:04:22.031
the green brain cells
are the ones that are holding on

00:04:22.055 --> 00:04:23.374
to a specific fear memory.

00:04:23.398 --> 00:04:25.353
So you are looking at the crystallization

00:04:25.377 --> 00:04:27.740
of the fleeting formation of fear.

00:04:27.764 --> 00:04:31.237
You're actually looking
at the cross-section of a memory right now.

00:04:31.261 --> 00:04:33.690
XL: Now, for the switch
we have been talking about,

00:04:33.714 --> 00:04:36.615
ideally, the switch has
to act really fast.

00:04:36.639 --> 00:04:39.194
It shouldn't take minutes
or hours to work.

00:04:39.218 --> 00:04:43.458
It should act at the speed
of the brain, in milliseconds.

00:04:43.482 --> 00:04:44.888
SR: So what do you think, Xu?

00:04:44.912 --> 00:04:47.490
Could we use, let's say,
pharmacological drugs

00:04:47.514 --> 00:04:49.328
to activate or inactivate brain cells?

00:04:49.352 --> 00:04:53.391
XL: Nah. Drugs are pretty messy.
They spread everywhere.

00:04:53.415 --> 00:04:56.399
And also it takes them
forever to act on cells.

00:04:56.423 --> 00:05:00.048
So it will not allow us
to control a memory in real time.

00:05:00.072 --> 00:05:04.342
So Steve, how about let's zap
the brain with electricity?

00:05:04.366 --> 00:05:06.647
SR: So electricity is pretty fast,

00:05:06.671 --> 00:05:08.386
but we probably wouldn't
be able to target it

00:05:08.410 --> 00:05:10.839
to just the specific cells
that hold onto a memory,

00:05:10.863 --> 00:05:12.618
and we'd probably fry the brain.

00:05:12.642 --> 00:05:15.813
XL: Oh. That's true.
So it looks like, hmm,

00:05:15.837 --> 00:05:18.424
indeed we need to find a better way

00:05:18.448 --> 00:05:21.719
to impact the brain at the speed of light.

00:05:21.743 --> 00:05:26.805
SR: So it just so happens that light
travels at the speed of light.

00:05:26.829 --> 00:05:30.288
So maybe we could activate
or inactive memories

00:05:30.312 --> 00:05:31.785
by just using light --

00:05:31.809 --> 00:05:33.140
XL: That's pretty fast.

00:05:33.164 --> 00:05:35.025
SR: -- and because normally brain cells

00:05:35.049 --> 00:05:36.621
don't respond to pulses of light,

00:05:36.645 --> 00:05:38.579
so those that would respond
to pulses of light

00:05:38.603 --> 00:05:41.035
are those that contain
a light-sensitive switch.

00:05:41.059 --> 00:05:42.981
Now to do that, first we need
to trick brain cells

00:05:43.005 --> 00:05:44.443
to respond to laser beams.

00:05:44.467 --> 00:05:45.513
XL: Yep. You heard it right.

00:05:45.537 --> 00:05:47.680
We are trying to shoot
lasers into the brain.

00:05:47.704 --> 00:05:49.390
(Laughter)

00:05:49.414 --> 00:05:52.714
SR: And the technique that lets
us do that is optogenetics.

00:05:52.738 --> 00:05:55.996
Optogenetics gave us this
light switch that we can use

00:05:56.020 --> 00:05:57.504
to turn brain cells on or off,

00:05:57.528 --> 00:06:00.021
and the name of that switch
is channelrhodopsin,

00:06:00.045 --> 00:06:02.558
seen here as these green dots
attached to this brain cell.

00:06:02.582 --> 00:06:05.868
You can think of channelrhodopsin
as a sort of light-sensitive switch

00:06:05.892 --> 00:06:08.484
that can be artificially
installed in brain cells

00:06:08.508 --> 00:06:10.398
so that now we can use that switch

00:06:10.422 --> 00:06:13.422
to activate or inactivate the brain
cell simply by clicking it,

00:06:13.446 --> 00:06:15.970
and in this case we click
it on with pulses of light.

00:06:15.994 --> 00:06:19.665
XL: So we attach this light-sensitive
switch of channelrhodopsin

00:06:19.689 --> 00:06:21.873
to the sensor we've been talking about

00:06:21.897 --> 00:06:24.328
and inject this into the brain.

00:06:24.352 --> 00:06:27.539
So whenever a memory is being formed,

00:06:27.563 --> 00:06:29.766
any active cell for that particular memory

00:06:29.790 --> 00:06:33.250
will also have this light-sensitive
switch installed in it

00:06:33.274 --> 00:06:35.651
so that we can control these cells

00:06:35.675 --> 00:06:39.915
by the flipping of a laser
just like this one you see.

00:06:39.939 --> 00:06:42.779
SR: So let's put all of this
to the test now.

00:06:42.803 --> 00:06:44.914
What we can do is we can take our mice

00:06:44.938 --> 00:06:47.842
and then we can put them in a box
that looks exactly like this box here,

00:06:47.866 --> 00:06:50.182
and then we can give them
a very mild foot shock

00:06:50.206 --> 00:06:52.254
so that they form a fear
memory of this box.

00:06:52.278 --> 00:06:54.337
They learn that something
bad happened here.

00:06:54.361 --> 00:06:56.679
Now with our system,
the cells that are active

00:06:56.703 --> 00:06:59.469
in the hippocampus
in the making of this memory,

00:06:59.493 --> 00:07:02.352
only those cells will now
contain channelrhodopsin.

00:07:02.376 --> 00:07:05.369
XL: When you are as small as a mouse,

00:07:05.393 --> 00:07:08.964
it feels as if the whole
world is trying to get you.

00:07:08.988 --> 00:07:10.712
So your best response of defense

00:07:10.736 --> 00:07:13.194
is trying to be undetected.

00:07:13.218 --> 00:07:15.227
Whenever a mouse is in fear,

00:07:15.251 --> 00:07:17.109
it will show this very typical behavior

00:07:17.133 --> 00:07:18.878
by staying at one corner of the box,

00:07:18.902 --> 00:07:21.640
trying to not move any part of its body,

00:07:21.664 --> 00:07:24.935
and this posture is called freezing.

00:07:24.959 --> 00:07:29.229
So if a mouse remembers that something
bad happened in this box,

00:07:29.253 --> 00:07:31.852
and when we put them
back into the same box,

00:07:31.876 --> 00:07:33.656
it will basically show freezing

00:07:33.680 --> 00:07:35.941
because it doesn't want to be detected

00:07:35.965 --> 00:07:38.636
by any potential threats in this box.

00:07:38.660 --> 00:07:39.991
SR: So you can think of freezing as,

00:07:40.015 --> 00:07:42.206
you're walking down the street
minding your own business,

00:07:42.230 --> 00:07:44.278
and then out of nowhere
you almost run into

00:07:44.302 --> 00:07:46.123
an ex-girlfriend or ex-boyfriend,

00:07:46.147 --> 00:07:48.257
and now those terrifying two seconds

00:07:48.281 --> 00:07:50.133
where you start thinking, "What do I do?
Do I say hi?

00:07:50.157 --> 00:07:51.501
Do I shake their hand? Do
I turn around and run away?

00:07:51.525 --> 00:07:53.530
Do I sit here and pretend
like I don't exist?"

00:07:53.554 --> 00:07:56.714
Those kinds of fleeting thoughts
that physically incapacitate you,

00:07:56.738 --> 00:07:59.460
that temporarily give you
that deer-in-headlights look.

00:07:59.484 --> 00:08:02.751
XL: However, if you put the mouse
in a completely different

00:08:02.775 --> 00:08:05.912
new box, like the next one,

00:08:05.936 --> 00:08:08.059
it will not be afraid of this box

00:08:08.083 --> 00:08:12.788
because there's no reason that it
will be afraid of this new environment.

00:08:12.812 --> 00:08:15.968
But what if we put
the mouse in this new box

00:08:15.992 --> 00:08:19.579
but at the same time,
we activate the fear memory

00:08:19.603 --> 00:08:22.258
using lasers just like we did before?

00:08:22.282 --> 00:08:25.112
Are we going to bring back the fear memory

00:08:25.136 --> 00:08:29.109
for the first box into this
completely new environment?

00:08:29.133 --> 00:08:31.844
SR: All right,
and here's the million-dollar experiment.

00:08:31.868 --> 00:08:34.757
Now to bring back to life
the memory of that day,

00:08:34.781 --> 00:08:36.940
I remember that the Red Sox had just won,

00:08:36.964 --> 00:08:38.849
it was a green spring day,

00:08:38.873 --> 00:08:40.731
perfect for going up and down the river

00:08:40.755 --> 00:08:43.000
and then maybe going to the North End

00:08:43.024 --> 00:08:45.159
to get some cannolis, #justsaying.

00:08:45.183 --> 00:08:48.261
Now Xu and I, on the other hand,

00:08:48.285 --> 00:08:51.091
were in a completely windowless black room

00:08:51.115 --> 00:08:54.751
not making any ocular movement
that even remotely resembles an eye blink

00:08:54.775 --> 00:08:57.218
because our eyes were fixed
onto a computer screen.

00:08:57.242 --> 00:09:00.195
We were looking at this mouse
here trying to activate a memory

00:09:00.219 --> 00:09:02.078
for the first time using our technique.

00:09:02.102 --> 00:09:04.345
XL: And this is what we saw.

00:09:04.369 --> 00:09:06.547
When we first put the mouse into this box,

00:09:06.571 --> 00:09:09.660
it's exploring, sniffing
around, walking around,

00:09:09.684 --> 00:09:11.349
minding its own business,

00:09:11.373 --> 00:09:13.050
because actually by nature,

00:09:13.074 --> 00:09:15.029
mice are pretty curious animals.

00:09:15.053 --> 00:09:17.651
They want to know, what's going
on in this new box?

00:09:17.675 --> 00:09:19.182
It's interesting.

00:09:19.206 --> 00:09:22.633
But the moment we turned
on the laser, like you see now,

00:09:22.657 --> 00:09:25.665
all of a sudden the mouse
entered this freezing mode.

00:09:25.689 --> 00:09:30.096
It stayed here and tried not
to move any part of its body.

00:09:30.120 --> 00:09:31.724
Clearly it's freezing.

00:09:31.748 --> 00:09:34.307
So indeed, it looks
like we are able to bring back

00:09:34.331 --> 00:09:36.371
the fear memory for the first box

00:09:36.395 --> 00:09:39.738
in this completely new environment.

00:09:39.762 --> 00:09:41.850
While watching this, Steve and I

00:09:41.874 --> 00:09:43.983
are as shocked as the mouse itself.

00:09:44.007 --> 00:09:45.245
(Laughter)

00:09:45.269 --> 00:09:48.552
So after the experiment,
the two of us just left the room

00:09:48.576 --> 00:09:50.305
without saying anything.

00:09:50.329 --> 00:09:53.701
After a kind of long,
awkward period of time,

00:09:53.725 --> 00:09:55.913
Steve broke the silence.

00:09:55.937 --> 00:09:58.254
SR: "Did that just work?"

00:09:58.278 --> 00:10:01.228
XL: "Yes," I said. "Indeed it worked!"

00:10:01.252 --> 00:10:03.345
We're really excited about this.

00:10:03.369 --> 00:10:05.969
And then we published our findings

00:10:05.993 --> 00:10:07.665
in the journal Nature.

00:10:07.689 --> 00:10:10.136
Ever since the publication of our work,

00:10:10.160 --> 00:10:12.551
we've been receiving numerous comments

00:10:12.575 --> 00:10:14.676
from all over the Internet.

00:10:14.700 --> 00:10:18.426
Maybe we can take a look at some of those.

00:10:18.450 --> 00:10:20.883
["OMGGGGG FINALLY... so much more to come, virtual reality, neural manipulation, visual dream emulation...
neural coding, 'writing and re-writing of memories', mental illnesses. Ahhh the future is awesome"]

00:10:20.907 --> 00:10:22.883
SR: So the first thing
that you'll notice is that people

00:10:22.907 --> 00:10:25.786
have really strong opinions
about this kind of work.

00:10:25.810 --> 00:10:28.340
Now I happen to completely
agree with the optimism

00:10:28.364 --> 00:10:29.156
of this first quote,

00:10:29.180 --> 00:10:31.964
because on a scale
of zero to Morgan Freeman's voice,

00:10:31.988 --> 00:10:34.465
it happens to be
one of the most evocative accolades

00:10:34.489 --> 00:10:36.015
that I've heard come our way.

00:10:36.039 --> 00:10:37.833
(Laughter)

00:10:37.857 --> 00:10:39.784
But as you'll see, it's not
the only opinion that's out there.

00:10:39.808 --> 00:10:41.348
["This scares the hell out of me... What if they could do that easily
in humans in a couple of years?! OH MY GOD WE'RE DOOMED"]

00:10:41.372 --> 00:10:43.658
XL: Indeed, if we take
a look at the second one,

00:10:43.682 --> 00:10:45.765
I think we can all agree that it's, meh,

00:10:45.789 --> 00:10:47.748
probably not as positive.

00:10:47.772 --> 00:10:49.933
But this also reminds us that,

00:10:49.957 --> 00:10:52.119
although we are still working with mice,

00:10:52.143 --> 00:10:55.636
it's probably a good idea
to start thinking and discussing

00:10:55.660 --> 00:10:58.627
about the possible ethical ramifications

00:10:58.651 --> 00:11:00.575
of memory control.

00:11:00.599 --> 00:11:02.775
SR: Now, in the spirit of the third quote,

00:11:02.799 --> 00:11:04.749
we want to tell you about a recent
project that we've been

00:11:04.773 --> 00:11:07.345
working on in lab that we've called
Project Inception.

00:11:07.369 --> 00:11:10.588
["They should make a movie about this. Where they plant ideas into peoples minds,
so they can control them for their own personal gain. We'll call it: Inception."]

00:11:10.612 --> 00:11:14.154
So we reasoned that now
that we can reactivate a memory,

00:11:14.178 --> 00:11:17.106
what if we do so but then begin
to tinker with that memory?

00:11:17.130 --> 00:11:20.139
Could we possibly even turn
it into a false memory?

00:11:20.163 --> 00:11:24.238
XL: So all memory
is sophisticated and dynamic,

00:11:24.262 --> 00:11:27.217
but if just for simplicity,
let's imagine memory

00:11:27.241 --> 00:11:28.619
as a movie clip.

00:11:28.643 --> 00:11:31.289
So far what we've told you
is basically we can control

00:11:31.313 --> 00:11:33.220
this "play" button of the clip

00:11:33.244 --> 00:11:37.805
so that we can play this video
clip any time, anywhere.

00:11:37.829 --> 00:11:40.336
But is there a possibility
that we can actually get

00:11:40.360 --> 00:11:43.196
inside the brain and edit this movie clip

00:11:43.220 --> 00:11:46.092
so that we can make it
different from the original?

00:11:46.116 --> 00:11:48.270
Yes we can.

00:11:48.294 --> 00:11:50.485
Turned out that all we need
to do is basically

00:11:50.509 --> 00:11:54.675
reactivate a memory using
lasers just like we did before,

00:11:54.699 --> 00:11:58.114
but at the same time,
if we present new information

00:11:58.138 --> 00:12:02.088
and allow this new information
to incorporate into this old memory,

00:12:02.112 --> 00:12:04.526
this will change the memory.

00:12:04.550 --> 00:12:08.189
It's sort of like making a remix tape.

00:12:08.213 --> 00:12:11.047
SR: So how do we do this?

00:12:11.071 --> 00:12:13.004
Rather than finding a fear
memory in the brain,

00:12:13.028 --> 00:12:14.720
we can start by taking our animals,

00:12:14.744 --> 00:12:17.697
and let's say we put them in a blue
box like this blue box here

00:12:17.721 --> 00:12:20.344
and we find the brain cells
that represent that blue box

00:12:20.368 --> 00:12:22.607
and we trick them to respond
to pulses of light

00:12:22.631 --> 00:12:24.341
exactly like we had said before.

00:12:24.365 --> 00:12:26.465
Now the next day, we can take
our animals and place them

00:12:26.489 --> 00:12:29.164
in a red box that they've never
experienced before.

00:12:29.188 --> 00:12:31.427
We can shoot light
into the brain to reactivate

00:12:31.451 --> 00:12:33.299
the memory of the blue box.

00:12:33.323 --> 00:12:35.043
So what would happen here
if, while the animal

00:12:35.067 --> 00:12:36.972
is recalling the memory of the blue box,

00:12:36.996 --> 00:12:39.580
we gave it a couple of mild foot shocks?

00:12:39.604 --> 00:12:42.273
So here we're trying to artificially
make an association

00:12:42.297 --> 00:12:44.188
between the memory of the blue box

00:12:44.212 --> 00:12:45.691
and the foot shocks themselves.

00:12:45.715 --> 00:12:47.477
We're just trying to connect the two.

00:12:47.501 --> 00:12:49.013
So to test if we had done so,

00:12:49.037 --> 00:12:50.341
we can take our animals once again

00:12:50.365 --> 00:12:52.287
and place them back in the blue box.

00:12:52.311 --> 00:12:55.026
Again, we had just reactivated
the memory of the blue box

00:12:55.050 --> 00:12:57.431
while the animal got a couple
of mild foot shocks,

00:12:57.455 --> 00:12:59.562
and now the animal suddenly freezes.

00:12:59.586 --> 00:13:02.920
It's as though it's recalling being
mildly shocked in this environment

00:13:02.944 --> 00:13:05.766
even though that never actually happened.

00:13:05.790 --> 00:13:07.628
So it formed a false memory,

00:13:07.652 --> 00:13:09.700
because it's falsely
fearing an environment

00:13:09.724 --> 00:13:11.058
where, technically speaking,

00:13:11.082 --> 00:13:13.242
nothing bad actually happened to it.

00:13:13.266 --> 00:13:15.695
XL: So, so far we are only talking about

00:13:15.719 --> 00:13:18.061
this light-controlled "on" switch.

00:13:18.085 --> 00:13:21.349
In fact, we also have
a light-controlled "off" switch,

00:13:21.373 --> 00:13:23.429
and it's very easy to imagine that

00:13:23.453 --> 00:13:25.907
by installing this
light-controlled "off" switch,

00:13:25.931 --> 00:13:31.495
we can also turn off a memory,
any time, anywhere.

00:13:31.519 --> 00:13:33.709
So everything
we've been talking about today

00:13:33.733 --> 00:13:38.386
is based on this philosophically
charged principle of neuroscience

00:13:38.410 --> 00:13:42.504
that the mind, with its seemingly
mysterious properties,

00:13:42.528 --> 00:13:46.149
is actually made of physical
stuff that we can tinker with.

00:13:46.173 --> 00:13:47.624
SR: And for me personally,

00:13:47.648 --> 00:13:49.410
I see a world where we can reactivate

00:13:49.434 --> 00:13:51.321
any kind of memory that we'd like.

00:13:51.345 --> 00:13:54.619
I also see a world where we can
erase unwanted memories.

00:13:54.643 --> 00:13:56.786
Now, I even see a world
where editing memories

00:13:56.810 --> 00:13:58.094
is something of a reality,

00:13:58.118 --> 00:13:59.799
because we're living in a time
where it's possible

00:13:59.823 --> 00:14:02.252
to pluck questions from the tree
of science fiction

00:14:02.276 --> 00:14:04.444
and to ground them
in experimental reality.

00:14:04.468 --> 00:14:06.327
XL: Nowadays, people in the lab

00:14:06.351 --> 00:14:08.713
and people in other
groups all over the world

00:14:08.737 --> 00:14:12.530
are using similar methods
to activate or edit memories,

00:14:12.554 --> 00:14:16.371
whether that's old or new,
positive or negative,

00:14:16.395 --> 00:14:19.043
all sorts of memories so
that we can understand

00:14:19.067 --> 00:14:20.907
how memory works.

00:14:20.931 --> 00:14:22.691
SR: For example, one group in our lab

00:14:22.715 --> 00:14:25.329
was able to find the brain cells
that make up a fear memory

00:14:25.353 --> 00:14:28.104
and converted them into a pleasurable
memory, just like that.

00:14:28.128 --> 00:14:31.271
That's exactly what I mean about editing
these kinds of processes.

00:14:31.295 --> 00:14:33.534
Now one dude in lab
was even able to reactivate

00:14:33.558 --> 00:14:35.479
memories of female mice in male mice,

00:14:35.503 --> 00:14:38.474
which rumor has it
is a pleasurable experience.

00:14:38.498 --> 00:14:42.591
XL: Indeed, we are living
in a very exciting moment

00:14:42.615 --> 00:14:46.396
where science doesn't have
any arbitrary speed limits

00:14:46.420 --> 00:14:49.583
but is only bound by our own imagination.

00:14:49.607 --> 00:14:51.750
SR: And finally, what do
we make of all this?

00:14:51.774 --> 00:14:53.701
How do we push this technology forward?

00:14:53.725 --> 00:14:55.916
These are the questions
that should not remain

00:14:55.940 --> 00:14:57.213
just inside the lab,

00:14:57.237 --> 00:14:59.809
and so one goal of today's talk
was to bring everybody

00:14:59.833 --> 00:15:02.214
up to speed with the kind
of stuff that's possible

00:15:02.238 --> 00:15:03.488
in modern neuroscience,

00:15:03.512 --> 00:15:04.998
but now, just as importantly,

00:15:05.022 --> 00:15:08.330
to actively engage everybody
in this conversation.

00:15:08.354 --> 00:15:11.116
So let's think together as a team
about what this all means

00:15:11.140 --> 00:15:13.133
and where we can and should go from here,

00:15:13.157 --> 00:15:15.231
because Xu and I think we all have

00:15:15.255 --> 00:15:17.767
some really big decisions ahead of us.

00:15:17.791 --> 00:15:18.892
Thank you. XL: Thank you.

00:15:18.916 --> 00:15:20.550
(Applause)

