WEBVTT
Kind: captions
Language: nl

00:00:00.000 --> 00:00:07.000
Vertaald door: Remco van Duijvenvoorde
Nagekeken door: Axel Saffran

00:00:13.160 --> 00:00:15.160
Ik wilde met een oorlogsscene beginnen.

00:00:15.160 --> 00:00:17.160
Er was weinig waarschuwing vooraf.

00:00:17.160 --> 00:00:19.160
De Iraakse opstandeling plaatste een IED,

00:00:19.160 --> 00:00:22.160
een geïmproviseerd explosief,

00:00:22.160 --> 00:00:24.160
zorgvuldig langs de kant van de weg.

00:00:24.160 --> 00:00:28.160
In 2006 waren er meer dan 2.500

00:00:28.160 --> 00:00:31.160
van deze aanvallen per maand,

00:00:31.160 --> 00:00:33.160
en zij waren de belangrijkste oorzaak

00:00:33.160 --> 00:00:35.160
van slachtoffers onder Amerikaanse soldaten

00:00:35.160 --> 00:00:37.160
en Iraakse burgers.

00:00:37.160 --> 00:00:39.160
Het team dat deze IED opspoorde

00:00:39.160 --> 00:00:41.160
heet de EOD -

00:00:41.160 --> 00:00:43.160
'Explosives Ordinance Disposal' - en

00:00:43.160 --> 00:00:45.160
zij zijn de voorhoede in de

00:00:45.160 --> 00:00:48.160
Amerikaanse strijd tegen deze bermbommen.

00:00:48.160 --> 00:00:50.160
Elk EOD team rukt ongeveer

00:00:50.160 --> 00:00:52.160
600 keer per jaar uit,

00:00:52.160 --> 00:00:55.160
ongeveer twee bommen per dag.

00:00:55.160 --> 00:00:57.160
Het beste voorbeeld van hoe waardevol ze zijn

00:00:57.160 --> 00:00:59.160
voor de oorlogsinspanningen, is dat

00:00:59.160 --> 00:01:01.160
de Iraakse opstandelingen een beloning van 50.000 dollar

00:01:01.160 --> 00:01:04.160
uitloven op het hoofd van een EOD soldaat.

00:01:04.160 --> 00:01:06.160
Helaas liep het bij deze oproep

00:01:06.160 --> 00:01:08.160
niet goed af.

00:01:08.160 --> 00:01:10.160
Tegen de tijd dat de soldaat dichtbij

00:01:10.160 --> 00:01:12.160
genoeg was om de bedrading te zien,

00:01:12.160 --> 00:01:15.160
explodeerde deze in een bal van vuur.

00:01:15.160 --> 00:01:17.160
Afhankelijk van de afstand

00:01:17.160 --> 00:01:19.160
en de gebruikte hoeveelheid explosief materiaal

00:01:19.160 --> 00:01:21.160
kan het de dood veroorzaken

00:01:21.160 --> 00:01:23.160
of verwonding. Je moet minstens

00:01:23.160 --> 00:01:25.160
45 meter afstand hebben om dat te voorkomen.

00:01:25.160 --> 00:01:27.160
De explosie kan zelfs je botten breken,

00:01:27.160 --> 00:01:29.160
ook al word je niet geraakt.

00:01:29.160 --> 00:01:31.160
De soldaat zat boven de bom.

00:01:31.160 --> 00:01:34.160
Toen de rest van het team ter plaatse kwam,

00:01:34.160 --> 00:01:36.160
waren er weinig restanten. Die avond had

00:01:36.160 --> 00:01:38.160
de commandant de droevige plicht een

00:01:38.160 --> 00:01:40.160
condoleancebrief naar de Verenigde Staten

00:01:40.160 --> 00:01:42.160
te sturen. Hij schreef hoe hard het verlies

00:01:42.160 --> 00:01:44.160
aankwam bij zijn eenheid, over het feit

00:01:44.160 --> 00:01:46.160
dat ze hun dapperste soldaat verloren.

00:01:46.160 --> 00:01:48.160
Een soldaat die hun leven gered had,

00:01:48.160 --> 00:01:50.160
meer dan eens.

00:01:50.160 --> 00:01:52.160
Hij verontschuldigde zich,

00:01:52.160 --> 00:01:54.160
dat hij hem niet naar huis kon brengen.

00:01:54.160 --> 00:01:56.160
Daarna sprak hij over het zilveren randje

00:01:56.160 --> 00:01:58.160
dat hij zag in het verlies.

00:01:58.160 --> 00:02:00.160
"Gelukkig," schreef hij, "als een robot sterft,

00:02:00.160 --> 00:02:02.160
hoef je tenminste geen brief te schrijven

00:02:02.160 --> 00:02:04.160
aan zijn moeder."

00:02:04.160 --> 00:02:06.160
Dit klinkt als sciencefiction,

00:02:06.160 --> 00:02:08.160
maar het is al realiteit op het slagveld.

00:02:08.160 --> 00:02:11.160
In dit geval was de soldaat

00:02:11.160 --> 00:02:14.160
een 19 kilo zware robot, een 'Packbot'.

00:02:14.160 --> 00:02:17.160
De brief van de commandant ging niet

00:02:17.160 --> 00:02:19.160
naar een boerderij in Iowa,

00:02:19.160 --> 00:02:22.160
als in een oude oorlogsfilm,

00:02:22.160 --> 00:02:24.160
maar naar de iRobot Company,

00:02:24.160 --> 00:02:27.160
genaamd naar de roman van Asimov,

00:02:27.160 --> 00:02:29.160
en de niet zo fantastische film met Will Smith,

00:02:29.160 --> 00:02:31.160
en... eeh... (Gelach)...

00:02:31.160 --> 00:02:33.160
Als je je realiseert

00:02:33.160 --> 00:02:35.160
dat in die fictieve wereld, robots begonnen

00:02:35.160 --> 00:02:37.160
met alledaagse klusjes, waarna ze beslissingen

00:02:37.160 --> 00:02:39.160
over leven en dood begonnen te nemen.

00:02:39.160 --> 00:02:41.160
Dat is de realiteit van vandaag.

00:02:41.160 --> 00:02:43.160
We gaan nu achter mij

00:02:43.160 --> 00:02:45.160
een fotoserie tonen van robots

00:02:45.160 --> 00:02:48.160
die nu worden gebruikt in oorlogvoering,

00:02:48.160 --> 00:02:50.160
of die al in de prototypefase zijn.

00:02:50.160 --> 00:02:53.160
Het is om je alvast een voorproefje te geven.

00:02:53.160 --> 00:02:55.160
Anders gezegd, je zult niets zien

00:02:55.160 --> 00:02:57.160
dat wordt aangedreven

00:02:57.160 --> 00:02:59.160
door Vulcan-technologie,

00:02:59.160 --> 00:03:01.160
of door hormonen van slimme tieners, of iets dergelijks.

00:03:01.160 --> 00:03:03.160
DIt is allemaal echt.

00:03:03.160 --> 00:03:05.160
Dus laten we beginnen met de foto's.

00:03:05.160 --> 00:03:07.160
Er is iets belangrijks aan de gang in de oorlogvoering

00:03:07.160 --> 00:03:09.160
en misschien wel in de geschiedenis van de mensheid.

00:03:09.160 --> 00:03:12.160
Het Amerikaanse leger ging naar Irak

00:03:12.160 --> 00:03:14.160
met een handjevol onbemande toestellen in de lucht.

00:03:14.160 --> 00:03:17.160
Dat zijn er nu 5.300.

00:03:17.160 --> 00:03:19.160
We zijn gegaan met nul onbemande grondsystemen.

00:03:19.160 --> 00:03:23.160
Dat zijn er nu 12.000.

00:03:23.160 --> 00:03:25.160
En de technische term 'killer application'

00:03:25.160 --> 00:03:28.160
krijgt in dit verband een nieuwe betekenis.

00:03:28.160 --> 00:03:30.160
Onthoud hierbij dat we nu praten

00:03:30.160 --> 00:03:32.160
over de T-Fordjes,

00:03:32.160 --> 00:03:34.160
de Wright Flyers,

00:03:34.160 --> 00:03:36.160
vergeleken met wat er binnenkort aankomt.

00:03:36.160 --> 00:03:38.160
Zo staan we er nu voor.

00:03:38.160 --> 00:03:40.160
Onlangs ontmoette ik

00:03:40.160 --> 00:03:42.160
een driesterrengeneraal van de Luchtmacht

00:03:42.160 --> 00:03:44.160
en hij zei: "Waar het binnenkort heen gaat

00:03:44.160 --> 00:03:46.160
is dat tienduizenden robots

00:03:46.160 --> 00:03:48.160
worden ingezet bij onze conflicten."

00:03:48.160 --> 00:03:50.160
Deze getallen doen ertoe, omdat we niet alleen

00:03:50.160 --> 00:03:52.160
praten over de tienduizenden robots van vandaag,

00:03:52.160 --> 00:03:54.160
maar over tienduizenden van deze prototypes,

00:03:54.160 --> 00:03:56.160
en de robots van morgen.

00:03:56.160 --> 00:03:59.160
Want een van de wetten die opgaat

00:03:59.160 --> 00:04:01.160
voor de technologie, is de wet van Moore,

00:04:01.160 --> 00:04:03.160
waardoor steeds meer

00:04:03.160 --> 00:04:05.160
rekencapaciteit in die robots past.

00:04:05.160 --> 00:04:07.160
Als je 25 jaar vooruitspoelt,

00:04:07.160 --> 00:04:09.160
en de wet van Moore blijkt correct,

00:04:09.160 --> 00:04:12.160
dan zullen die robots bijna een miljard keer

00:04:12.160 --> 00:04:15.160
meer rekenkracht hebben dan vandaag,

00:04:15.160 --> 00:04:17.160
Dat betekent dat dingen waarover

00:04:17.160 --> 00:04:19.160
we vroeger alleen praatten

00:04:19.160 --> 00:04:21.160
tijdens sciencefiction-congressen zoals Comic-Con

00:04:21.160 --> 00:04:23.160
besproken moeten worden in de machtscentra

00:04:23.160 --> 00:04:25.160
en plaatsen als het Pentagon.

00:04:25.160 --> 00:04:28.160
Er staat ons een robotrevolutie te wachten.

00:04:28.160 --> 00:04:30.160
Laat me duidelijk zijn.

00:04:30.160 --> 00:04:32.160
Het is geen revolutie

00:04:32.160 --> 00:04:34.160
waarbij je je zorgen moet maken dat de gouverneur

00:04:34.160 --> 00:04:36.160
van Californië voor je deur staat,

00:04:36.160 --> 00:04:38.160
à la de Terminator. (Gelach)

00:04:38.160 --> 00:04:40.160
Historici die op deze periode terugkijken,

00:04:40.160 --> 00:04:42.160
zullen concluderen dat dit een ander

00:04:42.160 --> 00:04:44.160
type revolutie is, een revolutie in oorlogvoering.

00:04:44.160 --> 00:04:46.160
Net als de uitvinding van de atoombom.

00:04:46.160 --> 00:04:48.160
Misschien zelfs groter,

00:04:48.160 --> 00:04:50.160
omdat onze onbemande systemen niet alleen

00:04:50.160 --> 00:04:52.160
het 'hoe' van de oorlogvoering beïnvloeden,

00:04:52.160 --> 00:04:54.160
ze beïnvloeden het 'wie' van het vechten

00:04:54.160 --> 00:04:56.160
op het meest fundamentele niveau.

00:04:56.160 --> 00:04:58.160
Iedere voorgaande revolutie in oorlog

00:04:58.160 --> 00:05:00.160
bijvoorbeeld het machinegeweer of de atoombom

00:05:00.160 --> 00:05:03.160
ging over een systeem dat of sneller schoot,

00:05:03.160 --> 00:05:06.160
of verder ging, of een grotere knal gaf.

00:05:06.160 --> 00:05:09.160
Dat is zeker het geval in robotica, maar

00:05:09.160 --> 00:05:12.160
het verandert ook de ervaring van de militair

00:05:12.160 --> 00:05:15.160
en zelfs de kern van de identiteit van de militair.

00:05:15.160 --> 00:05:18.160
Op een andere manier gezegd:

00:05:18.160 --> 00:05:20.160
het 5.000 jaar oude monopolie van de mens

00:05:20.160 --> 00:05:23.160
op het vechten in een oorlog,

00:05:23.160 --> 00:05:25.160
zal nog in onze tijd verloren gaan.

00:05:25.160 --> 00:05:27.160
Ik ben de laatste paar jaar bezig geweest

00:05:27.160 --> 00:05:29.160
om alle spelers in dit veld te ontmoeten,

00:05:29.160 --> 00:05:31.160
van de robotwetenschappers

00:05:31.160 --> 00:05:33.160
tot de sciencefiction-schrijvers die hen inspireerden,

00:05:33.160 --> 00:05:35.160
tot de 19-jarige piloten van onbemande toestellen,

00:05:35.160 --> 00:05:37.160
die vanuit Nevada vechten, tot de viersterrengeneraals

00:05:37.160 --> 00:05:39.160
en zelfs de Iraakse opstandelingen

00:05:39.160 --> 00:05:41.160
die het doelwit zijn,

00:05:41.160 --> 00:05:43.160
en wat zij van deze systemen denken.

00:05:43.160 --> 00:05:45.160
Wat ik interessant vond, waren niet alleen

00:05:45.160 --> 00:05:47.160
hun verhalen, maar hoe hun ervaringen wijzen op

00:05:47.160 --> 00:05:49.160
uitwaaiereffecten die zich

00:05:49.160 --> 00:05:51.160
uitbreiden in onze samenleving, in onze wetten,

00:05:51.160 --> 00:05:53.160
en in onze ethiek.

00:05:53.160 --> 00:05:55.160
In de de resterende tijd

00:05:55.160 --> 00:05:57.160
wil ik hier gedetailleerder op ingaan.

00:05:57.160 --> 00:05:59.160
Allereerst zal de toekomst van oorlogvoering,

00:05:59.160 --> 00:06:01.160
ook die op basis van robotica, niet een puur

00:06:01.160 --> 00:06:03.160
Amerikaanse aangelegenheid zijn.

00:06:03.160 --> 00:06:05.160
De V.S. lopen nu voor

00:06:05.160 --> 00:06:07.160
in militaire robotica, maar we weten dat er in

00:06:07.160 --> 00:06:09.160
de technologie niet iets bestaat als

00:06:09.160 --> 00:06:12.160
een permanente eerste stap of voordeel.

00:06:12.160 --> 00:06:14.160
Even snel de hand opsteken: hoeveel

00:06:14.160 --> 00:06:16.160
mensen in deze zaal gebruiken nog steeds

00:06:16.160 --> 00:06:18.160
Wang computers? (Gelach)

00:06:18.160 --> 00:06:20.160
Het is hetzelfde in oorlogvoering. De Britten

00:06:20.160 --> 00:06:23.160
en de Fransen vonden de tank uit.

00:06:23.160 --> 00:06:25.160
De Duitsers wisten hoe ze die

00:06:25.160 --> 00:06:27.160
moesten gebruiken. Waar we

00:06:27.160 --> 00:06:29.160
aan moeten denken voor de V.S. is dat we

00:06:29.160 --> 00:06:31.160
nu een voorsprong hebben, maar dat er

00:06:31.160 --> 00:06:33.160
43 andere landen zijn

00:06:33.160 --> 00:06:35.160
die werken aan militaire robotica. Daar zitten

00:06:35.160 --> 00:06:37.160
interessante landen bij als

00:06:37.160 --> 00:06:40.160
Rusland, China, Pakistan, Iran.

00:06:40.160 --> 00:06:43.160
Daarover maak ik me meer zorgen.

00:06:43.160 --> 00:06:45.160
Hoe ontwikkelen we ons in deze revolutie,

00:06:45.160 --> 00:06:47.160
gezien het niveau van onze productie,

00:06:47.160 --> 00:06:49.160
het niveau van onze wetenschap en

00:06:49.160 --> 00:06:51.160
wiskundig onderwijs in onze scholen?

00:06:51.160 --> 00:06:53.160
Of anders benaderd:

00:06:53.160 --> 00:06:55.160
wat betekent het als de hardware

00:06:55.160 --> 00:06:58.160
van je soldaten in toenemende mate

00:06:58.160 --> 00:07:03.160
uit China komt en software uit India?

00:07:03.160 --> 00:07:06.160
Maar evenzeer als software open source werd,

00:07:06.160 --> 00:07:08.160
werd oorlogvoering dat ook.

00:07:08.160 --> 00:07:11.160
In tegenstelling tot een vliegdekschip of een atoombom

00:07:11.160 --> 00:07:13.160
is er geen omvangrijk productiesysteem nodig

00:07:13.160 --> 00:07:15.160
om robots te bouwen. Veel ervan is

00:07:15.160 --> 00:07:17.160
uit voorraad verkrijgbaar. Veel is zelfs doe-het-zelf.

00:07:17.160 --> 00:07:19.160
Wat je net voorbij zag komen

00:07:19.160 --> 00:07:21.160
was een onbemand Raventoestel, uit de hand

00:07:21.160 --> 00:07:23.160
te lanceren. Voor ongeveer 1.000 dollar

00:07:23.160 --> 00:07:25.160
kunt er zelf eentje bouwen, gelijkwaardig

00:07:25.160 --> 00:07:27.160
aan wat de soldaten in Irak gebruiken.

00:07:27.160 --> 00:07:29.160
Dat werpt een volgende vraag op

00:07:29.160 --> 00:07:31.160
over oorlog en conflict. Goeie lui spelen

00:07:31.160 --> 00:07:33.160
er een beetje mee als met een bouwdoos,

00:07:33.160 --> 00:07:35.160
maar kwaadwillenden wellicht ook.

00:07:35.160 --> 00:07:37.160
Dit kruispunt tussen robotica en zaken als

00:07:37.160 --> 00:07:39.160
terrorisme zal fascinerend worden

00:07:39.160 --> 00:07:41.160
en zelfs zorgwekkend.

00:07:41.160 --> 00:07:43.160
We hebben het begin al gezien.

00:07:43.160 --> 00:07:45.160
In de oorlog tussen Israël, een staat,

00:07:45.160 --> 00:07:48.160
en Hezbollah, een niet-statelijke actor,

00:07:48.160 --> 00:07:50.160
stuurde de niet-statelijke actor

00:07:50.160 --> 00:07:52.160
vier onbemande toestellen naar Israël.

00:07:52.160 --> 00:07:54.160
Er is al een Jihadi-website

00:07:54.160 --> 00:07:56.160
waar je op afstand

00:07:56.160 --> 00:07:58.160
een geïmproviseerd explosief kunt laten detoneren,

00:07:58.160 --> 00:08:00.160
gewoon thuis vanachter je computer.

00:08:00.160 --> 00:08:02.160
Wat we volgens mij gaan zien

00:08:02.160 --> 00:08:04.160
zijn twee trends.

00:08:04.160 --> 00:08:06.160
Als eerste zul je de macht versterken

00:08:06.160 --> 00:08:10.160
van individuen tegen regeringen.

00:08:10.160 --> 00:08:12.160
Als tweede zullen we een

00:08:12.160 --> 00:08:14.160
uitbreiding zien van

00:08:14.160 --> 00:08:16.160
het bereik van terrorisme.

00:08:16.160 --> 00:08:18.160
In de toekomst kan dat een kruising zijn

00:08:18.160 --> 00:08:20.160
tussen Al Qaida 2.0 en de

00:08:20.160 --> 00:08:22.160
volgende generatie van de Unabomber.

00:08:22.160 --> 00:08:24.160
Een andere manier om hier tegenaan te kijken,

00:08:24.160 --> 00:08:26.160
is het feit dat je een robot er niet van hoeft

00:08:26.160 --> 00:08:28.160
te overtuigen dat hij na zijn dood

00:08:28.160 --> 00:08:31.160
72 maagden krijgt om hem

00:08:31.160 --> 00:08:34.160
over te halen zichzelf op te blazen.

00:08:34.160 --> 00:08:36.160
De uitwaaiereffecten hiervan zullen

00:08:36.160 --> 00:08:38.160
onze politiek beïnvloeden. Eén van de mensen

00:08:38.160 --> 00:08:40.160
die ik ontmoette was een voormalig adjunct-secretaris

00:08:40.160 --> 00:08:42.160
van Ronald Reagan. Hij zei het zo:

00:08:42.160 --> 00:08:44.160
"Ik vind die systemen mooi omdat

00:08:44.160 --> 00:08:46.160
ze Amerikaanse levens sparen, maar ik maak me zorgen

00:08:46.160 --> 00:08:48.160
over de vermarkting van oorlogen,

00:08:48.160 --> 00:08:51.160
meer krachttaal die afleidt

00:08:51.160 --> 00:08:53.160
van de kostendiscussie.

00:08:53.160 --> 00:08:55.160
Mensen zullen eerder het gebruik van geweld

00:08:55.160 --> 00:08:58.160
ondersteunen als ze het als 'zonder kosten' beschouwen."

00:08:58.160 --> 00:09:00.160
Robots belichamen trends

00:09:00.160 --> 00:09:03.160
die al aan de gang zijn in onze politiek.

00:09:03.160 --> 00:09:05.160
Misschien brengen ze het

00:09:05.160 --> 00:09:07.160
naar het logische eindpunt.

00:09:07.160 --> 00:09:09.160
We hebben geen dienstplicht. We hebben

00:09:09.160 --> 00:09:12.160
geen oorlogsverklaringen meer.

00:09:12.160 --> 00:09:14.160
We kopen geen oorlogsobligaties meer.

00:09:14.160 --> 00:09:16.160
Feit is nu, dat we onze Amerikaanse soldaten,

00:09:16.160 --> 00:09:18.160
die we anders in gevaar zouden brengen,

00:09:18.160 --> 00:09:20.160
steeds meer vervangen

00:09:20.160 --> 00:09:23.160
door machines en we stappen zo over die

00:09:23.160 --> 00:09:26.160
toch al lage drempel

00:09:26.160 --> 00:09:29.160
van oorlogvoeren heen.

00:09:29.160 --> 00:09:31.160
De toekomst van oorlogvoering zal ook

00:09:31.160 --> 00:09:33.160
een YouTube-oorlog worden.

00:09:33.160 --> 00:09:35.160
Onze nieuwe technologieën houden mensen

00:09:35.160 --> 00:09:37.160
niet alleen uit de buurt van risico's.

00:09:37.160 --> 00:09:40.160
Ze nemen ook alles op wat ze zien.

00:09:40.160 --> 00:09:43.160
Ze verbreken de link met het volk niet alleen,

00:09:43.160 --> 00:09:46.160
ze transformeren diens relatie met oorlog.

00:09:46.160 --> 00:09:48.160
Er zijn nu al enige duizenden

00:09:48.160 --> 00:09:50.160
videoclips met beeldmateriaal van de strijd

00:09:50.160 --> 00:09:52.160
in Irak op YouTube,

00:09:52.160 --> 00:09:54.160
de meeste opgenomen met onbemande toestellen.

00:09:54.160 --> 00:09:56.160
Het kan een voordeel zijn.

00:09:56.160 --> 00:09:58.160
Het kan het thuisfront en het oorlogsfront

00:09:58.160 --> 00:10:00.160
met elkaar verbinden

00:10:00.160 --> 00:10:02.160
als nooit tevoren.

00:10:02.160 --> 00:10:04.160
Maar bedenk dat dit plaatsvindt

00:10:04.160 --> 00:10:07.160
in onze vreemde, gekke wereld.

00:10:07.160 --> 00:10:09.160
Onvermijdelijk is, dat de mogelijkheid

00:10:09.160 --> 00:10:11.160
deze clips te downloaden naar je iPod,

00:10:11.160 --> 00:10:14.160
of je Zune, je de mogelijkheid

00:10:14.160 --> 00:10:18.160
geeft het in entertainment te veranderen.

00:10:18.160 --> 00:10:20.160
Soldaten hebben een naam voor dit soort clips.

00:10:20.160 --> 00:10:22.160
Ze noemen het oorlogsporno.

00:10:22.160 --> 00:10:24.160
Een typisch voorbeeld kreeg ik per email.

00:10:24.160 --> 00:10:26.160
Bijgevoegd zat een video

00:10:26.160 --> 00:10:28.160
van een Predatoraanval die een

00:10:28.160 --> 00:10:30.160
vijandelijke stelling vernietigde. Raketinslagen,

00:10:30.160 --> 00:10:33.160
lichamen die door explosies de lucht invlogen.

00:10:33.160 --> 00:10:35.160
Er was muziek onder gezet.

00:10:35.160 --> 00:10:37.160
Het nummer was

00:10:37.160 --> 00:10:40.160
"I Just Want to Fly" van Sugar Ray.

00:10:40.160 --> 00:10:43.160
Deze mogelijkheid om meer te zien

00:10:43.160 --> 00:10:46.160
maar minder te voelen, creëert een oneffenheid

00:10:46.160 --> 00:10:48.160
bij het publiek in relatie tot oorlog.

00:10:48.160 --> 00:10:50.160
Ik denk hierbij analoog aan sport.

00:10:50.160 --> 00:10:53.160
Hetzelfde verschil ontstaat

00:10:53.160 --> 00:10:56.160
als je kijkt naar een NBA-wedstrijd, professioneel

00:10:56.160 --> 00:10:59.160
basketball, op TV, waar de sporters

00:10:59.160 --> 00:11:01.160
kleine figuurtjes op het scherm zijn,

00:11:01.160 --> 00:11:04.160
of zelf aanwezig zijn bij de wedstrijd,

00:11:04.160 --> 00:11:06.160
waarbij je je realiseert hoe iemand van 2,10 meter

00:11:06.160 --> 00:11:08.160
er echt uitziet.

00:11:08.160 --> 00:11:10.160
We moeten onthouden

00:11:10.160 --> 00:11:12.160
dat dit maar de clips zijn.

00:11:12.160 --> 00:11:14.160
Dit zijn maar de Studio Sport-samenvattingen

00:11:14.160 --> 00:11:16.160
van de wedstrijd.

00:11:16.160 --> 00:11:18.160
Ze verliezen de strategie.

00:11:18.160 --> 00:11:20.160
Ze verliezen de menselijkheid.

00:11:20.160 --> 00:11:23.160
Oorlog verwordt tot doelpunten en slimme bommen.

00:11:23.160 --> 00:11:26.160
De ironie van dit alles is dat,

00:11:26.160 --> 00:11:28.160
terwijl de toekomst van oorlogvoering

00:11:28.160 --> 00:11:30.160
steeds meer over machines gaat,

00:11:30.160 --> 00:11:32.160
onze menselijke psychologie achter

00:11:32.160 --> 00:11:34.160
dit alles zit. Onze menselijke tekortkomingen

00:11:34.160 --> 00:11:36.160
leiden tot deze oorlogen.

00:11:36.160 --> 00:11:38.160
Een voorbeeld hiervan, dat

00:11:38.160 --> 00:11:40.160
veel weerklank vindt bij beleidsmakers,

00:11:40.160 --> 00:11:42.160
is hoe dit uitwerkt op onze zeer reële

00:11:42.160 --> 00:11:44.160
oorlog van ideeën die we uitvechten

00:11:44.160 --> 00:11:46.160
met radicale groepen.

00:11:46.160 --> 00:11:48.160
Welke boodschap denken we uit te zenden

00:11:48.160 --> 00:11:50.160
met deze machines, versus de boodschap

00:11:50.160 --> 00:11:53.160
die aan de andere kant wordt ontvangen.

00:11:53.160 --> 00:11:55.160
Een van de mensen die ik ontmoette,

00:11:55.160 --> 00:11:57.160
een hoge functionaris uit de regering Bush,

00:11:57.160 --> 00:11:59.160
zei het volgende over

00:11:59.160 --> 00:12:01.160
onze onbemanning van de oorlog:

00:12:01.160 --> 00:12:03.160
"Het versterkt onze kracht. Waar mensen

00:12:03.160 --> 00:12:05.160
bang voor zijn, is onze technologie."

00:12:05.160 --> 00:12:07.160
Als je er op uittrekt en mensen ontmoet,

00:12:07.160 --> 00:12:09.160
bijvoorbeeld in Libanon, is dat

00:12:09.160 --> 00:12:11.160
een heel ander verhaal. Een van de mensen

00:12:11.160 --> 00:12:13.160
die ik ontmoette was nieuwsredacteur.

00:12:13.160 --> 00:12:15.160
We praatten terwijl een onbemand toestel overvloog.

00:12:15.160 --> 00:12:17.160
Dit is wat hij te zeggen had:

00:12:17.160 --> 00:12:19.160
"Dit is het zoveelste teken van koude mensen,

00:12:19.160 --> 00:12:22.160
wrede Israëli's en Amerikanen.

00:12:22.160 --> 00:12:24.160
Het zijn lafaards omdat

00:12:24.160 --> 00:12:26.160
ze machines sturen om tegen ons te vechten.

00:12:26.160 --> 00:12:28.160
Ze willen niet als echte mannen tegen ons vechten,

00:12:28.160 --> 00:12:30.160
want ze zijn bang om te vechten,

00:12:30.160 --> 00:12:32.160
dus moeten we gewoon een paar van hun soldaten doden

00:12:32.160 --> 00:12:35.160
om ze te verslaan."

00:12:35.160 --> 00:12:37.160
De toekomst van de oorlog wordt gekenmerkt

00:12:37.160 --> 00:12:39.160
door een nieuw type militair.

00:12:39.160 --> 00:12:42.160
Het herdefinieert de beleving van

00:12:42.160 --> 00:12:44.160
ten strijde trekken.

00:12:44.160 --> 00:12:46.160
Je kunt dit de werkplekkrijger noemen.

00:12:46.160 --> 00:12:48.160
Een Predatorpiloot omschreef

00:12:48.160 --> 00:12:50.160
zijn ervaring van het vechten

00:12:50.160 --> 00:12:53.160
in de oorlog met Irak, terwijl hij nooit buiten Nevada kwam:

00:12:53.160 --> 00:12:55.160
"Je gaat 12 uur vechten,

00:12:55.160 --> 00:12:57.160
beschiet doelen met wapens,

00:12:57.160 --> 00:13:00.160
doodt vijandelijke strijders.

00:13:00.160 --> 00:13:02.160
Dan stap je in je auto,

00:13:02.160 --> 00:13:04.160
rijdt naar huis en binnen 20 minuten

00:13:04.160 --> 00:13:06.160
zit je aan de eettafel

00:13:06.160 --> 00:13:08.160
met je kinderen over hun huiswerk te praten."

00:13:08.160 --> 00:13:10.160
Het psychologisch balanceren

00:13:10.160 --> 00:13:12.160
van deze ervaringen is ontzettend moeilijk.

00:13:12.160 --> 00:13:15.160
Veel van deze piloten hebben

00:13:15.160 --> 00:13:17.160
méér last van posttraumatische stress

00:13:17.160 --> 00:13:20.160
dan eenheden die fysiek aanwezig waren in Irak.

00:13:20.160 --> 00:13:22.160
Sommigen maken zich zorgen dat

00:13:22.160 --> 00:13:24.160
deze loskoppeling tot iets anders leidt.

00:13:24.160 --> 00:13:26.160
Dat het de bereidheid tot oorlogsmisdaden

00:13:26.160 --> 00:13:28.160
veel gemakkelijker maakt.

00:13:28.160 --> 00:13:30.160
"Het is net een videospelletje",

00:13:30.160 --> 00:13:32.160
is hoe een jonge piloot omschreef

00:13:32.160 --> 00:13:34.160
hoe hij op afstand troepen elimineerde.

00:13:34.160 --> 00:13:37.160
Iedereen die Grand Theft Auto gespeeld heeft

00:13:37.160 --> 00:13:40.160
weet dat we in een virtuele wereld dingen doen,

00:13:40.160 --> 00:13:43.160
die we in het echt niet zouden doen.

00:13:43.160 --> 00:13:45.160
Veel van wat jullie van mij horen,

00:13:45.160 --> 00:13:47.160
gaat over de andere kant

00:13:47.160 --> 00:13:49.160
van technologische revoluties.

00:13:49.160 --> 00:13:51.160
Het vormt ons heden en wellicht

00:13:51.160 --> 00:13:54.160
onze toekomstige oorlogvoering.

00:13:54.160 --> 00:13:56.160
De Wet van Moore is van toepassing,

00:13:56.160 --> 00:13:58.160
maar ook de Wet van Murphy.

00:13:58.160 --> 00:14:00.160
De oorlogsmist trekt niet op.

00:14:00.160 --> 00:14:02.160
De vijand heeft een stem.

00:14:02.160 --> 00:14:04.160
We krijgen ongelofelijke, nieuwe mogelijkheden.

00:14:04.160 --> 00:14:06.160
We zien en ervaren ook

00:14:06.160 --> 00:14:08.160
nieuwe menselijke dilemma's.

00:14:08.160 --> 00:14:10.160
Soms zijn het gewoon "oops"-momenten.

00:14:10.160 --> 00:14:12.160
Zo omschreef het hoofd van een roboticabedrijf het.

00:14:12.160 --> 00:14:14.160
Het zijn gewoon

00:14:14.160 --> 00:14:16.160
"oops"-momenten. Wat zijn

00:14:16.160 --> 00:14:18.160
"oops"-momenten bij oorlogsrobots?

00:14:18.160 --> 00:14:20.160
Soms zijn ze best grappig.

00:14:20.160 --> 00:14:22.160
Soms zijn ze net als die scene uit

00:14:22.160 --> 00:14:24.160
de film met Eddy Murphy, "Best Defense",

00:14:24.160 --> 00:14:26.160
waarin ze een robot met een

00:14:26.160 --> 00:14:28.160
machinegeweer testten.

00:14:28.160 --> 00:14:30.160
Tijdens de demonstratie begon hij rond te draaien

00:14:30.160 --> 00:14:33.160
en richtte het machinegeweer

00:14:33.160 --> 00:14:36.160
op de tribune met de VIP's.

00:14:36.160 --> 00:14:38.160
Gelukkig was het wapen niet geladen

00:14:38.160 --> 00:14:40.160
en raakte niemand gewond.

00:14:40.160 --> 00:14:42.160
Andere "oops"-momenten zijn tragisch,

00:14:42.160 --> 00:14:44.160
zoals afgelopen jaar in Zuid Afrika,

00:14:44.160 --> 00:14:47.160
waar een anti-vliegtuigkanon een

00:14:47.160 --> 00:14:50.160
"softwarefoutje" had, inschakelde

00:14:50.160 --> 00:14:53.160
en vuurde, waarbij negen soldaten omkwamen.

00:14:53.160 --> 00:14:56.160
Er zijn problemen met de regels van oorlogvoering

00:14:56.160 --> 00:14:58.160
en verantwoording. Wat doen we

00:14:58.160 --> 00:15:00.160
met zaken als onbemande doodslag?

00:15:00.160 --> 00:15:02.160
Wat is onbemande doodslag?

00:15:02.160 --> 00:15:04.160
Er zijn al drie voorbeelden van

00:15:04.160 --> 00:15:06.160
Predatoraanvallen, waarbij we dachten

00:15:06.160 --> 00:15:08.160
dat we Bin Laden hadden, maar

00:15:08.160 --> 00:15:10.160
dat bleek niet zo te zijn.

00:15:10.160 --> 00:15:12.160
Daar staan we nu.

00:15:12.160 --> 00:15:14.160
Ik heb het niet eens over gewapende,

00:15:14.160 --> 00:15:16.160
autonome systemen,

00:15:16.160 --> 00:15:18.160
met het gezag om geweld te gebruiken.

00:15:18.160 --> 00:15:20.160
En geloof maar, dat dat er aan zit te komen.

00:15:20.160 --> 00:15:22.160
Tijdens mijn onderzoek kwam ik

00:15:22.160 --> 00:15:24.160
vier verschillende Pentagonprojecten tegen

00:15:24.160 --> 00:15:26.160
over verschillende aspecten hiervan.

00:15:26.160 --> 00:15:28.160
Nu rijst de vraag:

00:15:28.160 --> 00:15:30.160
"Waar leidt dit toe in kwesties rond

00:15:30.160 --> 00:15:32.160
oorlogsmisdaden?" Robots hebben geen emotie,

00:15:32.160 --> 00:15:35.160
ze raken niet van streek als hun maat wordt gedood.

00:15:35.160 --> 00:15:37.160
Ze plegen geen misdaden uit woede

00:15:37.160 --> 00:15:39.160
en wraak.

00:15:39.160 --> 00:15:42.160
Maar, robots hebben geen emotie.

00:15:42.160 --> 00:15:44.160
Ze zien een tachtigjarige oma

00:15:44.160 --> 00:15:46.160
in een rolstoel op dezelfde manier als

00:15:46.160 --> 00:15:49.160
ze een T-80 tank zien: het zijn beide

00:15:49.160 --> 00:15:52.160
slechts een serie enen en nullen.

00:15:52.160 --> 00:15:55.160
We moeten een antwoord vinden op de vraag:

00:15:55.160 --> 00:15:57.160
"Hoe maken we onze 20e-eeuwse wetten

00:15:57.160 --> 00:15:59.160
die nu zo oud zijn

00:15:59.160 --> 00:16:02.160
dat ze voor pensioen in aanmerking komen,

00:16:02.160 --> 00:16:05.160
geschikt voor deze 21e-eeuwse technologie?"

00:16:05.160 --> 00:16:08.160
Tenslotte: ik heb gesproken over

00:16:08.160 --> 00:16:11.160
wat de toekomst van oorlog lijkt te zijn.

00:16:11.160 --> 00:16:13.160
Let wel: ik heb alleen

00:16:13.160 --> 00:16:15.160
echte voorbeelden gebruikt. Jullie hebben alleen

00:16:15.160 --> 00:16:17.160
echte beelden en video's gezien.

00:16:17.160 --> 00:16:19.160
Hier ligt een grote uitdaging

00:16:19.160 --> 00:16:21.160
die ons allemaal zorgen moet baren

00:16:21.160 --> 00:16:23.160
ruim voordat we ons er zorgen over maken,

00:16:23.160 --> 00:16:25.160
dat onze Roomba het leven uit ons wegzuigt.

00:16:25.160 --> 00:16:27.160
Laten we het sciencefiction-gehalte

00:16:27.160 --> 00:16:30.160
van wat zich nu in oorlogvoering ontvouwt,

00:16:30.160 --> 00:16:33.160
als excuus dienen om te

00:16:33.160 --> 00:16:35.160
kunnen blijven ontkennen?

00:16:35.160 --> 00:16:37.160
Of gaan we de werkelijkheid onder ogen zien

00:16:37.160 --> 00:16:39.160
van de 21e-eeuwse oorlog?

00:16:39.160 --> 00:16:41.160
Zal onze huidige generatie dezelfde

00:16:41.160 --> 00:16:43.160
fout maken als de vorige

00:16:43.160 --> 00:16:45.160
met atoomwapens en niets doen

00:16:45.160 --> 00:16:47.160
aan de problemen die eromheen hangen

00:16:47.160 --> 00:16:49.160
tot de doos van Pandora al geopend is?

00:16:49.160 --> 00:16:51.160
Ik kan het fout hebben.

00:16:51.160 --> 00:16:53.160
Een robotgeleerde van het Pantagon

00:16:53.160 --> 00:16:55.160
zei van wel. Hij zei: "Er zijn geen echte

00:16:55.160 --> 00:16:57.160
sociale, ethische en morele kwesties

00:16:57.160 --> 00:16:59.160
rond robots.

00:16:59.160 --> 00:17:01.160
Tenzij," voegde hij toe "de machines

00:17:01.160 --> 00:17:04.160
herhaaldelijk de verkeerde mensen doodt.

00:17:04.160 --> 00:17:07.160
Dan wordt het gewoon een terugroepactie."

00:17:07.160 --> 00:17:10.160
Het eindpunt van dit alles is,

00:17:10.160 --> 00:17:15.160
dat we naar Hollywood kunnen kijken.

00:17:15.160 --> 00:17:17.160
Een paar jaar geleden werden in Hollywood

00:17:17.160 --> 00:17:20.160
alle bekende personages verzameld op

00:17:20.160 --> 00:17:22.160
een top 100-lijst van helden

00:17:22.160 --> 00:17:25.160
en een top 100-lijst van schurken.

00:17:25.160 --> 00:17:27.160
De personages die het beste en het

00:17:27.160 --> 00:17:29.160
slechtste van de wereld vertegenwoordigden.

00:17:29.160 --> 00:17:33.160
Slechts één personage haalde beide lijsten.

00:17:33.160 --> 00:17:36.160
De Terminator, een robot-moordmachine.

00:17:36.160 --> 00:17:38.160
Dit duidt op het feit dat we onze

00:17:38.160 --> 00:17:40.160
machines kunnen gebruiken

00:17:40.160 --> 00:17:42.160
ten goed en ten kwade. Voor mij

00:17:42.160 --> 00:17:44.160
duidt het ook op de dualiteit

00:17:44.160 --> 00:17:47.160
van mensen.

00:17:47.160 --> 00:17:49.160
Deze week vieren we

00:17:49.160 --> 00:17:51.160
onze creativiteit. Onze creativiteit

00:17:51.160 --> 00:17:53.160
bracht ons naar de sterren.

00:17:53.160 --> 00:17:55.160
Onze creativiteit bracht kunstwerken en

00:17:55.160 --> 00:17:58.160
literatuur voort om onze liefde uit te drukken.

00:17:58.160 --> 00:18:00.160
Nu gebruiken we onze creativiteit

00:18:00.160 --> 00:18:02.160
in een bepaalde richting, om fantastische

00:18:02.160 --> 00:18:05.160
machines te bouwen met geweldige mogelijkheden.

00:18:05.160 --> 00:18:07.160
Misschien zelfs

00:18:07.160 --> 00:18:10.160
een geheel nieuwe soort.

00:18:10.160 --> 00:18:12.160
Maar de belangrijkste reden waarom

00:18:12.160 --> 00:18:14.160
we dat doen, is onze neiging

00:18:14.160 --> 00:18:17.160
elkaar te vernietigen.

00:18:17.160 --> 00:18:19.160
We moeten ons afvragen:

00:18:19.160 --> 00:18:21.160
zijn het onze machines,

00:18:21.160 --> 00:18:23.160
of zijn wij zelf ontworpen voor oorlog?

00:18:23.160 --> 00:18:25.160
Dank u. (Applaus)

