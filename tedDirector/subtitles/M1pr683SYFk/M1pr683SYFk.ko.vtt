WEBVTT
Kind: captions
Language: ko

00:00:00.000 --> 00:00:07.000
번역: Junhan Kim
검토: Young-ho Park

00:00:13.160 --> 00:00:15.160
전장의 이야기로 제 강연을 시작하겠습니다.

00:00:15.160 --> 00:00:17.160
위험이 닥쳐 온다는 기미는 별로 없지요.

00:00:17.160 --> 00:00:19.160
이라크 반체제파가 IED, 즉

00:00:19.160 --> 00:00:22.160
급조된 폭발물을

00:00:22.160 --> 00:00:24.160
길가 여기저기에 설치합니다.

00:00:24.160 --> 00:00:28.160
2006년에는 이러한 공격이

00:00:28.160 --> 00:00:31.160
매달 2500회를 헤아릴 정도로 발생해서

00:00:31.160 --> 00:00:33.160
미군과 이라크 민간인이

00:00:33.160 --> 00:00:35.160
죽고 다치게 되는

00:00:35.160 --> 00:00:37.160
가장 큰 원인이 되었지요.

00:00:37.160 --> 00:00:39.160
IED를 탐색하고 해체하는 일을 하는 팀을

00:00:39.160 --> 00:00:41.160
EOD라고 하는데

00:00:41.160 --> 00:00:43.160
폭발물 처리반의 약자입니다.

00:00:43.160 --> 00:00:45.160
이들이 하는 일은 길가의 폭탄에 관련된

00:00:45.160 --> 00:00:48.160
미군의 임무중 가장 위험한 것이죠

00:00:48.160 --> 00:00:50.160
각 EOD 팀은 폭탄을 제거하기 위해

00:00:50.160 --> 00:00:52.160
매년 평균 600번,

00:00:52.160 --> 00:00:55.160
즉, 하루에 약 2번 출동합니다.

00:00:55.160 --> 00:00:57.160
그들이 이라크전에 얼마나 크게 기여하는가는

00:00:57.160 --> 00:00:59.160
이라크 반란군이 각 EOD 대원의 목에

00:00:59.160 --> 00:01:01.160
5만불의 포상금을 걸었다는

00:01:01.160 --> 00:01:04.160
사실만 봐도 알 수 있습니다.

00:01:04.160 --> 00:01:06.160
불행히도 이 이야기는

00:01:06.160 --> 00:01:08.160
비극적인 결과로 끝을 맺게 됩니다.

00:01:08.160 --> 00:01:10.160
EOD 대원이 폭발물에 연결된 전선을

00:01:10.160 --> 00:01:12.160
볼 수 있을 정도로 폭발물에 접근했을 때

00:01:12.160 --> 00:01:15.160
그 폭발물이 화염을 토하며 폭발했지요.

00:01:15.160 --> 00:01:17.160
거리와 폭약의 양에 따라

00:01:17.160 --> 00:01:19.160
IED가 폭발하면 사망하거나 부상을 당하는데

00:01:19.160 --> 00:01:21.160
인명피해를 줄이려면

00:01:21.160 --> 00:01:23.160
약 50 미터 정도는

00:01:23.160 --> 00:01:25.160
떨어져 있어야 합니다.

00:01:25.160 --> 00:01:27.160
파편에 맞지 않더러도 충격파로

00:01:27.160 --> 00:01:29.160
팔다리가 부러질 수 있지요.

00:01:29.160 --> 00:01:31.160
그 EOD 대원은 폭발물 위에 있었는데

00:01:31.160 --> 00:01:34.160
다른 대원들이 그에게 다가갔을때는

00:01:34.160 --> 00:01:36.160
남은 시신이 별로 없었지요.

00:01:36.160 --> 00:01:38.160
그날 그 팀의 지휘관은 미국에 있는 죽은 팀원의

00:01:38.160 --> 00:01:40.160
가족에게 위로의 편지를 쓰는

00:01:40.160 --> 00:01:42.160
슬픈 임무를 이행하며

00:01:42.160 --> 00:01:44.160
모든 팀원들이 그의 죽음을

00:01:44.160 --> 00:01:46.160
받아들이기 힘들어 하고 있으며

00:01:46.160 --> 00:01:48.160
그는 가장 용감한 군인이었고 그들의 생명을 여러번

00:01:48.160 --> 00:01:50.160
구해 줬다는 이야기를 적어내려갑니다.

00:01:50.160 --> 00:01:52.160
그리고 그는 죽은 동료를 본국으로

00:01:52.160 --> 00:01:54.160
데리고 가지 못해서 미안하다는 말을 하지요.

00:01:54.160 --> 00:01:56.160
그러나 그는 이런 비극적인 현실에도

00:01:56.160 --> 00:01:58.160
한줄기의 희망의 빛이 있다고 말했지요.

00:01:58.160 --> 00:02:00.160
"만약 로봇이 죽는다고 해도

00:02:00.160 --> 00:02:02.160
로봇의 어머니에게는

00:02:02.160 --> 00:02:04.160
편지를 쓰지 않아도 됩니다" 라고 말합니다.

00:02:04.160 --> 00:02:06.160
이것은 공상과학소설 처럼 들리지만

00:02:06.160 --> 00:02:08.160
전장에서는 현실이지요.

00:02:08.160 --> 00:02:11.160
여기서 말하는 EOD 대원은

00:02:11.160 --> 00:02:14.160
무게가 약 20 kg정도 되는 PackBot라는 로봇입니다.

00:02:14.160 --> 00:02:17.160
EOD 팀장의 편지는 옛날 전쟁영화에서

00:02:17.160 --> 00:02:19.160
나오는 것 처럼 아이오와에 있는

00:02:19.160 --> 00:02:22.160
어떤 농가로 배달되는게 아니고

00:02:22.160 --> 00:02:24.160
iRobot 이라는 회사로 배달되는데

00:02:24.160 --> 00:02:27.160
그 회사의 이름은 아시모프 소설과

00:02:27.160 --> 00:02:29.160
약간 썰렁한 윌 스미스 영화에 나오는

00:02:29.160 --> 00:02:31.160
이름을 본따서 만든 ..(웃음)

00:02:31.160 --> 00:02:33.160
그 소설과 영화에나오는 로봇들은

00:02:33.160 --> 00:02:35.160
처음엔 허드레한 잡일만 하다가

00:02:35.160 --> 00:02:37.160
나중에는 생사를 결정하는

00:02:37.160 --> 00:02:39.160
결정을 내리게 되지요.

00:02:39.160 --> 00:02:41.160
이것은 지금 우리가 당면한 현실입니다.

00:02:41.160 --> 00:02:43.160
저는 지금 여러분에게 사진을

00:02:43.160 --> 00:02:45.160
몇장 보여드리겠는데 이들은

00:02:45.160 --> 00:02:48.160
지금 우리가 이미 사용하고 있거나 또는

00:02:48.160 --> 00:02:50.160
프로토타입 단계에 있는 로봇들입니다.

00:02:50.160 --> 00:02:53.160
그냥 조금 보여드리겠습니다.

00:02:53.160 --> 00:02:55.160
다시 말하자면 지금 여러분이 보실 것은

00:02:55.160 --> 00:02:57.160
스타트랙의 벌칸 기술이나

00:02:57.160 --> 00:02:59.160
철없는 10대의 아드레날린으로

00:02:59.160 --> 00:03:01.160
작동하는 기계들이 아닙니다.

00:03:01.160 --> 00:03:03.160
이건 다 실물들입니다.

00:03:03.160 --> 00:03:05.160
자 이제 그런 사진을 몇장 보죠.

00:03:05.160 --> 00:03:07.160
지금 전장에서는 큰일이 벌어지고 있는데

00:03:07.160 --> 00:03:09.160
어쩌면 인류 역사상 가장 신중한

00:03:09.160 --> 00:03:12.160
일인지도 모르죠. 이락전 초기에 미국

00:03:12.160 --> 00:03:14.160
무인정찰기는 불과 몇대 밖에

00:03:14.160 --> 00:03:17.160
없었는데 지금은 5300대가 되지요.

00:03:17.160 --> 00:03:19.160
전쟁 시작 당시에는 육상에서 쓰이는 무인 시스템이

00:03:19.160 --> 00:03:23.160
하나도 없었는데 지금은 12,000개가 됩니다.

00:03:23.160 --> 00:03:25.160
'킬러 어플리케이션' 이라는 기술용어는

00:03:25.160 --> 00:03:28.160
여기에서는 새로운 의미로 해석될 수 있지요.

00:03:28.160 --> 00:03:30.160
그런데 현재의 무인 시스템들은

00:03:30.160 --> 00:03:32.160
앞으로 곧 소개될 시스템에 비하면

00:03:32.160 --> 00:03:34.160
포드 모델 T 자동차나

00:03:34.160 --> 00:03:36.160
라이트 형제의 비행기와 비슷합니다.

00:03:36.160 --> 00:03:38.160
우리는 지금 그런 획기적인 시점에 있습니다.

00:03:38.160 --> 00:03:40.160
제가 최근에 만났던 공군 3성 장군 한명은

00:03:40.160 --> 00:03:42.160
"우리는 곧 전장에서 수만대의

00:03:42.160 --> 00:03:44.160
로봇들을 사용할 것입니다"라고 말했지요.

00:03:44.160 --> 00:03:46.160
이것은 중요한 숫자인데 그 이유는

00:03:46.160 --> 00:03:48.160
이 숫자가 현재 사용하고 있는

00:03:48.160 --> 00:03:50.160
로봇과 동일한 기능의

00:03:50.160 --> 00:03:52.160
로봇을 말하는 것이 아니라

00:03:52.160 --> 00:03:54.160
현재 개발단계 또는

00:03:54.160 --> 00:03:56.160
미래의 로봇을 말하는

00:03:56.160 --> 00:03:59.160
것이기 때문입니다.

00:03:59.160 --> 00:04:01.160
기술 발전은 무어의 법칙을 따르기 때문에

00:04:01.160 --> 00:04:03.160
이 로봇들의 컴퓨팅 능력은 계속

00:04:03.160 --> 00:04:05.160
급속도로 늘어날 것입니다.

00:04:05.160 --> 00:04:07.160
그래서 앞으로 25년간 무어의 법칙이

00:04:07.160 --> 00:04:09.160
계속 적용된다면, 25년 후 로봇들의

00:04:09.160 --> 00:04:12.160
컴퓨팅 파워는 오늘의 로봇에 비해

00:04:12.160 --> 00:04:15.160
10억배는 더 강력해질 것입니다.

00:04:15.160 --> 00:04:17.160
그리고 이것은 지금까지는 코미콘 같은

00:04:17.160 --> 00:04:19.160
공상과학 컨벤션에서나

00:04:19.160 --> 00:04:21.160
다루던 화재를 이제는 펜타곤 같은

00:04:21.160 --> 00:04:23.160
군사력의 중추에서 거론되어야

00:04:23.160 --> 00:04:25.160
한다는 것을 의미합니다.

00:04:25.160 --> 00:04:28.160
로봇 혁명은 우리 눈앞에 다가왔습니다.

00:04:28.160 --> 00:04:30.160
여기서 한가지 분명히 하고 싶은 것은

00:04:30.160 --> 00:04:32.160
제가 지금 말하는 로봇 혁명은

00:04:32.160 --> 00:04:34.160
캘리포니아 주지사가 터미네이터같은 모습으로

00:04:34.160 --> 00:04:36.160
여러분의 집에 나타나는 것을

00:04:36.160 --> 00:04:38.160
걸 말하는게 아니죠. (웃음)

00:04:38.160 --> 00:04:40.160
장래의 역사가들은 지금 우리가 새로운 종류의

00:04:40.160 --> 00:04:42.160
혁명을 겪고 있다고 말할 것입니다.

00:04:42.160 --> 00:04:44.160
즉, 원자폭탄과 같은

00:04:44.160 --> 00:04:46.160
전쟁수단의 혁명을 말하는 것이지요.

00:04:46.160 --> 00:04:48.160
그러나 어쩌면 이 무기혁명의 영향은

00:04:48.160 --> 00:04:50.160
그보다 더 클 수 있는데 그 이유는

00:04:50.160 --> 00:04:52.160
무인 로봇 시스템들은 단순히 "어떻게"

00:04:52.160 --> 00:04:54.160
싸우냐는 것 뿐만아니라 "누구"가 싸우냐는

00:04:54.160 --> 00:04:56.160
근본적인 질문도 야기하기 때문입니다.

00:04:56.160 --> 00:04:58.160
기관총이나, 원자폭탄같은 지금까지의

00:04:58.160 --> 00:05:00.160
전쟁 도구의 혁신적인 발전은

00:05:00.160 --> 00:05:03.160
얼마나 더 빨리 또는 더 멀리 총을 쏘거나 또는

00:05:03.160 --> 00:05:06.160
더 큰 폭발을 일으킬 수 있는가를 의미했지요.

00:05:06.160 --> 00:05:09.160
이점은 로봇도 마찬가지지요.

00:05:09.160 --> 00:05:12.160
하지만, 로봇은 전쟁을 하는 사람들의 경험뿐만 아니라

00:05:12.160 --> 00:05:15.160
전쟁을 하는 사람들의 신분마저 바꿀 것입니다.

00:05:15.160 --> 00:05:18.160
다시 말하자면, 지난 5000년간 인간은

00:05:18.160 --> 00:05:20.160
인류의 전쟁을 독점했었지만

00:05:20.160 --> 00:05:23.160
우리세대에서 그 바통을 로봇에게

00:05:23.160 --> 00:05:25.160
넘겨주게 됐다는 말입니다.

00:05:25.160 --> 00:05:27.160
저는 지난 몇년간 동안

00:05:27.160 --> 00:05:29.160
로봇 과학자들에서부터

00:05:29.160 --> 00:05:31.160
그들에게 영감을 불어넣은 SF물 저자들,

00:05:31.160 --> 00:05:33.160
네바다 출신의 19세

00:05:33.160 --> 00:05:35.160
무인공격기 조종사,

00:05:35.160 --> 00:05:37.160
그들에게 명령을 내리는 4성장군,

00:05:37.160 --> 00:05:39.160
그리고 심지어는 이들 폭탄의 타겟이 되는

00:05:39.160 --> 00:05:41.160
이락 반군들에게도 무인로봇 시스템에 대한

00:05:41.160 --> 00:05:43.160
의견을 물었지요.

00:05:43.160 --> 00:05:45.160
그들과의 대화를 통해 제가 흥미있게

00:05:45.160 --> 00:05:47.160
느꼈던 것은 그들의 이야기 뿐만아니라

00:05:47.160 --> 00:05:49.160
그들의 경험이 앞으로 우리의 사회, 법률,

00:05:49.160 --> 00:05:51.160
도덕 등에 어떠한 영향을

00:05:51.160 --> 00:05:53.160
미치게 될것인가 였지요.

00:05:53.160 --> 00:05:55.160
저는 남은 시간 동안 이러한 토픽중

00:05:55.160 --> 00:05:57.160
몇가지에 대해 말하고자 합니다.

00:05:57.160 --> 00:05:59.160
첫 번째로 제가 이야기하려는 것은

00:05:59.160 --> 00:06:01.160
미래의 전쟁은 미국만 로봇 전투 능력을 가진

00:06:01.160 --> 00:06:03.160
전쟁이 되지 않을 것이라는 점입니다.

00:06:03.160 --> 00:06:05.160
미국은 현재 군용 로봇에서 선두적인

00:06:05.160 --> 00:06:07.160
위치에 있습니다. 하지만 우리가 잘 알다시피

00:06:07.160 --> 00:06:09.160
기술에 관한 한 먼저 시작했다고 해서

00:06:09.160 --> 00:06:12.160
항상 우위를 차지한다는 법은 없지요.

00:06:12.160 --> 00:06:14.160
제가 간단한 질문을 드리죠.

00:06:14.160 --> 00:06:16.160
지금 여러분 중에서 아직도

00:06:16.160 --> 00:06:18.160
Wang 컴퓨터를 사용하는 분이 계신가요? (웃음)

00:06:18.160 --> 00:06:20.160
전쟁도 마찬가지입니다.

00:06:20.160 --> 00:06:23.160
탱크는 영국과 프랑스가 발명했지요.

00:06:23.160 --> 00:06:25.160
그러나 실지로 쓸만한 탱크를

00:06:25.160 --> 00:06:27.160
만들어 낸 나라는 독일이었지요.

00:06:27.160 --> 00:06:29.160
그래서 지금은 미국이 앞서 있지만

00:06:29.160 --> 00:06:31.160
지금 현재 43개의 다른 나라들이

00:06:31.160 --> 00:06:33.160
군용 로봇들을 개발하고 있는데

00:06:33.160 --> 00:06:35.160
그런 나라들에는 러시아, 중국,

00:06:35.160 --> 00:06:37.160
파키스탄 같은 국가들이 포함된다는 것을

00:06:37.160 --> 00:06:40.160
명심해야 한다는 것입니다.

00:06:40.160 --> 00:06:43.160
이것은 제게 큰 걱정을 안겨줍니다.

00:06:43.160 --> 00:06:45.160
미국의 제조업, 과학 그리고

00:06:45.160 --> 00:06:47.160
교육 실정을 생각해 볼때 우리는

00:06:47.160 --> 00:06:49.160
앞으로 군사로봇 혁명을

00:06:49.160 --> 00:06:51.160
어떻게 맞이해야 할까요?

00:06:51.160 --> 00:06:53.160
이 문제를 다른 측면에서 보자면 우리 군인들의

00:06:53.160 --> 00:06:55.160
하드웨어는 중국에서 만들어지고

00:06:55.160 --> 00:06:58.160
소프트웨어는 인도에서 개발되는 있는 실정에서

00:06:58.160 --> 00:07:03.160
우리가 전쟁에 임한다는 것은 무엇을 뜻할까요?

00:07:03.160 --> 00:07:06.160
컴퓨터 소프트웨어가 Open-source 방식으로 변했듯이

00:07:06.160 --> 00:07:08.160
전쟁 장비도 마찬가지로 변했지요.

00:07:08.160 --> 00:07:11.160
항공모함이나 원자폭탄과는 달리 군사로봇의

00:07:11.160 --> 00:07:13.160
제조에는 거대한 생산 시설이 필요하지 않습니다.

00:07:13.160 --> 00:07:15.160
부품의 많은 수는 시판되는 제품을 쓸 수 있고

00:07:15.160 --> 00:07:17.160
일부는 자가제작도 가능합니다.

00:07:17.160 --> 00:07:19.160
지금 방금 보신 사진중의 하나에는

00:07:19.160 --> 00:07:21.160
Raven이라는 무인비행체가 있는데 이것은

00:07:21.160 --> 00:07:23.160
손으로 던져서 날릴 수 있고, 약 1000달러의 경비로

00:07:23.160 --> 00:07:25.160
이라크에서 군인들이 사용하는 것과

00:07:25.160 --> 00:07:27.160
비슷한 것을 자가제작 할 수 있지요.

00:07:27.160 --> 00:07:29.160
이러한 사실은 전쟁에서 새로운 문제점을 야기하지요.

00:07:29.160 --> 00:07:31.160
즉, 청군만 이런 값싼 장비를

00:07:31.160 --> 00:07:33.160
사용할 수 있는게 아니고

00:07:33.160 --> 00:07:35.160
홍군도 그럴 수 있으니까요.

00:07:35.160 --> 00:07:37.160
로봇과 테러리즘 같은 것을 합치면

00:07:37.160 --> 00:07:39.160
그 결과는 매우 흥미있을 수도 있고

00:07:39.160 --> 00:07:41.160
매우 염려될 수도 있습니다.

00:07:41.160 --> 00:07:43.160
우리는 이미 이런 양면적인 경우를 경험했지요.

00:07:43.160 --> 00:07:45.160
이스라엘 국가와 비국가 단체인

00:07:45.160 --> 00:07:48.160
헤즈볼라간에 전쟁이 벌어졌을때 헤즈볼라가

00:07:48.160 --> 00:07:50.160
이스라엘을 상대로 네가지 종류의

00:07:50.160 --> 00:07:52.160
무인비행기를 날려보냈지요.

00:07:52.160 --> 00:07:54.160
이미 집에 앉아서 컴퓨터로

00:07:54.160 --> 00:07:56.160
이락에 있는 급조폭발장치를

00:07:56.160 --> 00:07:58.160
폭발시킬 수 있게 하는 지하드의

00:07:58.160 --> 00:08:00.160
웹사이트가 이미 존재합니다.

00:08:00.160 --> 00:08:02.160
저는 앞으로 다음의 두가지가

00:08:02.160 --> 00:08:04.160
현실화 될 것이라고 생각합니다.

00:08:04.160 --> 00:08:06.160
그 첫번째는, 정부에 대항할 수 있는

00:08:06.160 --> 00:08:10.160
개개인의 힘이 증대될 것이고

00:08:10.160 --> 00:08:12.160
그 두번째는

00:08:12.160 --> 00:08:14.160
테러리즘의 무대가

00:08:14.160 --> 00:08:16.160
확장될 것이라는 것입니다.

00:08:16.160 --> 00:08:18.160
앞으로는 아마 알카에다 2세와

00:08:18.160 --> 00:08:20.160
차세대 유나바머 엘리트 테러범의

00:08:20.160 --> 00:08:22.160
잡종같은 것이 나올 가능성이 많이 있습니다.

00:08:22.160 --> 00:08:24.160
달리 말하자면, 로봇에게는

00:08:24.160 --> 00:08:26.160
자살폭탄 테러범으로 죽으면

00:08:26.160 --> 00:08:28.160
72명의 처녀를

00:08:28.160 --> 00:08:31.160
선물받게 된다고 설득시킬

00:08:31.160 --> 00:08:34.160
필요가 없다는 거죠.

00:08:34.160 --> 00:08:36.160
이러한 테러의 여파는 우리의 정치에 영향을

00:08:36.160 --> 00:08:38.160
주게 될 것입니다. 저는 전 국방부 차관보인

00:08:38.160 --> 00:08:40.160
로널드 레이건과 대화를 나눈적이 있었는데

00:08:40.160 --> 00:08:42.160
그는 다음과 같이 말했지요:

00:08:42.160 --> 00:08:44.160
"저는 군사로봇을 좋아합니다. 미국인의 생명을

00:08:44.160 --> 00:08:46.160
보호해주니까요. 하지만 저는 군사비용에 대한

00:08:46.160 --> 00:08:48.160
토론을 저지하기 위해 전쟁의 시장화 또는

00:08:48.160 --> 00:08:51.160
'충격과 공포' 이야기를 하는 것에

00:08:51.160 --> 00:08:53.160
대해 염려합니다.

00:08:53.160 --> 00:08:55.160
사람들은 비용이 들지 않는다고 생각하면

00:08:55.160 --> 00:08:58.160
무력사용을 지지할 가능성이 더 많지요."

00:08:58.160 --> 00:09:00.160
제 생각에는 로봇은 우리의 정치체에

00:09:00.160 --> 00:09:03.160
이미 존재하는 모종의 추세를 따르고 있는데

00:09:03.160 --> 00:09:05.160
로봇은 결국에는 그런 움직임의 논리적인

00:09:05.160 --> 00:09:07.160
결론에 도달하게 될지 모릅니다.

00:09:07.160 --> 00:09:09.160
우리에겐 징병제도가 없고

00:09:09.160 --> 00:09:12.160
우리는 더이상 선전포고도 안하지요.

00:09:12.160 --> 00:09:14.160
그리고 전쟁채권도 더이상 사지 않지요.

00:09:14.160 --> 00:09:16.160
그리고 이제는 점점 군인 대신에

00:09:16.160 --> 00:09:18.160
로봇을 위험한 사지로

00:09:18.160 --> 00:09:20.160
보내고 있으며,

00:09:20.160 --> 00:09:23.160
이미 툭하면 전쟁을 시작하는 사람들이

00:09:23.160 --> 00:09:26.160
더 쉽게 전쟁을 시작하게

00:09:26.160 --> 00:09:29.160
만들지도 모릅니다.

00:09:29.160 --> 00:09:31.160
또한, 미래의 전쟁은

00:09:31.160 --> 00:09:33.160
Youtube 전쟁이 될 것입니다.

00:09:33.160 --> 00:09:35.160
우리의 신기술은 전쟁의 위험으로 부터

00:09:35.160 --> 00:09:37.160
우리를 보호해 줄 뿐만 아니라

00:09:37.160 --> 00:09:40.160
모든 전쟁 상황을 기록할 것입니다.

00:09:40.160 --> 00:09:43.160
이들은 대중을 전쟁으로 부터 격리시킬 뿐만아니라,

00:09:43.160 --> 00:09:46.160
대중과 전쟁과의 관계를 재설정 할 것입니다.

00:09:46.160 --> 00:09:48.160
유튜브에는 이락의 전투 장면을

00:09:48.160 --> 00:09:50.160
보여주는 수천개의 동영상들이

00:09:50.160 --> 00:09:52.160
이미 올라와있지요.

00:09:52.160 --> 00:09:54.160
대부분은 무인비행기로 찍은 것이죠.

00:09:54.160 --> 00:09:56.160
이것은 좋은 일일지도 모릅니다.

00:09:56.160 --> 00:09:58.160
전과는 달리,

00:09:58.160 --> 00:10:00.160
전장터의 상황을 우리가

00:10:00.160 --> 00:10:02.160
직접 볼 수 있을 테니까요.

00:10:02.160 --> 00:10:04.160
그러나 우리는 이런 일들이 우리가 살고있는

00:10:04.160 --> 00:10:07.160
괘상한 세상에서 실지로 일어나고 있다는

00:10:07.160 --> 00:10:09.160
것을 명심해야 합니다.

00:10:09.160 --> 00:10:11.160
사람들은 이러한 동영상을

00:10:11.160 --> 00:10:14.160
IPOD이나 Zune로 다운해서 전쟁을

00:10:14.160 --> 00:10:18.160
오락화 할지도 모릅니다.

00:10:18.160 --> 00:10:20.160
군인들은 이런 동영상들을

00:10:20.160 --> 00:10:22.160
전쟁 포르노라고 부르지요.

00:10:22.160 --> 00:10:24.160
이런 전쟁 포르노의 전형적인 예의 하나는

00:10:24.160 --> 00:10:26.160
제가 이메일의 첨부파일로 받은

00:10:26.160 --> 00:10:28.160
비데오인데 그 비디오에는 프레데터라는

00:10:28.160 --> 00:10:30.160
무인공격기가 미사일로 적군기지를 공격하여

00:10:30.160 --> 00:10:33.160
적군의 시체가 박살나는 장면이 있었습니다.

00:10:33.160 --> 00:10:35.160
배경음악도 있었는데

00:10:35.160 --> 00:10:37.160
그 음악은 Sugar Ray가 부른

00:10:37.160 --> 00:10:40.160
"I Just Want to Fly"라는 팝송이였지요.

00:10:40.160 --> 00:10:43.160
이와같이 전쟁 이미지는 더 많이 보지만

00:10:43.160 --> 00:10:46.160
실제 전쟁 경험이 줄어들면 대중이 전쟁을

00:10:46.160 --> 00:10:48.160
대하는 태도에 문제가 생기게 되지요.

00:10:48.160 --> 00:10:50.160
이 문제를 스포츠 경기에

00:10:50.160 --> 00:10:53.160
비유하자면

00:10:53.160 --> 00:10:56.160
이것은 마치 TV 화면에 작게 축소돼서

00:10:56.160 --> 00:10:59.160
나오는 프로농구 NBA 선수들만 보다가

00:10:59.160 --> 00:11:01.160
하루는 경기장에서 그들을 직접 눈으로 보고

00:11:01.160 --> 00:11:04.160
과연 7feet(213cm)의 사람이 어떻게

00:11:04.160 --> 00:11:06.160
생겼는지 처음으로 깨닫는 것과

00:11:06.160 --> 00:11:08.160
마찬가지 이지요.

00:11:08.160 --> 00:11:10.160
그러나 우리는 이것이 단순히

00:11:10.160 --> 00:11:12.160
무비클립이라는 것을 잊지 않아야 합니다.

00:11:12.160 --> 00:11:14.160
우리는 전쟁 동영상은 ESPN 채널의 농구선수

00:11:14.160 --> 00:11:16.160
이미지에 해당한다는 것을 항상 명심해야 합니다.

00:11:16.160 --> 00:11:18.160
그렇지 않으면 현실성을 잃게되지요.

00:11:18.160 --> 00:11:20.160
전쟁 동영상은 인간성을 망각시키고 전쟁을

00:11:20.160 --> 00:11:23.160
단순히 슬램덩크나 정밀유도폭탄으로 단순화 시킬 수 있습니다.

00:11:23.160 --> 00:11:26.160
여기서 아이러니한 것은,

00:11:26.160 --> 00:11:28.160
미래의 전쟁에서 군사로봇에 대한

00:11:28.160 --> 00:11:30.160
의존도가 점점 더 높질지는 모르지만

00:11:30.160 --> 00:11:32.160
긍국적으로는 그런 변화의 원동력은

00:11:32.160 --> 00:11:34.160
인간의 심리이며 우리의 잘못은

00:11:34.160 --> 00:11:36.160
전쟁으로 이어진다는 것입니다.

00:11:36.160 --> 00:11:38.160
인간의 심리와 결점이 우리가

00:11:38.160 --> 00:11:40.160
과격파와 벌이고 있는 사상전쟁에

00:11:40.160 --> 00:11:42.160
어떤 영향을 미치는가는 이들이

00:11:42.160 --> 00:11:44.160
우리의 정책에 미치는 영향을

00:11:44.160 --> 00:11:46.160
보면 알 수 있습니다.

00:11:46.160 --> 00:11:48.160
우리는 군사로봇을 통해 어떤 메시지를

00:11:48.160 --> 00:11:50.160
그들에게 보내고 있다고 생각하며, 한편

00:11:50.160 --> 00:11:53.160
그들은 실제로 메시지를 받고 있을까요?

00:11:53.160 --> 00:11:55.160
제가 만난 사람 중에 하나는

00:11:55.160 --> 00:11:57.160
부시 정부의 관료이었는데

00:11:57.160 --> 00:11:59.160
그는 무인 전쟁에 대해서

00:11:59.160 --> 00:12:01.160
다음과 같은 이야기를 했지요:

00:12:01.160 --> 00:12:03.160
"우리는 우리의 강점을 활용하죠.

00:12:03.160 --> 00:12:05.160
"우리의 적은 우리의 기술을 두려워합니다"

00:12:05.160 --> 00:12:07.160
하지만 예를들면 레바논 같은 곳에 있는

00:12:07.160 --> 00:12:09.160
사람들을 만나보면 아주 다른 이야기를

00:12:09.160 --> 00:12:11.160
들을 수 있지요. 저는 레바논에서

00:12:11.160 --> 00:12:13.160
뉴스 편집장 한명을 만났는데

00:12:13.160 --> 00:12:15.160
마침 무인정찰기 한대가 날라갔지요.

00:12:15.160 --> 00:12:17.160
그는 그때 이렇게 말했지요:

00:12:17.160 --> 00:12:19.160
"이건 차고 잔인한 이스라엘인과 미국인들의

00:12:19.160 --> 00:12:22.160
또 다른 모습의 하나의입니다.

00:12:22.160 --> 00:12:24.160
그들은 겁쟁이기 때문에

00:12:24.160 --> 00:12:26.160
사람답게 싸우는 것을

00:12:26.160 --> 00:12:28.160
원하지 않을 뿐만 아니라

00:12:28.160 --> 00:12:30.160
싸우기를 두려워합니다.

00:12:30.160 --> 00:12:32.160
그렇기 때문에 그들을 몇명만 죽이면

00:12:32.160 --> 00:12:35.160
우리는 이깁니다".

00:12:35.160 --> 00:12:37.160
미래의 전쟁은 새로운 종류의

00:12:37.160 --> 00:12:39.160
군인이 싸울 것입니다.

00:12:39.160 --> 00:12:42.160
그리고 그것은 전쟁이라는 것을

00:12:42.160 --> 00:12:44.160
새로 정의하게 될것입니다.

00:12:44.160 --> 00:12:46.160
우리는 이들을 "사무실 용사"라고 부를 수 있겠지요.

00:12:46.160 --> 00:12:48.160
미국의 네바다 기지에서 이락에 있는

00:12:48.160 --> 00:12:50.160
프레데터 무인정찰기를 조종하는

00:12:50.160 --> 00:12:53.160
파일럿 한명은 다음과 같이 말했지요.

00:12:53.160 --> 00:12:55.160
"저는 12시간동안 전쟁터에서

00:12:55.160 --> 00:12:57.160
적군에 총을 쏘고 적군에 쏘는

00:12:57.160 --> 00:13:00.160
로켓을 조절하지요. 그리고는

00:13:00.160 --> 00:13:02.160
퇴근을 하고 차를 타고 귀가하지요.

00:13:02.160 --> 00:13:04.160
집에 도착한 20분 이내에

00:13:04.160 --> 00:13:06.160
저녁 식사 테이블에 앉아서

00:13:06.160 --> 00:13:08.160
아이들과 숙제 이야기를 하지요"

00:13:08.160 --> 00:13:10.160
매일 이렇게 극과 극을 왔다갔다 하는

00:13:10.160 --> 00:13:12.160
생활을 하는것은 심리적으로 매우 힘듣지요.

00:13:12.160 --> 00:13:15.160
무인정찰기 조종사들의

00:13:15.160 --> 00:13:17.160
외상 후 스트레스 장애(PTSD) 발병확률은

00:13:17.160 --> 00:13:20.160
이락에서 직접 싸우는 군인보다 더 높지요.

00:13:20.160 --> 00:13:22.160
또한, 일부 사람들은 이러한 신체적 분리는

00:13:22.160 --> 00:13:24.160
다른 영향을 미칠 수도 있다고 생각하는데,

00:13:24.160 --> 00:13:26.160
예를들면 전쟁범죄가 더 쉽게 발생할 수

00:13:26.160 --> 00:13:28.160
있지 않을가 하는 걱정도 있습니다.

00:13:28.160 --> 00:13:30.160
한 젊은 조종사는 멀리서

00:13:30.160 --> 00:13:32.160
적군을 죽이는 것이

00:13:32.160 --> 00:13:34.160
"완전히 비디오 게임 같다" 고 말했지요.

00:13:34.160 --> 00:13:37.160
GTA라는 비디오 게임을 해본 사람은

00:13:37.160 --> 00:13:40.160
우리는 비디오 게임에서 현실에서 못하는

00:13:40.160 --> 00:13:43.160
행동을 한다는 것을 잘 알지요.

00:13:43.160 --> 00:13:45.160
그래서 제가 여러분께 드리는 말의 욧점은

00:13:45.160 --> 00:13:47.160
전쟁기술의 혁명에는 다른 측면이

00:13:47.160 --> 00:13:49.160
있는데 그것은 기술혁명이

00:13:49.160 --> 00:13:51.160
우리의 현재와 어쩌면 미래 전쟁의 양상을

00:13:51.160 --> 00:13:54.160
정해줄지 모른다는 것입니다.

00:13:54.160 --> 00:13:56.160
무어의 법칙도 작용하지만

00:13:56.160 --> 00:13:58.160
머피의 법칙도 역시 작용하지요.

00:13:58.160 --> 00:14:00.160
전쟁의 불확실성은 아직도 남아있지요.

00:14:00.160 --> 00:14:02.160
적도 투표권을 가지고 있지요.

00:14:02.160 --> 00:14:04.160
우리의 엄청난 무인전투능력은

00:14:04.160 --> 00:14:06.160
계속 확대되고 있지만 우리는 또한 새로운

00:14:06.160 --> 00:14:08.160
인간 딜레마들을 보고 경험하고 있습니다.

00:14:08.160 --> 00:14:10.160
어느 로봇회사의 대표자 한명이

00:14:10.160 --> 00:14:12.160
그들이 말하는 소위 "어이쿠" 순간에 대해

00:14:12.160 --> 00:14:14.160
저에게 설명해 주었지요.

00:14:14.160 --> 00:14:16.160
"그건 어이쿠 순간이었어"라고 말하죠.

00:14:16.160 --> 00:14:18.160
로봇전쟁의 '어이쿠' 순간은 어떤것일까요?

00:14:18.160 --> 00:14:20.160
어떤때는 우수운 일이 생겼을때 그런말을 하지요.

00:14:20.160 --> 00:14:22.160
예를들어 에디머피의 영화

00:14:22.160 --> 00:14:24.160
슈퍼탱크작전에 나오는 상황이

00:14:24.160 --> 00:14:26.160
실지로 벌어질 때도

00:14:26.160 --> 00:14:28.160
그런 감탄사를 사용하지요.

00:14:28.160 --> 00:14:30.160
즉, 기관총이 장착된 로봇을 시위하다가

00:14:30.160 --> 00:14:33.160
잘못해서 신장비를 리뷰하기 위해 모인

00:14:33.160 --> 00:14:36.160
VIP에게 기관총을 겨누는 장면이지요.

00:14:36.160 --> 00:14:38.160
다행히도 장전된 상태가 아니었기 때문에

00:14:38.160 --> 00:14:40.160
피해자는 없었지만요.

00:14:40.160 --> 00:14:42.160
그러나 어이쿠 순간이 비극으로

00:14:42.160 --> 00:14:44.160
치닫는 경우도 있는데, 그 예로 작년에

00:14:44.160 --> 00:14:47.160
남아프리카공화국에서"소프트웨어 결함"으로

00:14:47.160 --> 00:14:50.160
대공캐논이 발포되며 9명의 남아공 군인을

00:14:50.160 --> 00:14:53.160
죽인 사고가 발생했었지요.

00:14:53.160 --> 00:14:56.160
우리는 현재 전쟁법규와 행동책임이라는

00:14:56.160 --> 00:14:58.160
새로운 문제를 안고 있습니다. 예를들면

00:14:58.160 --> 00:15:00.160
무인살육은 어떻게 처리해야 할까요?

00:15:00.160 --> 00:15:02.160
무인살육이란 무엇일까요?

00:15:02.160 --> 00:15:04.160
우리는 이미 프레데터 무인정찰기로

00:15:04.160 --> 00:15:06.160
빈라덴의 거처라고 생각되는 곳을

00:15:06.160 --> 00:15:08.160
3번이나 폭격했는데 나중에

00:15:08.160 --> 00:15:10.160
알고 보니 아니였어요.

00:15:10.160 --> 00:15:12.160
이것이 무인전투장비의 현황입니다.

00:15:12.160 --> 00:15:14.160
저는 지금 여기서 자체적인 판단으로

00:15:14.160 --> 00:15:16.160
화력을 사용하는 자동 무장시스템을

00:15:16.160 --> 00:15:18.160
말하는 것도 아닙니다.

00:15:18.160 --> 00:15:20.160
그러나 그런 날이 오지 않는다고는 생각하지

00:15:20.160 --> 00:15:22.160
마십시오. 저는 제연구를 통해 펜타곤이

00:15:22.160 --> 00:15:24.160
현재 4개의 무인무장체제 프로젝트를

00:15:24.160 --> 00:15:26.160
추진하고 있다는 것을 알고 있습니다.

00:15:26.160 --> 00:15:28.160
여러분은 무인시스템의 경우 전범 이슈를

00:15:28.160 --> 00:15:30.160
어떻게 해결할 것인지 궁금해 하실지 모릅니다.

00:15:30.160 --> 00:15:32.160
로봇들은 감정이 없기 때문에

00:15:32.160 --> 00:15:35.160
그들의 동료가 죽어도 화내지 않습니다.

00:15:35.160 --> 00:15:37.160
그들은 분노나 복수를 이유로

00:15:37.160 --> 00:15:39.160
전범을 범하지 않습니다.

00:15:39.160 --> 00:15:42.160
하지만 로봇들은 감정이 없기 때문에

00:15:42.160 --> 00:15:44.160
휠체어에 있는 80세의 할머니나

00:15:44.160 --> 00:15:46.160
T80 탱크를 구별하지 않지요.

00:15:46.160 --> 00:15:49.160
그들에게는 둘다 다

00:15:49.160 --> 00:15:52.160
0과 1의 데이터로 보이니까요.

00:15:52.160 --> 00:15:55.160
그래서 우리는 정부로 부터 무료 의료치료를

00:15:55.160 --> 00:15:57.160
받을수 있을 만큼 노후화된 현재의

00:15:57.160 --> 00:15:59.160
20세기 전쟁법규를 21세기의

00:15:59.160 --> 00:16:02.160
전쟁기술에 맞도록 개정하는 방안을

00:16:02.160 --> 00:16:05.160
찾아내야 합니다.

00:16:05.160 --> 00:16:08.160
마지막으로, 제가 지금까지 미래의 전쟁에 대해

00:16:08.160 --> 00:16:11.160
이야기한것처럼 들릴지 모르지만 제가 사용한 모든 예는

00:16:11.160 --> 00:16:13.160
현재 사용되는 무인무기체계이며 또한

00:16:13.160 --> 00:16:15.160
여러분이 보신 사진과 비디오도

00:16:15.160 --> 00:16:17.160
기존 시스템이라는 점을 기억하시기 바랍니다.

00:16:17.160 --> 00:16:19.160
전쟁 로봇에 대한 걱정은 룸바같은

00:16:19.160 --> 00:16:21.160
청소 로봇이 시람을 빨아 먹으면

00:16:21.160 --> 00:16:23.160
어떻게 하냐는 걱정보다 훨씬 더

00:16:23.160 --> 00:16:25.160
현실성이 있는 걱정입니다.

00:16:25.160 --> 00:16:27.160
지금 현재 전쟁에서 실지로 사용되는

00:16:27.160 --> 00:16:30.160
전쟁로봇이 너무나 공상과학 소설같이

00:16:30.160 --> 00:16:33.160
생각돼서 사람들이 믿지않는다면

00:16:33.160 --> 00:16:35.160
그대로 나둬야 할까요?

00:16:35.160 --> 00:16:37.160
우리는 21세기의 현실을

00:16:37.160 --> 00:16:39.160
인정할 것인가요?

00:16:39.160 --> 00:16:41.160
전세대가 원자폭탄에 대해 아무런 조치를

00:16:41.160 --> 00:16:43.160
취하지 않았던 것과 같은 실수를

00:16:43.160 --> 00:16:45.160
우리들이 되풀이 해서 이런 문제들이

00:16:45.160 --> 00:16:47.160
판도라 상자에서 나올때까지

00:16:47.160 --> 00:16:49.160
이런 이슈들을 다루지 않아도 좋을까요?

00:16:49.160 --> 00:16:51.160
그런데, 제가 틀렸을지도 몰르죠 -

00:16:51.160 --> 00:16:53.160
펜타곤의 한 로봇 과학자가 제 생각이

00:16:53.160 --> 00:16:55.160
틀렸다고 말했으니까요. 그는 "로봇에

00:16:55.160 --> 00:16:57.160
관한한 실질적으로 사회적 또는 도덕적인

00:16:57.160 --> 00:16:59.160
이슈가 없다" 고 말했지요.

00:16:59.160 --> 00:17:01.160
그는 "로봇들이 엉뚱한 사람들을

00:17:01.160 --> 00:17:04.160
계속 죽이면 제품 리콜을 하면 돼요"

00:17:04.160 --> 00:17:07.160
라고 덧붙여 말했지요.

00:17:07.160 --> 00:17:10.160
제 이야기의 결론은 --

00:17:10.160 --> 00:17:15.160
아, 헐리우드의 예를 들면 되겠군요.

00:17:15.160 --> 00:17:17.160
몇년전에 할리우드에서

00:17:17.160 --> 00:17:20.160
영화 역사상 가장 인기가 많았던

00:17:20.160 --> 00:17:22.160
100대 영웅과 100대 악당들의

00:17:22.160 --> 00:17:25.160
리스트를 만들었는데 이 캐릭터들은

00:17:25.160 --> 00:17:27.160
인간성의 최선와 최악을 상징하는

00:17:27.160 --> 00:17:29.160
캐릭터들이었지요.

00:17:29.160 --> 00:17:33.160
그런데 양쪽 리스트에 올라간 캐릭터는 단 하나밖에 없었는데

00:17:33.160 --> 00:17:36.160
그건 바로 로봇을 죽이는 터미네이터였습니다.

00:17:36.160 --> 00:17:38.160
이것은 로봇은 좋은 목적으로

00:17:38.160 --> 00:17:40.160
사용될 수도 있고 나쁜 목적으로도

00:17:40.160 --> 00:17:42.160
사용될 수 있다는 것을 제시하지요.

00:17:42.160 --> 00:17:44.160
저는 이것은 인간의 양면성을

00:17:44.160 --> 00:17:47.160
보여주기도 한다고 생각합니다.

00:17:47.160 --> 00:17:49.160
이번 주는 우리의 창의성을

00:17:49.160 --> 00:17:51.160
축하하는 주이며 우리의 창의력은

00:17:51.160 --> 00:17:53.160
인류를 별까지 닿게했습니다.

00:17:53.160 --> 00:17:55.160
우리의 창의력은 예술품과 문학작품을

00:17:55.160 --> 00:17:58.160
통해 우리의 사랑을 표현할 수 있게 했으며

00:17:58.160 --> 00:18:00.160
우리는 이제 우리의 창의력으로

00:18:00.160 --> 00:18:02.160
엄청난 기능을 가진 놀라운

00:18:02.160 --> 00:18:05.160
기계들을 만들고 있으며

00:18:05.160 --> 00:18:07.160
언젠가는 완전히 새로운 종을

00:18:07.160 --> 00:18:10.160
만들게 될지도 모릅니다.

00:18:10.160 --> 00:18:12.160
우리가 이런일을 하는 주된 이유의 하나는

00:18:12.160 --> 00:18:14.160
우리에게 서로를 파괴시키려는 욕구가 있기

00:18:14.160 --> 00:18:17.160
때문인데 그렇기 때문에 우리는 전쟁하는 회로를

00:18:17.160 --> 00:18:19.160
가진 것이 우리의 로봇인지

00:18:19.160 --> 00:18:21.160
아니면 우리 자신인지를

00:18:21.160 --> 00:18:23.160
질문해야 합니다.

00:18:23.160 --> 00:18:25.160
감사합니다. (박수)

