WEBVTT
Kind: captions
Language: en

00:00:15.402 --> 00:00:18.466
So I'm a doctor, but I kind of slipped
sideways into research,

00:00:18.490 --> 00:00:20.188
and now I'm an epidemiologist.

00:00:20.212 --> 00:00:22.356
And nobody really knows
what epidemiology is.

00:00:22.380 --> 00:00:25.533
Epidemiology is the science
of how we know in the real world

00:00:25.557 --> 00:00:27.667
if something is good
for you or bad for you.

00:00:27.691 --> 00:00:29.651
And it's best understood through example

00:00:29.675 --> 00:00:34.326
as the science of those crazy,
wacky newspaper headlines.

00:00:34.350 --> 00:00:36.683
And these are just some of the examples.

00:00:36.707 --> 00:00:38.157
These are from the Daily Mail.

00:00:38.181 --> 00:00:40.700
Every country in the world
has a newspaper like this.

00:00:40.724 --> 00:00:43.074
It has this bizarre,
ongoing philosophical project

00:00:43.098 --> 00:00:45.453
of dividing all the inanimate
objects in the world

00:00:45.477 --> 00:00:47.830
into the ones that either cause
or prevent cancer.

00:00:47.854 --> 00:00:50.362
Here are some of the things
they said cause cancer:

00:00:50.386 --> 00:00:52.367
divorce, Wi-Fi, toiletries and coffee.

00:00:52.391 --> 00:00:54.155
Some things they say prevent cancer:

00:00:54.179 --> 00:00:56.101
crusts, red pepper, licorice and coffee.

00:00:56.125 --> 00:00:58.031
So you can see there are contradictions.

00:00:58.055 --> 00:01:00.055
Coffee both causes and prevents cancer.

00:01:00.079 --> 00:01:01.803
As you start to read on, you can see

00:01:01.827 --> 00:01:04.766
that maybe there's some
political valence behind some of this.

00:01:04.790 --> 00:01:06.851
For women, housework
prevents breast cancer,

00:01:06.875 --> 00:01:09.920
but for men, shopping
could make you impotent.

00:01:09.944 --> 00:01:10.953
(Laughter)

00:01:10.977 --> 00:01:15.481
So we know that we need to start
unpicking the science behind this.

00:01:15.505 --> 00:01:21.038
And what I hope to show is that unpicking
the evidence behind dodgy claims

00:01:21.062 --> 00:01:24.782
isn't a kind of nasty, carping activity;

00:01:24.806 --> 00:01:26.167
it's socially useful.

00:01:26.191 --> 00:01:30.749
But it's also an extremely valuable
explanatory tool,

00:01:30.773 --> 00:01:33.808
because real science is about
critically appraising the evidence

00:01:33.832 --> 00:01:35.225
for somebody else's position.

00:01:35.249 --> 00:01:37.208
That's what happens in academic journals,

00:01:37.232 --> 00:01:39.296
it's what happens
at academic conferences --

00:01:39.320 --> 00:01:42.629
the Q&amp;A session after a postdoc
presents data is often a bloodbath.

00:01:42.653 --> 00:01:44.811
And nobody minds that;
we actively welcome it.

00:01:44.835 --> 00:01:47.873
It's like a consenting
intellectual S&amp;M activity.

00:01:47.897 --> 00:01:49.052
(Laughter)

00:01:49.076 --> 00:01:52.070
So what I'm going to show you
is all of the main things,

00:01:52.094 --> 00:01:55.284
all of the main features of my discipline,
evidence-based medicine.

00:01:55.308 --> 00:01:59.191
And I will talk you through all of these
and demonstrate how they work,

00:01:59.215 --> 00:02:02.557
exclusively using examples
of people getting stuff wrong.

00:02:02.581 --> 00:02:06.335
We'll start with the absolute weakest
form of evidence known to man,

00:02:06.359 --> 00:02:07.985
and that is authority.

00:02:08.009 --> 00:02:11.449
In science, we don't care how many letters
you have after your name --

00:02:11.473 --> 00:02:14.485
we want to know what your reasons are
for believing something.

00:02:14.509 --> 00:02:17.505
How do you know that something
is good for us or bad for us?

00:02:17.529 --> 00:02:21.710
But we're also unimpressed by authority
because it's so easy to contrive.

00:02:21.734 --> 00:02:24.116
This is somebody called
Dr. Gillian McKeith, PhD,

00:02:24.140 --> 00:02:27.309
or, to give her full
medical title, Gillian McKeith.

00:02:27.333 --> 00:02:29.993
(Laughter)

00:02:30.017 --> 00:02:32.173
Again, every country
has somebody like this.

00:02:32.197 --> 00:02:33.841
She is our TV diet guru.

00:02:33.865 --> 00:02:36.772
She has five series
of prime-time television,

00:02:36.796 --> 00:02:39.114
giving out very lavish
and exotic health advice.

00:02:39.138 --> 00:02:42.993
She, it turns out, has a non-accredited
correspondence course PhD

00:02:43.017 --> 00:02:44.297
from somewhere in America.

00:02:44.321 --> 00:02:47.086
She also boasts that she's a certified
professional member

00:02:47.110 --> 00:02:49.702
of the American Association
of Nutritional Consultants,

00:02:49.726 --> 00:02:52.125
which sounds very glamorous;
you get a certificate.

00:02:52.149 --> 00:02:55.166
This one belongs to my dead cat, Hettie.
She was a horrible cat.

00:02:55.190 --> 00:02:57.154
You go to the website, fill out the form,

00:02:57.178 --> 00:02:58.999
give them $60, it arrives in the post.

00:02:59.023 --> 00:03:01.856
That's not the only reason
we think this person is an idiot.

00:03:01.880 --> 00:03:04.529
She also says things like
eat lots of dark green leaves,

00:03:04.553 --> 00:03:07.410
they contain chlorophyll
and really oxygenate your blood.

00:03:07.434 --> 00:03:09.633
And anybody who's done
school biology remembers

00:03:09.657 --> 00:03:12.869
that chlorophyll and chloroplasts
only make oxygen in sunlight,

00:03:12.893 --> 00:03:16.023
and it's quite dark in your bowels
after you've eaten spinach.

00:03:16.047 --> 00:03:18.546
Next, we need proper science,
proper evidence.

00:03:18.570 --> 00:03:21.012
So: "Red wine can help
prevent breast cancer."

00:03:21.036 --> 00:03:23.599
This is a headline
from The Daily Telegraph in the UK.

00:03:23.623 --> 00:03:26.541
"A glass of red wine a day could help
prevent breast cancer."

00:03:26.565 --> 00:03:29.801
So you find this paper, and find
that it is a real piece of science.

00:03:29.825 --> 00:03:32.822
It's a description of the changes
in the behavior of one enzyme

00:03:32.846 --> 00:03:36.015
when you drip a chemical
extracted from some red grape skin

00:03:36.039 --> 00:03:37.614
onto some cancer cells

00:03:37.638 --> 00:03:40.838
in a dish on a bench
in a laboratory somewhere.

00:03:40.862 --> 00:03:44.954
And that's a really useful thing
to describe in a scientific paper.

00:03:44.978 --> 00:03:48.336
But on the question of your own personal
risk of getting breast cancer

00:03:48.360 --> 00:03:49.511
if you drink red wine,

00:03:49.535 --> 00:03:51.216
it tells you absolutely bugger all.

00:03:51.240 --> 00:03:53.777
Actually, it turns out
that your risk of breast cancer

00:03:53.801 --> 00:03:56.764
increases slightly with every amount
of alcohol you drink.

00:03:56.788 --> 00:04:00.636
So what we want are studies
in real human people.

00:04:00.660 --> 00:04:02.236
And here's another example.

00:04:02.260 --> 00:04:06.421
This is from Britain's "leading"
diet nutritionist in the Daily Mirror,

00:04:06.445 --> 00:04:08.219
our second-biggest selling newspaper.

00:04:08.243 --> 00:04:10.601
"An Australian study in 2001
found that olive oil,

00:04:10.625 --> 00:04:12.967
in combination with fruits,
vegetables and pulses,

00:04:12.991 --> 00:04:15.539
offers measurable protection
against skin wrinklings,"

00:04:15.563 --> 00:04:16.714
and give the advice:

00:04:16.738 --> 00:04:19.868
"If you eat olive oil and vegetables,
you'll have fewer wrinkles."

00:04:19.892 --> 00:04:22.050
They helpfully tell you
how to find the paper,

00:04:22.074 --> 00:04:24.161
and what you find
is an observational study.

00:04:24.185 --> 00:04:27.106
Obviously, nobody has been able
to go back to 1930,

00:04:27.130 --> 00:04:29.623
get all the people born
in one maternity unit,

00:04:29.647 --> 00:04:32.343
and half of them eat lots
of fruit and veg and olive oil,

00:04:32.367 --> 00:04:33.713
half of them eat McDonald's,

00:04:33.737 --> 00:04:36.140
and then we see how many wrinkles
you've got later.

00:04:36.164 --> 00:04:38.577
You have to take a snapshot
of how people are now.

00:04:38.601 --> 00:04:40.165
And what you find is, of course:

00:04:40.189 --> 00:04:42.690
people who eat veg and olive oil
have fewer wrinkles.

00:04:42.714 --> 00:04:46.455
But that's because people who eat
fruit and veg and olive oil are freaks --

00:04:46.479 --> 00:04:50.303
they're not normal, they're like you;
they come to events like this.

00:04:50.327 --> 00:04:51.386
(Laughter)

00:04:51.410 --> 00:04:54.429
They're posh, they're wealthy,
less likely to have outdoor jobs,

00:04:54.453 --> 00:04:55.969
less likely to do manual labor,

00:04:55.993 --> 00:04:58.733
they have better social support,
are less likely to smoke;

00:04:58.757 --> 00:05:00.631
for a host of fascinating, interlocking

00:05:00.655 --> 00:05:02.524
social, political and cultural reasons,

00:05:02.548 --> 00:05:04.320
they're less likely to have wrinkles.

00:05:04.344 --> 00:05:06.746
That doesn't mean
it's the vegetables or olive oil.

00:05:06.770 --> 00:05:08.016
(Laughter)

00:05:08.040 --> 00:05:10.533
So ideally, what you want
to do is a trial.

00:05:10.557 --> 00:05:13.137
People think they're familiar
with the idea of a trial.

00:05:13.161 --> 00:05:15.977
Trials are old; the first one
was in the Bible, Daniel 1:12.

00:05:16.001 --> 00:05:19.076
It's straightforward: take a bunch
of people, split them in half,

00:05:19.100 --> 00:05:21.726
treat one group one way,
the other group, the other way.

00:05:21.750 --> 00:05:24.273
A while later, you see
what happened to each of them.

00:05:24.297 --> 00:05:26.131
I'm going to tell you about one trial,

00:05:26.155 --> 00:05:28.321
which is probably
the most well-reported trial

00:05:28.345 --> 00:05:30.350
in the UK news media over the past decade.

00:05:30.374 --> 00:05:32.110
This is the trial of fish oil pills.

00:05:32.134 --> 00:05:35.287
The claim: fish oil pills improve
school performance and behavior

00:05:35.311 --> 00:05:36.462
in mainstream children.

00:05:36.486 --> 00:05:37.780
They said, "We did a trial.

00:05:37.804 --> 00:05:40.576
All the previous ones were positive,
this one will be too."

00:05:40.600 --> 00:05:41.982
That should ring alarm bells:

00:05:42.006 --> 00:05:45.066
if you know the answer to your trial,
you shouldn't be doing one.

00:05:45.090 --> 00:05:46.718
Either you've rigged it by design,

00:05:46.742 --> 00:05:50.179
or you've got enough data so there's
no need to randomize people anymore.

00:05:50.203 --> 00:05:52.704
So this is what they were going
to do in their trial:

00:05:52.728 --> 00:05:54.805
They were taking 3,000 children,

00:05:54.829 --> 00:05:58.483
they were going to give them these huge
fish oil pills, six of them a day,

00:05:58.507 --> 00:06:01.620
and then, a year later, measure
their school exam performance

00:06:01.644 --> 00:06:03.418
and compare their performance

00:06:03.442 --> 00:06:06.598
against what they predicted
their exam performance would have been

00:06:06.622 --> 00:06:08.698
if they hadn't had the pills.

00:06:08.722 --> 00:06:11.529
Now, can anybody spot
a flaw in this design?

00:06:11.553 --> 00:06:12.568
(Laughter)

00:06:12.592 --> 00:06:14.835
And no professors
of clinical trial methodology

00:06:14.859 --> 00:06:16.585
are allowed to answer this question.

00:06:16.609 --> 00:06:18.610
So there's no control group.

00:06:18.634 --> 00:06:21.969
But that sounds really techie, right?
That's a technical term.

00:06:21.993 --> 00:06:24.626
The kids got the pills,
and their performance improved.

00:06:24.650 --> 00:06:27.323
What else could it possibly
be if it wasn't the pills?

00:06:28.128 --> 00:06:30.401
They got older; we all develop over time.

00:06:30.425 --> 00:06:32.590
And of course, there's the placebo effect,

00:06:32.614 --> 00:06:35.452
one of the most fascinating things
in the whole of medicine.

00:06:35.476 --> 00:06:38.389
It's not just taking a pill
and performance or pain improving;

00:06:38.413 --> 00:06:42.076
it's about our beliefs and expectations,
the cultural meaning of a treatment.

00:06:42.100 --> 00:06:45.370
And this has been demonstrated
in a whole raft of fascinating studies

00:06:45.394 --> 00:06:47.611
comparing one kind of placebo
against another.

00:06:47.635 --> 00:06:48.793
So we know, for example,

00:06:48.817 --> 00:06:51.530
that two sugar pills a day
are a more effective treatment

00:06:51.554 --> 00:06:52.773
for gastric ulcers

00:06:52.797 --> 00:06:54.037
than one sugar pill.

00:06:54.061 --> 00:06:56.022
Two sugar pills a day beats one a day.

00:06:56.046 --> 00:06:58.821
That's an outrageous
and ridiculous finding, but it's true.

00:06:58.845 --> 00:07:02.142
We know from three different studies
on three different types of pain

00:07:02.166 --> 00:07:04.811
that a saltwater injection
is a more effective treatment

00:07:04.835 --> 00:07:07.440
than a sugar pill, a dummy pill
with no medicine in it,

00:07:07.464 --> 00:07:10.808
not because the injection or pills
do anything physically to the body,

00:07:10.832 --> 00:07:14.188
but because an injection feels
like a much more dramatic intervention.

00:07:14.212 --> 00:07:17.274
So we know that our beliefs
and expectations can be manipulated,

00:07:17.298 --> 00:07:21.346
which is why we do trials
where we control against a placebo,

00:07:21.370 --> 00:07:23.908
where one half of the people
get the real treatment,

00:07:23.932 --> 00:07:25.609
and the other half get placebo.

00:07:25.633 --> 00:07:27.482
But that's not enough.

00:07:28.496 --> 00:07:30.272
What I've just shown you are examples

00:07:30.296 --> 00:07:32.468
of the very simple
and straightforward ways

00:07:32.492 --> 00:07:35.755
that journalists and food supplement
pill peddlers and naturopaths

00:07:35.779 --> 00:07:38.236
can distort evidence
for their own purposes.

00:07:38.260 --> 00:07:40.440
What I find really fascinating

00:07:40.464 --> 00:07:43.621
is that the pharmaceutical industry
uses exactly the same kinds

00:07:43.645 --> 00:07:45.173
of tricks and devices,

00:07:45.197 --> 00:07:47.964
but slightly more sophisticated
versions of them,

00:07:47.988 --> 00:07:51.166
in order to distort the evidence
they give to doctors and patients,

00:07:51.190 --> 00:07:53.752
and which we use to make
vitally important decisions.

00:07:53.776 --> 00:07:56.309
So firstly, trials against placebo:

00:07:56.333 --> 00:07:58.705
everybody thinks a trial
should be a comparison

00:07:58.729 --> 00:08:00.324
of your new drug against placebo.

00:08:00.348 --> 00:08:02.268
But in a lot of situations that's wrong;

00:08:02.292 --> 00:08:05.190
often, we already have a good treatment
currently available.

00:08:05.214 --> 00:08:08.047
So we don't want to know
that your alternative new treatment

00:08:08.071 --> 00:08:09.222
is better than nothing,

00:08:09.246 --> 00:08:12.214
but that it's better than the best
available treatment we have.

00:08:12.238 --> 00:08:15.111
And yet, repeatedly, you consistently
see people doing trials

00:08:15.135 --> 00:08:16.441
still against placebo.

00:08:16.465 --> 00:08:18.972
And you can get licensed
to bring your drug to market

00:08:18.996 --> 00:08:21.495
with only data showing
that it's better than nothing,

00:08:21.519 --> 00:08:24.521
which is useless for a doctor like me
trying to make a decision.

00:08:24.545 --> 00:08:26.910
But that's not the only way
you can rig your data.

00:08:26.934 --> 00:08:28.182
You can also rig your data

00:08:28.206 --> 00:08:30.699
by making the thing you compare
your new drug against

00:08:30.723 --> 00:08:31.880
really rubbish.

00:08:31.904 --> 00:08:34.373
You can give the competing drug
in too low a dose,

00:08:34.397 --> 00:08:36.030
so people aren't properly treated.

00:08:36.054 --> 00:08:38.451
You can give the competing drug
in too high a dose,

00:08:38.475 --> 00:08:39.771
so people get side effects.

00:08:39.795 --> 00:08:41.475
And this is exactly what happened

00:08:41.499 --> 00:08:43.964
with antipsychotic medication
for schizophrenia.

00:08:43.988 --> 00:08:47.520
Twenty years ago, a new generation
of antipsychotic drugs were brought in;

00:08:47.544 --> 00:08:50.101
the promise was they would have
fewer side effects.

00:08:50.125 --> 00:08:53.579
So people set about doing trials
of the new drugs against the old drugs.

00:08:53.603 --> 00:08:56.288
But they gave the old drugs
in ridiculously high doses:

00:08:56.312 --> 00:08:58.157
20 milligrams a day of haloperidol.

00:08:58.181 --> 00:09:01.735
And it's a foregone conclusion
if you give a drug at that high a dose,

00:09:01.759 --> 00:09:05.039
it will have more side effects,
and your new drug will look better.

00:09:05.063 --> 00:09:07.051
Ten years ago, history repeated itself,

00:09:07.075 --> 00:09:10.400
when risperidone, the first
of the new-generation antipsychotic drugs,

00:09:10.424 --> 00:09:12.766
came off copyright,
so anybody could make copies.

00:09:12.790 --> 00:09:15.822
Everybody wanted to show their drug
was better than risperidone,

00:09:15.846 --> 00:09:18.247
so you see trials comparing
new antipsychotic drugs

00:09:18.271 --> 00:09:20.438
against risperidone
at eight milligrams a day.

00:09:20.462 --> 00:09:22.676
Again, not an insane dose,
not an illegal dose,

00:09:22.700 --> 00:09:24.618
but very much at the high end of normal.

00:09:24.642 --> 00:09:27.159
So you're bound to make
your new drug look better.

00:09:27.183 --> 00:09:29.780
And so it's no surprise that overall,

00:09:29.804 --> 00:09:32.573
industry-funded trials
are four times more likely

00:09:32.597 --> 00:09:33.926
to give a positive result

00:09:33.950 --> 00:09:36.003
than independently sponsored trials.

00:09:36.989 --> 00:09:39.633
But -- and it's a big but --

00:09:39.657 --> 00:09:42.178
(Laughter)

00:09:42.202 --> 00:09:43.483
it turns out,

00:09:43.507 --> 00:09:47.148
when you look at the methods
used by industry-funded trials,

00:09:47.172 --> 00:09:50.858
that they're actually better
than independently sponsored trials.

00:09:50.882 --> 00:09:53.774
And yet, they always manage
to get the result that they want.

00:09:53.798 --> 00:09:54.948
So how does this work?

00:09:54.972 --> 00:09:55.985
(Laughter)

00:09:56.009 --> 00:09:58.776
How can we explain
this strange phenomenon?

00:09:58.800 --> 00:10:00.598
Well, it turns out that what happens

00:10:00.622 --> 00:10:02.855
is the negative data
goes missing in action;

00:10:02.879 --> 00:10:04.816
it's withheld from doctors and patients.

00:10:04.840 --> 00:10:07.538
And this is the most important
aspect of the whole story.

00:10:07.562 --> 00:10:09.596
It's at the top
of the pyramid of evidence.

00:10:09.620 --> 00:10:12.306
We need to have all of the data
on a particular treatment

00:10:12.330 --> 00:10:14.490
to know whether or not
it really is effective.

00:10:14.514 --> 00:10:18.181
There are two different ways you can spot
whether some data has gone missing.

00:10:18.205 --> 00:10:20.404
You can use statistics
or you can use stories.

00:10:20.428 --> 00:10:22.817
I prefer statistics,
so that's what I'll do first.

00:10:22.841 --> 00:10:24.163
This is a funnel plot.

00:10:24.187 --> 00:10:26.378
A funnel plot is a very clever
way of spotting

00:10:26.402 --> 00:10:29.767
if small negative trials have disappeared,
have gone missing in action.

00:10:29.791 --> 00:10:33.269
This is a graph of all of the trials done
on a particular treatment.

00:10:33.293 --> 00:10:35.548
As you go up towards the top of the graph,

00:10:35.572 --> 00:10:37.501
what you see is each dot is a trial.

00:10:37.525 --> 00:10:40.651
As you go up, those are bigger trials,
so they've got less error;

00:10:40.675 --> 00:10:43.821
they're less likely to be randomly false
positives or negatives.

00:10:43.845 --> 00:10:45.237
So they all cluster together.

00:10:45.261 --> 00:10:47.768
The big trials are closer
to the true answer.

00:10:47.792 --> 00:10:49.808
Then as you go further down at the bottom,

00:10:49.832 --> 00:10:52.751
what you can see is, on this side,
spurious false negatives,

00:10:52.775 --> 00:10:55.021
and over on this side,
spurious false positives.

00:10:55.045 --> 00:10:57.121
If there is publication bias,

00:10:57.145 --> 00:10:59.675
if small negative trials
have gone missing in action,

00:10:59.699 --> 00:11:01.514
you can see it on one of these graphs.

00:11:01.538 --> 00:11:03.689
So you see here
that the small negative trials

00:11:03.713 --> 00:11:06.166
that should be on the bottom left
have disappeared.

00:11:06.190 --> 00:11:09.125
This is a graph demonstrating
the presence of publication bias

00:11:09.149 --> 00:11:11.069
in studies of publication bias.

00:11:11.093 --> 00:11:14.395
And I think that's the funniest
epidemiology joke you will ever hear.

00:11:14.419 --> 00:11:15.430
(Laughter)

00:11:15.454 --> 00:11:17.478
That's how you can prove it statistically.

00:11:17.502 --> 00:11:18.653
But what about stories?

00:11:18.677 --> 00:11:20.592
Well, they're heinous, they really are.

00:11:20.616 --> 00:11:22.205
This is a drug called reboxetine.

00:11:22.229 --> 00:11:25.168
This is a drug which I, myself,
have prescribed to patients.

00:11:25.192 --> 00:11:26.528
And I'm a very nerdy doctor.

00:11:26.552 --> 00:11:27.864
I hope I go out of my way

00:11:27.888 --> 00:11:30.247
to try and read and understand
all the literature.

00:11:30.271 --> 00:11:31.579
I read the trials on this.

00:11:31.603 --> 00:11:33.870
They were all positive,
all well-conducted.

00:11:33.894 --> 00:11:35.045
I found no flaw.

00:11:35.069 --> 00:11:38.650
Unfortunately, it turned out,
that many of these trials were withheld.

00:11:38.674 --> 00:11:43.219
In fact, 76 percent of all of the trials
that were done on this drug

00:11:43.243 --> 00:11:45.194
were withheld from doctors and patients.

00:11:45.218 --> 00:11:46.471
Now if you think about it,

00:11:46.495 --> 00:11:48.792
if I tossed a coin a hundred times,

00:11:48.816 --> 00:11:52.352
and I'm allowed to withhold from you
the answers half the times,

00:11:52.376 --> 00:11:56.465
then I can convince you
that I have a coin with two heads.

00:11:56.489 --> 00:11:58.402
If we remove half of the data,

00:11:58.426 --> 00:12:02.164
we can never know what the true
effect size of these medicines is.

00:12:02.188 --> 00:12:04.259
And this is not an isolated story.

00:12:04.283 --> 00:12:08.077
Around half of all of the trial data
on antidepressants has been withheld,

00:12:08.101 --> 00:12:09.537
but it goes way beyond that.

00:12:09.561 --> 00:12:12.907
The Nordic Cochrane Group were trying
to get ahold of the data on that

00:12:12.931 --> 00:12:14.126
to bring it all together.

00:12:14.150 --> 00:12:17.169
The Cochrane Groups are an international
nonprofit collaboration

00:12:17.193 --> 00:12:18.683
that produce systematic reviews

00:12:18.707 --> 00:12:20.804
of all of the data
that has ever been shown.

00:12:20.828 --> 00:12:23.362
And they need to have access
to all of the trial data.

00:12:23.386 --> 00:12:25.829
But the companies withheld
that data from them.

00:12:25.853 --> 00:12:28.048
So did the European Medicines Agency --

00:12:28.072 --> 00:12:29.658
for three years.

00:12:29.682 --> 00:12:32.714
This is a problem that is currently
lacking a solution.

00:12:32.738 --> 00:12:35.637
And to show how big it goes,
this is a drug called Tamiflu,

00:12:35.661 --> 00:12:37.323
which governments around the world

00:12:37.347 --> 00:12:40.190
have spent billions
and billions of dollars on.

00:12:40.214 --> 00:12:43.081
And they spend that money
on the promise that this is a drug

00:12:43.105 --> 00:12:46.077
which will reduce the rate
of complications with flu.

00:12:46.101 --> 00:12:47.252
We already have the data

00:12:47.276 --> 00:12:50.070
showing it reduces the duration
of your flu by a few hours.

00:12:50.094 --> 00:12:52.548
But I don't care about that,
governments don't care.

00:12:52.572 --> 00:12:55.026
I'm sorry if you have the flu,
I know it's horrible,

00:12:55.050 --> 00:12:57.294
but we're not going to spend
billions of dollars

00:12:57.318 --> 00:13:00.480
trying to reduce the duration
of your flu symptoms by half a day.

00:13:00.504 --> 00:13:01.829
We prescribe these drugs.

00:13:01.853 --> 00:13:03.656
We stockpile them for emergencies

00:13:03.680 --> 00:13:06.769
on the understanding they'll reduce
the number of complications,

00:13:06.793 --> 00:13:08.327
which means pneumonia and death.

00:13:08.351 --> 00:13:11.810
The infectious diseases Cochrane Group,
which are based in Italy,

00:13:11.834 --> 00:13:15.011
has been trying to get
the full data in a usable form

00:13:15.035 --> 00:13:16.303
out of the drug companies,

00:13:16.327 --> 00:13:18.418
so they can make a full decision

00:13:18.442 --> 00:13:20.539
about whether this drug
is effective or not,

00:13:20.563 --> 00:13:23.529
and they've not been able
to get that information.

00:13:23.553 --> 00:13:28.759
This is undoubtedly
the single biggest ethical problem

00:13:28.783 --> 00:13:30.759
facing medicine today.

00:13:31.204 --> 00:13:36.537
We cannot make decisions
in the absence of all of the information.

00:13:37.789 --> 00:13:40.766
So it's a little bit difficult from there

00:13:40.790 --> 00:13:44.236
to spin in some kind
of positive conclusion.

00:13:45.196 --> 00:13:46.827
But I would say this:

00:13:48.931 --> 00:13:51.727
I think that sunlight

00:13:51.751 --> 00:13:53.475
is the best disinfectant.

00:13:54.077 --> 00:13:56.812
All of these things
are happening in plain sight,

00:13:56.836 --> 00:14:01.167
and they're all protected
by a force field of tediousness.

00:14:01.631 --> 00:14:04.038
And I think, with all
of the problems in science,

00:14:04.062 --> 00:14:05.882
one of the best things that we can do

00:14:05.906 --> 00:14:08.709
is to lift up the lid,
finger around at the mechanics

00:14:08.733 --> 00:14:10.012
and peer in.

00:14:10.036 --> 00:14:11.196
Thank you very much.

00:14:11.220 --> 00:14:14.458
(Applause)

