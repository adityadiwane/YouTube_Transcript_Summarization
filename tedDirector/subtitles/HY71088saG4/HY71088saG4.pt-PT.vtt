WEBVTT
Kind: captions
Language: pt-PT

00:00:00.000 --> 00:00:07.000
Tradutor: Teresa Freitas
Revisora: Margarida Ferreira

00:00:12.653 --> 00:00:16.191
Em 2011, modifiquei o meu nome

00:00:16.225 --> 00:00:20.141
para poder participar num campo 
da juventude de extrema-direita na Hungria.

00:00:20.454 --> 00:00:24.920
Estava a fazer o doutoramento
sobre a socialização política da juventude

00:00:24.954 --> 00:00:28.135
— porque é que os jovens estavam
a desenvolver ideologias políticas

00:00:28.189 --> 00:00:30.199
num cenário de pós-comunismo,

00:00:30.223 --> 00:00:33.366
e reparei que muitos dos jovens
com quem eu falava

00:00:33.390 --> 00:00:35.130
estavam a aderir à extrema-direita.

00:00:35.164 --> 00:00:37.170
Isto para mim foi surpreendente.

00:00:37.194 --> 00:00:39.569
Por isso quis-me inscrever
nesse campo de jovens

00:00:39.593 --> 00:00:42.649
para ter uma melhor compreensão
do porquê dessas adesões.

00:00:42.673 --> 00:00:44.430
Um colega, então, inscreveu-me,

00:00:44.454 --> 00:00:47.292
mas o meu apelido soa
demasiado a "judeu".

00:00:47.500 --> 00:00:50.245
Desse modo, Erin passou a ser Iréna,

00:00:50.329 --> 00:00:52.469
e Saltman mudou para Shosh,

00:00:52.493 --> 00:00:55.414
que se traduz por "salgado"
em húngaro.

00:00:55.438 --> 00:00:57.908
Na Hungria, o apelido
vem em primeiro lugar

00:00:57.952 --> 00:01:01.886
por isso o meu nome em estilo James Bond
passou a ser "Irena Salgada",

00:01:02.210 --> 00:01:05.693
que não é algo que eu escolheria 
naturalmente para mim própria.

00:01:06.100 --> 00:01:08.167
Mas, ao frequentar o acampamento,

00:01:08.191 --> 00:01:12.694
fiquei chocada ao aperceber-me
que, na verdade, era muito divertido.

00:01:13.000 --> 00:01:15.325
Falavam muito pouco de política.

00:01:15.379 --> 00:01:18.412
Era sobretudo aprender a andar a cavalo,

00:01:18.466 --> 00:01:20.224
praticar arco e flecha,

00:01:20.278 --> 00:01:21.935
música ao vivo de noite,

00:01:21.989 --> 00:01:23.848
comida e álcool grátis,

00:01:23.872 --> 00:01:26.878
e algum tiro ao alvo com armas de pressão

00:01:26.918 --> 00:01:29.966
usando fotos de políticos como alvos.

00:01:30.440 --> 00:01:34.307
Pareceu-me, na verdade, um grupo
bastante amigável e inclusivo

00:01:34.371 --> 00:01:39.414
até alguém começar a falar ou mencionar
alguma coisa sobre o povo cigano,

00:01:39.628 --> 00:01:42.070
judeus ou imigrantes.

00:01:42.174 --> 00:01:46.124
Aí o discurso, rapidamente,
tornava-se num discurso de ódio,

00:01:46.663 --> 00:01:49.473
o que me levou ao meu trabalho de hoje

00:01:49.497 --> 00:01:51.548
em que fazemos a pergunta:

00:01:51.902 --> 00:01:55.172
"Porque é que as pessoas aderem
a movimentos extremistas violentos

00:01:55.202 --> 00:01:58.177
"e como podemos eficazmente
opor-nos a esses processos?"

00:01:58.393 --> 00:02:01.764
No rescaldo de horríveis 
atrocidades e ataques

00:02:01.828 --> 00:02:04.931
em países como a Bélgica, a França, 
e por todo o mundo,

00:02:05.095 --> 00:02:06.928
às vezes é mais fácil pensarmos:

00:02:06.952 --> 00:02:09.027
"Bem, têm que ser sociopatas,

00:02:09.101 --> 00:02:11.985
"têm que ser indivíduos
violentos por natureza.

00:02:12.009 --> 00:02:14.605
"Houve alguma coisa de anormal 
com a sua educação".

00:02:14.629 --> 00:02:16.806
E o que é realmente trágico

00:02:16.820 --> 00:02:19.151
é que frequentemente não há nenhum perfil.

00:02:19.155 --> 00:02:22.209
Muitos deles têm antecedentes instruídos,

00:02:22.233 --> 00:02:24.519
com passados socioeconómicos diferentes,

00:02:24.533 --> 00:02:27.201
homens e mulheres, de diferentes idades,

00:02:27.225 --> 00:02:29.503
alguns com famílias, outros solteiros.

00:02:29.527 --> 00:02:32.302
Então porquê? Qual é o fascínio?

00:02:32.356 --> 00:02:34.255
E é sobre isto que vos venho falar

00:02:34.279 --> 00:02:37.166
bem como sobre a maneira
de o combater na nossa atualidade.

00:02:38.531 --> 00:02:40.284
O que sabemos, pelas pesquisas,

00:02:40.348 --> 00:02:42.394
é que há uma série de diferentes coisas

00:02:42.418 --> 00:02:45.769
que afetam o processo de 
radicalização de uma pessoa,

00:02:45.793 --> 00:02:48.753
e categorizamo-los como fatores
"empurra" e "puxa".

00:02:48.797 --> 00:02:52.090
Estes são praticamente iguais em
grupos de extrema-direita, neonazis,

00:02:52.104 --> 00:02:55.068
grupos extremistas islâmicos
e grupos terroristas.

00:02:56.483 --> 00:02:59.611
Os fatores "empurra" são basicamente
o que nos torna vulneráveis

00:02:59.631 --> 00:03:01.253
ao processo de radicalização,

00:03:01.277 --> 00:03:03.453
para aderir a um grupo
extremista e violento.

00:03:03.477 --> 00:03:05.603
Estes podem ter diversas formas,

00:03:05.627 --> 00:03:09.540
como ter um sentimento
de alienação, de isolamento,

00:03:09.564 --> 00:03:11.715
de questionamento da própria identidade,

00:03:11.739 --> 00:03:14.665
ou sentir que o grupo onde
estamos inseridos está sob ataque,

00:03:14.729 --> 00:03:18.382
quer seja um grupo com base
na nacionalidade, na etnia

00:03:18.406 --> 00:03:19.732
ou numa religião,

00:03:19.756 --> 00:03:23.517
e sentir que forças superiores à nossa
volta não fazem nada para ajudar.

00:03:23.755 --> 00:03:27.416
Os fatores de "empurra", por si só,
não nos fazem ser um extremista violento,

00:03:27.460 --> 00:03:29.010
porque, se isso fosse verdade,

00:03:29.044 --> 00:03:32.384
esses fatores podiam ser utilizados
num grupo como a população cigana

00:03:32.438 --> 00:03:34.979
e estes não são um grupo 
mobilizado para a violência.

00:03:35.009 --> 00:03:37.180
Temos então que olhar para 
os fatores "puxa".

00:03:37.204 --> 00:03:40.514
O que é que estas organizações
extremistas oferecem

00:03:40.538 --> 00:03:42.427
que outros grupos não oferecem?

00:03:42.437 --> 00:03:45.100
Na verdade, normalmente oferecem
coisas muito positivas

00:03:45.130 --> 00:03:47.111
coisas que nos dão poder,

00:03:47.135 --> 00:03:49.598
como um sentido de irmandade

00:03:49.622 --> 00:03:51.096
e um sentimento de pertença,

00:03:51.120 --> 00:03:53.854
bem como oferecem
um propósito espiritual,

00:03:53.878 --> 00:03:57.593
um propósito divino de construção
de uma sociedade utópica

00:03:57.617 --> 00:03:59.538
se os seus objetivos forem cumpridos,

00:03:59.562 --> 00:04:02.313
mas também um sentimento
de fortalecimento e aventura.

00:04:02.337 --> 00:04:04.380
Quando vemos os
guerreiros terroristas

00:04:04.404 --> 00:04:07.095
encontramos homens jovens
com o vento a bater nos cabelos

00:04:07.119 --> 00:04:09.665
no deserto e mulheres juntando-se a eles

00:04:09.689 --> 00:04:12.330
para acasalamentos ao pôr do sol.

00:04:12.354 --> 00:04:16.174
É tudo muito romântico
e tornamo-nos num herói.

00:04:16.198 --> 00:04:19.256
Para mulheres e homens,
essa tem sido a propaganda utilizada.

00:04:19.487 --> 00:04:22.219
O que os grupos extremistas
são bons a fazer

00:04:22.263 --> 00:04:26.979
é pegar num mundo complicado, 
confuso e cheio de matizes

00:04:27.003 --> 00:04:30.246
e simplificá-lo transformando-o
apenas em preto e branco,

00:04:30.270 --> 00:04:31.480
bom ou mau.

00:04:31.504 --> 00:04:33.385
Nós tornamo-nos no "bom"

00:04:33.409 --> 00:04:35.584
a desafiar o que é "mau".

00:04:36.361 --> 00:04:40.225
Queria então falar um pouco
sobre o ISIS, o Daesh

00:04:40.249 --> 00:04:44.627
porque eles mudaram a forma como
nós olhamos para estes processos,

00:04:44.651 --> 00:04:47.857
de acordo com as suas táticas e materiais.

00:04:47.881 --> 00:04:50.519
Eles podem ser considerados
um movimento moderno.

00:04:50.745 --> 00:04:55.040
Um dos aspetos modernos é a utilização
da Internet e das redes sociais,

00:04:55.254 --> 00:04:59.636
como todos já vimos nos cabeçalhos,
no Twitter e nos vídeos de decapitações.

00:04:59.660 --> 00:05:02.135
Mas a Internet, por si só,
não nos radicaliza.

00:05:02.159 --> 00:05:03.576
A Internet é uma ferramenta.

00:05:03.610 --> 00:05:05.516
Não vamos a um site comprar sapatos

00:05:05.550 --> 00:05:07.508
e acabamos por tornar-nos num jihadista

00:05:07.613 --> 00:05:11.002
Contudo, a Internet serve de catalisador.

00:05:11.136 --> 00:05:15.145
Providencia ferramentas,
uma escala global e rapidez

00:05:15.169 --> 00:05:16.997
que não existe em mais nenhum lugar.

00:05:17.031 --> 00:05:19.162
Com o ISIS, de repente,

00:05:19.186 --> 00:05:24.504
a ideia da figura disfarçada e escura
do jihadista mudou para nós.

00:05:24.528 --> 00:05:26.583
De súbito, estávamos nas suas cozinhas.

00:05:26.607 --> 00:05:28.606
Víamos o que eles comiam ao jantar.

00:05:28.630 --> 00:05:29.781
Eles twittavam.

00:05:29.805 --> 00:05:32.773
Havia terroristas estrangeiros
a twittar na sua própria língua.

00:05:32.797 --> 00:05:35.269
Havia mulheres a falar 
do seu dia de casamento,

00:05:35.293 --> 00:05:37.450
do nascimento dos seus filhos.

00:05:37.614 --> 00:05:39.731
Tínhamos uma cultura de videojogos

00:05:39.765 --> 00:05:42.821
e referências ao jogo "Grand Theft Auto".

00:05:43.291 --> 00:05:46.902
De repente, eles eram familiares,
tornaram-se humanos.

00:05:46.951 --> 00:05:49.165
O problema é que, ao tentar contrariá-los,

00:05:49.189 --> 00:05:52.359
os governos e as empresas de redes sociais
só tentaram censurar.

00:05:52.408 --> 00:05:54.639
"Como livrar-nos
de conteúdos terroristas?"

00:05:54.663 --> 00:05:56.528
E tornou-se um jogo do gato e do rato,

00:05:56.558 --> 00:05:59.596
em que víamos contas a serem fechadas
para voltarem a aparecer,

00:05:59.620 --> 00:06:02.733
e uma arrogância em volta de alguém
que tinha 25 contas

00:06:02.757 --> 00:06:05.851
e material a ser disseminado 
para todo o mundo.

00:06:05.875 --> 00:06:08.296
Mas também vimos uma tendência perigosa:

00:06:08.319 --> 00:06:10.629
os extremistas violentos também conhecem

00:06:10.653 --> 00:06:12.888
as regras e regulamentações
das redes sociais.

00:06:12.952 --> 00:06:16.952
Por isso, víamos uma conversa banal
com um recrutador

00:06:16.976 --> 00:06:19.169
ser transmitida numa 
plataforma convencional

00:06:19.223 --> 00:06:22.214
e no momento em que a conversa
passava a ser ilegal,

00:06:22.252 --> 00:06:25.403
eles mudavam para uma plataforma
mais pequena, menos regulamentada,

00:06:25.457 --> 00:06:26.690
e mais encriptada.

00:06:26.774 --> 00:06:30.147
De repente, já não conseguíamos
localizar o rumo da conversa.

00:06:30.171 --> 00:06:32.093
Este é o problema da censura,

00:06:32.147 --> 00:06:35.449
que faz com que seja necessário
desenvolver alternativas à mesma.

00:06:35.855 --> 00:06:39.205
O ISIS é um fator de mudança
porque fixa-se na construção de um Estado.

00:06:39.229 --> 00:06:41.341
Não está apenas a recrutar combatentes;

00:06:41.365 --> 00:06:43.227
está a tentar contruir um Estado.

00:06:43.251 --> 00:06:45.191
E isso significa que de repente,

00:06:45.215 --> 00:06:47.215
o modelo de recrutamento é bem mais amplo.

00:06:47.239 --> 00:06:49.288
Não são precisos apenas guerreiros,

00:06:49.312 --> 00:06:53.578
são precisos arquitetos, engenheiros,
contabilistas, "hackers" e mulheres.

00:06:53.602 --> 00:06:56.182
Temos visto um grande aumento
de mulheres a afiliar-se

00:06:56.232 --> 00:06:59.175
nos últimos dois anos,
mas especialmente no ano passado.

00:06:59.195 --> 00:07:02.478
Nalguns países, uma em cada quatro
pessoas que se juntam ao extremismo

00:07:02.508 --> 00:07:03.691
são mulheres.

00:07:03.715 --> 00:07:05.313
Isso muda muito

00:07:05.367 --> 00:07:08.169
quem estamos a tentar enfrentar
neste processo.

00:07:08.499 --> 00:07:10.220
Mas não é só desgraça e tristeza.

00:07:10.274 --> 00:07:13.134
Gostava agora de falar
de algumas das coisas positivas

00:07:13.158 --> 00:07:17.002
e das inovações para tentar prevenir
e enfrentar o extremismo violento.

00:07:17.026 --> 00:07:19.299
Prevenir é muito diferente de enfrentar,

00:07:19.323 --> 00:07:21.929
e podemos pensar em termos médicos.

00:07:21.983 --> 00:07:24.215
A medicina preventiva pensa

00:07:24.249 --> 00:07:27.323
no que fazer para nos tornar 
naturalmente resistentes

00:07:27.347 --> 00:07:29.847
ao processo de radicalização,

00:07:29.871 --> 00:07:31.733
enquanto que será diferente

00:07:31.757 --> 00:07:34.416
na situação de alguém já mostrar
sintomas ou sinais

00:07:34.440 --> 00:07:37.181
de pertencer a uma ideologia
extremista violenta.

00:07:37.345 --> 00:07:38.892
Como medidas preventivas,

00:07:38.916 --> 00:07:41.607
falamos de amplos grupos de pessoas

00:07:41.631 --> 00:07:45.241
e da exposição a ideias
para torná-los resistentes.

00:07:45.310 --> 00:07:46.979
Enquanto que é muito diferente

00:07:47.043 --> 00:07:50.628
se alguém começa a questionar-se
e a concordar com certas coisas online,

00:07:50.652 --> 00:07:54.501
ou se alguém já tem 
a tatuagem de uma suástica

00:07:54.525 --> 00:07:56.793
e está fortemente integrado num grupo.

00:07:56.827 --> 00:07:58.581
Como é que podemos alcançá-los?

00:07:58.625 --> 00:08:02.067
Gostava de falar de três exemplos
de cada um desses níveis

00:08:02.491 --> 00:08:06.936
e explicar algumas das novas formas
de abordar essas pessoas.

00:08:07.194 --> 00:08:08.877
Uma é o "Diálogo Extremo".

00:08:08.891 --> 00:08:11.831
É um programa educacional
que nós ajudámos a desenvolver.

00:08:11.915 --> 00:08:13.976
Foi criado no Canadá.

00:08:14.140 --> 00:08:18.115
O seu objetivo é dialogar
num ambiente de sala de aula,

00:08:18.209 --> 00:08:19.831
usando narrativas,

00:08:19.835 --> 00:08:22.966
porque o extremismo violento 
pode ser difícil de tentar explicar,

00:08:22.990 --> 00:08:25.059
especialmente para os mais novos.

00:08:25.125 --> 00:08:29.038
Criámos uma rede de ex-extremistas
e sobreviventes de extremismo

00:08:29.062 --> 00:08:32.999
que contam as suas histórias em vídeo
e criam oportunidades de perguntas

00:08:33.023 --> 00:08:35.406
para estimular uma 
discussão sobre o tópico.

00:08:35.460 --> 00:08:39.022
Estes dois exemplos mostram Christianne
que perdeu o filho

00:08:39.072 --> 00:08:41.574
que se radicalizou
e morreu a lutar pelo ISIS,

00:08:41.628 --> 00:08:45.565
e o Daniel, um antigo neonazi,
que era extremamente violento.

00:08:45.671 --> 00:08:49.829
Eles falam sobre as suas vidas, 
onde estão agora, como se arrependem

00:08:49.853 --> 00:08:52.903
e obrigam a turma a ter um diálogo
à volta destas experiências.

00:08:52.995 --> 00:08:55.834
Olhando para o número médio de indivíduos,

00:08:55.874 --> 00:08:58.703
na verdade, precisamos de
muitas vozes da sociedade civil.

00:08:58.727 --> 00:09:02.262
Como é que se interage com pessoas
que estão a procurar informação online,

00:09:02.286 --> 00:09:04.538
que começam a brincar 
com uma certa ideologia,

00:09:04.562 --> 00:09:07.626
que fazem pesquisas sobre
questões de identidade?

00:09:07.650 --> 00:09:09.792
Como é que providenciamos alternativas?

00:09:09.816 --> 00:09:13.206
É então que juntamos grandes grupos
de vozes da sociedade civil

00:09:13.230 --> 00:09:17.921
como criativos, técnicos, criadores
de aplicações, artistas, comediantes

00:09:17.955 --> 00:09:20.558
e conseguimos criar um conteúdo específico

00:09:20.592 --> 00:09:24.786
e disseminá-lo, online,
para uma audiência estratégica.

00:09:24.810 --> 00:09:29.823
Um exemplo seria criar um vídeo satírico
que faça troça da fobia ao Islão,

00:09:30.160 --> 00:09:34.096
e direcioná-lo para jovens
entre os 15 e os 20 anos

00:09:34.120 --> 00:09:36.507
que têm interesse em músicas
de "poder branco"

00:09:36.541 --> 00:09:38.650
e vivem especificamente em Manchester.

00:09:38.664 --> 00:09:41.935
Podemos usar estas ferramentas de 
"marketing" para serem específicas

00:09:41.955 --> 00:09:44.592
para podermos saber quando
alguém está a assistir

00:09:44.616 --> 00:09:46.245
e envolver-se com esse conteúdo.

00:09:46.279 --> 00:09:48.759
Não é apenas a pessoa comum,
não sou eu nem vocês,

00:09:48.783 --> 00:09:51.890
é um público específico 
que pretendemos atingir.

00:09:52.524 --> 00:09:56.223
De seguida, desenvolvemos um programa 
piloto chamado "Um para um",

00:09:56.247 --> 00:09:57.956
em que pegámos em ex-extremistas

00:09:58.030 --> 00:10:02.684
e pusemo-los a contactar diretamente
com grupos de neofascistas

00:10:02.708 --> 00:10:04.452
e extremistas islâmicos.

00:10:04.486 --> 00:10:08.041
Colocavam mensagens diretas
pelo Messenger, a dizer:

00:10:08.055 --> 00:10:10.481
"Eu sei o que estás a fazer. 
Já estive no teu lugar

00:10:10.505 --> 00:10:12.127
"Se quiseres falar, estou aqui".

00:10:12.171 --> 00:10:15.325
Estávamos à espera de 
ameaças de morte com estas interações.

00:10:15.739 --> 00:10:19.509
É um pouco alarmante aparecer um ex-neonazi
a dizer "Olá, como estás?"

00:10:19.793 --> 00:10:24.500
Mas na verdade, cerca de 60%
dessas pessoas responderam

00:10:24.602 --> 00:10:28.537
e das que responderam,
outras 60% mantiveram o diálogo,

00:10:28.581 --> 00:10:30.757
o que significa que estavam a conversar

00:10:30.791 --> 00:10:34.007
com as pessoas mais difíceis de atingir
sobre as suas dificuldades,

00:10:34.031 --> 00:10:35.242
a criar dúvidas

00:10:35.286 --> 00:10:38.148
e a dar-lhes alternativas
sobre como abordar esses assuntos,

00:10:38.198 --> 00:10:39.912
e isso é muito importante.

00:10:40.881 --> 00:10:43.104
O que estamos a tentar fazer

00:10:43.128 --> 00:10:46.033
é trazer áreas improváveis para o debate.

00:10:46.057 --> 00:10:48.383
Temos ativistas extraordinários
por todo o mundo,

00:10:48.407 --> 00:10:50.943
mas por vezes, as suas mensagens
não são estratégicas

00:10:50.977 --> 00:10:53.543
ou não atingem o público que querem.

00:10:53.647 --> 00:10:56.036
Nós trabalhamos com redes 
de antigos extremistas.

00:10:56.070 --> 00:10:59.283
Nós trabalhamos com redes de jovens
de diferentes partes do mundo.

00:10:59.293 --> 00:11:02.453
Trabalhamos com eles para pôr 
o sector tecnológico em cima da mesa

00:11:02.497 --> 00:11:05.055
com artistas, criativos
e técnicos de "marketing"

00:11:05.079 --> 00:11:10.080
para termos uma forma mais robusta
de luta contra o extremismo

00:11:10.104 --> 00:11:11.584
que funcione em conjunto.

00:11:11.894 --> 00:11:14.474
Logo, queria dizer
a quem está na plateia

00:11:14.498 --> 00:11:17.197
— vocês são "designers" gráficos,

00:11:17.221 --> 00:11:19.303
um poeta, um especialista de "marketing",

00:11:19.317 --> 00:11:21.336
alguém que trabalha em relações públicas,

00:11:21.360 --> 00:11:22.713
um ator —

00:11:22.737 --> 00:11:24.888
podem achar que isto não é a vossa área

00:11:24.912 --> 00:11:27.651
mas as competências que vocês têm agora

00:11:27.675 --> 00:11:29.678
podem ser exatamente o que é preciso

00:11:29.702 --> 00:11:32.011
para ajudar no combate ao extremismo.

00:11:32.035 --> 00:11:33.186
Obrigada.

00:11:33.210 --> 00:11:37.423
(Aplausos)

