WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Emilia Sotres
Revisor: Lidia Cámara de la Fuente

00:00:12.833 --> 00:00:16.231
En el 2011 me cambié el nombre

00:00:16.255 --> 00:00:20.231
para participar en un campamento 
juvenil de extrema derecha en Hungría.

00:00:20.434 --> 00:00:25.160
Hacía el doctorado sobre 
la sociabilización política de los jóvenes

00:00:25.184 --> 00:00:28.255
por qué los jóvenes 
desarrollaban ideologías políticas

00:00:28.279 --> 00:00:30.289
en un marco postcomunista.

00:00:30.313 --> 00:00:33.546
Y observé que mucha gente joven
con la que hablaba

00:00:33.570 --> 00:00:35.170
se unía a la extrema derecha,

00:00:35.194 --> 00:00:37.350
y esto me sorprendía.

00:00:37.374 --> 00:00:39.669
Así que quise inscribirme 
en este campamento

00:00:39.693 --> 00:00:42.829
para tener un mejor entendimiento
de por qué la gente se unía.

00:00:42.853 --> 00:00:44.410
Un colega me registró

00:00:44.434 --> 00:00:47.362
y mi apellido suena 
demasiado judío.

00:00:47.680 --> 00:00:50.425
Así que Erin se convirtió en Iréna

00:00:50.449 --> 00:00:52.649
y Saltman se convirtió en Sós,

00:00:52.673 --> 00:00:55.594
que significa "salado" en húngaro.

00:00:55.618 --> 00:00:57.928
Y en húngaro el apellido va primero,

00:00:57.952 --> 00:01:02.366
así que mi nombre James Bond
cambió a "Salada Irena",

00:01:02.390 --> 00:01:05.873
que no es lo que yo habría 
escogido para mí.

00:01:06.280 --> 00:01:08.187
Pero al llegar a este campamento,

00:01:08.211 --> 00:01:12.734
quedé aún más sorprendida 
de que en realidad era muy divertido.

00:01:13.180 --> 00:01:15.395
Hablaban muy poco sobre política.

00:01:15.419 --> 00:01:18.432
Era más bien sobre 
aprender a montar a caballo,

00:01:18.456 --> 00:01:20.324
disparar con arco y flecha,

00:01:20.348 --> 00:01:22.035
música en vivo por la noche,

00:01:22.059 --> 00:01:24.028
comida y alcohol gratis,

00:01:24.052 --> 00:01:26.918
también práctica de tiro al blanco 
con balas de aire

00:01:26.942 --> 00:01:30.596
utilizando las caras de políticos
convencionales como blanco.

00:01:30.620 --> 00:01:34.347
Parecía realmente un grupo
muy amistoso e inclusivo

00:01:34.371 --> 00:01:39.784
hasta que se hablaba o mencionaba
el tema de la población gitana,

00:01:39.808 --> 00:01:42.070
la gente judía o los inmigrantes.

00:01:42.094 --> 00:01:46.244
Entonces el discurso se cargaba
de odio rápidamente.

00:01:46.843 --> 00:01:49.653
Esto me llevó a mi trabajo actual,

00:01:49.677 --> 00:01:52.058
donde formulamos la pregunta:

00:01:52.082 --> 00:01:55.122
¿Por qué la gente se une
a movimientos extremistas violentos

00:01:55.146 --> 00:01:58.177
y cómo contrarrestamos 
efectivamente estos procesos?

00:01:58.573 --> 00:02:01.864
Al evaluar los daños tras las 
horribles atrocidades y ataques

00:02:01.888 --> 00:02:05.251
en lugares como Bélgica, Francia,
y por todo el mundo,

00:02:05.275 --> 00:02:07.108
a veces es más sencillo pensar:

00:02:07.132 --> 00:02:09.077
"Bueno, deben de ser sociópatas,

00:02:09.101 --> 00:02:12.165
deben ser individuos de
naturaleza violenta."

00:02:12.189 --> 00:02:14.785
"Algo malo debe haber ocurrido 
durante su infancia."

00:02:14.809 --> 00:02:16.896
Y lo verdaderamente trágico es que

00:02:16.920 --> 00:02:19.111
muchas veces no existe un perfil único.

00:02:19.135 --> 00:02:22.389
Muchos de ellos tienen
estudios avanzados,

00:02:22.413 --> 00:02:24.509
diferentes ambientes socioeconómicos,

00:02:24.533 --> 00:02:27.381
hombres y mujeres, distintas edades,

00:02:27.405 --> 00:02:29.683
algunos con familias, otros solteros.

00:02:29.707 --> 00:02:32.362
Así que, ¿por qué?, ¿cuál es el atractivo?

00:02:32.386 --> 00:02:34.435
Y de eso quiero hablarles,

00:02:34.459 --> 00:02:37.346
y de cómo desafiarlo en la era moderna.

00:02:38.711 --> 00:02:40.194
Sabemos por la investigación

00:02:40.218 --> 00:02:42.574
que hay un número de factores

00:02:42.598 --> 00:02:45.949
que afectan el proceso de
radicalización de una persona,

00:02:45.973 --> 00:02:48.743
y los categorizamos en 
factores de atracción y disuasión.

00:02:48.767 --> 00:02:52.180
Y estos son similares para grupos 
de extrema derecha neonazis

00:02:52.204 --> 00:02:55.108
y para los islamistas radicales y 
grupos terroristas.

00:02:55.663 --> 00:02:59.521
Los factores de atracción son básicamente
aquellos que nos hacen vulnerables

00:02:59.545 --> 00:03:01.403
a un proceso de radicalización,

00:03:01.427 --> 00:03:03.633
a unirnos a un grupo extremista violento.

00:03:03.657 --> 00:03:05.783
Y estos pueden ser muy variados

00:03:05.807 --> 00:03:09.720
pero, a grandes rasgos, un sentido 
de enajenación, un sentido de aislamiento,

00:03:09.744 --> 00:03:11.895
cuestionarte tu propia identidad,

00:03:11.919 --> 00:03:14.745
pero también sentir que tu grupo 
está bajo ataque,

00:03:14.769 --> 00:03:18.562
y tu grupo puede estar basado 
en una nacionalidad, etnia,

00:03:18.586 --> 00:03:19.912
o una religión.

00:03:19.936 --> 00:03:23.547
Y sentir que quienes tienen el poder 
de ayudar no lo están haciendo.

00:03:24.075 --> 00:03:27.496
Los factores de atracción solo
no te hacen un extremista violento,

00:03:27.520 --> 00:03:28.950
porque si así fuera,

00:03:28.974 --> 00:03:32.244
los mismos factores se aplicarían 
a grupos como los gitanos,

00:03:32.268 --> 00:03:35.049
y ellos no son un grupo con 
brotes violentos.

00:03:35.073 --> 00:03:37.360
Así que hay que ver
los factores de atracción.

00:03:37.384 --> 00:03:40.694
¿Qué están ofreciendo estas
organizaciones extremistas violentas

00:03:40.718 --> 00:03:42.663
que otros grupos no ofrecen?

00:03:42.687 --> 00:03:45.250
De hecho, suelen ser cosas muy positivas,

00:03:45.274 --> 00:03:47.291
cosas que parecieran dar poder,

00:03:47.315 --> 00:03:49.778
como fraternidad y hermandad

00:03:49.802 --> 00:03:51.136
y un sentido de pertenencia,

00:03:51.160 --> 00:03:54.034
así como darle a alguien
un propósito espiritual,

00:03:54.058 --> 00:03:57.773
un propósito divino
de construir una sociedad utópica,

00:03:57.797 --> 00:03:59.718
si sus metas pueden ser alcanzadas,

00:03:59.742 --> 00:04:02.487
pero también un sentido de 
empoderamiento y de aventura.

00:04:02.487 --> 00:04:05.220
Cuando vemos a los combatientes
terroristas extranjeros,

00:04:05.220 --> 00:04:07.605
vemos a jóvenes 
con cabellos ondeados al viento

00:04:07.605 --> 00:04:09.845
en el desierto
y a las mujeres que se les unen

00:04:09.869 --> 00:04:12.510
para casarse en el atardecer.

00:04:12.534 --> 00:04:16.354
Es muy romántico,
y te conviertes en un héroe.

00:04:16.378 --> 00:04:19.266
Para ambos hombres y mujeres,
así es la propaganda.

00:04:19.667 --> 00:04:22.309
Los grupos extremistas son muy buenos

00:04:22.333 --> 00:04:27.159
tomando un mundo muy complicado,
confuso y matizado,

00:04:27.183 --> 00:04:30.426
y simplificarlo en blanco y negro,

00:04:30.450 --> 00:04:31.660
el mal y el bien.

00:04:31.684 --> 00:04:33.565
Y te conviertes en lo que es bueno,

00:04:33.589 --> 00:04:35.444
desafiando lo que es malo.

00:04:36.541 --> 00:04:40.405
Quiero hablar un poco de ISIS, Daesh,

00:04:40.429 --> 00:04:44.807
porque han sido revolucionarios
en cómo vemos estos procesos,

00:04:44.831 --> 00:04:48.037
a través de sus materiales y sus tácticas.

00:04:48.061 --> 00:04:50.609
Son en todo sentido un movimiento moderno.

00:04:50.925 --> 00:04:55.410
Un aspecto es internet
y el uso de redes sociales,

00:04:55.434 --> 00:04:59.816
como ya hemos visto en 
tuits y videos de decapitaciones.

00:04:59.840 --> 00:05:02.315
Pero internet por sí solo 
no te radicaliza.

00:05:02.339 --> 00:05:03.546
Es una herramienta.

00:05:03.570 --> 00:05:05.426
No vas a comprar zapatos en línea

00:05:05.450 --> 00:05:07.248
y accidentalmente te haces jihadista.

00:05:07.793 --> 00:05:11.182
No obstante, lo que sí hace internet
es ser un catalizador.

00:05:11.206 --> 00:05:15.325
Ofrece herramientas, escala y rapidez

00:05:15.349 --> 00:05:16.857
que no existen en otro lado.

00:05:16.881 --> 00:05:19.342
Y con ISIS de pronto

00:05:19.366 --> 00:05:24.684
esta idea de un jihadista como una figura
oscura y sombría cambió para nosotros.

00:05:24.708 --> 00:05:26.763
De repente nos encontrábamos
en sus cocinas.

00:05:26.787 --> 00:05:28.786
Veíamos lo que comían para la cena.

00:05:28.810 --> 00:05:29.961
Estaban tuiteando.

00:05:29.985 --> 00:05:33.303
Había guerreros terroristas foráneos 
tuiteando en su propia lengua.

00:05:33.303 --> 00:05:36.119
Teníamos mujeres ahí 
hablando de sus bodas,

00:05:36.143 --> 00:05:37.890
del nacimiento de sus hijos.

00:05:37.914 --> 00:05:39.811
Teníamos una cultura de videojuegos

00:05:39.835 --> 00:05:43.001
y referencias al Grand Theft Auto.

00:05:43.471 --> 00:05:45.932
Así que, de pronto, eran familiares.

00:05:45.956 --> 00:05:47.107
Eran humanos.

00:05:47.131 --> 00:05:49.345
Y el problema es que, 
para contrarrestarlos,

00:05:49.369 --> 00:05:51.679
muchos gobiernos 
y compañías de redes sociales

00:05:51.703 --> 00:05:52.838
intentaron censurarlos.

00:05:52.838 --> 00:05:54.899
¿Cómo deshacernos
del contenido terrorista?

00:05:54.899 --> 00:05:56.858
Se volvió un juego del gato y del ratón

00:05:56.858 --> 00:05:59.936
donde las cuentas que se cerraban 
rápidamente volvían a surgir,

00:05:59.936 --> 00:06:02.913
y la arrogancia de quien
presumía su vigésima quinta cuenta

00:06:02.937 --> 00:06:06.031
y material diseminado por doquier.

00:06:06.055 --> 00:06:08.076
Pero también vimos 
una tendencia peligrosa

00:06:08.100 --> 00:06:13.108
pues los extremistas violentos también 
conocen las reglas de las redes sociales.

00:06:13.132 --> 00:06:17.132
Veíamos una conversación
banal con un reclutador

00:06:17.156 --> 00:06:19.129
empezar en una plataforma convencional

00:06:19.153 --> 00:06:21.234
y en el punto en que esa conversación

00:06:21.258 --> 00:06:22.598
estaba por tornarse ilegar,

00:06:22.622 --> 00:06:25.233
cambiaban a una plataforma 
más pequeña, menos regulada

00:06:25.233 --> 00:06:26.770
y más encriptada.

00:06:26.794 --> 00:06:30.327
Así que de pronto no podíamos 
rastrear el avance de esa conversación.

00:06:30.351 --> 00:06:32.213
Este es un problema con la censura,

00:06:32.237 --> 00:06:35.469
y por ello tenemos que desarrollar
alternativas a la censura.

00:06:36.035 --> 00:06:39.385
ISIS también es distinto porque
está construyendo un estado.

00:06:39.409 --> 00:06:41.505
No sólo recluta combatientes,

00:06:41.505 --> 00:06:43.407
está intentando construir una nación.

00:06:43.431 --> 00:06:45.371
Y eso significa que repentinamente,

00:06:45.395 --> 00:06:47.395
tu modelo de reclutamiento es más amplio.

00:06:47.419 --> 00:06:49.468
No sólo tratas de conseguir combatientes,

00:06:49.492 --> 00:06:53.758
necesitas arquitectos, ingenieros,
contadores, hackers y mujeres.

00:06:53.782 --> 00:06:56.172
Hemos visto crecer el número de mujeres

00:06:56.196 --> 00:06:59.695
en los últimos 24, pero especialmente 
en los últimos 12 meses.

00:06:59.719 --> 00:07:02.608
En algunos países una de cada 
cuatro personas que se afilian

00:07:02.632 --> 00:07:03.871
son mujeres.

00:07:03.895 --> 00:07:05.263
Y entonces, esto cambia

00:07:05.287 --> 00:07:08.069
hacia quién intentamos
contrarrestrar en este proceso.

00:07:08.679 --> 00:07:10.330
Ahora bien, no todo es negro.

00:07:10.354 --> 00:07:13.314
Lo que quisiera ahora es hablar
de algunas cosas positivas

00:07:13.338 --> 00:07:17.182
y la innovación en prevención
y contraataque de violencia extremista.

00:07:17.206 --> 00:07:19.479
Prevenir es muy distinto a contraatacar,

00:07:19.503 --> 00:07:22.059
y de hecho, hay que pensarlo
en términos médicos.

00:07:22.083 --> 00:07:24.305
La medicina preventiva es

00:07:24.329 --> 00:07:27.503
cómo hacer que simplemente 
seamos resilientes

00:07:27.527 --> 00:07:30.027
a este proceso de radicalización.

00:07:30.051 --> 00:07:31.913
Y eso será diferente

00:07:31.937 --> 00:07:34.596
si alguien ya muestra 
síntomas o una señal

00:07:34.620 --> 00:07:37.195
de pertenecer a una ideología
extremista violenta.

00:07:37.195 --> 00:07:39.072
Y así en cuanto a medidas preventivas,

00:07:39.096 --> 00:07:41.787
hablamos de grupos
más extensos de gente

00:07:41.811 --> 00:07:43.628
y exponerlos a ideas

00:07:43.652 --> 00:07:45.419
para hacerlos resilientes.

00:07:45.443 --> 00:07:46.959
Aunque es muy distinto

00:07:46.983 --> 00:07:50.808
si alguien comienza a cuestionar o estar 
de acuerdo con ciertas cosas en línea,

00:07:50.832 --> 00:07:54.681
y también es distinto a quien
ya tiene un tatuaje con la esvástica

00:07:54.705 --> 00:07:56.753
y está muy incorporado en un grupo.

00:07:56.777 --> 00:07:58.211
¿Cómo llegas a esa gente?

00:07:58.785 --> 00:08:02.467
Me gustaría repasar tres ejemplos
de cada uno de estos niveles

00:08:02.491 --> 00:08:03.706
y explicarles

00:08:03.730 --> 00:08:07.046
cuáles son algunos métodos nuevos
para incorporar a esta gente.

00:08:07.374 --> 00:08:08.787
Uno es 'Diálogo extremo',

00:08:08.811 --> 00:08:11.891
y es un programa educativo
que ayudamos a desarrollar.

00:08:11.915 --> 00:08:14.296
Este es de Canadá,

00:08:14.320 --> 00:08:18.415
y tiene como objetivo crear diálogos
dentro del marco del aula de clases,

00:08:18.439 --> 00:08:19.971
utilizando la narrativa,

00:08:19.995 --> 00:08:23.146
porque la violencia extremista
puede ser difícil de explicar,

00:08:23.170 --> 00:08:24.869
sobre todo a los más jóvenes.

00:08:25.305 --> 00:08:29.218
Así que tenemos una red de exfanáticos
y sobrevivientes del extremismo

00:08:29.242 --> 00:08:33.179
que cuentan sus historias utilizando video
y formulan cuestionarios en el aula,

00:08:33.203 --> 00:08:35.506
para iniciar una conversación del tema.

00:08:35.530 --> 00:08:38.062
Estos dos ejemplos muestran a Christianne,

00:08:38.086 --> 00:08:39.237
que perdió a su hijo,

00:08:39.261 --> 00:08:41.754
quien se radicalizó y murió
luchando por ISIS.

00:08:41.778 --> 00:08:43.445
Y Daniel es un exneonazi

00:08:43.469 --> 00:08:45.827
extremadamente violento,

00:08:45.851 --> 00:08:50.009
y se cuestionan sobre sus vidas
y dónde están ahora y qué lamentan,

00:08:50.033 --> 00:08:52.683
y obligan al aula
a tener un diálogo al respecto.

00:08:53.175 --> 00:08:56.160
Ahora, enfocándonos en
la media de los individuos,

00:08:56.184 --> 00:08:59.003
de hecho, necesitamos mucho
las voces de la sociedad civil.

00:08:59.003 --> 00:09:02.352
¿Cómo interactúas con personas
que están buscando información en línea,

00:09:02.376 --> 00:09:04.718
que están considerando una ideología,

00:09:04.742 --> 00:09:07.806
que hacen esas preguntas 
escrutadoras sobre su identidad?

00:09:07.830 --> 00:09:09.972
¿Cómo les ofrecemos alternativas?

00:09:09.996 --> 00:09:13.386
Y es ahí donde combinamos 
las voces de grupos sociales

00:09:13.410 --> 00:09:17.941
con creativos, tecnólogos,
artistas, comediantes,

00:09:17.965 --> 00:09:20.648
para poder crear contenido 
muy específico

00:09:20.672 --> 00:09:24.966
y, en línea, diseminarlo
entre audiencias estratégicas.

00:09:24.990 --> 00:09:27.843
Un ejemplo sería crear 
un video satírico

00:09:27.843 --> 00:09:30.316
que se burle de la islamofobia,

00:09:30.330 --> 00:09:34.080
y dirigirlo a jóvenes de entre
15 y 20 años que estén en línea

00:09:34.080 --> 00:09:36.587
interesados en música
afín a la supremacía blanca

00:09:36.587 --> 00:09:38.970
y que viven específicamente en Manchester.

00:09:38.994 --> 00:09:42.025
Podemos utilizar estas herramientas
para ser muy específicos,

00:09:42.049 --> 00:09:44.772
y saber cuándo alguien está
viendo, observando

00:09:44.796 --> 00:09:46.285
y simpatizando con el contenido

00:09:46.309 --> 00:09:48.939
no es una persona común, 
no somos ni tú ni yo,

00:09:48.963 --> 00:09:52.070
es una audiencia muy específica
que buscamos captar.

00:09:52.704 --> 00:09:56.403
Aún más profundo, desarrollamos
un programa piloto llamado "Uno a uno",

00:09:56.427 --> 00:09:57.976
donde tomamos a exradicales

00:09:58.000 --> 00:10:02.864
y ellos contactaron directamente
a un grupo que se consideraba neofascista

00:10:02.888 --> 00:10:04.512
así como extremista islámico,

00:10:04.536 --> 00:10:08.351
y con Facebook Messanger pusimos
mensajes en sus bandejas de entrada

00:10:08.375 --> 00:10:10.661
diciendo: "Oye, sé a dónde vas,
yo he estado ahí,

00:10:10.685 --> 00:10:12.227
aquí estoy si quieres hablar."

00:10:12.251 --> 00:10:15.505
En realidad esperábamos amenazas 
de muerte con estas interacciones.

00:10:15.529 --> 00:10:19.949
Es un poco alarmante tener a un exneonazi 
diciéndote: "¿Cómo estás?"

00:10:19.973 --> 00:10:22.180
Pero de hecho vimos 
que alrededor del 60 %

00:10:22.204 --> 00:10:24.758
de las personas contactadas contestaron,

00:10:24.782 --> 00:10:28.867
y de ellas, otro 60 %
mantuvo el contacto,

00:10:28.891 --> 00:10:30.947
es decir que estaban conversando

00:10:30.971 --> 00:10:34.187
con los más difíciles de alcanzar
sobre lo que estaban viviendo,

00:10:34.211 --> 00:10:35.362
plantando la duda

00:10:35.386 --> 00:10:38.378
y dándoles alternativas
para hablar de estos temas,

00:10:38.402 --> 00:10:39.752
y eso es muy importante.

00:10:41.061 --> 00:10:43.284
Lo que estamos intentando hacer

00:10:43.308 --> 00:10:46.213
es traer a la mesa 
a sectores insólitos.

00:10:46.237 --> 00:10:48.563
Tenemos activistas increíbles
en todo el mundo,

00:10:48.587 --> 00:10:50.953
pero a menudo,
sus mensajes no son estratégicos

00:10:50.977 --> 00:10:53.587
o no alcanzan los foros
que quieren alcanzar.

00:10:53.587 --> 00:10:56.146
Así que trabajamos con redes
de antiguos extremistas.

00:10:56.170 --> 00:10:59.599
Trabajamos con redes de jóvenes
en diferentes partes del mundo.

00:10:59.623 --> 00:11:02.393
Y trabajamos para traer 
el sector tecnológico a la mesa

00:11:02.417 --> 00:11:05.235
con artistas y creativos
y expertos en mercadotecnia

00:11:05.259 --> 00:11:10.260
para que podamos tener un desafío
más robusto contra el extremismo

00:11:10.284 --> 00:11:11.584
que funcione.

00:11:12.074 --> 00:11:14.654
Así que si estás en el público

00:11:14.678 --> 00:11:17.377
y casualmente eres un 
diseñador gráfico,

00:11:17.401 --> 00:11:19.583
un poeta, un experto en mercadotecnia,

00:11:19.607 --> 00:11:21.516
alguien que trabaja en RRPP,

00:11:21.540 --> 00:11:22.893
un comediante

00:11:22.917 --> 00:11:25.068
puedes creer o no que este es tu lugar,

00:11:25.092 --> 00:11:27.831
pero en realidad, el talento
que tienes ahora

00:11:27.855 --> 00:11:29.858
puede ser exactamente 
lo que se necesita

00:11:29.882 --> 00:11:32.191
para combatir efectivamente 
el extremismo.

00:11:32.215 --> 00:11:33.366
Gracias

00:11:33.390 --> 00:11:37.603
(Aplausos)

