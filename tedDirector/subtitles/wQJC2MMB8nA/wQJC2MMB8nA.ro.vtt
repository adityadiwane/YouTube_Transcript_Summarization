WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Laszlo Kereszturi
Corector: Magda Marcu

00:00:15.260 --> 00:00:17.260
Securitatea înseamnă două lucruri diferite:

00:00:17.260 --> 00:00:19.260
este o senzație și este o realitate.

00:00:19.260 --> 00:00:21.260
Iar ele sunt diferite.

00:00:21.260 --> 00:00:23.260
Poți să te simți în siguranță

00:00:23.260 --> 00:00:25.260
chiar dacă nu ești.

00:00:25.260 --> 00:00:27.260
Și poți fi în siguranță

00:00:27.260 --> 00:00:29.260
chiar dacă nu simți asta.

00:00:29.260 --> 00:00:31.260
Chiar avem două concepte separate

00:00:31.260 --> 00:00:33.260
mapate în același cuvânt.

00:00:33.260 --> 00:00:35.260
Și ce vreau să fac în acest discurs

00:00:35.260 --> 00:00:37.260
e să le separ una de alta --

00:00:37.260 --> 00:00:39.260
înțelegând când diverg ele

00:00:39.260 --> 00:00:41.260
și cum converg ele.

00:00:41.260 --> 00:00:43.260
Iar limba chiar este o problemă aici.

00:00:43.260 --> 00:00:45.260
Nu există prea multe cuvinte potrivite

00:00:45.260 --> 00:00:48.260
pentru conceptele despre care vom vorbi.

00:00:48.260 --> 00:00:50.260
Deci dacă privești securitatea

00:00:50.260 --> 00:00:52.260
din punct de vedere economic,

00:00:52.260 --> 00:00:54.260
ea este un troc.

00:00:54.260 --> 00:00:56.260
De fiecare dată când obții ceva securitate,

00:00:56.260 --> 00:00:58.260
întotdeauna dai ceva în schimb.

00:00:58.260 --> 00:01:00.260
Fie că asta este o decizie personală --

00:01:00.260 --> 00:01:02.260
instalezi o alarmă antifurt acasă --

00:01:02.260 --> 00:01:05.260
sau o decizie națională -- când vei invada o țară străină --

00:01:05.260 --> 00:01:07.260
vei da ceva la schimb,

00:01:07.260 --> 00:01:10.260
fie bani sau timp, confort, posibilități,

00:01:10.260 --> 00:01:13.260
poate libertăți fundamentale.

00:01:13.260 --> 00:01:16.260
Iar întrebarea care trebuie pusă când examinezi ceva de securitate

00:01:16.260 --> 00:01:19.260
nu este dacă asta ne aduce mai multă siguranță,

00:01:19.260 --> 00:01:22.260
ci dacă schimbul a meritat sau nu.

00:01:22.260 --> 00:01:24.260
Ați auzit în ultimii câțiva ani,

00:01:24.260 --> 00:01:26.260
că lumea este mai sigură fiindcă Saddam Hussein nu mai este la putere.

00:01:26.260 --> 00:01:29.260
Poate că este adevărat, dar nu este foarte relevant.

00:01:29.260 --> 00:01:32.260
Întrebarea este: a meritat?

00:01:32.260 --> 00:01:35.260
Și poți decide singur, iar apoi

00:01:35.260 --> 00:01:37.260
vei decide dacă invazia a meritat.

00:01:37.260 --> 00:01:39.260
Așa trebuie să gândești despre securitate --

00:01:39.260 --> 00:01:41.260
în termeni de schimb.

00:01:41.260 --> 00:01:44.260
De multe ori nu există răspuns corect sau greșit.

00:01:44.260 --> 00:01:46.260
Unii din noi avem alarme în casele noastre,

00:01:46.260 --> 00:01:48.260
iar unii din noi nu avem.

00:01:48.260 --> 00:01:50.260
Și asta depinde de unde trăim,

00:01:50.260 --> 00:01:52.260
dacă trăim singuri sau avem o familie,

00:01:52.260 --> 00:01:54.260
cât de multe lucruri grozave avem,

00:01:54.260 --> 00:01:56.260
cât de mult dorim să acceptăm

00:01:56.260 --> 00:01:58.260
riscul furtului.

00:01:58.260 --> 00:02:00.260
În politică de asemenea

00:02:00.260 --> 00:02:02.260
sunt opinii diferite.

00:02:02.260 --> 00:02:04.260
De multe ori aceste schimburi

00:02:04.260 --> 00:02:06.260
sunt despre mai mult decât securitate,

00:02:06.260 --> 00:02:08.260
și cred că asta este foarte important.

00:02:08.260 --> 00:02:10.260
Oamenii au o intuiție înnăscută

00:02:10.260 --> 00:02:12.260
despre aceste schimburi.

00:02:12.260 --> 00:02:14.260
Le facem zilnic --

00:02:14.260 --> 00:02:16.260
noaptea trecută în camera mea de hotel,

00:02:16.260 --> 00:02:18.260
când am decis să încui ușa de două ori,

00:02:18.260 --> 00:02:20.260
sau voi în mașinile cu care ați venit aici,

00:02:20.260 --> 00:02:22.260
când mergem la prânz

00:02:22.260 --> 00:02:25.260
și decidem că hrana nu este otravă și o vom mânca.

00:02:25.260 --> 00:02:27.260
Facem aceste schimburi iar și iar

00:02:27.260 --> 00:02:29.260
de mai multe ori pe zi.

00:02:29.260 --> 00:02:31.260
Adesea nici nu le observăm.

00:02:31.260 --> 00:02:33.260
Ele sunt parte a vieții, toți o facem.

00:02:33.260 --> 00:02:36.260
Fiecare specie o face.

00:02:36.260 --> 00:02:38.260
Imaginați-vă un iepure în câmp, mâncând iarba,

00:02:38.260 --> 00:02:41.260
și iepurele vede o vulpe.

00:02:41.260 --> 00:02:43.260
Iepurele va face un schimb de securitate.

00:02:43.260 --> 00:02:45.260
"Să stau sau să fug?"

00:02:45.260 --> 00:02:47.260
Și dacă vă gândiți la asta,

00:02:47.260 --> 00:02:50.260
iepurii care sunt buni la aceste schimburi

00:02:50.260 --> 00:02:52.260
vor tinde să trăiască și să se reproducă,

00:02:52.260 --> 00:02:54.260
iar iepurii care nu sunt buni la asta

00:02:54.260 --> 00:02:56.260
vor fi mâncați sau vor muri de foame.

00:02:56.260 --> 00:02:58.260
Deci ați gândi că noi,

00:02:58.260 --> 00:03:01.260
ca o specie de succes a planetei --

00:03:01.260 --> 00:03:03.260
voi, eu, toți --

00:03:03.260 --> 00:03:06.260
am fi foarte buni în a face aceste schimburi.

00:03:06.260 --> 00:03:08.260
Cu toate acestea se pare că, iar și iar,

00:03:08.260 --> 00:03:11.260
suntem foarte nepricepuți în asta.

00:03:11.260 --> 00:03:14.260
Și eu cred că asta este o întrebare fundamental interesantă.

00:03:14.260 --> 00:03:16.260
Vă voi da răspunsul scurt.

00:03:16.260 --> 00:03:18.260
Răspunsul este că răspundem la senzația de securitate

00:03:18.260 --> 00:03:21.260
și nu la realitate.

00:03:21.260 --> 00:03:24.260
În majoritatea cazurilor asta merge.

00:03:25.260 --> 00:03:27.260
În majoritatea cazurilor,

00:03:27.260 --> 00:03:30.260
senzația și realitatea sunt identice.

00:03:30.260 --> 00:03:32.260
În mod cert asta este adevărat

00:03:32.260 --> 00:03:35.260
pentru majoritatea preistoriei umane.

00:03:35.260 --> 00:03:38.260
Am dezvoltat această abilitate

00:03:38.260 --> 00:03:40.260
fiindcă are sens din puct de vedere evoluționar.

00:03:40.260 --> 00:03:42.260
Un mod de a gândi la asta

00:03:42.260 --> 00:03:44.260
este că suntem extrem de optimizați

00:03:44.260 --> 00:03:46.260
pentru decizii de risc

00:03:46.260 --> 00:03:49.260
tipice vieții în mici grupuri familiale

00:03:49.260 --> 00:03:52.260
în savana africană din anul 100.000 î.H. --

00:03:52.260 --> 00:03:55.260
dar nu așa de mult pentru anul 2010, în New York.

00:03:56.260 --> 00:03:59.260
Există mai multe predispoziţii în perceperea riscului.

00:03:59.260 --> 00:04:01.260
Există o mulțime de experimente bune pentru asta.

00:04:01.260 --> 00:04:04.260
Și poți observa anumite predispoziţii care apar din nou și din nou.

00:04:04.260 --> 00:04:06.260
Vă voi da patru.

00:04:06.260 --> 00:04:09.260
Tindem să exagerăm riscurile spectaculoase și rare

00:04:09.260 --> 00:04:11.260
și să desconsiderăm riscurile comune --

00:04:11.260 --> 00:04:14.260
de ex. a zbura comparat cu a conduce.

00:04:14.260 --> 00:04:16.260
Necunoscutul este perceput

00:04:16.260 --> 00:04:19.260
a fi mai riscant decât cunoscutul.

00:04:20.260 --> 00:04:22.260
Un exemplu ar fi,

00:04:22.260 --> 00:04:25.260
oamenilor le e teamă de străinii care răpesc copii,

00:04:25.260 --> 00:04:28.260
când datele susțin că răpirea de către rude este mult mai comună.

00:04:28.260 --> 00:04:30.260
Asta este pentru copii.

00:04:30.260 --> 00:04:33.260
Trei, riscurile personificate

00:04:33.260 --> 00:04:36.260
sunt percepute a fi mai mari decât riscurile anonime --

00:04:36.260 --> 00:04:39.260
deci Bin Laden este mai înspăimântător fiindcă are un nume.

00:04:39.260 --> 00:04:41.260
Și a patra

00:04:41.260 --> 00:04:43.260
este că oamenii subestimează riscurile

00:04:43.260 --> 00:04:45.260
în situații pe care le controlează

00:04:45.260 --> 00:04:49.260
și le supraestimează în situații pe care nu le controlează.

00:04:49.260 --> 00:04:52.260
Deci odată ce te-ai apucat de sărituri cu parașuta sau de fumat,

00:04:52.260 --> 00:04:54.260
desconsideri riscurile.

00:04:54.260 --> 00:04:57.260
Dacă ți se impune un risc cu forța -- terorismul a fost un bun exemplu --

00:04:57.260 --> 00:05:00.260
îl vei exagera, fiindcă simți că nu este sub controlul tău.

00:05:02.260 --> 00:05:05.260
Există o mulțime de alte predispoziţii, aceste predispoziţii cognitive,

00:05:05.260 --> 00:05:08.260
care afectează deciziile noastre de risc.

00:05:08.260 --> 00:05:10.260
Este heuristica disponibilității,

00:05:10.260 --> 00:05:12.260
care de fapt înseamnă

00:05:12.260 --> 00:05:15.260
că estimăm probabilitatea a ceva

00:05:15.260 --> 00:05:19.260
prin cât de ușor ne imaginăm instanțele ei.

00:05:19.260 --> 00:05:21.260
Puteți să vă imaginați cum funcționează asta.

00:05:21.260 --> 00:05:24.260
Dacă auziți mult despre atacuri de tigri, trebuie să fie mulți tigri în jur.

00:05:24.260 --> 00:05:27.260
Nu auziți despre atacuri de lei, deci nu sunt mulți lei în jur.

00:05:27.260 --> 00:05:30.260
Asta funcționează până inventezi ziarele.

00:05:30.260 --> 00:05:32.260
Fiindcă ziarele

00:05:32.260 --> 00:05:34.260
repetă din nou și din nou

00:05:34.260 --> 00:05:36.260
riscurile rare.

00:05:36.260 --> 00:05:38.260
Eu le spun oamenilor: dacă este în știri, nu te îngrijora.

00:05:38.260 --> 00:05:40.260
Fiindcă prin definiție,

00:05:40.260 --> 00:05:43.260
știrea este ceva care se întâmplă foarte rar.

00:05:43.260 --> 00:05:45.260
(Râsete)

00:05:45.260 --> 00:05:48.260
Când ceva este așa de comun. nu mai apare în știri --

00:05:48.260 --> 00:05:50.260
accidente de mașină, violența domestică --

00:05:50.260 --> 00:05:53.260
acelea sunt riscurile pentru care să te îngrijorezi.

00:05:53.260 --> 00:05:55.260
Suntem de asemenea o specie de povestitori.

00:05:55.260 --> 00:05:58.260
Răspundem mai mult la povești, decât la date.

00:05:58.260 --> 00:06:00.260
Și există o lipsă de știință în aprecierea numerelor.

00:06:00.260 --> 00:06:03.260
Adică bancul: "Una, două, trei, multe" pare să fie adevărat.

00:06:03.260 --> 00:06:06.260
Suntem foarte buni la numere mici.

00:06:06.260 --> 00:06:08.260
Un mango, două mango, trei mango,

00:06:08.260 --> 00:06:10.260
însă 10,000 de mango, 100,000 mango --

00:06:10.260 --> 00:06:13.260
sunt totuși mai multe mango decât poți mânca înainte de a putrezi.

00:06:13.260 --> 00:06:16.260
Deci o jumătate, un sfert, o cincime -- suntem buni la asta.

00:06:16.260 --> 00:06:18.260
Unul dintr-un milion, unul dintr-un miliard --

00:06:18.260 --> 00:06:21.260
ambele sunt aproape ca niciodată.

00:06:21.260 --> 00:06:23.260
Așa că avem problemă cu riscurile

00:06:23.260 --> 00:06:25.260
care nu sunt foarte comune.

00:06:25.260 --> 00:06:27.260
Iar aceste predispoziţii cognitive

00:06:27.260 --> 00:06:30.260
acționează ca niște filtre între noi și realitate.

00:06:30.260 --> 00:06:32.260
Și rezultatul

00:06:32.260 --> 00:06:34.260
este că senzația și realitatea ies din sincron,

00:06:34.260 --> 00:06:37.260
ajung diferite.

00:06:37.260 --> 00:06:40.260
Fie ai o senzație -- te simți mai sigur decât ești în realitate.

00:06:40.260 --> 00:06:42.260
Este o falsă senzație de securitate.

00:06:42.260 --> 00:06:44.260
Sau invers,

00:06:44.260 --> 00:06:46.260
și atunci este o falsă senzație de insecuritate.

00:06:46.260 --> 00:06:49.260
Scriu mult despre "scena securității",

00:06:49.260 --> 00:06:52.260
care sunt produsele care îi fac pe oamenii să se simtă în siguranță,

00:06:52.260 --> 00:06:54.260
dar de fapt nu fac ceva util.

00:06:54.260 --> 00:06:56.260
Nu există cuvânt pentru lucrurile care ne asigură securitatea,

00:06:56.260 --> 00:06:58.260
dar nu ne fac să ne simțim mai în siguranță.

00:06:58.260 --> 00:07:01.260
Poate asta ar trebui să facă CIA pentru noi.

00:07:03.260 --> 00:07:05.260
Deci înapoi la economie.

00:07:05.260 --> 00:07:09.260
Dacă economia, dacă piața, dirijează securitatea,

00:07:09.260 --> 00:07:11.260
și dacă oamenii fac schimburi

00:07:11.260 --> 00:07:14.260
bazate pe senzația de securitate,

00:07:14.260 --> 00:07:16.260
atunci companiile trebuie să facă

00:07:16.260 --> 00:07:18.260
oamenii să se simtă în siguranță

00:07:18.260 --> 00:07:21.260
pentru a culege recompensele economice.

00:07:21.260 --> 00:07:24.260
Și sunt două căi de a face asta.

00:07:24.260 --> 00:07:26.260
Prima, poți asigura securitatea omenilor

00:07:26.260 --> 00:07:28.260
și speri că vor observa.

00:07:28.260 --> 00:07:31.260
Sau a doua, poți să-i faci pe oameni să se simtă în siguranță

00:07:31.260 --> 00:07:34.260
și speri că nu vor observa.

00:07:35.260 --> 00:07:38.260
Deci ce-i face pe oameni să observe?

00:07:38.260 --> 00:07:40.260
Câteva lucruri:

00:07:40.260 --> 00:07:42.260
înțelegerea securității,

00:07:42.260 --> 00:07:44.260
a riscurilor, a amenințărilor,

00:07:44.260 --> 00:07:47.260
a contramăsurilor, cum funcționează ele.

00:07:47.260 --> 00:07:49.260
Dar dacă știi lucrurile,

00:07:49.260 --> 00:07:52.260
este mai probabil ca senzațiile tale să se potrivească cu realitatea.

00:07:52.260 --> 00:07:55.260
Multe exemple din lumea reală ne pot ajuta.

00:07:55.260 --> 00:07:58.260
Știm cu toții despre rata crimelor din cartierul nostru,

00:07:58.260 --> 00:08:01.260
fiindcă trăim acolo și avem o atitudine față de asta,

00:08:01.260 --> 00:08:04.260
senzație care de fapt se potrivește cu realitatea.

00:08:04.260 --> 00:08:07.260
Spectacolul de securitate este dezvăluit

00:08:07.260 --> 00:08:10.260
când este evident că nu funționează corect.

00:08:10.260 --> 00:08:14.260
În regulă, deci ce-i face pe oameni să nu observe?

00:08:14.260 --> 00:08:16.260
Ei bine, o slabă înțelegere.

00:08:16.260 --> 00:08:19.260
Dacă nu înțelegi riscurile, nu înțelegi costurile,

00:08:19.260 --> 00:08:21.260
vei face probabil schimbul greșit,

00:08:21.260 --> 00:08:24.260
și senzația ta nu se va potrivi cu realitatea.

00:08:24.260 --> 00:08:26.260
Nu sunt destule exemple.

00:08:26.260 --> 00:08:28.260
Este o problemă inerentă

00:08:28.260 --> 00:08:30.260
cu evenimentele de mică probabilitate.

00:08:30.260 --> 00:08:32.260
Dacă, de exemplu,

00:08:32.260 --> 00:08:34.260
terorismul se întâmplă foarte rar,

00:08:34.260 --> 00:08:36.260
este foarte greu de judecat

00:08:36.260 --> 00:08:39.260
eficacitatea măsurilor antiteroriste.

00:08:40.260 --> 00:08:43.260
De asta continui să sacrifici fecioare,

00:08:43.260 --> 00:08:46.260
și de asta funcționează așa de minunat apărarea ta bazată pe inorogi.

00:08:46.260 --> 00:08:49.260
Nu sunt destule exemple de eșecuri.

00:08:50.260 --> 00:08:53.260
De asemenea, sentimentele care obturează problemele --

00:08:53.260 --> 00:08:55.260
predispoziţiile cognitive despre care am vorbit înainte,

00:08:55.260 --> 00:08:58.260
temeri, credințe populare,

00:08:58.260 --> 00:09:01.260
de fapt un model neadecvat al realității.

00:09:02.260 --> 00:09:05.260
Permiteți-mi să complic lucrurile.

00:09:05.260 --> 00:09:07.260
Am senzație și realitate.

00:09:07.260 --> 00:09:10.260
Vreau să adaug un al treilea element. Vreau să adaug modelul.

00:09:10.260 --> 00:09:12.260
Senzația și modelul este în capul nostru,

00:09:12.260 --> 00:09:14.260
realitatea este lumea din jur.

00:09:14.260 --> 00:09:17.260
Ea nu se schimbă; este reală.

00:09:17.260 --> 00:09:19.260
Senzația este bazată pe intuiția noastră.

00:09:19.260 --> 00:09:21.260
Modelul este bazat pe raționament.

00:09:21.260 --> 00:09:24.260
Asta este de fapt diferența.

00:09:24.260 --> 00:09:26.260
Într-o lume primitivă și simplă,

00:09:26.260 --> 00:09:29.260
chiar nu este nevoie de un model.

00:09:29.260 --> 00:09:32.260
Fiindcă senzația este aproape de realitate.

00:09:32.260 --> 00:09:34.260
Nu ai nevoie de un model.

00:09:34.260 --> 00:09:36.260
Dar într-o lume modernă și complexă,

00:09:36.260 --> 00:09:38.260
ai nevoie de modele

00:09:38.260 --> 00:09:41.260
pentru a înțelege mulțimea de riscuri care există.

00:09:42.260 --> 00:09:44.260
Nu există senzație despre microbi.

00:09:44.260 --> 00:09:47.260
Ai nevoie de un model pentru a-i înțelege.

00:09:47.260 --> 00:09:49.260
Deci acest model

00:09:49.260 --> 00:09:52.260
este o reprezentare inteligentă a realității.

00:09:52.260 --> 00:09:55.260
Este desigur limitat de știință,

00:09:55.260 --> 00:09:57.260
de tehnologie.

00:09:57.260 --> 00:10:00.260
Nu am putut avea o teorie a bolilor bazată pe microbi

00:10:00.260 --> 00:10:03.260
înainte de inventarea microscopului pentru a le vedea.

00:10:04.260 --> 00:10:07.260
Este limitat de predispoziţiile noastre cognitive.

00:10:07.260 --> 00:10:09.260
Dar are abilitatea

00:10:09.260 --> 00:10:11.260
de a suprascrie senzațiile noastre.

00:10:11.260 --> 00:10:14.260
De unde avem aceste modele? Le avem de la alții.

00:10:14.260 --> 00:10:17.260
Le avem din religie, cultură,

00:10:17.260 --> 00:10:19.260
profesori, strămoși.

00:10:19.260 --> 00:10:21.260
Cu câțiva ani în urmă,

00:10:21.260 --> 00:10:23.260
am fost în Africa de sud la un safari.

00:10:23.260 --> 00:10:26.260
Călăuza cu care am fost a crescut în Parcul Național Kruger.

00:10:26.260 --> 00:10:29.260
El avea niște modele foarte complexe despre cum să supraviețuiești.

00:10:29.260 --> 00:10:31.260
Iar asta depindea dacă te ataca

00:10:31.260 --> 00:10:33.260
un leu sau un leopard sau un rinocer sau un elefant --

00:10:33.260 --> 00:10:36.260
și când trebuie să fugi, și când trebuie să te urci într-un copac --

00:10:36.260 --> 00:10:38.260
și când nu trebuie să te urci într-un copac.

00:10:38.260 --> 00:10:41.260
Eu aș fi murit într-o singură zi,

00:10:41.260 --> 00:10:43.260
dar el s-a născut acolo,

00:10:43.260 --> 00:10:45.260
și înțelegea cum să supraviețuiești.

00:10:45.260 --> 00:10:47.260
Eu m-am născut în New York City.

00:10:47.260 --> 00:10:50.260
Dacă l-aș fi luat cu mine în New York, atunci el ar fi murit într-o singură zi.

00:10:50.260 --> 00:10:52.260
(Râsete)

00:10:52.260 --> 00:10:54.260
Fiindcă aveam modele diferite

00:10:54.260 --> 00:10:57.260
bazate pe experiențele noastre diferite.

00:10:58.260 --> 00:11:00.260
Modelele pot veni din massmedia,

00:11:00.260 --> 00:11:03.260
de la aleșii noștri oficiali.

00:11:03.260 --> 00:11:06.260
Gândiți-vă la modele de terorism,

00:11:06.260 --> 00:11:09.260
răpiri de copii,

00:11:09.260 --> 00:11:11.260
siguranța zborului, siguranța mașinii.

00:11:11.260 --> 00:11:14.260
Modelele pot veni din industrie.

00:11:14.260 --> 00:11:16.260
Cele două pe care la urmăresc sunt camerele de supraveghere,

00:11:16.260 --> 00:11:18.260
cardurile de identitate,

00:11:18.260 --> 00:11:21.260
destul de multe din modelele de securitatea calculatoarelor vin de acolo.

00:11:21.260 --> 00:11:24.260
O mulțime de modele vin din știință.

00:11:24.260 --> 00:11:26.260
Modelele de sănătate sunt un exemplu grozav.

00:11:26.260 --> 00:11:29.260
Gândiți-vă la cancer, gripa aviară, gripa porcină, SARS.

00:11:29.260 --> 00:11:32.260
Toate senzațiile noastre de securitate

00:11:32.260 --> 00:11:34.260
despre acele boli

00:11:34.260 --> 00:11:36.260
vin din modele

00:11:36.260 --> 00:11:39.260
date nouă, de fapt, de știință filtrată prin massmedia.

00:11:40.260 --> 00:11:43.260
Așa că modelele se pot schimba.

00:11:43.260 --> 00:11:45.260
Modelele nu sunt statice.

00:11:45.260 --> 00:11:48.260
Pe măsură ce devenim mai confortabili în mediile noastre,

00:11:48.260 --> 00:11:52.260
modelele noastre se pot muta mai aproape de senzațiile noastre.

00:11:53.260 --> 00:11:55.260
Un exemplu ar fi,

00:11:55.260 --> 00:11:57.260
dacă mergeți înapoi 100 de ani

00:11:57.260 --> 00:12:00.260
când electricitatea a început să fie folosită,

00:12:00.260 --> 00:12:02.260
erau multe temeri legate de ea.

00:12:02.260 --> 00:12:04.260
Erau oameni cărora le era frică să apese butonul soneriei,

00:12:04.260 --> 00:12:07.260
fiindcă era electricitate în el, iar asta era periculos.

00:12:07.260 --> 00:12:10.260
Noi suntem degajați privind electricitatea.

00:12:10.260 --> 00:12:12.260
Schimbăm becurile electrice

00:12:12.260 --> 00:12:14.260
fără să ne gândim la ea.

00:12:14.260 --> 00:12:18.260
Modelul nostru de securitate despre electricitate

00:12:18.260 --> 00:12:21.260
este ceva în care trăim de la naștere.

00:12:21.260 --> 00:12:24.260
El nu s-a schimbat pe durata vieții noastre.

00:12:24.260 --> 00:12:27.260
Și suntem buni la acest model.

00:12:27.260 --> 00:12:29.260
Sau gândiți-vă la riscurile

00:12:29.260 --> 00:12:31.260
Internetului perceput de generații --

00:12:31.260 --> 00:12:33.260
cum tratează părinții voștri securitatea Internetului,

00:12:33.260 --> 00:12:35.260
față de cum faceți voi,

00:12:35.260 --> 00:12:38.260
față de cum vor face copiii noștri.

00:12:38.260 --> 00:12:41.260
În cele din urmă modelele dispar în fundal.

00:12:42.260 --> 00:12:45.260
Intuitiv este doar un alt cuvânt pentru familiar.

00:12:45.260 --> 00:12:47.260
Pe măsură ce modelul tău este aproape de realitate,

00:12:47.260 --> 00:12:49.260
și converge cu senzațiile,

00:12:49.260 --> 00:12:52.260
adesea nici nu știi că e acolo.

00:12:52.260 --> 00:12:54.260
Un exemplu drăguț pentru asta

00:12:54.260 --> 00:12:57.260
a fost gripa porcină de anul trecut.

00:12:57.260 --> 00:12:59.260
Când gripa porcină a apărut prima dată,

00:12:59.260 --> 00:13:03.260
știrile inițiale au provocat multe reacții exagerate.

00:13:03.260 --> 00:13:05.260
Apoi a avut un nume,

00:13:05.260 --> 00:13:07.260
ceea ce a făcut-o mai de speriat decât gripa normală,

00:13:07.260 --> 00:13:09.260
chiar dacă a fost mai mortală.

00:13:09.260 --> 00:13:13.260
Și oamenii au gândit că doctorii vor fi în stare să-i facă față.

00:13:13.260 --> 00:13:15.260
Deci a fost senzația lipsei de control.

00:13:15.260 --> 00:13:17.260
Iar aceste două lucruri

00:13:17.260 --> 00:13:19.260
au făcut riscul mai mare decât era.

00:13:19.260 --> 00:13:22.260
După ce a trecut noutatea, au trecut luni,

00:13:22.260 --> 00:13:24.260
a existat o doză de toleranță,

00:13:24.260 --> 00:13:26.260
oamenii s-au obișnuit cu ea.

00:13:26.260 --> 00:13:29.260
Nu existau date noi, dar era mai puțină frică.

00:13:29.260 --> 00:13:31.260
Până toamna,

00:13:31.260 --> 00:13:33.260
oamenii au gândit

00:13:33.260 --> 00:13:35.260
că doctorii au rezolvat deja asta.

00:13:35.260 --> 00:13:37.260
Și există un fel de bifurcație --

00:13:37.260 --> 00:13:39.260
oamenii au trebuit să aleagă

00:13:39.260 --> 00:13:43.260
între frică și acceptare --

00:13:43.260 --> 00:13:45.260
de fapt frică și indiferență --

00:13:45.260 --> 00:13:48.260
și ei au devenit suspicioși.

00:13:48.260 --> 00:13:51.260
Și când a apărut vaccinul iarna trecută,

00:13:51.260 --> 00:13:54.260
erau o mulțime de oameni -- un număr surprinzător --

00:13:54.260 --> 00:13:57.260
care au refuzat să-l ia --

00:13:58.260 --> 00:14:00.260
ca un exemplu drăguț

00:14:00.260 --> 00:14:03.260
de cum se schimbă senzația de securitate a oamenilor, cum se schimbă modelul lor,

00:14:03.260 --> 00:14:05.260
într-un mod nebunesc

00:14:05.260 --> 00:14:07.260
fără informații noi,

00:14:07.260 --> 00:14:09.260
fără date noi de intrare.

00:14:09.260 --> 00:14:12.260
Acest lucru se întâmplă des.

00:14:12.260 --> 00:14:15.260
Voi mai face o complicare în plus.

00:14:15.260 --> 00:14:18.260
Avem senzație, model, realitate.

00:14:18.260 --> 00:14:20.260
Am o vedere foarte relativistă a securității.

00:14:20.260 --> 00:14:23.260
Cred că depinde de observator.

00:14:23.260 --> 00:14:25.260
Și majoritatea deciziilor de securitate

00:14:25.260 --> 00:14:29.260
implică o diversitate de oameni.

00:14:29.260 --> 00:14:31.260
Iar părțile interesate

00:14:31.260 --> 00:14:34.260
cu schimburi specifice

00:14:34.260 --> 00:14:36.260
vor încerca să influențeze decizia.

00:14:36.260 --> 00:14:38.260
Și eu numesc asta planul lor.

00:14:38.260 --> 00:14:40.260
Și vedeți planuri --

00:14:40.260 --> 00:14:43.260
în marketing, în politică --

00:14:43.260 --> 00:14:46.260
încercând să te convingă să ai un anumit model față de un altul,

00:14:46.260 --> 00:14:48.260
încercând să te convingă să ignori un model

00:14:48.260 --> 00:14:51.260
și să te încrezi în senzațiile tale,

00:14:51.260 --> 00:14:54.260
marginalizând oamenii cu modele care nu-ți plac.

00:14:54.260 --> 00:14:57.260
Asta nu este ceva neobişnuit.

00:14:57.260 --> 00:15:00.260
Un exemplu grozav este riscul fumatului.

00:15:01.260 --> 00:15:04.260
În istoria ultimilor 50 de ani, riscul fumatului

00:15:04.260 --> 00:15:06.260
arată cum se schimbă un model,

00:15:06.260 --> 00:15:09.260
și arată de asemenea cum o industrie luptă

00:15:09.260 --> 00:15:11.260
împotriva unui model care nu-i place.

00:15:11.260 --> 00:15:14.260
Comparați asta cu dezbaterea despre fumatul pasiv --

00:15:14.260 --> 00:15:17.260
probabil cu aproape 20 de ani în urmă.

00:15:17.260 --> 00:15:19.260
Gândiți-vă la centurile de siguranță.

00:15:19.260 --> 00:15:21.260
Când eram copil, nimeni nu purta centura de siguranță.

00:15:21.260 --> 00:15:23.260
Azi, niciun copil nu te va lăsa să conduci

00:15:23.260 --> 00:15:25.260
dacă nu ai centura de siguranță.

00:15:26.260 --> 00:15:28.260
Comparați asta cu dezbaterea despre perna de aer --

00:15:28.260 --> 00:15:31.260
probabil cu 30 de ani în urmă.

00:15:31.260 --> 00:15:34.260
Toate sunt exemple de schimbări de modele.

00:15:36.260 --> 00:15:39.260
Ceea ce învățăm este că schimbarea modelelor este dificilă.

00:15:39.260 --> 00:15:41.260
Modelele sunt greu de dislocat.

00:15:41.260 --> 00:15:43.260
Dacă sunt la fel cu senzațiile tale

00:15:43.260 --> 00:15:46.260
nu știi că ai un model.

00:15:46.260 --> 00:15:48.260
Și există o altă predispoziţie cognitivă

00:15:48.260 --> 00:15:50.260
pe care o numesc predispoziţie de confirmare,

00:15:50.260 --> 00:15:53.260
unde tindem să acceptăm datele

00:15:53.260 --> 00:15:55.260
care confirmă credințele noastre

00:15:55.260 --> 00:15:58.260
și să rejectăm datele care contrazic credințele noastre.

00:15:59.260 --> 00:16:01.260
Deci probabil vom ignora dovada

00:16:01.260 --> 00:16:04.260
împotriva modelului nostru, chiar dacă este convingătoare.

00:16:04.260 --> 00:16:07.260
Trebuie să devină foarte convingătoare înainte de a-i acorda atenție.

00:16:08.260 --> 00:16:10.260
Modele noi care se întind perioade lungi de timp sunt dificile.

00:16:10.260 --> 00:16:12.260
Încălzirea globală este un exemplu grozav.

00:16:12.260 --> 00:16:14.260
Suntem îngrozitori

00:16:14.260 --> 00:16:16.260
la modele care acoperă 80 de ani.

00:16:16.260 --> 00:16:18.260
Putem s-o facem până la următoarea recoltă.

00:16:18.260 --> 00:16:21.260
Adesea o putem face până cresc copiii noștri.

00:16:21.260 --> 00:16:24.260
Dar 80 de ani, pur și simplu nu suntem buni la asta.

00:16:24.260 --> 00:16:27.260
Deci este un model foarte greu de acceptat.

00:16:27.260 --> 00:16:31.260
Putem avea ambele modele simultan în cap,

00:16:31.260 --> 00:16:34.260
sau acel tip de problemă

00:16:34.260 --> 00:16:37.260
când avem ambele credințe simultan,

00:16:37.260 --> 00:16:39.260
sau disonanța cognitivă.

00:16:39.260 --> 00:16:41.260
În final modelul nou

00:16:41.260 --> 00:16:44.260
va înlocui modelul vechi.

00:16:44.260 --> 00:16:47.260
Senzațiile puternice pot crea un model.

00:16:47.260 --> 00:16:50.260
11 septembrie a creat un model de securitate

00:16:50.260 --> 00:16:52.260
în capul multor oameni.

00:16:52.260 --> 00:16:55.260
Experiența personală cu criminalitatea o poate face,

00:16:55.260 --> 00:16:57.260
panica pentru sănătatea personală,

00:16:57.260 --> 00:16:59.260
o panică de sănătate în știri.

00:16:59.260 --> 00:17:01.260
Psihiatrii numesc asta

00:17:01.260 --> 00:17:03.260
evenimente "se aprinde becul".

00:17:03.260 --> 00:17:06.260
Ele pot crea instantaneu un model,

00:17:06.260 --> 00:17:09.260
fiindcă sunt foarte emoționale.

00:17:09.260 --> 00:17:11.260
În lumea tehnologică

00:17:11.260 --> 00:17:13.260
nu avem experiența

00:17:13.260 --> 00:17:15.260
de a judeca modele.

00:17:15.260 --> 00:17:17.260
Și ne bazăm pe alții. Ne bazăm pe împuterniciți.

00:17:17.260 --> 00:17:21.260
Adică, asta funcționează cât timp este în regulă pentru alții.

00:17:21.260 --> 00:17:23.260
Ne bazăm pe agenții guvernamentale

00:17:23.260 --> 00:17:28.260
să ne spună care sunt medicamentele sigure.

00:17:28.260 --> 00:17:30.260
Ieri am zburat aici.

00:17:30.260 --> 00:17:32.260
Nu am verificat avionul.

00:17:32.260 --> 00:17:34.260
M-am bazat pe un alt grup

00:17:34.260 --> 00:17:37.260
să constate dacă avionul meu este sigur pentru zbor.

00:17:37.260 --> 00:17:40.260
Suntem aici, nimănui nu-i este teamă că acoperișul va cădea peste noi,

00:17:40.260 --> 00:17:43.260
nu fiindcă am verificat,

00:17:43.260 --> 00:17:45.260
ci fiindcă suntem destul de siguri

00:17:45.260 --> 00:17:48.260
că aici normele de construcție sunt bune.

00:17:48.260 --> 00:17:50.260
Este un model pe care-l acceptăm

00:17:50.260 --> 00:17:52.260
mai mult prin încredere.

00:17:52.260 --> 00:17:55.260
Și asta este în regulă.

00:17:57.260 --> 00:17:59.260
Ceea ce vrem este ca

00:17:59.260 --> 00:18:01.260
oamenii să devină suficient de obișnuiți

00:18:01.260 --> 00:18:03.260
cu modele mai bune --

00:18:03.260 --> 00:18:05.260
să le reflecte în senzațiile lor --

00:18:05.260 --> 00:18:09.260
să le permită să facă schimburi de securitate.

00:18:09.260 --> 00:18:11.260
Când acestea se strică,

00:18:11.260 --> 00:18:13.260
ai două opțiuni.

00:18:13.260 --> 00:18:15.260
Prima, poți repara senzațiile oamenilor,

00:18:15.260 --> 00:18:17.260
apelând direct la sentimente.

00:18:17.260 --> 00:18:20.260
Este manipulare, dar poate funcționa.

00:18:20.260 --> 00:18:22.260
A doua cale, mai cinstită,

00:18:22.260 --> 00:18:25.260
este să repari modelul.

00:18:26.260 --> 00:18:28.260
Schimbările se întâmplă încet.

00:18:28.260 --> 00:18:31.260
Dezbaterea despre fumat a luat 40 de ani,

00:18:31.260 --> 00:18:34.260
și asta a fost una ușoară.

00:18:34.260 --> 00:18:36.260
Unele din aceste lucruri sunt dificile.

00:18:36.260 --> 00:18:38.260
Adică foarte dificile,

00:18:38.260 --> 00:18:40.260
informația pare cea mai bună speranță pentru noi.

00:18:40.260 --> 00:18:42.260
Și am mințit.

00:18:42.260 --> 00:18:44.260
Țineți minte când am spus: senzație, model, realitate.

00:18:44.260 --> 00:18:47.260
Am spus că realitatea nu se schimbă. De fapt o face.

00:18:47.260 --> 00:18:49.260
Trăim într-o lume tehnologică;

00:18:49.260 --> 00:18:52.260
realitatea se schimbă tot timpul.

00:18:52.260 --> 00:18:55.260
Deci s-ar putea să avem -- pentru prima dată ca specie --

00:18:55.260 --> 00:18:58.260
senzația urmărește modelul, modelul urmărește realitatea,

00:18:58.260 --> 00:19:01.260
iar realitatea se mișcă -- s-ar putea să nu se ajungă niciodată.

00:19:02.260 --> 00:19:04.260
Nu știm.

00:19:04.260 --> 00:19:06.260
Dar pe termen lung,

00:19:06.260 --> 00:19:09.260
sunt importante și senzația și realitatea.

00:19:09.260 --> 00:19:12.260
Și vreau să închei cu două istorioare pentru a ilustra asta.

00:19:12.260 --> 00:19:14.260
1982 -- nu știu dacă oamenii își vor aminti asta --

00:19:14.260 --> 00:19:17.260
a fost o scurtă epidemie

00:19:17.260 --> 00:19:19.260
de otrăvire cu Tylenol în SUA.

00:19:19.260 --> 00:19:22.260
Este o poveste oribilă. Cineva a luat o sticlă de Tylenol,

00:19:22.260 --> 00:19:25.260
a pus otravă în ea, a închis-o la loc, a pus-o înapoi pe raft.

00:19:25.260 --> 00:19:27.260
Altcineva a cumpărat-o și a murit.

00:19:27.260 --> 00:19:29.260
Asta a îngrozit lumea.

00:19:29.260 --> 00:19:31.260
Au fost câteva cazuri de copiere a atacului.

00:19:31.260 --> 00:19:34.260
Nu exista un risc real, dar oamenii erau speriați.

00:19:34.260 --> 00:19:36.260
Și așa a fost inventată

00:19:36.260 --> 00:19:38.260
industria medicamentelor sigilate.

00:19:38.260 --> 00:19:40.260
Acele capace sigilate au rezultat din asta.

00:19:40.260 --> 00:19:42.260
Este un adevărat spectacol de securitate.

00:19:42.260 --> 00:19:44.260
Ca temă pentr acasă, gândiți-vă la 10 căi de a ocoli asta.

00:19:44.260 --> 00:19:47.260
Vă dau una: o seringă.

00:19:47.260 --> 00:19:50.260
Dar a făcut oamenii să se simtă mai bine.

00:19:50.260 --> 00:19:52.260
A făcut ca senzația lor de securitate

00:19:52.260 --> 00:19:54.260
să se potrivească mai mult cu realitatea.

00:19:54.260 --> 00:19:57.260
Ulima poveste, acum câțiva ani, o prietenă a născut.

00:19:57.260 --> 00:19:59.260
Am vizitat-o în spital.

00:19:59.260 --> 00:20:01.260
Am aflat că acum când se naște un copil,

00:20:01.260 --> 00:20:03.260
se pune o brățară cu identificator radio (RFID) bebelușului,

00:20:03.260 --> 00:20:05.260
se pune una corespunzătoare mamei,

00:20:05.260 --> 00:20:07.260
deci dacă oricine altcineva decât mama scoate copilul

00:20:07.260 --> 00:20:09.260
din maternitate, va suna o alarmă.

00:20:09.260 --> 00:20:11.260
Am zis: "Ei bine, asta este simplu dar elegant.

00:20:11.260 --> 00:20:13.260
Mă întreb cât de excesiv este furtul

00:20:13.260 --> 00:20:15.260
de bebeluși din spitale."

00:20:15.260 --> 00:20:17.260
Am mers acasă, am căutat asta.

00:20:17.260 --> 00:20:19.260
De fapt nu se întâmplă niciodată.

00:20:19.260 --> 00:20:21.260
Dar dacă te gândești la asta,

00:20:21.260 --> 00:20:23.260
dacă ești un spital,

00:20:23.260 --> 00:20:25.260
și dacă trebuie să iei un bebeluș de la mama lui,

00:20:25.260 --> 00:20:27.260
afară din cameră pentru niște teste,

00:20:27.260 --> 00:20:29.260
ar fi bine să ai un spectacol de securitate bun,

00:20:29.260 --> 00:20:31.260
sau mama îți va rupe brațul.

00:20:31.260 --> 00:20:33.260
(Râsete)

00:20:33.260 --> 00:20:35.260
Deci este important pentru noi,

00:20:35.260 --> 00:20:37.260
cei care proiectăm securitatea,

00:20:37.260 --> 00:20:40.260
care privim la politica de securitate,

00:20:40.260 --> 00:20:42.260
sau doar privim la politica publică

00:20:42.260 --> 00:20:44.260
în moduri care afectează securitatea.

00:20:44.260 --> 00:20:47.260
Nu este doar realitate, este senzație și realitate.

00:20:47.260 --> 00:20:49.260
Ce este important

00:20:49.260 --> 00:20:51.260
este ca ele să fie la fel.

00:20:51.260 --> 00:20:53.260
Este important, fiindcă dacă senzația se potrivește cu realitatea,

00:20:53.260 --> 00:20:55.260
facem schimburi mai bune de securitate.

00:20:55.260 --> 00:20:57.260
Vă mulțumesc.

00:20:57.260 --> 00:20:59.260
(Aplauze)

