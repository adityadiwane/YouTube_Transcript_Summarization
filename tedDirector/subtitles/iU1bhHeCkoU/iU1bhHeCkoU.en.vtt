WEBVTT
Kind: captions
Language: en

00:00:12.751 --> 00:00:15.088
Chis Anderson: Christiane,
great to have you here.

00:00:15.112 --> 00:00:16.955
So you've had this amazing viewpoint,

00:00:16.979 --> 00:00:20.039
and perhaps it's fair to say
that in the last few years,

00:00:20.063 --> 00:00:23.816
there have been some alarming
developments that you're seeing.

00:00:23.840 --> 00:00:25.404
What's alarmed you most?

00:00:25.428 --> 00:00:28.620
Christiane Amanpour: Well, just listening
to the earlier speakers,

00:00:28.644 --> 00:00:31.116
I can frame it
in what they've been saying:

00:00:31.140 --> 00:00:34.562
climate change, for instance --
cities, the threat to our environment

00:00:34.586 --> 00:00:35.846
and our lives.

00:00:36.260 --> 00:00:40.154
It basically also boils down to
understanding the truth

00:00:40.178 --> 00:00:43.189
and to be able to get to the truth
of what we're talking about

00:00:43.213 --> 00:00:45.305
in order to really be able to solve it.

00:00:45.329 --> 00:00:49.256
So if 99.9 percent
of the science on climate

00:00:49.280 --> 00:00:52.337
is empirical, scientific evidence,

00:00:52.361 --> 00:00:57.256
but it's competing almost equally
with a handful of deniers,

00:00:57.280 --> 00:00:58.507
that is not the truth;

00:00:58.531 --> 00:01:01.029
that is the epitome of fake news.

00:01:01.053 --> 00:01:06.155
And so for me, the last few years --
certainly this last year --

00:01:06.179 --> 00:01:10.439
has crystallized the notion of fake news
in a way that's truly alarming

00:01:10.463 --> 00:01:13.122
and not just some slogan
to be thrown around.

00:01:13.146 --> 00:01:16.957
Because when you can't distinguish
between the truth and fake news,

00:01:16.981 --> 00:01:20.872
you have a very much more
difficult time trying to solve

00:01:20.896 --> 00:01:23.347
some of the great issues that we face.

00:01:24.332 --> 00:01:27.753
CA: Well, you've been involved
in this question of,

00:01:27.777 --> 00:01:30.689
what is balance, what is truth,
what is impartiality,

00:01:30.713 --> 00:01:31.968
for a long time.

00:01:31.992 --> 00:01:37.862
You were on the front lines
reporting the Balkan Wars 25 years ago.

00:01:37.886 --> 00:01:41.298
And back then, you famously said,

00:01:41.322 --> 00:01:43.943
by calling out human right abuses,

00:01:43.967 --> 00:01:48.296
you said, "Look, there are some situations
one simply cannot be neutral about,

00:01:48.320 --> 00:01:49.700
because when you're neutral,

00:01:49.724 --> 00:01:51.611
you are an accomplice."

00:01:53.063 --> 00:01:57.960
So, do you feel that today's journalists
aren't heeding that advice

00:01:57.984 --> 00:01:59.456
about balance?

00:01:59.480 --> 00:02:03.586
CA: Well, look, I think for journalists,
objectivity is the golden rule.

00:02:03.610 --> 00:02:08.026
But I think sometimes we don't understand
what objectivity means.

00:02:08.050 --> 00:02:11.044
And I actually learned this very,
very young in my career,

00:02:11.068 --> 00:02:12.640
which was during the Balkan Wars.

00:02:12.664 --> 00:02:13.880
I was young then.

00:02:13.904 --> 00:02:16.443
It was about 25 years ago.

00:02:16.467 --> 00:02:22.248
And what we faced was the wholesale
violation, not just of human rights,

00:02:22.272 --> 00:02:25.251
but all the way to ethnic
cleansing and genocide,

00:02:25.275 --> 00:02:29.281
and that has been adjudicated
in the highest war crimes court

00:02:29.305 --> 00:02:30.469
in the world.

00:02:30.493 --> 00:02:32.146
So, we know what we were seeing.

00:02:32.170 --> 00:02:34.707
Trying to tell the world
what we were seeing

00:02:34.731 --> 00:02:37.506
brought us accusations of bias,

00:02:37.530 --> 00:02:39.419
of siding with one side,

00:02:39.443 --> 00:02:41.305
of not seeing the whole side,

00:02:41.329 --> 00:02:43.626
and just, you know,
trying to tell one story.

00:02:43.650 --> 00:02:47.957
I particularly and personally
was accused of siding with,

00:02:47.981 --> 00:02:49.963
for instance, the citizens of Sarajevo --

00:02:49.987 --> 00:02:51.414
"siding with the Muslims,"

00:02:51.438 --> 00:02:54.490
because they were the minority
who were being attacked

00:02:54.514 --> 00:02:58.252
by Christians on the Serb side

00:02:58.276 --> 00:02:59.995
in this area.

00:03:00.019 --> 00:03:01.361
And it worried me.

00:03:01.385 --> 00:03:03.576
It worried me that I was being
accused of this.

00:03:03.600 --> 00:03:04.942
I thought maybe I was wrong,

00:03:04.966 --> 00:03:07.314
maybe I'd forgotten what objectivity was.

00:03:07.338 --> 00:03:10.345
But then I started to understand
that what people wanted

00:03:10.369 --> 00:03:12.167
was actually not to do anything --

00:03:12.191 --> 00:03:13.608
not to step in,

00:03:13.632 --> 00:03:15.202
not to change the situation,

00:03:15.226 --> 00:03:16.675
not to find a solution.

00:03:16.699 --> 00:03:19.052
And so, their fake news at that time,

00:03:19.076 --> 00:03:20.458
their lie at that time --

00:03:20.482 --> 00:03:24.012
including our government's,
our democratically elected government's,

00:03:24.036 --> 00:03:26.308
with values and principles
of human rights --

00:03:26.332 --> 00:03:29.839
their lie was to say
that all sides are equally guilty,

00:03:29.863 --> 00:03:32.656
that this has been centuries
of ethnic hatred,

00:03:32.680 --> 00:03:34.562
whereas we knew that wasn't true,

00:03:34.586 --> 00:03:38.233
that one side had decided to kill,
slaughter and ethnically cleanse

00:03:38.257 --> 00:03:39.414
another side.

00:03:39.438 --> 00:03:40.934
So that is where, for me,

00:03:40.958 --> 00:03:46.264
I understood that objectivity means
giving all sides an equal hearing

00:03:46.288 --> 00:03:48.393
and talking to all sides,

00:03:48.417 --> 00:03:52.039
but not treating all sides equally,

00:03:52.063 --> 00:03:56.851
not creating a forced moral equivalence
or a factual equivalence.

00:03:56.875 --> 00:04:01.354
And when you come up against
that crisis point

00:04:01.378 --> 00:04:07.049
in situations of grave violations
of international and humanitarian law,

00:04:07.073 --> 00:04:09.415
if you don't understand
what you're seeing,

00:04:09.439 --> 00:04:11.599
if you don't understand the truth

00:04:11.623 --> 00:04:15.136
and if you get trapped
in the fake news paradigm,

00:04:15.160 --> 00:04:16.750
then you are an accomplice.

00:04:17.478 --> 00:04:20.475
And I refuse to be
an accomplice to genocide.

00:04:20.499 --> 00:04:23.782
(Applause)

00:04:26.222 --> 00:04:29.000
CH: So there have always been
these propaganda battles,

00:04:29.024 --> 00:04:33.050
and you were courageous in taking
the stand you took back then.

00:04:33.472 --> 00:04:37.199
Today, there's a whole new way, though,

00:04:37.223 --> 00:04:39.427
in which news seems to be becoming fake.

00:04:39.451 --> 00:04:41.085
How would you characterize that?

00:04:41.109 --> 00:04:43.193
CA: Well, look -- I am really alarmed.

00:04:43.217 --> 00:04:45.419
And everywhere I look,

00:04:45.443 --> 00:04:47.280
you know, we're buffeted by it.

00:04:47.304 --> 00:04:49.506
Obviously, when the leader
of the free world,

00:04:49.530 --> 00:04:52.003
when the most powerful person
in the entire world,

00:04:52.027 --> 00:04:54.273
which is the president
of the United States --

00:04:54.297 --> 00:04:59.116
this is the most important, most powerful
country in the whole world,

00:04:59.140 --> 00:05:03.380
economically, militarily, politically
in every which way --

00:05:04.235 --> 00:05:09.252
and it seeks to, obviously, promote
its values and power around the world.

00:05:09.276 --> 00:05:13.252
So we journalists,
who only seek the truth --

00:05:13.276 --> 00:05:14.797
I mean, that is our mission --

00:05:14.821 --> 00:05:16.938
we go around the world
looking for the truth

00:05:16.962 --> 00:05:18.935
in order to be everybody's eyes and ears,

00:05:18.959 --> 00:05:21.478
people who can't go out
in various parts of the world

00:05:21.502 --> 00:05:24.871
to figure out what's going on
about things that are vitally important

00:05:24.895 --> 00:05:26.851
to everybody's health and security.

00:05:26.875 --> 00:05:33.561
So when you have a major world leader
accusing you of fake news,

00:05:33.585 --> 00:05:37.428
it has an exponential ripple effect.

00:05:37.452 --> 00:05:41.724
And what it does is,
it starts to chip away

00:05:42.292 --> 00:05:45.180
at not just our credibility,

00:05:45.204 --> 00:05:47.233
but at people's minds --

00:05:48.192 --> 00:05:50.556
people who look at us,
and maybe they're thinking,

00:05:50.580 --> 00:05:53.249
"Well, if the president
of the United States says that,

00:05:53.273 --> 00:05:55.408
maybe somewhere there's a truth in there."

00:05:55.968 --> 00:06:00.152
CH: Presidents have always
been critical of the media --

00:06:00.176 --> 00:06:01.777
CA: Not in this way.

00:06:01.801 --> 00:06:03.306
CH: So, to what extent --

00:06:03.330 --> 00:06:04.394
(Laughter)

00:06:04.418 --> 00:06:07.538
(Applause)

00:06:07.562 --> 00:06:14.458
CH: I mean, someone a couple years ago
looking at the avalanche of information

00:06:14.482 --> 00:06:17.718
pouring through Twitter
and Facebook and so forth,

00:06:17.742 --> 00:06:18.900
might have said,

00:06:18.924 --> 00:06:21.765
"Look, our democracies are healthier
than they've ever been.

00:06:21.789 --> 00:06:23.310
There's more news than ever.

00:06:23.334 --> 00:06:25.545
Of course presidents
will say what they'll say,

00:06:25.569 --> 00:06:27.802
but everyone else can say
what they will say.

00:06:27.826 --> 00:06:31.981
What's not to like?
How is there an extra danger?"

00:06:32.005 --> 00:06:33.547
CA: So, I wish that was true.

00:06:34.812 --> 00:06:40.905
I wish that the proliferation of platforms
upon which we get our information

00:06:40.929 --> 00:06:44.807
meant that there was a proliferation
of truth and transparency

00:06:44.831 --> 00:06:46.699
and depth and accuracy.

00:06:46.723 --> 00:06:49.178
But I think the opposite has happened.

00:06:49.202 --> 00:06:51.292
You know, I'm a little bit of a Luddite,

00:06:51.316 --> 00:06:52.512
I will confess.

00:06:52.967 --> 00:06:56.351
Even when we started to talk about
the information superhighway,

00:06:56.375 --> 00:06:58.003
which was a long time ago,

00:06:58.027 --> 00:07:00.678
before social media, Twitter
and all the rest of it,

00:07:00.702 --> 00:07:02.526
I was actually really afraid

00:07:02.550 --> 00:07:06.571
that that would put people
into certain lanes and tunnels

00:07:06.595 --> 00:07:10.937
and have them just focusing
on areas of their own interest

00:07:10.961 --> 00:07:13.294
instead of seeing the broad picture.

00:07:13.318 --> 00:07:17.904
And I'm afraid to say
that with algorithms, with logarithms,

00:07:17.928 --> 00:07:19.576
with whatever the "-ithms" are

00:07:19.600 --> 00:07:23.866
that direct us into all these particular
channels of information,

00:07:23.890 --> 00:07:25.760
that seems to be happening right now.

00:07:25.784 --> 00:07:28.328
I mean, people have written
about this phenomenon.

00:07:28.352 --> 00:07:30.550
People have said that yes,
the internet came,

00:07:30.574 --> 00:07:36.317
its promise was to exponentially explode
our access to more democracy,

00:07:36.341 --> 00:07:38.055
more information,

00:07:38.079 --> 00:07:39.971
less bias,

00:07:39.995 --> 00:07:42.384
more varied information.

00:07:42.408 --> 00:07:44.733
And, in fact, the opposite has happened.

00:07:44.757 --> 00:07:48.775
And so that, for me,
is incredibly dangerous.

00:07:48.799 --> 00:07:53.314
And again, when you are the president
of this country and you say things,

00:07:53.338 --> 00:07:58.763
it also gives leaders in other
undemocratic countries the cover

00:07:59.829 --> 00:08:02.135
to affront us even worse,

00:08:02.159 --> 00:08:05.019
and to really whack us --
and their own journalists --

00:08:05.043 --> 00:08:06.866
with this bludgeon of fake news.

00:08:07.820 --> 00:08:10.004
CH: To what extent
is what happened, though,

00:08:10.028 --> 00:08:12.094
in part, just an unintended consequence,

00:08:12.118 --> 00:08:14.920
that the traditional
media that you worked in

00:08:14.944 --> 00:08:17.024
had this curation-mediation role,

00:08:17.048 --> 00:08:19.074
where certain norms were observed,

00:08:19.098 --> 00:08:22.251
certain stories would be rejected
because they weren't credible,

00:08:22.275 --> 00:08:28.774
but now that the standard
for publication and for amplification

00:08:28.798 --> 00:08:32.126
is just interest, attention,
excitement, click,

00:08:32.150 --> 00:08:33.313
"Did it get clicked on?"

00:08:33.337 --> 00:08:34.492
"Send it out there!"

00:08:34.516 --> 00:08:38.020
and that's what's --
is that part of what's caused the problem?

00:08:38.044 --> 00:08:41.639
CA: I think it's a big problem,
and we saw this in the election of 2016,

00:08:41.663 --> 00:08:46.770
where the idea of "clickbait"
was very sexy and very attractive,

00:08:46.794 --> 00:08:51.100
and so all these fake news sites
and fake news items

00:08:51.124 --> 00:08:55.246
were not just haphazardly
and by happenstance being put out there,

00:08:55.270 --> 00:08:59.721
there's been a whole industry
in the creation of fake news

00:08:59.745 --> 00:09:02.735
in parts of Eastern Europe, wherever,

00:09:02.759 --> 00:09:06.019
and you know, it's planted
in real space and in cyberspace.

00:09:06.043 --> 00:09:08.402
So I think that, also,

00:09:08.426 --> 00:09:13.547
the ability of our technology
to proliferate this stuff

00:09:13.571 --> 00:09:17.082
at the speed of sound
or light, just about --

00:09:17.106 --> 00:09:19.089
we've never faced that before.

00:09:19.113 --> 00:09:23.980
And we've never faced
such a massive amount of information

00:09:24.004 --> 00:09:25.569
which is not curated

00:09:25.593 --> 00:09:30.889
by those whose profession
leads them to abide by the truth,

00:09:30.913 --> 00:09:32.115
to fact-check

00:09:32.139 --> 00:09:36.973
and to maintain a code of conduct
and a code of professional ethics.

00:09:36.997 --> 00:09:40.340
CH: Many people here may know
people who work at Facebook

00:09:40.364 --> 00:09:42.688
or Twitter and Google and so on.

00:09:42.712 --> 00:09:45.844
They all seem like great people
with good intention --

00:09:45.868 --> 00:09:47.248
let's assume that.

00:09:47.272 --> 00:09:50.947
If you could speak with the leaders
of those companies,

00:09:50.971 --> 00:09:52.262
what would you say to them?

00:09:52.286 --> 00:09:54.055
CA: Well, you know what --

00:09:54.079 --> 00:09:56.423
I'm sure they are
incredibly well-intentioned,

00:09:56.447 --> 00:10:01.665
and they certainly developed
an unbelievable, game-changing system,

00:10:01.689 --> 00:10:04.900
where everybody's connected
on this thing called Facebook.

00:10:04.924 --> 00:10:08.725
And they've created a massive
economy for themselves

00:10:08.749 --> 00:10:11.429
and an amazing amount of income.

00:10:11.453 --> 00:10:12.633
I would just say,

00:10:12.657 --> 00:10:16.891
"Guys, you know, it's time
to wake up and smell the coffee

00:10:16.915 --> 00:10:19.617
and look at what's happening
to us right now."

00:10:19.641 --> 00:10:22.573
Mark Zuckerberg wants to create
a global community.

00:10:22.597 --> 00:10:25.816
I want to know: What is that global
community going to look like?

00:10:25.840 --> 00:10:29.907
I want to know where the codes
of conduct actually are.

00:10:29.931 --> 00:10:31.756
Mark Zuckerberg said --

00:10:31.780 --> 00:10:34.498
and I don't blame him,
he probably believed this --

00:10:34.522 --> 00:10:36.878
that it was crazy to think

00:10:36.902 --> 00:10:41.011
that the Russians or anybody else
could be tinkering and messing around

00:10:41.035 --> 00:10:42.278
with this avenue.

00:10:42.302 --> 00:10:44.784
And what have we just learned
in the last few weeks?

00:10:44.808 --> 00:10:47.766
That, actually, there has been
a major problem in that regard,

00:10:47.790 --> 00:10:50.908
and now they're having to investigate it
and figure it out.

00:10:50.932 --> 00:10:54.211
Yes, they're trying to do
what they can now

00:10:54.235 --> 00:10:56.393
to prevent the rise of fake news,

00:10:56.417 --> 00:10:57.800
but, you know,

00:10:57.824 --> 00:11:02.915
it went pretty unrestricted
for a long, long time.

00:11:02.939 --> 00:11:04.839
So I guess I would say, you know,

00:11:04.863 --> 00:11:06.962
you guys are brilliant at technology;

00:11:06.986 --> 00:11:08.877
let's figure out another algorithm.

00:11:08.901 --> 00:11:10.072
Can we not?

00:11:10.096 --> 00:11:12.983
CH: An algorithm that includes
journalistic investigation --

00:11:13.007 --> 00:11:16.363
CA: I don't really know how they do it,
but somehow, you know --

00:11:16.387 --> 00:11:18.206
filter out the crap!

00:11:18.230 --> 00:11:19.380
(Laughter)

00:11:19.404 --> 00:11:21.406
And not just the unintentional --

00:11:21.430 --> 00:11:24.684
(Applause)

00:11:24.708 --> 00:11:26.914
but the deliberate lies that are planted

00:11:26.938 --> 00:11:31.263
by people who've been doing this
as a matter of warfare

00:11:31.287 --> 00:11:32.589
for decades.

00:11:32.613 --> 00:11:34.546
The Soviets, the Russians --

00:11:34.570 --> 00:11:39.814
they are the masters of war
by other means, of hybrid warfare.

00:11:40.438 --> 00:11:41.882
And this is a --

00:11:42.509 --> 00:11:45.493
this is what they've decided to do.

00:11:45.517 --> 00:11:47.122
It worked in the United States,

00:11:47.146 --> 00:11:48.467
it didn't work in France,

00:11:48.491 --> 00:11:50.164
it hasn't worked in Germany.

00:11:50.188 --> 00:11:53.129
During the elections there,
where they've tried to interfere,

00:11:53.153 --> 00:11:55.755
the president of France
right now, Emmanuel Macron,

00:11:55.779 --> 00:11:58.302
took a very tough stand
and confronted it head on,

00:11:58.326 --> 00:11:59.484
as did Angela Merkel.

00:11:59.508 --> 00:12:02.493
CH: There's some hope to be had
from some of this, isn't there?

00:12:02.517 --> 00:12:03.668
That the world learns.

00:12:03.692 --> 00:12:05.010
We get fooled once,

00:12:05.034 --> 00:12:06.366
maybe we get fooled again,

00:12:06.390 --> 00:12:07.845
but maybe not the third time.

00:12:07.869 --> 00:12:09.037
Is that true?

00:12:09.061 --> 00:12:10.217
CA: I mean, let's hope.

00:12:10.241 --> 00:12:13.628
But I think in this regard that so much
of it is also about technology,

00:12:13.652 --> 00:12:17.097
that the technology has to also be given
some kind of moral compass.

00:12:17.121 --> 00:12:19.937
I know I'm talking nonsense,
but you know what I mean.

00:12:19.961 --> 00:12:23.669
CH: We need a filter-the-crap algorithm
with a moral compass --

00:12:23.693 --> 00:12:24.850
CA: There you go.

00:12:24.874 --> 00:12:26.026
CH: I think that's good.

00:12:26.050 --> 00:12:27.721
CA: No -- "moral technology."

00:12:27.745 --> 00:12:30.851
We all have moral compasses --
moral technology.

00:12:30.875 --> 00:12:33.854
CH: I think that's a great challenge.
CA: You know what I mean.

00:12:33.878 --> 00:12:35.822
CH: Talk just a minute about leadership.

00:12:35.846 --> 00:12:38.982
You've had a chance to speak
with so many people across the world.

00:12:39.006 --> 00:12:40.245
I think for some of us --

00:12:40.269 --> 00:12:42.961
I speak for myself,
I don't know if others feel this --

00:12:42.985 --> 00:12:44.981
there's kind of been a disappointment of:

00:12:45.005 --> 00:12:46.864
Where are the leaders?

00:12:46.888 --> 00:12:49.202
So many of us have been disappointed --

00:12:49.226 --> 00:12:51.242
Aung San Suu Kyi,
what's happened recently,

00:12:51.266 --> 00:12:53.351
it's like, "No! Another one
bites the dust."

00:12:53.375 --> 00:12:54.974
You know, it's heartbreaking.

00:12:54.998 --> 00:12:56.233
(Laughter)

00:12:56.257 --> 00:12:58.278
Who have you met

00:12:58.302 --> 00:13:01.172
who you have been
impressed by, inspired by?

00:13:01.196 --> 00:13:03.700
CA: Well, you talk about
the world in crisis,

00:13:03.724 --> 00:13:05.078
which is absolutely true,

00:13:05.102 --> 00:13:09.589
and those of us who spend our whole lives
immersed in this crisis --

00:13:09.613 --> 00:13:12.606
I mean, we're all on the verge
of a nervous breakdown.

00:13:12.630 --> 00:13:15.306
So it's pretty stressful right now.

00:13:15.330 --> 00:13:16.489
And you're right --

00:13:16.513 --> 00:13:19.623
there is this perceived and actual
vacuum of leadership,

00:13:19.647 --> 00:13:22.497
and it's not me saying it,
I ask all these --

00:13:22.521 --> 00:13:24.974
whoever I'm talking to,
I ask about leadership.

00:13:24.998 --> 00:13:29.508
I was speaking to the outgoing
president of Liberia today,

00:13:29.532 --> 00:13:31.342
[Ellen Johnson Sirleaf,]

00:13:31.366 --> 00:13:32.520
who --

00:13:32.544 --> 00:13:34.759
(Applause)

00:13:34.783 --> 00:13:36.325
in three weeks' time,

00:13:36.349 --> 00:13:40.293
will be one of the very rare
heads of an African country

00:13:40.317 --> 00:13:42.495
who actually abides by the constitution

00:13:42.519 --> 00:13:46.131
and gives up power
after her prescribed term.

00:13:46.155 --> 00:13:50.012
She has said she wants
to do that as a lesson.

00:13:50.036 --> 00:13:52.068
But when I asked her about leadership,

00:13:52.092 --> 00:13:54.775
and I gave a quick-fire round
of certain names,

00:13:54.799 --> 00:13:57.776
I presented her with the name
of the new French president,

00:13:57.800 --> 00:13:59.233
Emmanuel Macron.

00:13:59.257 --> 00:14:00.593
And she said --

00:14:00.617 --> 00:14:03.123
I said, "So what do you think
when I say his name?"

00:14:03.147 --> 00:14:04.420
And she said,

00:14:05.398 --> 00:14:07.723
"Shaping up potentially to be

00:14:07.747 --> 00:14:11.813
a leader to fill our current
leadership vacuum."

00:14:11.837 --> 00:14:13.670
I thought that was really interesting.

00:14:13.694 --> 00:14:16.150
Yesterday, I happened to have
an interview with him.

00:14:16.174 --> 00:14:17.332
I'm very proud to say,

00:14:17.356 --> 00:14:20.775
I got his first international interview.
It was great. It was yesterday.

00:14:20.799 --> 00:14:22.091
And I was really impressed.

00:14:22.115 --> 00:14:25.043
I don't know whether I should be
saying that in an open forum,

00:14:25.067 --> 00:14:26.522
but I was really impressed.

00:14:26.546 --> 00:14:27.764
(Laughter)

00:14:28.687 --> 00:14:31.362
And it could be just because
it was his first interview,

00:14:31.386 --> 00:14:33.481
but -- I asked questions,
and you know what?

00:14:33.505 --> 00:14:34.713
He answered them!

00:14:34.737 --> 00:14:36.670
(Laughter)

00:14:36.694 --> 00:14:39.963
(Applause)

00:14:39.987 --> 00:14:41.580
There was no spin,

00:14:41.604 --> 00:14:43.995
there was no wiggle and waggle,

00:14:44.019 --> 00:14:46.848
there was no spend-five-minutes-
to-come-back-to-the-point.

00:14:46.872 --> 00:14:48.540
I didn't have to keep interrupting,

00:14:48.564 --> 00:14:50.647
which I've become rather
renowned for doing,

00:14:50.671 --> 00:14:53.203
because I want people
to answer the question.

00:14:53.227 --> 00:14:55.278
And he answered me,

00:14:55.302 --> 00:14:57.916
and it was pretty interesting.

00:14:57.940 --> 00:14:59.371
And he said --

00:14:59.395 --> 00:15:01.173
CH: Tell me what he said.

00:15:01.197 --> 00:15:02.417
CA: No, no, you go ahead.

00:15:02.441 --> 00:15:04.669
CH: You're the interrupter,
I'm the listener.

00:15:04.693 --> 00:15:05.851
CA: No, no, go ahead.

00:15:05.875 --> 00:15:07.030
CH: What'd he say?

00:15:07.054 --> 00:15:10.132
CA: OK. You've talked about
nationalism and tribalism here today.

00:15:10.156 --> 00:15:13.918
I asked him, "How did you have the guts
to confront the prevailing winds

00:15:13.942 --> 00:15:18.477
of anti-globalization,
nationalism, populism

00:15:18.501 --> 00:15:20.463
when you can see what happened in Brexit,

00:15:20.487 --> 00:15:23.042
when you could see what happened
in the United States

00:15:23.066 --> 00:15:25.661
and what might have happened
in many European elections

00:15:25.685 --> 00:15:27.402
at the beginning of 2017?"

00:15:27.426 --> 00:15:28.745
And he said,

00:15:29.417 --> 00:15:32.691
"For me, nationalism means war.

00:15:33.306 --> 00:15:34.979
We have seen it before,

00:15:35.003 --> 00:15:37.261
we have lived through it before
on my continent,

00:15:37.285 --> 00:15:39.971
and I am very clear about that."

00:15:39.995 --> 00:15:43.956
So he was not going to,
just for political expediency,

00:15:43.980 --> 00:15:47.422
embrace the, kind of, lowest
common denominator

00:15:47.446 --> 00:15:51.451
that had been embraced
in other political elections.

00:15:51.475 --> 00:15:55.916
And he stood against Marine Le Pen,
who is a very dangerous woman.

00:15:56.748 --> 00:15:58.780
CH: Last question for you, Christiane.

00:15:59.913 --> 00:16:01.911
Tell us about ideas worth spreading.

00:16:01.935 --> 00:16:06.582
If you could plant one idea
into the minds of everyone here,

00:16:06.606 --> 00:16:07.803
what would that be?

00:16:07.827 --> 00:16:12.941
CA: I would say really be careful
where you get your information from;

00:16:12.965 --> 00:16:18.287
really take responsibility
for what you read, listen to and watch;

00:16:18.311 --> 00:16:23.198
make sure that you go to the trusted
brands to get your main information,

00:16:23.222 --> 00:16:27.911
no matter whether you have
a wide, eclectic intake,

00:16:27.935 --> 00:16:30.930
really stick with the brand
names that you know,

00:16:30.954 --> 00:16:34.546
because in this world right now,
at this moment right now,

00:16:34.570 --> 00:16:38.909
our crises, our challenges,
our problems are so severe,

00:16:38.933 --> 00:16:42.484
that unless we are all engaged
as global citizens

00:16:42.508 --> 00:16:44.411
who appreciate the truth,

00:16:44.435 --> 00:16:48.780
who understand science,
empirical evidence and facts,

00:16:48.804 --> 00:16:52.303
then we are just simply
going to be wandering along

00:16:52.327 --> 00:16:54.288
to a potential catastrophe.

00:16:54.312 --> 00:16:55.676
So I would say, the truth,

00:16:55.700 --> 00:16:57.956
and then I would come back
to Emmanuel Macron

00:16:57.980 --> 00:16:59.280
and talk about love.

00:16:59.842 --> 00:17:04.311
I would say that there's not
enough love going around.

00:17:04.335 --> 00:17:07.027
And I asked him to tell me about love.

00:17:07.051 --> 00:17:10.643
I said, "You know, your marriage
is the subject of global obsession."

00:17:10.667 --> 00:17:12.302
(Laughter)

00:17:12.326 --> 00:17:13.739
"Can you tell me about love?

00:17:13.763 --> 00:17:15.077
What does it mean to you?"

00:17:15.101 --> 00:17:18.042
I've never asked a president
or an elected leader about love.

00:17:18.066 --> 00:17:19.224
I thought I'd try it.

00:17:19.248 --> 00:17:23.163
And he said -- you know,
he actually answered it.

00:17:23.187 --> 00:17:27.348
And he said, "I love my wife,
she is part of me,

00:17:27.372 --> 00:17:28.999
we've been together for decades."

00:17:29.023 --> 00:17:30.708
But here's where it really counted,

00:17:30.732 --> 00:17:32.235
what really stuck with me.

00:17:32.259 --> 00:17:33.500
He said,

00:17:33.524 --> 00:17:37.044
"It is so important for me
to have somebody at home

00:17:37.068 --> 00:17:38.967
who tells me the truth."

00:17:40.438 --> 00:17:43.150
So you see, I brought it home.
It's all about the truth.

00:17:43.174 --> 00:17:44.180
(Laughter)

00:17:44.204 --> 00:17:47.011
CH: So there you go. Truth and love.
Ideas worth spreading.

00:17:47.035 --> 00:17:49.698
Christiane Amanpour, thank you
so much. That was great.

00:17:49.722 --> 00:17:50.790
(Applause)

00:17:50.814 --> 00:17:53.148
CA: Thank you.
CH: That was really lovely.

00:17:53.172 --> 00:17:54.387
(Applause)

00:17:54.411 --> 00:17:55.576
CA: Thank you.

