WEBVTT
Kind: captions
Language: en

00:00:12.528 --> 00:00:16.477
So in 1885, Karl Benz
invented the automobile.

00:00:16.707 --> 00:00:20.469
Later that year, he took it out
for the first public test drive,

00:00:20.469 --> 00:00:23.844
and -- true story --
crashed into a wall.

00:00:24.184 --> 00:00:26.227
For the last 130 years,

00:00:26.227 --> 00:00:30.546
we've been working around that least
reliable part of the car, the driver.

00:00:30.546 --> 00:00:31.900
We've made the car stronger.

00:00:32.200 --> 00:00:34.748
We've added seat belts,
we've added air bags,

00:00:34.748 --> 00:00:38.719
and in the last decade, we've actually
started trying to make the car smarter

00:00:38.719 --> 00:00:41.657
to fix that bug, the driver.

00:00:41.657 --> 00:00:44.918
Now, today I'm going to talk to you
a little bit about the difference

00:00:44.918 --> 00:00:48.726
between patching around the problem
with driver assistance systems

00:00:48.726 --> 00:00:51.290
and actually having fully
self-driving cars

00:00:51.290 --> 00:00:53.170
and what they can do for the world.

00:00:53.170 --> 00:00:56.165
I'm also going to talk to you
a little bit about our car

00:00:56.165 --> 00:01:00.164
and allow you to see how it sees the world
and how it reacts and what it does,

00:01:00.164 --> 00:01:03.351
but first I'm going to talk
a little bit about the problem.

00:01:03.651 --> 00:01:05.299
And it's a big problem:

00:01:05.299 --> 00:01:08.388
1.2 million people are killed
on the world's roads every year.

00:01:08.388 --> 00:01:12.172
In America alone, 33,000 people
are killed each year.

00:01:12.172 --> 00:01:14.200
To put that in perspective,

00:01:14.200 --> 00:01:18.997
that's the same as a 737
falling out of the sky every working day.

00:01:19.342 --> 00:01:21.128
It's kind of unbelievable.

00:01:21.548 --> 00:01:23.846
Cars are sold to us like this,

00:01:23.846 --> 00:01:26.563
but really, this is what driving's like.

00:01:26.563 --> 00:01:28.722
Right? It's not sunny, it's rainy,

00:01:28.722 --> 00:01:31.210
and you want to do anything
other than drive.

00:01:31.210 --> 00:01:32.832
And the reason why is this:

00:01:32.832 --> 00:01:34.690
Traffic is getting worse.

00:01:34.690 --> 00:01:38.196
In America, between 1990 and 2010,

00:01:38.196 --> 00:01:41.700
the vehicle miles traveled
increased by 38 percent.

00:01:42.213 --> 00:01:44.962
We grew by six percent of roads,

00:01:44.962 --> 00:01:46.564
so it's not in your brains.

00:01:46.564 --> 00:01:50.840
Traffic really is substantially worse
than it was not very long ago.

00:01:50.840 --> 00:01:53.249
And all of this has a very human cost.

00:01:53.529 --> 00:01:57.477
So if you take the average commute time
in America, which is about 50 minutes,

00:01:57.477 --> 00:02:01.126
you multiply that by the 120 million
workers we have,

00:02:01.126 --> 00:02:03.351
that turns out to be
about six billion minutes

00:02:03.351 --> 00:02:05.377
wasted in commuting every day.

00:02:05.377 --> 00:02:08.204
Now, that's a big number,
so let's put it in perspective.

00:02:08.204 --> 00:02:09.978
You take that six billion minutes

00:02:09.978 --> 00:02:13.762
and you divide it by the average
life expectancy of a person,

00:02:13.762 --> 00:02:16.897
that turns out to be 162 lifetimes

00:02:16.897 --> 00:02:19.822
spent every day, wasted,

00:02:19.822 --> 00:02:21.866
just getting from A to B.

00:02:21.866 --> 00:02:23.596
It's unbelievable.

00:02:23.596 --> 00:02:26.440
And then, there are those of us
who don't have the privilege

00:02:26.440 --> 00:02:28.112
of sitting in traffic.

00:02:28.112 --> 00:02:29.690
So this is Steve.

00:02:29.690 --> 00:02:31.455
He's an incredibly capable guy,

00:02:31.455 --> 00:02:33.971
but he just happens to be blind,

00:02:33.971 --> 00:02:37.188
and that means instead of a 30-minute
drive to work in the morning,

00:02:37.188 --> 00:02:41.167
it's a two-hour ordeal
of piecing together bits of public transit

00:02:41.167 --> 00:02:43.552
or asking friends and family for a ride.

00:02:43.552 --> 00:02:47.221
He doesn't have that same freedom
that you and I have to get around.

00:02:47.221 --> 00:02:49.681
We should do something about that.

00:02:49.891 --> 00:02:51.648
Now, conventional wisdom would say

00:02:51.648 --> 00:02:54.140
that we'll just take
these driver assistance systems

00:02:54.140 --> 00:02:57.890
and we'll kind of push them
and incrementally improve them,

00:02:57.890 --> 00:03:00.432
and over time, they'll turn
into self-driving cars.

00:03:00.432 --> 00:03:02.841
Well, I'm here to tell you
that's like me saying

00:03:02.841 --> 00:03:06.898
that if I work really hard at jumping,
one day I'll be able to fly.

00:03:06.898 --> 00:03:09.626
We actually need to do
something a little different.

00:03:09.626 --> 00:03:12.337
And so I'm going to talk to you
about three different ways

00:03:12.337 --> 00:03:15.683
that self-driving systems are different
than driver assistance systems.

00:03:15.683 --> 00:03:18.334
And I'm going to start
with some of our own experience.

00:03:18.334 --> 00:03:20.587
So back in 2013,

00:03:20.587 --> 00:03:23.250
we had the first test
of a self-driving car

00:03:23.250 --> 00:03:25.277
where we let regular people use it.

00:03:25.277 --> 00:03:27.479
Well, almost regular --
they were 100 Googlers,

00:03:27.479 --> 00:03:29.482
but they weren't working on the project.

00:03:29.482 --> 00:03:33.103
And we gave them the car and we allowed
them to use it in their daily lives.

00:03:33.103 --> 00:03:36.822
But unlike a real self-driving car,
this one had a big asterisk with it:

00:03:36.822 --> 00:03:38.326
They had to pay attention,

00:03:38.326 --> 00:03:40.959
because this was an experimental vehicle.

00:03:40.959 --> 00:03:44.484
We tested it a lot,
but it could still fail.

00:03:44.484 --> 00:03:46.543
And so we gave them two hours of training,

00:03:46.543 --> 00:03:48.635
we put them in the car,
we let them use it,

00:03:48.635 --> 00:03:50.762
and what we heard back
was something awesome,

00:03:50.762 --> 00:03:53.286
as someone trying
to bring a product into the world.

00:03:53.286 --> 00:03:55.211
Every one of them told us they loved it.

00:03:55.211 --> 00:03:58.777
In fact, we had a Porsche driver
who came in and told us on the first day,

00:03:58.777 --> 00:04:01.440
"This is completely stupid.
What are we thinking?"

00:04:01.850 --> 00:04:04.690
But at the end of it, he said,
"Not only should I have it,

00:04:04.690 --> 00:04:07.865
everyone else should have it,
because people are terrible drivers."

00:04:09.135 --> 00:04:10.870
So this was music to our ears,

00:04:10.870 --> 00:04:14.673
but then we started to look at what
the people inside the car were doing,

00:04:14.673 --> 00:04:16.252
and this was eye-opening.

00:04:16.252 --> 00:04:18.690
Now, my favorite story is this gentleman

00:04:18.690 --> 00:04:22.519
who looks down at his phone
and realizes the battery is low,

00:04:22.519 --> 00:04:27.067
so he turns around like this in the car
and digs around in his backpack,

00:04:27.067 --> 00:04:29.220
pulls out his laptop,

00:04:29.220 --> 00:04:30.787
puts it on the seat,

00:04:30.787 --> 00:04:32.551
goes in the back again,

00:04:32.551 --> 00:04:35.918
digs around, pulls out
the charging cable for his phone,

00:04:35.918 --> 00:04:39.285
futzes around, puts it into the laptop,
puts it on the phone.

00:04:39.285 --> 00:04:41.328
Sure enough, the phone is charging.

00:04:41.328 --> 00:04:45.322
All the time he's been doing
65 miles per hour down the freeway.

00:04:45.322 --> 00:04:47.806
Right? Unbelievable.

00:04:47.806 --> 00:04:50.927
So we thought about this and we said,
it's kind of obvious, right?

00:04:50.927 --> 00:04:53.190
The better the technology gets,

00:04:53.190 --> 00:04:55.311
the less reliable
the driver is going to get.

00:04:55.311 --> 00:04:57.707
So by just making the cars
incrementally smarter,

00:04:57.707 --> 00:05:00.609
we're probably not going to see
the wins we really need.

00:05:00.609 --> 00:05:04.510
Let me talk about something
a little technical for a moment here.

00:05:04.510 --> 00:05:06.948
So we're looking at this graph,
and along the bottom

00:05:06.948 --> 00:05:09.999
is how often does the car
apply the brakes when it shouldn't.

00:05:09.999 --> 00:05:11.620
You can ignore most of that axis,

00:05:11.620 --> 00:05:15.339
because if you're driving around town,
and the car starts stopping randomly,

00:05:15.339 --> 00:05:17.040
you're never going to buy that car.

00:05:17.040 --> 00:05:20.415
And the vertical axis is how often
the car is going to apply the brakes

00:05:20.415 --> 00:05:23.464
when it's supposed to
to help you avoid an accident.

00:05:23.464 --> 00:05:25.685
Now, if we look at
the bottom left corner here,

00:05:25.685 --> 00:05:27.530
this is your classic car.

00:05:27.530 --> 00:05:30.663
It doesn't apply the brakes for you,
it doesn't do anything goofy,

00:05:30.663 --> 00:05:33.442
but it also doesn't get you
out of an accident.

00:05:33.442 --> 00:05:36.460
Now, if we want to bring
a driver assistance system into a car,

00:05:36.460 --> 00:05:38.288
say with collision mitigation braking,

00:05:38.288 --> 00:05:40.900
we're going to put some package
of technology on there,

00:05:40.900 --> 00:05:44.318
and that's this curve, and it's going
to have some operating properties,

00:05:44.318 --> 00:05:46.808
but it's never going to avoid
all of the accidents,

00:05:46.808 --> 00:05:48.867
because it doesn't have that capability.

00:05:48.867 --> 00:05:51.116
But we'll pick some place
along the curve here,

00:05:51.116 --> 00:05:54.370
and maybe it avoids half of accidents
that the human driver misses,

00:05:54.370 --> 00:05:55.667
and that's amazing, right?

00:05:55.667 --> 00:05:58.394
We just reduced accidents on our roads
by a factor of two.

00:05:58.394 --> 00:06:02.381
There are now 17,000 less people
dying every year in America.

00:06:02.381 --> 00:06:04.401
But if we want a self-driving car,

00:06:04.401 --> 00:06:06.708
we need a technology curve
that looks like this.

00:06:06.708 --> 00:06:09.307
We're going to have to put
more sensors in the vehicle,

00:06:09.307 --> 00:06:11.328
and we'll pick some
operating point up here

00:06:11.328 --> 00:06:13.347
where it basically never
gets into a crash.

00:06:13.347 --> 00:06:15.790
They'll happen, but very low frequency.

00:06:15.790 --> 00:06:18.251
Now you and I could look at this
and we could argue

00:06:18.251 --> 00:06:21.856
about whether it's incremental, and
I could say something like "80-20 rule,"

00:06:21.856 --> 00:06:24.424
and it's really hard to move up
to that new curve.

00:06:24.424 --> 00:06:27.358
But let's look at it
from a different direction for a moment.

00:06:27.358 --> 00:06:30.870
So let's look at how often
the technology has to do the right thing.

00:06:30.870 --> 00:06:34.376
And so this green dot up here
is a driver assistance system.

00:06:34.376 --> 00:06:36.861
It turns out that human drivers

00:06:36.861 --> 00:06:39.508
make mistakes that lead
to traffic accidents

00:06:39.508 --> 00:06:42.680
about once every 100,000 miles in America.

00:06:42.680 --> 00:06:45.847
In contrast, a self-driving system
is probably making decisions

00:06:45.847 --> 00:06:49.510
about 10 times per second,

00:06:49.510 --> 00:06:50.932
so order of magnitude,

00:06:50.932 --> 00:06:53.764
that's about 1,000 times per mile.

00:06:53.764 --> 00:06:56.249
So if you compare the distance
between these two,

00:06:56.249 --> 00:06:58.849
it's about 10 to the eighth, right?

00:06:58.849 --> 00:07:00.614
Eight orders of magnitude.

00:07:00.614 --> 00:07:03.423
That's like comparing how fast I run

00:07:03.423 --> 00:07:05.629
to the speed of light.

00:07:05.629 --> 00:07:09.414
It doesn't matter how hard I train,
I'm never actually going to get there.

00:07:09.414 --> 00:07:11.852
So there's a pretty big gap there.

00:07:11.852 --> 00:07:15.581
And then finally, there's how
the system can handle uncertainty.

00:07:15.581 --> 00:07:18.904
So this pedestrian here might be
stepping into the road, might not be.

00:07:18.904 --> 00:07:22.299
I can't tell,
nor can any of our algorithms,

00:07:22.310 --> 00:07:24.594
but in the case of
a driver assistance system,

00:07:24.594 --> 00:07:27.400
that means it can't take action,
because again,

00:07:27.400 --> 00:07:30.739
if it presses the brakes unexpectedly,
that's completely unacceptable.

00:07:30.739 --> 00:07:33.872
Whereas a self-driving system
can look at that pedestrian and say,

00:07:33.872 --> 00:07:35.762
I don't know what they're about to do,

00:07:35.762 --> 00:07:39.524
slow down, take a better look,
and then react appropriately after that.

00:07:39.524 --> 00:07:43.226
So it can be much safer than
a driver assistance system can ever be.

00:07:43.226 --> 00:07:45.956
So that's enough about
the differences between the two.

00:07:45.956 --> 00:07:49.440
Let's spend some time talking about
how the car sees the world.

00:07:49.440 --> 00:07:50.692
So this is our vehicle.

00:07:50.692 --> 00:07:53.130
It starts by understanding
where it is in the world,

00:07:53.130 --> 00:07:55.917
by taking a map and its sensor data
and aligning the two,

00:07:55.917 --> 00:07:58.865
and then we layer on top of that
what it sees in the moment.

00:07:58.865 --> 00:08:02.520
So here, all the purple boxes you can see
are other vehicles on the road,

00:08:02.520 --> 00:08:05.048
and the red thing on the side
over there is a cyclist,

00:08:05.048 --> 00:08:07.450
and up in the distance,
if you look really closely,

00:08:07.450 --> 00:08:09.244
you can see some cones.

00:08:09.244 --> 00:08:12.017
Then we know where the car
is in the moment,

00:08:12.017 --> 00:08:15.850
but we have to do better than that:
we have to predict what's going to happen.

00:08:15.850 --> 00:08:19.338
So here the pickup truck in top right
is about to make a left lane change

00:08:19.338 --> 00:08:21.561
because the road in front of it is closed,

00:08:21.561 --> 00:08:23.292
so it needs to get out of the way.

00:08:23.292 --> 00:08:25.155
Knowing that one pickup truck is great,

00:08:25.155 --> 00:08:27.634
but we really need to know
what everybody's thinking,

00:08:27.634 --> 00:08:30.141
so it becomes quite a complicated problem.

00:08:30.141 --> 00:08:34.890
And then given that, we can figure out
how the car should respond in the moment,

00:08:34.890 --> 00:08:38.756
so what trajectory it should follow, how
quickly it should slow down or speed up.

00:08:38.756 --> 00:08:41.821
And then that all turns into
just following a path:

00:08:41.821 --> 00:08:45.018
turning the steering wheel left or right,
pressing the brake or gas.

00:08:45.018 --> 00:08:47.482
It's really just two numbers
at the end of the day.

00:08:47.482 --> 00:08:49.723
So how hard can it really be?

00:08:50.433 --> 00:08:52.385
Back when we started in 2009,

00:08:52.385 --> 00:08:54.183
this is what our system looked like.

00:08:54.183 --> 00:08:57.574
So you can see our car in the middle
and the other boxes on the road,

00:08:57.574 --> 00:08:58.845
driving down the highway.

00:08:58.845 --> 00:09:02.663
The car needs to understand where it is
and roughly where the other vehicles are.

00:09:02.663 --> 00:09:05.092
It's really a geometric
understanding of the world.

00:09:05.092 --> 00:09:08.040
Once we started driving
on neighborhood and city streets,

00:09:08.040 --> 00:09:10.485
the problem becomes a whole
new level of difficulty.

00:09:10.485 --> 00:09:13.979
You see pedestrians crossing in front
of us, cars crossing in front of us,

00:09:13.979 --> 00:09:15.790
going every which way,

00:09:15.790 --> 00:09:17.317
the traffic lights, crosswalks.

00:09:17.317 --> 00:09:20.114
It's an incredibly complicated
problem by comparison.

00:09:20.114 --> 00:09:22.217
And then once you have
that problem solved,

00:09:22.217 --> 00:09:24.729
the vehicle has to be able
to deal with construction.

00:09:24.729 --> 00:09:27.880
So here are the cones on the left
forcing it to drive to the right,

00:09:27.880 --> 00:09:30.282
but not just construction
in isolation, of course.

00:09:30.282 --> 00:09:34.005
It has to deal with other people moving
through that construction zone as well.

00:09:34.005 --> 00:09:37.268
And of course, if anyone's
breaking the rules, the police are there

00:09:37.268 --> 00:09:40.890
and the car has to understand that
that flashing light on the top of the car

00:09:40.890 --> 00:09:43.995
means that it's not just a car,
it's actually a police officer.

00:09:43.995 --> 00:09:46.027
Similarly, the orange box
on the side here,

00:09:46.027 --> 00:09:47.136
it's a school bus,

00:09:47.136 --> 00:09:49.656
and we have to treat that
differently as well.

00:09:50.576 --> 00:09:53.369
When we're out on the road,
other people have expectations:

00:09:53.369 --> 00:09:55.149
So, when a cyclist puts up their arm,

00:09:55.149 --> 00:09:58.667
it means they're expecting the car
to yield to them and make room for them

00:09:58.667 --> 00:10:00.720
to make a lane change.

00:10:01.030 --> 00:10:03.203
And when a police officer
stood in the road,

00:10:03.203 --> 00:10:05.943
our vehicle should understand
that this means stop,

00:10:05.943 --> 00:10:09.449
and when they signal to go,
we should continue.

00:10:09.449 --> 00:10:13.210
Now, the way we accomplish this
is by sharing data between the vehicles.

00:10:13.210 --> 00:10:14.906
The first, most crude model of this

00:10:14.906 --> 00:10:17.019
is when one vehicle
sees a construction zone,

00:10:17.019 --> 00:10:20.081
having another know about it
so it can be in the correct lane

00:10:20.081 --> 00:10:21.651
to avoid some of the difficulty.

00:10:21.651 --> 00:10:24.315
But we actually have a much
deeper understanding of this.

00:10:24.315 --> 00:10:27.324
We could take all of the data
that the cars have seen over time,

00:10:27.324 --> 00:10:29.700
the hundreds of thousands
of pedestrians, cyclists,

00:10:29.700 --> 00:10:31.487
and vehicles that have been out there

00:10:31.487 --> 00:10:33.182
and understand what they look like

00:10:33.182 --> 00:10:36.013
and use that to infer
what other vehicles should look like

00:10:36.013 --> 00:10:37.939
and other pedestrians should look like.

00:10:37.939 --> 00:10:40.960
And then, even more importantly,
we could take from that a model

00:10:40.960 --> 00:10:43.290
of how we expect them
to move through the world.

00:10:43.290 --> 00:10:46.253
So here the yellow box is a pedestrian
crossing in front of us.

00:10:46.253 --> 00:10:48.503
Here the blue box is a cyclist
and we anticipate

00:10:48.503 --> 00:10:51.815
that they're going to nudge out
and around the car to the right.

00:10:52.115 --> 00:10:54.207
Here there's a cyclist
coming down the road

00:10:54.207 --> 00:10:57.693
and we know they're going to continue
to drive down the shape of the road.

00:10:57.693 --> 00:10:59.560
Here somebody makes a right turn,

00:10:59.560 --> 00:11:02.920
and in a moment here, somebody's
going to make a U-turn in front of us,

00:11:02.920 --> 00:11:05.534
and we can anticipate that behavior
and respond safely.

00:11:05.534 --> 00:11:08.262
Now, that's all well and good
for things that we've seen,

00:11:08.262 --> 00:11:11.127
but of course, you encounter
lots of things that you haven't

00:11:11.127 --> 00:11:12.358
seen in the world before.

00:11:12.358 --> 00:11:14.099
And so just a couple of months ago,

00:11:14.099 --> 00:11:16.334
our vehicles were driving
through Mountain View,

00:11:16.334 --> 00:11:17.978
and this is what we encountered.

00:11:17.978 --> 00:11:20.060
This is a woman in an electric wheelchair

00:11:20.060 --> 00:11:22.677
chasing a duck in circles on the road.
(Laughter)

00:11:22.677 --> 00:11:25.788
Now it turns out, there is nowhere
in the DMV handbook

00:11:25.788 --> 00:11:28.033
that tells you how to deal with that,

00:11:28.033 --> 00:11:30.176
but our vehicles were able
to encounter that,

00:11:30.176 --> 00:11:32.431
slow down, and drive safely.

00:11:32.431 --> 00:11:34.472
Now, we don't have to deal
with just ducks.

00:11:34.472 --> 00:11:38.180
Watch this bird fly across in front of us.
The car reacts to that.

00:11:38.180 --> 00:11:39.795
Here we're dealing with a cyclist

00:11:39.795 --> 00:11:43.085
that you would never expect to see
anywhere other than Mountain View.

00:11:43.085 --> 00:11:45.153
And of course, we have
to deal with drivers,

00:11:45.153 --> 00:11:48.868
even the very small ones.

00:11:48.868 --> 00:11:52.999
Watch to the right as someone
jumps out of this truck at us.

00:11:54.460 --> 00:11:57.389
And now, watch the left as the car
with the green box decides

00:11:57.389 --> 00:12:00.714
he needs to make a right turn
at the last possible moment.

00:12:00.714 --> 00:12:03.565
Here, as we make a lane change,
the car to our left decides

00:12:03.565 --> 00:12:07.118
it wants to as well.

00:12:07.118 --> 00:12:09.811
And here, we watch a car
blow through a red light

00:12:09.811 --> 00:12:11.901
and yield to it.

00:12:11.901 --> 00:12:15.755
And similarly, here, a cyclist
blowing through that light as well.

00:12:15.755 --> 00:12:18.501
And of course,
the vehicle responds safely.

00:12:18.501 --> 00:12:21.102
And of course, we have people
who do I don't know what

00:12:21.102 --> 00:12:24.925
sometimes on the road, like this guy
pulling out between two self-driving cars.

00:12:24.925 --> 00:12:26.970
You have to ask, "What are you thinking?"

00:12:26.970 --> 00:12:28.182
(Laughter)

00:12:28.182 --> 00:12:30.703
Now, I just fire-hosed you
with a lot of stuff there,

00:12:30.703 --> 00:12:33.353
so I'm going to break one of these
down pretty quickly.

00:12:33.353 --> 00:12:36.293
So what we're looking at is the scene
with the cyclist again,

00:12:36.293 --> 00:12:39.784
and you might notice in the bottom,
we can't actually see the cyclist yet,

00:12:39.784 --> 00:12:42.288
but the car can: it's that little
blue box up there,

00:12:42.288 --> 00:12:44.369
and that comes from the laser data.

00:12:44.369 --> 00:12:46.787
And that's not actually
really easy to understand,

00:12:46.787 --> 00:12:50.371
so what I'm going to do is I'm going
to turn that laser data and look at it,

00:12:50.371 --> 00:12:53.400
and if you're really good at looking
at laser data, you can see

00:12:53.400 --> 00:12:54.887
a few dots on the curve there,

00:12:54.887 --> 00:12:57.259
right there, and that blue box
is that cyclist.

00:12:57.259 --> 00:12:58.408
Now as our light is red,

00:12:58.408 --> 00:13:00.600
the cyclist's light
has turned yellow already,

00:13:00.600 --> 00:13:03.038
and if you squint, you can see that
in the imagery.

00:13:03.038 --> 00:13:06.324
But the cyclist, we see, is going
to proceed through the intersection.

00:13:06.324 --> 00:13:08.718
Our light has now turned green,
his is solidly red,

00:13:08.718 --> 00:13:13.010
and we now anticipate that this bike
is going to come all the way across.

00:13:13.010 --> 00:13:16.752
Unfortunately the other drivers next to us
were not paying as much attention.

00:13:16.752 --> 00:13:19.909
They started to pull forward,
and fortunately for everyone,

00:13:19.909 --> 00:13:22.920
this cyclists reacts, avoids,

00:13:22.920 --> 00:13:25.111
and makes it through the intersection.

00:13:25.111 --> 00:13:26.679
And off we go.

00:13:26.679 --> 00:13:29.627
Now, as you can see, we've made
some pretty exciting progress,

00:13:29.627 --> 00:13:31.529
and at this point we're pretty convinced

00:13:31.529 --> 00:13:33.539
this technology is going
to come to market.

00:13:33.539 --> 00:13:38.322
We do three million miles of testing
in our simulators every single day,

00:13:38.322 --> 00:13:41.011
so you can imagine the experience
that our vehicles have.

00:13:41.011 --> 00:13:43.875
We are looking forward to having
this technology on the road,

00:13:43.875 --> 00:13:46.765
and we think the right path
is to go through the self-driving

00:13:46.765 --> 00:13:48.609
rather than driver assistance approach

00:13:48.609 --> 00:13:51.230
because the urgency is so large.

00:13:51.230 --> 00:13:53.623
In the time I have given this talk today,

00:13:53.623 --> 00:13:56.758
34 people have died on America's roads.

00:13:56.758 --> 00:13:59.126
How soon can we bring it out?

00:13:59.126 --> 00:14:02.958
Well, it's hard to say because
it's a really complicated problem,

00:14:02.958 --> 00:14:05.172
but these are my two boys.

00:14:05.172 --> 00:14:08.795
My oldest son is 11, and that means
in four and a half years,

00:14:08.795 --> 00:14:11.372
he's going to be able
to get his driver's license.

00:14:11.372 --> 00:14:14.576
My team and I are committed
to making sure that doesn't happen.

00:14:14.576 --> 00:14:16.480
Thank you.

00:14:16.480 --> 00:14:20.147
(Laughter) (Applause)

00:14:21.110 --> 00:14:23.678
Chris Anderson: Chris,
I've got a question for you.

00:14:23.678 --> 00:14:26.487
Chris Urmson: Sure.

00:14:26.487 --> 00:14:30.411
CA: So certainly, the mind of your cars
is pretty mind-boggling.

00:14:30.411 --> 00:14:34.870
On this debate between
driver-assisted and fully driverless --

00:14:34.870 --> 00:14:37.911
I mean, there's a real debate
going on out there right now.

00:14:37.911 --> 00:14:40.744
So some of the companies,
for example, Tesla,

00:14:40.744 --> 00:14:42.903
are going the driver-assisted route.

00:14:42.903 --> 00:14:48.151
What you're saying is that
that's kind of going to be a dead end

00:14:48.151 --> 00:14:53.607
because you can't just keep improving
that route and get to fully driverless

00:14:53.607 --> 00:14:57.137
at some point, and then a driver
is going to say, "This feels safe,"

00:14:57.137 --> 00:14:59.784
and climb into the back,
and something ugly will happen.

00:14:59.784 --> 00:15:02.460
CU: Right. No, that's exactly right,
and it's not to say

00:15:02.460 --> 00:15:05.997
that the driver assistance systems
aren't going to be incredibly valuable.

00:15:05.997 --> 00:15:08.055
They can save a lot of lives
in the interim,

00:15:08.055 --> 00:15:11.888
but to see the transformative opportunity
to help someone like Steve get around,

00:15:11.888 --> 00:15:13.857
to really get to the end case in safety,

00:15:13.857 --> 00:15:16.336
to have the opportunity
to change our cities

00:15:16.336 --> 00:15:20.540
and move parking out and get rid of
these urban craters we call parking lots,

00:15:20.540 --> 00:15:21.780
it's the only way to go.

00:15:21.780 --> 00:15:24.498
CA: We will be tracking your progress
with huge interest.

00:15:24.498 --> 00:15:28.730
Thanks so much, Chris.
CU: Thank you. (Applause)

