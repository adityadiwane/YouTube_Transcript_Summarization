WEBVTT
Kind: captions
Language: cs

00:00:00.000 --> 00:00:07.000
Překladatel: Tomáš Křehlík
Korektor: Jan Kadlec

00:00:15.260 --> 00:00:17.260
Tohle je fotka

00:00:17.260 --> 00:00:19.260
vytvořená umělcem, který se jmenuje Michael Najjar,

00:00:19.260 --> 00:00:21.260
a je reálná

00:00:21.260 --> 00:00:23.260
protože jel do Argentiny,

00:00:23.260 --> 00:00:25.260
aby to vyfotil.

00:00:25.260 --> 00:00:28.260
Ale je to taky fikce. Hodně na té fotce pracoval i potom.

00:00:28.260 --> 00:00:30.260
A tady je co udělal:

00:00:30.260 --> 00:00:32.260
digitálně upravil

00:00:32.260 --> 00:00:34.260
všechny obrysy a vrcholky hor,

00:00:34.260 --> 00:00:37.260
aby vypadaly jako vývoj Dow Jones indexu.

00:00:37.260 --> 00:00:39.260
Takže to, co vidíte,

00:00:39.260 --> 00:00:41.260
ten sráz, ta stěna s údolím,

00:00:41.260 --> 00:00:43.260
je finanční krize v roce 2008.

00:00:43.260 --> 00:00:45.260
Ta fotka byla vytvořená,

00:00:45.260 --> 00:00:47.260
když jsme byli hluboko v tamtom údolí.

00:00:47.260 --> 00:00:49.260
Netuším, kde jsme teď.

00:00:49.260 --> 00:00:51.260
Tohle je Hang Seng index

00:00:51.260 --> 00:00:53.260
pro Hong Kong.

00:00:53.260 --> 00:00:55.260
A podobný tvar.

00:00:55.260 --> 00:00:57.260
Přemýšlím proč.

00:00:57.260 --> 00:01:00.260
A tohle je umění. Tohle je metafora.

00:01:00.260 --> 00:01:02.260
Ale myslím, že je důležité,

00:01:02.260 --> 00:01:04.260
že je to břitká metafora.

00:01:04.260 --> 00:01:07.260
A stejně ostře bych rád dnes navrhl,

00:01:07.260 --> 00:01:09.260
abychom se trochu zamysleli

00:01:09.260 --> 00:01:12.260
nad rolí matematiky,

00:01:12.260 --> 00:01:15.260
nejenom finanční matematiky, ale matematiky obecně.

00:01:15.260 --> 00:01:17.260
A její přerod

00:01:17.260 --> 00:01:20.260
z něčeho, co jsme dostávali a odvozovali ze světa

00:01:20.260 --> 00:01:23.260
v něco, co začíná svět, kolem nás

00:01:23.260 --> 00:01:26.260
a v nás, utvářet.

00:01:26.260 --> 00:01:28.260
A jsou to především algoritmy,

00:01:28.260 --> 00:01:30.260
které jsou vlastně matematika,

00:01:30.260 --> 00:01:33.260
kterou používají počítače, aby rozhodovali věci.

00:01:33.260 --> 00:01:35.260
Učí se být citlivé vůči podstatě,

00:01:35.260 --> 00:01:37.260
protože se opakují pořád dokola.

00:01:37.260 --> 00:01:40.260
A tak kostnatí

00:01:40.260 --> 00:01:42.260
a stávají se reálnými.

00:01:42.260 --> 00:01:45.260
A přemýšlel jsem o tom hlavně,

00:01:45.260 --> 00:01:48.260
když jsem letěl před několika lety přes Atlantik,

00:01:48.260 --> 00:01:50.260
protože jsem se náhodou ocitl

00:01:50.260 --> 00:01:52.260
vedle maďarského fyzika, zhruba stejně starého.

00:01:52.260 --> 00:01:54.260
A tak jsme si povídali

00:01:54.260 --> 00:01:56.260
o tom, jaký byl život během studené války

00:01:56.260 --> 00:01:58.260
pro fyziky v Maďarsku.

00:01:58.260 --> 00:02:00.260
A tak mu říkám: "Co jste tenkrát dělali?"

00:02:00.260 --> 00:02:02.260
On na to: "Tak, hlavně jsme se snažili prolomit maskovací technologie."

00:02:02.260 --> 00:02:04.260
"To je dobrá práce, to je zajímavé.

00:02:04.260 --> 00:02:06.260
Jak to fungovalo?"

00:02:06.260 --> 00:02:08.260
A abyste tomu porozuměli,

00:02:08.260 --> 00:02:11.260
musíte trochu vědět, jak fungují maskovací technologie.

00:02:11.260 --> 00:02:14.260
No, hodně to zjednodušuji,

00:02:14.260 --> 00:02:16.260
ale vlastně… nemůžete

00:02:16.260 --> 00:02:18.260
jen tak dostat radarový signál

00:02:18.260 --> 00:02:21.260
skrz 156 tun železa, co je ve vzduchu.

00:02:21.260 --> 00:02:24.260
Jen tak to nezmizí.

00:02:24.260 --> 00:02:27.260
Ale když dokážete vzít tuhle obrovskou masivní věc

00:02:27.260 --> 00:02:30.260
a změnit ji v

00:02:30.260 --> 00:02:32.260
milion malých věcí,

00:02:32.260 --> 00:02:34.260
něco jako hejno ptáků,

00:02:34.260 --> 00:02:36.260
tak radar, který to hledá,

00:02:36.260 --> 00:02:38.260
musí vidět

00:02:38.260 --> 00:02:40.260
každé hejno ptáků na obloze.

00:02:40.260 --> 00:02:44.260
A pokud jste radar, tak je to fakt blbej úkol.

00:02:44.260 --> 00:02:47.260
A on mi na to povídá: "Jasně, pokud jsi radar.

00:02:47.260 --> 00:02:49.260
Takže jsme nepoužili radar.

00:02:49.260 --> 00:02:52.260
Postavili jsme černou skříňku, která hledá elektronické signály,

00:02:52.260 --> 00:02:55.260
elektronickou komunikaci.

00:02:55.260 --> 00:02:58.260
A když jsme viděli hejno ptáků, ve kterém byla nějaká elektronická komunikace,

00:02:58.260 --> 00:03:01.260
řekli jsme si, že to asi bude mít co dělat s Američany."

00:03:01.260 --> 00:03:03.260
A já mu povídám: "Jo,

00:03:03.260 --> 00:03:05.260
to je dobrý.

00:03:05.260 --> 00:03:07.260
Takže jste v podstatě zničili

00:03:07.260 --> 00:03:09.260
60 let leteckého výzkumu.

00:03:09.260 --> 00:03:11.260
Co je druhé dějství?

00:03:11.260 --> 00:03:13.260
Co děláš, když jsi vyrostl?"

00:03:13.260 --> 00:03:15.260
On na to:

00:03:15.260 --> 00:03:17.260
"To víš, finanční služby."

00:03:17.260 --> 00:03:19.260
Já mu povídám: "Hmm."

00:03:19.260 --> 00:03:22.260
Protože zrovna nedávno byly ve zprávách.

00:03:22.260 --> 00:03:24.260
Tak se ho ptám: "Jak to funguje?"

00:03:24.260 --> 00:03:26.260
A on na to: "Na Wall Street je teď 2000 fyziků

00:03:26.260 --> 00:03:28.260
a já jsem jeden z nich."

00:03:28.260 --> 00:03:31.260
"A jaká je černá skříňka pro Wall Street?"

00:03:31.260 --> 00:03:33.260
A on povídá: "To je vtipný, že se ptáš zrovna takhle,

00:03:33.260 --> 00:03:36.260
protože se tomu říká obchodování přes černou skříňku.

00:03:36.260 --> 00:03:38.260
Nebo taky občas algo obchodování,

00:03:38.260 --> 00:03:41.260
algoritmické obchodování."

00:03:41.260 --> 00:03:44.260
A algoritmické obchodování se rozvinulo zčásti proto,

00:03:44.260 --> 00:03:47.260
že institucionální obchodníci měli stejné problémy,

00:03:47.260 --> 00:03:50.260
jako mělo letectvo Spojených států,

00:03:50.260 --> 00:03:53.260
protože přetvářeli své finanční pozice,

00:03:53.260 --> 00:03:55.260
ať to byl Proctor &amp; Gamble nebo Accenture, to je jedno,

00:03:55.260 --> 00:03:57.260
přesouvali miliony akcií něčeho

00:03:57.260 --> 00:03:59.260
skrz trh.

00:03:59.260 --> 00:04:01.260
A pokud by to udělali všechno najednou,

00:04:01.260 --> 00:04:03.260
bylo by to jako hrát poker a hned vsadit všechno.

00:04:03.260 --> 00:04:05.260
Všichni by věděli, co plánují.

00:04:05.260 --> 00:04:07.260
A tak potřebovali najít způsob,

00:04:07.260 --> 00:04:09.260
jak rozdělit jednu velkou věc

00:04:09.260 --> 00:04:11.260
na milion malých transakcí –

00:04:11.260 --> 00:04:13.260
a k tomu použili algoritmy.

00:04:13.260 --> 00:04:15.260
A to kouzlo a děs je v tom,

00:04:15.260 --> 00:04:17.260
že ta stejná matematika,

00:04:17.260 --> 00:04:19.260
kterou používáme, abychom rozdělili jednu velkou věc

00:04:19.260 --> 00:04:21.260
na milion malých,

00:04:21.260 --> 00:04:23.260
se dá použít, abychom našli milion malých věcí

00:04:23.260 --> 00:04:25.260
a dali je zpátky dohromady

00:04:25.260 --> 00:04:27.260
a přišli na to, co se vlastně na trhu děje.

00:04:27.260 --> 00:04:29.260
Takže abyste si trochu představili,

00:04:29.260 --> 00:04:32.260
co se vlastně dneska děje na akciových trzích,

00:04:32.260 --> 00:04:34.260
představte si spoustu algoritmů,

00:04:34.260 --> 00:04:37.260
které jsou naprogramovány, aby se schovávaly,

00:04:37.260 --> 00:04:40.260
a spoustu algoritmů, které jsou naprogramovány, aby našly ty, co se schovávají.

00:04:40.260 --> 00:04:43.260
A všechno to je super a je to v pohodě.

00:04:43.260 --> 00:04:45.260
A je to 70 %

00:04:45.260 --> 00:04:47.260
amerického akciového trhu,

00:04:47.260 --> 00:04:49.260
70 % operačního systému,

00:04:49.260 --> 00:04:52.260
kterému se dřív říkalo penze

00:04:52.260 --> 00:04:55.260
nebo půjčka.

00:04:55.260 --> 00:04:57.260
A co by se mohlo porouchat?

00:04:57.260 --> 00:04:59.260
Co se mohlo stát je,

00:04:59.260 --> 00:05:01.260
že před rokem

00:05:01.260 --> 00:05:04.260
devět procent celého trhu jen tak zmizelo během pěti minut.

00:05:04.260 --> 00:05:07.260
A dneska se tomu říká propad ve 2:45.

00:05:07.260 --> 00:05:10.260
Z ničeho nic, devět procent zmizelo

00:05:10.260 --> 00:05:12.260
a dodneška

00:05:12.260 --> 00:05:14.260
se nedokážeme shodnout, co se stalo,

00:05:14.260 --> 00:05:17.260
protože to nikdo nezpůsobil, nikdo o to nepožádal.

00:05:17.260 --> 00:05:20.260
Nikdo neměl kontrolu nad tím, co se tenkrát dělo.

00:05:20.260 --> 00:05:22.260
Všechno co měli

00:05:22.260 --> 00:05:24.260
byl monitor,

00:05:24.260 --> 00:05:26.260
čísla na něm

00:05:26.260 --> 00:05:28.260
a jedno červené tlačítko,

00:05:28.260 --> 00:05:30.260
na kterém bylo napsáno "Stop."

00:05:30.260 --> 00:05:32.260
A to je ono,

00:05:32.260 --> 00:05:34.260
píšeme věci,

00:05:34.260 --> 00:05:37.260
píšeme věci, které už nedokážeme přečíst.

00:05:37.260 --> 00:05:39.260
A vytvořili jsme něco

00:05:39.260 --> 00:05:41.260
nečitelného.

00:05:41.260 --> 00:05:44.260
A ztratili jsme ponětí o tom,

00:05:44.260 --> 00:05:46.260
co se vlastně děje

00:05:46.260 --> 00:05:48.260
ve světě, který jsme stvořili.

00:05:48.260 --> 00:05:50.260
A postupně se k tomu dostáváme.

00:05:50.260 --> 00:05:53.260
V Bostonu je firma, která se jmenuje Nanex,

00:05:53.260 --> 00:05:55.260
a tam používají matematiku a magii

00:05:55.260 --> 00:05:57.260
a ještě nevím co,

00:05:57.260 --> 00:05:59.260
aby koukali do tržních dat

00:05:59.260 --> 00:06:02.260
a občas tam nacházeli některé tyhle algoritmy.

00:06:02.260 --> 00:06:05.260
A když je najdou, tak je vytáhnou

00:06:05.260 --> 00:06:08.260
a připíchnou je na zeď jako motýly.

00:06:08.260 --> 00:06:10.260
A taky dělají, co jsme vždycky dělali,

00:06:10.260 --> 00:06:13.260
když jsme čelili obrovskému množství dat, kterým nerozumíme.

00:06:13.260 --> 00:06:15.260
Pojmenovávají je

00:06:15.260 --> 00:06:17.260
a vyprávějí jejich příběh.

00:06:17.260 --> 00:06:19.260
Tohle je jeden, který našli,

00:06:19.260 --> 00:06:23.260
nazvali ho Nůž,

00:06:23.260 --> 00:06:25.260
Karneval,

00:06:25.260 --> 00:06:29.260
Žonglér,

00:06:29.260 --> 00:06:31.260
Soumrak.

00:06:31.260 --> 00:06:33.260
A vtip je v tom,

00:06:33.260 --> 00:06:36.260
že tyhle nejsou jenom na trzích.

00:06:36.260 --> 00:06:39.260
Tyhle věci najdete, kam se podíváte,

00:06:39.260 --> 00:06:41.260
pokud víte, jak se koukat.

00:06:41.260 --> 00:06:44.260
Najdete ji tady. Tahle kniha o mouchách,

00:06:44.260 --> 00:06:46.260
kterou jste možná hledali na Amazonu.

00:06:46.260 --> 00:06:48.260
Možná jste si všimli,

00:06:48.260 --> 00:06:50.260
že její cena byla 1.7 miliónu dolarů.

00:06:50.260 --> 00:06:52.260
Sice už se netiskne, ale stejně...

00:06:52.260 --> 00:06:54.260
(Smích)

00:06:54.260 --> 00:06:57.260
Pokud jste to koupili za 1.7, bylo to nakonec za babku.

00:06:57.260 --> 00:06:59.260
Za pár hodin cena vyskočila

00:06:59.260 --> 00:07:01.260
na 23.6 miliónu dolarů

00:07:01.260 --> 00:07:03.260
plus poštovné a balné.

00:07:03.260 --> 00:07:05.260
A otázka je,

00:07:05.260 --> 00:07:07.260
nikdo nic neprodával ani nekupoval, tak co se vlastně dělo?

00:07:07.260 --> 00:07:09.260
A můžete vidět tenhle druh chování na Amazonu

00:07:09.260 --> 00:07:11.260
stejně jistě jako ho uvidíte na Wall Streetu.

00:07:11.260 --> 00:07:13.260
A když něco takového uvidíte,

00:07:13.260 --> 00:07:15.260
to co vidíte je důkaz

00:07:15.260 --> 00:07:17.260
algoritmů v konfliktu,

00:07:17.260 --> 00:07:19.260
algoritmů, které jsou vzájemně uvězněny ve smyčce,

00:07:19.260 --> 00:07:21.260
bez jakéhokoliv lidského dohledu,

00:07:21.260 --> 00:07:24.260
bez dohledu dospělých,

00:07:24.260 --> 00:07:27.260
kteří by řekli: "Hmm, 1.7 milionu je dost."

00:07:27.260 --> 00:07:30.260
(Smích)

00:07:30.260 --> 00:07:33.260
A jako s Amazonem, stejné je to na Netflixu.

00:07:33.260 --> 00:07:35.260
A tak Netflix prošel

00:07:35.260 --> 00:07:37.260
za několik let různé algoritmy.

00:07:37.260 --> 00:07:40.260
Začali s Cinematch a vyzkoušeli několik dalších.

00:07:40.260 --> 00:07:42.260
Tady je Dinosauří planeta, tady Přitažlivost.

00:07:42.260 --> 00:07:44.260
Teď používají Pragmatický chaos.

00:07:44.260 --> 00:07:46.260
Pragmatický chaos, stejně jako všechny algoritmy Netflixu,

00:07:46.260 --> 00:07:48.260
se snaží o stejnou věc.

00:07:48.260 --> 00:07:50.260
Snaží se vám přijít na kloub,

00:07:50.260 --> 00:07:52.260
na to, jaký je firmware uvnitř lidské lebky,

00:07:52.260 --> 00:07:54.260
aby vám mohl doporučit film,

00:07:54.260 --> 00:07:56.260
na který se budete chtít podívat příště.

00:07:56.260 --> 00:07:59.260
A to je opravdu, opravdu složitý problém.

00:07:59.260 --> 00:08:01.260
Ale složitost toho problému

00:08:01.260 --> 00:08:04.260
a fakt, že se jim to zatím nepovedlo,

00:08:04.260 --> 00:08:06.260
nic neubírá

00:08:06.260 --> 00:08:08.260
na efektech, které Pragmatický chaos má.

00:08:08.260 --> 00:08:11.260
Pragmatický chaos, jako ostatní algoritmy Netflixu,

00:08:11.260 --> 00:08:13.260
nakonec určí

00:08:13.260 --> 00:08:15.260
60 procent

00:08:15.260 --> 00:08:17.260
filmů, které si nakonec vypůjčíte.

00:08:17.260 --> 00:08:19.260
Takže jeden kousek kódu

00:08:19.260 --> 00:08:22.260
s jednou představou o vás

00:08:22.260 --> 00:08:25.260
je zodpovědný za 60 procent filmů, které si půjčíte.

00:08:25.260 --> 00:08:27.260
Ale co kdybyste mohli ty filmy ohodnotit

00:08:27.260 --> 00:08:29.260
před tím, než se natočí?

00:08:29.260 --> 00:08:31.260
Nebylo by to praktické?

00:08:31.260 --> 00:08:34.260
No, pár statistiků z UK v Hollywoodu je

00:08:34.260 --> 00:08:36.260
a mají algoritmy na příběh.

00:08:36.260 --> 00:08:38.260
Společnost, která se jmenuje Epagogix.

00:08:38.260 --> 00:08:41.260
Můžete jim dát scénář, aby ho projeli,

00:08:41.260 --> 00:08:43.260
a oni vám řeknou, kvantifikovatelně,

00:08:43.260 --> 00:08:45.260
že film vydělá 30 milionů dolarů

00:08:45.260 --> 00:08:47.260
nebo 200 milionů.

00:08:47.260 --> 00:08:49.260
A průšvih je, že tohle není Google.

00:08:49.260 --> 00:08:51.260
Tohle nejsou informace.

00:08:51.260 --> 00:08:53.260
Nebo finanční ukazatele. To je kultura.

00:08:53.260 --> 00:08:55.260
A co tady vidíte

00:08:55.260 --> 00:08:57.260
nebo co tu normálně nevidíte je,

00:08:57.260 --> 00:09:01.260
že tohle je fyzika kultury.

00:09:01.260 --> 00:09:03.260
A pokud by tyhle algoritmy,

00:09:03.260 --> 00:09:05.260
jako algoritmy na Wall Streetu,

00:09:05.260 --> 00:09:08.260
jednoho dne zkolabovaly a nevyšlo by to,

00:09:08.260 --> 00:09:10.260
jak máme vědět,

00:09:10.260 --> 00:09:12.260
jak to bude vypadat?

00:09:12.260 --> 00:09:15.260
A jsou ve vašem domě. Ve vašem domě.

00:09:15.260 --> 00:09:17.260
Tyhle dva algoritmy soupeří o váš obývák.

00:09:17.260 --> 00:09:19.260
To jsou dva automatické vysavače,

00:09:19.260 --> 00:09:22.260
každý má úplně jinou představu o uklízení.

00:09:22.260 --> 00:09:24.260
A vy to vidíte,

00:09:24.260 --> 00:09:27.260
když to zpomalíte a připnete k nim světlo.

00:09:27.260 --> 00:09:30.260
A jsou trochu jako architekti ve vaší ložnici.

00:09:30.260 --> 00:09:33.260
A myšlenka, že sama architektura

00:09:33.260 --> 00:09:35.260
jaksi podléhá algoritmické optimalizaci,

00:09:35.260 --> 00:09:37.260
není úplně přehnaná.

00:09:37.260 --> 00:09:40.260
Je to sakra reálné a děje se to kolem vás.

00:09:40.260 --> 00:09:42.260
Nejvíc to cítíte,

00:09:42.260 --> 00:09:44.260
když jste zavření v železné krabici,

00:09:44.260 --> 00:09:46.260
moderním výtahu.

00:09:46.260 --> 00:09:48.260
Říkají jim výtahy, které kontrolují destinaci.

00:09:48.260 --> 00:09:51.260
To jsou ty, u kterých musíte zmáčknout patro, kam jedete,

00:09:51.260 --> 00:09:53.260
před tím než nastoupíte.

00:09:53.260 --> 00:09:55.260
Používají bin-packing algoritmus.

00:09:55.260 --> 00:09:57.260
Takže žádné bláznovství,

00:09:57.260 --> 00:09:59.260
že si každý může jít, do kterého výtahu chce.

00:09:59.260 --> 00:10:01.260
Každý kdo jede do 10. patra, jde do dvojky,

00:10:01.260 --> 00:10:04.260
a každý kdo jede do třetího, jde do výtahu číslo 5.

00:10:04.260 --> 00:10:06.260
Ale problém je,

00:10:06.260 --> 00:10:08.260
že lidé z toho šílí.

00:10:08.260 --> 00:10:10.260
Propadají panice.

00:10:10.260 --> 00:10:12.260
A vidíte proč.

00:10:12.260 --> 00:10:14.260
Je to kvůli tomu,

00:10:14.260 --> 00:10:17.260
že výtah nemá jednu důležitou součást. Tlačítka.

00:10:17.260 --> 00:10:19.260
(Smích)

00:10:19.260 --> 00:10:21.260
Jako ty věci, které lidé používají.

00:10:21.260 --> 00:10:23.260
Všechno, co má,

00:10:23.260 --> 00:10:26.260
je číslo, které se hýbe buď nahoru nebo dolů

00:10:26.260 --> 00:10:29.260
a červené tlačítko, na kterém je napsáno: "Stop."

00:10:29.260 --> 00:10:32.260
A tímhle způsobem designujeme.

00:10:32.260 --> 00:10:34.260
Designujeme

00:10:34.260 --> 00:10:36.260
v jazyku strojů.

00:10:36.260 --> 00:10:39.260
A kam se to až může vyvinout? Kam?

00:10:39.260 --> 00:10:41.260
Může se to hodně přehnat.

00:10:41.260 --> 00:10:44.260
Vraťme se na Wall Street.

00:10:45.260 --> 00:10:47.260
Protože algoritmy na Wall Streetu

00:10:47.260 --> 00:10:50.260
jsou závislé především na jedné věci

00:10:50.260 --> 00:10:52.260
a tou je rychlost.

00:10:52.260 --> 00:10:55.260
Pracují v milisekundách a mikrosekundách.

00:10:55.260 --> 00:10:57.260
Abyste pochopili, co jsou mikrosekundy:

00:10:57.260 --> 00:10:59.260
zabere vám 500 000 mikrosekund

00:10:59.260 --> 00:11:01.260
jen abyste klikli myší.

00:11:01.260 --> 00:11:03.260
Ale když jste algoritmus na Wall Streetu

00:11:03.260 --> 00:11:05.260
a jste pozadu o pět mikrosekund,

00:11:05.260 --> 00:11:07.260
jste nula.

00:11:07.260 --> 00:11:09.260
Takže pokud jste algoritmus,

00:11:09.260 --> 00:11:12.260
hledali byste architekta jako jsem já potkal ve Frankfurtu.

00:11:12.260 --> 00:11:14.260
Vyklízel mrakodrap,

00:11:14.260 --> 00:11:17.260
vyhazoval všechen nábytek, zařízení pro lidi,

00:11:17.260 --> 00:11:20.260
a dával na zem železo,

00:11:20.260 --> 00:11:23.260
aby se připravil na skříně serverů.

00:11:23.260 --> 00:11:25.260
Všechno to jen kvůli tomu,

00:11:25.260 --> 00:11:28.260
aby se algoritmus dostal blíž k Internetu.

00:11:28.260 --> 00:11:31.260
A čekali byste, že Internet bude distribuovaný systém.

00:11:31.260 --> 00:11:34.260
Jasně, je, ale přece jen odněkud.

00:11:34.260 --> 00:11:36.260
V New Yorku je distribuovaný z

00:11:36.260 --> 00:11:38.260
Carrier Hotelu,

00:11:38.260 --> 00:11:40.260
který je na Hudson Street.

00:11:40.260 --> 00:11:43.260
A to je místo, kde dráty přichází přímo do města.

00:11:43.260 --> 00:11:47.260
A čím dál odtamtud jste,

00:11:47.260 --> 00:11:49.260
pokaždé budete mít několik mikrosekund zpoždění.

00:11:49.260 --> 00:11:51.260
Tihle fešáci na Wall Streetu,

00:11:51.260 --> 00:11:53.260
Marco Polo a Cherokee Nation,

00:11:53.260 --> 00:11:55.260
jsou osm mikrosekund

00:11:55.260 --> 00:11:57.260
pozadu oproti všem těmhle krasavcům,

00:11:57.260 --> 00:12:01.260
kteří jsou v prázdných vyklízených budovách

00:12:01.260 --> 00:12:03.260
kolem Carrier Hotelu.

00:12:03.260 --> 00:12:06.260
To se děje,

00:12:06.260 --> 00:12:08.260
vyklízíme je,

00:12:08.260 --> 00:12:11.260
protože vy, milimetr po milimetru,

00:12:11.260 --> 00:12:14.260
gram po gramu, dolar po dolaru,

00:12:14.260 --> 00:12:17.260
nikdo z vás nedokáže z toho prostoru vymáčknout takový zisk,

00:12:17.260 --> 00:12:20.260
jako algoritmus Žonglér.

00:12:20.260 --> 00:12:22.260
Ale pokud to oddálíte,

00:12:22.260 --> 00:12:24.260
pokud to oddálíte,

00:12:24.260 --> 00:12:28.260
uviděli byste 825 mil dlouhý příkop

00:12:28.260 --> 00:12:30.260
mezi New Yorkem a Chicagem,

00:12:30.260 --> 00:12:32.260
který byl vybudován během posledních let

00:12:32.260 --> 00:12:35.260
společností Spread Networks.

00:12:35.260 --> 00:12:37.260
Je to optický kabel,

00:12:37.260 --> 00:12:39.260
který byl položený mezi tahle dvě města,

00:12:39.260 --> 00:12:42.260
jen kvůli tomu, aby přenášel jeden signál

00:12:42.260 --> 00:12:45.260
37krát rychleji, než dokážete kliknout na myš,

00:12:45.260 --> 00:12:48.260
jen pro tyhle algoritmy,

00:12:48.260 --> 00:12:51.260
jen pro Karneval a Nůž.

00:12:51.260 --> 00:12:53.260
A když o tom přemýšlíte,

00:12:53.260 --> 00:12:55.260
že přerýváme Spojené státy

00:12:55.260 --> 00:12:58.260
dynamitem a řezáním skal

00:12:58.260 --> 00:13:00.260
jen kvůli tomu, aby algoritmus mohl obchodovat

00:13:00.260 --> 00:13:03.260
o tři mikrosekundy rychleji,

00:13:03.260 --> 00:13:05.260
všechno kvůli komunikačnímu rámci,

00:13:05.260 --> 00:13:09.260
o kterém nebude člověk ani vědět,

00:13:09.260 --> 00:13:12.260
to je trochu projev osudu,

00:13:12.260 --> 00:13:15.260
který bude vždycky hledat další hranice.

00:13:15.260 --> 00:13:18.260
Naneštěstí už teď víme, co máme dělat.

00:13:18.260 --> 00:13:20.260
Tohle je jen teoretické.

00:13:20.260 --> 00:13:22.260
Nějaký matematik z MIT.

00:13:22.260 --> 00:13:24.260
A popravdě moc nerozumím tomu

00:13:24.260 --> 00:13:26.260
o čem mluví.

00:13:26.260 --> 00:13:29.260
Zahrnuje to světelné kužely a nějaké kvantové věci

00:13:29.260 --> 00:13:31.260
a opravdu nerozumím ani jednomu.

00:13:31.260 --> 00:13:33.260
Ale umím si přečíst tuhle mapu.

00:13:33.260 --> 00:13:35.260
A co ta mapa říká je,

00:13:35.260 --> 00:13:38.260
že pokud se snažíte vydělávat peníze na trzích, kde jsou červené tečky –

00:13:38.260 --> 00:13:40.260
to je kde jsou lidé a kde jsou města –

00:13:40.260 --> 00:13:43.260
budete muset dát servery do míst, kde jsou modré tečky,

00:13:43.260 --> 00:13:45.260
abyste to dělali efektivně.

00:13:45.260 --> 00:13:48.260
A čeho jste si už mohli všimnout,

00:13:48.260 --> 00:13:51.260
spousta modrých teček je uprostřed oceánů.

00:13:51.260 --> 00:13:54.260
To je to co budeme dělat, budeme budovat bubliny

00:13:54.260 --> 00:13:56.260
nebo plošiny.

00:13:56.260 --> 00:13:58.260
Půjdeme na vodu,

00:13:58.260 --> 00:14:00.260
abychom vydělali peníze z čistého nebe,

00:14:00.260 --> 00:14:02.260
protože to je přece dobrá budoucnost,

00:14:02.260 --> 00:14:04.260
pokud jste algoritmus.

00:14:04.260 --> 00:14:06.260
(Smích)

00:14:06.260 --> 00:14:09.260
A nejsou to ani tak peníze, co je na tom zajímavé.

00:14:09.260 --> 00:14:11.260
Je to to, co peníze motivují.

00:14:11.260 --> 00:14:13.260
Že přetváříme

00:14:13.260 --> 00:14:15.260
samotnou Zemi

00:14:15.260 --> 00:14:17.260
s nějakou algoritmickou efektivností.

00:14:17.260 --> 00:14:19.260
A teď když to víme

00:14:19.260 --> 00:14:21.260
a vrátíme se

00:14:21.260 --> 00:14:23.260
a podíváme se na fotky Michaela Najjara,

00:14:23.260 --> 00:14:26.260
zjistíme, že vůbec nejsou metaforou, ale proroctvím.

00:14:26.260 --> 00:14:28.260
Jsou proroctvím

00:14:28.260 --> 00:14:32.260
seismických a pozemních manifestací

00:14:32.260 --> 00:14:34.260
matematiky, kterou vytváříme.

00:14:34.260 --> 00:14:37.260
A krajina byla vždycky utvářena

00:14:37.260 --> 00:14:40.260
tou podivnou a složitou spoluprací

00:14:40.260 --> 00:14:43.260
člověka a přírody.

00:14:43.260 --> 00:14:46.260
Ale teď tu máme třetí evoluční sílu: algoritmy –

00:14:46.260 --> 00:14:49.260
Žongléra, Karneval.

00:14:49.260 --> 00:14:52.260
A budeme je muset chápat jako přírodu.

00:14:52.260 --> 00:14:54.260
A svým způsobem přírodní jsou.

00:14:54.260 --> 00:14:56.260
Děkuji.

00:14:56.260 --> 00:15:16.260
(Potlesk)

