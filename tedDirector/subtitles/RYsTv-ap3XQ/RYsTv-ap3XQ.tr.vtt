WEBVTT
Kind: captions
Language: tr

00:00:00.000 --> 00:00:07.000
Çeviri: Suleyman Cengiz
Gözden geçirme: Yunus ASIK

00:00:11.820 --> 00:00:18.840
İnsanlara psikolojinin hangi
parçasının zor olduğunu sorsanız

00:00:18.840 --> 00:00:21.440
ve "Düşünmek mi, duygular mı?" deseniz.

00:00:21.440 --> 00:00:24.360
Birçok insan der ki: "Duygular çok zor.

00:00:24.360 --> 00:00:29.820
Çok fazla karmaşıklar. Nasıl
çalıştıklarına dair hiçbir fikrim yok."

00:00:29.820 --> 00:00:32.190
Fakat düşünmek gerçekten çok basittir:

00:00:32.190 --> 00:00:35.820
Sadece mantıklı düşünme
veya ona benzer bir şey.

00:00:35.820 --> 00:00:38.730
Fakat bu zor olan kısmı değil.

00:00:38.730 --> 00:00:40.990
İşte karşımıza çıkan
problemlerin bir listesi.

00:00:40.990 --> 00:00:43.820
"Sağlık hakkında ne yapıyoruz?"
güzel bir soru.

00:00:43.820 --> 00:00:48.700
Geçen gün bir şey okuyordum ve diyordu ki,

00:00:48.700 --> 00:00:54.080
Batıda hastalığın muhtemelen
en büyük nedeni tokalaşmaktır.

00:00:54.400 --> 00:00:58.600
Tokalaşmayan insanlar hakkında ve onları

00:00:58.600 --> 00:01:01.330
tokalaşanlarla karşılaştıran
çok az araştırma vardı.

00:01:01.330 --> 00:01:05.820
Tokalaşmayanları nerede bulacağım
konusunda en küçük bir fikrim yok

00:01:05.820 --> 00:01:08.790
çünkü saklanıyor olmalılar.

00:01:08.820 --> 00:01:12.820
Bundan kaçınan insanlar

00:01:12.820 --> 00:01:17.050
yüzde 30 daha az bulaşıcı hastalık
veya benzer bir şeye yakalanıyorlar.

00:01:17.370 --> 00:01:19.990
Belki de yüzde 31 çeyrektir bu oran.

00:01:19.990 --> 00:01:25.240
Yani eğer epidemi vb problemleri gerçekten
çözmek istiyorsanız, bununla başlayalım.

00:01:25.870 --> 00:01:28.140
Bu fikri edindiğimden bu yana,

00:01:28.510 --> 00:01:32.410
yüzlerce el sıkmak zorunda kaldım.

00:01:34.910 --> 00:01:37.460
Sanırım bundan kaçınmanın tek yolu,

00:01:37.460 --> 00:01:39.860
korkunç görünen bir hastalığa sahip olmak

00:01:39.860 --> 00:01:42.160
ve böylece açıklama yapmak
zorunda kalmazsınız.

00:01:42.630 --> 00:01:46.240
Eğitim: Eğitimi nasıl geliştiririz?

00:01:46.510 --> 00:01:48.900
Tek iyi yol onlara anlatılanların

00:01:48.900 --> 00:01:53.100
bir sürü saçmalık olduğunu
anlamalarını sağlamaktır.

00:01:53.230 --> 00:01:55.190
Sonra, elbette, bunu yumuşatmak için

00:01:55.190 --> 00:02:00.180
bir şey yapmalısınız ki sizi dinlesinler.

00:02:00.590 --> 00:02:04.220
Kirlilik, enerji kısıntısı,
çevresel farklılık, fakirlik.

00:02:04.220 --> 00:02:07.820
Dengeli topluluklar nasıl
oluştururuz? Uzun ömürlülük.

00:02:07.820 --> 00:02:10.820
Peki, endişe edilecek çok problem var.

00:02:10.820 --> 00:02:13.550
Neyse, sanırım insanların
konuşmaları gereken soru

00:02:13.550 --> 00:02:17.820
-- bu kesinlikle yasaktır --
ne kadar insanın olması gerektiğidir?

00:02:19.790 --> 00:02:24.820
Sanırım 100 milyon veya
500 milyon civarında olmalı.

00:02:25.390 --> 00:02:29.820
Sonra bu problemlerin büyük
kısmının kaybolacağına dikkat edin.

00:02:29.820 --> 00:02:33.890
Eğer düzgünce yayılmış
100 milyon insan olsaydı,

00:02:37.430 --> 00:02:40.660
sonra etrafa biraz çöp atmış olsaydınız,

00:02:41.150 --> 00:02:44.820
tercihen görmediğiniz
bir yere, bu çürüyecektir.

00:02:44.820 --> 00:02:49.820
Veya okyanusa atarsınız
ve balıklar faydalanır.

00:02:49.820 --> 00:02:52.400
Problem, kaç insanın
bulunması gerektiğidir?

00:02:52.400 --> 00:02:54.820
Yapmamız gereken bir çeşit tercihdir.

00:02:54.820 --> 00:02:58.320
Çoğu kimse yaklaşık
1,5 metre veya fazladır

00:02:58.710 --> 00:03:00.470
ve bir de şu küp yasaları var.

00:03:00.480 --> 00:03:04.820
Yani onları, nanoteknoloji kullanarak 
bu kadar küçük yaparsanız, sanırım --

00:03:04.820 --> 00:03:05.710
(Gülüşmeler)

00:03:05.710 --> 00:03:08.140
bu durumda bin katı kadar
fazlasına sahip olurdunuz.

00:03:08.140 --> 00:03:10.560
Bu, problemi çözerdi
ama insanları daha küçültecek

00:03:10.560 --> 00:03:12.820
çalışmalar yapan kimseyi görmüyorum.

00:03:12.820 --> 00:03:17.530
Şimdi, nüfusu azaltmak hoştur
ama çoğu kimse çocuk istiyor.

00:03:17.690 --> 00:03:21.120
Muhtemelen birkaç yıl
uzakta tek çözüm var.

00:03:21.330 --> 00:03:24.210
46 kromozomun olduğunu biliyorsunuz.

00:03:24.850 --> 00:03:28.100
Eğer şanslıysan her bir
ebeveynden 23 adet gelir.

00:03:29.370 --> 00:03:31.990
Bazen bir fazla veya bir eksik olur,

00:03:32.780 --> 00:03:36.620
böylece büyük ebeveyn ve büyük
büyük ebeveyn aşamasını atlarsın

00:03:36.620 --> 00:03:38.920
ve doğrudan büyük-büyük-büyük
ebeveyne gidersin.

00:03:38.920 --> 00:03:40.680
46 insan olur

00:03:42.070 --> 00:03:44.750
ve onlara bir tarayıcı verirsin
veya her ne gerekirse

00:03:45.160 --> 00:03:47.820
ve onlar kromozomlarına bakıp her biri,

00:03:47.820 --> 00:03:50.520
hangisini en çok sevdiğini söyler --

00:03:51.650 --> 00:03:55.010
sadece iki cinsiyet olması
için artık sebep yok zaten.

00:03:55.010 --> 00:03:57.820
Böylece her çocuğun 46 ebeveyni olur

00:03:57.820 --> 00:04:03.820
ve her 46 ebeveynlik grubun 15 çocuğunun
olmasına izin verebildiğini varsayayım.

00:04:03.820 --> 00:04:05.630
Bu yeterli olmaz mıydı?

00:04:05.630 --> 00:04:09.820
Sonra çocuklar hayli destek,
terbiye ve eğitim alacaklardı.

00:04:09.820 --> 00:04:12.500
Dünya nüfusu çok çabuk düşecekti

00:04:12.500 --> 00:04:14.820
ve herkes çok mutlu olacaktı.

00:04:14.820 --> 00:04:17.820
Zaman paylaşımı biraz
daha ötede, gelecekte.

00:04:17.820 --> 00:04:21.490
Bir de Arthur Clarke'ın iki kez yazdığı,
"Against the Fall of Night"

00:04:21.490 --> 00:04:24.820
ve "Şehir ve Yıldızlar" adlı
şu harika roman var.

00:04:24.820 --> 00:04:27.820
Her ikisi de muhteşem
ve arada ortaya çıkan

00:04:27.820 --> 00:04:30.720
bilgisayarlar hariç, neredeyse aynı.

00:04:30.720 --> 00:04:34.930
Arthur bu eski kitaba bakıyordu
ve "Şey, bu yanlış olmuş.

00:04:34.930 --> 00:04:37.280
Gelecekte bilgisayarlar
bulunmalıydı." dedi.

00:04:37.280 --> 00:04:41.820
Böylece ikinci sürümünde
Dünya'da 100 milyon

00:04:41.820 --> 00:04:44.170
veya 1 milyar insan bulunuyor

00:04:44.190 --> 00:04:49.820
ama hepsi sabit disklerde,
disketlerde veya gelecekteki

00:04:49.820 --> 00:04:52.540
benzer bir şeyde depolanmışlardır.

00:04:52.660 --> 00:04:56.040
Bunların birkaç milyonu
bir anda dışardadır.

00:04:56.040 --> 00:05:02.150
Bir insan çıkar, bir şeylerle
uğraşarak bin yıl kadar yaşar

00:05:02.150 --> 00:05:05.820
ve sonra, bir milyar
veya bir milyon yıl için

00:05:05.820 --> 00:05:10.150
geri gitme zamanı geldiğinde,
unutuyorum, sayılar önemli değil

00:05:10.430 --> 00:05:13.820
ama Dünya üstünde aynı anda
gerçekten çok insan yok.

00:05:13.820 --> 00:05:16.350
Kendin ve anıların hakkında düşünürsün

00:05:16.350 --> 00:05:20.820
ve askıya geri dönmeden
önce anılarını düzeltirsin

00:05:20.820 --> 00:05:23.970
ve kişiliğini değiştirirsin falan.

00:05:24.270 --> 00:05:29.820
Kitabın anafikri yeterince
çeşitlilik olmadığıdır,

00:05:29.820 --> 00:05:32.820
bu yüzden şehri tasarlayan insanlar

00:05:32.820 --> 00:05:37.530
ara sıra tamamen yeni bir insan
yaratıldığını garantiye almaktadırlar.

00:05:37.920 --> 00:05:42.140
Romanda, Alvin isimli
belirli biri yaratılır.

00:05:42.820 --> 00:05:46.870
Der ki, belki en iyi yol bu olmayabilir
ve tüm sistemi mahveder.

00:05:47.390 --> 00:05:49.250
Önerdiğim çözümlerin yeterince iyi

00:05:49.250 --> 00:05:51.820
veya yeterince zekice
olduğunu düşünmüyorum.

00:05:51.820 --> 00:05:55.820
Sanırım asıl büyük problem,
karşılaştığımız problemlerin

00:05:55.820 --> 00:05:59.820
hangisinin yeterince iyi olduğunu
anlayacak kadar zeki olmayışımız.

00:05:59.820 --> 00:06:04.330
Bu nedenle HAL gibi süper
zeki makineler yapmalıyız.

00:06:04.330 --> 00:06:08.820
Hatırlarsın, "2001" kitabının bir yerinde

00:06:08.820 --> 00:06:13.820
HAL, şu gerçekten aptal astronotlar için
evrenin çok büyük, muhteşem

00:06:13.820 --> 00:06:16.770
ve derin olduğunu farkeder.

00:06:16.770 --> 00:06:18.710
Eğer HAL'in davranışını,

00:06:18.710 --> 00:06:22.360
uzay gemisindeki insanların
basitlikleriyle karşılaştırırsan

00:06:22.360 --> 00:06:24.820
satır aralarında
ne yazdığını görebilirsin.

00:06:24.820 --> 00:06:27.820
Peki bu konuda ne yapacağız?
Daha zeki olabilirdik.

00:06:27.820 --> 00:06:32.820
Şempanzelere göre oldukça zekiyiz sanırım,

00:06:33.230 --> 00:06:38.820
ama karşılaştığımız dev problemlerle
uğraşacak kadar zeki sayılmayız,

00:06:38.820 --> 00:06:40.820
ne soyut matematikte,

00:06:40.820 --> 00:06:45.820
ne ekonomileri anlamada,
ne de dünyamızı dengelemede.

00:06:46.090 --> 00:06:48.820
Öyleyse yapabileceğimiz
tek şey uzun yaşamak

00:06:48.820 --> 00:06:50.820
ve kimse ne kadar zor olduğunu bilmez

00:06:50.820 --> 00:06:54.030
ama muhtemelen birkaç yıla bulacağız.

00:06:54.280 --> 00:06:56.130
Bakın, yol ikiye ayrılıyor.

00:06:56.130 --> 00:07:00.820
İnsanların neredeyse şempanzelerin
iki katı uzun yaşadığını biliyoruz

00:07:00.820 --> 00:07:04.820
ve kimse 120 yıldan fazla yaşamaz,

00:07:04.820 --> 00:07:07.820
çok iyi anlaşılmayan sebeplerden ötürü.

00:07:07.820 --> 00:07:10.820
Ama çoğu kimse şu an
90 veya 100 yıl yaşıyor,

00:07:10.820 --> 00:07:14.820
tabii fazla tokalaşma vb yapmadıkça.

00:07:16.160 --> 00:07:19.820
Yani belki 200 yıl yaşarsak
bazı problemleri çözmek için

00:07:19.820 --> 00:07:24.820
yeterince beceri ve bilgi edinebiliriz.

00:07:24.820 --> 00:07:27.290
İşte problemi halletme yollarından biri.

00:07:27.290 --> 00:07:30.670
Dediğim gibi, ne kadar
zor olduğunu bilmiyoruz.

00:07:30.670 --> 00:07:35.820
Kısaca diğer tüm memeliler
şempanzenin yarısı kadar fazla yaşarlar,

00:07:35.820 --> 00:07:42.040
böylece biz, çoğu memelinin ömrünün
üç buçuk veya dört katı yaşarız.

00:07:42.570 --> 00:07:47.240
Primatlar düşünüldüğünde,
neredeyse aynı genlere sahibiz.

00:07:47.240 --> 00:07:49.540
Sadece şempanzelerden farklıyız,

00:07:49.540 --> 00:07:54.820
tamamen değersiz şimdiki bilgi düzeyinde,

00:07:54.820 --> 00:07:56.820
yalnızca birkaç yüz genle belki.

00:07:56.820 --> 00:07:59.820
Sanırım gen sayıcıları hala
ne yaptıklarını bilmiyorlar.

00:07:59.820 --> 00:08:02.820
Ne yaparsanız yapın, sakın
hayat sürecinizde yayınlanan

00:08:02.820 --> 00:08:05.820
genetik hakkındaki şeyleri okumayın.

00:08:05.820 --> 00:08:08.820
(Gülüşmeler)

00:08:08.820 --> 00:08:12.550
Maddenin çok kısa bir yarılanma
süresi var, beyin boyutuyla aynı.

00:08:12.710 --> 00:08:18.820
Sadece dört veya beş geni düzeltirsek,

00:08:18.820 --> 00:08:20.820
200 yıl yaşayabilmemiz mümkün.

00:08:20.820 --> 00:08:23.820
Veya tahmini 30 ila 40 olsa,

00:08:23.820 --> 00:08:25.820
belki birkaç yüz olabilir.

00:08:25.820 --> 00:08:28.830
Yani insanların tartışacağı bir mesele bu

00:08:29.040 --> 00:08:32.820
ve çoğu etikçinin, bilirsiniz,
bir etikçi aklınızda olan

00:08:32.820 --> 00:08:36.180
her şeyde yanlış bir şeyler gören kişidir.

00:08:36.180 --> 00:08:38.820
(Gülüşmeler)

00:08:38.820 --> 00:08:44.870
Yapmaya değer bir değişiklik olduğuna
inanan bir etikçi bulmak çok zordur

00:08:44.870 --> 00:08:47.350
çünkü ya sonuçlar diye sorar.

00:08:47.350 --> 00:08:51.790
Tabii ki, şu an yaptıklarımızın
sonuçlarından sorumlu değiliz,

00:08:51.790 --> 00:08:53.120
öyle değil mi?

00:08:53.120 --> 00:08:55.820
Tüm bu klonlar hakkındaki şikayet gibi.

00:08:55.820 --> 00:08:58.820
Yine de iki rastgele insan
evlenecek ve çocukları olacak,

00:08:58.820 --> 00:09:02.820
her ikisinin de hayli
bozuk bazı genleri olur

00:09:02.820 --> 00:09:07.490
ve çocuk muhtemelen normal doğacak.

00:09:07.490 --> 00:09:10.880
Şempanze standartlarında cidden çok iyi.

00:09:12.700 --> 00:09:16.720
Eğer hayatımız uzun olursa, nüfus artış
problemiyle yüzleşmek zorunda kalacağız.

00:09:16.720 --> 00:09:19.820
Çünkü 200 veya 1000 yıl yaşarsak,

00:09:19.820 --> 00:09:25.820
her 200 veya 1000 yılda bir defadan fazla
çocuk sahibi olmalarına izin veremeyiz.

00:09:26.470 --> 00:09:29.360
Bu durumda işgücü olmayacak.

00:09:29.360 --> 00:09:32.820
Laurie Garrett'ın
belirttiği şeylerden biri,

00:09:32.820 --> 00:09:40.210
çalışma yaşında nüfusu olmayan
toplumların başı dertte.

00:09:40.210 --> 00:09:41.400
Daha da kötüleşecek

00:09:41.400 --> 00:09:46.820
çünkü çocukları eğitecek veya
yaşlıları besleyecek kimse yok.

00:09:46.820 --> 00:09:49.800
Uzun yaşam süresi hakkında
konuştuğumda, tabii ki,

00:09:49.800 --> 00:09:54.820
200 yaşında olan birinin, 200
yaşındaki -ki aslında ölü olan-

00:09:54.820 --> 00:09:58.820
bizim görüntümüze benzemesini istemem.

00:09:58.820 --> 00:10:01.510
Bilirsiniz, beynin farklı
işlevlere sahip gibi görünen

00:10:01.510 --> 00:10:03.280
yaklaşık 400 farklı bölümü vardır.

00:10:03.280 --> 00:10:06.180
Çoğunun detaylı olarak nasıl
çalıştıklarını kimse bilmez

00:10:06.180 --> 00:10:09.820
ama içeride çok sayıda
farklı şey olduğunu biliyoruz.

00:10:09.820 --> 00:10:11.820
Her zaman birlikte çalışmazlar.

00:10:11.820 --> 00:10:15.820
Çoğunun diğerini sıfırladığı şeklindeki
Freud'un teorisini severim.

00:10:15.820 --> 00:10:19.820
Eğer kendinizi yüzlerce kaynağı olan

00:10:19.820 --> 00:10:25.820
bir tür şehir gibi düşünüyorsanız
o halde, mesela korktuğunuzda,

00:10:25.820 --> 00:10:29.820
uzun vadeli hedeflerinizi iptal
edebilirsiniz, ama daha derin düşünebilir

00:10:29.820 --> 00:10:34.410
ve tamamen o belirli hedefi nasıl
başaracağınıza odaklanabilirsiniz.

00:10:34.410 --> 00:10:37.290
Diğer herşeyi atarsınız.
Saplantılı biri olursunuz --

00:10:37.290 --> 00:10:40.820
tüm umursadığınız bu
platformdan dışarı çıkmamaktır.

00:10:40.820 --> 00:10:44.820
Aç olduğunuzda, yemek
daha çekici olur falan.

00:10:44.820 --> 00:10:51.660
Böylece becerilerinizin çokca gelişmiş
alt kümeleri olarak duyguları görüyorum.

00:10:51.660 --> 00:10:54.390
Duygu sadece düşünceye
eklenmiş bir şey değildir.

00:10:54.390 --> 00:10:58.820
Duygusal bir durum, genelde
müsait kaynaklarınızın 100

00:10:58.820 --> 00:11:02.070
veya 200 tanesini çıkardığınızda
elde ettiğinizdir.

00:11:02.360 --> 00:11:07.340
Yani duyguları, düşünmekten
az bir şeyin zıttı gibi düşünmek

00:11:07.340 --> 00:11:08.820
son derece verimlidir.

00:11:08.820 --> 00:11:13.150
Umarım gelecek birkaç yılda, bunun
göstergesi olan akıllı makineler çıkacak.

00:11:13.150 --> 00:11:15.820
Sanırım gerisi çok önemli
değil, bu akıllı makineleri

00:11:15.820 --> 00:11:20.250
nasıl yapacağımız hakkındaki detaylar.

00:11:20.820 --> 00:11:26.210
(Gülüşmeler)

00:11:26.210 --> 00:11:30.820
Aslında ana fikir,
gerçekten akıllı bir makine,

00:11:30.820 --> 00:11:36.460
bir problemle karşı karşıya
kaldığınızı farkeder.

00:11:36.460 --> 00:11:39.210
Problem buna benzer bir şeydir

00:11:39.390 --> 00:11:42.890
ve bu nedenle böyle
bir problem için iyi olacak

00:11:42.890 --> 00:11:45.820
belli bir düşünme
yolu veya yolları vardır.

00:11:46.040 --> 00:11:49.820
Sanırım gelecek, piskolojinin ana problemi

00:11:49.820 --> 00:11:54.060
çıkmazları, durumları,
engelleri sınıflandırmak

00:11:54.310 --> 00:11:56.820
ve bunları düşünüp eşleştirecek uygun

00:11:56.820 --> 00:11:59.820
ve olası düşünce yollarını
da sınıflandırmaktır.

00:11:59.820 --> 00:12:02.820
Görüyorsunuz ya, nerdeyse Pavlovcu gibi --

00:12:02.820 --> 00:12:04.820
gerçekten basit teorilerle

00:12:04.820 --> 00:12:07.820
piskolojinin ilk yüz yılını kaybettik;

00:12:07.820 --> 00:12:10.990
insanlar nasıl öğrenir, bir
duruma nasıl reaksiyon verir?

00:12:10.990 --> 00:12:16.580
Söylediğim şey, binlerce portu
bulunan büyük, devasa sistem

00:12:16.580 --> 00:12:22.690
tasarlamayı da içeren birçok
seviyeyi atladıktan sonra

00:12:22.690 --> 00:12:25.970
tekrar piskolojinin asıl
problemi ile yüzleşeceğiz.

00:12:26.020 --> 00:12:28.820
Durumlar nedir değil, benim belirttiğim

00:12:28.820 --> 00:12:30.820
problem türleri nelerdir

00:12:30.820 --> 00:12:34.210
ve strateji türleri nelerdir,
bunları nasıl öğrenirsiniz,

00:12:34.210 --> 00:12:36.820
bunları nasıl birleştirirsiniz,
gerçekten yaratıcı biri

00:12:36.820 --> 00:12:42.270
uygun kaynaklar arasından yeni bir
düşünme yolu nasıl bulur falan.

00:12:42.270 --> 00:12:44.190
Sanırım gelecek 20 senede

00:12:44.190 --> 00:12:48.820
eğer yapay zekaya geleneksel
yaklaşımlardan sıyrılabilirsek,

00:12:48.820 --> 00:12:52.890
sinir ağları, genetik algoritmalar
ve kurallı sistemler gibi

00:12:52.890 --> 00:12:56.350
ve fikrimizi sadece biraz daha
yükseğe yöneltirsek mesela,

00:12:56.350 --> 00:13:01.370
tüm bu şeyleri doğru problem türü için
kullanabilen bir sistem yapabilir miyiz?

00:13:01.370 --> 00:13:04.360
Bazı problemler sinir ağları
için iyidir, ama geriye kalanlar,

00:13:04.360 --> 00:13:06.630
sinir ağları için umut vadetmiyor.

00:13:06.630 --> 00:13:09.510
Genetik algoritmalar 
belli şeyler için harika,

00:13:09.510 --> 00:13:12.820
hangi konuda kötü olduklarında
şüpheliyim ve söylemeyeceğim.

00:13:12.820 --> 00:13:13.820
(Gülüşmeler)

00:13:13.820 --> 00:13:15.820
Teşekkürler.

00:13:15.820 --> 00:13:21.820
(Alkışlar)

