WEBVTT
Kind: captions
Language: it

00:00:00.000 --> 00:00:07.000
Traduttore: Maria Gitto
Revisore: Daniele Berti

00:00:18.330 --> 00:00:24.330
Se chiedete alle persone quale parte della psicologia ritengono sia difficile,

00:00:24.330 --> 00:00:27.330
e dite, beh, che ne pensate delle emozioni?

00:00:27.330 --> 00:00:30.330
Molte persone diranno: "Le emozioni sono terribilmente difficili.

00:00:30.330 --> 00:00:36.330
Sono incredibilmente complesse, non possono ... non ho idea di come funzionino.

00:00:36.330 --> 00:00:38.330
Ma la questione è davvero molto semplice:

00:00:38.330 --> 00:00:42.330
è solo una cosa di una specie di ragionamento logico o simile.

00:00:42.330 --> 00:00:45.330
Ma non è la parte difficile".

00:00:45.330 --> 00:00:47.330
Quindi ecco una lista di problemi che sono venuti fuori.

00:00:47.330 --> 00:00:50.330
Un bel problema è: che facciamo riguardo alla salute?

00:00:50.330 --> 00:00:54.330
L'altro giorno stavo leggendo qualcosa, e una persona diceva

00:00:54.330 --> 00:01:00.330
che probabilmente in Occidente, la più grossa causa delle malattie è la stretta di mano.

00:01:00.330 --> 00:01:04.330
E c'era un piccolo studio sulle persone che non stringono la mano,

00:01:04.330 --> 00:01:07.330
e si paragonavano a quelle che stringono la mano,

00:01:07.330 --> 00:01:12.330
e non ho la più pallida idea di dove si trovino quelle che non stringono la mano,

00:01:12.330 --> 00:01:15.330
perché devono essere nascoste.

00:01:15.330 --> 00:01:19.330
E le persone che lo evitano

00:01:19.330 --> 00:01:23.330
hanno il 30% in meno di malattie infettive o simili.

00:01:23.330 --> 00:01:26.330
O forse era il 31¼%.

00:01:26.330 --> 00:01:30.330
Così, se volete davvero risolvere il problema delle epidemie e via dicendo,

00:01:30.330 --> 00:01:34.330
iniziamo con quello. E da quando ho avuto quell'idea,

00:01:34.330 --> 00:01:38.330
ho dovuto stringere centinaia di mani.

00:01:38.330 --> 00:01:43.330
E credo che l'unico modo per evitarlo

00:01:43.330 --> 00:01:45.330
sia di avere qualche orribile malattia visibile,

00:01:45.330 --> 00:01:48.330
così da non dover dare spiegazioni.

00:01:48.330 --> 00:01:52.330
Educazione: come miglioriamo l'educazione?

00:01:52.330 --> 00:01:56.330
Beh, l'unico e miglior modo è fargli capire

00:01:56.330 --> 00:01:59.330
che quello che gli stanno dicendo non ha assolutamente senso.

00:01:59.330 --> 00:02:01.330
E poi, certo, si deve fare qualcosa

00:02:01.330 --> 00:02:06.330
per moderarlo, così che tutti, in qualche modo, ascoltino te.

00:02:06.330 --> 00:02:10.330
Inquinamento, carenza di energia, diversità ambientale, povertà -

00:02:10.330 --> 00:02:14.330
come facciamo delle società stabili? Longevità.

00:02:14.330 --> 00:02:17.330
Okay, ci sono molti problemi di cui preoccuparsi.

00:02:17.330 --> 00:02:19.330
Ad ogni modo, la domanda di cui credo che dovrebbero parlare le persone -

00:02:19.330 --> 00:02:24.330
ed è assolutamente un tabù - è, quante persone ci dovrebbero essere?

00:02:24.330 --> 00:02:31.330
E credo che dovrebbero essere circa 100 milioni o forse 500 milioni.

00:02:31.330 --> 00:02:36.330
E allora capiremmo che la stragrande maggioranza di questi problemi sparisce.

00:02:36.330 --> 00:02:38.330
Se ci fossero 100 milioni di persone

00:02:38.330 --> 00:02:44.330
opportunamente sparse, allora, se ci fossero dei rifiuti,

00:02:44.330 --> 00:02:51.330
li buttereste via, possibilmente dove non si vedono e marcirebbero.

00:02:51.330 --> 00:02:56.330
O li buttereste nell'oceano e alcuni pesci ne trarrebbero beneficio.

00:02:56.330 --> 00:02:58.330
Il problema è, quante persone ci dovrebbero essere?

00:02:58.330 --> 00:03:01.330
Ed è una specie di scelta che dobbiamo fare.

00:03:01.330 --> 00:03:04.330
Molte persone sono alte circa un metro e mezzo o più,

00:03:04.330 --> 00:03:08.330
e c'è questa perdita al cubo. Quindi se si facessero grandi così -

00:03:08.330 --> 00:03:11.330
usando la nanotecnologia immagino -

00:03:11.330 --> 00:03:12.330
(Risate)

00:03:12.330 --> 00:03:14.330
- allora ce ne potrebbero essere mille volte di più.

00:03:14.330 --> 00:03:16.330
Questo risolverebbe il problema, ma non vedo nessuno

00:03:16.330 --> 00:03:19.330
fare nessun tipo di ricerca per rimpicciolire le persone.

00:03:19.330 --> 00:03:24.330
Ora, è bello ridurre la popolazione, ma molte persone vogliono avere dei bambini.

00:03:24.330 --> 00:03:27.330
E c'è una soluzione che probabilmente è lontana solo qualche anno.

00:03:27.330 --> 00:03:32.330
Sapete di avere 46 cromosomi. Se siete fortunati, ne avete avuti 23

00:03:32.330 --> 00:03:38.330
da ognuno dei vostri genitori; a volte se ne ha uno in più o se ne perde uno,

00:03:38.330 --> 00:03:42.330
ma ... così potete saltare il passaggio dei nonni e dei bisnonni

00:03:42.330 --> 00:03:47.330
e andare dritti ai trisnonni. E avete 46 persone

00:03:47.330 --> 00:03:50.330
e gli date uno scanner, o quello di cui avete bisogno,

00:03:50.330 --> 00:03:54.330
e loro guardano i loro cromosomi e ognuno di loro dice

00:03:54.330 --> 00:03:59.330
quale gli o le piace di più, ... nessun motivo per avere solo i due sessi

00:03:59.330 --> 00:04:04.330
anche di più. Quindi ogni bambino ha 46 genitori,

00:04:04.330 --> 00:04:10.330
e immagino che possiate lasciare che ogni gruppo di 46 genitori abbia 15 bambini -

00:04:10.330 --> 00:04:12.330
non sarebbe abbastanza? E così i bambini

00:04:12.330 --> 00:04:16.330
otterrebbero abbondanza di sostegno e nutrimento e attenzione

00:04:16.330 --> 00:04:18.330
e la popolazione mondiale scenderebbe molto rapidamente

00:04:18.330 --> 00:04:21.330
e tutti sarebbero assolutamente felici.

00:04:21.330 --> 00:04:24.330
La condivisione del tempo è un po' più lontana nel futuro.

00:04:24.330 --> 00:04:27.330
E c'è questo grande romanzo che Arthur Clarke ha scritto due volte,

00:04:27.330 --> 00:04:31.330
chiamato Oltre il buio della notte e La città e le stelle.

00:04:31.330 --> 00:04:34.330
Sono entrambi meravigliosi e in gran parte gli stessi,

00:04:34.330 --> 00:04:36.330
tranne per il fatto che nel frattempo sono arrivati i computer.

00:04:36.330 --> 00:04:41.330
E Arthur guardando questo vecchio libro, ha detto, beh, era sbagliato.

00:04:41.330 --> 00:04:43.330
Il futuro deve avere qualche computer.

00:04:43.330 --> 00:04:48.330
Quindi nella sua seconda versione, ci sono 100 miliardi,

00:04:48.330 --> 00:04:56.330
o 1.000 miliardi di persone sulla terra, ma sono tutti ammassati in hard disk o floppy,

00:04:56.330 --> 00:04:58.330
o in qualunque cosa abbiano in futuro.

00:04:58.330 --> 00:05:02.330
E se ne fanno uscire qualche milione per volta.

00:05:02.330 --> 00:05:06.330
Una persona viene fuori, vive per un migliaio di anni

00:05:06.330 --> 00:05:12.330
fa quello che fa, e poi, quando è il momento di tornare indietro

00:05:12.330 --> 00:05:16.330
per un miliardo di anni ... o un milione, lo dimentico, le cifre non contano ...

00:05:16.330 --> 00:05:20.330
ma non ci sono troppe persone alla volta sulla terra.

00:05:20.330 --> 00:05:22.330
E si pensa a se stessi e alle proprie memorie,

00:05:22.330 --> 00:05:27.330
e prima di tornare indietro nel limbo, si cancellano le proprie memorie

00:05:27.330 --> 00:05:30.330
e si cambia la propria personalità e via dicendo.

00:05:30.330 --> 00:05:36.330
La trama del libro è che non c'è abbastanza diversità,

00:05:36.330 --> 00:05:39.330
così che le persone che hanno ideato le città

00:05:39.330 --> 00:05:43.330
hanno fatto in modo che di tanto in tanto venga creata una persona totalmente nuova.

00:05:43.330 --> 00:05:49.330
E nel romanzo, ne viene creato uno in particolare di nome Alvin. E dice,

00:05:49.330 --> 00:05:53.330
forse questo non è il modo migliore, e distrugge il sistema.

00:05:53.330 --> 00:05:55.330
Non credo che la soluzione che ho proposto

00:05:55.330 --> 00:05:58.330
sia abbastanza buona o abbastanza intelligente.

00:05:58.330 --> 00:06:02.330
Credo che il problema grosso sia che non siamo abbastanza intelligenti

00:06:02.330 --> 00:06:06.330
per capire quali dei problemi che stiamo affrontando siano buoni abbastanza.

00:06:06.330 --> 00:06:10.330
Di conseguenza, dobbiamo costruire macchine super intelligenti come HAL.

00:06:10.330 --> 00:06:15.330
Come ricorderete, ad un certo punto del libro 2001,

00:06:15.330 --> 00:06:20.330
HAL si rende conto che l'universo è troppo grande e maestoso e ampio

00:06:20.330 --> 00:06:24.330
per quegli stupidissimi astronauti. Se si confronta il comportamento di HAL

00:06:24.330 --> 00:06:28.330
con la banalità delle persone sulle astronavi,

00:06:28.330 --> 00:06:31.330
si può vedere cos'è scritto tra le righe.

00:06:31.330 --> 00:06:34.330
Beh, cosa faremo per questo? Diventeremo più intelligenti.

00:06:34.330 --> 00:06:39.330
Credo che siamo piuttosto intelligenti, paragonati agli scimpanzé,

00:06:39.330 --> 00:06:45.330
ma non siamo abbastanza intelligenti per trattare con i problemi colossali che affrontiamo,

00:06:45.330 --> 00:06:47.330
sia nella matematica astratta

00:06:47.330 --> 00:06:52.330
che nel comprendere l'economia o equilibrare il mondo.

00:06:52.330 --> 00:06:55.330
Quindi una cosa che possiamo fare è vivere di più.

00:06:55.330 --> 00:06:57.330
E nessuno sa quanto sia difficile,

00:06:57.330 --> 00:07:00.330
ma probabilmente lo scopriremo nel giro di pochi anni.

00:07:00.330 --> 00:07:03.330
Vedete, la strada ha due bivi. Sappiamo che le persone vivono

00:07:03.330 --> 00:07:07.330
due volte di più degli scimpanzé, o quasi,

00:07:07.330 --> 00:07:11.330
e che nessuno vive più di 120 anni,

00:07:11.330 --> 00:07:14.330
per ragioni che non sono ben comprensibili.

00:07:14.330 --> 00:07:17.330
Ma oggi, molte persone vivono fino a 90 o 100 anni,

00:07:17.330 --> 00:07:21.330
a meno che non stringano troppe mani o cose del genere.

00:07:21.330 --> 00:07:26.330
E quindi forse se vivessimo 200 anni, potremmo accumulare abilità

00:07:26.330 --> 00:07:31.330
e conoscenze sufficienti a risolvere alcuni problemi.

00:07:31.330 --> 00:07:33.330
Quindi questo è un modo di agire.

00:07:33.330 --> 00:07:36.330
E come ho detto, non sappiamo quanto sia difficile. Potrebbe essere -

00:07:36.330 --> 00:07:42.330
dopo tutto, molti altri mammiferi vivono la metà degli scimpanzé,

00:07:42.330 --> 00:07:45.330
quindi noi viviamo tre volte e mezza o quattro - siamo quattro volte

00:07:45.330 --> 00:07:51.330
più longevi di molti mammiferi. E nel caso dei primati,

00:07:51.330 --> 00:07:55.330
abbiamo quasi gli stessi geni. Differiamo dagli scimpanzé solo

00:07:55.330 --> 00:08:01.330
al presente stato di conoscenza - che sono solo sciocchezze -

00:08:01.330 --> 00:08:03.330
forse per qualche centinaio di geni.

00:08:03.330 --> 00:08:06.330
Ciò che credo è che chi conta i geni non sappia ancora ciò che fa.

00:08:06.330 --> 00:08:09.330
E qualunque cosa facciate, non leggete niente che riguardi la genetica

00:08:09.330 --> 00:08:12.330
e che sia pubblicato durante la vostra vita.

00:08:12.330 --> 00:08:15.330
(Risate)

00:08:15.330 --> 00:08:19.330
Questa roba ha vita breve, come la scienza del cervello.

00:08:19.330 --> 00:08:25.330
E quindi dovrebbe essere che se ci concentriamo su 4 o 5 geni,

00:08:25.330 --> 00:08:27.330
potremo vivere 200 anni.

00:08:27.330 --> 00:08:30.330
O forse solo 30 o 40,

00:08:30.330 --> 00:08:32.330
e dubito che siano qualche centinaia.

00:08:32.330 --> 00:08:36.330
Quindi questo è qualcosa di cui le persone discuteranno

00:08:36.330 --> 00:08:39.330
e molti etici - sapete, un etico è qualcuno

00:08:39.330 --> 00:08:42.330
che vede qualcosa di sbagliato in tutto ciò che vi passa per la testa.

00:08:42.330 --> 00:08:45.330
(Risate)

00:08:45.330 --> 00:08:49.330
Ed è davvero difficile trovare un etico che consideri che qualunque cambiamento

00:08:49.330 --> 00:08:53.330
valga la pena di essere fatto, perché dice: "e le conseguenze?"

00:08:53.330 --> 00:08:56.330
E certo, non siamo responsabili per le conseguenze

00:08:56.330 --> 00:09:02.330
di ciò che facciamo adesso, o no? Come tutte queste lamentele sui cloni.

00:09:02.330 --> 00:09:05.330
E ancora due persone a caso si uniranno e avranno questo bambino,

00:09:05.330 --> 00:09:09.330
ed entrambi hanno dei geni abbastanza scadenti,

00:09:09.330 --> 00:09:13.330
ed è probabile che il bambino venga fuori dalla norma.

00:09:13.330 --> 00:09:19.330
Che per gli standard degli scimpanzé, è anzi molto buono.

00:09:19.330 --> 00:09:22.330
Se avessimo la longevità, allora dovremmo affrontare comunque il problema

00:09:22.330 --> 00:09:26.330
dell'aumento della popolazione. Perché se le persone vivessero 200 o 1.000 anni,

00:09:26.330 --> 00:09:32.330
non potremmo lasciargli avere dei bambini più di una volta ogni 200 o 1.000 anni.

00:09:32.330 --> 00:09:35.330
E quindi non ci sarebbe forza lavoro.

00:09:35.330 --> 00:09:39.330
E una della cose che ha messo in evidenza Laurie Garret, e altri,

00:09:39.330 --> 00:09:44.330
è che una società che non ha persone

00:09:44.330 --> 00:09:47.330
in età da lavoro, è davvero nei guai. E le cose peggioreranno,

00:09:47.330 --> 00:09:53.330
perché non ci sarebbe nessuno ad educare i bambini o a nutrire gli anziani.

00:09:53.330 --> 00:09:55.330
E quando parlo di una vita lunga, certo

00:09:55.330 --> 00:10:01.330
non voglio che qualcuno che ha 200 anni sia l'immagine

00:10:01.330 --> 00:10:05.330
di ciò che è un bicentenario - che in effetti, è morto.

00:10:05.330 --> 00:10:07.330
Sapete, ci sono circa 400 diverse parti del cervello

00:10:07.330 --> 00:10:09.330
che sembrano avere diverse funzioni.

00:10:09.330 --> 00:10:12.330
Nessuno sa in dettaglio come lavori la maggior parte di esso,

00:10:12.330 --> 00:10:16.330
ma sappiamo che contengono molte cose diverse.

00:10:16.330 --> 00:10:18.330
E non sempre lavorano insieme. Mi piace la teoria di Freud

00:10:18.330 --> 00:10:22.330
che molte di loro si annullano a vicenda.

00:10:22.330 --> 00:10:26.330
Quindi se pensate a voi stessi come ad una specie di città

00:10:26.330 --> 00:10:32.330
con un centinaio di risorse, allora, quando si è spaventati, per esempio,

00:10:32.330 --> 00:10:36.330
si possono eliminare gli obiettivi ad ampio raggio, ma si può pensare con profondità

00:10:36.330 --> 00:10:40.330
e focalizzarsi esattamente su come raggiungere quel particolare obiettivo.

00:10:40.330 --> 00:10:43.330
Tutto il resto si butta via. Si diventa monomaniaci -

00:10:43.330 --> 00:10:47.330
tutto ciò di cui importa è non uscire da quella piattaforma.

00:10:47.330 --> 00:10:51.330
E quando si è arrabbiati, il cibo diventa più interessante, e così via.

00:10:51.330 --> 00:10:57.330
Quindi considero le emozioni come sotto gruppi molto evoluti delle vostre capacità.

00:10:57.330 --> 00:11:01.330
L'emozione non è qualcosa che si aggiunge al pensiero. Uno stato emozionale

00:11:01.330 --> 00:11:05.330
è ciò che si ottiene quando si eliminano 100 o 200

00:11:05.330 --> 00:11:08.330
delle normali risorse disponibili.

00:11:08.330 --> 00:11:11.330
Quindi pensando alle emozioni come all'opposto di ... come qualcosa

00:11:11.330 --> 00:11:15.330
meno che il pensare, è immensamente produttivo. E spero,

00:11:15.330 --> 00:11:19.330
nei prossimi anni, di dimostrare che ciò porterà a macchine più intelligenti.

00:11:19.330 --> 00:11:22.330
E suppongo che sia meglio saltare tutto il resto, ovvero alcuni dettagli

00:11:22.330 --> 00:11:27.330
su come potremmo fare queste macchine intelligenti e -

00:11:27.330 --> 00:11:32.330
(Risate)

00:11:32.330 --> 00:11:37.330
- e l'idea principale è infatti che il nucleo di una macchina davvero intelligente

00:11:37.330 --> 00:11:42.330
sia uno che riconosce che si sta affrontando un certo tipo di problema .

00:11:42.330 --> 00:11:45.330
Questo è un problema di tal tipo,

00:11:45.330 --> 00:11:50.330
e quindi c'è o ci sono determinati modi di pensare

00:11:50.330 --> 00:11:52.330
che vanno bene per quel problema.

00:11:52.330 --> 00:11:56.330
Quindi credo che il problema principale e futuro della psicologia sia classificare

00:11:56.330 --> 00:12:00.330
i tipi di difficoltà, i tipi di situazioni, i tipi di ostacoli

00:12:00.330 --> 00:12:06.330
e anche classificare modi validi e possibili di pensare, e accoppiarli.

00:12:06.330 --> 00:12:09.330
Quindi vedete, è quasi come un pavloviano -

00:12:09.330 --> 00:12:11.330
abbiamo perso le prime centinaia di anni di psicologia

00:12:11.330 --> 00:12:14.330
per teorie davvero banali dove si dice,

00:12:14.330 --> 00:12:20.330
come le persone imparano a reagire ad una situazione. Quello che sto dicendo,

00:12:20.330 --> 00:12:25.330
è che dopo essere passati attraverso molti livelli, incluso l'ideare

00:12:25.330 --> 00:12:28.330
un enorme e disordinato sistema con migliaia di parti,

00:12:28.330 --> 00:12:32.330
giungeremo di nuovo al problema centrale della psicologia.

00:12:32.330 --> 00:12:35.330
Dicendo, non quali sono le situazioni,

00:12:35.330 --> 00:12:37.330
ma quali sono i tipi di problemi

00:12:37.330 --> 00:12:40.330
e quali sono le strategie, come si apprendono,

00:12:40.330 --> 00:12:43.330
come si collegano, come fa una persona molto creativa

00:12:43.330 --> 00:12:48.330
a inventare un nuovo modo di pensare a partire dalle risorse disponibili e così via.

00:12:48.330 --> 00:12:50.330
Quindi credo che nei prossimi 20 anni,

00:12:50.330 --> 00:12:55.330
se potessimo liberarci dei tradizionali approcci all'intelligenza artificiale,

00:12:55.330 --> 00:12:57.330
come reti neurali e algoritmi genetici

00:12:57.330 --> 00:13:03.330
e sistemi basati sulle regole, e guardare un po' più in alto per dire:

00:13:03.330 --> 00:13:05.330
"Possiamo creare un sistema che possa usare tutte quelle cose

00:13:05.330 --> 00:13:09.330
per il giusto tipo di problema?" Alcuni problemi sono buoni per le reti neurali;

00:13:09.330 --> 00:13:12.330
sappiamo che per altri, le reti neurali non servono a niente.

00:13:12.330 --> 00:13:15.330
Gli algoritmi genetici sono ottimi per certe cose;

00:13:15.330 --> 00:13:19.330
immagino di sapere in cosa non vanno bene e non ve lo dirò.

00:13:19.330 --> 00:13:20.330
(Risate)

00:13:20.330 --> 00:13:22.330
Grazie.

00:13:22.330 --> 00:13:28.330
(Applausi)

