WEBVTT
Kind: captions
Language: pt-PT

00:00:00.000 --> 00:00:07.000
Tradutor: Dulce Calçada
Revisora: Rafael Eufrasio

00:00:18.648 --> 00:00:20.666
Se perguntarmos às pessoas

00:00:20.666 --> 00:00:24.711
que área da psicologia
pensam ser a mais difícil

00:00:24.711 --> 00:00:27.602
e lhes dermos a escolher
entre pensamento e emoções,

00:00:27.602 --> 00:00:29.084
a maioria dirá:

00:00:29.084 --> 00:00:31.448
"As emoções são extremamente difíceis.

00:00:31.448 --> 00:00:36.330
"São incrivelmente complexas,
não faço ideia de como funcionam.

00:00:36.330 --> 00:00:38.611
"Já o pensamento é muito simples.

00:00:38.611 --> 00:00:42.330
"É apenas mais ou menos
uma espécie de raciocínio lógico.

00:00:43.248 --> 00:00:45.084
"Mas essa não é a parte difícil."

00:00:45.430 --> 00:00:48.030
Temos aqui uma lista
de problemas por resolver.

00:00:48.030 --> 00:00:50.848
Um problema interessante é
o que fazer em relação à saúde?

00:00:50.848 --> 00:00:54.766
Ainda há dias estava a ler
uma coisa que dizia

00:00:54.766 --> 00:00:58.611
que, provavelmente, a maior causa
de doença no mundo ocidental

00:00:58.611 --> 00:01:00.960
é o aperto de mão.

00:01:01.548 --> 00:01:05.039
Havia um pequeno estudo que comparava
pessoas que não dão apertos de mão

00:01:05.039 --> 00:01:07.866
com pessoas que dão apertos de mão.

00:01:08.321 --> 00:01:12.330
Não faço a menor ideia onde terão encontrado
as que não dão apertos de mão,

00:01:12.330 --> 00:01:14.311
porque devem estar escondidas.

00:01:15.520 --> 00:01:19.330
As pessoas que evitam este gesto

00:01:19.330 --> 00:01:23.502
têm um risco cerca de 30% menor
de contrair doenças infecciosas.

00:01:23.648 --> 00:01:26.320
Ou talvez fosse 31,25%.

00:01:26.575 --> 00:01:31.602
Portanto, se quisermos acabar
com as epidemias, comecemos por aí.

00:01:32.066 --> 00:01:34.766
Desde que tive conhecimento desta ideia

00:01:34.766 --> 00:01:38.475
tive que apertar centenas de mãos.

00:01:39.902 --> 00:01:43.960
Penso que a única maneira de evitá-lo

00:01:43.960 --> 00:01:46.093
é ter alguma doença horrível bem visível,

00:01:46.093 --> 00:01:48.566
e aí não temos de explicar-nos.

00:01:48.966 --> 00:01:52.102
Ensino: como melhorar o ensino?

00:01:53.002 --> 00:01:56.330
A melhor maneira é fazê-los compreender

00:01:56.330 --> 00:01:59.780
que o que lhes têm dito
são completos disparates.

00:01:59.780 --> 00:02:02.675
E depois, claro, há que moderar
um pouco esta atitude,

00:02:02.675 --> 00:02:06.330
para que alguém de facto nos ouça.

00:02:07.011 --> 00:02:10.975
Poluição, escassez de energia, 
diversidade ambiental, pobreza.

00:02:10.975 --> 00:02:13.084
Como construir sociedades estáveis?

00:02:13.148 --> 00:02:14.666
Longevidade.

00:02:14.666 --> 00:02:17.666
Ok, há muitos problemas preocupantes.

00:02:17.666 --> 00:02:20.220
Aliás, a questão que penso
que devíamos discutir,

00:02:20.220 --> 00:02:23.748
e que é um tabu absoluto, é:
Quantas pessoas deveriam existir?

00:02:26.266 --> 00:02:31.284
Penso que deveriam existir cerca 
de 100 ou talvez 500 milhões.

00:02:31.939 --> 00:02:36.330
Reparem que muitos
destes problemas desaparecem.

00:02:36.739 --> 00:02:40.248
Se houvesse só 100 milhões de pessoas
convenientemente distribuídas...

00:02:40.248 --> 00:02:41.684
(Risos)

00:02:41.920 --> 00:02:47.140
... se houvesse algum lixo,
poderíamos deitá-lo fora,

00:02:47.140 --> 00:02:51.557
de preferência longe da vista,
e apodreceria.

00:02:51.557 --> 00:02:56.057
Ou poderíamos deitá-lo ao mar
e os peixes poderiam beneficiar dele.

00:02:56.630 --> 00:02:59.075
O problema é: 
quantas pessoas deveriam existir?

00:02:59.075 --> 00:03:01.702
É uma espécie de escolha
que temos de fazer.

00:03:01.702 --> 00:03:06.248
A maioria das pessoas mede 1,5 metros
ou mais, e há esta perda cúbica.

00:03:06.248 --> 00:03:09.139
Portanto, se conseguíssemos ter
pessoas deste tamanho,

00:03:09.139 --> 00:03:11.511
recorrendo à nanotecnologia, suponho...

00:03:11.511 --> 00:03:12.566
(Risos)

00:03:12.566 --> 00:03:14.830
... poderia haver mil vezes mais pessoas.

00:03:14.830 --> 00:03:16.330
Isso resolveria o problema,

00:03:16.330 --> 00:03:19.802
mas não vejo ninguém a investigar
como tornar as pessoas mais pequenas.

00:03:19.802 --> 00:03:23.439
É boa ideia reduzir a população,
mas muitas pessoas querem ter filhos.

00:03:24.330 --> 00:03:27.448
Provavelmente teremos uma solução
daqui a poucos anos.

00:03:28.510 --> 00:03:30.820
Sabem que temos 46 cromossomas.

00:03:31.493 --> 00:03:35.330
Com alguma sorte,
temos 23 de cada progenitor,

00:03:35.330 --> 00:03:38.330
por vezes ficamos
com um a mais ou a menos,

00:03:38.330 --> 00:03:42.684
mas podemos saltar
as etapas de avô e bisavô

00:03:42.684 --> 00:03:45.139
e ir diretamente para a de trisavô.

00:03:45.139 --> 00:03:50.830
Reunimos 46 pessoas e damos-lhes
qualquer tipo de analisador.

00:03:50.830 --> 00:03:55.812
Eles olham para os seus cromossomas
e cada um diz de qual gosta mais.

00:03:55.812 --> 00:03:57.657
(Risos)

00:03:57.657 --> 00:04:00.230
Já não há razão para haver só dois sexos.

00:04:01.780 --> 00:04:04.484
Portanto, cada criança tem 46 pais,

00:04:04.484 --> 00:04:09.293
e suponho que podíamos deixar 
cada grupo de 46 pais ter 15 filhos.

00:04:10.330 --> 00:04:12.220
Não seria suficiente?

00:04:12.330 --> 00:04:16.048
Depois os filhos teriam muito apoio,
sustento e educação

00:04:16.048 --> 00:04:19.048
e a população do mundo
entraria em declínio rapidamente

00:04:19.048 --> 00:04:21.566
e toda a gente seria totalmente feliz.

00:04:21.766 --> 00:04:24.730
A "partilha de tempo" estará
num futuro mais distante.

00:04:24.730 --> 00:04:27.884
Há um belo romance, que Arthur Clarke
escreveu duas vezes,

00:04:27.884 --> 00:04:31.330
chamado "Against the Fall of Night"
e "A Cidade e as Estrelas".

00:04:31.448 --> 00:04:34.330
São ambos maravilhosos
e em grande medida iguais,

00:04:34.330 --> 00:04:37.275
exceto que os computadores
foram inventados entre os dois.

00:04:37.275 --> 00:04:40.075
Arthur olhou para o primeiro livro e disse:

00:04:40.075 --> 00:04:43.466
"Isto está errado. 
O futuro tem que ter computadores."

00:04:43.466 --> 00:04:48.330
Assim, na segunda versão do livro, 
há 100 ou 1000 mil milhões

00:04:48.330 --> 00:04:51.293
de pessoas na Terra,

00:04:51.293 --> 00:04:56.584
mas estão todas armazenadas
em discos rígidos ou disquetes,

00:04:56.584 --> 00:04:58.993
ou o que quer que existisse no futuro.

00:04:58.993 --> 00:05:02.548
Deixam-se sair uns poucos milhões
de cada vez.

00:05:02.975 --> 00:05:06.870
Uma pessoa sai, vive durante mil anos,

00:05:06.870 --> 00:05:12.866
faz a sua vida, 
até ser altura de regressar

00:05:12.866 --> 00:05:16.666
por mil milhões de anos, ou um milhão,
esqueci-me, os números não interessam,

00:05:16.666 --> 00:05:20.330
mas não existem muitas pessoas
na Terra num dado período de tempo.

00:05:20.330 --> 00:05:23.057
Podemos refletir sobre nós próprios
e as nossas memórias

00:05:23.057 --> 00:05:27.330
e, antes de sermos suspendidos de novo.
podemos corrigi-las

00:05:27.330 --> 00:05:30.057
e mudar a nossa personalidade, 
por exemplo.

00:05:30.611 --> 00:05:36.330
O enredo do livro é que 
não há suficiente diversidade

00:05:36.330 --> 00:05:39.330
e assim, as pessoas 
que construíram a cidade

00:05:39.330 --> 00:05:43.511
certificam-se de que uma vez por outra
é criada uma pessoa totalmente nova.

00:05:44.511 --> 00:05:49.593
O romance fala de uma destas novas pessoas,
Alvin, que pensa:

00:05:49.593 --> 00:05:52.757
"Talvez esta não seja a melhor maneira",
e destrói todo o sistema.

00:05:53.466 --> 00:05:55.839
Penso que as soluções que propus aqui

00:05:55.839 --> 00:05:58.802
não são suficientemente boas
nem suficientemente inteligentes.

00:05:58.802 --> 00:06:02.630
Penso que o grande problema é que
não somos suficientemente inteligentes

00:06:02.630 --> 00:06:06.620
para compreender quais os problemas
que importa resolver.

00:06:06.620 --> 00:06:10.439
Portanto, temos que construir máquinas
superinteligentes como o HAL.

00:06:10.875 --> 00:06:15.802
Como devem estar lembrados, a dada altura
no livro "2001, Odisseia no Espaço",

00:06:15.802 --> 00:06:20.530
o HAL apercebe-se de que o Universo
é demasiado grande e profundo

00:06:20.530 --> 00:06:23.166
para aqueles astronautas estúpidos.

00:06:23.166 --> 00:06:25.511
Se compararmos o comportamento do HAL

00:06:25.511 --> 00:06:29.030
com a trivialidade das pessoas
a bordo da nave espacial,

00:06:29.030 --> 00:06:31.539
então conseguiremos ler nas entrelinhas.

00:06:31.539 --> 00:06:35.193
O que fazer então em relação a isso? 
Podíamos tornar-nos mais inteligentes.

00:06:35.193 --> 00:06:39.493
Acho que somos bastante inteligentes, 
em comparação com os chimpanzés,

00:06:39.493 --> 00:06:45.330
mas não o suficiente para lidar
com os problemas colossais que enfrentamos,

00:06:45.330 --> 00:06:48.002
tanto em matemática abstrata

00:06:48.002 --> 00:06:52.711
como na compreensão da economia
ou na luta por um mundo equilibrado.

00:06:52.711 --> 00:06:55.748
Uma coisa que podemos fazer 
é viver mais tempo.

00:06:55.748 --> 00:06:57.966
Ninguém sabe como isso será difícil,

00:06:57.966 --> 00:07:01.102
mas provavelmente descobri-lo-emos
nos próximos anos.

00:07:01.102 --> 00:07:03.330
Há uma bifurcação no caminho.

00:07:03.330 --> 00:07:07.330
Sabemos que as pessoas vivem
quase o dobro dos chimpanzés,

00:07:07.330 --> 00:07:11.330
e ninguém vive mais de 120 anos,

00:07:11.330 --> 00:07:14.330
por razões que não compreendemos bem.

00:07:14.638 --> 00:07:17.620
Mas muitas pessoas vivem
agora 90 ou 100 anos,

00:07:17.620 --> 00:07:20.739
a não ser que deem muitos apertos de mão
ou coisa do género.

00:07:20.739 --> 00:07:22.780
(Risos)

00:07:22.811 --> 00:07:26.720
Portanto, se vivêssemos 200 anos, 
talvez conseguíssemos acumular

00:07:26.720 --> 00:07:31.330
a capacidade e conhecimento necessários
para resolver alguns problemas.

00:07:31.330 --> 00:07:33.620
Isto é uma forma de ver a coisa.

00:07:33.620 --> 00:07:36.330
Como disse, não sabemos 
quão difícil será de concretizar.

00:07:36.866 --> 00:07:42.548
Afinal, a maioria dos outros mamíferos
vive metade do tempo dos chimpanzés,

00:07:42.548 --> 00:07:45.870
portanto nós temos 
cerca de 3,5 vezes ou 4 vezes

00:07:45.870 --> 00:07:48.657
a longevidade da maioria dos mamíferos.

00:07:49.248 --> 00:07:53.829
E no caso dos primatas,
temos praticamente os mesmos genes.

00:07:53.830 --> 00:07:57.511
Apenas diferimos dos chimpanzés,
no estado atual de conhecimento

00:07:57.511 --> 00:07:59.911
— que é absurdamente primitivo —

00:08:01.330 --> 00:08:03.602
talvez por umas poucas centenas de genes.

00:08:03.602 --> 00:08:06.939
Acho que os "contadores de genes"
ainda não sabem o que estão a fazer.

00:08:06.939 --> 00:08:09.330
Façam o que fizerem,
não leiam nada sobre genética

00:08:09.330 --> 00:08:12.511
que seja publicado durante a vossa vida.

00:08:12.720 --> 00:08:15.011
(Risos)

00:08:15.330 --> 00:08:17.629
Porque tem um tempo 
de semivida muito curto.

00:08:17.657 --> 00:08:19.957
O mesmo para a ciência do cérebro.

00:08:20.811 --> 00:08:25.330
Assim, pode ser que, manipulando
apenas 4 ou 5 genes,

00:08:25.330 --> 00:08:27.557
possamos passar a viver 200 anos.

00:08:27.557 --> 00:08:30.330
Ou pode ser que sejam 30 ou 40,

00:08:30.330 --> 00:08:32.730
e duvido que sejam várias centenas.

00:08:32.730 --> 00:08:35.657
Isto é uma coisa que as pessoas
estarão a discutir

00:08:35.657 --> 00:08:37.530
e muitos especialistas em Ética...

00:08:37.530 --> 00:08:41.039
Sabem, um especialista em Ética
é alguém que vê sempre algo errado

00:08:41.039 --> 00:08:43.960
com o que uma pessoa tem em mente.

00:08:43.960 --> 00:08:45.330
(Risos)

00:08:45.693 --> 00:08:49.120
É muito difícil encontrar um especialista
em Ética que considere

00:08:49.120 --> 00:08:52.221
que dada mudança valha a pena,
porque ele dirá:

00:08:52.221 --> 00:08:54.239
"Então e as consequências?"

00:08:54.557 --> 00:08:57.011
Claro que não somos responsáveis
pelas consequências

00:08:57.011 --> 00:08:59.566
do que estamos a fazer agora, pois não?

00:08:59.566 --> 00:09:02.666
É como todas essas reclamações
sobre os clones.

00:09:02.666 --> 00:09:05.739
No entanto, duas pessoas quaisquer
acasalam e têm um filho,

00:09:05.739 --> 00:09:09.548
e ambas terão genes bastante defeituosos,

00:09:09.548 --> 00:09:13.802
e a criança será provavelmente mediana,

00:09:13.802 --> 00:09:17.030
o que, segundo o padrão de um chimpanzé,
é de facto muito bom.

00:09:17.184 --> 00:09:19.039
(Risos)

00:09:19.330 --> 00:09:22.075
Se tivermos longevidade, 
teremos de enfrentar na mesma

00:09:22.075 --> 00:09:23.966
o problema do crescimento populacional

00:09:23.966 --> 00:09:27.130
Porque se as pessoas 
viverem 200 ou 1000 anos,

00:09:27.130 --> 00:09:32.330
não podemos deixá-las ter um filho
senão em cada 200 ou 1000 anos.

00:09:32.748 --> 00:09:35.593
E assim não haverá
força de trabalho disponível.

00:09:35.611 --> 00:09:39.330
Uma das coisas que Laurie Garrett
e outros têm apontado

00:09:39.330 --> 00:09:44.330
é que uma sociedade
que não tem pessoas

00:09:44.330 --> 00:09:47.130
em idade de trabalhar se vê em apuros.

00:09:47.130 --> 00:09:49.502
E as coisas vão piorar
porque não há ninguém

00:09:49.502 --> 00:09:52.811
para educar as crianças
ou alimentar os idosos.

00:09:53.330 --> 00:09:55.830
Quando falo de longevidade, claro,

00:09:55.830 --> 00:10:01.502
não quero que alguém com 200 anos
se pareça com a imagem que temos

00:10:01.502 --> 00:10:05.330
de alguém com essa idade 
— que, aliás, é a de alguém morto.

00:10:05.493 --> 00:10:08.175
Sabem, há cerca de 400 regiões 
distintas no cérebro

00:10:08.175 --> 00:10:09.939
que parecem ter funções diferentes.

00:10:09.939 --> 00:10:12.657
Ninguém sabe com pormenor
como funciona a maioria delas

00:10:12.657 --> 00:10:16.330
mas sabemos que existem lá
coisas muito diferentes.

00:10:16.520 --> 00:10:18.510
E nem sempre funcionam em conjunto.

00:10:18.510 --> 00:10:22.666
Gosto da teoria de Freud de que
a maioria delas se anulam mutuamente.

00:10:23.039 --> 00:10:26.739
Se pensarmos que somos
uma espécie de cidade,

00:10:26.739 --> 00:10:32.548
com uma centena de recursos, então,
quando temos medo, por exemplo,

00:10:32.548 --> 00:10:36.330
podemos ignorar os nossos objetivos 
de longo prazo

00:10:36.330 --> 00:10:40.666
e concentrar-nos naquele objetivo
muito particular.

00:10:40.666 --> 00:10:43.775
Esquecemos tudo o resto,
tornamo-nos monomaníacos,

00:10:43.775 --> 00:10:47.330
só nos preocupamos em não cair
da plataforma abaixo.

00:10:47.620 --> 00:10:51.330
Quando temos fome, a comida
torna-se mais atrativa, etc.

00:10:51.466 --> 00:10:58.166
Eu vejo as emoções como subconjuntos 
altamente evoluídos das nossas capacidades.

00:10:58.166 --> 00:11:01.211
A emoção não é 
"uma coisa adicionada ao pensamento".

00:11:01.211 --> 00:11:04.584
Um estado emocional
é o que resulta da remoção

00:11:04.584 --> 00:11:08.330
de 100 ou 200 dos nossos recursos
normalmente disponíveis.

00:11:08.766 --> 00:11:10.802
Portanto, pensar nas emoções
como o oposto

00:11:10.802 --> 00:11:15.330
a "uma coisa menos que o pensamento" 
é imensamente produtivo.

00:11:15.330 --> 00:11:19.502
Espero, nos próximos anos, mostrar que
isso nos levará a máquinas inteligentes.

00:11:19.893 --> 00:11:22.330
Acho que é melhor passar à frente disto,

00:11:22.330 --> 00:11:27.330
que são detalhes sobre como poderemos
construir estas máquinas.

00:11:27.566 --> 00:11:31.802
(Risos)

00:11:32.784 --> 00:11:37.802
A ideia principal é que o núcleo 
de uma máquina realmente inteligente

00:11:37.802 --> 00:11:42.502
é ela ser capaz de reconhecer 
o tipo de problema que está a enfrentar.

00:11:42.502 --> 00:11:46.157
Este é um problema de tal e tal tipo

00:11:46.157 --> 00:11:50.457
e, portanto, há uma 
ou várias maneiras de pensar

00:11:50.457 --> 00:11:52.575
que são boas para esse problema.

00:11:52.811 --> 00:11:55.520
Penso que no futuro,
o principal problema da Psicologia

00:11:55.520 --> 00:12:00.448
será classificar tipos de dilemas,
tipos de situações, tipos de obstáculos,

00:12:00.448 --> 00:12:03.729
classificar também as formas
de pensamento disponíveis

00:12:03.729 --> 00:12:06.330
e, depois, associá-los da melhor forma.

00:12:06.690 --> 00:12:09.093
Portanto veem, é quase pavloviano.

00:12:09.602 --> 00:12:12.048
Perdemos os primeiros
cem anos da Psicologia

00:12:12.048 --> 00:12:14.766
com teorias triviais acerca da forma

00:12:14.766 --> 00:12:17.730
como as pessoas aprendem
a reagir a uma dada situação.

00:12:20.584 --> 00:12:25.057
O que eu defendo é depois de passarmos
muitos níveis, incluindo a conceção

00:12:25.057 --> 00:12:29.311
de um sistema enorme e confuso
com milhares de peças,

00:12:29.311 --> 00:12:32.557
acabaremos ainda 
com o problema central da Psicologia.

00:12:32.557 --> 00:12:35.575
investigando não quais as situações,

00:12:35.575 --> 00:12:37.930
mas quais os tipos de problemas

00:12:37.930 --> 00:12:39.821
e os tipos de estratégias que existem,

00:12:39.821 --> 00:12:42.038
como aprendê-las,
como associá-las entre si

00:12:42.038 --> 00:12:44.211
e como é que uma pessoa realmente criativa

00:12:44.211 --> 00:12:48.330
inventa uma nova forma de pensar
a partir dos recursos disponíveis.

00:12:48.930 --> 00:12:50.902
Portanto, penso que nos próximos 20 anos,

00:12:50.902 --> 00:12:52.530
se nos conseguirmos livrar

00:12:52.530 --> 00:12:55.575
de todas as abordagens tradicionais
à inteligência artificial,

00:12:55.575 --> 00:12:58.293
como redes neuronais, algoritmos genéticos

00:12:58.293 --> 00:13:02.839
e sistemas baseados em regras,
e olharmos um pouco mais longe,

00:13:02.839 --> 00:13:04.930
será que conseguimos construir um sistema

00:13:04.930 --> 00:13:07.493
capaz de usar tudo isso
para o tipo certo de problema?

00:13:07.493 --> 00:13:09.330
Há problemas bons
para redes neuronais;

00:13:09.330 --> 00:13:12.448
sabemos que noutros problemas, 
as redes neuronais não funcionam.

00:13:12.448 --> 00:13:15.330
Os algoritmos genéticos
são ótimos para certas coisas.

00:13:15.330 --> 00:13:18.493
Suspeito que sei aquilo em que são maus
mas não vos vou dizer.

00:13:18.648 --> 00:13:20.457
(Risos)

00:13:20.611 --> 00:13:22.330
Obrigado.

00:13:22.793 --> 00:13:26.593
(Aplausos)

