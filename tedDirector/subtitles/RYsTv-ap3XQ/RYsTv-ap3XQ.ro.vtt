WEBVTT
Kind: captions
Language: ro

00:00:00.000 --> 00:00:07.000
Traducător: Magda Marcu
Corector: Ariana Bleau Lugo

00:00:18.330 --> 00:00:24.330
Dacă întrebaţi oamenii ce parte a psihologiei o consideră dificilă

00:00:24.330 --> 00:00:27.330
și le daţi de ales, spre exemplu, între gândire şi emoţie,

00:00:27.330 --> 00:00:30.330
majoritatea vor spune "Emoţiile sunt extrem de dificile.

00:00:30.330 --> 00:00:36.330
Sunt incredibil de complexe, nu pot...habar n-am cum funcţionează.

00:00:36.330 --> 00:00:38.330
Dar a gândi e o chestiune de-a dreptul clară:

00:00:38.330 --> 00:00:42.330
e vorba de raționamnet logic sau așa ceva.

00:00:42.330 --> 00:00:45.330
Dar asta nu e partea dificilă."

00:00:45.330 --> 00:00:47.330
Aşa că iată o listă de probleme care apar.

00:00:47.330 --> 00:00:50.330
O problemă drăguţă este: ce facem în privinţa sănătăţii?

00:00:50.330 --> 00:00:54.330
Zilele trecute citeam ceva, iar autorul spunea

00:00:54.330 --> 00:01:00.330
că probabil singura cea mai răspândită cauză pentru boală în Vest este strângerea de mână.

00:01:00.330 --> 00:01:04.330
Şi era un mic studiu despre oamenii care nu dau mâna,

00:01:04.330 --> 00:01:07.330
comparaţi cu cei care dau mâna,

00:01:07.330 --> 00:01:12.330
şi n-am nici cea mai vagă idee unde îi găseşti pe cei ce nu dau mâna,

00:01:12.330 --> 00:01:15.330
pentru că probabil se ascund.

00:01:15.330 --> 00:01:19.330
Iar persoanele care evită asta

00:01:19.330 --> 00:01:23.330
au cu 30 la sută mai puţine boli infecţioase sau ceva de genul ăsta.

00:01:23.330 --> 00:01:26.330
Sau poate că era 31.25%.

00:01:26.330 --> 00:01:30.330
Aşa că dacă vrem cu adevărat să rezolvăm problema epidemiilor şi aşa mai departe,

00:01:30.330 --> 00:01:34.330
hai să începem cu asta. Şi de când mi-a venit această idee,

00:01:34.330 --> 00:01:38.330
a trebuit să strâng sute de mâini.

00:01:38.330 --> 00:01:43.330
Şi cred că singura cale de a evita asta

00:01:43.330 --> 00:01:45.330
e să ai o boală vizibilă îngrozitoare,

00:01:45.330 --> 00:01:48.330
şi atunci nu trebuie să mai dai explicaţii.

00:01:48.330 --> 00:01:52.330
Educaţia: cum putem îmbunătăţi educaţia?

00:01:52.330 --> 00:01:56.330
Ei bine, cea mai bună cale este de a-i face să înţeleagă

00:01:56.330 --> 00:01:59.330
că ceea ce li se spune e de fapt o grămadă de prostii.

00:01:59.330 --> 00:02:01.330
şi apoi, bineînţeles, trebuie să faci ceva

00:02:01.330 --> 00:02:06.330
despre cum se accesează asta pentru ca oricine să poată asculta.

00:02:06.330 --> 00:02:10.330
Poluarea, criza de energie, diversitatea mediului, sărăcia --

00:02:10.330 --> 00:02:14.330
cum putem creea societăţi stabile? Longevitate.

00:02:14.330 --> 00:02:17.330
Ok, sunt multe probleme de care să ne îngrijorăm.

00:02:17.330 --> 00:02:19.330
Oricum, întrebarea despre care cred că ar trebui să discute oamenii --

00:02:19.330 --> 00:02:24.330
şi e un tabu absolut - este: câţi oameni ar trebui să fie?

00:02:24.330 --> 00:02:31.330
Iar eu cred că ar trebui să fie 100 de milioane sau poate 500 de milioane.

00:02:31.330 --> 00:02:36.330
Şi apoi observaţi cum multe din aceste probleme dispar.

00:02:36.330 --> 00:02:38.330
Dacă ar fi 100 de milioane de oameni

00:02:38.330 --> 00:02:44.330
răspândiți adecvat, atunci, dacă e ceva gunoi,

00:02:44.330 --> 00:02:51.330
îl arunci, preferabil undeva unde nu îl poţi vedea, şi se va descompune.

00:02:51.330 --> 00:02:56.330
Sau îl arunci în ocean şi niște peşti vor beneficia de el.

00:02:56.330 --> 00:02:58.330
Problema este, câţi oameni ar trebui să fie?

00:02:58.330 --> 00:03:01.330
Şi e un fel de alegere pe care trebuie să o facem.

00:03:01.330 --> 00:03:04.330
Majoritatea oamenilor au cam 60 de inchi (1.5m) sau mai mult,

00:03:04.330 --> 00:03:08.330
și e această pierdere la cub. Deci dacă îi faci atât de mici --

00:03:08.330 --> 00:03:11.330
cu ajutorul nanotehnologiei, presupun --

00:03:11.330 --> 00:03:12.330
(Râsete)

00:03:12.330 --> 00:03:14.330
- atunci ai putea avea de mii de ori mai mulţi.

00:03:14.330 --> 00:03:16.330
Asta ar putea rezolva problema, dar nu văd pe nimeni

00:03:16.330 --> 00:03:19.330
care să facă cercetare despre cum poţi face oamenii mai mici.

00:03:19.330 --> 00:03:24.330
Acum, ar fi frumos să reduci populaţia, dar mulţi oameni îşi doresc copii.

00:03:24.330 --> 00:03:27.330
Şi e o soluţie care e probabil cam la câțiva ani distanță.

00:03:27.330 --> 00:03:32.330
Ştii că ai 46 de cromozomi. Dacă eşti norocos, ai 23

00:03:32.330 --> 00:03:38.330
de la fiecare părinte; uneori ai unul în plus sau în minus,

00:03:38.330 --> 00:03:42.330
-- deci poţi sări stadiile de bunic sau străbunic

00:03:42.330 --> 00:03:47.330
şi trece direct la stră-stră-străbunic. Şi ai 46 de oameni

00:03:47.330 --> 00:03:50.330
şi le dai un scaner sau orice e nevoie,

00:03:50.330 --> 00:03:54.330
şi se uită la cromozomii lor şi fiecare spune

00:03:54.330 --> 00:03:59.330
care îi place cel mai mult lui sau ei -- nici măcar nu trebuie

00:03:59.330 --> 00:04:04.330
să avem doar două sexe. Deci fiecare copil are 46 de părinți,

00:04:04.330 --> 00:04:10.330
și presupun că ai putea să lași fiecare grup de 46 de părinți să aibă 15 copii --

00:04:10.330 --> 00:04:12.330
n-ar fi suficient așa? Și apoi copiii

00:04:12.330 --> 00:04:16.330
ar primi foarte mult ajutor și educație și îndrumare

00:04:16.330 --> 00:04:18.330
și populația globului ar scădea foarte rapid

00:04:18.330 --> 00:04:21.330
și toată lumea ar fi foarte fericită.

00:04:21.330 --> 00:04:24.330
Time-sharing e un pic mai departe în viitor.

00:04:24.330 --> 00:04:27.330
Și e povestirea asta grozavă pe care Arthur Clarke a scris-o de două ori,

00:04:27.330 --> 00:04:31.330
se cheamă "Înainte de căderea nopții" și "Orașul și stelele".

00:04:31.330 --> 00:04:34.330
Amândouă sunt minunate și foarte asemănătoare,

00:04:34.330 --> 00:04:36.330
cu excepția faptului ca între ele apar computerele.

00:04:36.330 --> 00:04:41.330
Și Arthur s-a uitat la cartea asta veche și a zis, ei bine, asta e greșit.

00:04:41.330 --> 00:04:43.330
Viitorul trebuie să aibă niște computere.

00:04:43.330 --> 00:04:48.330
Așa că în versiunea a doua, sunt 100 de miliarde,

00:04:48.330 --> 00:04:56.330
sau 1000 de miliarde de oameni pe Pământ, dar sunt toți depozitați pe hard discuri sau dischete,

00:04:56.330 --> 00:04:58.330
sau ce au ei acolo în viitor.

00:04:58.330 --> 00:05:02.330
Și lași afară câteva milioane din ei o dată.

00:05:02.330 --> 00:05:06.330
O persoană iese afară, trăiește 1000 de ani

00:05:06.330 --> 00:05:12.330
făcând orice fac ei, și apoi, când e timpul să meargă înapoi

00:05:12.330 --> 00:05:16.330
pentru un miliard de ani -- sau un milion, am uitat, numerele nu contează --

00:05:16.330 --> 00:05:20.330
dar nu sunt mulți oameni pe pământ în același timp.

00:05:20.330 --> 00:05:22.330
Și apuci să te gândești la tine și la amintirile tale,

00:05:22.330 --> 00:05:27.330
și înainte să te duci înapoi în suspensie îți editezi amintirile

00:05:27.330 --> 00:05:30.330
și îți schimbi personalitatea și așa mai departe.

00:05:30.330 --> 00:05:36.330
Complotul constă în faptul că nu e destulă diversitate,

00:05:36.330 --> 00:05:39.330
așa că oamenii care au făcut designul orașului

00:05:39.330 --> 00:05:43.330
se asigură că din când în când e creată o persoană nouă.

00:05:43.330 --> 00:05:49.330
Și în povestire, unul specific e creat, numit Alvin. Și el zice,

00:05:49.330 --> 00:05:53.330
poate că nu e ăsta cel mai bun mod, și strică tot sistemul.

00:05:53.330 --> 00:05:55.330
Nu cred că soluțiile pe care le propun

00:05:55.330 --> 00:05:58.330
sunt suficient de bune sau suficient de inteligente.

00:05:58.330 --> 00:06:02.330
Cred că marea problemă e că nu suntem suficient de inteligenți

00:06:02.330 --> 00:06:06.330
ca să înțelegem care dintre problemele de care ne lovim sunt destul de bune.

00:06:06.330 --> 00:06:10.330
De aceea, trebuie să construim mașini super inteligente ca HAL.

00:06:10.330 --> 00:06:15.330
Dacă vă amintiți, la un moment dat în cartea pentru 2001,

00:06:15.330 --> 00:06:20.330
HAL realizează că universul e prea mare și măreț și profund

00:06:20.330 --> 00:06:24.330
pentru astronauții ăia proști. Dacă compari comportamentul lui HAL

00:06:24.330 --> 00:06:28.330
cu josnicia oamenilor de pe navă,

00:06:28.330 --> 00:06:31.330
poți vedea ce e scris printre rânduri.

00:06:31.330 --> 00:06:34.330
Ei bine, ce putem face în legătură cu asta? Putem să devenim mai deștepți.

00:06:34.330 --> 00:06:39.330
Cred că suntem destul de deștepți, comparat cu cimpanzeii,

00:06:39.330 --> 00:06:45.330
dar nu suntem suficient de deștepți ca să rezolvăm problemele colosale de care ne lovim,

00:06:45.330 --> 00:06:47.330
fie în matematica teoretică

00:06:47.330 --> 00:06:52.330
fie în înțelegerea economiilor sau echilibrarea lumii din jur,

00:06:52.330 --> 00:06:55.330
Deci un lucru pe care îl putem face e să trăim mai mult.

00:06:55.330 --> 00:06:57.330
Și nimeni nu știe cât e de greu,

00:06:57.330 --> 00:07:00.330
dar probabil că vom afla în câțiva ani.

00:07:00.330 --> 00:07:03.330
Vedeți, sunt două răscruci pe drum. Știm că oamenii trăiesc

00:07:03.330 --> 00:07:07.330
de două ori mai mult decât companzeii, aproape,

00:07:07.330 --> 00:07:11.330
și nimeni nu trăiește mai mult de 120 de ani,

00:07:11.330 --> 00:07:14.330
din motive care nu sunt foarte bine înțelese.

00:07:14.330 --> 00:07:17.330
Dar mulți oameni trăiesc acum până la 90 sau 100,

00:07:17.330 --> 00:07:21.330
dacă nu strâng prea multe mâini sau ceva de genul ăsta.

00:07:21.330 --> 00:07:26.330
Și poate dacă am trăi 200 de ani, am putea să acumulăm destule abilități

00:07:26.330 --> 00:07:31.330
și cunoștințe ca să rezolvăm niște probleme.

00:07:31.330 --> 00:07:33.330
Deci ăsta e un mod de a face asta.

00:07:33.330 --> 00:07:36.330
Și după cum am spus, nu știm cât e de greu. S-ar putea --

00:07:36.330 --> 00:07:42.330
la urma urmei, cele mai multe mamifere trăiesc jumătate cât cimpanzeii,

00:07:42.330 --> 00:07:45.330
deci noi avem de 3½ sau de 4 ori -- avem de 4 ori

00:07:45.330 --> 00:07:51.330
longevitatea majorității mamiferelor. Și în cazul primatelor,

00:07:51.330 --> 00:07:55.330
avem aproape aceleași gene. Ne deosebim de cimpanzei

00:07:55.330 --> 00:08:01.330
după cunoștințele pe care le avem acum -- care sunt de aruncat la gunoi --

00:08:01.330 --> 00:08:03.330
poate doar prin câteva sute de gene.

00:08:03.330 --> 00:08:06.330
Ce cred e că numărătorii de gene încă nu știu ce fac.

00:08:06.330 --> 00:08:09.330
Și orice faceți, nu citiți despre genetică nimic

00:08:09.330 --> 00:08:12.330
din ce a fost publicat în timpul vieții voastre, sau pe-acolo.

00:08:12.330 --> 00:08:15.330
(Râsete)

00:08:15.330 --> 00:08:19.330
Chestiile astea au o perioadă foarte scurtă, la fel ca știința creierului.

00:08:19.330 --> 00:08:25.330
Și s-ar putea că dacă reparăm doar 4 sau 5 gene,

00:08:25.330 --> 00:08:27.330
să putem trăi 200 de ani.

00:08:27.330 --> 00:08:30.330
Sau s-ar putea să fie doar 30 sau 40,

00:08:30.330 --> 00:08:32.330
și mă îndoiesc că sunt câteva sute.

00:08:32.330 --> 00:08:36.330
Deci asta e ceva ce oamenii vor discuta

00:08:36.330 --> 00:08:39.330
și mulți specialiști în etică -- știți, un pecialist în etică e cineva

00:08:39.330 --> 00:08:42.330
care vede ceva greșit cu orice ai tu în minte.

00:08:42.330 --> 00:08:45.330
(Râsete)

00:08:45.330 --> 00:08:49.330
Și e greu să găsești un specialist în etică care să considere că merită

00:08:49.330 --> 00:08:53.330
făcută orice schimbare, pentru că, spune el, care sunt consecințele?

00:08:53.330 --> 00:08:56.330
Și bineînțeles, nu suntem responsabili pentru consecințele

00:08:56.330 --> 00:09:02.330
la ceea ce facem acum, nu-i așa? Ca toate obiecțiile despre clone.

00:09:02.330 --> 00:09:05.330
Și totuși doi oameni la întâmplare se vor împerechea și vor avea un copil,

00:09:05.330 --> 00:09:09.330
și amândoi au căteva gene de proastă calitate,

00:09:09.330 --> 00:09:13.330
și copilul probabil va ieși mediu.

00:09:13.330 --> 00:09:19.330
Ceea ce după starndardele cimpanzeilor este de fapt foarte bine.

00:09:19.330 --> 00:09:22.330
Dacă avem longevitate, va trebui să rezolvăm creșterea populației

00:09:22.330 --> 00:09:26.330
oricum. Pentru că dacă oamenii trăiesc 200 sau 1000 de ani,

00:09:26.330 --> 00:09:32.330
atunci nu putem să-i lăsăm să aibă mai mult de un copil la fiecare 200 sau 1000 de ani

00:09:32.330 --> 00:09:35.330
Și atunci nu va avea cine să muncească.

00:09:35.330 --> 00:09:39.330
Și unul din lucrurile subliniate de Laurie Garrett, și de alții,

00:09:39.330 --> 00:09:44.330
e că o societate care nu are oameni

00:09:44.330 --> 00:09:47.330
la vârstă aptă de muncă e în mare pericol. Și lucrurile vor deveni și mai rele,

00:09:47.330 --> 00:09:53.330
pentru că nu e nimeni să educe copiii sau să-i hrănească pe bătrâni.

00:09:53.330 --> 00:09:55.330
Și când vorbesc despre o viață lungă, bineînțeles,

00:09:55.330 --> 00:10:01.330
nu vreau ca cineva de 200 de ani să fie după imaginea noastră

00:10:01.330 --> 00:10:05.330
a cuiva de 200 de ani -- care este mort, de fapt.

00:10:05.330 --> 00:10:07.330
Știți, sunt cam 400 de părți diferite în creier

00:10:07.330 --> 00:10:09.330
care par să aibă funcții diferite.

00:10:09.330 --> 00:10:12.330
Nimeni nu știe în amănunt cum funcționează ele,

00:10:12.330 --> 00:10:16.330
dar știm că sunt o mulțime de lucruri diferite acolo.

00:10:16.330 --> 00:10:18.330
Și nu întotdeauna lucrează împreună. Îmi place teoria lui Freud

00:10:18.330 --> 00:10:22.330
că majoritatea se anulează reciproc.

00:10:22.330 --> 00:10:26.330
Și dacă te gândești la tine însuți ca un fel de oraș

00:10:26.330 --> 00:10:32.330
cu o sută de resurse, atunci, când ți-e frică, de exemplu,

00:10:32.330 --> 00:10:36.330
ai putea să renunți la scopurile tale de lungă durată, dar s-ar putea să gândești adânc

00:10:36.330 --> 00:10:40.330
și să te concentrezi cum să atingi exact acel obiectiv preferat.

00:10:40.330 --> 00:10:43.330
Dai orice altceva la o parte. Devii maniac --

00:10:43.330 --> 00:10:47.330
îți pasă numai să nu calci în afara acelei platforme.

00:10:47.330 --> 00:10:51.330
Și când ți-e foame, mâncarea devine mai atrăgătoare, și așa mai departe.

00:10:51.330 --> 00:10:57.330
Deci văd emoțiile ca sub-seturi foarte dezvoltate ale capabilității tale.

00:10:57.330 --> 00:11:01.330
Emoția nu e ceva adăugat gândului. O stare emoțională

00:11:01.330 --> 00:11:05.330
este ce obții când elimini 100 sau 200

00:11:05.330 --> 00:11:08.330
din resursele tale obișnuite.

00:11:08.330 --> 00:11:11.330
Deci gândindu-ne la emoții ca la opusul ... ca la ceva

00:11:11.330 --> 00:11:15.330
mai puțin decât gândirea este foarte productiv. Și sper,

00:11:15.330 --> 00:11:19.330
ca în următorii câțiva ani, să arăt că asta va duce la mașini inteligente.

00:11:19.330 --> 00:11:22.330
Și cred că mai bine sar peste restul, care sunt câteva detalii

00:11:22.330 --> 00:11:27.330
despre cum am putea să facem acele mașini inteligente și --

00:11:27.330 --> 00:11:32.330
(Râsete)

00:11:32.330 --> 00:11:37.330
și ideea principală e de fapt că în esență o mașină cu adevărat deșteaptă

00:11:37.330 --> 00:11:42.330
e una care recunoaște genul de problemă cu care te confrunți.

00:11:42.330 --> 00:11:45.330
Asta e o problemă de tipul ăsta,

00:11:45.330 --> 00:11:50.330
și de aceea este un anume mod sau moduri de gândire

00:11:50.330 --> 00:11:52.330
care sunt bune pentru acea problemă.

00:11:52.330 --> 00:11:56.330
Deci cred că principala viitoare problemă a psihologiei este să clasifice

00:11:56.330 --> 00:12:00.330
tipuri de necazuri, tipuri de situații, tipuri de obstacole,

00:12:00.330 --> 00:12:06.330
și de asemenea să clasifice posibile moduri de a le gândi și pune împreună.

00:12:06.330 --> 00:12:09.330
Deci vedeți, e aproape pavlovian --

00:12:09.330 --> 00:12:11.330
am pierdut prima sută de ani în psihologie

00:12:11.330 --> 00:12:14.330
cu teorii triviale unde spui,

00:12:14.330 --> 00:12:20.330
cum învață oamenii să reacționeze la o situație? Ce spun eu e,

00:12:20.330 --> 00:12:25.330
după ce trecem prin multe etape, incluzând designul

00:12:25.330 --> 00:12:28.330
unui sistem imens și confuz cu mii de părți,

00:12:28.330 --> 00:12:32.330
vom sfârși din nou cu problema centrală a psihologiei.

00:12:32.330 --> 00:12:35.330
Spunând, nu care sunt situațiile,

00:12:35.330 --> 00:12:37.330
dar care sunt tipurile de probleme

00:12:37.330 --> 00:12:40.330
și care sunt tipurile de strategii, cum le învățăm,

00:12:40.330 --> 00:12:43.330
cum le conectăm, cum inventează o persoană cu adevărat creativă

00:12:43.330 --> 00:12:48.330
un nou mod de gândire despre resursele existente și așa mai departe.

00:12:48.330 --> 00:12:50.330
Deci cred că în următorii 20 de ani,

00:12:50.330 --> 00:12:55.330
dacă renunțăm la toate abordările tradiționale față de inteligența artificială,

00:12:55.330 --> 00:12:57.330
ca rețele neurale și algoritmi genetici

00:12:57.330 --> 00:13:03.330
și sisteme pe grupe de reguli și privim puțin mai sus să spunem,

00:13:03.330 --> 00:13:05.330
putem să facem un sistem care să folosescă toate lucrurile alea

00:13:05.330 --> 00:13:09.330
pentru tipul corect de problemă? Unele probleme sunt bune pentru rețele neurale;

00:13:09.330 --> 00:13:12.330
știm că pentru altele, rețelele neurale nu folosesc la nimic.

00:13:12.330 --> 00:13:15.330
Algoritmii genetici sunt grozavi pentru anumite lucruri;

00:13:15.330 --> 00:13:19.330
Bănuiesc că știu la ce nu sunt buni și n-o să vă spun.

00:13:19.330 --> 00:13:20.330
(Râsete)

00:13:20.330 --> 00:13:22.330
Muțumesc.

00:13:22.330 --> 00:13:28.330
(Aplauze)

