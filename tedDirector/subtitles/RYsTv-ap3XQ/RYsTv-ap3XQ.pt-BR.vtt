WEBVTT
Kind: captions
Language: pt-BR

00:00:00.000 --> 00:00:18.330
Tradutor: Fabio Ceconello
Revisor: Rafael Eufrasio

00:00:18.330 --> 00:00:24.330
Se você perguntar às pessoas sobre que parte da psicologia elas consideram difícil,

00:00:24.330 --> 00:00:27.330
e você disser, bem, que tal raciocínio e emoções,

00:00:27.330 --> 00:00:30.330
a maioria das pessoas vai dizer, "Emoções são terrivelmente difíceis.

00:00:30.330 --> 00:00:36.330
Elas são incrivelmente complexas, elas não -- eu não tenho idéia de como funcionam.

00:00:36.330 --> 00:00:38.330
Mas o raciocínio é mesmo muito simples.

00:00:38.330 --> 00:00:42.330
É apenas um tipo de racionalização lógica ou algo assim.

00:00:42.330 --> 00:00:45.330
Mas essa não é a parte difícil."

00:00:45.330 --> 00:00:47.330
Mas aqui está uma lista de problemas que aparecem.

00:00:47.330 --> 00:00:50.330
Um belo problema é: o que fazer sobre a saúde?

00:00:50.330 --> 00:00:54.330
Outro dia eu estava lendo algo, e a pessoa dizia

00:00:54.330 --> 00:01:00.330
provavelmente a principal causa individual de doenças no ocidente é o aperto de mão.

00:01:00.330 --> 00:01:04.330
E havia um pequeno estudo sobre pessoas que não dão aperto de mão,

00:01:04.330 --> 00:01:07.330
e comparava elas com as que dão,

00:01:07.330 --> 00:01:12.330
e eu não tenho a mínima idéia de onde você encontra pessoas que recusam o aperto de mão,

00:01:12.330 --> 00:01:15.330
porque elas devem se esconder.

00:01:15.330 --> 00:01:19.330
E as pessoas que o evitam

00:01:19.330 --> 00:01:23.330
têm 30% menos doenças infecciosas, ou perto disso.

00:01:23.330 --> 00:01:26.330
Ou talvez era 31,25%.

00:01:26.330 --> 00:01:30.330
Então se você realmente quer resolver o problema de epidemias e etc.

00:01:30.330 --> 00:01:34.330
comecemos com isso. E uma vez que tive esta idéia,

00:01:34.330 --> 00:01:38.330
Eu tive de apertar centenas de mãos.

00:01:38.330 --> 00:01:43.330
E eu acho que o único modo de evitar isso

00:01:43.330 --> 00:01:45.330
é ter alguma doença visível horrível,

00:01:45.330 --> 00:01:48.330
e então você não tem de dar explicações.

00:01:48.330 --> 00:01:52.330
Educação: como melhoramos a educação?

00:01:52.330 --> 00:01:56.330
Bem, a melhor forma é fazê-los endender

00:01:56.330 --> 00:01:59.330
que o que eles estão aprendendo é um monte de coisas sem sentido.

00:01:59.330 --> 00:02:01.330
E então, é claro, você tem de fazer algo

00:02:01.330 --> 00:02:06.330
para moderar isso, para que todos possam dar ouvidos a você.

00:02:06.330 --> 00:02:10.330
Poluição, escassez de energia, diversidade ambiental, pobreza --

00:02:10.330 --> 00:02:14.330
como criamos sociedades estáveis? Longevidade.

00:02:14.330 --> 00:02:17.330
OK, existem muitos problemas com que se preocupar.

00:02:17.330 --> 00:02:19.330
De qualquer modo, a questão sobre a qual acho que deveria se falar --

00:02:19.330 --> 00:02:24.330
e é um tabu absoluto -- é, quantas pessoas deveriam existir?

00:02:24.330 --> 00:02:31.330
E eu acho que deveria ser entre 100 milhões ou talvez 500 milhões.

00:02:31.330 --> 00:02:36.330
E então veja que muitos destes problemas desapareceriam.

00:02:36.330 --> 00:02:38.330
Se você tivesse 100 milhões de pessoas

00:02:38.330 --> 00:02:44.330
devidamente espalhadas, então, se existe algum lixo,

00:02:44.330 --> 00:02:51.330
você joga fora, preferivelmente onde você não pode ver, e vai apodrecer.

00:02:51.330 --> 00:02:56.330
Ou você joga ele no oceano e algum peixe vai se beneficiar dele.

00:02:56.330 --> 00:02:58.330
O problema é, quantas pessoas deveriam existir?

00:02:58.330 --> 00:03:01.330
E é uma escolha que temos de fazer.

00:03:01.330 --> 00:03:04.330
A maioria das pessoas tem em torno de 1m80 ou mais,

00:03:04.330 --> 00:03:08.330
e existe uma perda cúbica. Então se você os fizesse deste tamanho --

00:03:08.330 --> 00:03:11.330
usando nanotecnologia, suponho --

00:03:11.330 --> 00:03:12.330
(risos)

00:03:12.330 --> 00:03:14.330
-- então você poderia ter mil vezes mais.

00:03:14.330 --> 00:03:16.330
Isto resolveria o problema, mas não vejo ninguém

00:03:16.330 --> 00:03:19.330
fazendo qualquer pesquisa sobre como tornar as pessoas menores.

00:03:19.330 --> 00:03:24.330
É legal reduzir a população, mas muitas pessoas querem ter filhos.

00:03:24.330 --> 00:03:27.330
E existe uma solução que provavelmente está a alguns anos de existir.

00:03:27.330 --> 00:03:32.330
Vocês sabem que têm 46 cromossomos. Se tiveram sorte, ganharam 23

00:03:32.330 --> 00:03:38.330
de cada um dos pais; às vezes você ganha um extra ou perde um,

00:03:38.330 --> 00:03:42.330
mas -- então você pode pular o estágio do avô e bisavô

00:03:42.330 --> 00:03:47.330
e ir direto ao tataravô. E você tem 46 pessoas

00:03:47.330 --> 00:03:50.330
e você dá a eles um scanner, ou o que quer que precisem,

00:03:50.330 --> 00:03:54.330
e elas analisam seus cromossomos, e cada uma diz

00:03:54.330 --> 00:03:59.330
qual gosta mais, ou ela -- não há razão para haver só dois sexos

00:03:59.330 --> 00:04:04.330
mesmo mais. Então cada filho tem 46 pais,

00:04:04.330 --> 00:04:10.330
e imagino que se poderia deixar cada grupo de 46 pais ter 15 filhos --

00:04:10.330 --> 00:04:12.330
não seria suficiente? E então os filhos

00:04:12.330 --> 00:04:16.330
teriam muito apoio, e sustento e orientação

00:04:16.330 --> 00:04:18.330
e então a população mundial cairia muito rapidamente

00:04:18.330 --> 00:04:21.330
e todos seriam totalmente felizes.

00:04:21.330 --> 00:04:24.330
Partilha de tempo está um pouco mais longe no futuro.

00:04:24.330 --> 00:04:27.330
E existe um ótimo romance que Arthur Clarke escreveu duas vezes,

00:04:27.330 --> 00:04:31.330
chamado "Against the Fall of Night" e "A Cidade e as Estrelas"

00:04:31.330 --> 00:04:34.330
eles são ambos maravilhosos e praticamente iguais

00:04:34.330 --> 00:04:36.330
exceto que computadores aconteceram no meio tempo.

00:04:36.330 --> 00:04:41.330
E Arthur estava olhando para este velho livro, e disse, isso está errado.

00:04:41.330 --> 00:04:43.330
O futuro tem de ter alguns computadores.

00:04:43.330 --> 00:04:48.330
Então na segunda versão dele, existem 100 bilhões,

00:04:48.330 --> 00:04:56.330
ou 1 trilhão de pessoas na Terra, mas elas estão todas armazenadas em discos rígidos ou disquetes,

00:04:56.330 --> 00:04:58.330
ou o que quer que exista no futuro.

00:04:58.330 --> 00:05:02.330
E só a alguns milhões é permitido sair cada vez.

00:05:02.330 --> 00:05:06.330
Uma pessoa sai, vive por mil anos

00:05:06.330 --> 00:05:12.330
fazendo o que quiser, e então, quando é hora de voltar

00:05:12.330 --> 00:05:16.330
por um bilhão de anos -- ou um milhão, já esqueci, os números não importam --

00:05:16.330 --> 00:05:20.330
mas não existe mesmo muita gente na terra de uma vez.

00:05:20.330 --> 00:05:22.330
E você pensa então sobre si e suas memórias,

00:05:22.330 --> 00:05:27.330
e antes de voltar à suspensão você edita suas memórias

00:05:27.330 --> 00:05:30.330
e muda sua personalidade e etc.

00:05:30.330 --> 00:05:36.330
A trama do livro é que não existe suficiente diversidade,

00:05:36.330 --> 00:05:39.330
então as pessoas que desenharam a cidade

00:05:39.330 --> 00:05:43.330
fazem com que de tempos em tempos uma pessoa inteiramente nova é criada.

00:05:43.330 --> 00:05:49.330
E neste romance, um indivíduo particular chamado Alvin é criado. E ele diz,

00:05:49.330 --> 00:05:53.330
talvez esta não é a melhor forma, e destrói o sistema inteiro.

00:05:53.330 --> 00:05:55.330
Não acho que as soluções que eu propus

00:05:55.330 --> 00:05:58.330
são boas o suficiente ou inteligentes o suficiente.

00:05:58.330 --> 00:06:02.330
Acho que o grande problema é que não somos inteligentes o suficiente

00:06:02.330 --> 00:06:06.330
para entender quais dos problemas que temos são bons o suficiente.

00:06:06.330 --> 00:06:10.330
Portanto, temos de construir máquinas superinteligentes como o HAL.

00:06:10.330 --> 00:06:15.330
Vocês devem lembrar, a certa altura do livro 2001,

00:06:15.330 --> 00:06:20.330
HAL percebe que o universo é muito grande e profundo

00:06:20.330 --> 00:06:24.330
para esses astronautas tão estúpidos. Se você contrastar o comportamento de HAL

00:06:24.330 --> 00:06:28.330
com a trivialidade das pessoas na espaçonave,

00:06:28.330 --> 00:06:31.330
você pode ver o que está escrito nas entrelinhas.

00:06:31.330 --> 00:06:34.330
Bem, o que vamos fazer sobre isso? Podemos ficar mais inteligentes.

00:06:34.330 --> 00:06:39.330
Acho que já somos bem inteligentes, comparados com chimpanzés,

00:06:39.330 --> 00:06:45.330
mas não somos inteligentes o suficiente para lidar com os problemas colossais que enfrentamos,

00:06:45.330 --> 00:06:47.330
seja na matemática abstrata

00:06:47.330 --> 00:06:52.330
ou em entender economia ou manter o equilíbrio do mundo.

00:06:52.330 --> 00:06:55.330
Então uma coisa que podemos fazer é viver mais.

00:06:55.330 --> 00:06:57.330
E ninguém sabe quão difícil isso será,

00:06:57.330 --> 00:07:00.330
mas vamos provavelmente descobrir em poucos anos.

00:07:00.330 --> 00:07:03.330
Sabe, existem duas encruzilhadas na estrada. Sabemos que as pessoas vivem

00:07:03.330 --> 00:07:07.330
o dobro dos chimpanzés, quase,

00:07:07.330 --> 00:07:11.330
e ninguém vive mais de 120 anos,

00:07:11.330 --> 00:07:14.330
por razões ainda não bem compreendidas.

00:07:14.330 --> 00:07:17.330
Mas muitas pessoas vivem até 90 ou 100,

00:07:17.330 --> 00:07:21.330
exceto se apertarem muitas mãos ou algo assim.

00:07:21.330 --> 00:07:26.330
Então talvez se vivêssemos 200 anos, poderíamos acumular habilidade suficiente

00:07:26.330 --> 00:07:31.330
e conhecimento para resolver alguns problemas.

00:07:31.330 --> 00:07:33.330
Esta é uma das formas de analisar isto.

00:07:33.330 --> 00:07:36.330
Como eu disse, não sabemos quão difícil é. Pode ser --

00:07:36.330 --> 00:07:42.330
afinal, a maioria dos outros mamíferos vivem a metade dos chimpanzés,

00:07:42.330 --> 00:07:45.330
então estamos três e meia ou quatro vezes -- quatro vezes

00:07:45.330 --> 00:07:51.330
a longevidade da maioria dos animais. E no caso dos primatas,

00:07:51.330 --> 00:07:55.330
temos praticamente os mesmos genes. Nossa diferença para chimpanzés

00:07:55.330 --> 00:08:01.330
no estado atual da ciência -- que é lixo absoluto --

00:08:01.330 --> 00:08:03.330
talvez algumas centenas de genes.

00:08:03.330 --> 00:08:06.330
Eu acho realmente que os contadores de genes não sabem o que estão fazendo ainda.

00:08:06.330 --> 00:08:09.330
E o que quer que você faça, não leia nada sobre genética

00:08:09.330 --> 00:08:12.330
que for publicado enquanto você viver, ou quase isso.

00:08:12.330 --> 00:08:15.330
(Risos)

00:08:15.330 --> 00:08:19.330
Essas coisas têm vida muito curta, assim como ciência cerebral.

00:08:19.330 --> 00:08:25.330
Então pode ser que se nós só consertarmos quatro ou cinco genes,

00:08:25.330 --> 00:08:27.330
podemos viver 200 anos.

00:08:27.330 --> 00:08:30.330
Ou pode ser que sejam só 30 ou 40,

00:08:30.330 --> 00:08:32.330
e duvido que sejam várias centenas.

00:08:32.330 --> 00:08:36.330
Portanto isto é algo que as pessoas vão discutir

00:08:36.330 --> 00:08:39.330
e muitos eticistas -- sabem, um eticista é alguém

00:08:39.330 --> 00:08:42.330
que vê algo errado com o que quer que você tenha em mente.

00:08:42.330 --> 00:08:45.330
(Risos)

00:08:45.330 --> 00:08:49.330
E é muito difícil de encontrar um eticista que considere qualquer mudança

00:08:49.330 --> 00:08:53.330
válida de fazer, porque ele diz, e quanto às consequências?

00:08:53.330 --> 00:08:56.330
E é claro, não somos responsáveis pelas consequências

00:08:56.330 --> 00:09:02.330
do que estamos fazendo agora, somos? Como todo este barulho sobre clones.

00:09:02.330 --> 00:09:05.330
Ainda assim duas pessoas aleatórias que têm um filho,

00:09:05.330 --> 00:09:09.330
e ambas têm alguns genes bem estragados,

00:09:09.330 --> 00:09:13.330
e o filho é provável que seja mediano.

00:09:13.330 --> 00:09:19.330
O que para os padrões de um chimpanzé é muito bom.

00:09:19.330 --> 00:09:22.330
Se tivermos longevidade, então teremos de encarar o crescimento populacional

00:09:22.330 --> 00:09:26.330
de qualquer modo. Porque se as pessoas viverem 200 ou 1000 anos,

00:09:26.330 --> 00:09:32.330
então não podemos deixar que tenham um filho mais que uma vez a cada 200 ou 1000 anos.

00:09:32.330 --> 00:09:35.330
Então não haverá mais trabalhadores.

00:09:35.330 --> 00:09:39.330
E uma das coisas que Laurie Garrett mencionou, e outros,

00:09:39.330 --> 00:09:44.330
é que uma sociedade que não tem pessoas

00:09:44.330 --> 00:09:47.330
em idade de trabalhar tem um sério problema. E as coisas vão piorar,

00:09:47.330 --> 00:09:53.330
porque não existirá ninguém para educar as crianças ou alimentar os idosos.

00:09:53.330 --> 00:09:55.330
E quando falo sobre uma vida longa, é claro,

00:09:55.330 --> 00:10:01.330
não quero que alguém com 200 anos seja como nossa imagem

00:10:01.330 --> 00:10:05.330
do que é alguém assim velho agora -- morto, na verdade.

00:10:05.330 --> 00:10:07.330
Sabem, existem quase 400 diferentes partes do cérebro

00:10:07.330 --> 00:10:09.330
que parecem ter diferentes funções.

00:10:09.330 --> 00:10:12.330
Ninguém sabe como a maioria delas trabalha em detalhes,

00:10:12.330 --> 00:10:16.330
mas sabemos que existem muitas coisas diferentes lá.

00:10:16.330 --> 00:10:18.330
E elas nem sempre trabalham juntas. Gosto da teoria de Freud

00:10:18.330 --> 00:10:22.330
de que a maioria delas estão se cancelando mutuamente.

00:10:22.330 --> 00:10:26.330
Então se você pensar em si como uma cidade

00:10:26.330 --> 00:10:32.330
com cem recursos, então, quando está preocupado, por exemplo,

00:10:32.330 --> 00:10:36.330
pode descartar suas metas de longo prazo, mas pode pensar profundamente

00:10:36.330 --> 00:10:40.330
e focar em exatamente como atingir uma meta particular.

00:10:40.330 --> 00:10:43.330
Você joga todo o resto fora. Você se torna monomaníaco --

00:10:43.330 --> 00:10:47.330
tudo com que se preocupa é não pular fora da plataforma.

00:10:47.330 --> 00:10:51.330
E quando você está com fome, a comida fica mais atraente, e etc.

00:10:51.330 --> 00:10:57.330
Portanto vejo emoções como altamente evoluídos subconjuntos de sua capacidade.

00:10:57.330 --> 00:11:01.330
Emoção não é algo acrescentado ao pensamento. Um estado emocional

00:11:01.330 --> 00:11:05.330
é o que você obtém quando remove 100 ou 200

00:11:05.330 --> 00:11:08.330
dos seus recursos normalmente disponíveis.

00:11:08.330 --> 00:11:11.330
Então pensar sobre emoções como o oposto de algo

00:11:11.330 --> 00:11:15.330
menos que pensar é imensamente produtivo. E espero,

00:11:15.330 --> 00:11:19.330
nos próximos anos, mostrar que isto vai levar a máquinas inteligentes.

00:11:19.330 --> 00:11:22.330
E acho que é melhor pular o resto disso, que são alguns detalhes

00:11:22.330 --> 00:11:27.330
sobre como podemos fazer estas máquinas inteligentes e --

00:11:27.330 --> 00:11:32.330
(Risos)

00:11:32.330 --> 00:11:37.330
-- e a principal idéia é na verdade que o centro de uma máquina realmente inteligente

00:11:37.330 --> 00:11:42.330
é uma que reconhece que você está encarando certo tipo de problema.

00:11:42.330 --> 00:11:45.330
que é um problema de tal-e-tal tipo,

00:11:45.330 --> 00:11:50.330
e portanto existe um certo modo ou modos de pensar

00:11:50.330 --> 00:11:52.330
que são bons para esse problema.

00:11:52.330 --> 00:11:56.330
Portanto acho que no futuro o maior problema da psicologia será classificar

00:11:56.330 --> 00:12:00.330
tipos de prognósticos, tipos de situações, tipos de obstáculos

00:12:00.330 --> 00:12:06.330
e também classificar os modos de pensar disponíveis e possíveis e combiná-los.

00:12:06.330 --> 00:12:09.330
Podemos ver que é quase como um Pavloviano --

00:12:09.330 --> 00:12:11.330
perdemos os primeiros cem anos de psicologia

00:12:11.330 --> 00:12:14.330
com teorias realmente triviais onde se diz,

00:12:14.330 --> 00:12:20.330
como as pessoas aprendem a reagir a uma situação? O que quero dizer é,

00:12:20.330 --> 00:12:25.330
depois de passar por muitos níveis, incluindo desenhar

00:12:25.330 --> 00:12:28.330
um enorme e caótico sistema com milhares de partes,

00:12:28.330 --> 00:12:32.330
vamos terminar novamente com o problema central da psicologia.

00:12:32.330 --> 00:12:35.330
Dizendo, não quais são as situações,

00:12:35.330 --> 00:12:37.330
mas quais são os tipos de problemas

00:12:37.330 --> 00:12:40.330
e quais são os tipos de estratégias, como as aprendemos,

00:12:40.330 --> 00:12:43.330
como as conectamos, como uma pessoa realmente criativa

00:12:43.330 --> 00:12:48.330
inventa um novo modo de pensar sobre os recursos disponíveis e etc.

00:12:48.330 --> 00:12:50.330
Portanto penso que nos próximos 20 anos,

00:12:50.330 --> 00:12:55.330
Se pudermos nos livrar de todas as abordagens tradicionais à inteligência artificial,

00:12:55.330 --> 00:12:57.330
como redes neurais e algoritmos genéticos

00:12:57.330 --> 00:13:03.330
e sistemas especialistas, e apenas elevar a perspectiva um pouco para dizer,

00:13:03.330 --> 00:13:05.330
podemos fazer um sistema que possa usar todas estas coisas

00:13:05.330 --> 00:13:09.330
para o tipo certo de problema? Alguns problemas são bons para redes neurais,

00:13:09.330 --> 00:13:12.330
sabemos que para outros, redes neurais são inúteis.

00:13:12.330 --> 00:13:15.330
Algoritmos genéticos são ótimos para certas coisas;

00:13:15.330 --> 00:13:19.330
Suspeito que sei para que eles são ruins e não vou lhes dizer.

00:13:19.330 --> 00:13:20.330
(Risos)

00:13:20.330 --> 00:13:22.330
Obrigado.

00:13:22.330 --> 00:13:28.330
(Aplausos)

