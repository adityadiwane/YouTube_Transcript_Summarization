WEBVTT
Kind: captions
Language: es

00:00:00.000 --> 00:00:07.000
Traductor: Ruth Alonso
Revisor: Karla V. Leal

00:00:18.330 --> 00:00:24.330
Si le preguntan a la gente qué parte de la psicología creen que es más difícil,

00:00:24.330 --> 00:00:27.330
y dices, bueno, "¿qué hay del pensamiento y las emociones?"

00:00:27.330 --> 00:00:30.330
La mayoría de la gente dirá, "las emociones son muy complicadas.

00:00:30.330 --> 00:00:36.330
Son increíblemente complejas, no pueden... No tengo ni idea de cómo funcionan¨.

00:00:36.330 --> 00:00:38.330
Pero el pensamiento es muy directo:

00:00:38.330 --> 00:00:42.330
es simplemente una especie de razonamiento lógico o algo así.

00:00:42.330 --> 00:00:45.330
Pero eso no es lo difícil.

00:00:45.330 --> 00:00:47.330
Así que aquí hay una lista de problemas que surgen.

00:00:47.330 --> 00:00:50.330
Un problema fino es: ¿qué haremos con respecto a la salud?

00:00:50.330 --> 00:00:54.330
El otro día estaba leyendo algo y la persona decía que probablemente

00:00:54.330 --> 00:01:00.330
dar la mano en occidente es el principal causante de enfermedades.

00:01:00.330 --> 00:01:04.330
Y hubo un pequeño estudio sobre la gente que no da la mano,

00:01:04.330 --> 00:01:07.330
que los comparaba con los que sí la dan,

00:01:07.330 --> 00:01:12.330
y no tengo ni remota idea de dónde se encuentran los que no dan la mano,

00:01:12.330 --> 00:01:15.330
porque deben de estar escondidos.

00:01:15.330 --> 00:01:19.330
Y la gente que evita eso tiene un 30% menos

00:01:19.330 --> 00:01:23.330
de posibilidades de contraer enfermedades contagiosas.

00:01:23.330 --> 00:01:26.330
O quizás fuera un 31% y un cuarto.

00:01:26.330 --> 00:01:30.330
Así que si realmente queremos solucionar el problema de las epidemias y demás,

00:01:30.330 --> 00:01:34.330
empecemos con eso. Y desde que se me ocurrió esa idea,

00:01:34.330 --> 00:01:38.330
he dado la mano cientos de veces.

00:01:38.330 --> 00:01:43.330
Creo que la única manera de evitarlo

00:01:43.330 --> 00:01:45.330
es tener algún tipo de enfermedad visiblemente horrorosa

00:01:45.330 --> 00:01:48.330
y así no tienes que explicar nada.

00:01:48.330 --> 00:01:52.330
Educación: ¿cómo mejorar la educación?

00:01:52.330 --> 00:01:56.330
Bueno, la mejor manera es hacer que entiendan

00:01:56.330 --> 00:01:59.330
que lo que se les cuenta son tonterías.

00:01:59.330 --> 00:02:01.330
Claro, entonces, tienes que hacer algo

00:02:01.330 --> 00:02:06.330
para moderar eso y que así de alguna manera te escuchen a ti.

00:02:06.330 --> 00:02:10.330
Polución, carencia de energía, diversidad ambiental, pobreza...

00:02:10.330 --> 00:02:14.330
¿Cómo crear sociedades estables? Longevidad.

00:02:14.330 --> 00:02:17.330
Hay muchos problemas de los que preocuparse.

00:02:17.330 --> 00:02:19.330
En cualquier caso, la pregunta que creo que la gente debe hacerse -

00:02:19.330 --> 00:02:24.330
y es completamente tabú- es, ¿cuántas personas debería haber?

00:02:24.330 --> 00:02:31.330
Creo que debería haber sobre 100 millones, o quizá 500.

00:02:31.330 --> 00:02:36.330
Y entonces nos damos cuenta de que muchos de estos problemas desaparecen.

00:02:36.330 --> 00:02:38.330
Si tienes 100 millones de personas

00:02:38.330 --> 00:02:44.330
bien esparcidas, si hay algo de basura

00:02:44.330 --> 00:02:51.330
la tiras, preferentemente donde no se pueda ver, y se pudrirá.

00:02:51.330 --> 00:02:56.330
O la tiras al océano y algunos peces se beneficiarán.

00:02:56.330 --> 00:02:58.330
El problema es, ¿cuánta gente debería haber?

00:02:58.330 --> 00:03:01.330
Es una decisión que tenemos que tomar.

00:03:01.330 --> 00:03:04.330
La mayoría de la gente mide 60 pulgadas o más,

00:03:04.330 --> 00:03:08.330
y hay esta pérdida al cubo si los haces así de grandes -

00:03:08.330 --> 00:03:11.330
usando nanotecnología, supongo-

00:03:11.330 --> 00:03:12.330
(Risas)

00:03:12.330 --> 00:03:14.330
entonces podrían tener mil veces más.

00:03:14.330 --> 00:03:16.330
Eso solucionaría el problema, pero no veo a nadie

00:03:16.330 --> 00:03:19.330
investigando cómo hacer a la gente más pequeña.

00:03:19.330 --> 00:03:24.330
Claro que está bien reducir la población, pero mucha gente quiere tener hijos.

00:03:24.330 --> 00:03:27.330
Hay una solución que probablemente sólo está desfasada unos años.

00:03:27.330 --> 00:03:32.330
Saben que tienen 46 cromosomas. Si tienen suerte, tienen 23

00:03:32.330 --> 00:03:38.330
de cada padre; a veces tienes uno extra o uno menos,

00:03:38.330 --> 00:03:42.330
pero -de modo que saltarías la etapa de abuelo y bisabuelo

00:03:42.330 --> 00:03:47.330
e irías directamente al tatarabuelo. Si tienes 46 personas

00:03:47.330 --> 00:03:50.330
y les das un escáner, o lo que necesites,

00:03:50.330 --> 00:03:54.330
y miran sus cromosomas y cada uno dice

00:03:54.330 --> 00:03:59.330
cuál le gusta más, o ella- ya no hay razón para tener sólo dos sexos.

00:03:59.330 --> 00:04:04.330
Así que cada hijo tiene 46 padres,

00:04:04.330 --> 00:04:10.330
y supongo que se puede dejar a cada grupo de 46 padres tener 15 hijos,

00:04:10.330 --> 00:04:12.330
¿no sería eso suficiente? De ese modo los niños

00:04:12.330 --> 00:04:16.330
tendrían suficiente apoyo, amor y modelos

00:04:16.330 --> 00:04:18.330
y la población mundial se reduciría rápidamente

00:04:18.330 --> 00:04:21.330
y todos serían totalmente felices.

00:04:21.330 --> 00:04:24.330
El tiempo compartido está más alejado en el futuro.

00:04:24.330 --> 00:04:27.330
Hay una gran novela que Arthur Clark escribió dos veces,

00:04:27.330 --> 00:04:31.330
llamada "Tras la caída de la noche" y "La ciudad y las estrellas".

00:04:31.330 --> 00:04:34.330
Las dos son maravillosas y básicamente la misma,

00:04:34.330 --> 00:04:36.330
sólo que las computadoras surgieron entre ambas,

00:04:36.330 --> 00:04:41.330
y Arthur estaba mirando la novela más vieja, y dijo, "bueno, eso fue un error.

00:04:41.330 --> 00:04:43.330
El futuro ha de tener ordenadores".

00:04:43.330 --> 00:04:48.330
Así que en la segunda versión hay 100 millardos,

00:04:48.330 --> 00:04:56.330
o 1.000 millardos de gente en la tierra, guardados en discos duros o disquetes,

00:04:56.330 --> 00:04:58.330
o lo que sea que tengan en el futuro.

00:04:58.330 --> 00:05:02.330
Así que dejas salir a unos cuantos millones cada vez.

00:05:02.330 --> 00:05:06.330
Sale una persona, vive mil años

00:05:06.330 --> 00:05:12.330
haciendo lo que sea, y entonces, cuando hay que retroceder

00:05:12.330 --> 00:05:16.330
un millardo de años -o un millón, lo olvido, las cifras no importan-

00:05:16.330 --> 00:05:20.330
en realidad no hay mucha gente en la tierra a la vez.

00:05:20.330 --> 00:05:22.330
Puedes pensar en ti mismo y tus recuerdos,

00:05:22.330 --> 00:05:27.330
y antes de volver a estar en suspensión editas tus recuerdos

00:05:27.330 --> 00:05:30.330
y cambias tu personalidad, y así sucesivamente.

00:05:30.330 --> 00:05:36.330
La trama del libro es que no hay suficiente diversidad,

00:05:36.330 --> 00:05:39.330
así que la gente que diseñó la ciudad

00:05:39.330 --> 00:05:43.330
se asegura de que cada cierto tiempo se cree una persona nueva.

00:05:43.330 --> 00:05:49.330
En la novela, se crea una persona llamada Alvin, que dice:

00:05:49.330 --> 00:05:53.330
"tal vez esta no es la mejor manera", y estropea todo el sistema.

00:05:53.330 --> 00:05:55.330
No creo que las soluciones que propuse

00:05:55.330 --> 00:05:58.330
sean lo suficientemente buenas o inteligentes.

00:05:58.330 --> 00:06:02.330
Creo que el gran problema es que no somos lo suficientemente listos

00:06:02.330 --> 00:06:06.330
para entender cuáles de los problemas ante nosotros son lo suficientemente relevantes.

00:06:06.330 --> 00:06:10.330
Así que tenemos que construir máquinas sumamente inteligentes como HAL.

00:06:10.330 --> 00:06:15.330
Como recordarán, en un momento del libro para 2001,

00:06:15.330 --> 00:06:20.330
HAL se da cuenta de que el universo es demasiado grande, maravilloso y lleno de significado

00:06:20.330 --> 00:06:24.330
para unos astronautas tan estúpidos. Si comparan el comportamiento de HAL

00:06:24.330 --> 00:06:28.330
con la trivialidad de la gente en la nave,

00:06:28.330 --> 00:06:31.330
verán lo que está escrito entre líneas.

00:06:31.330 --> 00:06:34.330
Y sobre eso, ¿qué vamos a hacer? Podríamos ser más listos.

00:06:34.330 --> 00:06:39.330
Creo que somos bastante listos, comparados con los chimpancés.

00:06:39.330 --> 00:06:45.330
pero no lo bastante para lidiar con los colosales problemas ante nosotros,

00:06:45.330 --> 00:06:47.330
sea en matemáticas abstractas,

00:06:47.330 --> 00:06:52.330
en economía, o en equilibrar el mundo.

00:06:52.330 --> 00:06:55.330
Algo que podemos hacer es vivir más.

00:06:55.330 --> 00:06:57.330
Y nadie sabe lo difícil que es eso,

00:06:57.330 --> 00:07:00.330
pero probablemente lo sabremos en unos años.

00:07:00.330 --> 00:07:03.330
La carretera se bifurca. Sabemos que la gente vive

00:07:03.330 --> 00:07:07.330
casi el doble que los chimpancés,

00:07:07.330 --> 00:07:11.330
y que nadie vive más de 120 años,

00:07:11.330 --> 00:07:14.330
por razones que no entendemos bien.

00:07:14.330 --> 00:07:17.330
Pero mucha gente vive 90 ó 100 años,

00:07:17.330 --> 00:07:21.330
a menos que den demasiado la mano o algo así.

00:07:21.330 --> 00:07:26.330
Así que tal vez si viviéramos 200 años, acumularíamos suficientes destrezas

00:07:26.330 --> 00:07:31.330
y conocimientos para solucionar algunos problemas.

00:07:31.330 --> 00:07:33.330
Esa es una forma de actuar.

00:07:33.330 --> 00:07:36.330
Y, como dije, no sabemos qué tan difícil es. Al fin y al cabo,

00:07:36.330 --> 00:07:42.330
la mayoría de los otros mamíferos viven la mitad que los chimpancés,

00:07:42.330 --> 00:07:45.330
así que vivimos tres veces y media o cuatro... vivimos cuatro veces más

00:07:45.330 --> 00:07:51.330
que la mayoría de los mamíferos. En el caso de los primates,

00:07:51.330 --> 00:07:55.330
tenemos casi los mismos genes. Lo que nos separa de los chimpancés

00:07:55.330 --> 00:08:01.330
es el estado actual del saber, que es un total disparate,

00:08:01.330 --> 00:08:03.330
tal vez unas centenas de genes.

00:08:03.330 --> 00:08:06.330
Creo que los contadores de genes aún no saben lo que están haciendo.

00:08:06.330 --> 00:08:09.330
Y hagan lo que hagan, no lean nada sobre genética

00:08:09.330 --> 00:08:12.330
que se publique mientras vivan.

00:08:12.330 --> 00:08:15.330
(Risas)

00:08:15.330 --> 00:08:19.330
Esas ideas tienen una esperanza de vida corta, al igual que las ciencias del cerebro.

00:08:19.330 --> 00:08:25.330
Así que tal vez si arreglamos cuatro o cinco genes,

00:08:25.330 --> 00:08:27.330
podremos vivir 200 años.

00:08:27.330 --> 00:08:30.330
O tal vez sólo 30 ó 40,

00:08:30.330 --> 00:08:32.330
dudo que varios centenares.

00:08:32.330 --> 00:08:36.330
Esto es algo que la gente discutirá

00:08:36.330 --> 00:08:39.330
y muchos éticos -un ético es alguien

00:08:39.330 --> 00:08:42.330
que encuentra algo malo en todo lo que piensas.

00:08:42.330 --> 00:08:45.330
(Risas)

00:08:45.330 --> 00:08:49.330
Es difícil encontrar un experto en ética que considere cualquier cambio

00:08:49.330 --> 00:08:53.330
digno de hacerse, porque dice, "¿y las consecuencias?"

00:08:53.330 --> 00:08:56.330
Y claro, no somos responsables de las consecuencias

00:08:56.330 --> 00:09:02.330
de lo que estamos haciendo ahora, ¿no? Como esta protesta sobre los clones.

00:09:02.330 --> 00:09:05.330
Y sin embargo dos personas al azar se aparearán y tendrán un hijo,

00:09:05.330 --> 00:09:09.330
y aunque ambos tienen genes bastante podridos,

00:09:09.330 --> 00:09:13.330
es probable que el niño salga normal.

00:09:13.330 --> 00:09:19.330
Lo cual, para estándares chimpancés, está pero que muy bien.

00:09:19.330 --> 00:09:22.330
Si ganamos en longevidad, tendremos que afrontar de todos modos el problema

00:09:22.330 --> 00:09:26.330
del crecimiento problacional porque si la gente vive 200 ó 1.000 años,

00:09:26.330 --> 00:09:32.330
no podemos dejar que tengan más de un hijo cada 200 ó 1.000 años.

00:09:32.330 --> 00:09:35.330
Así no habrá población activa.

00:09:35.330 --> 00:09:39.330
Una de las cosas que Laurie Garrett, y otros, han señalado

00:09:39.330 --> 00:09:44.330
es que una sociedad sin población activa

00:09:44.330 --> 00:09:47.330
es un problema grave. Y las cosas van a empeorar, porque

00:09:47.330 --> 00:09:53.330
no hay nadie para educar a los niños o alimentar a los ancianos.

00:09:53.330 --> 00:09:55.330
Y cuando hablo de vidas largas, claro,

00:09:55.330 --> 00:10:01.330
no quiero que alguien con 200 años tenga la imagen que tenemos

00:10:01.330 --> 00:10:05.330
de alguien con 200 años, es decir, muerto.

00:10:05.330 --> 00:10:07.330
Hay cerca de 400 partes diferentes en el cerebro

00:10:07.330 --> 00:10:09.330
que parecen tener funciones diferentes.

00:10:09.330 --> 00:10:12.330
Nadie sabe los detalles de cómo funcionan muchas,

00:10:12.330 --> 00:10:16.330
pero sabemos que ahí hay muchas cosas diferentes,

00:10:16.330 --> 00:10:18.330
y no siempre trabajan juntas. Me gusta la teoría de Freud

00:10:18.330 --> 00:10:22.330
de que la mayoría se anulan.

00:10:22.330 --> 00:10:26.330
Si piensas en ti mismo como en una ciudad

00:10:26.330 --> 00:10:32.330
con cien recursos, entonces, cuando tienes miedo, por ejemplo,

00:10:32.330 --> 00:10:36.330
tal vez descartes objetivos a largo plazo, pero puede que pienses en serio

00:10:36.330 --> 00:10:40.330
y te centres exactamente en cómo conseguir un objetivo concreto.

00:10:40.330 --> 00:10:43.330
Dejas todo lo demás de lado, te conviertes en un mononaníaco -

00:10:43.330 --> 00:10:47.330
lo único que te preocupa es no salirte de esa plataforma.

00:10:47.330 --> 00:10:51.330
Y cuando tienes hambre, la comida se hace más apetecible y así sucesivamente.

00:10:51.330 --> 00:10:57.330
Veo las emociones como subgrupos muy evolucionados de la capacidad de ustedes.

00:10:57.330 --> 00:11:01.330
La emoción no es algo que se añade al pensamiento. Un estado emocional

00:11:01.330 --> 00:11:05.330
es lo que te queda cuando quitas 100 ó 200

00:11:05.330 --> 00:11:08.330
de tus recursos disponibles habitualmente.

00:11:08.330 --> 00:11:11.330
Pensar en las emociones como algo opuesto, como algo

00:11:11.330 --> 00:11:15.330
menos que el pensamiento es muy productivo, y espero,

00:11:15.330 --> 00:11:19.330
en los próximos años, que esto nos lleve a máquinas inteligentes.

00:11:19.330 --> 00:11:22.330
Supongo que lo mejor es que me salte el resto, son detalles sobre

00:11:22.330 --> 00:11:27.330
cómo hacer esas máquinas inteligentes -

00:11:27.330 --> 00:11:32.330
(Risas)

00:11:32.330 --> 00:11:37.330
- la idea principal es que de hecho el corazón de una máquina inteligente

00:11:37.330 --> 00:11:42.330
es una máquina que reconoce cuándo te estás enfrentando a algún problema:

00:11:42.330 --> 00:11:45.330
«Este es un problema de tal o cual tipo».

00:11:45.330 --> 00:11:50.330
Consecuentemente, hay ciertas maneras de pensar

00:11:50.330 --> 00:11:52.330
que son buenas para ese problema.

00:11:52.330 --> 00:11:56.330
Creo que el problema más importante para la psicología futura es clasificar

00:11:56.330 --> 00:12:00.330
tipos de problemas, de situaciones, de obstáculos

00:12:00.330 --> 00:12:06.330
y también clasificar maneras de pensar disponibles y emparejarlos.

00:12:06.330 --> 00:12:09.330
Así que ya ven, es casi como de Pavlov -

00:12:09.330 --> 00:12:11.330
perdimos los primeros cien años de psicología

00:12:11.330 --> 00:12:14.330
en teorías realmente triviales que hablan de

00:12:14.330 --> 00:12:20.330
cómo la gente aprende a reaccionar ante una situación. Lo que digo es,

00:12:20.330 --> 00:12:25.330
tras pasar por muchos niveles, incluyendo el diseño de un sistema

00:12:25.330 --> 00:12:28.330
enorme y desordenado con miles de partes,

00:12:28.330 --> 00:12:32.330
terminaremos otra vez en el problema central de la psicología.

00:12:32.330 --> 00:12:35.330
No nos preguntaremos: ¿cúales son las situaciones?,

00:12:35.330 --> 00:12:37.330
sino: ¿cúales son los tipos de problemas?

00:12:37.330 --> 00:12:40.330
¿Cúales son los tipos de estrategias? ¿Cómo se aprenden?

00:12:40.330 --> 00:12:43.330
¿Cómo se conectan? ¿Cómo inventa una persona muy creativa

00:12:43.330 --> 00:12:48.330
una forma nueva de pensar a partir de los recursos disponibles? Y así sucesivamente.

00:12:48.330 --> 00:12:50.330
Creo que en los próximos 20 años,

00:12:50.330 --> 00:12:55.330
si nos podemos librar de los acercamientos tradicionales a la inteligencia artificial,

00:12:55.330 --> 00:12:57.330
como redes neuronales, algoritmos genéticos

00:12:57.330 --> 00:13:03.330
y sistemas expertos, tendremos las miras más altas y nos preguntaremos

00:13:03.330 --> 00:13:05.330
si podemos crear un sistema que pueda usar esas cosas para

00:13:05.330 --> 00:13:09.330
el problema adecuado. Algunos problemas son buenos para redes neuronales;

00:13:09.330 --> 00:13:12.330
sabemos que para otros las redes neurolanes son inútiles.

00:13:12.330 --> 00:13:15.330
los algoritmos genéticos son estupendos para ciertas cosas;

00:13:15.330 --> 00:13:19.330
sospecho saber para qué son malos y no se lo diré.

00:13:19.330 --> 00:13:20.330
(Risas)

00:13:20.330 --> 00:13:22.330
Gracias.

00:13:22.330 --> 00:13:28.330
(Aplausos)

