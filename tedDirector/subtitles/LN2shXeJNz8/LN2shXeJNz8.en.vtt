WEBVTT
Kind: captions
Language: en

00:00:18.330 --> 00:00:24.330
What technology can we really apply to reducing global poverty?

00:00:24.330 --> 00:00:28.330
And what I found was quite surprising.

00:00:28.330 --> 00:00:31.330
We started looking at things like death rates in the 20th century,

00:00:31.330 --> 00:00:34.330
and how they'd been improved, and very simple things turned out.

00:00:34.330 --> 00:00:37.330
You'd think maybe antibiotics made more difference than clean water,

00:00:37.330 --> 00:00:40.330
but it's actually the opposite.

00:00:40.330 --> 00:00:43.330
And so very simple things -- off-the-shelf technologies

00:00:43.330 --> 00:00:48.330
that we could easily find on the then-early Web --

00:00:48.330 --> 00:00:53.330
would clearly make a huge difference to that problem.

00:00:53.330 --> 00:00:57.330
But I also, in looking at more powerful technologies

00:00:57.330 --> 00:01:02.330
and nanotechnology and genetic engineering and other new emerging

00:01:02.330 --> 00:01:06.330
kind of digital technologies, became very concerned

00:01:06.330 --> 00:01:10.330
about the potential for abuse.

00:01:10.330 --> 00:01:15.330
If you think about it, in history, a long, long time ago

00:01:15.330 --> 00:01:18.330
we dealt with the problem of an individual abusing another individual.

00:01:18.330 --> 00:01:21.330
We came up with something -- the Ten Commandments: Thou shalt not kill.

00:01:21.330 --> 00:01:23.330
That's a, kind of a one-on-one thing.

00:01:23.330 --> 00:01:27.330
We organized into cities. We had many people.

00:01:27.330 --> 00:01:31.330
And to keep the many from tyrannizing the one,

00:01:31.330 --> 00:01:35.330
we came up with concepts like individual liberty.

00:01:35.330 --> 00:01:36.330
And then, to have to deal with large groups,

00:01:36.330 --> 00:01:39.330
say, at the nation-state level,

00:01:39.330 --> 00:01:41.330
and we had to have mutual non-aggression,

00:01:41.330 --> 00:01:45.330
or through a series of conflicts, we eventually came to

00:01:45.330 --> 00:01:51.330
a rough international bargain to largely keep the peace.

00:01:51.330 --> 00:01:56.330
But now we have a new situation, really what people call

00:01:56.330 --> 00:01:59.330
an asymmetric situation, where technology is so powerful

00:01:59.330 --> 00:02:03.330
that it extends beyond a nation-state.

00:02:03.330 --> 00:02:06.330
It's not the nation-states that have potential access

00:02:06.330 --> 00:02:11.330
to mass destruction, but individuals.

00:02:11.330 --> 00:02:16.330
And this is a consequence of the fact that these new technologies tend to be digital.

00:02:16.330 --> 00:02:20.330
We saw genome sequences.

00:02:20.330 --> 00:02:21.330
You can download the gene sequences

00:02:21.330 --> 00:02:25.330
of pathogens off the Internet if you want to,

00:02:25.330 --> 00:02:30.330
and clearly someone recently -- I saw in a science magazine --

00:02:30.330 --> 00:02:35.330
they said, well, the 1918 flu is too dangerous to FedEx around.

00:02:35.330 --> 00:02:38.330
If people want to use it in their labs for working on research,

00:02:38.330 --> 00:02:41.330
just reconstruct it yourself,

00:02:41.330 --> 00:02:45.330
because, you know, it might break in FedEx.

00:02:45.330 --> 00:02:50.330
So that this is possible to do this is not deniable.

00:02:50.330 --> 00:02:55.330
So individuals in small groups super-empowered by access to these

00:02:55.330 --> 00:03:00.330
kinds of self-replicating technologies, whether it be biological

00:03:00.330 --> 00:03:03.330
or other, are clearly a danger in our world.

00:03:03.330 --> 00:03:07.330
And the danger is that they can cause roughly what's a pandemic.

00:03:07.330 --> 00:03:10.330
And we really don't have experience with pandemics,

00:03:10.330 --> 00:03:13.330
and we're also not very good as a society at acting

00:03:13.330 --> 00:03:17.330
to things we don't have direct and sort of gut-level experience with.

00:03:17.330 --> 00:03:21.330
So it's not in our nature to pre-act.

00:03:21.330 --> 00:03:26.330
And in this case, piling on more technology doesn't solve the problem,

00:03:26.330 --> 00:03:29.330
because it only super-empowers people more.

00:03:29.330 --> 00:03:33.330
So the solution has to be, as people like Russell and Einstein

00:03:33.330 --> 00:03:35.330
and others imagine in a conversation that existed

00:03:35.330 --> 00:03:39.330
in a much stronger form, I think, early in the 20th century,

00:03:39.330 --> 00:03:42.330
that the solution had to be not just the head but the heart.

00:03:42.330 --> 00:03:47.330
You know, public policy and moral progress.

00:03:47.330 --> 00:03:53.330
The bargain that gives us civilization is a bargain to not use power.

00:03:53.330 --> 00:03:56.330
We get our individual rights by society protecting us from others

00:03:56.330 --> 00:04:01.330
not doing everything they can do but largely doing only what is legal.

00:04:01.330 --> 00:04:06.330
And so to limit the danger of these new things, we have to limit,

00:04:06.330 --> 00:04:08.330
ultimately, the ability of individuals

00:04:08.330 --> 00:04:11.330
to have access, essentially, to pandemic power.

00:04:11.330 --> 00:04:15.330
We also have to have sensible defense, because no limitation

00:04:15.330 --> 00:04:18.330
is going to prevent a crazy person from doing something.

00:04:18.330 --> 00:04:20.330
And you know, and the troubling thing is that

00:04:20.330 --> 00:04:22.330
it's much easier to do something bad than to defend

00:04:22.330 --> 00:04:24.330
against all possible bad things,

00:04:24.330 --> 00:04:28.330
so the offensive uses really have an asymmetric advantage.

00:04:28.330 --> 00:04:32.330
So these are the kind of thoughts I was thinking in 1999 and 2000,

00:04:32.330 --> 00:04:34.330
and my friends told me I was getting really depressed,

00:04:34.330 --> 00:04:36.330
and they were really worried about me.

00:04:36.330 --> 00:04:39.330
And then I signed a book contract to write more gloomy thoughts about this

00:04:39.330 --> 00:04:41.330
and moved into a hotel room in New York

00:04:41.330 --> 00:04:45.330
with one room full of books on the Plague,

00:04:45.330 --> 00:04:48.330
and you know, nuclear bombs exploding in New York

00:04:48.330 --> 00:04:51.330
where I would be within the circle, and so on.

00:04:51.330 --> 00:04:55.330
And then I was there on September 11th,

00:04:55.330 --> 00:04:56.330
and I stood in the streets with everyone.

00:04:56.330 --> 00:04:58.330
And it was quite an experience to be there.

00:04:58.330 --> 00:05:01.330
I got up the next morning and walked out of the city,

00:05:01.330 --> 00:05:04.330
and all the sanitation trucks were parked on Houston Street

00:05:04.330 --> 00:05:06.330
and ready to go down and start taking the rubble away.

00:05:06.330 --> 00:05:08.330
And I walked down the middle, up to the train station,

00:05:08.330 --> 00:05:11.330
and everything below 14th Street was closed.

00:05:11.330 --> 00:05:15.330
It was quite a compelling experience, but not really, I suppose,

00:05:15.330 --> 00:05:18.330
a surprise to someone who'd had his room full of the books.

00:05:18.330 --> 00:05:22.330
It was always a surprise that it happened then and there,

00:05:22.330 --> 00:05:26.330
but it wasn't a surprise that it happened at all.

00:05:26.330 --> 00:05:28.330
And everyone then started writing about this.

00:05:28.330 --> 00:05:29.330
Thousands of people started writing about this.

00:05:29.330 --> 00:05:31.330
And I eventually abandoned the book, and then Chris called me

00:05:31.330 --> 00:05:34.330
to talk at the conference. I really don't talk about this anymore

00:05:34.330 --> 00:05:39.330
because, you know, there's enough frustrating and depressing things going on.

00:05:39.330 --> 00:05:42.330
But I agreed to come and say a few things about this.

00:05:42.330 --> 00:05:45.330
And I would say that we can't give up the rule of law

00:05:45.330 --> 00:05:49.330
to fight an asymmetric threat, which is what we seem to be doing

00:05:49.330 --> 00:05:54.330
because of the present, the people that are in power,

00:05:54.330 --> 00:05:59.330
because that's to give up the thing that makes civilization.

00:05:59.330 --> 00:06:02.330
And we can't fight the threat in the kind of stupid way we're doing,

00:06:02.330 --> 00:06:04.330
because a million-dollar act

00:06:04.330 --> 00:06:07.330
causes a billion dollars of damage, causes a trillion dollar response

00:06:07.330 --> 00:06:10.330
which is largely ineffective and arguably, probably almost certainly,

00:06:10.330 --> 00:06:12.330
has made the problem worse.

00:06:12.330 --> 00:06:17.330
So we can't fight the thing with a million-to-one cost,

00:06:17.330 --> 00:06:23.330
one-to-a-million cost-benefit ratio.

00:06:24.330 --> 00:06:29.330
So after giving up on the book -- and I had the great honor

00:06:29.330 --> 00:06:33.330
to be able to join Kleiner Perkins about a year ago,

00:06:33.330 --> 00:06:40.330
and to work through venture capital on the innovative side,

00:06:40.330 --> 00:06:44.330
and to try to find some innovations that could address what I saw as

00:06:44.330 --> 00:06:46.330
some of these big problems.

00:06:46.330 --> 00:06:49.330
Things where, you know, a factor of 10 difference

00:06:49.330 --> 00:06:53.330
can make a factor of 1,000 difference in the outcome.

00:06:53.330 --> 00:06:56.330
I've been amazed in the last year at the incredible quality

00:06:56.330 --> 00:07:01.330
and excitement of the innovations that have come across my desk.

00:07:01.330 --> 00:07:04.330
It's overwhelming at times. I'm very thankful for Google and Wikipedia

00:07:04.330 --> 00:07:08.330
so I can understand at least a little of what people are talking about

00:07:08.330 --> 00:07:10.330
who come through the doors.

00:07:10.330 --> 00:07:13.330
But I wanted to share with you three areas

00:07:13.330 --> 00:07:16.330
that I'm particularly excited about and that relate to the problems

00:07:16.330 --> 00:07:21.330
that I was talking about in the Wired article.

00:07:21.330 --> 00:07:23.330
The first is this whole area of education,

00:07:23.330 --> 00:07:27.330
and it really relates to what Nicholas was talking about with a $100 computer.

00:07:27.330 --> 00:07:31.330
And that is to say that there's a lot of legs left in Moore's Law.

00:07:31.330 --> 00:07:35.330
The most advanced transistors today are at 65 nanometers,

00:07:35.330 --> 00:07:38.330
and we've seen, and I've had the pleasure to invest

00:07:38.330 --> 00:07:44.330
in, companies that give me great confidence that we'll extend Moore's Law

00:07:44.330 --> 00:07:47.330
all the way down to roughly the 10 nanometer scale.

00:07:47.330 --> 00:07:53.330
Another factor of, say, six in dimensional reduction,

00:07:53.330 --> 00:07:58.330
which should give us about another factor of 100 in raw improvement

00:07:58.330 --> 00:08:03.330
in what the chips can do. And so, to put that in practical terms,

00:08:03.330 --> 00:08:07.330
if something costs about 1,000 dollars today,

00:08:07.330 --> 00:08:12.330
say, the best personal computer you can buy, that might be its cost,

00:08:12.330 --> 00:08:18.330
I think we can have that in 2020 for 10 dollars. Okay?

00:08:18.330 --> 00:08:23.330
Now, just imagine what that $100 computer will be in 2020

00:08:23.330 --> 00:08:25.330
as a tool for education.

00:08:25.330 --> 00:08:27.330
I think the challenge for us is --

00:08:27.330 --> 00:08:29.330
I'm very certain that that will happen, the challenge is,

00:08:29.330 --> 00:08:34.330
will we develop the kind of educational tools and things with the net

00:08:34.330 --> 00:08:37.330
to let us take advantage of that device?

00:08:37.330 --> 00:08:41.330
I'd argue today that we have incredibly powerful computers,

00:08:41.330 --> 00:08:43.330
but we don't have very good software for them.

00:08:43.330 --> 00:08:46.330
And it's only in retrospect, after the better software comes along,

00:08:46.330 --> 00:08:48.330
and you take it and you run it on a ten-year-old machine, you say,

00:08:48.330 --> 00:08:50.330
God, the machine was that fast?

00:08:50.330 --> 00:08:52.330
I remember when they took the Apple Mac interface

00:08:52.330 --> 00:08:55.330
and they put it back on the Apple II.

00:08:55.330 --> 00:08:58.330
The Apple II was perfectly capable of running that kind of interface,

00:08:58.330 --> 00:09:01.330
we just didn't know how to do it at the time.

00:09:01.330 --> 00:09:03.330
So given that we know and should believe --

00:09:03.330 --> 00:09:06.330
because Moore's Law's been, like, a constant,

00:09:06.330 --> 00:09:09.330
I mean, it's just been very predictable progress

00:09:09.330 --> 00:09:12.330
over the last 40 years or whatever.

00:09:12.330 --> 00:09:16.330
We can know what the computers are going to be like in 2020.

00:09:16.330 --> 00:09:18.330
It's great that we have initiatives to say,

00:09:18.330 --> 00:09:21.330
let's go create the education and educate people in the world,

00:09:21.330 --> 00:09:23.330
because that's a great force for peace.

00:09:23.330 --> 00:09:26.330
And we can give everyone in the world a $100 computer

00:09:26.330 --> 00:09:31.330
or a $10 computer in the next 15 years.

00:09:31.330 --> 00:09:36.330
The second area that I'm focusing on is the environmental problem,

00:09:36.330 --> 00:09:40.330
because that's clearly going to put a lot of pressure on this world.

00:09:40.330 --> 00:09:44.330
We'll hear a lot more about that from Al Gore very shortly.

00:09:44.330 --> 00:09:47.330
The thing that we see as the kind of Moore's Law trend

00:09:47.330 --> 00:09:50.330
that's driving improvement in our ability to address

00:09:50.330 --> 00:09:54.330
the environmental problem is new materials.

00:09:54.330 --> 00:09:58.330
We have a challenge, because the urban population is growing

00:09:58.330 --> 00:10:01.330
in this century from two billion to six billion

00:10:01.330 --> 00:10:03.330
in a very short amount of time. People are moving to the cities.

00:10:03.330 --> 00:10:06.330
They all need clean water, they need energy, they need transportation,

00:10:06.330 --> 00:10:10.330
and we want them to develop in a green way.

00:10:10.330 --> 00:10:12.330
We're reasonably efficient in the industrial sectors.

00:10:12.330 --> 00:10:15.330
We've made improvements in energy and resource efficiency,

00:10:15.330 --> 00:10:19.330
but the consumer sector, especially in America, is very inefficient.

00:10:19.330 --> 00:10:23.330
But these new materials bring such incredible innovations

00:10:23.330 --> 00:10:27.330
that there's a strong basis for hope that these things

00:10:27.330 --> 00:10:29.330
will be so profitable that they can be brought to the market.

00:10:29.330 --> 00:10:32.330
And I want to give you a specific example of a new material

00:10:32.330 --> 00:10:35.330
that was discovered 15 years ago.

00:10:35.330 --> 00:10:40.330
If we take carbon nanotubes, you know, Iijima discovered them in 1991,

00:10:40.330 --> 00:10:42.330
they just have incredible properties.

00:10:42.330 --> 00:10:43.330
And these are the kinds of things we're going to discover

00:10:43.330 --> 00:10:46.330
as we start to engineer at the nano scale.

00:10:46.330 --> 00:10:49.330
Their strength: they're almost the strongest material,

00:10:49.330 --> 00:10:51.330
tensile strength material known.

00:10:52.330 --> 00:10:57.330
They're very, very stiff. They stretch very, very little.

00:10:57.330 --> 00:11:00.330
In two dimensions, if you make, like, a fabric out of them,

00:11:00.330 --> 00:11:03.330
they're 30 times stronger than Kevlar.

00:11:03.330 --> 00:11:06.330
And if you make a three-dimensional structure, like a buckyball,

00:11:06.330 --> 00:11:08.330
they have all sorts of incredible properties.

00:11:08.330 --> 00:11:11.330
If you shoot a particle at them and knock a hole in them,

00:11:11.330 --> 00:11:14.330
they repair themselves; they go zip and they repair the hole

00:11:14.330 --> 00:11:17.330
in femtoseconds, which is not -- is really quick.

00:11:17.330 --> 00:11:20.330
(Laughter)

00:11:20.330 --> 00:11:24.330
If you shine a light on them, they produce electricity.

00:11:24.330 --> 00:11:27.330
In fact, if you flash them with a camera they catch on fire.

00:11:27.330 --> 00:11:31.330
If you put electricity on them, they emit light.

00:11:31.330 --> 00:11:34.330
If you run current through them, you can run 1,000 times more current

00:11:34.330 --> 00:11:38.330
through one of these than through a piece of metal.

00:11:38.330 --> 00:11:41.330
You can make both p- and n-type semiconductors,

00:11:41.330 --> 00:11:43.330
which means you can make transistors out of them.

00:11:43.330 --> 00:11:46.330
They conduct heat along their length but not across --

00:11:46.330 --> 00:11:48.330
well, there is no width, but not in the other direction

00:11:48.330 --> 00:11:54.330
if you stack them up; that's a property of carbon fiber also.

00:11:54.330 --> 00:11:57.330
If you put particles in them, and they go shooting out the tip --

00:11:57.330 --> 00:12:00.330
they're like miniature linear accelerators or electron guns.

00:12:00.330 --> 00:12:03.330
The inside of the nanotubes is so small --

00:12:03.330 --> 00:12:05.330
the smallest ones are 0.7 nanometers --

00:12:05.330 --> 00:12:07.330
that it's basically a quantum world.

00:12:07.330 --> 00:12:10.330
It's a strange place inside a nanotube.

00:12:10.330 --> 00:12:13.330
And so we begin to see, and we've seen business plans already,

00:12:13.330 --> 00:12:16.330
where the kind of things Lisa Randall's talking about are in there.

00:12:16.330 --> 00:12:18.330
I had one business plan where I was trying to learn more about

00:12:18.330 --> 00:12:21.330
Witten's cosmic dimension strings to try to understand

00:12:21.330 --> 00:12:24.330
what the phenomenon was going on in this proposed nanomaterial.

00:12:24.330 --> 00:12:30.330
So inside of a nanotube, we're really at the limit here.

00:12:30.330 --> 00:12:34.330
So what we see is with these and other new materials

00:12:34.330 --> 00:12:38.330
that we can do things with different properties -- lighter, stronger --

00:12:38.330 --> 00:12:44.330
and apply these new materials to the environmental problems.

00:12:44.330 --> 00:12:45.330
New materials that can make water,

00:12:45.330 --> 00:12:47.330
new materials that can make fuel cells work better,

00:12:47.330 --> 00:12:51.330
new materials that catalyze chemical reactions,

00:12:51.330 --> 00:12:54.330
that cut pollution and so on.

00:12:54.330 --> 00:12:57.330
Ethanol -- new ways of making ethanol.

00:12:57.330 --> 00:13:00.330
New ways of making electric transportation.

00:13:00.330 --> 00:13:04.330
The whole green dream -- because it can be profitable.

00:13:04.330 --> 00:13:06.330
And we've dedicated -- we've just raised a new fund,

00:13:06.330 --> 00:13:09.330
we dedicated 100 million dollars to these kinds of investments.

00:13:09.330 --> 00:13:13.330
We believe that Genentech, the Compaq, the Lotus, the Sun,

00:13:13.330 --> 00:13:17.330
the Netscape, the Amazon, the Google in these fields

00:13:17.330 --> 00:13:20.330
are yet to be found, because this materials revolution

00:13:20.330 --> 00:13:23.330
will drive these things forward.

00:13:24.330 --> 00:13:26.330
The third area that we're working on,

00:13:26.330 --> 00:13:30.330
and we just announced last week -- we were all in New York.

00:13:30.330 --> 00:13:36.330
We raised 200 million dollars in a specialty fund

00:13:36.330 --> 00:13:40.330
to work on a pandemic in biodefense.

00:13:40.330 --> 00:13:43.330
And to give you an idea of the last fund that Kleiner raised

00:13:43.330 --> 00:13:48.330
was a $400 million fund, so this for us is a very substantial fund.

00:13:48.330 --> 00:13:52.330
And what we did, over the last few months -- well, a few months ago,

00:13:52.330 --> 00:13:55.330
Ray Kurzweil and I wrote an op-ed in the New York Times

00:13:55.330 --> 00:13:58.330
about how publishing the 1918 genome was very dangerous.

00:13:58.330 --> 00:14:02.330
And John Doerr and Brook and others got concerned, [unclear],

00:14:02.330 --> 00:14:06.330
and we started looking around at what the world was doing

00:14:06.330 --> 00:14:11.330
about being prepared for a pandemic. And we saw a lot of gaps.

00:14:11.330 --> 00:14:15.330
And so we asked ourselves, you know, can we find innovative things

00:14:15.330 --> 00:14:19.330
that will go fill these gaps? And Brooks told me in a break here,

00:14:19.330 --> 00:14:21.330
he said he's found so much stuff he can't sleep,

00:14:21.330 --> 00:14:24.330
because there's so many great technologies out there,

00:14:24.330 --> 00:14:27.330
we're essentially buried. And we need them, you know.

00:14:27.330 --> 00:14:30.330
We have one antiviral that people are talking about stockpiling

00:14:30.330 --> 00:14:33.330
that still works, roughly. That's Tamiflu.

00:14:33.330 --> 00:14:38.330
But Tamiflu -- the virus is resistant. It is resistant to Tamiflu.

00:14:38.330 --> 00:14:42.330
We've discovered with AIDS we need cocktails to work well

00:14:42.330 --> 00:14:45.330
so that the viral resistance -- we need several anti-virals.

00:14:45.330 --> 00:14:47.330
We need better surveillance.

00:14:47.330 --> 00:14:50.330
We need networks that can find out what's going on.

00:14:50.330 --> 00:14:54.330
We need rapid diagnostics so that we can tell if somebody has

00:14:54.330 --> 00:14:58.330
a strain of flu which we have only identified very recently.

00:14:58.330 --> 00:15:00.330
We've got to be able to make the rapid diagnostics quickly.

00:15:00.330 --> 00:15:03.330
We need new anti-virals and cocktails. We need new kinds of vaccines.

00:15:03.330 --> 00:15:05.330
Vaccines that are broad spectrum.

00:15:05.330 --> 00:15:09.330
Vaccines that we can manufacture quickly.

00:15:09.330 --> 00:15:11.330
Cocktails, more polyvalent vaccines.

00:15:11.330 --> 00:15:14.330
You normally get a trivalent vaccine against three possible strains.

00:15:14.330 --> 00:15:17.330
We need -- we don't know where this thing is going.

00:15:17.330 --> 00:15:20.330
We believe that if we could fill these 10 gaps,

00:15:20.330 --> 00:15:26.330
we have a chance to help really reduce the risk of a pandemic.

00:15:26.330 --> 00:15:30.330
And the difference between a normal flu season and a pandemic

00:15:30.330 --> 00:15:33.330
is about a factor of 1,000 in deaths

00:15:33.330 --> 00:15:36.330
and certainly enormous economic impact.

00:15:36.330 --> 00:15:39.330
So we're very excited because we think we can fund 10,

00:15:39.330 --> 00:15:43.330
or speed up 10 projects and see them come to market

00:15:43.330 --> 00:15:46.330
in the next couple years that will address this.

00:15:46.330 --> 00:15:49.330
So if we can address, use technology, help address education,

00:15:49.330 --> 00:15:52.330
help address the environment, help address the pandemic,

00:15:52.330 --> 00:15:56.330
does that solve the larger problem that I was talking about

00:15:56.330 --> 00:16:01.330
in the Wired article? And I'm afraid the answer is really no,

00:16:01.330 --> 00:16:05.330
because you can't solve a problem with the management of technology

00:16:05.330 --> 00:16:08.330
with more technology.

00:16:08.330 --> 00:16:13.330
If we let an unlimited amount of power loose, then we will --

00:16:13.330 --> 00:16:15.330
a very small number of people will be able to abuse it.

00:16:15.330 --> 00:16:19.330
We can't fight at a million-to-one disadvantage.

00:16:19.330 --> 00:16:22.330
So what we need to do is, we need better policy.

00:16:22.330 --> 00:16:25.330
And for example, some things we could do

00:16:25.330 --> 00:16:29.330
that would be policy solutions which are not really in the political air right now

00:16:29.330 --> 00:16:33.330
but perhaps with the change of administration would be -- use markets.

00:16:33.330 --> 00:16:35.330
Markets are a very strong force.

00:16:35.330 --> 00:16:38.330
For example, rather than trying to regulate away problems,

00:16:38.330 --> 00:16:40.330
which probably won't work, if we could price

00:16:40.330 --> 00:16:45.330
into the cost of doing business, the cost of catastrophe,

00:16:45.330 --> 00:16:48.330
so that people who are doing things that had a higher cost of catastrophe

00:16:48.330 --> 00:16:51.330
would have to take insurance against that risk.

00:16:51.330 --> 00:16:53.330
So if you wanted to put a drug on the market you could put it on.

00:16:53.330 --> 00:16:55.330
But it wouldn't have to be approved by regulators;

00:16:55.330 --> 00:16:59.330
you'd have to convince an actuary that it would be safe.

00:16:59.330 --> 00:17:02.330
And if you apply the notion of insurance more broadly,

00:17:02.330 --> 00:17:05.330
you can use a more powerful force, a market force,

00:17:05.330 --> 00:17:07.330
to provide feedback.

00:17:07.330 --> 00:17:08.330
How could you keep the law?

00:17:08.330 --> 00:17:10.330
I think the law would be a really good thing to keep.

00:17:10.330 --> 00:17:12.330
Well, you have to hold people accountable.

00:17:12.330 --> 00:17:14.330
The law requires accountability.

00:17:14.330 --> 00:17:17.330
Today scientists, technologists, businessmen, engineers

00:17:17.330 --> 00:17:19.330
don't have any personal responsibility

00:17:19.330 --> 00:17:21.330
for the consequences of their actions.

00:17:21.330 --> 00:17:25.330
So if you tie that -- you have to tie that back with the law.

00:17:25.330 --> 00:17:29.330
And finally, I think we have to do something that's not really --

00:17:29.330 --> 00:17:30.330
it's almost unacceptable to say this -- which,

00:17:30.330 --> 00:17:33.330
we have to begin to design the future.

00:17:33.330 --> 00:17:37.330
We can't pick the future, but we can steer the future.

00:17:37.330 --> 00:17:39.330
Our investment in trying to prevent pandemic flu

00:17:39.330 --> 00:17:43.330
is affecting the distribution of possible outcomes.

00:17:43.330 --> 00:17:45.330
We may not be able to stop it, but the likelihood

00:17:45.330 --> 00:17:49.330
that it will get past us is lower if we focus on that problem.

00:17:49.330 --> 00:17:53.330
So we can design the future if we choose what kind of things

00:17:53.330 --> 00:17:56.330
we want to have happen and not have happen,

00:17:56.330 --> 00:17:59.330
and steer us to a lower-risk place.

00:17:59.330 --> 00:18:05.330
Vice President Gore will talk about how we could steer the climate trajectory

00:18:05.330 --> 00:18:08.330
into a lower probability of catastrophic risk.

00:18:08.330 --> 00:18:11.330
But above all, what we have to do is we have to help the good guys,

00:18:11.330 --> 00:18:13.330
the people on the defensive side,

00:18:13.330 --> 00:18:17.330
have an advantage over the people who want to abuse things.

00:18:17.330 --> 00:18:19.330
And what we have to do to do that

00:18:19.330 --> 00:18:22.330
is we have to limit access to certain information.

00:18:22.330 --> 00:18:25.330
And growing up as we have, and holding very high

00:18:25.330 --> 00:18:29.330
the value of free speech, this is a hard thing for us to accept --

00:18:29.330 --> 00:18:30.330
for all of us to accept.

00:18:30.330 --> 00:18:35.330
It's especially hard for the scientists to accept who still remember,

00:18:35.330 --> 00:18:37.330
you know, Galileo essentially locked up,

00:18:37.330 --> 00:18:41.330
and who are still fighting this battle against the church.

00:18:41.330 --> 00:18:46.330
But that's the price of having a civilization.

00:18:46.330 --> 00:18:48.330
The price of retaining the rule of law

00:18:48.330 --> 00:18:53.330
is to limit the access to the great and kind of unbridled power.

00:18:53.330 --> 00:18:54.330
Thank you.

00:18:54.330 --> 00:18:56.330
(Applause)

