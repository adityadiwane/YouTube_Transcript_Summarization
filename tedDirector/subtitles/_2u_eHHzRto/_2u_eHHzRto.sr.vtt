WEBVTT
Kind: captions
Language: sr

00:00:00.000 --> 00:00:07.000
Prevodilac: Romeo Mlinar
Lektor: Tijana Mihajlović

00:00:12.655 --> 00:00:14.221
Algoritmi su svuda.

00:00:15.931 --> 00:00:19.056
Filtriraju i odvajaju
pobednike od gubitnika.

00:00:19.739 --> 00:00:21.853
Pobednici dobijaju posao

00:00:21.877 --> 00:00:23.810
ili dobru ponudu kreditne kartice.

00:00:23.820 --> 00:00:26.471
Za gubitnike nema ni intervjua

00:00:27.270 --> 00:00:29.187
ili plaćaju više za osiguranje.

00:00:29.797 --> 00:00:33.406
Ocenjuju nas tajne formule
koje ne razumemo,

00:00:34.225 --> 00:00:37.442
za koje često ne postoje
sistemi za podnošenje žalbe.

00:00:38.780 --> 00:00:40.166
To nas tera se zapitamo:

00:00:40.190 --> 00:00:43.103
„Šta ako algoritmi greše?“

00:00:44.640 --> 00:00:47.000
Da napravite algoritam
potrebne su vam dve stvari:

00:00:47.020 --> 00:00:48.615
podaci, šta je bilo u prošlosti,

00:00:48.639 --> 00:00:50.000
i definicija uspeha,

00:00:50.014 --> 00:00:52.851
koji tražite i kojem se često nadate.

00:00:52.865 --> 00:00:57.852
Osposobljavate algoritam
posmatranjem i zaključivanjem.

00:00:57.876 --> 00:01:01.295
Algoritam pronalazi vezu sa uspehom.

00:01:01.319 --> 00:01:03.782
Koja situacija vodi ka uspehu?

00:01:04.331 --> 00:01:06.183
Zapravo, svi koriste algoritme,

00:01:06.217 --> 00:01:08.965
ali ih ne formalizuju u pisani kôd.

00:01:08.989 --> 00:01:09.877
Evo vam primera.

00:01:09.897 --> 00:01:13.213
Svaki dan koristim algoritam
da napravim porodici doručak.

00:01:13.701 --> 00:01:15.177
Podaci koje koristim su:

00:01:16.074 --> 00:01:17.603
namirnice u kuhinji,

00:01:17.637 --> 00:01:19.164
vreme koje imam na raspolaganju,

00:01:19.188 --> 00:01:20.221
ambicija koju imam,

00:01:20.255 --> 00:01:22.104
i te podatke obrađujem.

00:01:22.118 --> 00:01:26.369
U hranu ne računam
ona mala pakovanja instant špageta.

00:01:26.403 --> 00:01:28.332
(Smeh)

00:01:28.356 --> 00:01:30.201
Moja definicija uspeha je -

00:01:30.225 --> 00:01:32.884
obrok je uspeo ako moja deca jedu povrće.

00:01:33.711 --> 00:01:36.145
To bi izgledalo mnogo drugačije
da se moj sin pita.

00:01:36.179 --> 00:01:38.967
Njemu bi uspeh bio da se najede nutele.

00:01:40.729 --> 00:01:42.955
Ali, ja biram uspeh.

00:01:42.969 --> 00:01:45.676
Ja sam zadužena za to.
Moje mišljenje je važno.

00:01:45.690 --> 00:01:48.365
To je prvo pravilo algoritama.

00:01:48.409 --> 00:01:51.589
Algoritmi su mišljenja ugrađena u kôd.

00:01:53.132 --> 00:01:57.035
To se veoma razlikuje od onoga što mislite
da većina ljudi misli o algoritmima.

00:01:57.069 --> 00:02:01.223
Ljudi misle da su algoritmi
objektivni, istiniti i naučni.

00:02:01.967 --> 00:02:03.666
To je marketinški trik.

00:02:05.089 --> 00:02:07.214
Marketinški trik jeste

00:02:07.238 --> 00:02:10.112
i kada vas plaše algoritmima,

00:02:10.126 --> 00:02:13.787
kada vas teraju da verujete
i da se plašite algoritama

00:02:13.801 --> 00:02:16.069
jer verujete matematici i plašite je se.

00:02:17.137 --> 00:02:21.967
Mnogo grešaka može se desiti
kada slepo verujemo u masovne podatke.

00:02:23.244 --> 00:02:26.617
Ovo je Kiri Soares,
direktor srednje škole u Bruklinu.

00:02:26.661 --> 00:02:29.147
Godine 2011. rekla mi je
da njen kolektiv ocenjuju

00:02:29.171 --> 00:02:31.898
složenim, tajnim algoritmom

00:02:31.932 --> 00:02:34.091
koji se zove „model dodatne vrednosti“.

00:02:34.115 --> 00:02:36.707
Rekla sam joj: „Saznaj
koja je formula i pokaži mi je.

00:02:36.711 --> 00:02:38.552
Objasniću ti je.“

00:02:38.586 --> 00:02:40.487
Rekla je: „Pokušala sam dobiti formulu,

00:02:40.511 --> 00:02:43.823
ali osoba iz Ministarstva obrazovanja
mi je rekla da je to matematika

00:02:43.847 --> 00:02:45.463
i da je neću razumeti.“

00:02:46.896 --> 00:02:48.234
Postaje sve gore.

00:02:48.258 --> 00:02:51.788
Njujork Post je podneo zahtev
na osnovu zakona o slobodi informacija,

00:02:51.812 --> 00:02:54.771
dobio imena i ocene svih nastavnika

00:02:54.805 --> 00:02:57.587
i onda ih objavio kao čin
sramoćenja nastavnika.

00:02:58.714 --> 00:03:02.574
Kada sam probala istim putem doći
do formula, do izvornog kôda,

00:03:02.618 --> 00:03:04.677
rečeno mi je da ne može.

00:03:04.687 --> 00:03:05.793
Odbijena sam.

00:03:05.811 --> 00:03:06.965
Posle sam saznala

00:03:06.989 --> 00:03:09.935
da niko u Njujorku
nema podatke o toj formuli.

00:03:09.959 --> 00:03:11.264
Niko je nije razumeo.

00:03:13.499 --> 00:03:16.643
Onda se uključio neko
veoma bistar, Geri Rubenstajn.

00:03:16.667 --> 00:03:20.338
Pronašao je 665 nastavnika
iz onog članka u Njujork Postu

00:03:20.362 --> 00:03:22.318
koji zapravo imaju dva rezultata.

00:03:22.352 --> 00:03:26.703
Ovo se moglo desiti jer su predavali
matematiku u sedmom i osmom razredu.

00:03:26.720 --> 00:03:28.378
Odlučio je da ih ubaci u grafikon.

00:03:28.392 --> 00:03:30.385
Svaka tačka je nastavnica ili nastavnik.

00:03:30.434 --> 00:03:33.023
(Smeh)

00:03:33.037 --> 00:03:34.558
Šta je to?

00:03:34.582 --> 00:03:35.919
(Smeh)

00:03:35.943 --> 00:03:39.109
To se nikako nije trebalo koristiti
za individualne procene.

00:03:39.133 --> 00:03:41.059
Ovo je kao generator nasumičnih brojeva.

00:03:41.083 --> 00:03:44.309
(Aplauz)

00:03:44.323 --> 00:03:45.195
Ali, korišćeno je.

00:03:45.239 --> 00:03:46.155
Ovo je Sara Visoki.

00:03:46.189 --> 00:03:48.794
Otpuštena je kad i 205 drugih nastavnika

00:03:48.828 --> 00:03:51.570
iz škola vašingtonskog okruga

00:03:51.604 --> 00:03:54.513
iako je imala odlučne preporuke direktora

00:03:54.547 --> 00:03:55.975
i roditelja učenika.

00:03:56.900 --> 00:03:58.752
Znam šta mnogi od vas ovde sada misle,

00:03:58.776 --> 00:04:01.903
posebno naučnici za podatke,
stručnjaci za veštačku inteligenciju.

00:04:01.923 --> 00:04:05.883
Mislite: „Pa, nikada ne bismo napravili
tako nedosledan algoritam.“

00:04:06.423 --> 00:04:08.036
Ali, algoritmi mogu pogrešiti,

00:04:08.080 --> 00:04:12.678
čak imati i duboko destruktivno dejstvo
sa dobrom namerama.

00:04:14.061 --> 00:04:16.440
Dok loše napravljen avion

00:04:16.464 --> 00:04:18.465
padne na tlo i svi to vide,

00:04:18.489 --> 00:04:20.339
loše osmišljen algoritam

00:04:21.705 --> 00:04:25.610
može trajati dugo i potajno
i tiho praviti ogromnu štetu.

00:04:27.348 --> 00:04:28.918
Ovo je Rodžer Ejls.

00:04:28.952 --> 00:04:30.952
(Smeh)

00:04:32.064 --> 00:04:34.452
Osnovao je Foks Njuz 1996. godine.

00:04:34.996 --> 00:04:37.407
Preko 20 žena žalilo se
na seksualno uznemiravanje.

00:04:37.421 --> 00:04:40.796
Rekle su da im u Foks Njuzu
nije dozvoljen uspeh.

00:04:40.830 --> 00:04:42.160
Izbačen je prošle godine,

00:04:42.184 --> 00:04:46.284
ali nedavno smo videli
da problemi još nisu rešeni.

00:04:47.214 --> 00:04:48.814
To zahteva da se postavi pitanje

00:04:48.838 --> 00:04:51.722
šta Foks Njuz treba da uradi
da okrene novi list.

00:04:52.785 --> 00:04:55.566
Šta bi se desilo da proces zapošljavanja

00:04:55.590 --> 00:04:57.384
zamene mašinskim algoritmom koji uči?

00:04:57.384 --> 00:04:59.089
Zvuči dobro, zar ne?

00:04:59.117 --> 00:05:00.507
Razmislite o tome.

00:05:00.551 --> 00:05:02.606
Podaci. Šta bi bi bili podaci?

00:05:02.640 --> 00:05:07.587
Ima smisla izabrati prijave za Foks Njuz
tokom poslednjih 21 godina.

00:05:07.601 --> 00:05:08.593
Ima smisla.

00:05:09.087 --> 00:05:11.025
A definicija uspeha?

00:05:11.321 --> 00:05:12.915
Razuman izbor bio bi, valjda,

00:05:12.919 --> 00:05:14.597
neko ko je uspešan u Foks Njuzu?

00:05:14.621 --> 00:05:18.121
Recimo, osoba koja je tamo
bila četiri godine

00:05:18.145 --> 00:05:19.799
i dobila unapređenje makar jednom.

00:05:20.326 --> 00:05:21.537
Ima smisla.

00:05:22.011 --> 00:05:24.365
Onda bismo osposobljavali algoritam.

00:05:24.389 --> 00:05:28.266
Osposobili bismo ga da traži ljude,
da uči šta je vodilo ka uspehu,

00:05:28.709 --> 00:05:33.077
kakve vrste prijava su vremenom
vodile ka uspehu

00:05:33.091 --> 00:05:34.745
u skladu sa tom definicijom.

00:05:35.750 --> 00:05:37.525
Razmislite sada šta bi se desilo

00:05:37.559 --> 00:05:40.114
kada bismo to primenili
na trenutne kandidate.

00:05:40.639 --> 00:05:42.268
Izbacilo bi žene

00:05:43.253 --> 00:05:47.183
jer ne deluju kao osobe
koje su bile uspešne u prošlosti.

00:05:51.332 --> 00:05:53.869
Algoritmi ne popravljaju stvari

00:05:53.879 --> 00:05:56.413
ako ih samo nonšalantno
i slepo primenjujete.

00:05:56.431 --> 00:05:58.003
Ne popravljaju stvari.

00:05:58.027 --> 00:06:00.245
Ponavljaju našu praksu iz prošlosti,

00:06:00.259 --> 00:06:01.292
naše šablone.

00:06:01.316 --> 00:06:03.255
Automatizuju status kvo.

00:06:04.288 --> 00:06:06.677
Da živimo u savršenom
svetu to bi bilo sjajno,

00:06:07.495 --> 00:06:08.807
ali ne živimo.

00:06:08.821 --> 00:06:12.633
Dodaću da većina firmi
nema sramne parnice,

00:06:14.026 --> 00:06:16.614
ali naučnicima za podatke
u tim kompanijama

00:06:16.628 --> 00:06:18.817
rečeno je idu tragom podataka,

00:06:18.851 --> 00:06:20.994
da paze na tačnost.

00:06:21.853 --> 00:06:23.234
Razmislite šta to znači.

00:06:23.248 --> 00:06:27.335
Pošto smo svi pristrasni, to znači
da će možda kodifikovati seksizam

00:06:27.369 --> 00:06:29.415
ili drugu netrpeljivost.

00:06:31.068 --> 00:06:32.489
Misaoni eksperiment,

00:06:32.533 --> 00:06:34.042
jer ih volim:

00:06:35.154 --> 00:06:38.129
jedno društvo, skroz podeljeno -

00:06:39.827 --> 00:06:43.149
na osnovu rase, svi gradovi, sve opštine -

00:06:43.169 --> 00:06:46.066
a policiju šaljemo
samo u delove gde živi manjina

00:06:46.090 --> 00:06:47.283
u potrazi za kriminalom.

00:06:48.021 --> 00:06:50.240
Podaci o hapšenjima
bili bi veoma pristrasni.

00:06:51.531 --> 00:06:54.246
Šta ako bismo, povrh svega,
pronašli naučnike za podatke

00:06:54.270 --> 00:06:58.431
i platili tim naučnicima
da predvide mesto sledećeg zločina?

00:06:58.865 --> 00:07:00.352
Opštine sa manjinama.

00:07:00.885 --> 00:07:04.010
Ili da predvide
ko će sledeći biti kriminalac?

00:07:04.388 --> 00:07:05.783
Neko iz manjine.

00:07:07.559 --> 00:07:12.400
Naučnici bi se hvalisali
svojim sjajnim i tačnim modelom,

00:07:12.415 --> 00:07:13.714
i bili bi u pravu.

00:07:15.541 --> 00:07:20.070
Realnost nije tako drastična,
ali postoje ozbiljne podele

00:07:20.070 --> 00:07:21.777
u mnogim malim i velikom gradovima,

00:07:21.777 --> 00:07:23.384
i imamo mnoštvo dokaza

00:07:23.398 --> 00:07:26.086
o pristrasnim podacima
u sistemu policije i pravosuđa.

00:07:27.242 --> 00:07:30.057
Mi zapravo predviđamo krizna mesta,

00:07:30.081 --> 00:07:31.891
mesta gde će se desiti nasilje.

00:07:31.921 --> 00:07:35.897
I predviđamo, zapravo,
pojedinačni kriminalitet,

00:07:35.921 --> 00:07:37.691
kriminalitet pojedinaca.

00:07:38.562 --> 00:07:42.295
Novinska organizacija Propablika
nedavno je proverila

00:07:42.329 --> 00:07:44.193
jedan „algoritam ugrožen recidivizmom“

00:07:44.217 --> 00:07:45.380
kako ih zovu,

00:07:45.404 --> 00:07:48.598
koje sudije koriste
u presudama na Floridi.

00:07:50.061 --> 00:07:53.646
Bernard, levo, crnac,
dobio je 10 od 10 poena.

00:07:54.769 --> 00:07:56.776
Dilan, desno, 3 od 10.

00:07:56.800 --> 00:07:59.581
Deset od deset, visok rizik.
Tri od deset, nizak rizik.

00:08:00.198 --> 00:08:02.583
Obojica su privedeni
zbog posedovanja droge.

00:08:02.617 --> 00:08:03.771
Obojica su imali dosije,

00:08:03.795 --> 00:08:06.601
ali Dilan je imao krivično delo,

00:08:06.625 --> 00:08:07.801
a Bernard nije.

00:08:09.448 --> 00:08:12.514
Ovo je bitno jer što su ti veći poeni,

00:08:12.528 --> 00:08:16.001
veće su šanse da dobiješ dužu kaznu.

00:08:17.864 --> 00:08:19.158
O čemu se ovde radi?

00:08:20.166 --> 00:08:21.498
Pranje podataka.

00:08:22.550 --> 00:08:26.977
Proces kojim tehnolozi
sakrivaju ružnu istinu

00:08:27.001 --> 00:08:28.822
u crne kutije algoritama

00:08:28.856 --> 00:08:30.146
i nazivaju ih objektivnima;

00:08:30.860 --> 00:08:32.428
nazivaju ih meritokratskim.

00:08:34.698 --> 00:08:37.083
Za tajne, važne i destruktivne algoritme

00:08:37.107 --> 00:08:41.374
sam skovala frazu
„oružje za matematičko uništenje“.

00:08:41.401 --> 00:08:42.965
(Smeh)

00:08:42.989 --> 00:08:45.433
(Aplauz)

00:08:46.347 --> 00:08:48.541
Oni su svuda i to nije greška.

00:08:49.295 --> 00:08:53.018
To su privatne kompanije
koje prave privatne algoritme

00:08:53.042 --> 00:08:54.434
za privatne ciljeve.

00:08:54.794 --> 00:08:58.008
Čak i one već spomenute,
za nastavnike i policiju,

00:08:58.052 --> 00:08:59.551
napravile su privatne kompanije

00:08:59.555 --> 00:09:01.546
i zatim ih prodale vladinim telima.

00:09:02.270 --> 00:09:03.793
Zovu ih „tajnim umakom“;

00:09:03.827 --> 00:09:06.105
zato nam ništa ne mogu reći o tome.

00:09:06.139 --> 00:09:08.359
To je i privatna moć.

00:09:09.434 --> 00:09:14.129
Zarađuju na korišćenju autoriteta
koji se ne može proveriti.

00:09:16.684 --> 00:09:19.618
Možda ste pomislili da,
pošto je ovo privatno,

00:09:19.642 --> 00:09:20.650
postoji konkurencija;

00:09:20.674 --> 00:09:23.100
možda će slobodno tržište rešiti problem.

00:09:23.124 --> 00:09:24.373
Neće.

00:09:24.387 --> 00:09:27.507
Mnogo se novca može napraviti nepravdom.

00:09:28.727 --> 00:09:32.096
Uz to, mi nismo
ekonomski racionalni činioci.

00:09:32.631 --> 00:09:33.923
Svi smo pristrasni.

00:09:34.600 --> 00:09:37.977
Svi smo rasisti i netrpeljivi
onako kako ne želimo biti

00:09:38.011 --> 00:09:40.030
u oblicima koje i ne poznajemo.

00:09:40.962 --> 00:09:44.043
Ipak, znamo da je to kolektivno

00:09:44.077 --> 00:09:47.097
jer to sociolozi dosledno dokazuju

00:09:47.131 --> 00:09:48.796
eksperimentima koje osmišljavaju,

00:09:48.820 --> 00:09:51.488
kada pošalju gomilu prijava za posao,

00:09:51.522 --> 00:09:54.283
podjednako dobrih, ali neke imaju
imena koja zvuče belački

00:09:54.287 --> 00:09:55.993
a neke koje zvuče kao crnački,

00:09:56.007 --> 00:09:58.701
i uvek su razočaravajući rezultati; uvek.

00:09:59.080 --> 00:10:00.851
Tako, mi smo pristrasni

00:10:00.865 --> 00:10:04.294
i mi u algoritme ubacujemo pristrasnost

00:10:04.308 --> 00:10:06.120
izborom podataka za prikupljanje,

00:10:06.164 --> 00:10:08.907
kao kada sam odlučila
da ne mislim o instant-špagetama;

00:10:08.931 --> 00:10:10.556
odlučila sam da su nebitne.

00:10:10.590 --> 00:10:16.274
Ako verujemo podacima
koji otkrivaju praksu iz prošlosti

00:10:16.308 --> 00:10:18.322
i biramo definiciju uspeha,

00:10:18.356 --> 00:10:22.339
kako onda očekujemo
da algoritmi ostanu neoštećeni?

00:10:22.383 --> 00:10:24.739
Ne možemo. Moramo ih proveriti.

00:10:25.795 --> 00:10:27.504
Moramo proveriti da li su pravični.

00:10:27.528 --> 00:10:30.239
Dobra vest jeste da možemo
proveriti jesu li pravični.

00:10:30.253 --> 00:10:33.605
Algoritme možemo ispitati

00:10:33.629 --> 00:10:35.663
i reći će nam istinu svaki put.

00:10:35.667 --> 00:10:38.160
I možemo ih popraviti.
Možemo ih poboljšati.

00:10:38.184 --> 00:10:40.559
To zovem revizijom algoritma

00:10:40.583 --> 00:10:42.262
i ukratko ću vam je objasniti.

00:10:42.286 --> 00:10:44.482
Prvo, provera integriteta podataka.

00:10:45.752 --> 00:10:48.619
Zbog algoritma rizika od recidivizma
o kojem sam govorila,

00:10:49.112 --> 00:10:52.685
provera integriteta podataka
značila bi prihvatanje činjenice

00:10:52.719 --> 00:10:56.245
da u SAD crnci i belci
podjednako puše travu

00:10:56.289 --> 00:10:58.774
ali crnci imaju mnogo više
šanse da budu uhapšeni -

00:10:58.798 --> 00:11:01.982
četiri ili pet puta, zavisi od kraja.

00:11:02.867 --> 00:11:05.763
Kako ta pristrasnost izgleda
u drugim kriminalnim oblastima,

00:11:05.787 --> 00:11:07.238
i kako je uzimamo u obzir?

00:11:07.782 --> 00:11:10.821
Drugo, treba da razmislimo
o definiciji uspeha,

00:11:10.845 --> 00:11:12.226
da je revidiramo.

00:11:12.250 --> 00:11:15.002
Setite se algoritma za zapošljavanje
koji smo spomenuli.

00:11:15.036 --> 00:11:18.201
Osoba koja je tu četiri godine
i unapređena je jednom?

00:11:18.235 --> 00:11:19.694
Pa, to je uspešan zaposleni,

00:11:19.714 --> 00:11:22.793
ali je takođe i zaposleni
u skladu sa njihovom kulturom.

00:11:23.739 --> 00:11:25.355
Tako i to može biti pristrasno.

00:11:25.369 --> 00:11:27.594
Moramo razdvojiti te dve stvari.

00:11:27.628 --> 00:11:31.154
Treba da uzmemo
slepe audicije za orkestar kao primer.

00:11:31.178 --> 00:11:34.114
Tamo ljudi konkurišu su iza zastora.

00:11:34.536 --> 00:11:36.467
Što je meni bitno jeste

00:11:36.501 --> 00:11:40.098
da ljudi koji slušaju
odlučuju šta je bitno

00:11:40.112 --> 00:11:41.631
i odlučuju su šta nije bitno,

00:11:41.635 --> 00:11:43.694
tako da im to ne odvlači pažnju.

00:11:44.561 --> 00:11:47.310
Otkad su počele
slepe audicije za orkestre,

00:11:47.324 --> 00:11:50.768
broj žena u orkestrima
povećao se pet puta.

00:11:51.783 --> 00:11:53.798
Zatim, moramo razmotriti tačnost.

00:11:54.773 --> 00:11:58.507
Tada bi se model dodatne vrednosti
za nastavnike odmah raspao.

00:11:59.058 --> 00:12:01.220
Nema savršenog algoritma, naravno,

00:12:02.130 --> 00:12:05.735
pa moramo razmotriti
greške svakog algoritma.

00:12:06.386 --> 00:12:11.135
Koliko su greške česte
i za koga ovaj model ne funkcioniše?

00:12:11.450 --> 00:12:13.228
Koja je cena te nefunkcionalnosti?

00:12:14.054 --> 00:12:16.261
Na kraju, moramo razmotriti

00:12:17.583 --> 00:12:19.769
dugoročne efekte algoritama,

00:12:20.486 --> 00:12:22.903
njihove povratne kružne sprege
koje se stvaraju.

00:12:23.226 --> 00:12:24.332
Ovo zvuči apstraktno,

00:12:24.356 --> 00:12:27.360
ali zamislite da su Fejsbukovi inženjeri
to uzeli u obzir

00:12:27.820 --> 00:12:32.675
pre odluke da nam prikažu
samo postove naših prijatelja.

00:12:33.291 --> 00:12:36.525
Imam još dve poruke,
jednu za naučnike koji se bave podacima.

00:12:37.060 --> 00:12:40.469
Naučnici za podatke - ne treba
da budemo sudije istine.

00:12:41.060 --> 00:12:44.097
Treba da budemo
prevodioci etičkih rasprava

00:12:44.107 --> 00:12:46.441
koje se odvijaju u širem društvu.

00:12:47.069 --> 00:12:49.312
(Aplauz)

00:12:49.336 --> 00:12:50.892
A za vas ostale,

00:12:51.651 --> 00:12:53.227
koji niste naučnici za podatke:

00:12:53.251 --> 00:12:54.749
ovo nije test iz matematike.

00:12:55.152 --> 00:12:56.500
Ovo je politička borba.

00:12:58.077 --> 00:13:01.984
Od naših algoritamskih vladara
moramo zahtevati odgovornost.

00:13:03.588 --> 00:13:05.087
(Aplauz)

00:13:05.121 --> 00:13:09.336
Doba slepe vere u masovne podatke
mora se okončati.

00:13:09.360 --> 00:13:10.527
Hvala vam mnogo.

00:13:10.541 --> 00:13:12.964
(Aplauz)

