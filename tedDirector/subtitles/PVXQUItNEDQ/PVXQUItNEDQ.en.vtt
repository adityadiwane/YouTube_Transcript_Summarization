WEBVTT
Kind: captions
Language: en

00:00:12.988 --> 00:00:15.304
Let me tell you a story.

00:00:15.304 --> 00:00:17.103
It goes back 200 million years.

00:00:17.103 --> 00:00:19.087
It's a story of the neocortex,

00:00:19.087 --> 00:00:21.061
which means "new rind."

00:00:21.061 --> 00:00:23.492
So in these early mammals,

00:00:23.492 --> 00:00:25.547
because only mammals have a neocortex,

00:00:25.547 --> 00:00:27.211
rodent-like creatures.

00:00:27.211 --> 00:00:30.790
It was the size of a postage stamp and just as thin,

00:00:30.790 --> 00:00:32.229
and was a thin covering around

00:00:32.229 --> 00:00:34.493
their walnut-sized brain,

00:00:34.493 --> 00:00:38.194
but it was capable of a new type of thinking.

00:00:38.194 --> 00:00:39.761
Rather than the fixed behaviors

00:00:39.761 --> 00:00:41.753
that non-mammalian animals have,

00:00:41.753 --> 00:00:44.445
it could invent new behaviors.

00:00:44.445 --> 00:00:46.998
So a mouse is escaping a predator,

00:00:46.998 --> 00:00:48.538
its path is blocked,

00:00:48.538 --> 00:00:50.667
it'll try to invent a new solution.

00:00:50.667 --> 00:00:51.933
That may work, it may not,

00:00:51.933 --> 00:00:53.843
but if it does, it will remember that

00:00:53.843 --> 00:00:55.135
and have a new behavior,

00:00:55.135 --> 00:00:56.592
and that can actually spread virally

00:00:56.592 --> 00:00:58.787
through the rest of the community.

00:00:58.787 --> 00:01:00.396
Another mouse watching this could say,

00:01:00.396 --> 00:01:03.100
"Hey, that was pretty clever, going around that rock,"

00:01:03.100 --> 00:01:06.825
and it could adopt a new behavior as well.

00:01:06.825 --> 00:01:08.542
Non-mammalian animals

00:01:08.542 --> 00:01:10.255
couldn't do any of those things.

00:01:10.255 --> 00:01:11.470
They had fixed behaviors.

00:01:11.470 --> 00:01:12.801
Now they could learn a new behavior

00:01:12.801 --> 00:01:15.377
but not in the course of one lifetime.

00:01:15.377 --> 00:01:17.144
In the course of maybe a thousand lifetimes,

00:01:17.144 --> 00:01:20.474
it could evolve a new fixed behavior.

00:01:20.474 --> 00:01:23.851
That was perfectly okay 200 million years ago.

00:01:23.851 --> 00:01:25.832
The environment changed very slowly.

00:01:25.832 --> 00:01:27.386
It could take 10,000 years for there to be

00:01:27.386 --> 00:01:29.478
a significant environmental change,

00:01:29.478 --> 00:01:30.860
and during that period of time

00:01:30.860 --> 00:01:33.789
it would evolve a new behavior.

00:01:33.789 --> 00:01:35.310
Now that went along fine,

00:01:35.310 --> 00:01:37.014
but then something happened.

00:01:37.014 --> 00:01:39.260
Sixty-five million years ago,

00:01:39.260 --> 00:01:41.875
there was a sudden, violent
change to the environment.

00:01:41.875 --> 00:01:45.380
We call it the Cretaceous extinction event.

00:01:45.380 --> 00:01:47.673
That's when the dinosaurs went extinct,

00:01:47.673 --> 00:01:51.122
that's when 75 percent of the

00:01:51.122 --> 00:01:53.868
animal and plant species went extinct,

00:01:53.868 --> 00:01:55.613
and that's when mammals

00:01:55.613 --> 00:01:57.765
overtook their ecological niche,

00:01:57.765 --> 00:02:01.419
and to anthropomorphize, biological evolution said,

00:02:01.419 --> 00:02:03.444
"Hmm, this neocortex is pretty good stuff,"

00:02:03.444 --> 00:02:05.237
and it began to grow it.

00:02:05.237 --> 00:02:06.579
And mammals got bigger,

00:02:06.579 --> 00:02:09.494
their brains got bigger at an even faster pace,

00:02:09.494 --> 00:02:13.301
and the neocortex got bigger even faster than that

00:02:13.301 --> 00:02:16.230
and developed these distinctive ridges and folds

00:02:16.230 --> 00:02:19.111
basically to increase its surface area.

00:02:19.111 --> 00:02:20.930
If you took the human neocortex

00:02:20.930 --> 00:02:22.231
and stretched it out,

00:02:22.231 --> 00:02:23.944
it's about the size of a table napkin,

00:02:23.944 --> 00:02:25.250
and it's still a thin structure.

00:02:25.250 --> 00:02:27.230
It's about the thickness of a table napkin.

00:02:27.230 --> 00:02:29.727
But it has so many convolutions and ridges

00:02:29.727 --> 00:02:32.802
it's now 80 percent of our brain,

00:02:32.802 --> 00:02:35.263
and that's where we do our thinking,

00:02:35.263 --> 00:02:37.024
and it's the great sublimator.

00:02:37.024 --> 00:02:38.138
We still have that old brain

00:02:38.138 --> 00:02:40.902
that provides our basic drives and motivations,

00:02:40.902 --> 00:02:43.618
but I may have a drive for conquest,

00:02:43.618 --> 00:02:46.333
and that'll be sublimated by the neocortex

00:02:46.333 --> 00:02:49.242
into writing a poem or inventing an app

00:02:49.242 --> 00:02:50.751
or giving a TED Talk,

00:02:50.751 --> 00:02:54.373
and it's really the neocortex that's where

00:02:54.373 --> 00:02:56.341
the action is.

00:02:56.341 --> 00:02:58.058
Fifty years ago, I wrote a paper

00:02:58.058 --> 00:02:59.976
describing how I thought the brain worked,

00:02:59.976 --> 00:03:03.175
and I described it as a series of modules.

00:03:03.175 --> 00:03:05.303
Each module could do things with a pattern.

00:03:05.303 --> 00:03:08.049
It could learn a pattern. It could remember a pattern.

00:03:08.049 --> 00:03:09.456
It could implement a pattern.

00:03:09.456 --> 00:03:12.135
And these modules were organized in hierarchies,

00:03:12.135 --> 00:03:15.089
and we created that hierarchy with our own thinking.

00:03:15.089 --> 00:03:18.422
And there was actually very little to go on

00:03:18.422 --> 00:03:19.984
50 years ago.

00:03:19.984 --> 00:03:22.099
It led me to meet President Johnson.

00:03:22.099 --> 00:03:24.272
I've been thinking about this for 50 years,

00:03:24.272 --> 00:03:27.100
and a year and a half ago I came out with the book

00:03:27.100 --> 00:03:28.365
"How To Create A Mind,"

00:03:28.365 --> 00:03:29.978
which has the same thesis,

00:03:29.978 --> 00:03:32.790
but now there's a plethora of evidence.

00:03:32.790 --> 00:03:34.604
The amount of data we're getting about the brain

00:03:34.604 --> 00:03:36.807
from neuroscience is doubling every year.

00:03:36.807 --> 00:03:39.461
Spatial resolution of brainscanning of all types

00:03:39.461 --> 00:03:41.746
is doubling every year.

00:03:41.746 --> 00:03:43.463
We can now see inside a living brain

00:03:43.463 --> 00:03:46.333
and see individual interneural connections

00:03:46.333 --> 00:03:49.036
connecting in real time, firing in real time.

00:03:49.036 --> 00:03:51.455
We can see your brain create your thoughts.

00:03:51.455 --> 00:03:53.030
We can see your thoughts create your brain,

00:03:53.030 --> 00:03:55.029
which is really key to how it works.

00:03:55.029 --> 00:03:57.248
So let me describe briefly how it works.

00:03:57.248 --> 00:03:59.523
I've actually counted these modules.

00:03:59.523 --> 00:04:01.569
We have about 300 million of them,

00:04:01.569 --> 00:04:03.798
and we create them in these hierarchies.

00:04:03.798 --> 00:04:05.880
I'll give you a simple example.

00:04:05.880 --> 00:04:08.685
I've got a bunch of modules

00:04:08.685 --> 00:04:12.088
that can recognize the crossbar to a capital A,

00:04:12.088 --> 00:04:14.002
and that's all they care about.

00:04:14.002 --> 00:04:15.580
A beautiful song can play,

00:04:15.580 --> 00:04:17.014
a pretty girl could walk by,

00:04:17.014 --> 00:04:19.860
they don't care, but they see
a crossbar to a capital A,

00:04:19.860 --> 00:04:22.881
they get very excited and they say "crossbar,"

00:04:22.881 --> 00:04:24.993
and they put out a high probability

00:04:24.993 --> 00:04:26.627
on their output axon.

00:04:26.627 --> 00:04:27.960
That goes to the next level,

00:04:27.960 --> 00:04:30.710
and these layers are organized in conceptual levels.

00:04:30.710 --> 00:04:32.566
Each is more abstract than the next one,

00:04:32.566 --> 00:04:34.984
so the next one might say "capital A."

00:04:34.984 --> 00:04:37.875
That goes up to a higher
level that might say "Apple."

00:04:37.875 --> 00:04:40.042
Information flows down also.

00:04:40.042 --> 00:04:42.978
If the apple recognizer has seen A-P-P-L,

00:04:42.978 --> 00:04:46.197
it'll think to itself, "Hmm, I
think an E is probably likely,"

00:04:46.197 --> 00:04:48.761
and it'll send a signal down to all the E recognizers

00:04:48.761 --> 00:04:50.380
saying, "Be on the lookout for an E,

00:04:50.380 --> 00:04:51.936
I think one might be coming."

00:04:51.936 --> 00:04:54.779
The E recognizers will lower their threshold

00:04:54.779 --> 00:04:56.724
and they see some sloppy
thing, could be an E.

00:04:56.724 --> 00:04:58.214
Ordinarily you wouldn't think so,

00:04:58.214 --> 00:05:00.223
but we're expecting an E, it's good enough,

00:05:00.223 --> 00:05:02.040
and yeah, I've seen an E, and then apple says,

00:05:02.040 --> 00:05:03.768
"Yeah, I've seen an Apple."

00:05:03.768 --> 00:05:05.514
Go up another five levels,

00:05:05.514 --> 00:05:06.867
and you're now at a pretty high level

00:05:06.867 --> 00:05:08.436
of this hierarchy,

00:05:08.436 --> 00:05:10.789
and stretch down into the different senses,

00:05:10.789 --> 00:05:13.444
and you may have a module
that sees a certain fabric,

00:05:13.444 --> 00:05:16.288
hears a certain voice quality,
smells a certain perfume,

00:05:16.288 --> 00:05:18.801
and will say, "My wife has entered the room."

00:05:18.801 --> 00:05:20.696
Go up another 10 levels, and now you're at

00:05:20.696 --> 00:05:21.856
a very high level.

00:05:21.856 --> 00:05:23.793
You're probably in the frontal cortex,

00:05:23.793 --> 00:05:27.560
and you'll have modules that say, "That was ironic.

00:05:27.560 --> 00:05:29.930
That's funny. She's pretty."

00:05:29.930 --> 00:05:32.035
You might think that those are more sophisticated,

00:05:32.035 --> 00:05:33.541
but actually what's more complicated

00:05:33.541 --> 00:05:36.210
is the hierarchy beneath them.

00:05:36.210 --> 00:05:38.830
There was a 16-year-old girl, she had brain surgery,

00:05:38.830 --> 00:05:40.881
and she was conscious because the surgeons

00:05:40.881 --> 00:05:42.418
wanted to talk to her.

00:05:42.418 --> 00:05:44.240
You can do that because there's no pain receptors

00:05:44.240 --> 00:05:45.278
in the brain.

00:05:45.278 --> 00:05:47.078
And whenever they stimulated particular,

00:05:47.078 --> 00:05:49.541
very small points on her neocortex,

00:05:49.541 --> 00:05:52.206
shown here in red, she would laugh.

00:05:52.206 --> 00:05:53.646
So at first they thought they were triggering

00:05:53.646 --> 00:05:55.366
some kind of laugh reflex,

00:05:55.366 --> 00:05:57.885
but no, they quickly realized they had found

00:05:57.885 --> 00:06:00.929
the points in her neocortex that detect humor,

00:06:00.929 --> 00:06:02.898
and she just found everything hilarious

00:06:02.898 --> 00:06:05.335
whenever they stimulated these points.

00:06:05.335 --> 00:06:07.260
"You guys are so funny just standing around,"

00:06:07.260 --> 00:06:08.998
was the typical comment,

00:06:08.998 --> 00:06:11.300
and they weren't funny,

00:06:11.300 --> 00:06:14.547
not while doing surgery.

00:06:14.547 --> 00:06:19.377
So how are we doing today?

00:06:19.377 --> 00:06:22.431
Well, computers are actually beginning to master

00:06:22.431 --> 00:06:24.432
human language with techniques

00:06:24.432 --> 00:06:27.299
that are similar to the neocortex.

00:06:27.299 --> 00:06:28.813
I actually described the algorithm,

00:06:28.813 --> 00:06:30.867
which is similar to something called

00:06:30.867 --> 00:06:33.100
a hierarchical hidden Markov model,

00:06:33.100 --> 00:06:36.341
something I've worked on since the '90s.

00:06:36.341 --> 00:06:39.579
"Jeopardy" is a very broad natural language game,

00:06:39.579 --> 00:06:41.471
and Watson got a higher score

00:06:41.471 --> 00:06:43.471
than the best two players combined.

00:06:43.471 --> 00:06:45.970
It got this query correct:

00:06:45.970 --> 00:06:48.055
"A long, tiresome speech

00:06:48.055 --> 00:06:50.207
delivered by a frothy pie topping,"

00:06:50.207 --> 00:06:53.003
and it quickly responded,
"What is a meringue harangue?"

00:06:53.003 --> 00:06:55.638
And Jennings and the other guy didn't get that.

00:06:55.638 --> 00:06:57.564
It's a pretty sophisticated example of

00:06:57.564 --> 00:06:59.478
computers actually understanding human language,

00:06:59.478 --> 00:07:01.130
and it actually got its knowledge by reading

00:07:01.130 --> 00:07:04.915
Wikipedia and several other encyclopedias.

00:07:04.915 --> 00:07:07.048
Five to 10 years from now,

00:07:07.048 --> 00:07:09.232
search engines will actually be based on

00:07:09.232 --> 00:07:12.026
not just looking for combinations of words and links

00:07:12.026 --> 00:07:13.940
but actually understanding,

00:07:13.940 --> 00:07:16.351
reading for understanding the billions of pages

00:07:16.351 --> 00:07:19.084
on the web and in books.

00:07:19.084 --> 00:07:21.700
So you'll be walking along, and Google will pop up

00:07:21.700 --> 00:07:24.781
and say, "You know, Mary, you expressed concern

00:07:24.781 --> 00:07:27.800
to me a month ago that your glutathione supplement

00:07:27.800 --> 00:07:30.031
wasn't getting past the blood-brain barrier.

00:07:30.031 --> 00:07:32.624
Well, new research just came out 13 seconds ago

00:07:32.624 --> 00:07:34.335
that shows a whole new approach to that

00:07:34.335 --> 00:07:36.328
and a new way to take glutathione.

00:07:36.328 --> 00:07:38.890
Let me summarize it for you."

00:07:38.890 --> 00:07:42.574
Twenty years from now, we'll have nanobots,

00:07:42.574 --> 00:07:44.201
because another exponential trend

00:07:44.201 --> 00:07:45.816
is the shrinking of technology.

00:07:45.816 --> 00:07:48.186
They'll go into our brain

00:07:48.186 --> 00:07:49.889
through the capillaries

00:07:49.889 --> 00:07:52.366
and basically connect our neocortex

00:07:52.366 --> 00:07:55.551
to a synthetic neocortex in the cloud

00:07:55.551 --> 00:07:59.142
providing an extension of our neocortex.

00:07:59.142 --> 00:08:00.720
Now today, I mean,

00:08:00.720 --> 00:08:02.250
you have a computer in your phone,

00:08:02.250 --> 00:08:05.004
but if you need 10,000 computers for a few seconds

00:08:05.004 --> 00:08:06.499
to do a complex search,

00:08:06.499 --> 00:08:09.895
you can access that for a second or two in the cloud.

00:08:09.895 --> 00:08:12.990
In the 2030s, if you need some extra neocortex,

00:08:12.990 --> 00:08:15.263
you'll be able to connect to that in the cloud

00:08:15.263 --> 00:08:16.911
directly from your brain.

00:08:16.911 --> 00:08:18.454
So I'm walking along and I say,

00:08:18.454 --> 00:08:19.817
"Oh, there's Chris Anderson.

00:08:19.817 --> 00:08:21.342
He's coming my way.

00:08:21.342 --> 00:08:23.677
I'd better think of something clever to say.

00:08:23.677 --> 00:08:25.201
I've got three seconds.

00:08:25.201 --> 00:08:28.298
My 300 million modules in my neocortex

00:08:28.298 --> 00:08:29.538
isn't going to cut it.

00:08:29.538 --> 00:08:30.784
I need a billion more."

00:08:30.784 --> 00:08:34.107
I'll be able to access that in the cloud.

00:08:34.107 --> 00:08:36.919
And our thinking, then, will be a hybrid

00:08:36.919 --> 00:08:40.441
of biological and non-biological thinking,

00:08:40.441 --> 00:08:42.339
but the non-biological portion

00:08:42.339 --> 00:08:45.021
is subject to my law of accelerating returns.

00:08:45.021 --> 00:08:47.260
It will grow exponentially.

00:08:47.260 --> 00:08:49.276
And remember what happens

00:08:49.276 --> 00:08:51.921
the last time we expanded our neocortex?

00:08:51.921 --> 00:08:53.347
That was two million years ago

00:08:53.347 --> 00:08:54.583
when we became humanoids

00:08:54.583 --> 00:08:56.177
and developed these large foreheads.

00:08:56.177 --> 00:08:58.760
Other primates have a slanted brow.

00:08:58.760 --> 00:09:00.505
They don't have the frontal cortex.

00:09:00.505 --> 00:09:04.190
But the frontal cortex is not
really qualitatively different.

00:09:04.190 --> 00:09:06.933
It's a quantitative expansion of neocortex,

00:09:06.933 --> 00:09:09.636
but that additional quantity of thinking

00:09:09.636 --> 00:09:11.415
was the enabling factor for us to take

00:09:11.415 --> 00:09:14.761
a qualitative leap and invent language

00:09:14.761 --> 00:09:16.728
and art and science and technology

00:09:16.728 --> 00:09:18.182
and TED conferences.

00:09:18.182 --> 00:09:20.313
No other species has done that.

00:09:20.313 --> 00:09:22.388
And so, over the next few decades,

00:09:22.388 --> 00:09:24.148
we're going to do it again.

00:09:24.148 --> 00:09:26.422
We're going to again expand our neocortex,

00:09:26.422 --> 00:09:28.178
only this time we won't be limited

00:09:28.178 --> 00:09:32.458
by a fixed architecture of enclosure.

00:09:32.458 --> 00:09:35.762
It'll be expanded without limit.

00:09:35.762 --> 00:09:38.005
That additional quantity will again

00:09:38.005 --> 00:09:41.010
be the enabling factor for another qualitative leap

00:09:41.010 --> 00:09:42.645
in culture and technology.

00:09:42.645 --> 00:09:44.699
Thank you very much.

00:09:44.699 --> 00:09:47.785
(Applause)

