WEBVTT
Kind: captions
Language: ka

00:00:00.000 --> 00:00:07.000
Translator: Levan Lashauri
Reviewer: Tamta Makharadze

00:00:13.000 --> 00:00:15.216
ვაპირებ იმ ინტუიციურ სისუსტეზე ვისაუბრო,

00:00:15.240 --> 00:00:17.290
რომელიც ბევრ ჩვენგანს ახასიათებს.

00:00:17.480 --> 00:00:20.860
ეს გარკვეული საფრთხის ამოცნობის უუნარობაა.

00:00:21.360 --> 00:00:23.096
ვაპირებ აღვწერო სცენარი,

00:00:23.120 --> 00:00:26.376
რომელიც ერთდროულად შემაძრწუნებელიცაა

00:00:26.400 --> 00:00:28.210
და მოსალოდნელიც.

00:00:28.840 --> 00:00:30.496
რაც, როგორც ირკვევა

00:00:30.520 --> 00:00:32.056
არაა კარგი კომბინაცია.

00:00:32.080 --> 00:00:34.536
მიუხედავად ამისა,
საშიშის ნაცვლად უმეტესობა

00:00:34.560 --> 00:00:37.050
სახალისოდ აღიქვამს იმას,
რაზეც ვაპირებ ვისაუბრო.

00:00:37.200 --> 00:00:40.176
ვაპირებ აღვწერო, თუ როგორ შეიძლება

00:00:40.200 --> 00:00:41.976
ხელოვნური ინტელექტის სფეროში წინსვლამ

00:00:42.000 --> 00:00:43.776
საბოლოოდ გაგვანადგუროს.

00:00:43.800 --> 00:00:46.270
პრინციპში, ვფიქრობ,
ძნელი წარმოსადგენიც კია,

00:00:46.270 --> 00:00:49.610
როგორ შეიძლება არ გაგვანადგუროს,
ან არ გვიბიძგოს თვითგანადგურებისკენ.

00:00:49.610 --> 00:00:51.256
თუმცა, თუ თქვენც ჩემნაირი ხართ,

00:00:51.280 --> 00:00:53.936
გეგონებათ, რომ ასეთ რამეებზე
ფიქრი სახალისოა.

00:00:53.960 --> 00:00:57.336
თავად ასეთი რეაქციაც პრობლემის ნაწილია.

00:00:57.360 --> 00:00:59.560
ამ რეაქციამ უნდა შეგაწუხოთ.

00:00:59.920 --> 00:01:02.576
ახლა, ამ საუბარში, თუ დაგაწრმუნებთ,

00:01:02.600 --> 00:01:06.016
რომ კლიმატის ცვლილებით,
ან სხვა რამე კატასტროფით გამოწვეული

00:01:06.040 --> 00:01:09.096
გლობალური შიმშილობაა მოსალონდელი

00:01:09.120 --> 00:01:12.536
და რომ თქვენმა შვილიშვილებმა,
ან მათმა შვილიშვილებმა

00:01:12.560 --> 00:01:14.820
დიდი შანსია ამ პირობებში იცხოვრონ,

00:01:15.200 --> 00:01:16.400
თქვენ არ იფიქრებთ:

00:01:17.440 --> 00:01:18.776
"საინტერესოა,

00:01:18.800 --> 00:01:20.580
მომწონს ეს TED talk-ი"

00:01:21.200 --> 00:01:23.410
შიმშილობა არაა სახალისო.

00:01:23.800 --> 00:01:27.236
სამეცნიერო ფანტასტიკის ხელით სიკვდილი
კი სახალისოა.

00:01:27.236 --> 00:01:31.316
ერთ-ერთი, რაც ხელოვნური ინტელექტის
შექმნასთან დაკავშირებით მაწუხებს ისაა,

00:01:31.316 --> 00:01:35.296
რომ ჩვენ თითქოს არ შეგვწევს უნარი
გვქონდეს ადექვატური ემოციური რეაქცია

00:01:35.320 --> 00:01:37.136
მოსალოდნელ საფრთხეებზე.

00:01:37.160 --> 00:01:41.270
არც მე ძალმიძს ამ რეაქიის გამომუშავება,
თუმცა ამ თემაზე გამოვდივარ.

00:01:42.120 --> 00:01:44.816
თითქოს ორი კარის წინ ვდგავართ.

00:01:44.840 --> 00:01:46.096
პირველ კარს მიღმა,

00:01:46.120 --> 00:01:49.416
ხელოვნური ინტელექტის განვითარების
პროგრესი ჩერდება.

00:01:49.440 --> 00:01:53.456
ჩვენი კოპიუტერების აპარატული და პროგრამული
საშუალებები რატომღაც აღარ უმჯობესდება.

00:01:53.480 --> 00:01:56.850
ერთი წამით დაფიქრდით,
რატომ შეიძლება ეს მოხდეს.

00:01:57.080 --> 00:02:00.736
იმის გათვალისწინებით, თუ რა ფასეულია
მანქანური ინტელექტი და ავტომატიზაცია,

00:02:00.760 --> 00:02:04.800
ჩვენ აუცილებლად განვაგრძობთ
ტექნოლოგიურ წინსვლას, თუ შეგვეძლება.

00:02:05.200 --> 00:02:07.567
რამ შეიძლება ეს შეაჩეროს?

00:02:07.800 --> 00:02:10.450
სრულმასშტაბიანმა ბირთვულმა ომმა?

00:02:11.000 --> 00:02:13.340
გლობალურმა პანდემიამ?

00:02:14.320 --> 00:02:16.880
ასტეროიდის დაჯახებამ?

00:02:17.640 --> 00:02:20.216
ჯასტინ ბიბერის პრეზიდენტობამ?

00:02:20.240 --> 00:02:22.520
(სიცილი)

00:02:24.760 --> 00:02:28.680
მოკლედ, რაღაც ისეთი უნდა იყოს,
რაც არსებულ ცივილიზაციას დაანგრევს.

00:02:29.360 --> 00:02:33.656
წარმოიდგინეთ, რა ცუდი რამ უნდა იყოს,

00:02:33.680 --> 00:02:37.016
რომ ტექნოლოგიური პროგრესი შეაჩეროს

00:02:37.040 --> 00:02:38.256
სამუდამოდ,

00:02:38.280 --> 00:02:39.910
თაობიდან თაობამდე.

00:02:39.950 --> 00:02:42.380
განმარტებიდან გამომდინარე,
ეს ყველაზე უარესი რამეა,

00:02:42.380 --> 00:02:44.576
რაც კი ოდესმე მომხდარა
კაცობრიობის ისტორიაში.

00:02:44.576 --> 00:02:45.936
ამის ერთადერთი ალტერნატივა,

00:02:45.936 --> 00:02:48.176
რომელიც მეორე კარს მიღმაა,
არის რეალობა,

00:02:48.200 --> 00:02:51.336
რომლის მიხედვით ჩვენ ვაგძელებთ
გონიერი მანქანების გაუმჯობესებას

00:02:51.360 --> 00:02:53.350
წლიდან წლამდე.

00:02:53.720 --> 00:02:57.520
რაღაც მომენტში, ჩვენ შევქმნით მანქანებს,
რომლებიც ჩვენზე ჭკვიანები იქნებიან

00:02:57.790 --> 00:03:00.340
და რა დროსაც ეს მოხდება,

00:03:00.340 --> 00:03:02.696
ისინი საკუთარი თავების
გაუმჯობესებას შეუდგებიან

00:03:02.720 --> 00:03:05.100
და დავდგებით, როგორც ამას
ი. დ. გუდმა უწოდა,

00:03:05.100 --> 00:03:07.256
"ინტელექტის აფეთქების" საფრთხის წინაშე,

00:03:07.280 --> 00:03:09.920
რითიც შეიძლება
პროცესები ხელიდან გაგვექცეს.

00:03:10.120 --> 00:03:12.936
ხშირად ეს მსგავსი კარიკატურების
სახითაა გამოსახული.

00:03:12.960 --> 00:03:16.176
როგორც ბოროტი რობოტების არმიები,

00:03:16.200 --> 00:03:17.456
რომლებიც თავს გვესხმიან,

00:03:17.480 --> 00:03:20.176
მაგრამ ეს არაა ყველაზე სავარაუდო სცენარი.

00:03:20.200 --> 00:03:24.480
ჩვენი მანქანები,
მყისიერად კი არ გაბოროტდებიან.

00:03:24.480 --> 00:03:27.600
სინამდვილეში წუხილი იმაზეა,
რომ ჩვენ ისეთ მანქანებს შევქმნით,

00:03:27.600 --> 00:03:30.276
რომლებიც ჩვენზე იმდენად უფრო
კომპეტენტურები იქნებიან,

00:03:30.276 --> 00:03:33.576
რომ ჩვენსა და მათ მიზნებს შორის
მცირედმა უთანხმოებამაც კი

00:03:33.600 --> 00:03:35.520
შეიძლება გაგვანადგუროს.

00:03:35.960 --> 00:03:38.380
დაფიქრდით, რა აზრის ვართ ჭიანჭველებზე.

00:03:38.600 --> 00:03:40.256
ჩვენ ისინი არ გვძულს.

00:03:40.280 --> 00:03:42.336
ჩვენ მიზანი არაა მათ ვავნოთ.

00:03:42.360 --> 00:03:44.736
პრინციპში ზოგჯერ ვცდილობთ კიდეც არ ვავნოთ.

00:03:44.760 --> 00:03:46.776
ფეხს არ ვადგამთ ტროტუარზე.

00:03:46.800 --> 00:03:48.936
მაგრამ როცა კი მათი არსებობა,

00:03:48.960 --> 00:03:51.456
ჩვენს მიზნებს სერიოზულად ეწინააღმდეგება,

00:03:51.480 --> 00:03:53.957
მაგალითად ამნაირი შენობის აგებისას,

00:03:53.981 --> 00:03:56.241
ჩვენ ყოყმანის გარეშე ვანადგურებთ მათ.

00:03:56.480 --> 00:03:59.416
მე ის მაწუხებს,
რომ ერთ დღესაც ჩვენ შევქმნით მანქანებს,

00:03:59.440 --> 00:04:02.176
რომელებიც, ცნობიერები იქნებიან თუ არა,

00:04:02.200 --> 00:04:05.180
შეიძლება მსგავსი გულგრილობით მოგვეკიდონ.

00:04:05.760 --> 00:04:09.290
ეჭვი მაქვს ბევრ თქვენგანს,
ეს ზედმეტ გაზვიადებად ეჩვენება.

00:04:09.360 --> 00:04:13.940
დარმწუნებული ვარ ზოგი თქვენგანი,
ზეგონიერი ხელოვნური ინტელექტის შექმნის

00:04:13.940 --> 00:04:17.376
არათუ გარდაუვალობას, არამედ
შესაძლებლობასაც კი ეჭვქვეშ აყენებს,

00:04:17.400 --> 00:04:21.020
მაგრამ მაშინ თქვენ პრობლემა უნდა იპოვოთ
შემდეგი დაშვებებიდან ერთ-ერთში.

00:04:21.044 --> 00:04:23.066
სულ სამია ასეთი.

00:04:23.800 --> 00:04:28.979
ინტელექტი ფიზიკურ სისტემებში
ინფორმაციის დამუშავებას წარმოადგენს.

00:04:29.320 --> 00:04:31.935
პრინციპში, ეს დაშვებაზე ცოტა უფრო მეტიცაა.

00:04:31.959 --> 00:04:35.416
ჩვენ უკვე შევქმენით მანქანები
ვიწრო ინტელექტით

00:04:35.440 --> 00:04:37.456
და ბევრი მათქგანი მუშაობს კიდეც

00:04:37.480 --> 00:04:40.520
ზეადამიანის შესაბამისი ინტელექტის დონეზე.

00:04:40.840 --> 00:04:43.416
ასევე ვიცით, რომ მატერიას

00:04:43.440 --> 00:04:46.056
შეუძლია წამოქმნას ე.წ. "ზოგადი ინტელექტი",

00:04:46.080 --> 00:04:49.736
სხვადასხვა სფეროებაში
მოქნილად აზროვნების უნარი,

00:04:49.760 --> 00:04:52.896
რადგან ჩვენი ტვინები ახერხებენ ამას.

00:04:52.920 --> 00:04:56.856
აქ ხომ მხოლოდ ატომებია

00:04:56.880 --> 00:05:01.376
და თუ ატომებისგან შემდგარი
ისეთი სისტემების შექმნას განვაგრძობთ,

00:05:01.400 --> 00:05:04.096
რომლებიც სულ უფრო მეტ
გონიერ საქციელს გამოავლენენ,

00:05:04.120 --> 00:05:06.656
რაღაცამ თუ არ შეგვაჩერა,

00:05:06.680 --> 00:05:10.056
საბოლოოდ ზოგადი ინტელექტის მქონე

00:05:10.080 --> 00:05:11.376
მანქანებს შევქმნით.

00:05:11.400 --> 00:05:15.056
მნიშვნელოვანია გავიაზროთ,
რომ პროგრესის ტემპს არ აქვს მნიშვნელობა,

00:05:15.080 --> 00:05:18.256
რადგან ნებისმიერი ტემპი საკმარისია,
რომ ბოლოში გავიდეთ.

00:05:18.280 --> 00:05:22.246
ჩვენ არ გვჭირდება მურის კანონი ამისთვის.
არ გვჭირდება ექსპონენციალური პროგრესი.

00:05:22.246 --> 00:05:25.140
ჩვენ მხოლოდ წინსვლა გვჭირდება.

00:05:25.480 --> 00:05:28.850
მეორე დაშვება ისაა,
რომ ჩვენ განვაგრძობთ პროგრესს.

00:05:29.000 --> 00:05:32.470
განვაგრძობთ გონიერი მანქანების შექმნას.

00:05:33.000 --> 00:05:37.376
თუ ინტელექტის ფასს გავითვალისწინებთ...

00:05:37.400 --> 00:05:40.430
ინტელექტი, ან ყველაფერ იმის წყაროა
რასაც ვაფასებთ,

00:05:40.430 --> 00:05:43.736
ან გვჭირდება იმისთვის, რომ დავიცვათ
ყველაფერი ის რასაც ვაფასებთ.

00:05:43.760 --> 00:05:46.016
ის ჩვენი ყველაზე ფასეული რესურსია.

00:05:46.040 --> 00:05:47.576
ამიტომ გვინდა ამის კეთება.

00:05:47.600 --> 00:05:50.936
ჩვენ გვაქვს პრობლემები,
რომელთა გადაწყვეტა აუცილებელია.

00:05:50.960 --> 00:05:54.620
ჩვენ გვინდა ალცჰაიმერის და კიბოს მაგვარი
დაავადებების განკურნება.

00:05:54.960 --> 00:05:58.896
გვინდა ეკონომიკური სისტემებში გარკვევა.
და კლიმატური მეცნიერების გაუმჯობესება.

00:05:58.920 --> 00:06:01.176
ამიტომ თუ შევძელით,
ამას აუცილებლად ვიზამთ.

00:06:01.200 --> 00:06:05.496
მატარებელი უკვე დაიძრა
და მას მუხრუჭი არ აქვს.

00:06:05.880 --> 00:06:11.336
ბოლოს, ჩვენ არ წარმოვადგენთ
ინტელექტის პიკს.

00:06:11.360 --> 00:06:13.500
მასთან ახლოსაც კი არ ვართ.

00:06:13.640 --> 00:06:15.536
ეს მართლაც საკვანძო აზრია.

00:06:15.560 --> 00:06:18.296
ეს არის ის, რაც ჩვენს მდგომარეობას
ასე არასაიმედოს

00:06:18.296 --> 00:06:22.980
და რისკების მიმართ
ჩვენს ინტუიციას, ასე არასანდოს ხდის.

00:06:23.120 --> 00:06:26.280
განვიხილოთ ყველა დროის
უჭკვიანესი ადამიანი.

00:06:26.640 --> 00:06:30.056
ერთ-ერთ ასეთად თითქმის ყველა
ჯონ ვან ნოიმანს დაასახელებს.

00:06:30.080 --> 00:06:33.416
შთაბეჭდილება, რომელიც ვან ნოიმანმა
მის გარშემომყოფებზე მოახდინა,

00:06:33.440 --> 00:06:37.496
მისი თანამედროვე უდედესი მათემატიკოსების
და ფიზიკოსების ჩათვლით,

00:06:37.520 --> 00:06:39.456
კარგადაა დოკუმენტირებული.

00:06:39.480 --> 00:06:43.256
ამ ისტორიების მხოლოდ ნახევარიც
რომ იყოს ნახევრად მართალი,

00:06:43.280 --> 00:06:44.496
ეჭვგარეშეა,

00:06:44.520 --> 00:06:46.976
რომ ის ყველა დროის ერთ-ერთი
უჭკვიანესი ადამიანი იყო.

00:06:47.000 --> 00:06:49.830
განვიხილოთ ინტელექტის სპექტრი.

00:06:50.320 --> 00:06:52.599
აქ არის ჯონ ვან ნოიმანი.

00:06:53.560 --> 00:06:55.474
აქ კი, ვართ მე და თქვენ

00:06:56.050 --> 00:06:57.416
და აქ კი - ქათამია.

00:06:57.440 --> 00:06:59.376
(სიცილი)

00:06:59.400 --> 00:07:00.616
უკაცრავად, ქათამი.

00:07:00.640 --> 00:07:01.896
(სიცილი)

00:07:01.920 --> 00:07:05.656
საჭირო არაა ეს საუბარი,
კიდევ უფრო დეპრესიული გავხადოთ.

00:07:05.680 --> 00:07:07.280
(სიცილი)

00:07:08.339 --> 00:07:11.816
დიდად სავარაუდოა,
რომ ინტელექტის სპექტრი,

00:07:11.840 --> 00:07:14.960
ბევრად უფრო შორს მიდის,
ვიდრე ჩვენ ამჟამად წარმოგვიდგენია

00:07:15.880 --> 00:07:19.096
და თუ ჩვენ შევქმნით მანქანებს,
რომლებსაც ჩვენზე დიდი ინტელექტი აქვთ,

00:07:19.120 --> 00:07:21.070
დიდი ალბათობით ისინი ამ სპექტრის

00:07:21.070 --> 00:07:23.296
ჩვენთვის წარმოუდგენელ სივრცეებს აითვისებენ

00:07:23.320 --> 00:07:26.590
და ისე გვაჯობებენ,
რომ ვერც კი წარმოვიდგენთ.

00:07:27.000 --> 00:07:31.336
მნიშვნელოვანია ვხვდებოდეთ, რომ ეს ასეა
მხოლოდ სისწრაფის შემთხვევაშიც კი.

00:07:31.360 --> 00:07:36.416
წარმოიდგინეთ, რომ შევქმენით
ზეგონიერი ხელოვნური ინტელექტი,

00:07:36.440 --> 00:07:39.896
რომელიც სტენფორდის, ან MIT-ის

00:07:39.920 --> 00:07:42.216
საშუალო დონის მკვლევართა ჯგუფზე
ჭკვიანი არაა.

00:07:42.240 --> 00:07:45.576
ელექტრონული სქემები დაახლოებით
მილიონჯერ უფრო სწრაფად ფუნქციონირებენ,

00:07:45.576 --> 00:07:46.496
ვიდრე ბიოქიმიური.

00:07:46.520 --> 00:07:49.656
ამიტომ ეს მანქანა იაზროვნებს
დაახლოებით მილიონჯერ სწრაფად,

00:07:49.680 --> 00:07:51.496
ვიდრე ტვინები რომლებმაც ის შექმნეს.

00:07:51.520 --> 00:07:53.176
თუ მას ერთი კვირა ვამუშვებთ,

00:07:53.200 --> 00:07:58.160
ის შეასრულებს ადამიანის დონის
20 000 წლის ინტელეტქუალურ სამუშაოს

00:07:58.400 --> 00:08:00.360
კვირიდან კვირამდე.

00:08:01.130 --> 00:08:05.356
ამის შემდეგ, არათუ როგორ შევზღუდავთ,
არამედ როგორ გავუგებთ ტვინს,

00:08:05.356 --> 00:08:08.450
რომელიც ასე პროგრესირებს?

00:08:08.840 --> 00:08:12.426
კიდევ ერთი რამ,
რაც გულწრფელად მაწუხებს ისაა

00:08:12.426 --> 00:08:15.330
რომ საუკეთესო ვარიანტში,

00:08:15.330 --> 00:08:20.176
წარმოიდგინეთ დავაპროექტეთ ისეთი
ზეგონიერი ხელოვნური ინტელექტი,

00:08:20.200 --> 00:08:22.196
რომელსაც უსაფრთხოების პრობლემა არ აქვს.

00:08:22.196 --> 00:08:24.856
ჩვენ პირველივე ჯერზე
გვაქვს იდეალური პროექტი.

00:08:24.880 --> 00:08:27.096
თითქოს ზეციდან გვებოძა პროექტი,

00:08:27.120 --> 00:08:29.136
რომელიც ისე მუშაობს როგორც ჩავიფიქრეთ.

00:08:29.160 --> 00:08:32.880
ასეთი მანქანა იდეალური იქნებოდა
შრომის შესამსუბუქებლად.

00:08:33.210 --> 00:08:36.179
მან შეიძლება დააპროექტოს მანქანა,
რომელიც შექმნის მანქანას,

00:08:36.179 --> 00:08:37.300
რომელსაც შეუძლია

00:08:37.300 --> 00:08:39.876
ნებისმიერი ფიზიკური სამუშაოს შესრულება
მზის ენერგიით,

00:08:39.876 --> 00:08:42.096
მეტ-ნაკლებად ნედლეულის ფასად.

00:08:42.120 --> 00:08:45.376
ანუ ლაპარაკია ადამიანის დამქანცველი შრომის
დასასრულზე.

00:08:45.400 --> 00:08:48.810
ლაპარაკია ასევე უმეტესი
ინტელექტულაური შრომის დასასრულზე.

00:08:49.200 --> 00:08:52.256
მაშ, რას გააკეთებენ
ჩვენნაირი პრიმატები ამ სიტუაციაში?

00:08:52.280 --> 00:08:57.160
თავისუფლად შევძლებთ ვითამაშოთ
ფრისბი და მასაჟი ვუკეთოთ ერთმანეთს.

00:08:57.840 --> 00:09:00.696
დავამატოთ ცოტა LSD,
ცოტა უცნაური ტანსაცმელი

00:09:00.720 --> 00:09:03.736
და მთელი მსოფლიო "Burning Man"-ის
ფესტივალს დაემსგავსება.

00:09:03.736 --> 00:09:05.470
(სიცილი)

00:09:06.320 --> 00:09:08.690
ეს შეიძლება მშვენივრად ჟღერდეს,

00:09:09.280 --> 00:09:11.656
მაგრამ ჰკითხეთ საკუთარ თავებს,

00:09:11.680 --> 00:09:14.416
რა მოხდება არსებულ ეკონომიკურ
და პოლიტიკურ წყობაში?

00:09:14.440 --> 00:09:16.856
სავარაუდოა, რომ მივიღოთ

00:09:16.880 --> 00:09:21.016
უთანასწორობის და უმუშევრობის ისეთი დონე,

00:09:21.040 --> 00:09:22.536
როგორიც არასდროს გვინახავს.

00:09:22.560 --> 00:09:25.506
ამ ახალი სიმდიდრის
მთელი კაცობირობის სასარგებლოდ

00:09:25.506 --> 00:09:27.590
გაღების სურვილის არ ქონის პირობებში,

00:09:27.640 --> 00:09:31.406
მილიარდელების მცირე ჯგუფი,
დაამშვენებს ბიზნესჟურნალების გარეკანებს,

00:09:31.406 --> 00:09:34.160
მაშინ როცა დანარჩენები იშიმშილებენ.

00:09:34.320 --> 00:09:36.616
რას იზამენ რუსები, ან ჩინელები,

00:09:36.640 --> 00:09:39.256
თუ გაიგებენ, რომ სილიკონის ველზე
რომელიღაც კომპანია,

00:09:39.280 --> 00:09:42.016
აპირებს ზეგონიერი
ხელოვნური ინტელექტი აამუშაოს?

00:09:42.040 --> 00:09:44.896
ამ მანქანას არნახული ძალით შეეძლება

00:09:44.920 --> 00:09:47.136
აწარმოოს ომი,

00:09:47.160 --> 00:09:49.650
როგორც სახმელეთო, ისე კიბერომი.

00:09:50.120 --> 00:09:52.836
ეს ის სცენარია,
რომელშიც გამარჯვებული იღებს ყველაფერს.

00:09:52.836 --> 00:09:55.606
ამ შეჯიბრში 6 თვით წინ ყოფნა,

00:09:55.606 --> 00:09:59.046
მინიმუმ 500 000 წლით წინ ყოფნას ნიშნავს.

00:09:59.480 --> 00:10:04.216
ამიტომ, ასეთი გარღვევის შესახებ
ჭირებმაც კი,

00:10:04.240 --> 00:10:06.616
შეიძლება გადარიოს ჩვენი სახეობა.

00:10:06.640 --> 00:10:09.536
ერთ-ერთი ყველაზე საშიში რამ,

00:10:09.560 --> 00:10:12.336
ამჟამად, ჩემი აზრით

00:10:12.360 --> 00:10:16.656
არის ის რასაც ხელოვნური ინტელექტის
მკვლევარები ამბობენ,

00:10:16.680 --> 00:10:18.660
როცა უნდათ, რომ იმედი მოგვცენ.

00:10:19.000 --> 00:10:22.456
ყველაზე ხშირად ნათქვამი მიზეზი იმისა,
რომ არ ვიღელვოთ, არის დრო.

00:10:22.480 --> 00:10:24.536
ხომ იცით, იქამდე ჯერ კიდევ შორია.

00:10:24.560 --> 00:10:27.450
სავარაუდოდ სადღაც 50 -100 წელია იქამდე.

00:10:27.720 --> 00:10:28.976
ერთმა მკვლევარმა თქვა:

00:10:29.000 --> 00:10:30.576
"ხელოვნურ ინტელექტზე ნერვიულობა,

00:10:30.600 --> 00:10:33.470
იგივეა რაც ინერვიულოთ
მარსის გადამეტდასახლებულობაზე"

00:10:33.546 --> 00:10:36.126
ეს, "ამაზე ფიქრით ტვინს ნუ დაიღლით "-ის

00:10:36.126 --> 00:10:38.576
სილიკონის ველისეული ვერსიაა

00:10:38.576 --> 00:10:39.496
(სიცილი)

00:10:39.520 --> 00:10:41.416
თითქოს ვერავინ ამჩნევს,

00:10:41.440 --> 00:10:44.056
რომ დროითი ფაქტორის მოყვანა

00:10:44.080 --> 00:10:46.656
სრულიად უადგილოა.

00:10:46.680 --> 00:10:49.936
თუ ინტელექტი მხოლოდ
ინფორმაციის დამუშავების ამბავია

00:10:49.960 --> 00:10:52.616
და ჩვენ განვაგრძობთ
მანქანების გაუმჯობესებას,

00:10:52.640 --> 00:10:56.080
მაშინ მივიღებთ რაღაც ტიპის
სუპერინტელექტს

00:10:56.320 --> 00:10:59.976
და ჩვენ წარმოდგენა არ გვაქვს,
რა დრო დაგვჭირდება იმისთვის,

00:11:00.000 --> 00:11:03.010
რომ მივიღოთ შესაბამისი
უსაფრთხოების ზომები.

00:11:03.670 --> 00:11:05.496
ნება მომეცით, კიდევ გავიმეორო.

00:11:05.520 --> 00:11:09.336
ჩვენ წარმოდგენა არ გვაქვს,
რა დრო დაგვჭირდება იმისთვის,

00:11:09.360 --> 00:11:12.510
რომ მივიღოთ შესაბამისი
უსაფრთხოების ზომები.

00:11:12.920 --> 00:11:16.376
თუ ვერ შეამჩნიეთ, გეტყვით,
რომ ეს ის 50 წელი არ არის, რაც უწინ იყო.

00:11:16.400 --> 00:11:18.856
ეს არის 50 წელი თვეებში.

00:11:18.880 --> 00:11:21.060
ამდენი ხანია რაც აიფონები გვაქვს.

00:11:21.440 --> 00:11:24.500
ამდენი ხანია რაც "სიმფსონები" გადის.

00:11:24.680 --> 00:11:27.056
50 წელი არც ისე დიდი დროა იმისთვის,

00:11:27.080 --> 00:11:31.140
რომ ჩვენი სახეობისთვის
ერთ-ერთ უდიდეს გამოწვევას შევეგებოთ.

00:11:31.640 --> 00:11:35.656
კიდევ ერთხელ, თითქოს არ შეგვწევს უნარი
გვქონდეს ადექვატური ემოციური რეაქცია,

00:11:35.680 --> 00:11:38.376
იმის მიმართ, რაც აშკარად მოსალოდნელია.

00:11:38.400 --> 00:11:42.376
კომპიუტერულმა მეცნიერმა სტიურატ რასელმა
კარგი ანალოგია გააკეთა.

00:11:42.400 --> 00:11:47.296
მან თქვა, წარმოიდგინეთ, რომ უცხოპლანეტელი
ცივილიზაციისგან მივიღეთ გზავნილი,

00:11:47.320 --> 00:11:49.016
რომელიც ამბობს:

00:11:49.040 --> 00:11:50.576
"დედამიწის მოსახლეობავ,

00:11:50.600 --> 00:11:53.500
ჩვენ გეწვევით თქვენ პლანეტაზე
50 წელიწადში.

00:11:53.800 --> 00:11:55.376
მოემზადეთ"

00:11:55.400 --> 00:11:59.656
და ამის შემდეგ თვეების თვლას დავიწყებთ,
სანამ ხომალდი არ ჩამოვა?

00:11:59.680 --> 00:12:03.340
ალბათ, ამაზე ცოტა უფრო მეტ
გადაუდებლობას ვიგრძნობდით.

00:12:03.730 --> 00:12:06.160
კიდევ ერთი მიზეზი,
რასაც დასამშვიდებლად ამბობენ,

00:12:06.160 --> 00:12:09.956
არის რომ ამ მანქანებს ჩვენი ფასეულობების
გაზიარების გარდა სხვა გზა არ ექნებათ,

00:12:10.056 --> 00:12:12.216
რადგან ისინი ჩვენი გაგრძელებები იქნებიან.

00:12:12.240 --> 00:12:14.056
ისინი ჩვენს ტვინს მიუერთდებიან,

00:12:14.080 --> 00:12:17.010
ჩვენ კი მათი ლიმბური სისტემა გავხდებით.

00:12:17.140 --> 00:12:18.536
ერთი წამით დავფიქრდეთ,

00:12:18.560 --> 00:12:21.736
რომ ყველაზე უსაფრთხო
და ერთადერთი წინდახედული,

00:12:21.760 --> 00:12:23.096
რეკომენდებული გზა,

00:12:23.120 --> 00:12:26.350
არის ამ ტექნოლოგიების პირდაპირ
ჩვენ ტვინში ჩანერგვა.

00:12:26.600 --> 00:12:29.976
ეს შეიძლება მართლაც ყველაზე უსაფრთხო
და ერთადერთი წინდახედული გზა იყოს,

00:12:30.000 --> 00:12:33.056
მაგრამ როგორც წესი,
ტექნოლოგიის უსაფრთხოებაზე ზრუნვა,

00:12:33.080 --> 00:12:36.736
მანამ უნდა იყოს დამთავრებული,
სანამ მას თავში შევიტენით.

00:12:36.760 --> 00:12:38.776
(სიცილი)

00:12:38.800 --> 00:12:44.136
უფრო სიღრმისეული პრობლემა ისაა,
რომ ზეგონიერი ხელოვნური ინტელექტის შექმნა,

00:12:44.160 --> 00:12:45.896
თავისთავად უფრო მარტივი ჩანს,

00:12:45.920 --> 00:12:47.090
ვიდრე მისი შექმნა

00:12:47.090 --> 00:12:49.576
და შემდეგ ნეირომეცნიერების სრული შესწავლა,

00:12:49.600 --> 00:12:52.760
რაც საშუალებას მოგვცემს 
მოვახდინოთ ჩვენ ტვინში მისი ინტეგრაცია.

00:12:52.800 --> 00:12:55.976
იმის გათვალისწინებით,
რომ კომპანიები და მთავრობები,

00:12:56.000 --> 00:12:59.656
რომლებიც ამას აკეთებენ,
თავს ყველა დანარჩენთან შეჯიბრში აღიქვამენ

00:12:59.680 --> 00:13:02.936
და რომ ამ შეჯიბრის მოგება,
მსოფლიოს მოგებას ნიშნავს,

00:13:02.960 --> 00:13:05.416
თუ მეორე წამს ამ მსოფლიოს
არ გაანადგურებენ,

00:13:05.440 --> 00:13:08.056
მაშინ სავარაუდოა,
რომ პირველ რიგში იმას გააკეთებენ,

00:13:08.080 --> 00:13:10.260
რისი გაკეთებაც ყველაზე მარტივია.

00:13:10.560 --> 00:13:13.416
სამწუხაროდ მე არ მაქვს
ამ პრობლემაზე პასუხი,

00:13:13.440 --> 00:13:15.970
გარდა რჩევისა, რომ უფრო მეტმა ჩვენგანმა
იფიქროს ამაზე.

00:13:15.970 --> 00:13:18.586
ვფიქრობ, რაღაც "მანჰეტენის პროექტის"
მაგვარი გვჭირდება

00:13:18.586 --> 00:13:20.256
ხელოვნური ინტელექტის მიმართულებით.

00:13:20.256 --> 00:13:23.446
არა იმისთვის, რომ ის შევქმნათ,
რადგან ვფიქრობ ეს გარდაუვლად მოხდება,

00:13:23.446 --> 00:13:26.616
არამედ, რომ გავარკვიოთ, 
თუ როგორ ავიცილოთ თავიდან სამხედრო შეჯიბრი

00:13:26.640 --> 00:13:30.136
და შევქმნათ ეს მანქანა ისე,
რომ ის თანხვედრაში იყოს, ჩვენ ინტერესთან.

00:13:30.160 --> 00:13:32.436
როცა ვლაპარაკობთ ზეგონიერ
ხელოვნურ ინტელექტზე,

00:13:32.436 --> 00:13:34.576
რომელსაც საკუთარი თავის შეცვლა შეუძლია,

00:13:34.600 --> 00:13:39.216
მგონია, რომ ერთი შანსი გვაქვს,
სწორ საწყის პირობებს მივაგნით

00:13:39.240 --> 00:13:41.296
და ამ შემთხვევაშიც დაგვჭირდება,

00:13:41.320 --> 00:13:45.180
რომ ამის პოლიტიკური და ეკონომიკური
შედეგები გადავხარშოთ.

00:13:45.760 --> 00:13:47.816
თუმცა, როგორც კი ვაღიარებთ,

00:13:47.840 --> 00:13:52.290
რომ ინტელექტის წყარო
ინფორმაციის დამუშავებაა,

00:13:52.720 --> 00:13:57.520
რომ რაღაც შესაბამისი გამოთვლითი სისტემა
წარმოდაგენს ინტელექტის ბაზისს,

00:13:58.360 --> 00:14:02.910
ვაღიარებთ, რომ ჩვენ უწყვეტად
გავაუმჯობესებთ ამ სისტემებს

00:14:03.280 --> 00:14:07.736
და ვაღიარებთ, რომ გონებრივი შესაძლებლობის
ჰორიზონტი იმაზე ბევრად უფრო შორს მიდის,

00:14:07.760 --> 00:14:09.900
ვიდრე ჩვენ დღეს წარმოგვიდგენია,

00:14:10.120 --> 00:14:11.336
მაშინ უნდა ვაღიაროთ,

00:14:11.360 --> 00:14:14.560
რომ ჩვენ ვართ რაღაც ტიპის
ღმერთის შექმნის პროცესში.

00:14:14.670 --> 00:14:17.746
ახლა ის დროა, ვიზრუნოთ იმაზე,
რომ ეს ისეთი ღმერთი იყოს,

00:14:17.746 --> 00:14:19.993
რომელთანაც შევძლებთ თანაცხოვრებას.

00:14:20.120 --> 00:14:21.656
დიდი მადლობა.

00:14:21.680 --> 00:14:26.773
(აპლოდისმენტები)

