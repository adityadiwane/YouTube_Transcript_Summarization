WEBVTT
Kind: captions
Language: th

00:00:00.000 --> 00:00:07.000
Translator: yamela areesamarn
Reviewer: Kelwalin Dhanasarnsombut

00:00:13.000 --> 00:00:15.216
ผมจะพูดถึงความล้มเหลว
ของการหยั่งรู้โดยสัญชาตญาณ

00:00:15.240 --> 00:00:16.840
ซึ่งพวกเราหลายคนประสบอยู่

00:00:17.480 --> 00:00:20.520
แท้จริงแล้ว มันเป็นความล้มเหลว
ของการสัมผัสได้ถึงอันตรายบางอย่าง

00:00:21.360 --> 00:00:23.096
ผมกำลังจะอธิบายสถานการณ์หนึ่ง

00:00:23.120 --> 00:00:26.376
ที่ผมคิดว่ามันทั้งน่าสะพรึงกลัว

00:00:26.400 --> 00:00:28.160
และก็น่าจะเกิดขึ้นได้

00:00:28.840 --> 00:00:30.496
และนั่นไม่ใช่ส่วนผสมที่ดีเลย

00:00:30.520 --> 00:00:32.056
ดังที่ปรากฎออกมา

00:00:32.080 --> 00:00:34.536
แต่แทนที่จะกลัว 
ท่านทั้งหลายส่วนใหญ่จะรู้สึกว่า

00:00:34.560 --> 00:00:36.910
สิ่งที่ผมกำลังจะพูดถึงนั้น 
เป็นอะไรที่ดูเจ๋ง

00:00:37.200 --> 00:00:40.176
ผมกำลังจะอธิบายให้ฟังว่า
ผลประโยชน์ที่เราได้รับ

00:00:40.200 --> 00:00:41.976
จากปัญญาประดิษฐ์

00:00:42.000 --> 00:00:43.776
ในที่สุดแล้วอาจทำลายเราได้อย่างไร

00:00:43.800 --> 00:00:46.760
และที่จริง ผมว่ามันยากมาก
ที่จะเข้าใจว่าพวกมันจะไม่ทำลายเรา

00:00:46.760 --> 00:00:49.230
หรือไม่ดลใจให้เรา
ทำลายตัวเองได้อย่างไร

00:00:49.400 --> 00:00:51.256
ถ้าหากว่าคุณเป็นอย่างผม

00:00:51.280 --> 00:00:53.936
คุณจะพบว่ามันสนุกดี
ที่จะคิดถึงเรื่องเหล่านี้

00:00:53.960 --> 00:00:57.336
และการตอบสนองนั้น
ก็เป็นส่วนหนึ่งของปัญหา

00:00:57.360 --> 00:00:59.740
ใช่ไหมครับ การตอบรับนั้น
น่าจะทำให้คุณกังวลใจ

00:00:59.920 --> 00:01:02.576
ถ้าในการบรรยายนี้
ผมต้องการโน้มน้าวคุณให้เชื่อว่า

00:01:02.600 --> 00:01:06.016
เราน่าจะต้องประสบกับความทุกข์ยาก
จากความอดอยากไปทั่วโลก

00:01:06.040 --> 00:01:09.096
ไม่ว่าจะเป็นเพราะการเปลี่ยนแปลง
สภาวะอากาศ หรือหายนะอย่างอื่น

00:01:09.120 --> 00:01:12.536
และลูกหลานของพวกคุณ
หรือของลูกหลานของพวกเขา

00:01:12.560 --> 00:01:14.360
อาจจะต้องมีความเป็นอยู่แบบนี้

00:01:15.200 --> 00:01:16.870
คุณคงจะไม่คิดหรอกว่า

00:01:17.440 --> 00:01:18.776
"น่าสนใจนะ

00:01:18.800 --> 00:01:20.000
ฉันชอบ TED Talk เรื่องนี้"

00:01:21.200 --> 00:01:23.450
ความอดอยากนั้นไม่น่าสนุก

00:01:23.800 --> 00:01:27.176
ในขณะที่ ความตาย
ในนวนิยายวิทยาศาสตร์เป็นเรื่องสนุก

00:01:27.200 --> 00:01:30.760
สิ่งหนึ่งที่ทำให้ผมกังวลที่สุดเกี่ยวกับ
การพัฒนาปัญญาประดิษฐ์ขึ้นมา ณ ตอนนี้

00:01:30.760 --> 00:01:35.296
ก็คือ ดูเหมือนว่าเราไม่สามารถสร้าง
การตอบสนองทางอารมณ์ที่เหมาะสม

00:01:35.320 --> 00:01:37.136
ต่ออันตรายที่อยู่เบื้องหน้าได้

00:01:37.160 --> 00:01:40.890
ผมเองก็ไม่สามารถที่จะปลุกการตอบสนองนี้ได้
ผมจึงต้องมาพูดเรื่องนี้

00:01:42.120 --> 00:01:44.816
มันเหมือนกับว่า 
เรายืนอยู่ข้างหน้าประตูสองบาน

00:01:44.840 --> 00:01:46.096
ด้านหลังประตูหมายเลขหนึ่ง

00:01:46.120 --> 00:01:49.416
เราหยุดที่จะก้าวหน้าต่อไป
ในการสร้างจักรกลที่ชาญฉลาด

00:01:49.440 --> 00:01:53.456
คอมพิวเตอร์ฮาร์ดแวร์และซอฟแวร์
ต่างหยุดพัฒนา ด้วยเหตุผลบางอย่าง

00:01:53.480 --> 00:01:56.850
ลองใช้เวลาสักครู่เพื่อพิจารณานะครับ
ว่าทำไมเรื่องแบบนี้อาจจะเกิดขึ้นได้

00:01:56.850 --> 00:02:00.736
ผมหมายความว่า ด้วยคุณค่าของ
ความฉลาดและความเป็นอัตโนมัตินั้น

00:02:00.760 --> 00:02:04.280
เราจะยังคงพัฒนาเทคโนโลยีของเราต่อไป
หากเรายังสามารถทำได้

00:02:05.200 --> 00:02:07.687
อะไรล่ะจะหยุดเราไม่ไห้ทำสิ่งนี้

00:02:07.800 --> 00:02:09.600
สงครามนิวเคลียร์เต็มรูปแบบหรือ

00:02:11.000 --> 00:02:12.560
โรคที่ระบาดไปทั่วโลกหรือ

00:02:14.320 --> 00:02:16.330
ดาวเคราะห์น้อยมาชนโลกหรือ

00:02:17.640 --> 00:02:20.476
จัสติน บีเบอร์ 
มาเป็นประธานาธิบดีของสหรัฐหรือ

00:02:20.476 --> 00:02:22.520
(เสียงหัวเราะ)

00:02:24.760 --> 00:02:28.680
ประเด็นก็คือ บางสิ่งบางอย่างจะต้อง
มาทำลายอารยธรรมที่เรารู้จัก

00:02:29.360 --> 00:02:33.656
คุณจะต้องจินตนาการเองว่า
มันจะแย่ขนาดไหน

00:02:33.680 --> 00:02:37.016
ที่จะมากีดกันเราจากการ
ปรับปรุงเทคโนโลยีของเราให้ดีขึ้น

00:02:37.040 --> 00:02:38.256
อย่างถาวร

00:02:38.280 --> 00:02:40.296
ที่เกิดขึ้นยุคแล้วยุคเล่า

00:02:40.320 --> 00:02:42.456
เกือบจะเรียกได้ว่า
นี่คือสิ่งเลวร้ายที่สุด

00:02:42.480 --> 00:02:44.496
ที่ได้เคยเกิดขึ้น
ในประวัติศาสตร์มนุษยชาติ

00:02:44.520 --> 00:02:45.816
ฉะนั้นตัวเลือกเดียวที่เหลือ

00:02:45.840 --> 00:02:48.176
และนั่นคือสิ่งที่อยู่ด้านหลัง
ประตูหมายเลขสอง

00:02:48.200 --> 00:02:51.336
ก็คือ เรายังคงปรับปรุงจักรกลที่ฉลาด
ของเรานี้ให้ดีขึ้นต่อไป

00:02:51.360 --> 00:02:53.410
ปีแล้วปีเล่า

00:02:53.720 --> 00:02:57.360
จนเมื่อถึงจุดหนึ่ง
เราก็จะสร้างจักรกลที่ฉลาดกว่าเรา

00:02:58.080 --> 00:03:00.450
และเมื่อเรามีจักรกล
ที่ฉลาดกว่าเราแล้ว

00:03:00.450 --> 00:03:02.660
มันก็จะเริ่มต้นปรับปรุงตัวมันเองให้ดีขึ้น

00:03:02.660 --> 00:03:05.456
แล้วเราก็จะเสี่ยงกับ
สิ่งที่นักคณิตศาสตร์ ไอเจ กูด เรียกว่า

00:03:05.480 --> 00:03:07.256
"การระเบิดของความชาญฉลาด"

00:03:07.280 --> 00:03:09.470
กระบวนการที่ซึ่งมนุษย์
ไม่สามารถควบคุมมันได้

00:03:10.000 --> 00:03:12.936
เรื่องนี้มักจะถูกทำเป็นการ์ตูนล้อเลียน
อย่างที่แสดงให้ดูตรงนี้

00:03:12.960 --> 00:03:16.176
เป็นความกลัวที่ทหารหุ่นยนต์ที่มุ่งร้าย

00:03:16.200 --> 00:03:17.456
จะเข้ามาโจมตีทำร้ายเรา

00:03:17.480 --> 00:03:20.176
แต่นั่นไม่ใช่สถานการณ์
ที่น่าจะเป็นไปได้มากที่สุด

00:03:20.200 --> 00:03:25.056
ไม่ใช่ว่าจักรกลของเรา
จะกลายเป็นภัยอันตรายขึ้นมาเอง

00:03:25.080 --> 00:03:27.696
ความกังวลจริง ๆ ก็คือ 
เราจะสร้างจักรกล

00:03:27.720 --> 00:03:29.776
ที่มีความสามารถที่สูงกว่าเรามาก ๆ

00:03:29.800 --> 00:03:33.576
ที่ความแตกต่างเพียงเล็กน้อยระหว่าง
เป้าหมายของมันกับของเราเอง

00:03:33.600 --> 00:03:34.800
ก็อาจจะทำลายเราได้

00:03:35.960 --> 00:03:38.040
ลองแค่คิดดูว่า 
เรามีสัมพันธ์กับมดอย่างไร

00:03:38.600 --> 00:03:40.256
เราไม่ได้เกลียดพวกมัน

00:03:40.280 --> 00:03:42.336
เราไม่ได้ยอมลำบาก
ใช้ความพยายามไปทำร้ายมัน

00:03:42.360 --> 00:03:44.736
อันที่จริง บางครั้งเราต้องอดกลั้น
ที่จะไม่ทำร้ายมัน

00:03:44.760 --> 00:03:46.776
เราก้าวข้ามพวกมันไปบนทางเดิน

00:03:46.800 --> 00:03:48.936
แต่เมื่อใดก็ตามที่การปรากฏอยู่ของมัน

00:03:48.960 --> 00:03:51.456
ขัดแย้งอย่างรุนแรง
กับเป้าหมายอย่างหนึ่งของเรา

00:03:51.480 --> 00:03:53.957
ยกตัวอย่าง เมื่อก่อสร้างอาคาร 
เช่น อาคารนี้

00:03:53.981 --> 00:03:55.941
เราทำลายล้างพวกมันได้อย่างสบายใจ

00:03:56.480 --> 00:03:59.416
ความวิตกกังวลก็คือสักวันหนึ่ง
เราจะสร้างจักรกล

00:03:59.440 --> 00:04:02.176
ที่ไม่ว่าพวกมันจะมีความคิด
อย่างมีสติหรือไม่ก็ตาม

00:04:02.200 --> 00:04:04.780
จะทำกับเราได้อย่างเฉยเมย
ในแบบเดียวกัน

00:04:05.760 --> 00:04:08.890
ครับ ผมเข้าใจว่า สิ่งนี้ดูจะไกลจากความจริง
สำหรับหลาย ๆ ท่าน

00:04:09.360 --> 00:04:15.350
ผมมั่นใจว่ายังมีคนไม่เชื่อว่า
ปัญญาประดิษฐ์ยอดอัจฉริยะจะเกิดขึ้นได้จริง

00:04:15.350 --> 00:04:17.646
หรือไม่เชื่อว่ามันหลีกเลี่ยงไม่ได้

00:04:17.646 --> 00:04:21.020
แต่คุณจะพบว่ามีบางอย่างที่ไม่ถูกต้อง
ในสมมติฐานเบื้องต้นต่อไปนี้

00:04:21.044 --> 00:04:22.616
ซึ่งก็มีเพียงสามอย่างเท่านั้น

00:04:23.800 --> 00:04:28.519
หนึ่งคือ ความฉลาดเป็นเรื่องของการ
ประมวลข้อมูลในระบบทางกายภาพ

00:04:28.930 --> 00:04:31.899
แต่จริง ๆ แล้ว ข้อนี้มัน
มากกว่าสมมติฐานเบื้องต้นสักหน่อย

00:04:31.899 --> 00:04:35.416
เราใส่ความฉลาดในขอบเขตแคบ ๆ 
ไว้ในจักรกลของเราเรียบร้อยแล้ว

00:04:35.440 --> 00:04:37.456
และจักรกลมากมายเหล่านี้ก็ทำงาน

00:04:37.480 --> 00:04:40.120
ด้วยความฉลาดระดับเหนือมนุษย์อยู่แล้ว

00:04:40.840 --> 00:04:43.416
และเราก็รู้ว่า แค่มีความฉลาดระดับนั้น

00:04:43.440 --> 00:04:46.056
ก็ทำให้เกิดสิ่งที่เรียกว่า
"ความฉลาดทั่วไป"

00:04:46.080 --> 00:04:49.736
ซึ่งเป็นความสามารถที่จะคิด
ได้อย่างยืดหยุ่นในหลาย ๆ ด้าน

00:04:49.760 --> 00:04:52.896
ก็เพราะว่าสมองของเรานั้น 
ก็สามารถทำได้ ใช่ไหมล่ะครับ

00:04:52.920 --> 00:04:56.856
ผมหมายความว่า 
มันก็แค่อะตอมในนี้

00:04:56.880 --> 00:05:01.376
และตราบใดที่เรายังคงสร้าง
ระบบของอะตอม

00:05:01.400 --> 00:05:04.096
ที่แสดงพฤติกรรมชาญฉลาด
มากขึ้นและมากขึ้น

00:05:04.120 --> 00:05:06.656
ในที่สุดถ้าเราไม่ถูกขัดขวาง

00:05:06.680 --> 00:05:10.056
เราก็จะสร้างความฉลาดทั่วไป

00:05:10.080 --> 00:05:11.376
เอาไว้ในจักรกลของเรา

00:05:11.400 --> 00:05:15.056
มันจำเป็นมากที่ต้องตระหนักว่า
อัตราความก้าวหน้านั้นไม่สำคัญ

00:05:15.080 --> 00:05:18.256
เพราะความก้าวหน้าใด ๆ ก็ตาม
ก็เพียงพอที่จะพาเราเข้าสู่ช่วงสุดท้าย

00:05:18.280 --> 00:05:22.056
ไม่จำเป็นต้องดำเนินไปตามกฎของมอร์ 
ไม่จำเป็นต้องก้าวหน้าไปแบบยกกำลัง

00:05:22.080 --> 00:05:24.290
เราแค่ต้องก้าวหน้าต่อไปเรื่อย ๆ
เท่านั้นเอง

00:05:25.480 --> 00:05:28.720
สมมติฐานเบื้องต้นข้อที่สอง 
คือเราจะก้าวหน้าต่อไปเรื่อย ๆ

00:05:29.000 --> 00:05:31.760
เราจะยังคงปรับปรุงจักรกล
ที่ชาญฉลาดของเราต่อไป

00:05:33.000 --> 00:05:37.376
และด้วยคุณค่าของความฉลาด --

00:05:37.400 --> 00:05:40.920
ผมหมายถึงว่า ไม่ว่าความฉลาด
จะเป็นทุก ๆ อย่างที่เราเห็นว่ามีคุณค่า

00:05:40.920 --> 00:05:43.836
หรือเราต้องใช้มันเพื่อปกป้อง
ทุก ๆ อย่างที่เราเห็นว่ามีคุณค่า

00:05:43.836 --> 00:05:46.016
มันก็เป็นสิ่งที่มีคุณค่าที่สุดของเรา

00:05:46.040 --> 00:05:47.576
ฉะนั้น เราจึงต้องการทำสิ่งนี้

00:05:47.600 --> 00:05:50.936
เรามีปัญหา
ที่เราจำเป็นต้องแก้ไขอย่างเร่งด่วน

00:05:50.960 --> 00:05:54.160
เราต้องการรักษาโรค 
อย่างเช่น อัลไซเมอร์และมะเร็ง

00:05:54.960 --> 00:05:58.896
เราต้องการเข้าใจระบบเศรษฐกิจ
เราต้องการปรับปรุงศาสตร์ภูมิอากาศวิทยา

00:05:58.920 --> 00:06:01.176
เราจึงต้องทำสิ่งนี้ 
หากเราสามารถทำได้

00:06:01.200 --> 00:06:04.486
รถไฟได้ออกจากสถานีไปแล้ว
และไม่มีเบรคที่จะดึงมันไว้ได้

00:06:05.880 --> 00:06:11.336
ข้อสุดท้าย เราไม่ได้ยืนอยู่
บนจุดสูงสุดของความฉลาด

00:06:11.360 --> 00:06:13.430
ไม่แม้แต่จะใกล้เคียง

00:06:13.430 --> 00:06:15.516
นี่เป็นความเข้าใจที่สำคัญยิ่ง

00:06:15.516 --> 00:06:17.996
นี่แหละที่ทำให้สถานการณ์ของเรา
ล่อแหลมต่ออันตรายยิ่ง

00:06:18.000 --> 00:06:22.040
และนี่แหละที่ทำให้สัญชาตญาณของเรา
ที่มีต่อความเสี่ยงนั้นเชื่อถือไม่ได้

00:06:23.120 --> 00:06:25.840
ครับ แค่ลองพิจารณา
ถึงคนฉลาดที่สุดที่เคยมีชีวิตอยู่

00:06:26.640 --> 00:06:30.056
สำหรับทุกคนแล้ว หนึ่งในรายชื่อนั้น
ก็คืออ จอห์น วอน นอยแมน

00:06:30.080 --> 00:06:33.416
ผมหมายถึง ความประทับใจของผู้คน
ที่มีต่อ วอน นอยแมน

00:06:33.440 --> 00:06:37.496
และนั่นก็รวมถึงนักคณิตศาสตร์
และนักฟิสิกส์ที่ยิ่งใหญ่ในยุคนั้น

00:06:37.520 --> 00:06:39.456
ได้ถูกบันทีกไว้เป็นอย่างดี

00:06:39.480 --> 00:06:43.256
ถ้าเรื่องราวของเขาสักครึ่งหนึ่งนั้น
จะมีมูลความจริงอยู่ถึงสักครึ่ง

00:06:43.280 --> 00:06:44.496
ก็ไม่ต้องกังขาเลยว่า

00:06:44.520 --> 00:06:46.976
เขาเป็นคนฉลาดที่สุดในโลกคนหนึ่ง

00:06:47.000 --> 00:06:49.520
เมื่อพิจารณาระดับช่วงของความฉลาด

00:06:50.320 --> 00:06:51.749
ตรงนี้เรามี จอห์น วอน นอยแมน

00:06:53.560 --> 00:06:54.894
แล้วเราก็มี คุณและผม

00:06:56.120 --> 00:06:57.416
แล้วต่อมาก็มีไก่

00:06:57.440 --> 00:06:59.376
(เสียงหัวเราะ)

00:06:59.400 --> 00:07:00.616
ขอโทษครับ ไก่

00:07:00.640 --> 00:07:01.896
(เสียงหัวเราะ)

00:07:01.920 --> 00:07:05.656
ไม่มีเหตุผลอะไร ที่ผมจะทำให้
การบรรยายนี้หดหู่ใจมากเกินจำเป็น

00:07:05.680 --> 00:07:07.280
(เสียงหัวเราะ)

00:07:08.339 --> 00:07:11.816
อย่างไรก็ตาม ดูจะเป็นไปได้มาก
ที่ระดับช่วงของความฉลาดนั้น

00:07:11.840 --> 00:07:14.960
ขยายออกไปได้ไกล
มากกว่าที่เราตระหนักในปัจจุบัน

00:07:15.880 --> 00:07:19.096
และถ้าเราสร้างจักรกลที่ฉลาดกว่าเรา

00:07:19.120 --> 00:07:21.416
พวกมันก็น่าจะสำรวจตรวจค้น
ความชาญฉลาดเหล่านี้

00:07:21.440 --> 00:07:23.296
ในแบบที่เราคิดไม่ถึง

00:07:23.320 --> 00:07:25.840
และเหนือกว่าเราในแบบที่เราคิดไม่ถึง

00:07:27.000 --> 00:07:31.336
มันจำเป็นที่เราต้องยอมรับว่า 
สิ่งนี้เป็นจริงไปแล้ว ในเรื่องความเร็ว

00:07:31.360 --> 00:07:36.416
ใช่ไหมครับ ลองคิดดูว่า ถ้าเราแค่สร้าง
ปัญญาประดิษฐ์อัจฉริยะขึ้นมาสักเครื่อง

00:07:36.440 --> 00:07:39.896
ที่ไม่ได้ฉลาดกว่ากลุ่มนักวิจัยทั่ว ๆ ไป

00:07:39.920 --> 00:07:42.216
ที่แสตนฟอร์ดหรือเอ็มไอที

00:07:42.240 --> 00:07:45.216
วงจรไฟฟ้านั้นทำงานได้เร็วกว่าวงจรชีวเคมี

00:07:45.240 --> 00:07:46.496
ประมาณหนึ่งล้านเท่า

00:07:46.520 --> 00:07:49.806
ดังนั้น จักรกลนี้ควรจะคิดได้เร็วกว่า
ปัญญาของมนุษย์ผู้สร้างมันขึ้นมา

00:07:49.806 --> 00:07:51.496
ประมาณหนึ่งล้านเท่า

00:07:51.520 --> 00:07:53.176
เมื่อคุณเดินเครื่องนานหนึ่งสัปดาห์

00:07:53.200 --> 00:07:57.760
มันจะทำงานได้เท่ากับการทำงานโดยใช้
สติปัญญาในระดับของมนุษย์นาน 20,000 ปี

00:07:58.400 --> 00:08:00.360
นานสัปดาห์แล้วสัปดาห์เล่า

00:08:01.640 --> 00:08:05.686
เราจะไปเข้าใจ หรือแม้แต่จำกัดขอบเขต
ของปัญญาประดิษฐ์

00:08:05.686 --> 00:08:07.920
ที่สร้างความก้าวหน้าแบบนี้ได้อย่างไร

00:08:08.840 --> 00:08:10.976
อีกเรื่องหนึ่งที่น่าวิตกกังวล

00:08:11.000 --> 00:08:15.976
คือ ลองจินตนาการถึงสถานการณ์ที่ดีที่สุด

00:08:16.000 --> 00:08:20.090
จินตนาการว่า เราค้นพบการออกแบบ
ปัญญาประดิษฐ์อันชาญฉลาด

00:08:20.090 --> 00:08:21.606
ที่ไม่มีปัญหาเรื่องความปลอดภัย

00:08:21.606 --> 00:08:24.856
เรามีแบบที่สมบูรณ์เป็นครั้งแรก

00:08:24.880 --> 00:08:27.096
ราวกับว่าเราได้รับคำพยากรณ์

00:08:27.120 --> 00:08:29.136
ที่เป็นไปดังใจคิดเป๊ะ

00:08:29.160 --> 00:08:33.300
ครับ จักรกลนี้ก็น่าจะเป็นเครื่องมือ
ที่ประหยัดแรงงานได้อย่างสมบูรณ์แบบ

00:08:33.680 --> 00:08:36.109
มันสามารถออกแบบจักรกล
ที่สามารถสร้างจักรกล

00:08:36.133 --> 00:08:37.896
ซึ่งสามารถทำงานเชิงกายภาพอะไรก็ได้

00:08:37.920 --> 00:08:39.376
ใช้พลังจากแสงอาทิตย์

00:08:39.400 --> 00:08:42.096
โดยมีต้นทุนแค่ค่าวัตถุดิบ

00:08:42.120 --> 00:08:45.376
ดังนั้น เรากำลังพูดกันถึงการสิ้นสุด
ของงานหนักที่น่าเบื่อของมนุษย์

00:08:45.400 --> 00:08:48.530
เรากำลังพูดถึงการจบสิ้นของงาน
ที่ใช้สติปัญญามากที่สุดด้วยเช่นกัน

00:08:49.200 --> 00:08:52.256
แล้วลิงจ๋ออย่างพวกเรานั้น
จะทำอย่างไรในสถานการณ์แบบนี้

00:08:52.280 --> 00:08:56.360
ครับ เราก็ว่างที่จะไปเล่นจานร่อน 
แล้วก็ทำการนวดเฟ้นให้กันและกัน

00:08:57.840 --> 00:09:00.696
เพิ่มการเสพสารแอลเอสดี 
และเสื้อผ้าที่ดูไม่ออกว่าเป็นแนวไหน

00:09:00.720 --> 00:09:02.896
และโลกทั้งใบก็คงกลายเป็น
งานเทศกาล Burning Man

00:09:02.920 --> 00:09:04.560
(เสียงหัวเราะ)

00:09:06.320 --> 00:09:08.320
ครับ นั่นอาจจะฟังดูค่อนข้างจะดี

00:09:09.280 --> 00:09:11.656
แต่ลองถามตัวเองดูว่าจะเกิดอะไรขึ้น

00:09:11.680 --> 00:09:14.416
ภายใต้ระเบียบการเมืองและเศรษฐกิจ
ในปัจจุบันของเรานี้

00:09:14.440 --> 00:09:16.856
ดูเหมือนว่าเราน่าจะได้เห็น

00:09:16.880 --> 00:09:20.980
ความไม่เท่าเทียมของความมั่งคั่ง
และอัตราการว่างงานที่สูง

00:09:20.980 --> 00:09:22.536
อย่างที่เราไม่เคยได้เห็นมาก่อน

00:09:22.560 --> 00:09:25.266
การขาดความเต็มใจ
ที่จะรีบนำความมั่งคั่งที่เกิดขึ้นใหม่นี้

00:09:25.266 --> 00:09:27.200
มารับใช้มนุษยชาติทั้งมวลในทันที

00:09:27.640 --> 00:09:31.256
ทำให้เศรษฐีระดับพันล้านบางราย
อาจเฉิดฉายบนปกนิตยสารธุรกิจ

00:09:31.280 --> 00:09:33.720
ในขณะที่ส่วนอื่น ๆ ของโลก
กำลังอดอยากปากแห้งกัน

00:09:34.320 --> 00:09:36.616
แล้วคนรัสเซียหรือคนจีนจะทำอย่างไร

00:09:36.640 --> 00:09:39.256
หากพวกเขารู้ว่าบางบริษัทในซิลิคอนแวลลีย์

00:09:39.280 --> 00:09:42.016
กำลังจะนำปัญญาประดิษฐ์ที่ชาญฉลาดมาใช้

00:09:42.040 --> 00:09:44.896
จักรกลที่ว่านี้อาจสามารถนำไปใช้
ในการศึกสงครามได้

00:09:44.920 --> 00:09:47.136
ไม่ว่าจะเป็นทางภาคพื้นโลก 
หรือทางอินเทอร์เน็ต

00:09:47.160 --> 00:09:48.840
ด้วยพละกำลังที่ไม่อาจประเมินได้

00:09:50.120 --> 00:09:51.976
นี่คือสถานการณ์แบบผู้ชนะได้ทุกอย่าง

00:09:52.000 --> 00:09:55.136
เพื่อที่จะนำหน้าไปหกเดือน
ในการแข่งขันนี้

00:09:55.160 --> 00:09:57.936
คือการที่เราต้องนำหน้าอยู่ 500,000 ปี

00:09:57.960 --> 00:09:59.456
เป็นอย่างน้อย

00:09:59.480 --> 00:10:04.216
ฉะนั้น จึงเหมือนกับว่า แม้เพียงข่าวลือ
ในเรื่องการค้นพบที่ยิ่งใหญ่แบบนี้

00:10:04.240 --> 00:10:06.736
ก็อาจเป็นเหตุให้ชาติพันธุ์ของเรา
บ้าระห่ำกันขึ้นมาได้

00:10:06.736 --> 00:10:09.536
ครับ สิ่งหนึ่งที่น่าหวาดกลัวที่สุด

00:10:09.560 --> 00:10:12.336
ในความเห็นของผม ในขณะนี้

00:10:12.360 --> 00:10:16.656
คือ สิ่งที่พวกนักวิจัยปัญญาประดิษฐ์พูดกัน

00:10:16.680 --> 00:10:18.770
เมื่อพวกเขาต้องการจะปลอบใจเรา

00:10:19.000 --> 00:10:22.456
และเหตุผลที่ธรรมดาที่สุดที่เขาบอกพวกเรา
ให้ไม่ต้องกังวลก็คือเรื่องเวลา

00:10:22.480 --> 00:10:24.536
เรื่องนี้มันอีกนานนัก ไม่รู้หรอกหรือ

00:10:24.560 --> 00:10:27.000
มันน่าจะเป็นอีก 50 หรือ 100 ปี ข้างหน้า

00:10:27.720 --> 00:10:28.976
นักวิจัยคนหนึ่งเคยพูดว่า

00:10:29.000 --> 00:10:30.576
"กังวลเรื่องความปลอดภัยของปัญญาประดิษฐ์

00:10:30.600 --> 00:10:32.880
ก็จะเหมือนกับกังวล
เรื่องประชากรจะล้นดาวอังคาร"

00:10:33.786 --> 00:10:35.736
นี่เป็นเรื่องราวในรูปแบบของซิลิคอนแวลลีย์

00:10:35.760 --> 00:10:38.406
ในการบอกว่า "ไม่ต้องเอาสมองน้อยๆ 
มากังวลเรื่องนี้หรอก"

00:10:38.406 --> 00:10:39.496
(เสียงหัวเราะ)

00:10:39.520 --> 00:10:41.416
ดูเหมือนจะไม่มีใครสังเกตเห็นว่า

00:10:41.440 --> 00:10:44.056
การอ้างถึงขอบเขตของเวลา

00:10:44.080 --> 00:10:46.656
เป็นคำพูดที่ไม่มีเหตุผลอย่างสิ้นเชิง

00:10:46.680 --> 00:10:49.936
ถ้าหากว่าความชาญฉลาดเป็นเพียง
เรื่องของการประมวลผลข้อมูล

00:10:49.960 --> 00:10:52.616
และเรายังคงปรับปรุงจักรกลของเรา
ให้ดียิ่งขึ้นต่อไป

00:10:52.640 --> 00:10:55.520
เราก็จะผลิตอะไรบางอย่างในรูปแบบ
สุดยอดความชาญฉลาดออกมา

00:10:56.320 --> 00:10:59.976
และเราก็ไม่รู้เลยว่า
เราจะใช้เวลานานแค่ไหน

00:11:00.000 --> 00:11:02.400
เพื่อสร้างสภาวะที่จะทำสิ่งนั้น
ได้อย่างปลอดภัย

00:11:04.200 --> 00:11:05.496
ขอผมยํ้าอีกครั้ง

00:11:05.520 --> 00:11:09.336
เราไม่รู้เลยว่าเราจะใช้เวลานานแค่ไหน

00:11:09.360 --> 00:11:12.490
เพื่อสร้างสภาวะที่จะทำสิ่งนั้น
ได้อย่างปลอดภัย

00:11:12.920 --> 00:11:16.376
และถ้าคุณยังไม่ทันสังเกตอีกล่ะก็
50 ปีนั้นไม่เป็นอย่างที่มันเคยเป็น

00:11:16.400 --> 00:11:18.856
นี่คือ 50 ปีในอีกไม่กี่เดือน

00:11:18.880 --> 00:11:20.720
เรามีไอโฟนมานานเท่านี้

00:11:21.440 --> 00:11:24.040
"เดอะ ซิมพ์สันส์" ออกอากาศทางทีวี
มานานแค่นี้

00:11:24.680 --> 00:11:27.056
ห้าสิบปีไม่ใช่เวลาที่นานมาก

00:11:27.080 --> 00:11:30.240
ที่จะพบกับสิ่งท้าทายที่ยิ่งใหญ่ที่สุด
ที่ชาติพันธ์ุของเราจะเผชิญ

00:11:31.640 --> 00:11:35.590
ยํ้าอีกครั้งนะครับ ดูเหมือนเรากำลังล้มเหลว
ที่จะมีการตอบสนองทางอารมณ์ที่เหมาะสม

00:11:35.590 --> 00:11:38.526
ต่อสิ่งที่เราเชื่อได้ด้วยเหตุผล
ในทุก ๆ ด้าน ว่ามันกำลังมาถึง

00:11:38.526 --> 00:11:42.376
นักวิทยาศาสตร์คอมพิวเตอร์ สจวร์ต รัสเซลล์
เปรียบเทียบไว้เป็นอย่างดีในเรื่องนี้

00:11:42.400 --> 00:11:47.296
เขาพูดว่า ลองจินตนาการดูว่า
เราได้รับข้อความจากอารยธรรมต่างดาว

00:11:47.320 --> 00:11:49.016
ความว่า

00:11:49.040 --> 00:11:50.576
"มนุษย์โลก

00:11:50.600 --> 00:11:52.960
เราจะไปถึงดาวเคราะห์ของท่านในอีก 50 ปี

00:11:53.800 --> 00:11:55.376
เตรียมตัวให้พร้อมนะ"

00:11:55.400 --> 00:11:59.656
แล้วตอนนี้เราจะแค่นับเดือนถอยหลัง
จนยานแม่มาลงจอดบนพื้นโลกอย่างนั้นหรือ

00:11:59.680 --> 00:12:02.680
เราน่าจะรู้สึกต้องรีบเร่งขึ้น
กว่าที่เราเป็นอยู่บ้าง

00:12:04.680 --> 00:12:06.536
อีกเหตุผลหนึ่ง ที่เขาบอกเราไม่ให้กังวล

00:12:06.560 --> 00:12:09.576
คือจักรกลพวกนี้
ยังไงก็จะมีค่านิยมเหมือนกับเรา

00:12:09.600 --> 00:12:12.216
เพราะแท้จริงแล้วมันจะเป็น
ส่วนต่อขยายออกไปของตัวเราเอง

00:12:12.240 --> 00:12:14.056
พวกมันจะถูกเชื่อมต่อกับสมองของเรา

00:12:14.080 --> 00:12:17.160
หรือที่จริงคือ เรากลายเป็นสมองระบบลิมบิก
(ทำหน้าที่รับรู้อารมณ์) ของพวกมัน

00:12:17.160 --> 00:12:18.536
ครับ มาพิจารณาสักครู่

00:12:18.560 --> 00:12:21.736
ว่าวิถีทางเดียวที่ปลอดภัยและรอบคอบ
ที่จะใช้ต่อไปข้างหน้า

00:12:21.760 --> 00:12:23.096
ที่ได้รับการเสนอแนะมานั้น

00:12:23.120 --> 00:12:25.920
คือการปลูกถ่ายเทคโนโลยีนี้
เข้าสู่สมองของเราโดยตรง

00:12:26.600 --> 00:12:29.976
ครับ จริง ๆ แล้วนี่อาจเป็นวิถีทางเดียว
ที่ปลอดภัยและรอบคอบที่จะใช้ต่อไป

00:12:30.000 --> 00:12:33.056
แต่โดยปกติ ความกังวลเรื่อง
ความปลอดภัยของเทคโนโลยี

00:12:33.080 --> 00:12:36.736
จะต้องได้รับการคลี่คลายให้ได้ไม่มากก็น้อย
ก่อนที่จะเอามันไปติดเข้าไปในหัวของเรา

00:12:36.760 --> 00:12:38.776
(เสียงหัวเราะ)

00:12:38.800 --> 00:12:44.136
ปัญหาที่ลึกลํ้ากว่าก็คือการสร้าง
ปัญญาประดิษฐ์อัจฉริยะขึ้นมา โดยตัวมันเอง

00:12:44.160 --> 00:12:45.896
ดูน่าจะง่ายกว่า

00:12:45.920 --> 00:12:47.776
การสร้างปัญญาประดิษฐ์อัจฉริยะ

00:12:47.800 --> 00:12:49.576
โดยมีประสาทวิทยาศาสตร์ที่สมบูรณ์แบบ

00:12:49.600 --> 00:12:52.280
ที่ทำให้เราหลอมรวมปัญญาความคิดของเรา 
เข้ากับมันได้อย่างแนบเนียน

00:12:52.800 --> 00:12:55.976
และถ้าคิดถึงว่า บริษัทและรัฐบาลทั้งหลาย
ที่กำลังทำงานนี้อยู่

00:12:56.000 --> 00:12:59.656
น่าจะรู้ดีว่าพวกเขานั้นกำลังแข่งขันกันอยู่

00:12:59.680 --> 00:13:02.936
เพราะว่าการเอาชนะการแข่งขันนี้ได้
คือการที่จะได้ครองโลก

00:13:02.960 --> 00:13:05.416
ถ้าคุณไม่ทำลายมันในวินาทีต่อมาไปซะก่อน

00:13:05.440 --> 00:13:08.056
มันก็ดูน่าจะเป็นไปได้ว่า
อะไรก็ตามที่ทำได้ง่ายกว่า

00:13:08.080 --> 00:13:09.860
ก็จะถูกทำเป็นอันดับแรก

00:13:10.560 --> 00:13:13.416
ครับ โชคไม่ดี ผมไม่มีวิธีแก้ปัญหานี้

00:13:13.440 --> 00:13:16.040
นอกเหนือจากการแนะนำ
ให้พวกเรานี้คิดถึงมันมากขึ้นกว่านี้

00:13:16.040 --> 00:13:18.456
ผมว่าเราต้องการอะไร
คล้ายๆ โครงการแมนฮัตตัน

00:13:18.480 --> 00:13:20.360
ในหัวเรื่องปัญญาประดิษฐ์นี้

00:13:20.360 --> 00:13:23.576
ไม่ใช่เพื่อจะสร้างมัน เพราะผมว่า
มันต้องเกิดแน่ เลี่ยงไม่ได้อยู่แล้ว

00:13:23.576 --> 00:13:26.616
แต่เพื่อให้เข้าใจถึงวิธีที่จะหลีกเลี่ยง
การแข่งขันกันสะสมอาวุธ

00:13:26.640 --> 00:13:30.136
และสร้างมันขึ้นมา ในแบบที่
สอดคล้องกับผลประโยชน์ของเรา

00:13:30.160 --> 00:13:32.296
เมื่อเราพูดกันถึงปัญญาประดิษฐ์อัจฉริยะ

00:13:32.320 --> 00:13:34.576
ที่สามารถเปลี่ยนแปลงตัวมันได้เอง

00:13:34.600 --> 00:13:39.216
ก็ดูเหมือนว่า เรามีเพียงโอกาสเดียว
ที่จะทำให้สภาพการณ์เริ่มแรกนั้นถูกต้อง

00:13:39.240 --> 00:13:41.296
และถึงกระนั้น เราก็จำเป็นจะต้องซึมซับ

00:13:41.320 --> 00:13:44.360
ผลสืบเนื่องทางการเมืองและเศรษฐกิจ
ของการที่ต้องทำให้มันถูกต้อง

00:13:45.760 --> 00:13:47.816
แต่ ณ วินาทีที่เรายอมรับ

00:13:47.840 --> 00:13:51.840
ว่าการประมวลข้อมูล
เป็นแหล่งที่มาของความชาญฉลาด

00:13:52.720 --> 00:13:57.520
ว่าระบบคอมพิวเตอร์ที่เหมาะสมบางอย่างนั้น
คือสิ่งที่เป็นพื้นฐานของความชาญฉลาด

00:13:58.360 --> 00:14:02.120
และเราก็ยอมรับว่า เราจะปรับปรุง
ระบบเหล่านี้อย่างต่อเนื่อง

00:14:03.280 --> 00:14:07.736
และเรายอมรับว่า มันเป็นไปได้มากว่า
ขอบเขตของปัญญารู้คิดจะไกลเกินกว่า

00:14:07.760 --> 00:14:09.710
สิ่งที่เรารู้ในปัจจุบัน

00:14:10.120 --> 00:14:11.526
แล้วเราก็ต้องยอมรับ

00:14:11.526 --> 00:14:14.530
ว่าเราอยู่ในกระบวนการ
ของการสร้างเทพเจ้าบางอย่างขึ้นมา

00:14:15.400 --> 00:14:16.976
ขณะนี้ จึงน่าจะเป็นช่วงเวลาที่ดี

00:14:17.000 --> 00:14:20.113
ที่เราจะทำให้แน่ใจว่าเทพเจ้าองค์นั้น
จะเป็นเทพที่อยู่ร่วมกับเราได้

00:14:20.120 --> 00:14:21.656
ขอบคุณมากครับ

00:14:21.680 --> 00:14:26.773
(เสียงปรบมือ)

