WEBVTT
Kind: captions
Language: en

00:00:13.280 --> 00:00:16.936
In my lab, we build
autonomous aerial robots

00:00:16.960 --> 00:00:18.840
like the one you see flying here.

00:00:20.720 --> 00:00:24.416
Unlike the commercially available drones
that you can buy today,

00:00:24.440 --> 00:00:27.080
this robot doesn't have any GPS on board.

00:00:28.160 --> 00:00:29.376
So without GPS,

00:00:29.400 --> 00:00:32.680
it's hard for robots like this
to determine their position.

00:00:34.240 --> 00:00:38.976
This robot uses onboard sensors,
cameras and laser scanners,

00:00:39.000 --> 00:00:40.696
to scan the environment.

00:00:40.720 --> 00:00:43.776
It detects features from the environment,

00:00:43.800 --> 00:00:46.536
and it determines where it is
relative to those features,

00:00:46.560 --> 00:00:48.696
using a method of triangulation.

00:00:48.720 --> 00:00:52.176
And then it can assemble
all these features into a map,

00:00:52.200 --> 00:00:53.936
like you see behind me.

00:00:53.960 --> 00:00:57.896
And this map then allows the robot
to understand where the obstacles are

00:00:57.920 --> 00:01:00.640
and navigate in a collision-free manner.

00:01:01.160 --> 00:01:03.256
What I want to show you next

00:01:03.280 --> 00:01:06.496
is a set of experiments
we did inside our laboratory,

00:01:06.520 --> 00:01:10.000
where this robot was able
to go for longer distances.

00:01:10.400 --> 00:01:15.416
So here you'll see, on the top right,
what the robot sees with the camera.

00:01:15.440 --> 00:01:16.656
And on the main screen --

00:01:16.680 --> 00:01:19.136
and of course this is sped up
by a factor of four --

00:01:19.160 --> 00:01:21.827
on the main screen you'll see
the map that it's building.

00:01:21.851 --> 00:01:26.136
So this is a high-resolution map
of the corridor around our laboratory.

00:01:26.160 --> 00:01:28.496
And in a minute
you'll see it enter our lab,

00:01:28.520 --> 00:01:31.376
which is recognizable
by the clutter that you see.

00:01:31.400 --> 00:01:32.416
(Laughter)

00:01:32.440 --> 00:01:34.447
But the main point I want to convey to you

00:01:34.472 --> 00:01:38.056
is that these robots are capable
of building high-resolution maps

00:01:38.080 --> 00:01:40.576
at five centimeters resolution,

00:01:40.600 --> 00:01:44.776
allowing somebody who is outside the lab,
or outside the building

00:01:44.800 --> 00:01:48.016
to deploy these
without actually going inside,

00:01:48.040 --> 00:01:51.800
and trying to infer
what happens inside the building.

00:01:52.400 --> 00:01:54.640
Now there's one problem
with robots like this.

00:01:55.600 --> 00:01:57.800
The first problem is it's pretty big.

00:01:58.120 --> 00:01:59.800
Because it's big, it's heavy.

00:02:00.640 --> 00:02:03.680
And these robots consume
about 100 watts per pound.

00:02:04.360 --> 00:02:06.640
And this makes for
a very short mission life.

00:02:08.000 --> 00:02:09.456
The second problem

00:02:09.480 --> 00:02:13.376
is that these robots have onboard sensors
that end up being very expensive --

00:02:13.400 --> 00:02:16.840
a laser scanner, a camera
and the processors.

00:02:17.280 --> 00:02:20.320
That drives up the cost of this robot.

00:02:21.440 --> 00:02:24.096
So we asked ourselves a question:

00:02:24.120 --> 00:02:27.896
what consumer product
can you buy in an electronics store

00:02:27.920 --> 00:02:34.200
that is inexpensive, that's lightweight,
that has sensing onboard and computation?

00:02:36.080 --> 00:02:38.736
And we invented the flying phone.

00:02:38.760 --> 00:02:40.696
(Laughter)

00:02:40.720 --> 00:02:46.896
So this robot uses a Samsung Galaxy
smartphone that you can buy off the shelf,

00:02:46.920 --> 00:02:50.936
and all you need is an app that you
can download from our app store.

00:02:50.960 --> 00:02:55.176
And you can see this robot
reading the letters, "TED" in this case,

00:02:55.200 --> 00:02:58.136
looking at the corners
of the "T" and the "E"

00:02:58.160 --> 00:03:01.640
and then triangulating off of that,
flying autonomously.

00:03:02.720 --> 00:03:05.976
That joystick is just there
to make sure if the robot goes crazy,

00:03:06.000 --> 00:03:07.416
Giuseppe can kill it.

00:03:07.440 --> 00:03:09.080
(Laughter)

00:03:10.920 --> 00:03:14.736
In addition to building
these small robots,

00:03:14.760 --> 00:03:19.560
we also experiment with aggressive
behaviors, like you see here.

00:03:19.920 --> 00:03:25.216
So this robot is now traveling
at two to three meters per second,

00:03:25.240 --> 00:03:28.736
pitching and rolling aggressively
as it changes direction.

00:03:28.760 --> 00:03:33.016
The main point is we can have
smaller robots that can go faster

00:03:33.040 --> 00:03:36.000
and then travel in these
very unstructured environments.

00:03:37.120 --> 00:03:39.176
And in this next video,

00:03:39.200 --> 00:03:45.096
just like you see this bird, an eagle,
gracefully coordinating its wings,

00:03:45.120 --> 00:03:49.416
its eyes and feet
to grab prey out of the water,

00:03:49.440 --> 00:03:51.336
our robot can go fishing, too.

00:03:51.360 --> 00:03:52.856
(Laughter)

00:03:52.880 --> 00:03:56.936
In this case, this is a Philly cheesesteak
hoagie that it's grabbing out of thin air.

00:03:56.960 --> 00:03:59.360
(Laughter)

00:03:59.680 --> 00:04:02.976
So you can see this robot
going at about three meters per second,

00:04:03.000 --> 00:04:08.136
which is faster than walking speed,
coordinating its arms, its claws

00:04:08.160 --> 00:04:12.280
and its flight with split-second timing
to achieve this maneuver.

00:04:14.120 --> 00:04:15.336
In another experiment,

00:04:15.360 --> 00:04:19.016
I want to show you
how the robot adapts its flight

00:04:19.040 --> 00:04:21.416
to control its suspended payload,

00:04:21.440 --> 00:04:25.240
whose length is actually larger
than the width of the window.

00:04:25.680 --> 00:04:27.376
So in order to accomplish this,

00:04:27.400 --> 00:04:31.096
it actually has to pitch
and adjust the altitude

00:04:31.120 --> 00:04:33.440
and swing the payload through.

00:04:38.920 --> 00:04:41.216
But of course we want
to make these even smaller,

00:04:41.240 --> 00:04:44.256
and we're inspired
in particular by honeybees.

00:04:44.280 --> 00:04:47.536
So if you look at honeybees,
and this is a slowed down video,

00:04:47.560 --> 00:04:51.280
they're so small,
the inertia is so lightweight --

00:04:51.960 --> 00:04:53.136
(Laughter)

00:04:53.160 --> 00:04:56.696
that they don't care --
they bounce off my hand, for example.

00:04:56.720 --> 00:04:59.880
This is a little robot
that mimics the honeybee behavior.

00:05:00.600 --> 00:05:01.816
And smaller is better,

00:05:01.840 --> 00:05:05.376
because along with the small size
you get lower inertia.

00:05:05.400 --> 00:05:06.936
Along with lower inertia --

00:05:06.960 --> 00:05:09.816
(Robot buzzing, laughter)

00:05:09.840 --> 00:05:12.656
along with lower inertia,
you're resistant to collisions.

00:05:12.680 --> 00:05:14.400
And that makes you more robust.

00:05:15.800 --> 00:05:18.456
So just like these honeybees,
we build small robots.

00:05:18.480 --> 00:05:21.856
And this particular one
is only 25 grams in weight.

00:05:21.880 --> 00:05:24.040
It consumes only six watts of power.

00:05:24.440 --> 00:05:26.976
And it can travel
up to six meters per second.

00:05:27.000 --> 00:05:29.336
So if I normalize that to its size,

00:05:29.360 --> 00:05:33.000
it's like a Boeing 787 traveling
ten times the speed of sound.

00:05:36.000 --> 00:05:38.096
(Laughter)

00:05:38.120 --> 00:05:40.040
And I want to show you an example.

00:05:40.840 --> 00:05:46.096
This is probably the first planned mid-air
collision, at one-twentieth normal speed.

00:05:46.120 --> 00:05:48.978
These are going at a relative speed
of two meters per second,

00:05:49.002 --> 00:05:51.482
and this illustrates the basic principle.

00:05:52.200 --> 00:05:57.176
The two-gram carbon fiber cage around it
prevents the propellers from entangling,

00:05:57.200 --> 00:06:02.496
but essentially the collision is absorbed
and the robot responds to the collisions.

00:06:02.520 --> 00:06:05.080
And so small also means safe.

00:06:05.400 --> 00:06:07.416
In my lab, as we developed these robots,

00:06:07.440 --> 00:06:09.060
we start off with these big robots

00:06:09.084 --> 00:06:11.896
and then now we're down
to these small robots.

00:06:11.920 --> 00:06:15.376
And if you plot a histogram
of the number of Band-Aids we've ordered

00:06:15.400 --> 00:06:17.976
in the past, that sort of tailed off now.

00:06:18.000 --> 00:06:19.960
Because these robots are really safe.

00:06:20.760 --> 00:06:23.216
The small size has some disadvantages,

00:06:23.240 --> 00:06:27.320
and nature has found a number of ways
to compensate for these disadvantages.

00:06:27.960 --> 00:06:31.960
The basic idea is they aggregate
to form large groups, or swarms.

00:06:32.320 --> 00:06:36.296
So, similarly, in our lab,
we try to create artificial robot swarms.

00:06:36.320 --> 00:06:37.701
And this is quite challenging

00:06:37.725 --> 00:06:41.045
because now you have to think
about networks of robots.

00:06:41.360 --> 00:06:42.656
And within each robot,

00:06:42.680 --> 00:06:48.296
you have to think about the interplay
of sensing, communication, computation --

00:06:48.320 --> 00:06:53.280
and this network then becomes
quite difficult to control and manage.

00:06:54.160 --> 00:06:57.456
So from nature we take away
three organizing principles

00:06:57.480 --> 00:07:00.640
that essentially allow us
to develop our algorithms.

00:07:01.640 --> 00:07:06.176
The first idea is that robots
need to be aware of their neighbors.

00:07:06.200 --> 00:07:09.640
They need to be able to sense
and communicate with their neighbors.

00:07:10.040 --> 00:07:12.696
So this video illustrates the basic idea.

00:07:12.720 --> 00:07:14.016
You have four robots --

00:07:14.040 --> 00:07:18.280
one of the robots has actually been
hijacked by a human operator, literally.

00:07:19.217 --> 00:07:21.456
But because the robots
interact with each other,

00:07:21.480 --> 00:07:23.136
they sense their neighbors,

00:07:23.160 --> 00:07:24.456
they essentially follow.

00:07:24.480 --> 00:07:29.840
And here there's a single person
able to lead this network of followers.

00:07:32.000 --> 00:07:37.056
So again, it's not because all the robots
know where they're supposed to go.

00:07:37.080 --> 00:07:41.400
It's because they're just reacting
to the positions of their neighbors.

00:07:43.720 --> 00:07:47.840
(Laughter)

00:07:48.280 --> 00:07:53.520
So the next experiment illustrates
the second organizing principle.

00:07:54.920 --> 00:07:58.720
And this principle has to do
with the principle of anonymity.

00:07:59.400 --> 00:08:03.696
Here the key idea is that

00:08:03.720 --> 00:08:07.960
the robots are agnostic
to the identities of their neighbors.

00:08:08.440 --> 00:08:11.056
They're asked to form a circular shape,

00:08:11.080 --> 00:08:14.376
and no matter how many robots
you introduce into the formation,

00:08:14.400 --> 00:08:16.976
or how many robots you pull out,

00:08:17.000 --> 00:08:20.136
each robot is simply
reacting to its neighbor.

00:08:20.160 --> 00:08:25.136
It's aware of the fact that it needs
to form the circular shape,

00:08:25.160 --> 00:08:26.936
but collaborating with its neighbors

00:08:26.960 --> 00:08:30.680
it forms the shape
without central coordination.

00:08:31.520 --> 00:08:33.936
Now if you put these ideas together,

00:08:33.960 --> 00:08:37.856
the third idea is that we
essentially give these robots

00:08:37.880 --> 00:08:42.176
mathematical descriptions
of the shape they need to execute.

00:08:42.200 --> 00:08:45.696
And these shapes can be varying
as a function of time,

00:08:45.720 --> 00:08:50.216
and you'll see these robots
start from a circular formation,

00:08:50.240 --> 00:08:53.496
change into a rectangular formation,
stretch into a straight line,

00:08:53.520 --> 00:08:54.895
back into an ellipse.

00:08:54.919 --> 00:08:58.536
And they do this with the same
kind of split-second coordination

00:08:58.560 --> 00:09:01.840
that you see in natural swarms, in nature.

00:09:03.080 --> 00:09:05.216
So why work with swarms?

00:09:05.240 --> 00:09:09.360
Let me tell you about two applications
that we are very interested in.

00:09:10.160 --> 00:09:12.536
The first one has to do with agriculture,

00:09:12.560 --> 00:09:15.920
which is probably the biggest problem
that we're facing worldwide.

00:09:16.760 --> 00:09:18.016
As you well know,

00:09:18.040 --> 00:09:21.560
one in every seven persons
in this earth is malnourished.

00:09:21.920 --> 00:09:25.400
Most of the land that we can cultivate
has already been cultivated.

00:09:25.960 --> 00:09:29.176
And the efficiency of most systems
in the world is improving,

00:09:29.200 --> 00:09:32.720
but our production system
efficiency is actually declining.

00:09:33.080 --> 00:09:37.296
And that's mostly because of water
shortage, crop diseases, climate change

00:09:37.320 --> 00:09:38.840
and a couple of other things.

00:09:39.360 --> 00:09:40.840
So what can robots do?

00:09:41.200 --> 00:09:45.816
Well, we adopt an approach that's
called Precision Farming in the community.

00:09:45.840 --> 00:09:51.216
And the basic idea is that we fly
aerial robots through orchards,

00:09:51.240 --> 00:09:54.360
and then we build
precision models of individual plants.

00:09:54.829 --> 00:09:56.496
So just like personalized medicine,

00:09:56.520 --> 00:10:01.336
while you might imagine wanting
to treat every patient individually,

00:10:01.360 --> 00:10:05.056
what we'd like to do is build
models of individual plants

00:10:05.080 --> 00:10:09.216
and then tell the farmer
what kind of inputs every plant needs --

00:10:09.240 --> 00:10:13.680
the inputs in this case being water,
fertilizer and pesticide.

00:10:14.640 --> 00:10:18.256
Here you'll see robots
traveling through an apple orchard,

00:10:18.280 --> 00:10:20.536
and in a minute you'll see
two of its companions

00:10:20.560 --> 00:10:22.370
doing the same thing on the left side.

00:10:22.800 --> 00:10:26.456
And what they're doing is essentially
building a map of the orchard.

00:10:26.480 --> 00:10:29.296
Within the map is a map
of every plant in this orchard.

00:10:29.320 --> 00:10:30.976
(Robot buzzing)

00:10:31.000 --> 00:10:32.896
Let's see what those maps look like.

00:10:32.920 --> 00:10:37.216
In the next video, you'll see the cameras
that are being used on this robot.

00:10:37.240 --> 00:10:40.480
On the top-left is essentially
a standard color camera.

00:10:41.640 --> 00:10:44.936
On the left-center is an infrared camera.

00:10:44.960 --> 00:10:48.736
And on the bottom-left
is a thermal camera.

00:10:48.760 --> 00:10:52.096
And on the main panel, you're seeing
a three-dimensional reconstruction

00:10:52.120 --> 00:10:58.240
of every tree in the orchard
as the sensors fly right past the trees.

00:10:59.640 --> 00:11:03.680
Armed with information like this,
we can do several things.

00:11:04.200 --> 00:11:08.456
The first and possibly the most important
thing we can do is very simple:

00:11:08.480 --> 00:11:10.920
count the number of fruits on every tree.

00:11:11.520 --> 00:11:16.056
By doing this, you tell the farmer
how many fruits she has in every tree

00:11:16.080 --> 00:11:20.336
and allow her to estimate
the yield in the orchard,

00:11:20.360 --> 00:11:23.200
optimizing the production
chain downstream.

00:11:23.640 --> 00:11:25.256
The second thing we can do

00:11:25.280 --> 00:11:29.776
is take models of plants, construct
three-dimensional reconstructions,

00:11:29.800 --> 00:11:32.336
and from that estimate the canopy size,

00:11:32.360 --> 00:11:36.136
and then correlate the canopy size
to the amount of leaf area on every plant.

00:11:36.160 --> 00:11:38.336
And this is called the leaf area index.

00:11:38.360 --> 00:11:40.296
So if you know this leaf area index,

00:11:40.320 --> 00:11:45.776
you essentially have a measure of how much
photosynthesis is possible in every plant,

00:11:45.800 --> 00:11:48.680
which again tells you
how healthy each plant is.

00:11:49.520 --> 00:11:53.736
By combining visual
and infrared information,

00:11:53.760 --> 00:11:57.056
we can also compute indices such as NDVI.

00:11:57.080 --> 00:11:59.896
And in this particular case,
you can essentially see

00:11:59.920 --> 00:12:02.936
there are some crops that are
not doing as well as other crops.

00:12:02.960 --> 00:12:07.016
This is easily discernible from imagery,

00:12:07.040 --> 00:12:09.256
not just visual imagery but combining

00:12:09.280 --> 00:12:12.056
both visual imagery and infrared imagery.

00:12:12.080 --> 00:12:13.416
And then lastly,

00:12:13.440 --> 00:12:17.456
one thing we're interested in doing is
detecting the early onset of chlorosis --

00:12:17.480 --> 00:12:18.976
and this is an orange tree --

00:12:19.000 --> 00:12:21.560
which is essentially seen
by yellowing of leaves.

00:12:21.880 --> 00:12:25.776
But robots flying overhead
can easily spot this autonomously

00:12:25.800 --> 00:12:28.736
and then report to the farmer
that he or she has a problem

00:12:28.760 --> 00:12:30.280
in this section of the orchard.

00:12:30.800 --> 00:12:33.496
Systems like this can really help,

00:12:33.520 --> 00:12:39.336
and we're projecting yields
that can improve by about ten percent

00:12:39.360 --> 00:12:42.576
and, more importantly, decrease
the amount of inputs such as water

00:12:42.600 --> 00:12:45.880
by 25 percent by using
aerial robot swarms.

00:12:47.200 --> 00:12:52.936
Lastly, I want you to applaud
the people who actually create the future,

00:12:52.960 --> 00:12:57.880
Yash Mulgaonkar, Sikang Liu
and Giuseppe Loianno,

00:12:57.920 --> 00:13:01.416
who are responsible for the three
demonstrations that you saw.

00:13:01.440 --> 00:13:02.616
Thank you.

00:13:02.640 --> 00:13:08.560
(Applause)

