WEBVTT
Kind: captions
Language: ja

00:00:00.000 --> 00:00:07.000
翻訳: Tomoyuki Suzuki
校正: Misaki Sato

00:00:13.140 --> 00:00:15.810
私の研究室では ご覧のような

00:00:15.810 --> 00:00:18.840
自律飛行ロボットを作っています

00:00:20.720 --> 00:00:24.440
今時 お店で売っているような
ドローンとは違って

00:00:24.440 --> 00:00:27.080
GPSは搭載していません

00:00:28.160 --> 00:00:29.400
GPSなしでは

00:00:29.400 --> 00:00:32.750
このようなロボットが
自分の位置を特定するのは困難です

00:00:34.240 --> 00:00:39.000
このロボットの場合 搭載したセンサー、
カメラ、レーザースキャナーで

00:00:39.000 --> 00:00:40.720
周囲を走査していて

00:00:40.720 --> 00:00:43.800
周りにあるものを検知し

00:00:43.800 --> 00:00:46.560
三角測量によって
それらに対する

00:00:46.560 --> 00:00:48.720
相対的な位置を把握しています

00:00:48.720 --> 00:00:52.010
それらのデータをまとめて
後ろに出ているような

00:00:52.010 --> 00:00:54.170
マップを構築することが出来ます

00:00:54.170 --> 00:00:57.920
こうやってマップができると
どこに障害物があるか分かり

00:00:57.920 --> 00:01:00.640
ロボットは衝突することなく
飛行することが出来ます

00:01:01.160 --> 00:01:03.280
次にお見せしたいのは

00:01:03.280 --> 00:01:06.520
このロボットに
もっと長い距離を飛行させてみた

00:01:06.520 --> 00:01:10.400
私たちの研究所で行った
一連の実験です

00:01:10.400 --> 00:01:15.440
右上にあるのは
ロボットのカメラが撮った映像です

00:01:15.440 --> 00:01:16.680
メインスクリーンでは

00:01:16.680 --> 00:01:19.160
―４倍速でお見せしていますが―

00:01:19.160 --> 00:01:21.851
マップ構築の様子をご覧になれます

00:01:21.851 --> 00:01:26.160
これは研究室周辺の廊下を
高解像度でマップ化したもので

00:01:26.160 --> 00:01:28.520
まもなく研究室へと入ってきます

00:01:28.520 --> 00:01:31.400
散らかっている様子で
それと分かるかと思いますが—

00:01:31.400 --> 00:01:32.440
(笑)

00:01:32.440 --> 00:01:34.472
ここで最も強調したいのは

00:01:34.472 --> 00:01:38.080
これらのロボットは
５センチという高い解像度で

00:01:38.080 --> 00:01:40.600
マップを作成することが
出来るということで

00:01:40.600 --> 00:01:44.800
研究室や建物の外部にいる人でも

00:01:44.800 --> 00:01:47.860
このロボットを放つことで
実際に中に入ることなく

00:01:47.860 --> 00:01:51.930
中で何が起こっているか
推察することができます

00:01:52.400 --> 00:01:54.640
このようなロボットには
問題点があります

00:01:55.600 --> 00:01:58.120
１つ目の問題は
大きいということです

00:01:58.120 --> 00:02:00.010
大きいので重量もあります

00:02:00.640 --> 00:02:04.010
１キログラムにつき約200ワットの
電力を消費します

00:02:04.360 --> 00:02:06.640
ですからあまり長くは作業できません

00:02:08.000 --> 00:02:09.480
２つ目の問題は

00:02:09.480 --> 00:02:13.400
ロボットに搭載されている
レーザースキャナーやカメラや

00:02:13.400 --> 00:02:16.840
CPUがとても高価だということです

00:02:17.280 --> 00:02:20.320
そのためロボットのコストが
跳ね上がります

00:02:21.440 --> 00:02:24.120
そこで私達は自問しました

00:02:24.120 --> 00:02:27.490
消費者が電気屋で買えるような

00:02:27.490 --> 00:02:34.200
センサーやCPUを搭載した
高価でない軽量な商品はないだろうか？

00:02:36.080 --> 00:02:38.760
そうやって空飛ぶ携帯電話が
生まれました

00:02:38.760 --> 00:02:40.720
(笑)

00:02:40.720 --> 00:02:46.560
このロボットは お店ですぐに買える
サムスンのギャラクシー携帯を利用し

00:02:46.560 --> 00:02:50.960
アプリはAppストアから
ダウンロードできます

00:02:50.960 --> 00:02:55.200
このロボットは 今
「TED」の文字を読み取っているところです

00:02:55.200 --> 00:02:58.160
「T」と「E」の角を探し出し

00:02:58.160 --> 00:03:01.640
三角測量しつつ自律飛行しています

00:03:02.720 --> 00:03:05.760
ジョイスティックは
ロボットが暴走した時のためで

00:03:05.760 --> 00:03:07.710
その時にはジュゼッペ君が
止めてくれます

00:03:07.710 --> 00:03:09.080
(笑)

00:03:10.920 --> 00:03:14.760
単に小さなロボットを
作るというだけでなく

00:03:14.760 --> 00:03:19.920
このような激しい動きをさせる
実験もしています

00:03:19.920 --> 00:03:24.850
このロボットは秒速２－３メートルで動き

00:03:24.850 --> 00:03:28.760
方向転換をするときには
上下運動や回転運動を素早く行います

00:03:28.760 --> 00:03:33.040
重要な点は 小さなロボットは
素早く動け

00:03:33.040 --> 00:03:36.250
障害の多い環境中を
うまく移動できることです

00:03:37.120 --> 00:03:39.200
次のビデオでお見せするのは

00:03:39.200 --> 00:03:44.940
鷲のような鳥が
羽と目と足を優雅に連携させて

00:03:44.940 --> 00:03:48.550
水中の獲物を捉まえるように

00:03:48.550 --> 00:03:51.560
私たちのロボットにも
魚採りができることです

00:03:51.560 --> 00:03:52.880
(笑)

00:03:52.880 --> 00:03:56.690
どこからともなくやって来て
チーズ &amp; ステーキのロールパンサンドを

00:03:56.690 --> 00:03:59.680
かっさらっています (笑)

00:03:59.680 --> 00:04:04.730
このロボットは人の歩く速さよりも速い
秒速約３メートルで動き

00:04:04.730 --> 00:04:09.010
腕と爪と飛行を
絶妙なタイミングで連携させ

00:04:09.010 --> 00:04:12.280
このような動作を達成しています

00:04:14.120 --> 00:04:16.080
別の実験でお見せするのは

00:04:16.080 --> 00:04:18.460
枠の幅よりも長い紐で

00:04:18.460 --> 00:04:21.300
重りを吊したロボットが

00:04:21.300 --> 00:04:25.680
その枠の中を
上手くくぐり抜ける様子です

00:04:25.680 --> 00:04:27.400
これを成し遂げるには

00:04:27.400 --> 00:04:31.120
上下に動いて 高度を調整することで

00:04:31.120 --> 00:04:33.860
重りをスイングさせる
必要があります

00:04:38.750 --> 00:04:41.740
しかし もっと小さいものが
作れたらと思っています

00:04:41.740 --> 00:04:44.280
特にミツバチにヒントを得ました

00:04:44.280 --> 00:04:47.560
これはスローモーションで
再生したビデオですが

00:04:47.560 --> 00:04:51.280
ミツバチはとても小さく
その慣性力は僅かです

00:04:51.960 --> 00:04:53.160
(笑)

00:04:53.160 --> 00:04:56.720
例えば 私の手にぶつかっても
ほとんど気にかけません

00:04:56.720 --> 00:04:59.880
これはミツバチの動きをまねた
小型ロボットです

00:05:00.600 --> 00:05:01.840
小さいほど

00:05:01.840 --> 00:05:05.400
慣性力が小さくなるので
都合がいいのです

00:05:05.400 --> 00:05:06.960
慣性力が小さいと—

00:05:06.960 --> 00:05:09.840
(周りをブンブン飛び回るロボット) (笑)

00:05:09.840 --> 00:05:12.680
慣性力が小さいと
衝突に対し強くなります

00:05:12.680 --> 00:05:14.680
より丈夫になるということです

00:05:15.800 --> 00:05:18.480
そういうわけでミツバチのように
小さなロボットを作ります

00:05:18.480 --> 00:05:21.880
これは僅か25グラムしかありません

00:05:21.880 --> 00:05:24.440
消費電力はほんの６ワットです

00:05:24.440 --> 00:05:27.000
秒速６メートルまで出せます

00:05:27.000 --> 00:05:29.360
ボーイング787の大きさだったら

00:05:29.360 --> 00:05:33.000
音速の10倍に相当する速さです

00:05:36.000 --> 00:05:38.120
(笑)

00:05:38.120 --> 00:05:40.040
実例をお見せしましょう

00:05:40.840 --> 00:05:46.120
これはたぶん初めての空中衝突実験で
20分の１のスピードでお見せしています

00:05:46.120 --> 00:05:49.002
(ロボット同士の) 相対速度は
毎秒２メートルで

00:05:49.002 --> 00:05:51.762
お話しした基本原理を例示しています

00:05:52.200 --> 00:05:57.200
機体を保護する２グラムの炭素繊維のカゴは
プロペラ同士が絡まるのを防いでいます

00:05:57.200 --> 00:06:02.520
衝撃は吸収され
ロボットは衝突に対応しています

00:06:02.520 --> 00:06:05.400
小さいということは安全も意味します

00:06:05.400 --> 00:06:07.440
研究室ではこんなロボットを作ってきました

00:06:07.440 --> 00:06:09.084
大型のロボットから始め

00:06:09.084 --> 00:06:11.920
小型のものへと移っていきました

00:06:11.920 --> 00:06:15.400
これまで研究室で発注した絆創膏の数を
ヒストグラムにしたら

00:06:15.400 --> 00:06:18.000
どんどん小さくなっていることが
分るでしょう

00:06:18.000 --> 00:06:20.200
ロボットが安全になってきたからです

00:06:20.760 --> 00:06:23.240
小さいと不利な点もあります

00:06:23.240 --> 00:06:27.320
自然はこの不利な点を補う方法を
進化させてきました

00:06:27.960 --> 00:06:32.320
基本的には集団や群れを作る
ということです

00:06:32.320 --> 00:06:36.320
我々の研究室でも 同様に
人工的なロボットの集団を試してみました

00:06:36.320 --> 00:06:37.725
これはかなり難しい技術です

00:06:37.725 --> 00:06:41.360
ロボット間のネットワークを
考慮しなければならないからです

00:06:41.360 --> 00:06:42.680
各ロボットの

00:06:42.680 --> 00:06:48.320
センサー、通信、計算の
連携を考えなければなりません

00:06:48.320 --> 00:06:53.280
このネットワークの制御、管理が
実にやっかいなのです

00:06:54.160 --> 00:06:57.480
自然から３つの(自己)組織化の原理を
見習うことによって

00:06:57.480 --> 00:07:00.640
制御のアルゴリズムを
開発することができます

00:07:01.640 --> 00:07:06.200
１つ目のアイデアは
ロボットが近くの個体を認識することです

00:07:06.200 --> 00:07:10.040
近隣の個体を認識して
互いに通信できなければなりません

00:07:10.040 --> 00:07:12.720
このビデオはその基本原理を示しています

00:07:12.720 --> 00:07:14.040
４機のロボットがいます

00:07:14.040 --> 00:07:18.280
その内１機が 文字通り
人間のオペレータによってハイジャックされています

00:07:19.217 --> 00:07:21.480
ロボットは互いに相互作用し

00:07:21.480 --> 00:07:23.160
近くの個体を認識しているので

00:07:23.160 --> 00:07:24.480
動きに追従します

00:07:24.480 --> 00:07:29.840
この例では１人の人間が
追従するロボットを先導しています

00:07:32.000 --> 00:07:37.080
どのロボットもどこへ行くべきか
分っているわけではなく

00:07:37.080 --> 00:07:41.400
ただ近くのロボットの位置に対し
反応しているだけです

00:07:43.720 --> 00:07:47.840
(笑)

00:07:48.280 --> 00:07:53.520
次の実験は
組織化の２つ目の原理を示すものです

00:07:54.920 --> 00:07:58.720
この原理は匿名性の原理と関連しています

00:07:59.400 --> 00:08:02.750
ここで基本となる考えは

00:08:02.780 --> 00:08:08.070
ロボットは近隣の個体を
識別していないということです

00:08:08.440 --> 00:08:11.080
円陣を組めという指令を受けると

00:08:11.080 --> 00:08:14.400
編隊を組むロボットの数を
いかに増やそうと

00:08:14.400 --> 00:08:17.000
あるいは 何体か取り除こうと

00:08:17.000 --> 00:08:20.290
各ロボットは単に
隣にいるロボットに反応するだけなのです

00:08:20.290 --> 00:08:24.800
円陣を組むという
指示を受けるものの

00:08:24.800 --> 00:08:26.960
隣のロボットと協調するだけで

00:08:26.960 --> 00:08:31.030
中央制御によって
編隊を形成しているわけではありません

00:08:31.520 --> 00:08:33.960
これらのアイデアを一緒にすると

00:08:33.960 --> 00:08:37.880
３つ目のアイデアが得られます

00:08:37.880 --> 00:08:42.200
ロボットに編隊の形の
数学的記述を与えるということです

00:08:42.200 --> 00:08:45.720
形は時間と共に変わっていきます

00:08:45.720 --> 00:08:50.240
ご覧の様に
円形から始まり

00:08:50.240 --> 00:08:53.520
長方形を形作った後
直線状に広がり

00:08:53.520 --> 00:08:54.919
また楕円に戻ります

00:08:54.919 --> 00:08:58.560
自然界における生物の群れと同様に

00:08:58.560 --> 00:09:01.840
瞬間瞬間の協調によって
こういったことを成し遂げています

00:09:03.080 --> 00:09:05.240
なぜ群れについて研究しているのか？

00:09:05.240 --> 00:09:09.360
我々がとても興味を抱いている
２つの応用があります

00:09:10.160 --> 00:09:12.560
１つ目は農業に関するものです

00:09:12.560 --> 00:09:16.180
我々が世界で直面している
最大の問題と言って良いでしょう

00:09:16.760 --> 00:09:18.040
ご存知の通り

00:09:18.040 --> 00:09:21.920
世界では
７人に１人が栄養失調です

00:09:21.920 --> 00:09:25.400
耕作可能な土地は
既に殆ど開拓されています

00:09:25.960 --> 00:09:29.200
こんにちの世界では
多くのシステムの効率が向上していますが

00:09:29.200 --> 00:09:33.080
農業の生産効率は低下しています

00:09:33.080 --> 00:09:37.320
原因はおそらく 水不足、穀物の病気
気候変動や

00:09:37.320 --> 00:09:39.000
その他の理由にあります

00:09:39.230 --> 00:09:41.500
ロボットに何が出来るでしょう？

00:09:41.500 --> 00:09:45.840
この分野で精密農業(プレシジョンファーミング）
と呼ばれる手法を取り入れてみました

00:09:45.840 --> 00:09:50.060
基本的な考えはこうです
果樹園にロボットを飛ばし

00:09:50.060 --> 00:09:54.360
個々の木の精密なモデルを作成します

00:09:54.829 --> 00:09:58.080
個々の患者の
遺伝体質に合わせた

00:09:58.080 --> 00:10:01.360
オーダーメード医療のように

00:10:01.360 --> 00:10:05.080
個々の木のモデルを製作することによって

00:10:05.080 --> 00:10:09.240
農家はそれぞれの木が必要とするもの―

00:10:09.240 --> 00:10:14.040
この場合 水、肥料や殺虫剤といったものですが
それを知ることができます

00:10:14.640 --> 00:10:18.280
ロボットがリンゴ園を飛び交っています

00:10:18.280 --> 00:10:20.620
仲間の２機が同じようなことを
しているのが

00:10:20.620 --> 00:10:22.480
すぐに 左手に見えてきます

00:10:22.800 --> 00:10:26.260
果樹園のマップを作成しているところで

00:10:26.260 --> 00:10:29.500
果樹園にある１本１本の木を
マッピングしています

00:10:29.500 --> 00:10:31.000
(ブンブン)

00:10:31.000 --> 00:10:32.920
ではそのマップを見てみましょう

00:10:32.920 --> 00:10:37.240
次のビデオではロボットに搭載された
カメラの映像をご覧になれます

00:10:37.240 --> 00:10:40.480
左上は通常のカラー映像です

00:10:41.640 --> 00:10:44.960
左中央は赤外線映像で

00:10:44.960 --> 00:10:48.760
左下はサーマルカメラのものです

00:10:48.760 --> 00:10:52.120
中央のパネルでは
各センサーが木々を通過するのに合わせ

00:10:52.120 --> 00:10:58.240
果樹園の木の状態が
３次元的に再構成されていく様子が見られます

00:10:59.640 --> 00:11:03.680
こういった情報を用いて
多くのことが出来ます

00:11:04.200 --> 00:11:08.480
１つ目はおそらく最も重要なことですが
とても単純なこと

00:11:08.480 --> 00:11:11.310
木になっている果実の数を
数えるということです

00:11:11.520 --> 00:11:16.080
これによって農家は
個々の木になる果実の数を知り

00:11:16.080 --> 00:11:20.360
果樹園全体の収穫量を見積もり

00:11:20.360 --> 00:11:23.420
生産販売経路を
最適化することができます

00:11:23.640 --> 00:11:25.280
２つ目に可能なことは

00:11:25.280 --> 00:11:29.800
木のモデルに基づき
３次元形状を再構成し

00:11:29.800 --> 00:11:32.360
そこから樹冠の面積を
推定することで

00:11:32.360 --> 00:11:36.160
土地単位面積あたりの
葉面積を求めるということです

00:11:36.160 --> 00:11:38.360
これは葉面積指数と呼ばれます

00:11:38.360 --> 00:11:40.320
葉面積指数は

00:11:40.320 --> 00:11:45.800
それぞれの木がどれだけの光合成を
行っているかの指標となり

00:11:45.800 --> 00:11:48.680
個々の木の健康度を示します

00:11:49.520 --> 00:11:53.760
可視光と赤外線データを組み合わせると

00:11:53.760 --> 00:11:57.080
正規化植生指標といった指標を
計算することができます

00:11:57.080 --> 00:11:59.720
ご覧の例では

00:11:59.720 --> 00:12:03.140
ある作物が他の作物に比べて
状態が悪いことが見て取れます

00:12:03.140 --> 00:12:05.760
これは通常の可視光だけでなく

00:12:05.760 --> 00:12:09.280
可視光と赤外線イメージを
組み合わせることで

00:12:09.280 --> 00:12:12.080
容易に識別できるようになります

00:12:12.080 --> 00:12:13.440
最後に

00:12:13.440 --> 00:12:17.480
我々が関心を持っているのは
植物の黄白化の早期発見です

00:12:17.480 --> 00:12:19.000
これはオレンジの木です

00:12:19.000 --> 00:12:21.880
葉が黄色くなっています

00:12:21.880 --> 00:12:25.800
上空にロボットを飛ばすことで
これは自動で容易に発見できます

00:12:25.800 --> 00:12:28.760
そして果樹園のこの区域に
異常があることを

00:12:28.760 --> 00:12:30.280
農家に知らせます

00:12:30.800 --> 00:12:33.520
このようなシステムはとても有効で

00:12:33.520 --> 00:12:39.360
10％の収穫量増加が期待できますが

00:12:39.360 --> 00:12:42.600
さらに重要なのは
飛行ロボットを使うことで

00:12:42.600 --> 00:12:46.190
水の25％削減など
投入資源を減らせることです

00:12:47.200 --> 00:12:52.960
最後になりますが 未来を創造する
この人達に拍手をお願いしたいと思います

00:12:52.960 --> 00:12:57.920
ヤッシュ・ムルガンカー、シカン・リウ
ジュゼッペ・ロイアーノ

00:12:57.920 --> 00:13:01.440
彼らがご覧になった３つのデモを
作成してくれました

00:13:01.440 --> 00:13:02.640
有難うございました

00:13:02.640 --> 00:13:08.560
(拍手)

