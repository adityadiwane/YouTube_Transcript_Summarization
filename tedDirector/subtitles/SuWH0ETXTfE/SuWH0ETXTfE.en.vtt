WEBVTT
Kind: captions
Language: en

00:00:25.000 --> 00:00:28.000
What I want to talk to you about today is

00:00:28.000 --> 00:00:37.000
virtual worlds, digital globes, the 3-D Web, the Metaverse.

00:00:37.000 --> 00:00:39.000
What does this all mean for us?

00:00:39.000 --> 00:00:44.000
What it means is the Web is going to become an exciting place again.

00:00:44.000 --> 00:00:47.000
It's going to become super exciting as we transform

00:00:47.000 --> 00:00:51.000
to this highly immersive and interactive world.

00:00:51.000 --> 00:00:54.000
With graphics, computing power, low latencies,

00:00:54.000 --> 00:00:57.000
these types of applications and possibilities

00:00:57.000 --> 00:01:02.000
are going to stream rich data into your lives.

00:01:02.000 --> 00:01:07.000
So the Virtual Earth initiative, and other types of these initiatives,

00:01:07.000 --> 00:01:13.000
are all about extending our current search metaphor.

00:01:13.000 --> 00:01:16.000
When you think about it, we're so constrained by browsing the Web,

00:01:16.000 --> 00:01:19.000
remembering URLs, saving favorites.

00:01:19.000 --> 00:01:22.000
As we move to search, we rely on the relevance rankings,

00:01:22.000 --> 00:01:25.000
the Web matching, the index crawling.

00:01:25.000 --> 00:01:27.000
But we want to use our brain!

00:01:27.000 --> 00:01:30.000
We want to navigate, explore, discover information.

00:01:30.000 --> 00:01:35.000
In order to do that, we have to put you as a user back in the driver's seat.

00:01:35.000 --> 00:01:39.000
We need cooperation between you and the computing network and the computer.

00:01:39.000 --> 00:01:43.000
So what better way to put you back in the driver's seat

00:01:43.000 --> 00:01:46.000
than to put you in the real world that you interact in every day?

00:01:46.000 --> 00:01:50.000
Why not leverage the learnings that you've been learning your entire life?

00:01:50.000 --> 00:01:53.000
So Virtual Earth is about starting off

00:01:53.000 --> 00:01:58.000
creating the first digital representation, comprehensive, of the entire world.

00:01:58.000 --> 00:02:01.000
What we want to do is mix in all types of data.

00:02:01.000 --> 00:02:06.000
Tag it. Attribute it. Metadata. Get the community to add local depth,

00:02:06.000 --> 00:02:09.000
global perspective, local knowledge.

00:02:09.000 --> 00:02:11.000
So when you think about this problem,

00:02:11.000 --> 00:02:15.000
what an enormous undertaking. Where do you begin?

00:02:15.000 --> 00:02:19.000
Well, we collect data from satellites, from airplanes,

00:02:19.000 --> 00:02:22.000
from ground vehicles, from people.

00:02:22.000 --> 00:02:27.000
This process is an engineering problem,

00:02:27.000 --> 00:02:31.000
a mechanical problem, a logistical problem, an operational problem.

00:02:31.000 --> 00:02:33.000
Here is an example of our aerial camera.

00:02:33.000 --> 00:02:36.000
This is panchromatic. It's actually four color cones.

00:02:36.000 --> 00:02:38.000
In addition, it's multi-spectral.

00:02:38.000 --> 00:02:42.000
We collect four gigabits per second of data,

00:02:42.000 --> 00:02:44.000
if you can imagine that kind of data stream coming down.

00:02:44.000 --> 00:02:50.000
That's equivalent to a constellation of 12 satellites at highest res capacity.

00:02:50.000 --> 00:02:54.000
We fly these airplanes at 5,000 feet in the air.

00:02:54.000 --> 00:02:57.000
You can see the camera on the front. We collect multiple viewpoints,

00:02:57.000 --> 00:03:03.000
vantage points, angles, textures. We bring all that data back in.

00:03:03.000 --> 00:03:07.000
We sit here -- you know, think about the ground vehicles, the human scale --

00:03:07.000 --> 00:03:09.000
what do you see in person? We need to capture that up close

00:03:09.000 --> 00:03:13.000
to establish that what it's like-type experience.

00:03:13.000 --> 00:03:17.000
I bet many of you have seen the Apple commercials,

00:03:17.000 --> 00:03:23.000
kind of poking at the PC for their brilliance and simplicity.

00:03:23.000 --> 00:03:25.000
So a little unknown secret is --

00:03:25.000 --> 00:03:29.000
did you see the one with the guy, he's got the Web cam?

00:03:29.000 --> 00:03:33.000
The poor PC guy. They're duct taping his head. They're just wrapping it on him.

00:03:33.000 --> 00:03:37.000
Well, a little unknown secret is his brother actually works on the Virtual Earth team.

00:03:37.000 --> 00:03:42.000
(Laughter). So they've got a little bit of a sibling rivalry thing going on here.

00:03:42.000 --> 00:03:44.000
But let me tell you -- it doesn't affect his day job.

00:03:44.000 --> 00:03:47.000
We think a lot of good can come from this technology.

00:03:47.000 --> 00:03:51.000
This was after Katrina. We were the first commercial fleet of airplanes

00:03:51.000 --> 00:03:54.000
to be cleared into the disaster impact zone.

00:03:54.000 --> 00:03:59.000
We flew the area. We imaged it. We sent in people. We took pictures of interiors,

00:03:59.000 --> 00:04:03.000
disaster areas. We helped with the first responders, the search and rescue.

00:04:03.000 --> 00:04:08.000
Often the first time anyone saw what happened to their house was on Virtual Earth.

00:04:08.000 --> 00:04:10.000
We made it all freely available on the Web, just to --

00:04:10.000 --> 00:04:14.000
it was obviously our chance of helping out with the cause.

00:04:14.000 --> 00:04:17.000
When we think about how all this comes together,

00:04:17.000 --> 00:04:21.000
it's all about software, algorithms and math.

00:04:21.000 --> 00:04:24.000
You know, we capture this imagery but to build the 3-D models

00:04:24.000 --> 00:04:29.000
we need to do geo-positioning. We need to do geo-registering of the images.

00:04:29.000 --> 00:04:31.000
We have to bundle adjust them. Find tie points.

00:04:31.000 --> 00:04:34.000
Extract geometry from the images.

00:04:34.000 --> 00:04:38.000
This process is a very calculated process.

00:04:38.000 --> 00:04:39.000
In fact, it was always done manual.

00:04:39.000 --> 00:04:43.000
Hollywood would spend millions of dollars to do a small urban corridor

00:04:43.000 --> 00:04:46.000
for a movie because they'd have to do it manually.

00:04:46.000 --> 00:04:48.000
They'd drive the streets with lasers called LIDAR.

00:04:48.000 --> 00:04:52.000
They'd collected information with photos. They'd manually build each building.

00:04:52.000 --> 00:04:54.000
We do this all through software, algorithms and math --

00:04:54.000 --> 00:04:57.000
a highly automated pipeline creating these cities.

00:04:57.000 --> 00:05:00.000
We took a decimal point off what it cost to build these cities,

00:05:00.000 --> 00:05:04.000
and that's how we're going to be able to scale this out and make this reality a dream.

00:05:04.000 --> 00:05:06.000
We think about the user interface.

00:05:06.000 --> 00:05:09.000
What does it mean to look at it from multiple perspectives?

00:05:09.000 --> 00:05:14.000
An ortho-view, a nadir-view. How do you keep the precision of the fidelity of the imagery

00:05:14.000 --> 00:05:18.000
while maintaining the fluidity of the model?

00:05:18.000 --> 00:05:20.000
I'll wrap up by showing you the --

00:05:20.000 --> 00:05:24.000
this is a brand-new peek I haven't really shown into the lab area of Virtual Earth.

00:05:24.000 --> 00:05:27.000
What we're doing is -- people like this a lot,

00:05:27.000 --> 00:05:30.000
this bird's eye imagery we work with. It's this high resolution data.

00:05:30.000 --> 00:05:34.000
But what we've found is they like the fluidity of the 3-D model.

00:05:34.000 --> 00:05:38.000
A child can navigate with an Xbox controller or a game controller.

00:05:38.000 --> 00:05:43.000
So here what we're trying to do is we bring the picture and project it into the 3-D model space.

00:05:43.000 --> 00:05:49.000
You can see all types of resolution. From here, I can slowly pan the image over.

00:05:49.000 --> 00:05:52.000
I can get the next image. I can blend and transition.

00:05:52.000 --> 00:05:57.000
By doing this I don't lose the original detail. In fact, I might be recording history.

00:05:57.000 --> 00:06:00.000
The freshness, the capacity. I can turn this image.

00:06:00.000 --> 00:06:03.000
I can look at it from multiple viewpoints and angles.

00:06:03.000 --> 00:06:06.000
What we're trying to do is build a virtual world.

00:06:06.000 --> 00:06:11.000
We hope that we can make computing a user model you're familiar with,

00:06:11.000 --> 00:06:15.000
and really derive insights from you, from all different directions.

00:06:15.000 --> 00:06:17.000
I thank you very much for your time.

00:06:17.000 --> 00:06:18.000
(Applause)

