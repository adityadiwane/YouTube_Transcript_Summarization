WEBVTT
Kind: captions
Language: en

00:00:15.260 --> 00:00:18.260
For the last 10 years, I've been spending my time trying to figure out

00:00:18.260 --> 00:00:20.260
how and why human beings

00:00:20.260 --> 00:00:23.260
assemble themselves into social networks.

00:00:23.260 --> 00:00:25.260
And the kind of social network I'm talking about

00:00:25.260 --> 00:00:27.260
is not the recent online variety,

00:00:27.260 --> 00:00:29.260
but rather, the kind of social networks

00:00:29.260 --> 00:00:32.260
that human beings have been assembling for hundreds of thousands of years,

00:00:32.260 --> 00:00:35.260
ever since we emerged from the African savannah.

00:00:35.260 --> 00:00:37.260
So, I form friendships and co-worker

00:00:37.260 --> 00:00:40.260
and sibling and relative relationships with other people

00:00:40.260 --> 00:00:42.260
who in turn have similar relationships with other people.

00:00:42.260 --> 00:00:45.260
And this spreads on out endlessly into a distance.

00:00:45.260 --> 00:00:47.260
And you get a network that looks like this.

00:00:47.260 --> 00:00:49.260
Every dot is a person.

00:00:49.260 --> 00:00:51.260
Every line between them is a relationship between two people --

00:00:51.260 --> 00:00:53.260
different kinds of relationships.

00:00:53.260 --> 00:00:56.260
And you can get this kind of vast fabric of humanity,

00:00:56.260 --> 00:00:58.260
in which we're all embedded.

00:00:58.260 --> 00:01:01.260
And my colleague, James Fowler and I have been studying for quite sometime

00:01:01.260 --> 00:01:03.260
what are the mathematical, social,

00:01:03.260 --> 00:01:06.260
biological and psychological rules

00:01:06.260 --> 00:01:08.260
that govern how these networks are assembled

00:01:08.260 --> 00:01:10.260
and what are the similar rules

00:01:10.260 --> 00:01:13.260
that govern how they operate, how they affect our lives.

00:01:13.260 --> 00:01:15.260
But recently, we've been wondering

00:01:15.260 --> 00:01:18.260
whether it might be possible to take advantage of this insight,

00:01:18.260 --> 00:01:20.260
to actually find ways to improve the world,

00:01:20.260 --> 00:01:22.260
to do something better,

00:01:22.260 --> 00:01:25.260
to actually fix things, not just understand things.

00:01:25.260 --> 00:01:28.260
So one of the first things we thought we would tackle

00:01:28.260 --> 00:01:31.260
would be how we go about predicting epidemics.

00:01:31.260 --> 00:01:33.260
And the current state of the art in predicting an epidemic --

00:01:33.260 --> 00:01:36.260
if you're the CDC or some other national body --

00:01:36.260 --> 00:01:38.260
is to sit in the middle where you are

00:01:38.260 --> 00:01:40.260
and collect data

00:01:40.260 --> 00:01:42.260
from physicians and laboratories in the field

00:01:42.260 --> 00:01:45.260
that report the prevalence or the incidence of certain conditions.

00:01:45.260 --> 00:01:48.260
So, so and so patients have been diagnosed with something,

00:01:48.260 --> 00:01:50.260
or other patients have been diagnosed,

00:01:50.260 --> 00:01:53.260
and all these data are fed into a central repository, with some delay.

00:01:53.260 --> 00:01:55.260
And if everything goes smoothly,

00:01:55.260 --> 00:01:57.260
one to two weeks from now

00:01:57.260 --> 00:02:00.260
you'll know where the epidemic was today.

00:02:00.260 --> 00:02:02.260
And actually, about a year or so ago,

00:02:02.260 --> 00:02:04.260
there was this promulgation

00:02:04.260 --> 00:02:07.260
of the idea of Google Flu Trends, with respect to the flu,

00:02:07.260 --> 00:02:10.260
where by looking at people's searching behavior today,

00:02:10.260 --> 00:02:12.260
we could know where the flu --

00:02:12.260 --> 00:02:14.260
what the status of the epidemic was today,

00:02:14.260 --> 00:02:17.260
what's the prevalence of the epidemic today.

00:02:17.260 --> 00:02:19.260
But what I'd like to show you today

00:02:19.260 --> 00:02:21.260
is a means by which we might get

00:02:21.260 --> 00:02:24.260
not just rapid warning about an epidemic,

00:02:24.260 --> 00:02:26.260
but also actually

00:02:26.260 --> 00:02:28.260
early detection of an epidemic.

00:02:28.260 --> 00:02:30.260
And, in fact, this idea can be used

00:02:30.260 --> 00:02:33.260
not just to predict epidemics of germs,

00:02:33.260 --> 00:02:36.260
but also to predict epidemics of all sorts of kinds.

00:02:37.260 --> 00:02:40.260
For example, anything that spreads by a form of social contagion

00:02:40.260 --> 00:02:42.260
could be understood in this way,

00:02:42.260 --> 00:02:44.260
from abstract ideas on the left

00:02:44.260 --> 00:02:47.260
like patriotism, or altruism, or religion

00:02:47.260 --> 00:02:49.260
to practices

00:02:49.260 --> 00:02:51.260
like dieting behavior, or book purchasing,

00:02:51.260 --> 00:02:54.260
or drinking, or bicycle-helmet [and] other safety practices,

00:02:54.260 --> 00:02:56.260
or products that people might buy,

00:02:56.260 --> 00:02:58.260
purchases of electronic goods,

00:02:58.260 --> 00:03:01.260
anything in which there's kind of an interpersonal spread.

00:03:01.260 --> 00:03:03.260
A kind of a diffusion of innovation

00:03:03.260 --> 00:03:05.260
could be understood and predicted

00:03:05.260 --> 00:03:08.260
by the mechanism I'm going to show you now.

00:03:08.260 --> 00:03:10.260
So, as all of you probably know,

00:03:10.260 --> 00:03:12.260
the classic way of thinking about this

00:03:12.260 --> 00:03:14.260
is the diffusion-of-innovation,

00:03:14.260 --> 00:03:16.260
or the adoption curve.

00:03:16.260 --> 00:03:18.260
So here on the Y-axis, we have the percent of the people affected,

00:03:18.260 --> 00:03:20.260
and on the X-axis, we have time.

00:03:20.260 --> 00:03:23.260
And at the very beginning, not too many people are affected,

00:03:23.260 --> 00:03:25.260
and you get this classic sigmoidal,

00:03:25.260 --> 00:03:27.260
or S-shaped, curve.

00:03:27.260 --> 00:03:29.260
And the reason for this shape is that at the very beginning,

00:03:29.260 --> 00:03:31.260
let's say one or two people

00:03:31.260 --> 00:03:33.260
are infected, or affected by the thing

00:03:33.260 --> 00:03:35.260
and then they affect, or infect, two people,

00:03:35.260 --> 00:03:38.260
who in turn affect four, eight, 16 and so forth,

00:03:38.260 --> 00:03:41.260
and you get the epidemic growth phase of the curve.

00:03:41.260 --> 00:03:43.260
And eventually, you saturate the population.

00:03:43.260 --> 00:03:45.260
There are fewer and fewer people

00:03:45.260 --> 00:03:47.260
who are still available that you might infect,

00:03:47.260 --> 00:03:49.260
and then you get the plateau of the curve,

00:03:49.260 --> 00:03:52.260
and you get this classic sigmoidal curve.

00:03:52.260 --> 00:03:54.260
And this holds for germs, ideas,

00:03:54.260 --> 00:03:56.260
product adoption, behaviors,

00:03:56.260 --> 00:03:58.260
and the like.

00:03:58.260 --> 00:04:01.260
But things don't just diffuse in human populations at random.

00:04:01.260 --> 00:04:03.260
They actually diffuse through networks.

00:04:03.260 --> 00:04:06.260
Because, as I said, we live our lives in networks,

00:04:06.260 --> 00:04:09.260
and these networks have a particular kind of a structure.

00:04:09.260 --> 00:04:11.260
Now if you look at a network like this --

00:04:11.260 --> 00:04:13.260
this is 105 people.

00:04:13.260 --> 00:04:15.260
And the lines represent -- the dots are the people,

00:04:15.260 --> 00:04:17.260
and the lines represent friendship relationships.

00:04:17.260 --> 00:04:19.260
You might see that people occupy

00:04:19.260 --> 00:04:21.260
different locations within the network.

00:04:21.260 --> 00:04:23.260
And there are different kinds of relationships between the people.

00:04:23.260 --> 00:04:26.260
You could have friendship relationships, sibling relationships,

00:04:26.260 --> 00:04:29.260
spousal relationships, co-worker relationships,

00:04:29.260 --> 00:04:32.260
neighbor relationships and the like.

00:04:32.260 --> 00:04:34.260
And different sorts of things

00:04:34.260 --> 00:04:36.260
spread across different sorts of ties.

00:04:36.260 --> 00:04:38.260
For instance, sexually transmitted diseases

00:04:38.260 --> 00:04:40.260
will spread across sexual ties.

00:04:40.260 --> 00:04:42.260
Or, for instance, people's smoking behavior

00:04:42.260 --> 00:04:44.260
might be influenced by their friends.

00:04:44.260 --> 00:04:46.260
Or their altruistic or their charitable giving behavior

00:04:46.260 --> 00:04:48.260
might be influenced by their coworkers,

00:04:48.260 --> 00:04:50.260
or by their neighbors.

00:04:50.260 --> 00:04:53.260
But not all positions in the network are the same.

00:04:53.260 --> 00:04:55.260
So if you look at this, you might immediately grasp

00:04:55.260 --> 00:04:58.260
that different people have different numbers of connections.

00:04:58.260 --> 00:05:00.260
Some people have one connection, some have two,

00:05:00.260 --> 00:05:03.260
some have six, some have 10 connections.

00:05:03.260 --> 00:05:05.260
And this is called the "degree" of a node,

00:05:05.260 --> 00:05:07.260
or the number of connections that a node has.

00:05:07.260 --> 00:05:09.260
But in addition, there's something else.

00:05:09.260 --> 00:05:11.260
So, if you look at nodes A and B,

00:05:11.260 --> 00:05:13.260
they both have six connections.

00:05:13.260 --> 00:05:16.260
But if you can see this image [of the network] from a bird's eye view,

00:05:16.260 --> 00:05:18.260
you can appreciate that there's something very different

00:05:18.260 --> 00:05:20.260
about nodes A and B.

00:05:20.260 --> 00:05:23.260
So, let me ask you this -- I can cultivate this intuition by asking a question --

00:05:23.260 --> 00:05:25.260
who would you rather be

00:05:25.260 --> 00:05:28.260
if a deadly germ was spreading through the network, A or B?

00:05:28.260 --> 00:05:30.260
(Audience: B.) Nicholas Christakis: B, it's obvious.

00:05:30.260 --> 00:05:32.260
B is located on the edge of the network.

00:05:32.260 --> 00:05:34.260
Now, who would you rather be

00:05:34.260 --> 00:05:37.260
if a juicy piece of gossip were spreading through the network?

00:05:37.260 --> 00:05:40.260
A. And you have an immediate appreciation

00:05:40.260 --> 00:05:42.260
that A is going to be more likely

00:05:42.260 --> 00:05:45.260
to get the thing that's spreading and to get it sooner

00:05:45.260 --> 00:05:48.260
by virtue of their structural location within the network.

00:05:48.260 --> 00:05:50.260
A, in fact, is more central,

00:05:50.260 --> 00:05:53.260
and this can be formalized mathematically.

00:05:53.260 --> 00:05:55.260
So, if we want to track something

00:05:55.260 --> 00:05:58.260
that was spreading through a network,

00:05:58.260 --> 00:06:00.260
what we ideally would like to do is to set up sensors

00:06:00.260 --> 00:06:02.260
on the central individuals within the network,

00:06:02.260 --> 00:06:04.260
including node A,

00:06:04.260 --> 00:06:07.260
monitor those people that are right there in the middle of the network,

00:06:07.260 --> 00:06:09.260
and somehow get an early detection

00:06:09.260 --> 00:06:12.260
of whatever it is that is spreading through the network.

00:06:12.260 --> 00:06:15.260
So if you saw them contract a germ or a piece of information,

00:06:15.260 --> 00:06:17.260
you would know that, soon enough,

00:06:17.260 --> 00:06:19.260
everybody was about to contract this germ

00:06:19.260 --> 00:06:21.260
or this piece of information.

00:06:21.260 --> 00:06:23.260
And this would be much better

00:06:23.260 --> 00:06:25.260
than monitoring six randomly chosen people,

00:06:25.260 --> 00:06:28.260
without reference to the structure of the population.

00:06:28.260 --> 00:06:30.260
And in fact, if you could do that,

00:06:30.260 --> 00:06:32.260
what you would see is something like this.

00:06:32.260 --> 00:06:35.260
On the left-hand panel, again, we have the S-shaped curve of adoption.

00:06:35.260 --> 00:06:37.260
In the dotted red line, we show

00:06:37.260 --> 00:06:39.260
what the adoption would be in the random people,

00:06:39.260 --> 00:06:42.260
and in the left-hand line, shifted to the left,

00:06:42.260 --> 00:06:44.260
we show what the adoption would be

00:06:44.260 --> 00:06:46.260
in the central individuals within the network.

00:06:46.260 --> 00:06:48.260
On the Y-axis is the cumulative instances of contagion,

00:06:48.260 --> 00:06:50.260
and on the X-axis is the time.

00:06:50.260 --> 00:06:52.260
And on the right-hand side, we show the same data,

00:06:52.260 --> 00:06:54.260
but here with daily incidence.

00:06:54.260 --> 00:06:56.260
And what we show here is -- like, here --

00:06:56.260 --> 00:06:58.260
very few people are affected, more and more and more and up to here,

00:06:58.260 --> 00:07:00.260
and here's the peak of the epidemic.

00:07:00.260 --> 00:07:02.260
But shifted to the left is what's occurring in the central individuals.

00:07:02.260 --> 00:07:05.260
And this difference in time between the two

00:07:05.260 --> 00:07:08.260
is the early detection, the early warning we can get,

00:07:08.260 --> 00:07:10.260
about an impending epidemic

00:07:10.260 --> 00:07:12.260
in the human population.

00:07:12.260 --> 00:07:14.260
The problem, however,

00:07:14.260 --> 00:07:16.260
is that mapping human social networks

00:07:16.260 --> 00:07:18.260
is not always possible.

00:07:18.260 --> 00:07:20.260
It can be expensive, not feasible,

00:07:20.260 --> 00:07:22.260
unethical,

00:07:22.260 --> 00:07:25.260
or, frankly, just not possible to do such a thing.

00:07:25.260 --> 00:07:27.260
So, how can we figure out

00:07:27.260 --> 00:07:29.260
who the central people are in a network

00:07:29.260 --> 00:07:32.260
without actually mapping the network?

00:07:32.260 --> 00:07:34.260
What we came up with

00:07:34.260 --> 00:07:36.260
was an idea to exploit an old fact,

00:07:36.260 --> 00:07:38.260
or a known fact, about social networks,

00:07:38.260 --> 00:07:40.260
which goes like this:

00:07:40.260 --> 00:07:42.260
Do you know that your friends

00:07:42.260 --> 00:07:45.260
have more friends than you do?

00:07:45.260 --> 00:07:48.260
Your friends have more friends than you do,

00:07:48.260 --> 00:07:50.260
and this is known as the friendship paradox.

00:07:50.260 --> 00:07:52.260
Imagine a very popular person in the social network --

00:07:52.260 --> 00:07:55.260
like a party host who has hundreds of friends --

00:07:55.260 --> 00:07:57.260
and a misanthrope who has just one friend,

00:07:57.260 --> 00:08:00.260
and you pick someone at random from the population;

00:08:00.260 --> 00:08:02.260
they were much more likely to know the party host.

00:08:02.260 --> 00:08:04.260
And if they nominate the party host as their friend,

00:08:04.260 --> 00:08:06.260
that party host has a hundred friends,

00:08:06.260 --> 00:08:09.260
therefore, has more friends than they do.

00:08:09.260 --> 00:08:12.260
And this, in essence, is what's known as the friendship paradox.

00:08:12.260 --> 00:08:15.260
The friends of randomly chosen people

00:08:15.260 --> 00:08:17.260
have higher degree, and are more central

00:08:17.260 --> 00:08:19.260
than the random people themselves.

00:08:19.260 --> 00:08:21.260
And you can get an intuitive appreciation for this

00:08:21.260 --> 00:08:24.260
if you imagine just the people at the perimeter of the network.

00:08:24.260 --> 00:08:26.260
If you pick this person,

00:08:26.260 --> 00:08:29.260
the only friend they have to nominate is this person,

00:08:29.260 --> 00:08:31.260
who, by construction, must have at least two

00:08:31.260 --> 00:08:33.260
and typically more friends.

00:08:33.260 --> 00:08:35.260
And that happens at every peripheral node.

00:08:35.260 --> 00:08:38.260
And in fact, it happens throughout the network as you move in,

00:08:38.260 --> 00:08:40.260
everyone you pick, when they nominate a random --

00:08:40.260 --> 00:08:43.260
when a random person nominates a friend of theirs,

00:08:43.260 --> 00:08:46.260
you move closer to the center of the network.

00:08:46.260 --> 00:08:49.260
So, we thought we would exploit this idea

00:08:49.260 --> 00:08:52.260
in order to study whether we could predict phenomena within networks.

00:08:52.260 --> 00:08:54.260
Because now, with this idea

00:08:54.260 --> 00:08:56.260
we can take a random sample of people,

00:08:56.260 --> 00:08:58.260
have them nominate their friends,

00:08:58.260 --> 00:09:00.260
those friends would be more central,

00:09:00.260 --> 00:09:03.260
and we could do this without having to map the network.

00:09:03.260 --> 00:09:06.260
And we tested this idea with an outbreak of H1N1 flu

00:09:06.260 --> 00:09:08.260
at Harvard College

00:09:08.260 --> 00:09:11.260
in the fall and winter of 2009, just a few months ago.

00:09:11.260 --> 00:09:14.260
We took 1,300 randomly selected undergraduates,

00:09:14.260 --> 00:09:16.260
we had them nominate their friends,

00:09:16.260 --> 00:09:18.260
and we followed both the random students and their friends

00:09:18.260 --> 00:09:20.260
daily in time

00:09:20.260 --> 00:09:23.260
to see whether or not they had the flu epidemic.

00:09:23.260 --> 00:09:26.260
And we did this passively by looking at whether or not they'd gone to university health services.

00:09:26.260 --> 00:09:29.260
And also, we had them [actively] email us a couple of times a week.

00:09:29.260 --> 00:09:32.260
Exactly what we predicted happened.

00:09:32.260 --> 00:09:35.260
So the random group is in the red line.

00:09:35.260 --> 00:09:38.260
The epidemic in the friends group has shifted to the left, over here.

00:09:38.260 --> 00:09:41.260
And the difference in the two is 16 days.

00:09:41.260 --> 00:09:43.260
By monitoring the friends group,

00:09:43.260 --> 00:09:45.260
we could get 16 days advance warning

00:09:45.260 --> 00:09:48.260
of an impending epidemic in this human population.

00:09:48.260 --> 00:09:50.260
Now, in addition to that,

00:09:50.260 --> 00:09:53.260
if you were an analyst who was trying to study an epidemic

00:09:53.260 --> 00:09:56.260
or to predict the adoption of a product, for example,

00:09:56.260 --> 00:09:59.260
what you could do is you could pick a random sample of the population,

00:09:59.260 --> 00:10:02.260
also have them nominate their friends and follow the friends

00:10:02.260 --> 00:10:05.260
and follow both the randoms and the friends.

00:10:05.260 --> 00:10:08.260
Among the friends, the first evidence you saw of a blip above zero

00:10:08.260 --> 00:10:11.260
in adoption of the innovation, for example,

00:10:11.260 --> 00:10:13.260
would be evidence of an impending epidemic.

00:10:13.260 --> 00:10:16.260
Or you could see the first time the two curves diverged,

00:10:16.260 --> 00:10:18.260
as shown on the left.

00:10:18.260 --> 00:10:21.260
When did the randoms -- when did the friends take off

00:10:21.260 --> 00:10:23.260
and leave the randoms,

00:10:23.260 --> 00:10:25.260
and [when did] their curve start shifting?

00:10:25.260 --> 00:10:27.260
And that, as indicated by the white line,

00:10:27.260 --> 00:10:29.260
occurred 46 days

00:10:29.260 --> 00:10:31.260
before the peak of the epidemic.

00:10:31.260 --> 00:10:33.260
So this would be a technique

00:10:33.260 --> 00:10:35.260
whereby we could get more than a month-and-a-half warning

00:10:35.260 --> 00:10:38.260
about a flu epidemic in a particular population.

00:10:38.260 --> 00:10:40.260
I should say that

00:10:40.260 --> 00:10:42.260
how far advanced a notice one might get about something

00:10:42.260 --> 00:10:44.260
depends on a host of factors.

00:10:44.260 --> 00:10:46.260
It could depend on the nature of the pathogen --

00:10:46.260 --> 00:10:48.260
different pathogens,

00:10:48.260 --> 00:10:50.260
using this technique, you'd get different warning --

00:10:50.260 --> 00:10:52.260
or other phenomena that are spreading,

00:10:52.260 --> 00:10:55.260
or frankly, on the structure of the human network.

00:10:55.260 --> 00:10:58.260
Now in our case, although it wasn't necessary,

00:10:58.260 --> 00:11:00.260
we could also actually map the network of the students.

00:11:00.260 --> 00:11:02.260
So, this is a map of 714 students

00:11:02.260 --> 00:11:04.260
and their friendship ties.

00:11:04.260 --> 00:11:06.260
And in a minute now, I'm going to put this map into motion.

00:11:06.260 --> 00:11:08.260
We're going to take daily cuts through the network

00:11:08.260 --> 00:11:10.260
for 120 days.

00:11:10.260 --> 00:11:13.260
The red dots are going to be cases of the flu,

00:11:13.260 --> 00:11:16.260
and the yellow dots are going to be friends of the people with the flu.

00:11:16.260 --> 00:11:18.260
And the size of the dots is going to be proportional

00:11:18.260 --> 00:11:20.260
to how many of their friends have the flu.

00:11:20.260 --> 00:11:23.260
So bigger dots mean more of your friends have the flu.

00:11:23.260 --> 00:11:26.260
And if you look at this image -- here we are now in September the 13th --

00:11:26.260 --> 00:11:28.260
you're going to see a few cases light up.

00:11:28.260 --> 00:11:30.260
You're going to see kind of blooming of the flu in the middle.

00:11:30.260 --> 00:11:33.260
Here we are on October the 19th.

00:11:33.260 --> 00:11:35.260
The slope of the epidemic curve is approaching now, in November.

00:11:35.260 --> 00:11:38.260
Bang, bang, bang, bang, bang -- you're going to see lots of blooming in the middle,

00:11:38.260 --> 00:11:40.260
and then you're going to see a sort of leveling off,

00:11:40.260 --> 00:11:43.260
fewer and fewer cases towards the end of December.

00:11:43.260 --> 00:11:45.260
And this type of a visualization

00:11:45.260 --> 00:11:47.260
can show that epidemics like this take root

00:11:47.260 --> 00:11:49.260
and affect central individuals first,

00:11:49.260 --> 00:11:51.260
before they affect others.

00:11:51.260 --> 00:11:53.260
Now, as I've been suggesting,

00:11:53.260 --> 00:11:56.260
this method is not restricted to germs,

00:11:56.260 --> 00:11:58.260
but actually to anything that spreads in populations.

00:11:58.260 --> 00:12:00.260
Information spreads in populations,

00:12:00.260 --> 00:12:02.260
norms can spread in populations,

00:12:02.260 --> 00:12:04.260
behaviors can spread in populations.

00:12:04.260 --> 00:12:07.260
And by behaviors, I can mean things like criminal behavior,

00:12:07.260 --> 00:12:10.260
or voting behavior, or health care behavior,

00:12:10.260 --> 00:12:12.260
like smoking, or vaccination,

00:12:12.260 --> 00:12:14.260
or product adoption, or other kinds of behaviors

00:12:14.260 --> 00:12:16.260
that relate to interpersonal influence.

00:12:16.260 --> 00:12:19.260
If I'm likely to do something that affects others around me,

00:12:19.260 --> 00:12:22.260
this technique can get early warning or early detection

00:12:22.260 --> 00:12:25.260
about the adoption within the population.

00:12:25.260 --> 00:12:27.260
The key thing is that for it to work,

00:12:27.260 --> 00:12:29.260
there has to be interpersonal influence.

00:12:29.260 --> 00:12:31.260
It cannot be because of some broadcast mechanism

00:12:31.260 --> 00:12:34.260
affecting everyone uniformly.

00:12:35.260 --> 00:12:37.260
Now the same insights

00:12:37.260 --> 00:12:40.260
can also be exploited -- with respect to networks --

00:12:40.260 --> 00:12:43.260
can also be exploited in other ways,

00:12:43.260 --> 00:12:45.260
for example, in the use of targeting

00:12:45.260 --> 00:12:47.260
specific people for interventions.

00:12:47.260 --> 00:12:49.260
So, for example, most of you are probably familiar

00:12:49.260 --> 00:12:51.260
with the notion of herd immunity.

00:12:51.260 --> 00:12:54.260
So, if we have a population of a thousand people,

00:12:54.260 --> 00:12:57.260
and we want to make the population immune to a pathogen,

00:12:57.260 --> 00:12:59.260
we don't have to immunize every single person.

00:12:59.260 --> 00:13:01.260
If we immunize 960 of them,

00:13:01.260 --> 00:13:04.260
it's as if we had immunized a hundred [percent] of them.

00:13:04.260 --> 00:13:07.260
Because even if one or two of the non-immune people gets infected,

00:13:07.260 --> 00:13:09.260
there's no one for them to infect.

00:13:09.260 --> 00:13:11.260
They are surrounded by immunized people.

00:13:11.260 --> 00:13:14.260
So 96 percent is as good as 100 percent.

00:13:14.260 --> 00:13:16.260
Well, some other scientists have estimated

00:13:16.260 --> 00:13:18.260
what would happen if you took a 30 percent random sample

00:13:18.260 --> 00:13:21.260
of these 1000 people, 300 people and immunized them.

00:13:21.260 --> 00:13:23.260
Would you get any population-level immunity?

00:13:23.260 --> 00:13:26.260
And the answer is no.

00:13:26.260 --> 00:13:28.260
But if you took this 30 percent, these 300 people

00:13:28.260 --> 00:13:30.260
and had them nominate their friends

00:13:30.260 --> 00:13:33.260
and took the same number of vaccine doses

00:13:33.260 --> 00:13:35.260
and vaccinated the friends of the 300 --

00:13:35.260 --> 00:13:37.260
the 300 friends --

00:13:37.260 --> 00:13:39.260
you can get the same level of herd immunity

00:13:39.260 --> 00:13:42.260
as if you had vaccinated 96 percent of the population

00:13:42.260 --> 00:13:45.260
at a much greater efficiency, with a strict budget constraint.

00:13:45.260 --> 00:13:47.260
And similar ideas can be used, for instance,

00:13:47.260 --> 00:13:49.260
to target distribution of things like bed nets

00:13:49.260 --> 00:13:51.260
in the developing world.

00:13:51.260 --> 00:13:54.260
If we could understand the structure of networks in villages,

00:13:54.260 --> 00:13:56.260
we could target to whom to give the interventions

00:13:56.260 --> 00:13:58.260
to foster these kinds of spreads.

00:13:58.260 --> 00:14:01.260
Or, frankly, for advertising with all kinds of products.

00:14:01.260 --> 00:14:03.260
If we could understand how to target,

00:14:03.260 --> 00:14:05.260
it could affect the efficiency

00:14:05.260 --> 00:14:07.260
of what we're trying to achieve.

00:14:07.260 --> 00:14:09.260
And in fact, we can use data

00:14:09.260 --> 00:14:11.260
from all kinds of sources nowadays [to do this].

00:14:11.260 --> 00:14:13.260
This is a map of eight million phone users

00:14:13.260 --> 00:14:15.260
in a European country.

00:14:15.260 --> 00:14:17.260
Every dot is a person, and every line represents

00:14:17.260 --> 00:14:19.260
a volume of calls between the people.

00:14:19.260 --> 00:14:22.260
And we can use such data, that's being passively obtained,

00:14:22.260 --> 00:14:24.260
to map these whole countries

00:14:24.260 --> 00:14:27.260
and understand who is located where within the network.

00:14:27.260 --> 00:14:29.260
Without actually having to query them at all,

00:14:29.260 --> 00:14:31.260
we can get this kind of a structural insight.

00:14:31.260 --> 00:14:34.260
And other sources of information, as you're no doubt aware

00:14:34.260 --> 00:14:37.260
are available about such features, from email interactions,

00:14:37.260 --> 00:14:39.260
online interactions,

00:14:39.260 --> 00:14:42.260
online social networks and so forth.

00:14:42.260 --> 00:14:44.260
And in fact, we are in the era of what I would call

00:14:44.260 --> 00:14:47.260
"massive-passive" data collection efforts.

00:14:47.260 --> 00:14:50.260
They're all kinds of ways we can use massively collected data

00:14:50.260 --> 00:14:53.260
to create sensor networks

00:14:53.260 --> 00:14:55.260
to follow the population,

00:14:55.260 --> 00:14:57.260
understand what's happening in the population,

00:14:57.260 --> 00:15:00.260
and intervene in the population for the better.

00:15:00.260 --> 00:15:02.260
Because these new technologies tell us

00:15:02.260 --> 00:15:04.260
not just who is talking to whom,

00:15:04.260 --> 00:15:06.260
but where everyone is,

00:15:06.260 --> 00:15:09.260
and what they're thinking based on what they're uploading on the Internet,

00:15:09.260 --> 00:15:11.260
and what they're buying based on their purchases.

00:15:11.260 --> 00:15:14.260
And all this administrative data can be pulled together

00:15:14.260 --> 00:15:16.260
and processed to understand human behavior

00:15:16.260 --> 00:15:19.260
in a way we never could before.

00:15:19.260 --> 00:15:22.260
So, for example, we could use truckers' purchases of fuel.

00:15:22.260 --> 00:15:24.260
So the truckers are just going about their business,

00:15:24.260 --> 00:15:26.260
and they're buying fuel.

00:15:26.260 --> 00:15:29.260
And we see a blip up in the truckers' purchases of fuel,

00:15:29.260 --> 00:15:31.260
and we know that a recession is about to end.

00:15:31.260 --> 00:15:33.260
Or we can monitor the velocity

00:15:33.260 --> 00:15:36.260
with which people are moving with their phones on a highway,

00:15:36.260 --> 00:15:38.260
and the phone company can see,

00:15:38.260 --> 00:15:40.260
as the velocity is slowing down,

00:15:40.260 --> 00:15:42.260
that there's a traffic jam.

00:15:42.260 --> 00:15:45.260
And they can feed that information back to their subscribers,

00:15:45.260 --> 00:15:47.260
but only to their subscribers on the same highway

00:15:47.260 --> 00:15:49.260
located behind the traffic jam!

00:15:49.260 --> 00:15:52.260
Or we can monitor doctors prescribing behaviors, passively,

00:15:52.260 --> 00:15:55.260
and see how the diffusion of innovation with pharmaceuticals

00:15:55.260 --> 00:15:57.260
occurs within [networks of] doctors.

00:15:57.260 --> 00:15:59.260
Or again, we can monitor purchasing behavior in people

00:15:59.260 --> 00:16:01.260
and watch how these types of phenomena

00:16:01.260 --> 00:16:04.260
can diffuse within human populations.

00:16:04.260 --> 00:16:06.260
And there are three ways, I think,

00:16:06.260 --> 00:16:08.260
that these massive-passive data can be used.

00:16:08.260 --> 00:16:10.260
One is fully passive,

00:16:10.260 --> 00:16:12.260
like I just described --

00:16:12.260 --> 00:16:14.260
as in, for instance, the trucker example,

00:16:14.260 --> 00:16:16.260
where we don't actually intervene in the population in any way.

00:16:16.260 --> 00:16:18.260
One is quasi-active,

00:16:18.260 --> 00:16:20.260
like the flu example I gave,

00:16:20.260 --> 00:16:23.260
where we get some people to nominate their friends

00:16:23.260 --> 00:16:25.260
and then passively monitor their friends --

00:16:25.260 --> 00:16:27.260
do they have the flu, or not? -- and then get warning.

00:16:27.260 --> 00:16:29.260
Or another example would be,

00:16:29.260 --> 00:16:32.260
if you're a phone company, you figure out who's central in the network

00:16:32.260 --> 00:16:35.260
and you ask those people, "Look, will you just text us your fever every day?

00:16:35.260 --> 00:16:37.260
Just text us your temperature."

00:16:37.260 --> 00:16:40.260
And collect vast amounts of information about people's temperature,

00:16:40.260 --> 00:16:42.260
but from centrally located individuals.

00:16:42.260 --> 00:16:44.260
And be able, on a large scale,

00:16:44.260 --> 00:16:46.260
to monitor an impending epidemic

00:16:46.260 --> 00:16:48.260
with very minimal input from people.

00:16:48.260 --> 00:16:50.260
Or, finally, it can be more fully active --

00:16:50.260 --> 00:16:52.260
as I know subsequent speakers will also talk about today --

00:16:52.260 --> 00:16:54.260
where people might globally participate in wikis,

00:16:54.260 --> 00:16:57.260
or photographing, or monitoring elections,

00:16:57.260 --> 00:16:59.260
and upload information in a way that allows us to pool

00:16:59.260 --> 00:17:01.260
information in order to understand social processes

00:17:01.260 --> 00:17:03.260
and social phenomena.

00:17:03.260 --> 00:17:05.260
In fact, the availability of these data, I think,

00:17:05.260 --> 00:17:07.260
heralds a kind of new era

00:17:07.260 --> 00:17:09.260
of what I and others would like to call

00:17:09.260 --> 00:17:11.260
"computational social science."

00:17:11.260 --> 00:17:14.260
It's sort of like when Galileo invented -- or, didn't invent --

00:17:14.260 --> 00:17:16.260
came to use a telescope

00:17:16.260 --> 00:17:18.260
and could see the heavens in a new way,

00:17:18.260 --> 00:17:20.260
or Leeuwenhoek became aware of the microscope --

00:17:20.260 --> 00:17:22.260
or actually invented --

00:17:22.260 --> 00:17:24.260
and could see biology in a new way.

00:17:24.260 --> 00:17:26.260
But now we have access to these kinds of data

00:17:26.260 --> 00:17:28.260
that allow us to understand social processes

00:17:28.260 --> 00:17:30.260
and social phenomena

00:17:30.260 --> 00:17:33.260
in an entirely new way that was never before possible.

00:17:33.260 --> 00:17:35.260
And with this science, we can

00:17:35.260 --> 00:17:37.260
understand how exactly

00:17:37.260 --> 00:17:39.260
the whole comes to be greater

00:17:39.260 --> 00:17:41.260
than the sum of its parts.

00:17:41.260 --> 00:17:43.260
And actually, we can use these insights

00:17:43.260 --> 00:17:46.260
to improve society and improve human well-being.

00:17:46.260 --> 00:17:48.260
Thank you.

